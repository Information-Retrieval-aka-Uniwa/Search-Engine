[
    {
        "doc_id": 0,
        "title": "Monadic transductions and definable classes of matroids",
        "authors": [
            "Susan Jowett",
            "Dillon Mayhew",
            "Songbao Mo",
            "Christopher Tuffley"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "A transduction provides us with a way of using the monadic second-order language of a structure to make statements about a derived structure. Any transduction induces a relation on the set of these structures. This article presents a self-contained presentation of the theory of transductions for the monadic second-order language of matroids. This includes a proof of the matroid version of the Backwards Translation Theorem, which lifts any formula applied to the images of the transduction into a formula which we can apply to the pre-images. Applications include proofs that the class of lattice-path matroids and the class of spike-minors can be defined by sentences in monadic second-order logic.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12969"
    },
    {
        "doc_id": 1,
        "title": "Measure transport with kernel mean embeddings",
        "authors": [
            "L. Wang",
            "N. N\u00fcsken"
        ],
        "subjects": [
            "Statistics Theory",
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "Kalman filters constitute a scalable and robust methodology for approximate Bayesian inference, matching first and second order moments of the target posterior. To improve the accuracy in nonlinear and non-Gaussian settings, we extend this principle to include more or different characteristics, based on kernel mean embeddings (KMEs) of probability measures into their corresponding Hilbert spaces. Focusing on the continuous-time setting, we develop a family of interacting particle systems (termed $\\textit{KME-dynamics}$) that bridge between the prior and the posterior, and that include the Kalman-Bucy filter as a special case. A variant of KME-dynamics has recently been derived from an optimal transport perspective by Maurais and Marzouk, and we expose further connections to (kernelised) diffusion maps, leading to a variational formulation of regression type. Finally, we conduct numerical experiments on toy examples and the Lorenz-63 model, the latter of which show particular promise for a hybrid modification (called Kalman-adjusted KME-dynamics).",
        "comments": "21 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12967"
    },
    {
        "doc_id": 2,
        "title": "Exponential perturbative expansions and coordinate transformations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a unified approach for different exponential perturbation techniques used in the treatment of time-dependent quantum mechanical problems, namely the Magnus expansion, the Floquet--Magnus expansion for periodic systems, the quantum averaging technique and the Lie--Deprit perturbative algorithms. Even the standard perturbation theory fits in this framework. The approach is based on carrying out an appropriate change of coordinates (or picture) in each case, and can be formulated for any time-dependent linear system of ordinary differential equations. All the procedures (except the standard perturbation theory) lead to approximate solutions preserving by construction unitarity when applied to the time-dependent Schr\u00f6dinger equation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12955"
    },
    {
        "doc_id": 3,
        "title": "A unifying framework for perturbative exponential factorizations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a framework where Fer and Wilcox expansions for the solution of differential equations are derived from two particular choices for the initial transformation that seeds the product expansion. In this scheme intermediate expansions can also be envisaged. Recurrence formulas are developed. A new lower bound for the convergence of the Wilcox expansion is provided as well as some applications of the results. In particular, two examples are worked out up to high order of approximation to illustrate the behavior of the Wilcox expansion.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12952"
    },
    {
        "doc_id": 4,
        "title": "To answer a question of Professor Georges Rhin",
        "authors": [
            "V. Flammang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Professor Georges Rhin considers a nonzero algebraic integer $\\a$ with conjugates $\\a_1=\\a, \\ldots, \\a_d$ and asks what can be said about $\\d \\sum_{ | \\a_i | >1} | \\a_i |$, that we denote ${\\rm{R}}(\\a)$. If $\\a$ is supposed to be a totally positive algebraic integer, we can establish an analog to the famous Schur-Siegel-Smyth trace problem for this measure. After that, we compute the greatest lower bound $c(\u03b8)$ of the quantities ${\\rm{R(\\a)}}/d$, for $\\a$ belonging to nine subintervals of $]0, 90 [$. The third three subintervals are complete and consecutive. All our results are obtained by using the method of explicit auxiliary functions. The polynomials involved in these functions are found by our recursive algorithm.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12951"
    },
    {
        "doc_id": 5,
        "title": "On the spectral asymptotics in domains with long boundary",
        "authors": [
            "Leonid Friedlander"
        ],
        "subjects": [
            "Spectral Theory"
        ],
        "abstract": "I discuss a simple toy problem for the Dirichlet Laplacian in a sequence of domains where the contribution of the boundary to the spectral asymptotics is of the same order as the contribution from the interior",
        "comments": "MSC Class:          35P20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12948"
    },
    {
        "doc_id": 6,
        "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
        "authors": [
            "Dylan Zhang",
            "Curt Tigges",
            "Zory Zhang",
            "Stella Biderman",
            "Maxim Raginsky",
            "Talia Ringer"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Formal Languages and Automata Theory",
            "Logic in Computer Science",
            "Programming Languages"
        ],
        "abstract": "This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \\textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \\textit{semantics} -- one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture.\n  With our framework as a powerful conceptual tool, we identify different issues under various set-ups. The models trained to emulate recursive computations cannot fully capture the recursion yet instead fit short-cut algorithms and thus cannot solve certain edge cases that are under-represented in the training distribution. In addition, it is difficult for state-of-the-art large language models (LLMs) to mine recursive rules from in-context demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating reduction (step-wise computation) of the recursive function.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.14699",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12947"
    },
    {
        "doc_id": 7,
        "title": "The local limit of rooted directed animals on the square lattice",
        "authors": [
            "Olivier H\u00e9nard",
            "\u00c9douard Maurel-Segala",
            "Arvind Singh"
        ],
        "subjects": [
            "Probability",
            "Combinatorics"
        ],
        "abstract": "We consider the local limit of finite uniformly distributed directed animals on the square lattice viewed from the root. Two constructions of the resulting uniform infinite directed animal are given: one as a heap of dominoes, constructed by letting gravity act on a right-continuous random walk and one as a Markov process, obtained by slicing the animal horizontally. We look at geometric properties of this local limit and prove, in particular, that it consists of a single vertex at infinitely many (random) levels. Several martingales are found in connection with the confinement of the infinite directed animal on the non-negative coordinates.",
        "comments": "59 pages, 16 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12935"
    },
    {
        "doc_id": 8,
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "authors": [
            "Angela Zhou"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "comments": "conference version accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12934"
    },
    {
        "doc_id": 9,
        "title": "The fiber bundle structure of General Relativity in Ashtekar variables",
        "authors": [
            "Matteo Bruno"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "In this review, we aim to analyze the mathematical interpretation of the Ashtekar-Barbero-Immirzi formulation of General Relativity. Along with a brief introduction to the necessary mathematical structures and tools, we illustrate some relevant physical theory quantities as geometrical objects within the framework of principal bundle theory.",
        "comments": "27 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12927"
    },
    {
        "doc_id": 10,
        "title": "A hypocoercivity-exploiting stabilised finite element method for Kolmogorov equation",
        "authors": [
            "Zhaonan Dong",
            "Emmanuil H. Georgoulis",
            "Philip J. Herbert"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a new stabilised finite element method for the classical Kolmogorov equation. The latter serves as a basic model problem for large classes of kinetic-type equations and, crucially, is characterised by degenerate diffusion. The stabilisation is constructed so that the resulting method admits a \\emph{numerical hypocoercivity} property, analogous to the corresponding property of the PDE problem. More specifically, the stabilisation is constructed so that spectral gap is possible in the resulting ``stronger-than-energy'' stabilisation norm, despite the degenerate nature of the diffusion in Kolmogorov, thereby the method has a provably robust behaviour as the ``time'' variable goes to infinity. We consider both a spatially discrete version of the stabilised finite element method and a fully discrete version, with the time discretisation realised by discontinuous Galerkin timestepping. Both stability and a priori error bounds are proven in all cases. Numerical experiments verify the theoretical findings.",
        "comments": "20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12921"
    },
    {
        "doc_id": 11,
        "title": "Decompositions of linear operators on pre-euclidean spaces by means of graphs",
        "authors": [
            "Hani Abdelwahab",
            "Elisabete Barreiro",
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Representation Theory",
            "Functional Analysis"
        ],
        "abstract": "In this work we study a linear operator $f$ on a pre-euclidean space $\\mathcal{V}$ by using properties of a corresponding graph. Given a basis $\\B$ of $\\mathcal{V}$, we present a decomposition of $\\mathcal{V}$ as an orthogonal direct sum of certain linear subspaces $\\{U_i\\}_{i \\in I}$, each one admitting a basis inherited from $\\B$, in such way that $f = \\sum_{i \\in I}f_i$, being each $f_i$ a linear operator satisfying certain conditions respect with $U_i$. Considering new hypothesis, we assure the existence of an isomorphism between the graphs associated to $f$ relative to two different bases. We also study the minimality of $\\mathcal{V}$ by using the graph associated to $f$ relative to $\\B$.",
        "comments": "Journal ref:Mathematics 11 (2023) special Issue \"Functional Analysis, Topology and Quantum Mechanics II\", no. 3, 725",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12916"
    },
    {
        "doc_id": 12,
        "title": "Viability and control of a delayed SIR epidemic with an ICU state constraint",
        "authors": [
            "Dimitri Breda",
            "Matteo Della Rossa",
            "Lorenzo Freddi"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This paper studies viability and control synthesis for a delayed SIR epidemic. The model integrates a constant delay representing an incubation/latency time. The control inputs model non-pharmaceutical interventions, while an intensive care unit (ICU) state-constraint is introduced to reflect the healthcare system's capacity. The arising delayed control system is analyzed via functional viability tools, providing insights into fulfilling the ICU constraint through feedback control maps. In particular, we consider two scenarios: first, we consider the case of general continuous initial conditions. Then, as a further refinement of our analysis, we assume that the initial conditions satisfy a Lipschitz continuity property, consistent with the considered model. The study compares the (in general, sub-optimal) obtained control policies with the optimal ones for the delay-free case, emphasizing the impact of the delay parameter. The obtained results are supported and illustrated, in a concluding section, by numerical examples.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12907"
    },
    {
        "doc_id": 13,
        "title": "Weight modules over split Lie algebras",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Representation Theory"
        ],
        "abstract": "We study the structure of weight modules $V$ with restrictions neither on the dimension nor on the base field, over split Lie algebras $L$. We show that if $L$ is perfect and $V$ satisfies $LV=V$ and ${\\mathcal Z}(V)=0$, then $$\\hbox{$L =\\bigoplus\\limits_{i\\in I} I_{i}$ and $V = \\bigoplus\\limits_{j \\in J} V_{j}$}$$ with any $I_{i}$ an ideal of $L$ satisfying $[I_{i},I_{k}]=0$ if $i \\neq k$, and any $V_{j}$ a (weight) submodule of $V$ in such a way that for any $j \\in J$ there exists a unique $i \\in I$ such that $I_iV_j \\neq 0,$ being $V_j$ a weight module over $I_i$. Under certain conditions, it is shown that the above decomposition of $V$ is by means of the family of its minimal submodules, each one being a simple (weight) submodule.",
        "comments": "Journal ref:        Modern Phys. Lett. A 28 (2013), no. 5, 1350008, 9 pp",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12906"
    },
    {
        "doc_id": 14,
        "title": "New simple solutions of the Yang--Baxter equation and their permutation groups",
        "authors": [
            "Ferran Cedo",
            "Jan Okninski"
        ],
        "subjects": [
            "Quantum Algebra",
            "Group Theory"
        ],
        "abstract": "A new class of indecomposable, irretractable, involutive, non-degenerate set-theoretic solutions of the Yang--Baxter equation is constructed. This class complements the class of such solutions constructed in \\cite{CO22} and together they generalize the class of solutions described in \\cite[Theorem 4.7{CO21}. Necessary and sufficient conditions are found in order that these new solutions are simple. For a rich subclass of these solutions the structure of their permutation groups, considered as left braces, is determined. In particular, these results answer a question stated in \\cite{CO21}. In the finite case, all these solutions have square cardinality. A new class of finite simple solutions of non-square cardinality such that their permutation groups are simple left braces is also constructed.",
        "comments": "arXiv admin note: text overlap with arXiv:2112.07271",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12904"
    },
    {
        "doc_id": 15,
        "title": "Propagation reversal on trees in the large diffusion regime",
        "authors": [
            "Hermen Jan Hupkes",
            "Mia Jukic"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "In this work we study travelling wave solutions to bistable reaction diffusion equations on bi-infinite $k$-ary trees in the continuum regime where the diffusion parameter is large. Adapting the spectral convergence method developed by Bates and his coworkers, we find an asymptotic prediction for the speed of travelling front solutions. In addition, we prove that the associated profiles converge to the solutions of a suitable limiting reaction-diffusion PDE. Finally, for the standard cubic nonlinearity we provide explicit formula's to bound the thin region in parameter space where the propagation direction undergoes a reversal.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12899"
    },
    {
        "doc_id": 16,
        "title": "Graded pseudo-H-rings",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Antonio D\u00edaz",
            "Marina Haralampidou",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Consider a pseudo-$H$-space $E$ endowed with a separately continuous biadditive associative multiplication which induces a grading on $E$ with respect to an abelian group $G$. We call such a space a graded pseudo-$H$-ring and we show that it has the form $E = cl(U + \\sum_j I_j)$ with $U$ a closed subspace of $E_1$ (the summand associated to the unit element in $G$), and any $I_j$ runs over a well described closed graded ideal of $E$, satisfying $I_jI_k = 0$ if $j \\neq k$. We also give a context in which graded simplicity of $E$ is characterized. Moreover, the second Wedderburn-type theorem is given for certain graded pseudo-$H$-rings.",
        "comments": "Journal ref:        Banach Journal of Mathematical Analysis 9 (2015), no. 2, 311-321",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12897"
    },
    {
        "doc_id": 17,
        "title": "Determination of a pair of newforms from the product of their twisted central values",
        "authors": [
            "Pramath Anamby",
            "Ritwik Pal"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We show that a pair of newforms $(f,g)$ can be uniquely determined by the product of the central $L$-values of their twists. To achieve our goal, we prove an asymptotic formula for the average of the product of the central values of two twisted $L$-functions- $L(1/2, f \\times \u03c7)L(1/2, g \\times \u03c7\u03c8)$, where $(f,g)$ is a pair of newforms. The average is taken over the primitive Dirichlet characters $\u03c7$ and $\u03c8$ of distinct prime moduli.",
        "comments": "Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12891"
    },
    {
        "doc_id": 18,
        "title": "Finitely many implies infinitely many",
        "authors": [
            "Melvyn B. Nathanson"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Many mathematical statements have the following form. If something is true for all finite subsets of an infinite set $I$, then it is true for all of $I$. This paper describes some old and new results on infinite sets of linear and polynomial equations with the property that solutions for all finite subsets of the set of equations implies the existence of a solution for the infinite set of equations.",
        "comments": "12 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12887"
    },
    {
        "doc_id": 19,
        "title": "On split Leibniz superalgebras",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "We study the structure of arbitrary split Leibniz superalgebras. We show that any of such superalgebras ${\\frak L}$ is of the form ${\\frak L} = {\\mathcal U} + \\sum_jI_j$ with ${\\mathcal U}$ a subspace of an abelian (graded) subalgebra $H$ and any $I_j$ a well described (graded) ideal of ${\\frak L}$ satisfying $[I_j,I_k] = 0$ if $j \\neq k$. In the case of ${\\frak L}$ being of maximal length, the simplicity of ${\\frak L}$ is also characterized in terms of connections of roots.",
        "comments": "arXiv admin note: text overlap with arXiv:2003.12607",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12886"
    },
    {
        "doc_id": 20,
        "title": "Pirashvili--Richter-type theorems for the reflexive and dihedral homology theories",
        "authors": [
            "Daniel Graves"
        ],
        "subjects": [
            "Algebraic Topology"
        ],
        "abstract": "Reflexive homology and dihedral homology are the homology theories associated to the reflexive and dihedral crossed simplicial groups respectively. The former has recently been shown to capture interesting information about $C_2$-equivariant homotopy theory and its structure is related to the study of \"real\" objects in algebraic topology. The latter has long been of interest for its applications in $O(2)$-equivariant homotopy theory and connections to Hermitian algebraic $K$-theory. In this paper, we show that the reflexive and dihedral homology theories can be interpreted as functor homology over categories of non-commutative sets, after the fashion of Pirashvili and Richter's result for the Hochschild and cyclic homology theories.",
        "comments": "13 pages. Comments welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12884"
    },
    {
        "doc_id": 21,
        "title": "Counting subgraphs of coloring graphs",
        "authors": [
            "Shamil Asgarli",
            "Sara Krehbiel",
            "Howard W. Levinson",
            "Heather M. Russell"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "The chromatic polynomial $\u03c0_{G}(k)$ of a graph $G$ can be viewed as counting the number of vertices in a family of coloring graphs $\\mathcal C_k(G)$ associated with (proper) $k$-colorings of $G$ as a function of the number of colors $k$. These coloring graphs can be understood as a reconfiguration system. We generalize the chromatic polynomial to $\u03c0_G^{(H)}(k)$, counting occurrences of arbitrary induced subgraphs $H$ in these coloring graphs, and we prove that these functions are polynomial in $k$. In particular, we study the chromatic pairs polynomial $\u03c0_{G}^{(P_2)}(k)$, which counts the number of edges in coloring graphs, corresponding to the number of pairs of colorings that differ on a single vertex. We show two trees share a chromatic pairs polynomial if and only if they have the same degree sequence, and we conjecture that the chromatic pairs polynomial refines the chromatic polynomial in general. We also instantiate our polynomials with other choices of $H$ to generate new graph invariants.",
        "comments": "25 pages, 14 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12883"
    },
    {
        "doc_id": 22,
        "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic Conservation Laws",
        "authors": [
            "Jake J. Harmon",
            "Svetlana Tokareva",
            "Anatoly Zlotnik",
            "Pieter J. Swart"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolic partial differential equations (PDEs) under uncertainty. Constructed around the framework of stochastic finite volume (SFV) methods, our approach circumvents sampling schemes or simulation ensembles while also preserving fundamental properties, in particular hyperbolicity of the resulting systems and conservation of the discrete solutions. Furthermore, we augment the existing SFV theory with a priori convergence results for statistical quantities, in particular push-forward densities, which we demonstrate through numerical experiments. By linking refinement indicators to regions of the physical and stochastic spaces, we drive anisotropic refinements of the discretizations, introducing new degrees of freedom (DoFs) where deemed profitable. To illustrate our proposed method, we consider a series of numerical examples for non-linear hyperbolic PDEs based on Burgers' and Euler's equations.",
        "comments": "Report number:          LA-UR 23-32498                          MSC Class:          35L60; 35L67; 65C30; 65M50; 65M60",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12880"
    },
    {
        "doc_id": 23,
        "title": "An extension of the Liouville theorem for Fourier multipliers to sub-exponentially growing solutions",
        "authors": [
            "David Berger",
            "Ren\u00e9 L. Schilling",
            "Eugene Shargorodsky",
            "Teo Sharia"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We study the equation $m(D)f = 0$ in a large class of sub-exponentially growing functions. Under appropriate restrictions on $m \\in C(\\mathbb{R}^n)$, we show that every such solution can be analytically continued to a sub-exponentially growing entire function on $\\mathbb{C}^n$ if and only if $m(\u03be) \\not= 0$ for $\u03be\\not= 0$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12876"
    },
    {
        "doc_id": 24,
        "title": "Some Aspects of Higher Continued Fractions",
        "authors": [
            "Etan Basser",
            "Nicholas Ovenhouse",
            "Anuj Sakarda"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We investigate some properties of the higher continued fractions defined recently by Musiker, Ovenhouse, Schiffler, and Zhang. We prove that the maps defining the higher continued fractions are increasing continuous functions on the positive real numbers. We also investigate some asymptotics of these maps.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12859"
    },
    {
        "doc_id": 25,
        "title": "Implicative-orthomodular lattices",
        "authors": [
            "Lavinia Corina Ciungu"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Based on implicative involutive BE algebras, we redefine the orthomodular lattices, by introducing the notion of implicative-orthomodular lattices, and we study their properties. We characterize these algebras, proving that the implicative-orthomodular lattices are quantum-Wajsberg algebras. We also define and characterize the implicative-modular algebras as a subclass of implicative-orthomodular lattices. The orthomodular softlattices and orthomodular widelattices are also redefined, by introducing the notions of implicative-orthomodular softlattices and implicative-orthomodular widelattices. Finally, we prove that the implicative-orthomodular softlattices are equivalent to implicative-orthomodular lattices and that the implicative-orthomodular widelattices are special cases of quantum-Wajsberg algebras.",
        "comments": "arXiv admin note: text overlap with arXiv:2401.04140",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12845"
    },
    {
        "doc_id": 26,
        "title": "Gelation and localization in multicomponent coagulation with multiplicative kernel through branching processes",
        "authors": [
            "Jochem Hoogendijk",
            "Ivan Kryven",
            "Camillo Schenone"
        ],
        "subjects": [
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "The multicomponent coagulation equation is a generalisation of the Smoluchowski coagulation equation in which size of a particle is described by a vector. As with the original Smoluchowski equation, the multicomponent coagulation equation features gelation when supplied with a multiplicative kernel. Additionally, a new type of behaviour called localization is observed due to the multivariate nature of the particle size distribution. Here we extend and apply the branching process representation technique, which we introduced to study differential equations in our previous work, to find a concise probabilistic solution of the multicomponent coagulation equation supplied with monodisperse initial conditions and provide short proofs for the gelation time and localization.",
        "comments": "12 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12844"
    },
    {
        "doc_id": 27,
        "title": "Moving null curves and integrability",
        "authors": [
            "Metin G\u00fcrses",
            "Asli Pekcan"
        ],
        "subjects": [
            "Exactly Solvable and Integrable Systems",
            "Differential Geometry"
        ],
        "abstract": "We study the null curves and their motion in a $3$-dimensional flat space-time $M_{3}$. We show that when the motion of null curves forms two surfaces in $M_{3}$ the integrability conditions lead to the well-known AKNS hierarchy. In this case we obtain all the geometrical quantities of the surfaces arising from the whole hierarchy but we particulary focus on the surfaces of the MKdV and KdV equations. We obtain one- and two-soliton surfaces associated to the MKdV equation and show that the Gauss and mean curvatures of these surfaces develop singularities in finite time. We show that the tetrad vectors on the curves satisfy the spin vector equation in the ferromagnetism model of Heisenberg.",
        "comments": "16 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12841"
    },
    {
        "doc_id": 28,
        "title": "Hamilton cycles for involutions of classical types",
        "authors": [
            "Gon\u00e7alo Gutierres",
            "Ricardo Mamede",
            "Jos\u00e9 Luis Santos"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Let ${\\mathcal W}_n$ denote any of the three families of classical Weyl groups: the symmetric groups ${\\mathcal S}_n$, the hyperoctahedral groups (signed permutation groups) ${\\mathcal S}^B_n$, or the even-signed permutation groups ${\\mathcal S}^D_n$. In this paper we give an uniform construction of a Hamilton cycle for the restriction to involutions on these three families of groups with respect to a inverse-closed connecting set of involutions. This Hamilton cycle is optimal with respect to the Hamming distance only for the symmetric group ${\\mathcal S}_n$.\n  We also recall an optimal algorithm for a Gray code for type $B$ involutions. A modification of this algorithm would provide a Gray Code for type $D$ involutions with Hamming distance two, which would be optimal. We give such a construction for ${\\mathcal S}^D_4$ and ${\\mathcal S}^D_5$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12839"
    },
    {
        "doc_id": 29,
        "title": "Bifurcation of periodic solutions to nonlinear measure differential equations",
        "authors": [
            "Maria Carolina Mesquita Macena Stefani",
            "Milan Tvrd\u00fd"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "This paper is devoted to bifurcations of periodic solutions of nonlinear measure differential equations with a parameter. Main tools are nonlinear generalized differential equations (in the sense of Kurzweil) and the Kurzweil gauge type generalized integral. We continue the research started by the first author under the supervision of the second one.",
        "comments": "MSC Class:          26A39; 34C23; 34C25; 47H11",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12837"
    },
    {
        "doc_id": 30,
        "title": "Equivariant $K$-theory of even-dimensional complex quadrics",
        "authors": [
            "Bidhan Paul"
        ],
        "subjects": [
            "Algebraic Topology",
            "K-Theory and Homology"
        ],
        "abstract": "The aim of this paper is to describe the torus equivariant $K$-ring of even-dimensional complex quadrics by studying the graph equivariant $K$-theory of their corresponding GKM graphs. This involves providing a presentation for its graph equivariant $K$- ring in terms of generators and relations. This parallels the description of the equivariant cohomology ring of even-dimensional complex quadrics due to Kuroki.",
        "comments": "17 pages, comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12833"
    },
    {
        "doc_id": 31,
        "title": "Numerical approximation of the stochastic Cahn-Hilliard equation with space-time white noise near the sharp interface limit",
        "authors": [
            "\u013dubom\u00edr Ba\u0148as",
            "Jean Daniel Mukam"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We consider the stochastic Cahn-Hilliard equation with additive space-time white noise $\u03b5^\u03b3\\dot{W}$ in dimension $d=2,3$, where $\u03b5>0$ is an interfacial width parameter. We study numerical approximation of the equation which combines a structure preserving implicit time-discretization scheme with a discrete approximation of the space-time white noise. We derive a strong error estimate for the considered numerical approximation which is robust with respect to the inverse of the interfacial width parameter $\u03b5$. Furthermore, by a splitting approach, we show that for sufficiently large scaling parameter $\u03b3$, the numerical approximation of the stochastic Cahn-Hilliard equation converges uniformly to the deterministic Hele-Shaw/Mullins-Sekerka problem in the sharp interface limit $\u03b5\\rightarrow 0$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12832"
    },
    {
        "doc_id": 32,
        "title": "Compactness and existence theory for a general class of stationary radiative transfer equations",
        "authors": [
            "Elena Dematt\u00e8",
            "Jin Woo Jang",
            "Juan J. L. Vel\u00e1zquez"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we study the steady-states of a large class of stationary radiative transfer equations in a $C^1$ convex bounded domain. Namely, we consider the case in which both absorption-emission and scattering coefficients depend on the local temperature $T$ and the radiation frequency $\u03bd.$ The radiative transfer equation determines the temperature of the material at each point. The main difficulty in proving existence of solutions is to obtain compactness of the sequence of integrals along lines that appear in several exponential terms. We prove a new compactness result suitable to deal with such a non-local operator containing integrals on a line segment. On the other hand, to obtain the existence theory of the full equation with both absorption and scattering terms we combine the compactness result with the construction of suitable Green functions for a class of non-local equations.",
        "comments": "MSC Class:          35Q31 (Primary) 85A25; 76N10; 35R25; 35A02 (Secondary)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12828"
    },
    {
        "doc_id": 33,
        "title": "Exodromy beyond conicality",
        "authors": [
            "Peter J. Haine",
            "Mauro Porta",
            "Jean-Baptiste Teyssier"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "Category Theory"
        ],
        "abstract": "We show that compact subanalytic stratified spaces and algebraic stratifications of real varieties have finite exit-path $\\infty$-categories, refining classical theorems of Lefschetz-Whitehead, Lojasiewicz, and Hironaka on the finiteness of the underlying homotopy types of these spaces. These stratifications are typically not conical; hence we cannot rely on the currently available exodromy equivalence between constructible sheaves on a stratified space, which requires conicality as a fundamental hypothesis. Building on ideas of Clausen and Orsnes Jansen, we study the class of exodromic stratified spaces, for which the conclusion of the exodromy theorem holds. We prove two new fundamental properties of this class of stratified spaces: coarsenings of exodromic stratifications are exodromic, and every morphism between exodromic stratified spaces induces a functor between the associated exit path $\\infty$-categories. As a consequence, we produce many new examples of exodromic stratified spaces, including: coarsenings of conical stratifications, locally finite subanalytic stratifications of real analytic spaces, and algebraic stratifications of real varieties. Our proofs are at the generality of stratified $\\infty$-topoi, hence apply to even more general situations such as stratified topological stacks. Finally, we use the previously mentioned finiteness results to construct derived moduli stacks of constructible and perverse sheaves.",
        "comments": "Comments very welcome. 73 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12825"
    },
    {
        "doc_id": 34,
        "title": "Ray-Singer Torsion, Topological Strings and Black Holes",
        "authors": [
            "Cumrun Vafa"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "Genus one amplitude for topological strings on Calabi-Yau 3-folds can be computed using mirror symmetry: The partition function at genus one gets mapped to a holomorphic version of Ray-Singer torsion on the mirror Calabi-Yau. On the other hand it can be shown by a physical argument that this gives a curvature squared correction term to the gravitational action. This in paticular leads to an effective quantum gravity cutoff known as the species scale, which varies over moduli space of Calabi-Yau manifolds. This resolves some of the puzzles associated to the entropy of small black holes when there are a large number of light species of particles. Thus Ray-Singer torsion, via its connection to topological strings at genus one, provides a measure of light degrees of freedom of four dimensional N=2 supergravity theories. Based on a talk given on May 12th, 2023 at the Singer Memorial Conference, MIT.",
        "comments": "11 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12816"
    },
    {
        "doc_id": 35,
        "title": "$b$-Hurwitz numbers from Whittaker vectors for $\\mathcal{W}$-algebras",
        "authors": [
            "Nitin K. Chidambaram",
            "Maciej Do\u0142\u0119ga",
            "Kento Osuga"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Mathematical Physics",
            "Combinatorics",
            "Representation Theory"
        ],
        "abstract": "We show that $b$-Hurwitz numbers with a rational weight are obtained by taking an explicit limit of a Whittaker vector for the $\\mathcal{W}$-algebra of type $A$. Our result is a vast generalization of several previous results that treated the monotone case, and the cases of quadratic and cubic polynomial weights. It also provides an interpretation of the associated Whittaker vector in terms of generalized branched coverings that might be of independent interest. Our result is new even in the special case $b=0$ that corresponds to classical hypergeometric Hurwitz numbers, and implies that they are governed by the topological recursion of Eynard-Orantin. This gives an independent proof of the recent result of Bychkov-Dunin-Barkowski-Kazarian-Shadrin.",
        "comments": "40 pages, comments welcome!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12814"
    },
    {
        "doc_id": 36,
        "title": "Optimal Stopping of Branching Diffusion Processes",
        "authors": [
            "Idris Kharroubi",
            "Antonio Ocello"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "This article explores an optimal stopping problem for branching diffusion processes. It consists in looking for optimal stopping lines, a type of stopping time that maintains the branching structure of the processes under analysis. By using a dynamic programming approach, we characterize the value function for a multiplicative cost that depends on the particle's label. We reduce the problem's dimensionality by setting a branching property and defining the problem in a finite-dimensional context. Within this framework, we focus on the value function, establishing polynomial growth and local Lipschitz properties, together with an innovative dynamic programming principle. This outcome leads to an analytical characterization with the help of a nonlinear elliptic PDE. We conclude by showing that the value function serves as the unique viscosity solution for this PDE, generalizing the comparison principle to this setting.",
        "comments": "MSC Class:          60G40; 60J80; 35J60; 49L20; 49L25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12811"
    },
    {
        "doc_id": 37,
        "title": "A sequence of $\u03c0/3$-equiangular hyperbolic polyhedra",
        "authors": [
            "Jun Nonaka"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "Atkinson [2] found a sequence of three-dimensional hyperbolic polyhedra whose dihedral angles are $\u03c0/3$. In this paper, we show the other sequence of such polyhedra. We also find the volumes of some of such polyhedra.",
        "comments": "12 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12809"
    },
    {
        "doc_id": 38,
        "title": "New lower bounds for three-term progression free sets in $\\mathbb{F}_p^n$",
        "authors": [
            "Christian Elsholtz",
            "Laura Proske",
            "Lisa Sauermann"
        ],
        "subjects": [
            "Combinatorics",
            "Number Theory"
        ],
        "abstract": "We prove new lower bounds on the maximum size of sets $A\\subseteq \\mathbb{F}_p^n$ or $A\\subseteq \\mathbb{Z}_m^n$ not containing three-term arithmetic progressions (consisting of three distinct points). More specifically, we prove that for any fixed integer $m\\ge 2$ and sufficiently large $n$ (in terms of $m$), there exists a three-term progression free subset $A\\subseteq \\mathbb{Z}_m^n$ of size $|A|\\ge (cm)^n$ for some absolute constant $c>1/2$. Such a bound for $c=1/2$ can be obtained with a classical construction of Salem and Spencer from 1942, and improving upon this value of $1/2$ has been a well-known open problem (our proof gives $c= 0.54$).\n  Our construction relies on finding a subset $S\\subset \\mathbb{Z}_m^2$ of size at least $(7/24)m^2$ with a certain type of reducibility property. This property allows us to ``lift'' $S$ to a three-term progression free subset of $\\mathbb{Z}_m^n$ for large $n$ (even though the original set $S\\subset \\mathbb{Z}_m^2$ does contain three-term arithmetic progressions).",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12802"
    },
    {
        "doc_id": 39,
        "title": "Some convergence analysis for multicontinuum homogenization",
        "authors": [
            "Wing Tat Leung"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this paper, we provide an analysis of a recently proposed multicontinuum homogenization technique. The analysis differs from those used in classical homogenization methods for several reasons. First, the cell problems in multicontinuum homogenization use constraint problems and can not be directly substituted into the differential operator. Secondly, the problem contains high contrast that remains in the homogenized problem. The homogenized problem averages the microstructure while containing the small parameter. In this analysis, we first based on our previous techniques, CEM-GMsFEM, to define a CEM-downscaling operator that maps the multicontinuum quantities to an approximated microscopic solution. Following the regularity assumption of the multicontinuum quantities, we construct a downscaling operator and the homogenized multicontinuum equations using the information of linear approximation of the multicontinuum quantities. The error analysis is given by the residual estimate of the homogenized equations and the well-posedness assumption of the homogenized equations.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12799"
    },
    {
        "doc_id": 40,
        "title": "Well-posedness of low regularity solutions for the 3D relativistic Euler equations",
        "authors": [
            "Huali Zhang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We study the well-posedness of low regularity solutions for the Cauchy problem of 3D relativistic Euler equations. By introducing a new decomposition for the relativistic velocity, deriving a new transport equation for modified vorticity, and establishing Strichartz estimates of linear wave equations endowed with the acoustic metric, we first prove a complete local well-posedness result for the Cauchy problem of 3D relativistic Euler equations if the initial velocity $\\bu_0=(u^0_0,\\mathring{\\bu}_0)^{\\mathrm{T}}$, logarithmic enthalpy $h_0$, and modified vorticity $\\bw_0$ satisfy $(h_0,\\mathring{\\bu}_0,\\bw_0)\\in H^s \\times H^s \\times H^{s_0} (2<s_0<s)$, where $\\mathring{\\bu}_0$ is a three-vector and $u^0_0=\\sqrt{1+|\\mathring{\\bu}_0|^2}$. Secondly, combining the above Strichartz estimates, semi-classical analysis, and induction method, we prove the corresponding problem is well-posed if $(h_0,\\mathring{\\bu}_0,\\bw_0) \\in H^s \\times H^s \\times H^2 (s>2)$. Our approach relies on Andersson-Zhang's work \\cite{AZ} on corresponding non-relativistic problems. All our results are valid for a general equation of state $p(\\varrho)=\\varrho^\\vartheta, \\vartheta>1$.",
        "comments": "Welcome all comments!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12796"
    },
    {
        "doc_id": 41,
        "title": "Contractions in perfect graph",
        "authors": [
            "Alexandre Dupont-Bouillard",
            "Pierre Fouilhoux",
            "Roland Grappe",
            "Mathieu Lacroix"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper, we characterize the class of {\\em contraction perfect} graphs which are the graphs that remain perfect after the contraction of any edge set. We prove that a graph is contraction perfect if and only if it is perfect and the contraction of any single edge preserves its perfection. This yields a characterization of contraction perfect graphs in terms of forbidden induced subgraphs, and a polynomial algorithm to recognize them. We also define the utter graph $u(G)$ which is the graph whose stable sets are in bijection with the co-2-plexes of $G$, and prove that $u(G)$ is perfect if and only if $G$ is contraction perfect.",
        "comments": "11 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12793"
    },
    {
        "doc_id": 42,
        "title": "The Alekseev-Meinrenken diffeomorphism arising from the Stokes phenomenon",
        "authors": [
            "Xiaomeng Xu"
        ],
        "subjects": [
            "Differential Geometry",
            "Classical Analysis and ODEs"
        ],
        "abstract": "The Alekseev-Meinrenken diffeomorphism is a distinguished diffeomorphism from the space of $n\\times n$ Hermitian matrices to the space of $n\\times n$ positive definite Hermitian matrices. This paper derives the explicit expression of the diffeomorphism, via the Stokes phenomenon of meromorphic linear systems of ordinary differential equations with Poncar\u00e9 rank $1$.",
        "comments": "18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12792"
    },
    {
        "doc_id": 43,
        "title": "On indices and monogenity of quartic number fields defined by quadrinomials",
        "authors": [
            "Hamid Ben Yakkou"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Consider a quartic number field $K$ generated by a root of an irreducible quadrinomial of the form $ F(x)= x^4+ax^3+bx+c \\in \\Z[x]$. Let $i(K)$ denote the index of $K$. Engstrom \\cite{Engstrom} established that $i(K)=2^u \\cdot 3^v$ with $u \\le 2$ and $v \\le 1$. In this paper, we provide sufficient conditions on $a$, $b$ and $c$ for $i(K)$ to be divisible by $2$ or $3$, determining the exact corresponding values of $u$ and $v$ in each case.\n  In particular, when $i(K) \\neq 1$, $K$ cannot be monogenic. We also identify new infinite parametric families of monogenic quartic number generated by roots of non-monogenic quadrinomials. We illustrate our results by some computational examples. Our method based on a theorem of Ore on the decomposition of primes in number fields \\cite{Nar,O}.",
        "comments": "MSC Class:          11R04; 11R16; 11R21; 11Y40                          ACM Class:          F.2.2",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12782"
    },
    {
        "doc_id": 44,
        "title": "On the average stopping time of the Collatz map in $\\mathbb{F}_2[x]$",
        "authors": [
            "Manuel Inselmann"
        ],
        "subjects": [
            "Dynamical Systems",
            "Combinatorics",
            "Probability"
        ],
        "abstract": "Define the map $T_1$ on $\\mathbb{F}_2[x]$ by $T_1(f)=\\frac{f}{x}$ if $f(0)=0$ and $T_1(f)=\\frac{(x+1)f+1}{x}$ if $f(0)=1$. For a non-zero polynomial $f$ let $\u03c4_1(f)$ denote the least natural $k$ number for which $T_1^{k}(f)=1$. Define the average stopping time to be $\u03c1_1(n)=\\frac{\\sum_{f\\in \\mathbb{F}_2[x], \\text{deg}(f)=n }\u03c4_1(f)}{2^n}$. We show that $\\frac{\u03c1_1(n)}{n}$ converges to $2$ as $n\\rightarrow\\infty$ confirming a conjecture of Alon, Behajaina and Paran. Furthermore, we give a new proof that $\u03c4_1(f)\\in O(\\text{deg}(f)^{1.5})$ for all $f\\in\\mathbb{F}_2[x]\\setminus\\{0\\}$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12781"
    },
    {
        "doc_id": 45,
        "title": "On $p$-adic Hurwitz-type spectral zeta functions",
        "authors": [
            "Su Hu",
            "Min-Soo Kim"
        ],
        "subjects": [
            "Number Theory",
            "Mathematical Physics",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Let $\\left\\{E_n\\right\\}_{n=1}^{\\infty}$ be the set of energy levels corresponding to a Hamiltonian $H$.\n  Denote by $$\u03bb_{0}=0~~\\textrm{and}~~\u03bb_{n}=E_{n}$$\n  for $n\\in\\mathbb N.$ In this paper, we shall construct and investigate the $p$-adic counterparts of the Hurwitz-type spectral zeta function \\begin{equation} \u03b6^{H}(s,\u03bb)=\\sum_{n=0}^{\\infty}\\frac{1}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} and its alternating form \\begin{equation} \u03b6_{E}^{H}(s,\u03bb)=2\\sum_{n=0}^{\\infty}\\frac{(-1)^{n}}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} in a parallel way.",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12775"
    },
    {
        "doc_id": 46,
        "title": "Y-function and L'Hospital-type Monotonicity Rules with Nabla and Diamond-Alpha Derivatives on Time Scales",
        "authors": [
            "Xiao-Yue Du",
            "Zhong-Xuan Mao",
            "Jing-Feng Tian"
        ],
        "subjects": [
            "Classical Analysis and ODEs"
        ],
        "abstract": "The main objective of this paper is to establish the $Y$-function and L'Hospital-type monotonicity rules with nabla and diamond-alpha derivatives on time scales.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12774"
    },
    {
        "doc_id": 47,
        "title": "Multitype branching processes in random environments with not strictly positive expectation matrices",
        "authors": [
            "Vilma Orgov\u00e1nyi",
            "K\u00e1roly Simon"
        ],
        "subjects": [
            "Probability",
            "Dynamical Systems"
        ],
        "abstract": "It is well known that under some conditions the almost sure survival probability of a multitype branching processes in random environment is positive if the Lyapunov exponent corresponding to the expectation matrices is positive, and zero if the Lyapunov exponent is negative. The goal of this note is to establish similar results when certain positivity conditions on the expectation matrices are not met. One application of such a result is to classify the positivity of Lebesgue measure of certain overlapping random self-similar sets in the line.",
        "comments": "22 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12767"
    },
    {
        "doc_id": 48,
        "title": "Absorbing ideals: a survey on $\u03c9$-stable groups",
        "authors": [
            "Bruno Moreira Fernandes"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We introduce a new concept in the Absorbing Ideal Theory in commutative rings, that is, the $\u03c9$-stable groups. We will provide examples and non-examples of these groups, and establish their relationship with H-congruence. Ultimately, we will study the action of these groups considering the transitivity condition",
        "comments": "9 pages",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12766"
    },
    {
        "doc_id": 49,
        "title": "Spectral analysis of a semiclassical random walk associated to a general confining potential",
        "authors": [
            "Thomas Normand"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Spectral Theory"
        ],
        "abstract": "We consider a semiclassical random walk with respect to a probability measure associated to a potential with a finite number of critical points. We recover the spectral results from [1] on the corresponding operator in a more general setting and with improved accuracy. In particular we do not make any assumption on the distribution of the critical points of the potential, in the spirit of [15]. Our approach consists in adapting the ideas from [15] to the recent gaussian quasimodes framework which appears to be more robust than the usual methods, especially when dealing with non local operators.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12765"
    },
    {
        "doc_id": 50,
        "title": "Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\\mathcal{O}(1/k)$ Finite-Sample Complexity",
        "authors": [
            "Thinh T. Doan"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $\\mathcal{O}(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $\\mathcal{O}(1/k^{2/3})$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12764"
    },
    {
        "doc_id": 51,
        "title": "Optimal design of a local renewable electricity supply system for power-intensive production processes with demand response",
        "authors": [
            "Sonja H. M. Germscheid",
            "Benedikt Nilges",
            "Niklas von der Assen",
            "Alexander Mitsos",
            "Manuel Dahmen"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This work studies synergies arising from combining industrial demand response and local renewable electricity supply. To this end, we optimize the design of a local electricity generation and storage system with an integrated demand response scheduling of a continuous power-intensive production process in a multi-stage problem. We optimize both total annualized cost and global warming impact and consider local photovoltaic and wind electricity generation, an electric battery, and electricity trading on day-ahead and intraday market. We find that installing a battery can reduce emissions and enable large trading volumes on the electricity markets, but significantly increases cost. Economic and ecologic process and battery operation are driven primarily by the electricity price and grid emission factor, respectively, rather than locally generated electricity. A parameter study reveals that economic savings from the local system and flexibilizing the process behave almost additive.",
        "comments": "manuscript (32 pages, 9 figures, 6 tables), supporting materials (11 pages, 9 figures, 2 tables)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12759"
    },
    {
        "doc_id": 52,
        "title": "Optimal Confidence Bands for Shape-restricted Regression in Multidimensions",
        "authors": [
            "Ashley",
            "Datta",
            "Somabha Mukherjee",
            "Bodhisattva Sen"
        ],
        "subjects": [
            "Statistics Theory",
            "Methodology"
        ],
        "abstract": "In this paper, we propose and study construction of confidence bands for shape-constrained regression functions when the predictor is multivariate. In particular, we consider the continuous multidimensional white noise model given by $d Y(\\mathbf{t}) = n^{1/2} f(\\mathbf{t}) \\,d\\mathbf{t} + d W(\\mathbf{t})$, where $Y$ is the observed stochastic process on $[0,1]^d$ ($d\\ge 1$), $W$ is the standard Brownian sheet on $[0,1]^d$, and $f$ is the unknown function of interest assumed to belong to a (shape-constrained) function class, e.g., coordinate-wise monotone functions or convex functions. The constructed confidence bands are based on local kernel averaging with bandwidth chosen automatically via a multivariate multiscale statistic. The confidence bands have guaranteed coverage for every $n$ and for every member of the underlying function class. Under monotonicity/convexity constraints on $f$, the proposed confidence bands automatically adapt (in terms of width) to the global and local (H\u00f6lder) smoothness and intrinsic dimensionality of the unknown $f$; the bands are also shown to be optimal in a certain sense. These bands have (almost) parametric ($n^{-1/2}$) widths when the underlying function has ``low-complexity'' (e.g., piecewise constant/affine).",
        "comments": "43 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12753"
    },
    {
        "doc_id": 53,
        "title": "N-free posets and orthomodularity",
        "authors": [
            "Gejza Jen\u010da"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We prove that the incomparability orthoset of a finite poset is Dacey if and only if the poset is N-free. We give a characterization of finite posets with compatible incomparability orthosets.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12749"
    },
    {
        "doc_id": 54,
        "title": "Multicausal transport: barycenters and dynamic matching",
        "authors": [
            "Beatrice Acciaio",
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "We introduce a multivariate version of adapted transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agents' types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.",
        "comments": "26 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12748"
    },
    {
        "doc_id": 55,
        "title": "Approximation of sea surface velocity field by fitting surrogate two-dimensional flow to scattered measurements",
        "authors": [
            "Karlo Jakac",
            "Luka Lan\u010da",
            "Ante Sikirica",
            "Stefan Ivi\u0107"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Optimization and Control"
        ],
        "abstract": "In this paper, a rapid approximation method is introduced to estimate the sea surface velocity field based on scattered measurements. The method uses a simplified two-dimensional flow model as a surrogate model, which mimics the real submesoscale flow. The proposed approach treats the interpolation of the flow velocities as an optimization problem, aiming to fit the flow model to the scattered measurements. To ensure consistency between the simulated velocity field and the measured values, the boundary conditions in the numerical simulations are adjusted during the optimization process. Additionally, the relevance of quantity and quality of the scattered measurements is assessed, emphasizing the importance of the measurement locations within the domain as well as explaining how these measurements contribute to the accuracy and reliability of the sea surface velocity field approximation. The proposed methodology has been successfully tested in both synthetic and real-world scenarios, leveraging measurements obtained from GPS drifters and HF-radar systems. The adaptability of this approach for different domains, measurement types and conditions implies that it is suitable for real-world submesoscale scenarios where only an approximation of the sea surface velocity field is sufficient.",
        "comments": "22 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12746"
    },
    {
        "doc_id": 56,
        "title": "Anderson stochastic quantization equation",
        "authors": [
            "Hugo Eulry",
            "Antoine Mouzard",
            "Tristan Robert"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Probability"
        ],
        "abstract": "We study the parabolic defocusing stochastic quantization equation with both mutliplicative spatial white noise and an independant space-time white noise forcing, on compact surfaces, with polynomial nonlinearity. After renormalizing the nonlinearity, we construct the random Gibbs measure as an absolutely continuous measure with respect to the law of the Anderson Gaussian Free Field for fixed realization of the spatial white noise. Then, when the initial data is distributed according to the Gibbs measure, we prove almost sure global well-posedness for the dynamics and invariance of the Gibbs measure.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12742"
    },
    {
        "doc_id": 57,
        "title": "Polynomial representation of TU-games",
        "authors": [
            "Ulrich Faigle",
            "Michel Grabisch"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We propose in this paper a polynomial representation of TU-games, fuzzy measures, capacities, and more generally set functions. Our representation needs a countably infinite set of players and the natural ordering of finite sets of $\\mathbb{N}$, defined recursively. For a given basis of the vector space of games, we associate to each game $v$ a formal polynomial of degree at most $2^n-1$ whose coefficients are the coordinates of $v$ in the given basis. By the fundamental theorem of algebra, $v$ can be represented by the roots of the polynomial. We present some new families of games stemming from this polynomial context, like the irreducible games, the multiplicative games and the cyclotomic games.",
        "comments": "MSC Class:          12D99; 91A12",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12741"
    },
    {
        "doc_id": 58,
        "title": "Controlling the C3 super class linearization algorithm",
        "authors": [
            "Florent Hivert",
            "Nicolas M. Thi\u00e9ry"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "C3 is an algorithm used by several widely used programming languages such as Python to support multiple inheritance in object oriented programming (OOP): for each class, C3 computes recursively a linear extension of the poset of all its super classes (the Method Resolution Order, MRO) from user-provided local information (an ordering of the direct super classes). This algorithm can fail if the local information is not consistent.\n  For large hierarchies of classes, as encountered when modeling hierarchies of concepts from abstract algebra in the SageMath computational system, maintaining consistent local information by hand does not scale and leads to unpredictable C3 failures.\n  This paper reports on the authors' work to analyze and circumvent this maintenance nightmare. First, we discovered through extensive computer exploration that there exists posets admitting no consistent local information; we exhibit the smallest one which has 10 elements. Then, we provide and analyze an algorithm that, given a poset and a linear extension, automatically builds local information for C3 in such a way that guarantees that it will never fail, at the price of a slight relaxation of the hypotheses. This algorithm has been used in production in SageMath since 2013.",
        "comments": "15 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12740"
    },
    {
        "doc_id": 59,
        "title": "Invariants cohomologiques mod 2 et invariants de Witt des groupes altern\u00e9s",
        "authors": [
            "Jean-Pierre Serre"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "We determine the cohomological invariants and the Witt invariants of the alternating group $A_n$.",
        "comments": "in French",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12738"
    },
    {
        "doc_id": 60,
        "title": "The algebraic degree of the Wasserstein distance",
        "authors": [
            "Chiara Meroni",
            "Bernhard Reinke",
            "Kexin Wang"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Group Theory"
        ],
        "abstract": "Given two rational univariate polynomials, the Wasserstein distance of their associated measures is an algebraic number. We determine the algebraic degree of the squared Wasserstein distance, serving as a measure of algebraic complexity of the corresponding optimization problem. The computation relies on the structure of a subpolytope of the Birkhoff polytope, invariant under a transformation induced by complex conjugation.",
        "comments": "17 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12735"
    },
    {
        "doc_id": 61,
        "title": "On the improved convergence of lifted distributional Gauss curvature from Regge elements",
        "authors": [
            "Jay Gopalakrishnan",
            "Michael Neunteufel",
            "Joachim Sch\u00f6berl",
            "Max Wardetzky"
        ],
        "subjects": [
            "Numerical Analysis",
            "Differential Geometry"
        ],
        "abstract": "Although Regge finite element functions are not continuous, useful generalizations of nonlinear derivatives like the curvature, can be defined using them. This paper is devoted to studying the convergence of the finite element lifting of a generalized (distributional) Gauss curvature defined using a metric tensor in the Regge finite element space. Specifically, we investigate the interplay between the polynomial degree of the curvature lifting by Lagrange elements and the degree of the metric tensor in the Regge finite element space. Previously, a superconvergence result, where convergence rate of one order higher than expected, was obtained when the metric is the canonical Regge interpolant of the exact metric. In this work, we show that an even higher order can be obtained if the degree of the curvature lifting is reduced by one polynomial degre and if at least linear Regge elements are used. These improved convergence rates are confirmed by numerical examples.",
        "comments": "MSC Class:          65N30 (Primary) 53A70; 83C27 (Secondary)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12734"
    },
    {
        "doc_id": 62,
        "title": "On A Proof of the ADKMV Conjecture",
        "authors": [
            "Zhiyuan Wang",
            "Chenglang Yang",
            "Jian Zhou"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Algebraic Geometry",
            "Exactly Solvable and Integrable Systems"
        ],
        "abstract": "We present a mathematical proof of a conjectural formula due to Aganagic, Dijkgraaf, Klemm, Mari\u00f1o and Vafa, expressing the topological vertex as a Bogoliubov transform of the fermionic vacuum. In our proof we introduce a boson-fermionic field assignment which generalizes the well-known boson-fermion correspondence. The proof also works for the generalization to the framed topological vertex made by Deng and Zhou. As a consequence, partition functions of toric Calabi-Yau threefolds are related to tau-functions of multi-component KP hierarchy.",
        "comments": "36 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12726"
    },
    {
        "doc_id": 63,
        "title": "Wasserstein Diffusion on Multidimensional Spaces",
        "authors": [
            "Karl-Theodor Sturm"
        ],
        "subjects": [
            "Probability",
            "Functional Analysis",
            "Metric Geometry"
        ],
        "abstract": "Given any closed Riemannian manifold $M$, we construct a reversible diffusion process on the space ${\\mathcal P}(M)$ of probability measures on $M$ that is\n  (i) reversible w.r.t.~the entropic measure ${\\mathbb P}^\u03b2$ on ${\\mathcal P}(M)$, heuristically given as $$d\\mathbb{P}^\u03b2(\u03bc)=\\frac{1}{Z} e^{-\u03b2\\, \\text{Ent}(\u03bc| m)}\\ d\\mathbb{P}^*(\u03bc);$$ (ii) associated with a regular Dirichlet form with carr\u00e9 du champ derived from the Wasserstein gradient in the sense of Otto calculus $${\\mathcal E}_W(f)=\\liminf_{g\\to f}\\ \\frac12\\int_{{\\mathcal P}(M)} \\big\\|\\nabla_W g\\big\\|^2(\u03bc)\\ d{\\mathbb P}^\u03b2(\u03bc);$$ (iii) non-degenerate, at least in the case of the $n$-sphere and the $n$-torus.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12721"
    },
    {
        "doc_id": 64,
        "title": "$n$-valued Coset Groups and Dynamics",
        "authors": [
            "Mikhail Kornev"
        ],
        "subjects": [
            "Group Theory",
            "Combinatorics",
            "Dynamical Systems"
        ],
        "abstract": "We obtain asymptotic and exact formulae of growth functions for some families of $n$-valued coset groups. We also describe connections between the theory of $n$-valued groups and Symbolic Dynamics.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12718"
    },
    {
        "doc_id": 65,
        "title": "On positively divisible non-Markovian processes",
        "authors": [
            "Bilal Canturk",
            "Heinz-Peter Breuer"
        ],
        "subjects": [
            "Probability",
            "Mathematical Physics"
        ],
        "abstract": "There are some positively divisible non-Markovian processes whose transition matrices satisfy the Chapman-Kolmogorov equation. These processes should also satisfy the Kolmogorov consistency conditions, an essential requirement for a process to be classified as a stochastic process. Combining the Kolmogorov consistency conditions with the Chapman-Kolmogorov equation, we derive a necessary condition for positively divisible stochastic processes on a finite sample space. This necessary condition enables a systematic approach to the manipulation of certain Markov processes in order to obtain a positively divisible non-Markovian process. We illustrate this idea by an example and, in addition, analyze a classic example given by Feller in the light of our approach.",
        "comments": "14 pages, 1 figure",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12715"
    },
    {
        "doc_id": 66,
        "title": "Moutard hyperquadrics and generalized Darboux directions",
        "authors": [
            "Fernanda Py Silva Cordeiro",
            "Marcos Craizer"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "For a fixed point of a non-degenerate surface in 3-space, there are three directions in its tangent plane such that the third order contact of a quadric in the Moutard pencil in these directions with the surface is a perfect cube. These directions are called Darboux directions and they coincide with the zeros of the cubic form at the point. In this paper, we extend this result to non-degenerate hypersurfaces.",
        "comments": "9 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12712"
    },
    {
        "doc_id": 67,
        "title": "Quandles as pre-Lie skew braces, set-theoretic Hopf algebras & universal R-matrices",
        "authors": [
            "Anastasia Doikou",
            "Bernard Rybolowicz",
            "Paola Stefanelli"
        ],
        "subjects": [
            "Quantum Algebra",
            "Mathematical Physics",
            "Rings and Algebras"
        ],
        "abstract": "We present connections between left non-degenerate solutions of set-theoretic Yang-Baxter equation and left shelves using certain maps called Drinfel'd homomorphisms. We further generalise the notion of affine quandle, by using heap endomorphisms and metahomomorphisms, and identify the Yang-Baxter algebra for solutions of the braid equation associated to a given quandle. We introduce the notion of the pre-Lie skew brace and identify certain affine quandles that give rise to pre-Lie skew braces. Generalisations of the braiding of a group, associated to set-theoretic solutions of the braid equation is also presented. These generalized structures encode part of the underlying Hopf algebra. Indeed, we also introduce the quasi-triangular Hopf algebras and the universal R-matrices for quandle algebras and for set-theoretic Yang-Baxter algebras. In fact, we obtain the universal R-matrix for the set-theoretic Yang-Baxter algebras after identifying the associated admissible Drinfel'd twist. Generic set-theoretic solutions coming from heap endomorphisms are also identified.",
        "comments": "36 pages LaTex",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12704"
    },
    {
        "doc_id": 68,
        "title": "Heaps of pieces for lattice paths",
        "authors": [
            "Keiichi Shigechi"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We study heaps of pieces for lattice paths, which give a combinatorial visualization of lattice paths. We introduce two types of heaps: type $I$ and type $II$. A heap of type $I$ is characterized by peaks of a lattice path. We have a duality between a lattice path $\u03bc$ and its dual $\\overline\u03bc$ on heaps of type $I$. A heap of type $II$ for $\u03bc$ is characterized by the skew shape between the lowest path and $\u03bc$. We give a determinant expression for the generating function of heaps for general lattice paths, and an explicit formula for rational $(1,k)$-Dyck paths by using the inversion lemma. We introduce and study heaps in $k+1$-dimensions which are bijective to heaps of type $II$ for $(1,k)$-Dyck paths. Further, we show a bijective correspondence between type $I$ and type $II$ in the case of rational $(1,k)$-Dyck paths. As another application of heaps, we give two explicit formulae for the generating function of heaps for symmetric Dyck paths in terms of statistics on Dyck paths and on symmetric Dyck paths respectively.",
        "comments": "31 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12701"
    },
    {
        "doc_id": 69,
        "title": "Pragmatic Communication in Multi-Agent Collaborative Perception",
        "authors": [
            "Yue Hu",
            "Xianghe Pang",
            "Xiaoqi Qin",
            "Yonina C. Eldar",
            "Siheng Chen",
            "Ping Zhang",
            "Wenjun Zhang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Collaborative perception allows each agent to enhance its perceptual abilities by exchanging messages with others. It inherently results in a trade-off between perception ability and communication costs. Previous works transmit complete full-frame high-dimensional feature maps among agents, resulting in substantial communication costs. To promote communication efficiency, we propose only transmitting the information needed for the collaborator's downstream task. This pragmatic communication strategy focuses on three key aspects: i) pragmatic message selection, which selects task-critical parts from the complete data, resulting in spatially and temporally sparse feature vectors; ii) pragmatic message representation, which achieves pragmatic approximation of high-dimensional feature vectors with a task-adaptive dictionary, enabling communicating with integer indices; iii) pragmatic collaborator selection, which identifies beneficial collaborators, pruning unnecessary communication links. Following this strategy, we first formulate a mathematical optimization framework for the perception-communication trade-off and then propose PragComm, a multi-agent collaborative perception system with two key components: i) single-agent detection and tracking and ii) pragmatic collaboration. The proposed PragComm promotes pragmatic communication and adapts to a wide range of communication conditions. We evaluate PragComm for both collaborative 3D object detection and tracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V and V2X-SIM2.0. PragComm consistently outperforms previous methods with more than 32.7K times lower communication volume on OPV2V. Code is available at github.com/PhyllisH/PragComm.",
        "comments": "18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12694"
    },
    {
        "doc_id": 70,
        "title": "Random Riemannian Geometry in 4 Dimensions",
        "authors": [
            "Karl-Theodor Sturm"
        ],
        "subjects": [
            "Probability",
            "Differential Geometry",
            "Metric Geometry"
        ],
        "abstract": "We construct and analyze conformally invariant random fields on 4-dimensional Riemannian manifolds $(M,g)$. These centered Gaussian fields $h$, called \\emph{co-biharmonic Gaussian fields}, are characterized by their covariance kernels $k$ defined as the integral kernel for the inverse of the \\emph{Paneitz operator} \\begin{equation*}\\mathsf p=\\frac1{8\u03c0^2}\\bigg[\u0394^2+\n  \\mathsf{div}\\left(2\\mathsf{Ric}-\\frac23\\mathsf{scal}\\right)\\nabla \\bigg]. \\end{equation*} The kernel $k$ is invariant (modulo additive corrections) under conformal transformations, and it exhibits a precise logarithmic divergence $$\\Big|k(x,y)-\\log\\frac1{d(x,y)}\\Big|\\le C.$$ In terms of the co-biharmonic Gaussian field $h$, we define the \\emph{quantum Liouville measure}, a random measure on $M$, heuristically given as \\begin{equation*}\n  d\u03bc(x):= e^{\u03b3h(x)-\\frac{\u03b3^2}2k(x,x)}\\,d \\text{vol}_g(x)\\,, \\end{equation*} and rigorously obtained a.s.~for $|\u03b3|<\\sqrt8$ as weak limit of the RHS with $h$ replaced by suitable regular approximations $(h_\\ell)_{\\ell\\in\\mathbb N}$.\n  For the flat torus $M=\\mathbb T^4$, we provide discrete approximations of the Gaussian field and of the Liouville measures in terms of semi-discrete random objects, based on Gaussian random variables on the discrete torus and piecewise constant functions in the isotropic Haar system.",
        "comments": "MSC Class:          60G15; 58J65; 31C25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12676"
    },
    {
        "doc_id": 71,
        "title": "Analysis of a combined Filtered/phase-field approach to topology optimization in elasticit",
        "authors": [
            "Ferdinando Auricchio",
            "Michele Marino",
            "Idriss Mazari",
            "Ulisse Stefanelli"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "We advance a combined filtered/phase-field approach to topology optimization in the setting of linearized elasticity. Existence of minimizers is proved and rigorous parameter asymptotics are discussed by means of variational convergence techniques. Moreover, we investigate an abstract space discretization in the spirit of conformal finite elements. Eventually, stationarity is equivalently reformulated in terms of a Lagrangian.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12675"
    },
    {
        "doc_id": 72,
        "title": "\u03bb-Cent-Dians and Generalized-Center for Network Design",
        "authors": [
            "V\u00edctor Bucarey",
            "Natividad Gonz\u00e1lez-Blanco",
            "Martine Labb\u00e9",
            "Juan A. Mesa"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "In this paper, we extend the notions of $\u03bb$-cent-dian and generalized-center from Facility Location Theory to the more intricate domain of Network Design. Our focus is on the task of designing a sub-network within a given underlying network while adhering to a budget constraint. This sub-network is intended to efficiently serve a collection of origin/destination pairs of demand. % rather than individual points.\n  The $\u03bb$-cent-dian problem studies the balance between efficiency and equity. We investigate the properties of the $\u03bb$-cent-dian and generalized-center solution networks under the lens of equity, efficiency, and Pareto-optimality. We provide a mathematical formulation for $\u03bb\\geq 0$ and discuss the bilevel structure of this problem for $\u03bb>1$. Furthermore, we describe a procedure to obtain a complete parametrization of the Pareto-optimality set based on solving two mixed integer linear formulations by introducing the concept of maximum $\u03bb$-cent-dian. We evaluate the quality of the different solution concepts using some inequality measures. Finally, for $\u03bb\\in[0,1]$, we study the implementation of a Benders decomposition method to solve it at scale.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12673"
    },
    {
        "doc_id": 73,
        "title": "Highly connected orientations from edge-disjoint rigid subgraphs",
        "authors": [
            "D\u00e1niel Garamv\u00f6lgyi",
            "Tibor Jord\u00e1n",
            "Csaba Kir\u00e1ly",
            "Soma Vill\u00e1nyi"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We give an affirmative answer to a long-standing conjecture of Thomassen, stating that every sufficiently highly connected graph has a $k$-vertex-connected orientation. We prove that a connectivity of order $O(k^5)$ suffices. As a key tool, we show that for every pair of positive integers $d$ and $t$, every $(t \\cdot h(d))$-connected graph contains $t$ edge-disjoint $d$-rigid (in particular, $d$-connected) spanning subgraphs, where $h(d) = 10d(d+1)$. This also implies a positive answer to the conjecture of Kriesell that every sufficiently highly connected graph $G$ contains a spanning tree $T$ such that $G-E(T)$ is $k$-connected.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12670"
    },
    {
        "doc_id": 74,
        "title": "EL-VIT: Probing Vision Transformer with Interactive Visualization",
        "authors": [
            "Hong Zhou",
            "Rui Zhang",
            "Peifeng Lai",
            "Chaoran Guo",
            "Yong Wang",
            "Zhida Sun",
            "Junjie Li"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Nowadays, Vision Transformer (ViT) is widely utilized in various computer vision tasks, owing to its unique self-attention mechanism. However, the model architecture of ViT is complex and often challenging to comprehend, leading to a steep learning curve. ViT developers and users frequently encounter difficulties in interpreting its inner workings. Therefore, a visualization system is needed to assist ViT users in understanding its functionality. This paper introduces EL-VIT, an interactive visual analytics system designed to probe the Vision Transformer and facilitate a better understanding of its operations. The system consists of four layers of visualization views. The first three layers include model overview, knowledge background graph, and model detail view. These three layers elucidate the operation process of ViT from three perspectives: the overall model architecture, detailed explanation, and mathematical operations, enabling users to understand the underlying principles and the transition process between layers. The fourth interpretation view helps ViT users and experts gain a deeper understanding by calculating the cosine similarity between patches. Our two usage scenarios demonstrate the effectiveness and usability of EL-VIT in helping ViT users understand the working mechanism of ViT.",
        "comments": "10 pages, 7 figures, conference",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12666"
    },
    {
        "doc_id": 75,
        "title": "Polynomial and rational interpolation: potential, barycentric weights, and Lebesgue constants",
        "authors": [
            "Kelong Zhao",
            "Shuhuang Xiang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this paper, we focus on barycentric weights and Lebesgue constants for Lagrange interpolation of arbitrary node distributions on \\([-1,1]\\). The following three main works are included: estimates of upper and lower bounds on the barycentric weights are given in terms of the logarithmic potential function; for interpolation of non-equilibrium potentials, lower bounds with exponentially growing parts of Lebesgue constants are given; and for interpolation consistent with equilibrium potentials, non-exponentially growing upper bounds on their Lebesgue constants are given. Based on the work in this paper, we can discuss the behavior of the Lebesgue constant and the existence of exponential convergence in a unified manner in the framework of potential theory.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12664"
    },
    {
        "doc_id": 76,
        "title": "Global existence for long wave Hopf unstable spatially extended systems with a conservation law",
        "authors": [
            "Nicole Gauss",
            "Anna Logioti",
            "Guido Schneider",
            "Dominik Zimmermann"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "We are interested in reaction-diffusion systems, with a conservation law, exhibiting a Hopf bifurcation at the spatial wave number $k = 0$. With the help of a multiple scaling perturbation ansatz a Ginzburg-Landau equation coupled to a scalar conservation law can be derived as an amplitude system for the approximate description of the dynamics of the original reaction-diffusion system near the first instability. We use the amplitude system to show the global existence of all solutions starting in a small neighborhood of the weakly unstable ground state for original systems posed on a large spatial interval with periodic boundary conditions.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12660"
    },
    {
        "doc_id": 77,
        "title": "Cokernel statistics for walk matrices of directed and weighted random graphs",
        "authors": [
            "Alexander Van Werde"
        ],
        "subjects": [
            "Combinatorics",
            "Probability"
        ],
        "abstract": "The walk matrix associated to an $n\\times n$ integer matrix $X$ and an integer vector $b$ is defined by $W := (b,X b, . . . ,X^{n-1} b)$. We study limiting laws for the cokernel of $W$ in the scenario where $X$ is a random matrix with independent entries and $b$ is deterministic. Our first main result provides a formula for the distribution of the $p^{m}$-torsion part of the cokernel, as a group, when $X$ has independent entries from a specific distribution. The second main result relaxes the distributional assumption and concerns the $\\mathbb{Z}[x]$-module structure.\n  The motivation for this work arises from an open problem in spectral graph theory which asks to show that random graphs are often determined up to isomorphism by their (generalized) spectrum. Sufficient conditions for generalized spectral determinacy can namely be stated in terms of the cokernel of a walk matrix. Extensions of our results could potentially be used to determine how often those conditions are satisfied. Some remaining challenges for such extensions are outlined in the paper",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12655"
    },
    {
        "doc_id": 78,
        "title": "Mock Alexander Polynomials",
        "authors": [
            "Neslihan G\u00fcg\u00fcmc\u00fc",
            "Louis H. Kauffman"
        ],
        "subjects": [
            "Geometric Topology",
            "Combinatorics"
        ],
        "abstract": "In this paper, we construct mock Alexander polynomials for starred links and linkoids in surfaces. These polynomials are defined as specific sums over states of link or linkoid diagrams that satisfy $f=n$, where $f$ denotes the number of regions and $n$ denotes the number of crossings of diagrams.",
        "comments": "MSC Class:          57M25; 57M20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12654"
    },
    {
        "doc_id": 79,
        "title": "Geometry of Mechanics",
        "authors": [
            "Miguel C. Mu\u00f1oz-Lecanda",
            "Narciso Rom\u00e1n-Roy"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "We study the geometry underlying mechanics and its application to describe autonomous and nonautonomous conservative dynamical systems of different types; as well as dissipative dynamical systems. We use different geometric descriptions to study the main properties and characteristics of these systems; such as their Lagrangian, Hamiltonian and unified formalisms, their symmetries, the variational principles, and others. The study is done mainly for the regular case, although some comments and explanations about singular systems are also included.",
        "comments": "237 pages. This is a draft version of a future book. Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12650"
    },
    {
        "doc_id": 80,
        "title": "Space-time unfitted finite elements on moving explicit geometry representations",
        "authors": [
            "Santiago Badia",
            "Pere A. Martorell",
            "Francesc Verdugo"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Numerical Analysis"
        ],
        "abstract": "This work proposes a novel variational approximation of partial differential equations on moving geometries determined by explicit boundary representations. The benefits of the proposed formulation are the ability to handle large displacements of explicitly represented domain boundaries without generating body-fitted meshes and remeshing techniques. For the space discretization, we use a background mesh and an unfitted method that relies on integration on cut cells only. We perform this intersection by using clipping algorithms. To deal with the mesh movement, we pullback the equations to a reference configuration (the spatial mesh at the initial time slab times the time interval) that is constant in time. This way, the geometrical intersection algorithm is only required in 3D, another key property of the proposed scheme. At the end of the time slab, we compute the deformed mesh, intersect the deformed boundary with the background mesh, and consider an exact transfer operator between meshes to compute jump terms in the time discontinuous Galerkin integration. The transfer is also computed using geometrical intersection algorithms. We demonstrate the applicability of the method to fluid problems around rotating (2D and 3D) geometries described by oriented boundary meshes. We also provide a set of numerical experiments that show the optimal convergence of the method.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12649"
    },
    {
        "doc_id": 81,
        "title": "Sequential discontinuity and first-order problems",
        "authors": [
            "Arno Pauly",
            "Giovanni Sold\u00e0"
        ],
        "subjects": [
            "Logic",
            "Logic in Computer Science",
            "General Topology"
        ],
        "abstract": "We explore the low levels of the structure of the continuous Weihrauch degrees of first-order problems. In particular, we show that there exists a minimal discontinuous first-order degree, namely that of $\\accn$, without any determinacy assumptions. The same degree is also revealed as the least sequentially discontinuous one, i.e. the least degree with a representative whose restriction to some sequence converging to a limit point is still discontinuous.\n  The study of games related to continuous Weihrauch reducibility constitutes an important ingredient in the proof of the main theorem. We present some initial additional results about the degrees of first-order problems that can be obtained using this approach.",
        "comments": "MSC Class:          03D78; 03D30; 54H05",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12641"
    },
    {
        "doc_id": 82,
        "title": "On The Axioms Of $\\mathcal{M},\\mathcal{N}$-Adhesive Categories",
        "authors": [
            "Davide Castelnovo",
            "Marino Miculan"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Category Theory"
        ],
        "abstract": "Adhesive and quasiadhesive categories provide a general framework for the study of algebraic graph rewriting systems. In a quasiadhesive category any two regular subobjects have a join which is again a regular subobject. Vice versa, if regular monos are adhesive, then the existence of a regular join for any pair of regular subobjects entails quasiadhesivity. It is also known (quasi)adhesive categories can be embedded in a Grothendieck topos via a functor preserving pullbacks and pushouts along (regular) monomorphisms. In this paper we extend these results to $\\mathcal{M}, \\mathcal{N}$-adhesive categories, a concept recently introduced to generalize the notion of (quasi)adhesivity. We introduce the notion of $\\mathcal{N}$-adhesive morphism, which allows us to express $\\mathcal{M}, \\mathcal{N}$-adhesivity as a condition on the subobjects's posets. Moreover, $\\mathcal{N}$-adhesive morphisms allows us to show how an $\\mathcal{M},\\mathcal{N}$-adhesive category can be embedded into a Grothendieck topos, preserving pullbacks and $\\mathcal{M}, \\mathcal{N}$-pushouts.",
        "comments": "ACM Class:          F.4.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12638"
    },
    {
        "doc_id": 83,
        "title": "Spectra and pseudo-spectra of tridiagonal $k$-Toeplitz matrices and the topological origin of the non-Hermitian skin effect",
        "authors": [
            "Habib Ammari",
            "Silvio Barandun",
            "Yannick De Bruijn",
            "Ping Liu",
            "Clemens Thalhammer"
        ],
        "subjects": [
            "Mathematical Physics",
            "Materials Science",
            "Rings and Algebras",
            "Optics"
        ],
        "abstract": "We establish new results on the spectra and pseudo-spectra of tridiagonal $k$-Toeplitz operators and matrices. In particular, we prove the connection between the winding number of the eigenvalues of the symbol function and the exponential decay of the associated eigenvectors (or pseudo-eigenvectors). Our results elucidate the topological origin of the non-Hermitian skin effect in general one-dimensional polymer systems of subwavelength resonators with imaginary gauge potentials, proving the observation and conjecture in arXiv:2307.13551. We also numerically verify our theory for these systems.",
        "comments": "18 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12626"
    },
    {
        "doc_id": 84,
        "title": "Benders decomposition for congested partial set covering location with uncertain demand",
        "authors": [
            "Alice Calamita",
            "Ivana Ljubi\u0107",
            "Laura Palagi"
        ],
        "subjects": [
            "Optimization and Control",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper, we introduce a mixed integer quadratic formulation for the congested variant of the partial set covering location problem, which involves determining a subset of facility locations to open and efficiently allocating customers to these facilities to minimize the combined costs of facility opening and congestion while ensuring target coverage. To enhance the resilience of the solution against demand fluctuations, we address the case under uncertain customer demand using $\u0393$-robustness. We formulate the deterministic problem and its robust counterpart as mixed-integer quadratic problems. We investigate the effect of the protection level in adapted instances from the literature to provide critical insights into how sensitive the planning is to the protection level. Moreover, since the size of the robust counterpart grows with the number of customers, which could be significant in real-world contexts, we propose the use of Benders decomposition to effectively reduce the number of variables by projecting out of the master problem all the variables dependent on the number of customers. We illustrate how to incorporate our Benders approach within a mixed-integer second-order cone programming (MISOCP) solver, addressing explicitly all the ingredients that are instrumental for its success. We discuss single-tree and multi-tree approaches and introduce a perturbation technique to deal with the degeneracy of the Benders subproblem efficiently. Our tailored Benders approaches outperform the perspective reformulation solved using the state-of-the-art MISOCP solver Gurobi on adapted instances from the literature.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12625"
    },
    {
        "doc_id": 85,
        "title": "A Unifying System Theory Framework for Distributed Optimization and Games",
        "authors": [
            "Guido Carnevale",
            "Nicola Mimmo",
            "Giuseppe Notarstefano"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This paper introduces a systematic methodological framework to design and analyze distributed algorithms for optimization and games over networks. Starting from a centralized method, we identify an aggregation function involving all the decision variables (e.g., a global cost gradient or constraint) and design a distributed consensus-oriented dynamics to asymptotically approximate the unavailable information at each agent. Then, we delineate the proper methodology for intertwining the identified building blocks, i.e., the optimization-oriented method and the consensus-oriented one. The key intuition is to interpret the obtained interconnection as a singularly perturbed system. We rely on this interpretation to provide sufficient conditions for the building blocks to be successfully connected into a distributed scheme exhibiting the convergence guarantees of the centralized algorithm. Finally, we show the potential of our approach by developing a new distributed scheme with linear rate for constraint-coupled problems.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12623"
    },
    {
        "doc_id": 86,
        "title": "Characteristic polynomials of isometries of even unimodular lattices",
        "authors": [
            "Yuta Takada"
        ],
        "subjects": [
            "Number Theory",
            "Algebraic Geometry"
        ],
        "abstract": "E. Bayer-Fluckiger gave a necessary and sufficient condition for a polynomial to be realized as the characteristic polynomial of a semisimple isometry of an even unimodular lattice, by describing the local-global obstruction, and the author extended the result. This article presents a systematic way to compute the obstruction. As an application, we give a necessary and sufficient condition for a Salem number of degree $10$ or $18$ to be realized as the dynamical degree of an automorphism of nonprojective K3 surface, in terms of its minimal polynomial.",
        "comments": "MSC Class:          11H56; 14J28",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12620"
    },
    {
        "doc_id": 87,
        "title": "Sum of two squares in biquadratic fields",
        "authors": [
            "Wenhuan Huang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "This paper gives an algorithm to determine whether a number in a biquadratic field is a sum of two squares, based on local-global principle of isotropy of quadratic forms.",
        "comments": "4 pages. Suggestions for improvement are welcomed",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12619"
    },
    {
        "doc_id": 88,
        "title": "Computation of classical and $v$-adic $L$-series of $t$-motives",
        "authors": [
            "Xavier Caruso",
            "Quentin Gazda"
        ],
        "subjects": [
            "Symbolic Computation",
            "Number Theory"
        ],
        "abstract": "We design an algorithm for computing the $L$-series associated to an Anderson $t$-motives, exhibiting quasilinear complexity with respect to the target precision. Based on experiments, we conjecture that the order of vanishing at $T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good reduction does not depend on the finite place $v$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12618"
    },
    {
        "doc_id": 89,
        "title": "On the hardness of deciding the finite convergence of Lasserre hierarchies",
        "authors": [
            "Luis Felipe Vargas"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "A polynomial optimization problem (POP) asks for minimizing a polynomial function given a finite set of polynomial constraints (equations and inequalities). This problem is well-known to be hard in general, as it encodes many hard combinatorial problems. The Lasserre hierarchy is a sequence of semidefinite relaxations for solving (POP). Under the standard archimedean condition, this hierarchy is guaranteed to converge asymptotically to the optimal value of (POP) (Lasserre, 2001) and, moreover, finite convergence holds generically (Nie, 2012). In this paper, we aim to investigate whether there is an efficient algorithmic procedure to decide whether the Lasserre hierarchy of (POP) has finite convergence. We show that unless P=NP there cannot exist such an algorithmic procedure that runs in polynomial time. We show this already for the standard quadratic programs. Our approach relies on characterizing when finite convergence holds for the so-called Motzkin-Straus formulation (and some variations of it) for the stability number of a graph.",
        "comments": "MSC Class:          90C23; 90c20; 68Q17; 11E25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12613"
    },
    {
        "doc_id": 90,
        "title": "The twin peaks of learning neural networks",
        "authors": [
            "Elizaveta Demyanenko",
            "Christoph Feinauer",
            "Enrico M. Malatesta",
            "Luca Saglietti"
        ],
        "subjects": [
            "Machine Learning",
            "Disordered Systems and Neural Networks",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "Recent works demonstrated the existence of a double-descent phenomenon for the generalization error of neural networks, where highly overparameterized models escape overfitting and achieve good test performance, at odds with the standard bias-variance trade-off described by statistical learning theory. In the present work, we explore a link between this phenomenon and the increase of complexity and sensitivity of the function represented by neural networks. In particular, we study the Boolean mean dimension (BMD), a metric developed in the context of Boolean function analysis. Focusing on a simple teacher-student setting for the random feature model, we derive a theoretical analysis based on the replica method that yields an interpretable expression for the BMD, in the high dimensional regime where the number of data points, the number of features, and the input size grow to infinity. We find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak, and then slowly approaches a low asymptotic value. The same phenomenology is then traced in numerical experiments with different model classes and training setups. Moreover, we find empirically that adversarially initialized models tend to show higher BMD values, and that models that are more robust to adversarial attacks exhibit a lower BMD.",
        "comments": "36 pages, 30 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12610"
    },
    {
        "doc_id": 91,
        "title": "Dispersive estimates for wave and Schr\u00f6dinger equations with a potential in non-trapping exterior domains",
        "authors": [
            "Thomas Duyckaerts",
            "Jianwei Urban Yang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We prove resolvent estimates for a Schr\u00f6dinger operator with a short-range potential outside an obstacle with Dirichlet boundary conditions. As a consequence, we deduce integrability of the local energy for the wave equation, and smoothing effect for the Schr\u00f6dinger equation. Finally, for both equations, we prove that local Strichartz estimates for the free equation outside an obstacle imply global Strichartz estimates with a short-range potential outside the same obstacle. The estimates are all global in time, after projection on the continuous spectrum of the operator.",
        "comments": "MSC Class:          35L05; 35Q41; 35B65; 35P25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12608"
    },
    {
        "doc_id": 92,
        "title": "The asymptotic behavior of fraudulent algorithms",
        "authors": [
            "Michel Bena\u00efm",
            "Laurent Miclo"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "Let $U$ be a Morse function on a  compact connected $m$-dimensional Riemannian manifold, $m \\geq 2,$ satisfying $\\min U=0$ and let $\\mathcal{U} = \\{x \\in M \\: : U(x) = 0\\}$ be the set of global minimizers. Consider the stochastic algorithm $X^{(\u03b2)}:=(X^{(\u03b2)}(t))_{t\\geq 0}$ defined on $N = M \\setminus \\mathcal{U},$  whose generator is$U \u0394\\cdot-\u03b2\\langle \\nabla U,\\nabla \\cdot\\rangle$, where $\u03b2\\in\\RR$ is a real parameter.We show that for $\u03b2>\\frac{m}{2}-1,$ $X^{(\u03b2)}(t)$ converges a.s.\\ as $t \\rightarrow   \\infty$, toward a point $p \\in \\mathcal{U}$ and that each  $p \\in \\mathcal{U}$  has a positive probability to be selected. On the other hand, for $\u03b2<  \\frac{m}{2}-1,$ the law of $(X^{(\u03b2)}(t))$ converges in total variation (at an exponential rate) toward the probability measure  $\u03c0_\u03b2$ having density proportional to  $U(x)^{-1-\u03b2}$ with respect to the Riemannian measure.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12605"
    },
    {
        "doc_id": 93,
        "title": "A coupling concept for Stokes-Darcy systems: the ICDD method",
        "authors": [
            "Marco Discacciati",
            "Paola Gervasio"
        ],
        "subjects": [
            "Numerical Analysis",
            "Fluid Dynamics"
        ],
        "abstract": "We present a coupling framework for Stokes-Darcy systems valid for arbitrary flow direction at low Reynolds numbers and for isotropic porous media. The proposed method is based on an overlapping domain decomposition concept to represent the transition region between the free-fluid and the porous-medium regimes. Matching conditions at the interfaces of the decomposition impose the continuity of velocity (on one interface) and pressure (on the other one) and the resulting algorithm can be easily implemented in a non-intrusive way. The numerical approximations of the fluid velocity and pressure obtained by the studied method converge to the corresponding counterparts computed by direct numerical simulation at the microscale, with convergence rates equal to suitable powers of the scale separation parameter $\\varepsilon$ in agreement with classical results in homogenization.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12602"
    },
    {
        "doc_id": 94,
        "title": "Asymptotic confidence interval for R2 in multiple linear regression",
        "authors": [
            "J Dedecker",
            "O Guedj",
            "M L Taupin"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Following White's approach of robust multiple linear regression, we give asymptotic confidence intervals for the multiple correlation coefficient R2 under minimal moment conditions. We also give the asymptotic joint distribution of the empirical estimators of the individual R2's. Through different sets of simulations, we show that the procedure is indeed robust (contrary to the procedure involving the near exact distribution of the empirical estimator of R2 is the multivariate Gaussian case) and can be also applied to count linear regression.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12598"
    },
    {
        "doc_id": 95,
        "title": "Superconvergent postprocessing of $C^0$ interior penalty method",
        "authors": [
            "Ying Cai",
            "Hailong Guo",
            "Zhimin Zhang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "This paper focuses on the superconvergence analysis of the Hessian recovery technique for the $C^0$ Interior Penalty Method (C0IP) in solving the biharmonic equation. We establish interior error estimates for C0IP method that serve as the superconvergent analysis tool. Using the argument of superconvergence by difference quotient, we prove superconvergent results of the recovered Hessian matrix on translation-invariant meshes. The Hessian recovery technique enables us to construct an asymptotically exact ${\\it a\\, posteriori}$ error estimator for the C0IP method. Numerical experiments are provided to support our theoretical results.",
        "comments": "MSC Class:          65N30; 65N25; 65N15; 65N50",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12589"
    },
    {
        "doc_id": 96,
        "title": "Center stable manifolds for the radial semi-linear wave equation outside a ball",
        "authors": [
            "Thomas Duyckaerts",
            "Jianwei Urban Yang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider the nonlinear wave equation, with a large exponent, power-like non-linearity, outside a ball of the Euclidean 3-dimensional space. In a previous article, we have proved that any global solution converges, up to a radiation term, to a stationary solution of the equation. In this work, we construct the center-stable manifold associated to each of the stationary solution, giving a complete description of the dynamics of global solutions. We also study the behavior of solutions close to each of the center-stable manifold.",
        "comments": "MSC Class:          35L05; 35A01; 35B40; 35B44; 37K40",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12581"
    },
    {
        "doc_id": 97,
        "title": "Chow ring of moduli spaces of quasi-polarised K3 surfaces in lower genus",
        "authors": [
            "Fei Si"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "In the paper, we show the Chow ring of moduli spaces of quasi-polarised K3 surfaces in lower genus ($\\le 5$) is tautological.",
        "comments": "16 pages. Comments are very welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12580"
    },
    {
        "doc_id": 98,
        "title": "On polynomial images of a closed ball",
        "authors": [
            "Jos\u00e9 F. Fernando",
            "Carlos Ueno"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "In this work we approach the problem of determining which (compact) semialgebraic subsets of ${\\mathbb R}^n$ are images under polynomial maps $f:{\\mathbb R}^m\\to{\\mathbb R}^n$ of the closed unit ball $\\overline{\\mathcal B}_m$ centered at the origin of some Euclidean space ${\\mathbb R}^m$ and that of estimating (when possible) which is the smallest $m$ with this property. Contrary to what happens with the images of ${\\mathbb R}^m$ under polynomial maps, it is quite straightforward to provide basic examples of semialgebraic sets that are polynomial images of the closed unit ball. For instance, simplices, cylinders, hypercubes, elliptic, parabolic or hyperbolic segments (of dimension $n$) are polynomial images of the closed unit ball in ${\\mathbb R}^n$.\n  The previous examples (and other basic ones proposed in the article) provide a large family of `$n$-bricks' and we find necessary and sufficient conditions to guarantee that a finite union of `$n$-bricks' is again a polynomial image of the closed unit ball either of dimension $n$ or $n+1$. In this direction, we prove: {\\em A finite union ${\\mathcal S}$ of $n$-dimensional convex polyhedra is the image of the $n$-dimensional closed unit ball $\\overline{\\mathcal B}_n$ if and only if ${\\mathcal S}$ is connected by analytic paths}.\n  The previous result can be generalized using the `$n$-bricks' mentioned before and we show: {\\em If ${\\mathcal S}_1,\\ldots,{\\mathcal S}_\\ell\\subset{\\mathbb R}^n$ are `$n$-bricks', the union ${\\mathcal S}:=\\bigcup_{i=1}^\\ell{\\mathcal S}_i$ is the image of the closed unit ball $\\overline{\\mathcal B}_{n+1}$ of ${\\mathbb R}^{n+1}$ under a polynomial map $f:{\\mathbb R}^{n+1}\\to{\\mathbb R}^n$ if and only if ${\\mathcal S}$ is connected by analytic paths}.",
        "comments": "41 pages, 18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12579"
    },
    {
        "doc_id": 99,
        "title": "Representation of positive semidefinite elements as sum of squares in 2-dimensional local rings",
        "authors": [
            "Jos\u00e9 F. Fernando"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "A classical problem in real geometry concerns the representation of positive semidefinite elements of a ring $A$ as sums of squares of elements of $A$. If $A$ is an excellent ring of dimension $\\geq3$, it is already known that it contains positive semidefinite elements that cannot be represented as sums of squares in $A$. The one dimensional local case has been afforded by Scheiderer (mainly when its residue field is real closed). In this work we focus on the $2$-dimensional case and determine (under some mild conditions) which local excellent henselian rings $A$ of embedding dimension $3$ have the property that every positive semidefinite element of $A$ is a sum of squares of elements of $A$.",
        "comments": "55 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12572"
    },
    {
        "doc_id": 100,
        "title": "Distributed Empirical Likelihood Inference With or Without Byzantine Failures",
        "authors": [
            "Qihua Wang",
            "Jinye Du",
            "Ying Sheng"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Empirical likelihood is a very important nonparametric approach which is of wide application. However, it is hard and even infeasible to calculate the empirical log-likelihood ratio statistic with massive data. The main challenge is the calculation of the Lagrange multiplier. This motivates us to develop a distributed empirical likelihood method by calculating the Lagrange multiplier in a multi-round distributed manner. It is shown that the distributed empirical log-likelihood ratio statistic is asymptotically standard chi-squared under some mild conditions. The proposed algorithm is communication-efficient and achieves the desired accuracy in a few rounds. Further, the distributed empirical likelihood method is extended to the case of Byzantine failures. A machine selection algorithm is developed to identify the worker machines without Byzantine failures such that the distributed empirical likelihood method can be applied. The proposed methods are evaluated by numerical simulations and illustrated with an analysis of airline on-time performance study and a surface climate analysis of Yangtze River Economic Belt.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12827"
    },
    {
        "doc_id": 101,
        "title": "Generative AI Triggers Welfare-Reducing Decisions in Humans",
        "authors": [
            "Fabian Dvorak",
            "Regina Stumpf",
            "Sebastian Fehrler",
            "Urs Fischbacher"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Generative artificial intelligence (AI) is poised to reshape the way individuals communicate and interact. While this form of AI has the potential to efficiently make numerous human decisions, there is limited understanding of how individuals respond to its use in social interaction. In particular, it remains unclear how individuals engage with algorithms when the interaction entails consequences for other people. Here, we report the results of a large-scale pre-registered online experiment (N = 3,552) indicating diminished fairness, trust, trustworthiness, cooperation, and coordination by human players in economic twoplayer games, when the decision of the interaction partner is taken over by ChatGPT. On the contrary, we observe no adverse welfare effects when individuals are uncertain about whether they are interacting with a human or generative AI. Therefore, the promotion of AI transparency, often suggested as a solution to mitigate the negative impacts of generative AI on society, shows a detrimental effect on welfare in our study. Concurrently, participants frequently delegate decisions to ChatGPT, particularly when the AI's involvement is undisclosed, and individuals struggle to discern between AI and human decisions.",
        "comments": "19 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12773"
    },
    {
        "doc_id": 102,
        "title": "Improving single-molecule conductance measurements with change point detection from the econometrics toolbox",
        "authors": [
            "Joseph M. Hamill",
            "William Bro-J\u00f8rgensen",
            "Zolt\u00e1n Balogh",
            "Haixing Li",
            "Susanne Leitherer",
            "David Solomon",
            "Andr\u00e1s Halbritter",
            "Gemma Solomon"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Soft Condensed Matter"
        ],
        "abstract": "Structural breaks occur in timeseries data across a broad range of fields, from economics to nanosciences. For measurements of single-molecule break junctions, structural breaks in conductance versus displacement data occur when the molecular junction ruptures. This moment is significant because the molecule is likely in its most extended geometry, and therefore resembles most closely the geometry used in theoretical predictions. Conventional single-molecule break junction data analysis, on the other hand, typically uses the entire molecular plateau to estimate the single-molecule conductance, which skews the estimate when the plateau is sloped. Borrowing from econometrics, where the study of structural breaks is well established, we present change point detection (CPD) as a tool to search for junction rupture in single-molecule break junction data, and improve estimates in single-molecule conductance. We demonstrate that using CPD instead of the conventional 1D conductance histogram to determine the mean molecular conductance yields a standard deviation in the estimate of typically half that of the conventional approach, greatly improving accuracy. We apply CPD to three separate data sets, two on 4,4'-bipyridine and one on a silane, two at room temperature and one at 4 K, two in one lab, one in another, to show the wide applicability of even the simplest of CPD algorithms: the Chow test. This versatility and better accuracy will propagate into more accurate theoretical simulations. These improved metrics, in turn, will further improve any downstream analyses, including all emerging machine learning approaches.",
        "comments": "33 pages and 11 figures and supporting material of 8 pages and 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12769"
    },
    {
        "doc_id": 103,
        "title": "Optimal design of a local renewable electricity supply system for power-intensive production processes with demand response",
        "authors": [
            "Sonja H. M. Germscheid",
            "Benedikt Nilges",
            "Niklas von der Assen",
            "Alexander Mitsos",
            "Manuel Dahmen"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This work studies synergies arising from combining industrial demand response and local renewable electricity supply. To this end, we optimize the design of a local electricity generation and storage system with an integrated demand response scheduling of a continuous power-intensive production process in a multi-stage problem. We optimize both total annualized cost and global warming impact and consider local photovoltaic and wind electricity generation, an electric battery, and electricity trading on day-ahead and intraday market. We find that installing a battery can reduce emissions and enable large trading volumes on the electricity markets, but significantly increases cost. Economic and ecologic process and battery operation are driven primarily by the electricity price and grid emission factor, respectively, rather than locally generated electricity. A parameter study reveals that economic savings from the local system and flexibilizing the process behave almost additive.",
        "comments": "manuscript (32 pages, 9 figures, 6 tables), supporting materials (11 pages, 9 figures, 2 tables)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12759"
    },
    {
        "doc_id": 104,
        "title": "Multicausal transport: barycenters and dynamic matching",
        "authors": [
            "Beatrice Acciaio",
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "We introduce a multivariate version of adapted transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agents' types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.",
        "comments": "26 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12748"
    },
    {
        "doc_id": 105,
        "title": "Arrow's single peaked domains, richness, and domains for plurality and the Borda count",
        "authors": [
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper we extend the study of Arrow's generalisation of Black's single-peaked domain and connect this to domains where voting rules satisfy different versions of independence of irrelevant alternatives.\n  First we report on a computational generation of all non-isomorphic Arrow's single-peaked domains on $n\\leq 9$ alternatives. Next, we introduce a quantitative measure of richness for domains, as the largest number $r$ such that every alternative is given every rank between 1 and $r$ by the orders in the domain. We investigate the richness of Arrow's single-peaked domains and prove that Black's single-peaked domain has the highest possible richness, but it is not the only domain which attains the maximum.\n  After this we connect Arrow's single-peaked domains to the discussion by Dasgupta, Maskin and others of domains on which plurality and the Borda count satisfy different versions of Independence of Irrelevant alternatives (IIA). For Nash's version of IIA and plurality, it turns out the domains are exactly the duals of Arrow's single-peaked domains. As a consequence there can be at most two alternatives which are ranked first in any such domain.\n  For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum domain size which is exponentially smaller than $2^{n-1}$, the size of Black's single-peaked domain.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12547"
    },
    {
        "doc_id": 106,
        "title": "Moen Meets Rotemberg: An Earthly Model of the Divine Coincidence",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "This paper proposes a model of the divine coincidence, explaining its recent appearance in US data. The divine coincidence matters because it helps explain the behavior of inflation after the pandemic, and it guarantees that the full-employment and price-stability mandates of the Federal Reserve coincide. In the model, a Phillips curve relating unemployment to inflation arises from Moen's (1997) directed search. The Phillips curve is nonvertical thanks to Rotemberg's (1982) price-adjustment costs. The model's Phillips curve guarantees that the rate of inflation is on target whenever the rate of unemployment is efficient, generating the divine coincidence. If we assume that wage decreases -- which reduce workers' morale -- are more costly to producers than price increases -- which upset customers -- the Phillips curve also displays a kink at the point of divine coincidence.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12475"
    },
    {
        "doc_id": 107,
        "title": "Convex-Concave Zero-sum Markov Stackelberg Games",
        "authors": [
            "Denizalp Goktas",
            "Arjun Prakash",
            "Amy Greenwald"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "Zero-sum Markov Stackelberg games can be used to model myriad problems, in domains ranging from economics to human robot interaction. In this paper, we develop policy gradient methods that solve these games in continuous state and action settings using noisy gradient estimates computed from observed trajectories of play. When the games are convex-concave, we prove that our algorithms converge to Stackelberg equilibrium in polynomial time. We also show that reach-avoid problems are naturally modeled as convex-concave zero-sum Markov Stackelberg games, and that Stackelberg equilibrium policies are more effective than their Nash counterparts in these problems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12437"
    },
    {
        "doc_id": 108,
        "title": "A Unified Approach to Second and Third Degree Price Discrimination",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Michael C. Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory"
        ],
        "abstract": "We analyze the welfare impact of a monopolist able to segment a multiproduct market and offer differentiated price menus within each segment. We characterize a family of extremal distributions such that all achievable welfare outcomes can be reached by selecting segments from within these distributions. This family of distributions arises as the solution to the consumer maximizing distribution of values for multigood markets. With these results, we analyze the effect of segmentation on consumer surplus and prices in both interior and extremal markets, including conditions under which there exists a segmentation benefiting all consumers. Finally, we present an efficient algorithm for computing segmentations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12366"
    },
    {
        "doc_id": 109,
        "title": "Business Model Contributions to Bank Profit Performance: A Machine Learning Approach",
        "authors": [
            "F. Bolivar",
            "Miguel A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the relation between bank profit performance and business models. Using a machine learning-based approach, we propose a methodological strategy in which balance sheet components' contributions to profitability are the identification instruments of business models. We apply this strategy to the European Union banking system from 1997 to 2021. Our main findings indicate that the standard retail-oriented business model is the profile that performs best in terms of profitability, whereas adopting a non-specialized business profile is a strategic decision that leads to poor profitability. Additionally, our findings suggest that the effect of high capital ratios on profitability depends on the business profile. The contributions of business models to profitability decreased during the Great Recession. Although the situation showed signs of improvement afterward, the European Union banking system's ability to yield returns is still problematic in the post-crisis period, even for the best-performing group.",
        "comments": "46 pages, 10 tables, 3 figures, submitted version of a paper published in Research in International Business and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12334"
    },
    {
        "doc_id": 110,
        "title": "Bank Business Models, Size, and Profitability",
        "authors": [
            "F. Bolivar",
            "M. A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "To examine the relation between profitability and business models (BMs) across bank sizes, the paper proposes a research strategy based on machine learning techniques. This strategy allows for analyzing whether size and profit performance underlie BM heterogeneity, with BM identification being based on how the components of the bank portfolio contribute to profitability. The empirical exercise focuses on the European Union banking system. Our results suggest that banks with analogous levels of performance and different sizes share strategic features. Additionally, high capital ratios seem compatible with high profitability if banks, relative to their size peers, adopt a standard retail BM.",
        "comments": "14 pages, 1 figure, 3 tables, accepted version of an article published in Finance Research Letters",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12323"
    },
    {
        "doc_id": 111,
        "title": "The outcomes of generative AI are exactly the Nash equilibria of a non-potential game",
        "authors": [
            "Boualem Djehiche",
            "Hamidou Tembine"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "In this article we show that the asymptotic outcomes of both shallow and deep neural networks such as those used in BloombergGPT to generate economic time series are exactly the Nash equilibria of a non-potential game. We then design and analyze deep neural network algorithms that converge to these equilibria. The methodology is extended to federated deep neural networks between clusters of regional servers and on-device clients. Finally, the variational inequalities behind large language models including encoder-decoder related transformers are established.",
        "comments": "24 pages. Accepted and to appear in: International Econometric Conference of Vietnam",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12321"
    },
    {
        "doc_id": 112,
        "title": "The Risk-Return Relation in the Corporate Loan Market",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the hypothesis that returns play a risk-compensating role in the market for corporate revolving lines of credit. Specifically, we test whether borrower risk and the expected return on these debt instruments are positively related. Our main findings support this prediction, in contrast to the only previous work that examined this problem two decades ago. Nevertheless, we find evidence of mispricing regarding the risk of deteriorating firms using their facilities more intensively and during the subprime crisis.",
        "comments": "56 pages, 3 figurees, 7 tables, accepted version of a paper published in the North American Journal of Economics and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12315"
    },
    {
        "doc_id": 113,
        "title": "Interpreting Event-Studies from Recent Difference-in-Differences Methods",
        "authors": [
            "Jonathan Roth"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This note discusses the interpretation of event-study plots produced by recent difference-in-differences methods. I show that even when specialized to the case of non-staggered treatment timing, the default plots produced by software for three of the most popular recent methods (de Chaisemartin and D'Haultfoeuille, 2020; Callaway and SantAnna, 2021; Borusyak, Jaravel and Spiess, 2024) do not match those of traditional two-way fixed effects (TWFE) event-studies: the new methods may show a kink or jump at the time of treatment even when the TWFE event-study shows a straight line. This difference stems from the fact that the new methods construct the pre-treatment coefficients asymmetrically from the post-treatment coefficients. As a result, visual heuristics for analyzing TWFE event-study plots should not be immediately applied to those from these methods. I conclude with practical recommendations for constructing and interpreting event-study plots when using these methods.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12309"
    },
    {
        "doc_id": 114,
        "title": "Pricing and Usage: An Empirical Analysis of Lines of Credit",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The hypothesis that committed revolving credit lines with fixed spreads can provide firms with interest rate insurance is a standard feature of models on these credit facilities' interest rate structure. Nevertheless, this hypothesis has not been tested. Its empirical examination is the main contribution of this paper. To perform this analysis, and given the unavailability of data, we hand-collect data on usage at the credit line level itself. The resulting dataset enables us also to take into account characteristics of credit lines that have been ignored by previous research. One of them is that credit lines can have simultaneously fixed and performance-based spreads.",
        "comments": "32 pages, 7 tables, accepted version of a paper published in the Journal of International Financial Markets, Institutions and Money",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12301"
    },
    {
        "doc_id": 115,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 116,
        "title": "The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review",
        "authors": [
            "Chandregowda Pachegowda"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ],
        "abstract": "Artificial intelligence (AI) is an emerging technology that has the potential to transform many aspects of society, including the economy, healthcare, and transportation. This article synthesizes recent research literature on the global impact of AI, exploring its potential benefits and risks. The article highlights the implications of AI, including its impact on economic, ethical, social, security & privacy, and job displacement aspects. It discusses the ethical concerns surrounding AI development, including issues of bias, security, and privacy violations. To ensure the responsible development and deployment of AI, collaboration between government, industry, and academia is essential. The article concludes by emphasizing the importance of public engagement and education to promote awareness and understanding of AI's impact on society at large.",
        "comments": "4 pages",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.12223"
    },
    {
        "doc_id": 117,
        "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
        "authors": [
            "Tahereh Zarrat Ehsan",
            "Seyed Mehdi Mohtavipour"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal chicken health conditions, minimizing economic losses and bolstering profitability. This paper presents a novel real-time framework for analyzing chicken behavior in cage-free poultry houses to detect abnormal behaviors. Specifically, two significant abnormalities, namely inactive broiler and huddling behavior, are investigated in this study. The proposed framework comprises three key steps: (1) chicken detection utilizing a state-of-the-art deep learning model, (2) tracking individual chickens across consecutive frames with a fast tracker module, and (3) detecting abnormal behaviors within the video stream. Experimental studies are conducted to evaluate the efficacy of the proposed algorithm in accurately assessing chicken behavior. The results illustrate that our framework provides a precise and efficient solution for real-time anomaly detection, facilitating timely interventions to maintain chicken health and enhance overall productivity on poultry farms. Github: https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
        "comments": "11 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12176"
    },
    {
        "doc_id": 118,
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Theoretical Economics"
        ],
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about centralization in block-building (due to, e.g., MEV and private order flow) and the outsourcing of block-building by validators to specialists (i.e., proposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers inevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve decentralization among proposers?\n  This paper develops mathematical models and results that offer answers to these questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block producer rewards, and staking costs, we quantify the extent to which heterogeneous rewards lead to concentration in the equilibrium staking distribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly reinvest rewards into staking, we quantify, as a function of the block producer heterogeneity, the rate at which stake concentrates on the most sophisticated block producers.\n  3. In a model with heterogeneous proposers and specialized builders, we quantify, as a function of the competitiveness of the builder ecosystem, the extent to which proposer-builder separation reduces the heterogeneity in rewards across different proposers.\n  Our models and results take advantage of connections to contest design, P\u00f3lya urn processes, and auction theory.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12120"
    },
    {
        "doc_id": 119,
        "title": "Measures of the Capital Network of the U.S. Economy",
        "authors": [
            "Ben Klemens"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "About two million U.S. corporations and partnerships are linked to each other and human investors by about 15 million owner-subsidiary links. Comparable social networks such as corporate board memberships and socially-built systems such as the network of Internet links are \"small worlds,\" meaning a network with a small diameter and link densities with a power-law distribution, but these properties had not yet been measured for the business entity network. This article shows that both inbound links and outbound links display a power-law distribution with a coefficient of concentration estimable to within a generally narrow confidence interval, overall, for subnetworks including only business entities, only for the great connected component of the network, and in subnetworks with edges associated with certain industries, for all years 2009-2021. In contrast to other networks with power-law distributed link densities, the network is mostly a tree, and has a diameter an order of magnitude larger than a small-world network with the same link distribution. The regularity of the power-law distribution indicates that its coefficient can be used as a new, well-defined macroeconomic metric for the concentration of capital flows in an economy. Economists might use it as a new measure of market concentration which is more comprehensive than measures based only on the few biggest firms. Comparing capital link concentrations across countries would facilitate modeling the relationship between business network characteristics and other macroeconomic indicators.",
        "comments": "18 pages. JEL classifications: L14; C81; M42; G34",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12118"
    },
    {
        "doc_id": 120,
        "title": "Metrics matter, a Formal comment on Ward et al Plos-One 2016 paper : Is decoupling GDP growth from environmental impact possible?",
        "authors": [
            "Herv\u00e9 Bercegol",
            "Paul E. Brockway"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The Ward et al. (2016) Plos-One paper is an important, heavily-cited paper in the decoupling literature. The authors present evidence of 1990-2015 growth in material and energy consumption and GDP at a world level, and for selected countries. They find only relative decoupling has occurred, leading to their central claim that future absolute decoupling is implausible. However, the authors have made two key errors in their collected data: GDP data is in current prices which includes inflation, and their global material use data is the total mass of fossil energy materials. Strictly, GDP data should be in constant prices to allow for its comparison over time, and material inputs to an economy should be the sum of mineral raw materials. Amending for these errors, we find much smaller levels of energy-GDP relative decoupling, and no materials-GDP decoupling at all at a global level. We check these new results by adding data for 1900-1990 to provide a longer time series, and find consistently low (and even no) levels of global relative decoupling of material use. The central claim for materials over the implausibility of future absolute decoupling therefore not only remains valid but is reinforced by the corrected datasets.",
        "comments": "6 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12100"
    },
    {
        "doc_id": 121,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 122,
        "title": "Market Responses to Genuine Versus Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers",
        "authors": [
            "Chen Liang",
            "Murat Tunc",
            "Gordon Burtch"
        ],
        "subjects": [
            "General Economics",
            "Computers and Society",
            "Human-Computer Interaction"
        ],
        "abstract": "Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about the motivations of donors in these charity fundraisers, resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity, based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of strategic generosity), and based on an individual's degree of social exposure within the NFT marketplace. We show that charity-NFT \"relisters\" experience significant penalties in the market, in terms of the prices they are able to command on other NFT listings, particularly among those who relist quickly and those who are more socially exposed. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12064"
    },
    {
        "doc_id": 123,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 124,
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "Several of the classical results in social choice theory demonstrate that in order for many voting systems to be well-behaved the set domain of individual preferences must satisfy some kind of restriction, such as being single-peaked on a political axis. As a consequence it becomes interesting to measure how diverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference diversity, focusing on the abundance of distinct suborders one subsets of the alternative. We provide a common generalisation of the frequently used concepts of ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our theorems imply a ceiling for the local diversity in domains on large sets of alternatives, which show that in this measure Black's single-peaked domain is in fact optimal. We also demonstrate that for some numbers of alternatives, there are Condorcet domains which have largest local diversity without having maximum order.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11912"
    },
    {
        "doc_id": 125,
        "title": "Efficiency in random allocation with ordinal rules",
        "authors": [
            "Samson Alva",
            "Eun Jeong Heo",
            "Vikram Manjunath"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study ordinal rules for allocating indivisible goods via lottery. Ordinality requires a rule to consider only how agents rank degenerate lotteries and may be necessitated by cognitive, informational, or as we show, incentive constraints. The limited responsiveness of ordinal rules to agents' preferences means that they can only satisfy welfare properties based on first order stochastic dominance, which is incomplete.\n  We define a new efficiency concept for ordinal rules. While ordinality and efficiency together are incompatible with the usual notions of fairness and somewhat limit randomization, they do leave room for a rich class of rules. We demonstrate this through a characterization of all ordinal, efficient, strategy-proof, non-bossy, boundedly invariant, and neutral rules.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11899"
    },
    {
        "doc_id": 126,
        "title": "Finite horizon optimal control of reaction-diffusion SIV epidemic system with stochastic environment",
        "authors": [
            "Zong Wang"
        ],
        "subjects": [
            "Optimization and Control",
            "Dynamical Systems"
        ],
        "abstract": "This contribution mainly focuses on the finite horizon optimal control problems of a susceptible-infected-vaccinated(SIV) epidemic system governed by reaction-diffusion equations and Markov switching. Stochastic dynamic programming is employed to find the optimal vaccination effort and economic return for a stochastic reaction diffusion SIV epidemic model. To achieve this, a key step is to show the existence and uniqueness of invariant measure for the model. Then, we obtained the necessary and sufficient conditions for the near-optimal control. Furthermore, we give an algorithm to approximate the Hamilton-Jacobi Bellman (HJB) equation. Finally, some numerical simulations are presented to confirm our analytic results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11744"
    },
    {
        "doc_id": 127,
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "authors": [
            "Yu Zhu",
            "Kang Li",
            "Lequan Yu",
            "Pheng-Ann Heng"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.",
        "comments": "Accepted by AAAI 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11674"
    },
    {
        "doc_id": 128,
        "title": "Analyzing the Impact of Financial Inclusion on Economic Growth in Bangladesh",
        "authors": [
            "Ganapati Kumar Biswas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial inclusion is touted one of the principal drivers for economic growth for an economy. The study aims to explore the impact of financial inclusion on economic growth in Bangladesh. In my study, I used the number of loan accounts as the proxy for financial inclusion. Using time series data from spans from 2004-2021, the study revealed that there exists a long-run relationship between GDP, financial inclusion, and other macroeconomic variables in Bangladesh. The study also found that financial inclusion had a positive impact on economic growth of Bangladesh during the study period. Therefore, the policymakers and the central bank of Bangladesh as the apex authority of financial system should promote financial inclusion activities to achieve sustainable economic growth.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11585"
    },
    {
        "doc_id": 129,
        "title": "A note on the stability of Monotone Markov Chains",
        "authors": [
            "Bar Light"
        ],
        "subjects": [
            "Probability",
            "Theoretical Economics"
        ],
        "abstract": "This note studies monotone Markov chains a subclass of Markov chains with extensive applications in operations research and economics. While the properties that ensure the global stability of these chains are well studied, their establishment often relies on the fulfillment of a certain splitting condition. We address the challenges of verifying the splitting condition, by introducing simple, applicable conditions that ensure global stability. The simplicity of these conditions is demonstrated through various examples including autoregressive processes and portfolio allocation problems.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11568"
    },
    {
        "doc_id": 130,
        "title": "Taxi dispatching strategies with compensations",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski",
            "Javier Palanca",
            "Javier Bajo"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi vehicles are key elements in daily traffic activity. The advance of ICT and geo-positioning systems has given rise to new opportunities for improving the efficiency of taxi fleets in terms of waiting times of passengers, cost and time for drivers, traffic density, CO2 emissions, etc., by using more informed, intelligent dispatching. Still, the explicit spatial and temporal components, as well as the scale and, in particular, the dynamicity of the problem of pairing passengers and taxis in big towns, render traditional approaches for solving standard assignment problem useless for this purpose, and call for intelligent approximation strategies based on domain-specific heuristics. Furthermore, taxi drivers are often autonomous actors and may not agree to participate in assignments that, though globally efficient, may not be sufficently beneficial for them individually. This paper presents a new heuristic algorithm for taxi assignment to customers that considers taxi reassignments if this may lead to globally better solutions. In addition, as such new assignments may reduce the expected revenues of individual drivers, we propose an economic compensation scheme to make individually rational drivers agree to proposed modifications in their assigned clients. We carried out a set of experiments, where several commonly used assignment strategies are compared to three different instantiations of our heuristic algorithm. The results indicate that our proposal has the potential to reduce customer waiting times in fleets of autonomous taxis, while being also beneficial from an economic point of view.",
        "comments": "ACM Class:          I.2.1",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11553"
    },
    {
        "doc_id": 131,
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "authors": [
            "Zhigang Wang",
            "Xu Zhang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Transformer-based models are becoming deeper and larger recently. For better scalability, an underlying training solution in industry is to split billions of parameters (tensors) into many tasks and then run them across homogeneous accelerators (e.g., GPUs). However, such dedicated compute cluster is prohibitively expensive in academia and moderate companies. An economic replacement is to aggregate existing heterogeneous devices and share resources among multi-tenants. Nevertheless, static hardware configurations and dynamic resource contention definitely cause straggling tasks, which heavily slows down the overall training efficiency. Existing works feature contributions mainly tailored for traditional data parallelism. They cannot work well for the new tensor parallelism due to strict communication and correctness constraints.\n  In this paper we first present ZERO-resizing, a novel dynamic workload balancing technique without any data migration. We tune workloads in real-time by temporarily resizing matrices involved in core tensor-related computations. We particularly design data imputation and priority selection policies to respectively satisfy consistency constraint required by normal training and reduce the accuracy loss. We also give a lightweight data migration technique without loss of accuracy, to cope with heavy heterogeneity. Our final SEMI-migration solution is built on top of these two techniques and can adaptively distinguish their respective balancing missions, to achieve an overall success in efficiency and accuracy. Extensive experiments on the representative Colossal-AI platform validate the effectiveness of our proposals.",
        "comments": "13 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11469"
    },
    {
        "doc_id": 132,
        "title": "Local Identification in the Instrumental Variable Multivariate Quantile Regression Model",
        "authors": [
            "Haruki Kono"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The instrumental variable (IV) quantile regression model introduced by Chernozhukov and Hansen (2005) is a useful tool for analyzing quantile treatment effects in the presence of endogeneity, but when outcome variables are multidimensional, it is silent on the joint distribution of different dimensions of each variable. To overcome this limitation, we propose an IV model built on the optimal-transport-based multivariate quantile that takes into account the correlation between the entries of the outcome variable. We then provide a local identification result for the model. Surprisingly, we find that the support size of the IV required for the identification is independent of the dimension of the outcome vector, as long as the IV is sufficiently informative. Our result follows from a general identification theorem that we establish, which has independent theoretical significance.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11422"
    },
    {
        "doc_id": 133,
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "authors": [
            "Md Zubair",
            "Md. Shahidul Salim",
            "Mehrab Mustafy Rahman",
            "Mohammad Jahid Ibna Basher",
            "Shahin Imran",
            "Iqbal H. Sarker"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with higher accuracy. These predictions guide our system to assist the farmers in making feasible decisions about planting, irrigation, harvesting, and so on. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.",
        "comments": "16 pages, 14 figures and 12 tables. Submitted to Engineering Application of Artificial Intelligence (Elsevier)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11410"
    },
    {
        "doc_id": 134,
        "title": "Fake Google restaurant reviews and the implications for consumers and restaurants",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The use of online reviews to aid with purchase decisions is popular among consumers as it is a simple heuristic tool based on the reported experiences of other consumers. However, not all online reviews are written by real consumers or reflect actual experiences, and present implications for consumers and businesses. This study examines the effects of fake online reviews written by artificial intelligence (AI) on consumer decision making. Respondents were surveyed about their attitudes and habits concerning online reviews using an online questionnaire (n=351), and participated in a restaurant choice experiment using varying proportions of fake and real reviews. While the findings confirm prior studies, new insights are gained about the confusion for consumers and consequences for businesses when reviews written by AI are believed rather than real reviews. The study presents a fake review detection model using logistic regression modeling to score and flag reviews as a solution.",
        "comments": "pp.1-158, 41 tables, 11 figures. Doctor of Business Administration Dissertation",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11345"
    },
    {
        "doc_id": 135,
        "title": "An income-based approach to modeling commuting distance in the Toronto area",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The purpose of this article is to propose a novel model of the effects of changes in shelter and driving costs on car commuting distances in the overheated Toronto housing market from 2011 to 2016. The model borrows from theoretical concepts of microeconomics and urban geography to examine the Toronto housing market. Using 2011 and 2016 Census data for census metropolitan areas (CMAs) and census agglomerations (CAs) in Southern Ontario and computed driving costs, the model of car commuting distance is based on variables of allocation of monthly household income to monthly shelter costs and driving costs as a function of the car driving distance to Toronto. Using this model, we can predict the effect on car commuting distance due to changes in any of the variables. The model also offers an explanation for communities of Toronto car commuters beyond a driving radius that we might expect for daily commuting. The model confirms that increases in shelter costs in the Toronto housing market from 2011 to 2016 have forced the boundaries of feasible housing locations outward, and forced households to move farther away, thus increasing car commuting distance.",
        "comments": "pp.1-40, 8 tables, 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11343"
    },
    {
        "doc_id": 136,
        "title": "Coevolution of Resource and Strategies in Common-Pool Resource Dilemmas: A Coupled Human-Environmental System Model",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Yongliang Yang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "Common-pool resource governance requires users to cooperate and avoid overexploitation, but defection and free-riding often undermine cooperation. We model a human-environmental system that integrates dynamics of resource and users' strategies. The resource follows a logistic function that depends on natural growth rate, carrying capacity, and extraction rates of cooperators and defectors. The users' strategies evolve according to different processes that capture effects of payoff, resource, and noise. We analyze the feedback between resource availability and strategic adaptation, and explores the conditions for the emergence and maintenance of cooperation. We find different processes lead to different regimes of equilibrium solutions and resource levels depending on the parameter configuration and initial conditions. We also show that some processes can enhance the sustainability of the resource by making the users more responsive to the resource scarcity. The paper advances the understanding of human-environmental system and offers insights for resource governance policies and interventions.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11269"
    },
    {
        "doc_id": 137,
        "title": "Estimation with Pairwise Observations",
        "authors": [
            "Felix Chan",
            "Laszlo Matyas"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The paper introduces a new estimation method for the standard linear regression model. The procedure is not driven by the optimisation of any objective function rather, it is a simple weighted average of slopes from observation pairs. The paper shows that such estimator is consistent for carefully selected weights. Other properties, such as asymptotic distributions, have also been derived to facilitate valid statistical inference. Unlike traditional methods, such as Least Squares and Maximum Likelihood, among others, the estimated residual of this estimator is not by construction orthogonal to the explanatory variables of the model. This property allows a wide range of practical applications, such as the testing of endogeneity, i.e.,the correlation between the explanatory variables and the disturbance terms, and potentially several others.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11229"
    },
    {
        "doc_id": 138,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 139,
        "title": "Long-term Effects of India's Childhood Immunization Program on Earnings and Consumption Expenditure: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Summan, Nandi, and Bloom (2023; SNB) finds that exposure of babies to India's Universal Immunization Programme (UIP) in the late 1980s increased their weekly wages in early adulthood by 0.138 log points and per-capita household consumption 0.028 points. But the results are attained by regressing on age, in years, while controlling for year of birth--two variables that, as constructed, are nearly collinear. The results are therefore attributable to trends during the one-year survey period, such as inflation. A randomization exercise shows that when the true impacts are zero, the SNB estimator averages 0.088 points for wages and 0.039 points for consumption.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11100"
    },
    {
        "doc_id": 140,
        "title": "Information Based Inference in Models with Set-Valued Predictions and Misspecification",
        "authors": [
            "Hiroaki Kaido",
            "Francesca Molinari"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This paper proposes an information-based inference method for partially identified parameters in incomplete models that is valid both when the model is correctly specified and when it is misspecified. Key features of the method are: (i) it is based on minimizing a suitably defined Kullback-Leibler information criterion that accounts for incompleteness of the model and delivers a non-empty pseudo-true set; (ii) it is computationally tractable; (iii) its implementation is the same for both correctly and incorrectly specified models; (iv) it exploits all information provided by variation in discrete and continuous covariates; (v) it relies on Rao's score statistic, which is shown to be asymptotically pivotal.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11046"
    },
    {
        "doc_id": 141,
        "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models",
        "authors": [
            "Ben Aoki-Sherwood",
            "Catherine Bregou",
            "David Liben-Nowell",
            "Kiran Tomlinson",
            "Thomas Zeng"
        ],
        "subjects": [
            "Machine Learning",
            "Multiagent Systems",
            "Econometrics"
        ],
        "abstract": "A common theory of choice posits that individuals make choices in a two-step process, first selecting some subset of the alternatives to consider before making a selection from the resulting consideration set. However, inferring unobserved consideration sets (or item consideration probabilities) in this \"consider then choose\" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We consider a natural extension of consider-then-choose models to a top-$k$ ranking setting, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that knowledge of item utilities allows us to infer bounds on the relative sizes of consideration probabilities. Additionally, given a condition on the expected consideration set size, we derive absolute upper and lower bounds on item consideration probabilities. We also provide algorithms to tighten those bounds on consideration probabilities by propagating inferred constraints. Thus, we show that we can learn useful information about consideration probabilities despite not being able to identify them precisely. We demonstrate our methods on a ranking dataset from a psychology experiment with two different ranking tasks (one with fixed consideration sets and one with unknown consideration sets). This combination of data allows us to estimate utilities and then learn about unknown consideration probabilities using our bounds.",
        "comments": "11 pages; accepted as an extended abstract to AAMAS '24",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11016"
    },
    {
        "doc_id": 142,
        "title": "Subjective Causality",
        "authors": [
            "Joseph Y. Halpern",
            "Evan Piermont"
        ],
        "subjects": [
            "Theoretical Economics",
            "Artificial Intelligence",
            "Logic in Computer Science"
        ],
        "abstract": "We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are consistent with some causal model and to identify causal judgements from observed behavior.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10937"
    },
    {
        "doc_id": 143,
        "title": "An Experimental Study of Decentralized Matching",
        "authors": [
            "Federico Echenique",
            "Alejandro Robinson-Cort\u00e9s",
            "Leeat Yariv"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "We present an experimental study of decentralized two-sided matching markets with no transfers. Experimental participants are informed of everyone's preferences and can make arbitrary non-binding match offers that get finalized when a period of market inactivity has elapsed. Several insights emerge. First, stable outcomes are prevalent. Second, while centralized clearinghouses commonly aim at implementing extremal stable matchings, our decentralized markets most frequently culminate in the median stable matching. Third, preferences' cardinal representations impact the stable partners participants match with. Last, the dynamics underlying our results exhibit strategic sophistication, with agents successfully avoiding cycles of blocking pairs.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10872"
    },
    {
        "doc_id": 144,
        "title": "Aberration compensation for the anamorphic triplet",
        "authors": [
            "Dmitry Zhuridov"
        ],
        "subjects": [
            "Optics",
            "Applied Physics",
            "Instrumentation and Detectors"
        ],
        "abstract": "Compensation of the generalized spherical aberrations is discussed for the plane-symmetric and anamorphic optical systems. The compensation rules are derived for an economical three-component double-plane symmetric telescopic system containing two cylindrical mirrors and one toroidal lens. Anamorphic systems, which provide large magnifications in the two orthogonal directions, are presented.",
        "comments": "4 pages, 4 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10762"
    },
    {
        "doc_id": 145,
        "title": "Methodology to assess prosumer participation in European electricity markets",
        "authors": [
            "Rub\u00e9n Rodr\u00edguez-Vilches",
            "Francisco Mart\u00edn-Mart\u00ednez",
            "\u00c1lvaro S\u00e1nchez-Miralles",
            "Javier Rodrigo Guti\u00e9rrez de la C\u00e1mara",
            "Sergio Mu\u00f1oz Delgado"
        ],
        "subjects": [
            "Physics and Society",
            "Systems and Control"
        ],
        "abstract": "The emergence of distributed generation and the electrification of demand have opened the possibility for prosumers to participate in electricity markets, receiving economic benefits on their bills and contributing to the reduction of carbon emissions, aligning with United Nations Sustainable Development Goal 7. Consumers and prosumers can participate through implicit and explicit demand flexibility and (collective) self-consumption. This study analyses the potential markets in which prosumers can participate and indicates whether these are currently open. The markets studied include day-ahead, intraday, ancillary services, adequacy services, constraint management, and local flexibility markets. Additionally, collective self-consumption is analysed as a service through which prosumers can participate in the electricity market. Previous studies are usually focused on a single market or in a single country, making impossible a complete comparison. This analysis has been done in Spain, Italy, Croatia, and the United Kingdom as representative countries to obtain a methodology to assess countries' openness to prosumer participation in electricity markets, comparing regulatory frameworks and assigning scores based on their prosumer inclusion across various markets. This work updates current literature reviews with the changes and a new description of local market designs in Spain. This methodology can be used to compare other countries' grade of openness. The results of this study show that the analysed countries can be categorised into three groups: almost open, partially open, and closed markets. Analysing the differences, recommendations on the following steps to foster user participation are suggested for each group.",
        "comments": "Journal ref:        Renewable and Sustainable Energy Reviews Volume 191, March 2024, 114179",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10696"
    },
    {
        "doc_id": 146,
        "title": "Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing",
        "authors": [
            "Wolfgang Maass",
            "Ankit Agrawal",
            "Alessandro Ciani",
            "Sven Danz",
            "Alejandro Delgadillo",
            "Philipp Ganser",
            "Pascal Kienast",
            "Marco Kulig",
            "Valentina K\u00f6nig",
            "Nil Rodellas-Gr\u00e0cia",
            "Rivan Rughubar",
            "Stefan Schr\u00f6der",
            "Marc Stautner",
            "Hannah Stein",
            "Tobias Stollenwerk",
            "Daniel Zeuch",
            "Frank K. Wilhelm"
        ],
        "subjects": [
            "Quantum Physics",
            "Systems and Control"
        ],
        "abstract": "Quantum computing (QC) and machine learning (ML), taken individually or combined into quantum-assisted ML (QML), are ascending computing paradigms whose calculations come with huge potential for speedup, increase in precision, and resource reductions. Likely improvements for numerical simulations in engineering imply the possibility of a strong economic impact on the manufacturing industry. In this project report, we propose a framework for a quantum computing-enhanced service ecosystem for simulation in manufacturing, consisting of various layers ranging from hardware to algorithms to service and organizational layers. In addition, we give insight into the current state of the art of applications research based on QC and QML, both from a scientific and an industrial point of view. We further analyse two high-value use cases with the aim of a quantitative evaluation of these new computing paradigms for industrially-relevant settings.",
        "comments": "10 pages, 3 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10623"
    },
    {
        "doc_id": 147,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 148,
        "title": "Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest Machine Learning",
        "authors": [
            "Zaina Abu Hweij",
            "Florence Liang",
            "Sophie Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Medical Physics"
        ],
        "abstract": "Acute compartment syndrome (ACS) is an orthopedic emergency, caused by elevated pressure within a muscle compartment, that leads to permanent tissue damage and eventually death. Diagnosis of ACS relies heavily on patient-reported symptoms, a method that is clinically unreliable and often supplemented with invasive intracompartmental pressure measurements. This study proposes a continuous, objective, noninvasive diagnostic for ACS. The device detects ACS through a random forest machine learning model that uses pressure readings from force-sensitive resistors (FSRs) placed on the skin. The final diagnosis is exported real-time to a web application via Bluetooth. To validate the diagnostic, a data set containing FSR measurements and the corresponding simulated intracompartmental pressure was created. The diagnostic achieved an accuracy, on par to the invasive gold standard, of 97%. The device excelled in key performance metrics including precision, sensitivity, and F1 score. Manufactured for 73 USD, our device may be an economic alternative to needle-based diagnostics. These results demonstrate the potential of noninvasive ACS diagnostics to meet clinical standards and enhance patient care.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10386"
    },
    {
        "doc_id": 149,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 150,
        "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms",
        "authors": [
            "Iris Yan"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere. GS can cause severe damages to satellites, power grids, and communication infrastructures. Estimate of direct economic impacts of a large scale GS exceeds $40 billion a day in the US. Early prediction is critical in preventing and minimizing the hazards. However, current methods either predict several hours ahead but fail to identify all types of GS, or make predictions within short time, e.g., one hour ahead of the occurrence. This work aims to predict all types of geomagnetic storms reliably and as early as possible using big data and machine learning algorithms. By fusing big data collected from multiple ground stations in the world on different aspects of solar measurements and using Random Forests regression with feature selection and downsampling on minor geomagnetic storm instances (which carry majority of the data), we are able to achieve an accuracy of 82.55% on data collected in 2021 when making early predictions three hours in advance. Given that important predictive features such as historic Kp indices are measured every 3 hours and their importance decay quickly with the amount of time in advance, an early prediction of 3 hours ahead of time is believed to be close to the practical limit.",
        "comments": "14 pages, 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10290"
    },
    {
        "doc_id": 151,
        "title": "How industrial clusters influence the growth of the regional GDP: A spatial-approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Steffen Loeber"
        ],
        "subjects": [
            "General Economics",
            "Econometrics"
        ],
        "abstract": "In this paper, we employ spatial econometric methods to analyze panel data from German NUTS 3 regions. Our goal is to gain a deeper understanding of the significance and interdependence of industry clusters in shaping the dynamics of GDP. To achieve a more nuanced spatial differentiation, we introduce indicator matrices for each industry sector which allows for extending the spatial Durbin model to a new version of it. This approach is essential due to both the economic importance of these sectors and the potential issue of omitted variables. Failing to account for industry sectors can lead to omitted variable bias and estimation problems. To assess the effects of the major industry sectors, we incorporate eight distinct branches of industry into our analysis. According to prevailing economic theory, these clusters should have a positive impact on the regions they are associated with. Our findings indeed reveal highly significant impacts, which can be either positive or negative, of specific sectors on local GDP growth. Spatially, we observe that direct and indirect effects can exhibit opposite signs, indicative of heightened competitiveness within and between industry sectors. Therefore, we recommend that industry sectors should be taken into consideration when conducting spatial analysis of GDP. Doing so allows for a more comprehensive understanding of the economic dynamics at play.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10261"
    },
    {
        "doc_id": 152,
        "title": "Nowcasting Madagascar's real GDP using machine learning algorithms",
        "authors": [
            "Franck Ramaharo",
            "Gerzhino Rasolofomanana"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "We investigate the predictive power of different machine learning algorithms to nowcast Madagascar's gross domestic product (GDP). We trained popular regression models, including linear regularized regression (Ridge, Lasso, Elastic-net), dimensionality reduction model (principal component regression), k-nearest neighbors algorithm (k-NN regression), support vector regression (linear SVR), and tree-based ensemble models (Random forest and XGBoost regressions), on 10 Malagasy quarterly macroeconomic leading indicators over the period 2007Q1--2022Q4, and we used simple econometric models as a benchmark. We measured the nowcast accuracy of each model by calculating the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by aggregating individual predictions, consistently outperforms traditional econometric models. We conclude that machine learning models can deliver more accurate and timely nowcasts of Malagasy economic performance and provide policymakers with additional guidance for data-driven decision making.",
        "comments": "13 pages, 6 figures, 5 tables",
        "date": "24 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10255"
    },
    {
        "doc_id": 153,
        "title": "Equilibrium Multiplicity: A Systematic Approach using Homotopies, with an Application to Chicago",
        "authors": [
            "Amine C-L. Ouazad"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Discrete choice models with social interactions or spillovers may exhibit multiple equilibria. This paper provides a systematic approach to enumerating them for a quantitative spatial model with discrete locations, social interactions, and elastic housing supply. The approach relies on two homotopies. A homotopy is a smooth function that transforms the solutions of a simpler city where solutions are known, to a city with heterogeneous locations and finite supply elasticity. The first homotopy is that, in the set of cities with perfectly elastic floor surface supply, an economy with heterogeneous locations is homotopic to an economy with homogeneous locations, whose solutions can be comprehensively enumerated. Such an economy is epsilon close to an economy whose equilibria are the zeros of a system of polynomials. This is a well-studied area of mathematics where the enumeration of equilibria can be guaranteed. The second homotopy is that a city with perfectly elastic housing supply is homotopic to a city with an arbitrary supply elasticity. In a small number of cases, the path may bifurcate and a single path yields two or more equilibria. By running the method on thousands of cities, we obtain a large number of equilibria. Each equilibrium has different population distributions. We provide a method that is computationally feasible for economies with a large number of locations choices, with an empirical application to the City of Chicago. There exist multiple ``counterfactual Chicagos'' consistent with the estimated parameters. Population distribution, prices, and welfare are not uniquely pinned down by amenities. The paper's method can be applied to models in trade and IO. Further applications of algebraic geometry are suggested.",
        "comments": "MSC Class:          91; 90; 65                          ACM Class:          G.3; J.4; I.6",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10181"
    },
    {
        "doc_id": 154,
        "title": "Nowcasting economic activity in European regions using a mixed-frequency dynamic factor model",
        "authors": [
            "Luca Barbaglia",
            "Lorenzo Frattarolo",
            "Niko Hauzenberger",
            "Dominik Hirschbuehl",
            "Florian Huber",
            "Luca Onorante",
            "Michael Pfarrhofer",
            "Luca Tiozzo Pezzoli"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Timely information about the state of regional economies can be essential for planning, implementing and evaluating locally targeted economic policies. However, European regional accounts for output are published at an annual frequency and with a two-year delay. To obtain robust and more timely measures in a computationally efficient manner, we propose a mixed-frequency dynamic factor model that accounts for national information to produce high-frequency estimates of the regional gross value added (GVA). We show that our model produces reliable nowcasts of GVA in 162 regions across 12 European countries.",
        "comments": "JEL: C22, C53, R11; keywords: factor models, mixed-frequency, nowcasting, regional data",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10054"
    },
    {
        "doc_id": 155,
        "title": "A Quantile Nelson-Siegel model",
        "authors": [
            "Matteo Iacopini",
            "Aubrey Poon",
            "Luca Rossini",
            "Dan Zhu"
        ],
        "subjects": [
            "Applications",
            "Econometrics"
        ],
        "abstract": "A widespread approach to modelling the interaction between macroeconomic variables and the yield curve relies on three latent factors usually interpreted as the level, slope, and curvature (Diebold et al., 2006). This approach is inherently focused on the conditional mean of the yields and postulates a dynamic linear model where the latent factors smoothly change over time. However, periods of deep crisis, such as the Great Recession and the recent pandemic, have highlighted the importance of statistical models that account for asymmetric shocks and are able to forecast the tails of a variable's distribution. A new version of the dynamic three-factor model is proposed to address this issue based on quantile regressions. The novel approach leverages the potential of quantile regression to model the entire (conditional) distribution of the yields instead of restricting to its mean. An application to US data from the 1970s shows the significant heterogeneity of the interactions between financial and macroeconomic variables across different quantiles. Moreover, an out-of-sample forecasting exercise showcases the proposed method's advantages in predicting the yield distribution tails compared to the standard conditional mean model. Finally, by inspecting the posterior distribution of the three factors during the recent major crises, new evidence is found that supports the greater and longer-lasting negative impact of the great recession on the yields compared to the COVID-19 pandemic.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09874"
    },
    {
        "doc_id": 156,
        "title": "Wealth dynamics in a multi-aggregate closed monetary system",
        "authors": [
            "Andrea Monaco",
            "Matteo Ghio",
            "Adamaria Perrotta"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We examine the statistical properties of a closed monetary economy with multi-aggregates interactions. Building upon Yakovenko's single-agent monetary model (Dragulescu and Yakovenko, 2000), we investigate the joint equilibrium distribution of aggregate size and wealth. By comparing theoretical and simulated data, we validate our findings and investigate the influence of both micro dynamics and macro characteristics of the system on the distribution. Additionally, we analyze the system's convergence towards equilibrium under various conditions. Our laboratory model may offer valuable insights into macroeconomic phenomena allowing to reproduce typical wealth distribution features observed in real economy.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09871"
    },
    {
        "doc_id": 157,
        "title": "Game-theoretic Model Predictive Control for Modelling Competitive Supply Chains",
        "authors": [
            "Sophie Hall",
            "Laura Guerrini",
            "Florian D\u00f6rfler",
            "Dominic Liao-McPherson"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Supply chains transform raw materials into finished goods and distribute them to end consumers. The vast majority of products we use daily are supplied to us through complex global supply chains. This paper proposes a modelling methodology for dynamic competitive supply chains based on game theory and model predictive control. We model each manufacturer in the supply chain as a rational utility maximizing agent that selects their actions by finding an open-loop generalized Nash equilibrium of a multi-stage game. To react to competitors and the state of the market, every agent re-plans their actions in a receding horizon manner based on estimates of market and supplier parameters thereby creating an approximate closed-loop equilibrium policy. We demonstrate through numerical simulations that this modelling approach is computationally tractable and generates economically interpretable behaviors in a variety of settings such as demand spikes, supply shocks, and information asymmetry.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09853"
    },
    {
        "doc_id": 158,
        "title": "Game Representations and Extensions of the Shapley Value",
        "authors": [
            "Pradeep Dubey"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We show that any cooperative game can be represented by an assignment of costly facilities to players, in which it is intuitively obvious how to allocate the total cost in an equitable manner. This equitable solution turns out to be the Shapley value of the game, and thus provides as an alternative justification of the value. Game representations also open the door for extending the Shapley value to situations where not all coalitions can form, provided those that can constitute a \"semi-algebra\"; or, more generally, a \"hierarchy\"; or, still more generally, have \"full span\".",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09845"
    },
    {
        "doc_id": 159,
        "title": "A Framework for Digital Currencies for Financial Inclusion in Latin America and the Caribbean",
        "authors": [
            "Gabriel Bizama",
            "Alexander Wu",
            "Bernardo Paniagua",
            "Max Mitre"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This research aims to provide a framework to assess the contribution of digital currencies to promote financial inclusion, based on a diagnosis of the landscape of financial inclusion and domestic and cross-border payments in Latin America and the Caribbean. It also provides insights from central banks in the region on key aspects regarding a possible implementation of central bank digital currencies. Findings show that although digital currencies development is at an early stage, a well-designed system could reduce the cost of domestic and cross-border payments, improve the settlement of transactions to achieve real-time payments, expand the accessibility of central bank money, incorporate programmable payments and achieve system performance demands.",
        "comments": "32 pages, 7 figures, 3 tables and 3 boxes",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09811"
    },
    {
        "doc_id": 160,
        "title": "AI and the Opportunity for Shared Prosperity: Lessons from the History of Technology and the Economy",
        "authors": [
            "Guy Ben-Ishai",
            "Jeff Dean",
            "James Manyika",
            "Ruth Porat",
            "Hal Varian",
            "Kent Walker"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Recent progress in artificial intelligence (AI) marks a pivotal moment in human history. It presents the opportunity for machines to learn, adapt, and perform tasks that have the potential to assist people, from everyday activities to their most creative and ambitious projects. It could also help businesses and organizations harness knowledge, increase productivity, innovate, transform, and power shared prosperity. This tremendous potential raises two fundamental questions: (1) Will AI actually advance national and global economic transformation to benefit society at large? and (2) What issues must we get right to fully realize AI's economic value, expand prosperity and improve lives everywhere? We explore these questions by considering the recent history of technology and innovation as a guide for the likely impact of AI and what we must do to realize its economic potential to benefit society. While we do not presume the future will be entirely like that past, for reasons we will discuss, we do believe prior experience with technological change offers many useful lessons. We conclude that while progress in AI presents a historic opportunity to advance our economic prosperity and future wellbeing, its economic benefits will not come automatically and that AI risks exacerbating existing economic challenges unless we collectively and purposefully act to enable its potential and address its challenges. We suggest a collective policy agenda - involving developers, deployers and users of AI, infrastructure providers, policymakers, and those involved in workforce training - that may help both realize and harness AI's economic potential and address its risks to our shared prosperity.",
        "comments": "Draft withdrawn to obtain feedback",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09811"
    },
    {
        "doc_id": 161,
        "title": "Empowering Africa: An In-depth Exploration of the Adoption of Artificial Intelligence Across the Continent",
        "authors": [
            "Kinyua Gikunda"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "This paper explores the dynamic landscape of Artificial Intelligence (AI) adoption in Africa, analysing its varied applications in addressing socio-economic challenges and fostering development. Examining the African AI ecosystem, the study considers regional nuances, cultural factors, and infrastructural constraints shaping the deployment of AI solutions. Case studies in healthcare, agriculture, finance, and education highlight AI's transformative potential for efficiency, accessibility, and inclusivity. The paper emphasizes indigenous AI innovations and international collaborations contributing to a distinct African AI ecosystem. Ethical considerations, including data privacy and algorithmic bias, are addressed alongside policy frameworks supporting responsible AI implementation. The role of governmental bodies, regulations, and private sector partnerships is explored in creating a conducive AI development environment. Challenges such as digital literacy gaps and job displacement are discussed, with proposed strategies for mitigation. In conclusion, the paper provides a nuanced understanding of AI in Africa, contributing to sustainable development discussions and advocating for an inclusive and ethical AI ecosystem on the continent.",
        "comments": " ",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09457"
    },
    {
        "doc_id": 162,
        "title": "Equity Premium in Efficient Markets",
        "authors": [
            "B. N. Kausik"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Equity premium, the surplus returns of stocks over bonds, has been an enduring puzzle. While numerous prior works approach the problem assuming the utility of money is invariant across contexts, our approach implies that in efficient markets the utility of money is polymorphic, with risk aversion dependent on the information available in each context, i.e. the discount on each future cash flow depends on all information available on that cash flow. Specifically, we prove that in efficient markets, informed investors maximize return on volatility by being risk-neutral with riskless bonds, and risk-averse with equities, thereby resolving the puzzle. We validate our results on historical data with surprising consistency.\n  JEL Classification: C58, G00, G12, G17",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09265"
    },
    {
        "doc_id": 163,
        "title": "Airline delays, congestion internalization and non-price spillover effects of low cost carrier entry",
        "authors": [
            "William E. Bendinelli",
            "Humberto F. A. J. Bettini",
            "Alessandro V. M. Oliveira"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper develops an econometric model of flight delays to investigate the influence of competition and dominance on the incentives of carriers to maintain on-time performance. We consider both the route and the airport levels to inspect the local and global effects of competition, with a unifying framework to test the hypotheses of 1. airport congestion internalization and 2. the market competition-quality relationship in a single econometric model. In particular, we examine the impacts of the entry of low cost carriers (LCC) on the flight delays of incumbent full service carriers in the Brazilian airline industry. The main results indicate a highly significant effect of airport congestion self-internalization in parallel with route-level quality competition. Additionally, the potential competition caused by LCC presence provokes a global effect that suggests the existence of non-price spillovers of the LCC entry to non-entered routes.",
        "comments": "Journal ref:        Transportation Research Part A: Policy and Practice, 85, 39-52 (2016)",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09174"
    },
    {
        "doc_id": 164,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 165,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 166,
        "title": "Strategic formation of production networks",
        "authors": [
            "Antoine Mandel",
            "Van-Quy Nguyen",
            "Bach Dong-Xuan"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We provide a strategic model of the formation of production networks that subsumes the standard general equilibrium approach. The objective of firms in our setting is to choose their supply relationships so as to maximize their profit at the general equilibrium that unfolds. We show that this objective is equivalent to the maximization by the firms of their eigenvector centrality in the production network. As is common in network formation games based on centrality, there are multiple Nash equilibria in our setting. We have investigated the characteristics and the social efficiency of these equilibria in a stylized version of our model representing international trade networks. We show that the impact of network structure on social welfare is firstly determined by a trade-off between costs of increasing process complexity and positive spillovers on productivity induced by the diversification of the input mix. We further analyze a variant of our model that accounts for the risks of disruption of supply relationships. In this setting, we characterize how social welfare depends on the structure of the production network, the spatial distribution of risks, and the process of shock aggregation in supply chains. We finally show that simple trade policies characterized by sets of links that are either prevented or catalyzed can be a powerful equilibrium selection device.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08929"
    },
    {
        "doc_id": 167,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 168,
        "title": "MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data",
        "authors": [
            "Zhengke Sun",
            "Yuliang Ma"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "The problem of traffic congestion not only causes a large amount of economic losses, but also seriously endangers the urban environment. Predicting traffic congestion has important practical significance. So far, most studies have been based on historical data from sensors placed on different roads to predict future traffic flow and speed, to analyze the traffic congestion conditions of a certain road segment. However, due to the fixed position of sensors, it is difficult to mine new information. On the other hand, vehicle trajectory data is more flexible and can extract traffic information as needed. Therefore, we proposed a new traffic congestion prediction model - Multi Adjacency relationship Attention Graph Convolutional Networks(MA2GCN). This model transformed vehicle trajectory data into graph structured data in grid form, and proposed a vehicle entry and exit matrix based on the mobility between different grids. At the same time, in order to improve the performance of the model, this paper also built a new adaptive adjacency matrix generation method and adjacency matrix attention module. This model mainly used gated temporal convolution and graph convolution to extract temporal and spatial information, respectively. Compared with multiple baselines, our model achieved the best performance on Shanghai taxi GPS trajectory dataset. The code is available at https://github.com/zachysun/Taxi_Traffic_Benchmark.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08727"
    },
    {
        "doc_id": 169,
        "title": "Automated Design Appraisal: Estimating Real Estate Price Growth and Value at Risk due to Local Development",
        "authors": [
            "Adam R. Swietek"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial criteria in architectural design evaluation are limited to cost performance. Here, I introduce a method, Automated Design Appraisal (ADA), to predict the market price of a generated building design concept within a local urban context. Integrating ADA with 3D building performance simulations enables financial impact assessment that exceeds the spatial resolution of previous work. Within an integrated impact assessment, ADA measures the direct and localized effect of urban development. To demonstrate its practical utility, I study local devaluation risk due to nearby development associated with changes to visual landscape quality. The results shed light on the relationship between amenities and property value, identifying clusters of properties physically exposed or financially sensitive to local land-use change. Beyond its application as a financial sensitivity tool, ADA serves as a blueprint for architectural design optimization procedures, in which economic performance is evaluated based on learned preferences derived from financial market data.",
        "comments": "18 pages, 7 figures",
        "date": "17 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08645"
    },
    {
        "doc_id": 170,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 171,
        "title": "Non-Banking Sector development effect on Economic Growth. A Nighttime light data approach",
        "authors": [
            "Leonard Mushunje",
            "Maxwell Mashasha"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper uses nighttime light(NTL) data to measure the nexus of the non-banking sector, particularly insurance, and economic growth in South Africa. We hypothesize that insurance sector growth positively propels economic growth due to its economic growth-supportive traits like investment protection and optimal risk mitigation. We also claim that Nighttime light data is a good economic measure than Gross domestic product (GDP). We used weighted regressions to measure the relationships between nighttime light data, GDP, and insurance sector development. We used time series South African GDP data collected from the World Bank for the period running from 2000 to 2018, and the nighttime lights data from the National Geophysical Data Centre (NGDC) in partnership with the National Oceanic and Atmospheric Administration (NOAA). From the models fitted and the reported BIC, AIC, and likelihood ratios, the insurance sector proved to have more predictive power on economic development in South Africa, and radiance light explained economic growth better than GDP and GDP/Capita. We concluded that nighttime data is a good proxy for economic growth than GDP/Capita in emerging economies like South Africa, where secondary data needs to be more robust and sometimes inflated. The findings will guide researchers and policymakers on what drives economic development and what policies to put in place. It would be interesting to extend the current study to other sectors such as micro-finances, mutual and hedge funds.",
        "comments": "28 pages",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08596"
    },
    {
        "doc_id": 172,
        "title": "How do we measure trade elasticity for services?",
        "authors": [
            "Satoshi Nakano",
            "Kazuhiko Nishimura"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper is about our attempt of identifying trade elasticities through the variations in the exchange rate, for possible applications to the case of services whose physical transactions are veiled in the trade statistics. The regression analysis to estimate the elasticity entails a situation where the explanatory variable is leaked into the error term through the latent supply equation, causing an endogeneity problem for which an instrumental variable cannot be found. Our identification strategy is to utilize the normalizing condition, which enables the supply parameter to be identified, along with the reduced-form equation of the system of demand and supply equations. We evaluate the performances of the method proposed by applying to several different tangible goods, whose benchmark trade elasticities are estimable by utilizing the information on their physical transactions.",
        "comments": " ",
        "date": "18 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08594"
    },
    {
        "doc_id": 173,
        "title": "Incremento del precio de los combustibles y su incidencia en los productos de la canasta basica del canton el triunfo, provincia del guayas",
        "authors": [
            "Alvear Guzman Katherine",
            "Campozano Buele Jenner",
            "Duran Canarte Paulette",
            "Holguin Cedeno Roger",
            "Mejia Crespin Fernando"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The objective of this research was to analyze the impact of the increase in the price of fuels and its incidence on the products of the basic basket of the El Triunfo, the province of Guayas. In the present study, the non-experimental quantitative method was used. The study population was limited to the families of the town, seeking to determine how their level of consumption was impacted after the increase in fuels. Just 95 people were randomly taken. The study instrument that was used was surveys, with a focus on the purchasing power of families with respect to the basic basket after the increase in fuel prices. The results were processed through Cronbach's Alpha and reflected in pie charts. The independent and dependent variable that make up our study, were related through a simple linear regression, to determine if they correlate with each other.\n  Keywords: Fuels, Basic basket, Linear regression, Subsidies, Inflation",
        "comments": "in Spanish language",
        "date": "13 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08590"
    },
    {
        "doc_id": 174,
        "title": "Incentivizing Secure Software Development: The Role of Liability (Waiver) and Audit",
        "authors": [
            "Ziyuan Huang",
            "Gergely Bicz\u00f3k",
            "Mingyan Liu"
        ],
        "subjects": [
            "Cryptography and Security",
            "Systems and Control"
        ],
        "abstract": "Misaligned incentives in secure software development have long been the focus of research in the economics of security. Product liability, a powerful legal framework in other industries, has been largely ineffective for software products until recent times. However, the rapid regulatory responses to recent global cyberattacks by both the United States and the European Union, together with the (relative) success of the General Data Protection Regulation in defining both duty and standard of care for software vendors, may just enable regulators to use liability to re-align incentives for the benefit of the digital society. Specifically, the recently proposed United States National Cybersecurity Strategy shifts responsibility for cyber incidents back to software vendors. In doing so, the strategy also puts forward the concept of the liability waiver: if a software company voluntarily undergoes and passes an IT security audit, its liability is waived.\n  In this paper, we analyze this audit scenario from the aspect of the software vendor. We propose a mechanism where a software vendor should first undergo a repeated auditing process in each stage of which the vendor decides whether to quit early or stay with additional security investment. We show that the optimal strategy for an opt-in vendor is to never quit; and exert cumulative investments in either \"one-and-done\" or \"incremental\" manner. We relate the audit mechanism to a liability waiver insurance policy and revealed its effect on reshaping the vendor's risk perception. We also discuss influence of audit quality on the vendor's incentives and pinpoint that a desirable audit rule should be highly accurate and less strict.",
        "comments": "21 pages, 6 figures, submitted to the 23rd Workshop on the Economics of Information Security",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08476"
    },
    {
        "doc_id": 175,
        "title": "Assessing the impact of forced and voluntary behavioral changes on economic-epidemiological co-dynamics: A comparative case study between Belgium and Sweden during the 2020 COVID-19 pandemic",
        "authors": [
            "Tijs W. Alleman",
            "Jan M. Baetens"
        ],
        "subjects": [
            "Econometrics",
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "During the COVID-19 pandemic, governments faced the challenge of managing population behavior to prevent their healthcare systems from collapsing. Sweden adopted a strategy centered on voluntary sanitary recommendations while Belgium resorted to mandatory measures. Their consequences on pandemic progression and associated economic impacts remain insufficiently understood. This study leverages the divergent policies of Belgium and Sweden during the COVID-19 pandemic to relax the unrealistic -- but persistently used -- assumption that social contacts are not influenced by an epidemic's dynamics. We develop an epidemiological-economic co-simulation model where pandemic-induced behavioral changes are a superposition of voluntary actions driven by fear, prosocial behavior or social pressure, and compulsory compliance with government directives. Our findings emphasize the importance of early responses, which reduce the stringency of measures necessary to safeguard healthcare systems and minimize ensuing economic damage. Voluntary behavioral changes lead to a pattern of recurring epidemics, which should be regarded as the natural long-term course of pandemics. Governments should carefully consider prolonging lockdown longer than necessary because this leads to higher economic damage and a potentially higher second surge when measures are released. Our model can aid policymakers in the selection of an appropriate long-term strategy that minimizes economic damage.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08442"
    },
    {
        "doc_id": 176,
        "title": "Causal Machine Learning for Moderation Effects",
        "authors": [
            "Nora Bearth",
            "Michael Lechner"
        ],
        "subjects": [
            "Econometrics",
            "Machine Learning"
        ],
        "abstract": "It is valuable for any decision maker to know the impact of decisions (treatments) on average and for subgroups. The causal machine learning literature has recently provided tools for estimating group average treatment effects (GATE) to understand treatment heterogeneity better. This paper addresses the challenge of interpreting such differences in treatment effects between groups while accounting for variations in other covariates. We propose a new parameter, the balanced group average treatment effect (BGATE), which measures a GATE with a specific distribution of a priori-determined covariates. By taking the difference of two BGATEs, we can analyse heterogeneity more meaningfully than by comparing two GATEs. The estimation strategy for this parameter is based on double/debiased machine learning for discrete treatments in an unconfoundedness setting, and the estimator is shown to be $\\sqrt{N}$-consistent and asymptotically normal under standard conditions. Adding additional identifying assumptions allows specific balanced differences in treatment effects between groups to be interpreted causally, leading to the causal balanced group average treatment effect. We explore the finite sample properties in a small-scale simulation study and demonstrate the usefulness of these parameters in an empirical example.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08290"
    },
    {
        "doc_id": 177,
        "title": "A techno-economic model for avoiding conflicts of interest between owners of offshore wind farms and maintenance suppliers",
        "authors": [
            "Alberto Pliego Marug\u00e1n",
            "Fausto Pedro Garc\u00eda M\u00e1rquez",
            "Jes\u00fas Mar\u00eda Pinar P\u00e9rez"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "General Economics",
            "Systems and Control"
        ],
        "abstract": "Currently, wind energy is one of the most important sources of renewable energy. Offshore locations for wind turbines are increasingly exploited because of their numerous advantages. However, offshore wind farms require high investment in maintenance service. Due to its complexity and special requirements, maintenance service is usually outsourced by wind farm owners. In this paper, we propose a novel approach to determine, quantify, and reduce the possible conflicts of interest between owners and maintenance suppliers. We created a complete techno-economic model to address this problem from an impartial point of view. An iterative process was developed to obtain statistical results that can help stakeholders negotiate the terms of the contract, in which the availability of the wind farm is the reference parameter by which to determine penalisations and incentives. Moreover, a multi-objective programming problem was addressed that maximises the profits of both parties without losing the alignment of their interests. The main scientific contribution of this paper is the maintenance analysis of offshore wind farms from two perspectives: that of the owner and the maintenance supplier. This analysis evaluates the conflicts of interest of both parties. In addition, we demonstrate that proper adjustment of some parameters, such as penalisation, incentives, and resources, and adequate control of availability can help reduce this conflict of interests.",
        "comments": "Published in Renewable and Sustainable Energy Reviews (ELSEVIER) 10 July 2022. DOI: https://doi.org/10.1016/j.rser.2022.112753 Cite as: Marug\u00e1n, A. P., M\u00e1rquez, F. P. G., & P\u00e9rez, J. M. P. (2022). A techno-economic model for avoiding conflicts of interest between owners of offshore wind farms and maintenance suppliers. Renewable and Sustainable Energy Reviews, 168, 112753",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08251"
    },
    {
        "doc_id": 178,
        "title": "A Large-Scale Epidemic Simulation Framework for Realistic Social Contact Networks",
        "authors": [
            "Joy Kitson",
            "Ian Costello",
            "Jiangzhuo Chen",
            "Diego Jim\u00e9nez",
            "Stefan Hoops",
            "Henning Mortveit",
            "Esteban Meneses",
            "Jae-Seung Yeom",
            "Madhav V. Marathe",
            "Abhinav Bhatele"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Global pandemics can wreak havoc and lead to significant social, economic, and personal losses. Preventing the spread of infectious diseases requires implementing interventions at different levels of government, and evaluating the potential impact and efficacy of those preemptive measures. Agent-based modeling can be used for detailed studies of epidemic diffusion and possible interventions. We present Loimos, a highly parallel simulation of epidemic diffusion written on top of Charm++, an asynchronous task-based parallel runtime. Loimos uses a hybrid of time-stepping and discrete-event simulation to model disease spread. We demonstrate that our implementation of Loimos is able to scale to large core counts on an HPC system. In particular, Loimos is able to simulate a US-scale synthetic interaction network in an average of 1.497 seconds per simulation day when executed on 16 nodes on Rivanna at the University of Virginia, processing around 428 billion interactions (person-person edges) in under five minutes for an average of 1.4 billion traversed edges per second (TEPS).",
        "comments": "13 pages (including references), 9 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08124"
    },
    {
        "doc_id": 179,
        "title": "Automated lag-selection for multi-step univariate time series forecast using Bayesian Optimization: Forecast station-wise monthly rainfall of nine divisional cities of Bangladesh",
        "authors": [
            "Rezoanoor Rahman",
            "Fariha Taskin"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Rainfall is an essential hydrological component, and most of the economic activities of an agrarian country like Bangladesh depend on rainfall. An accurate rainfall forecast can help make necessary decisions and reduce the damages caused by heavy or low to no rainfall. The monthly average rainfall is a time series data, and recently, long short-term memory (LSTM) neural networks are being used heavily for time series forecasting problems. One major challenge of forecasting using LSTMs is to select the appropriate number of lag values. In this research, we considered the number of lag values selected as a hyperparameter of LSTM; it, with the other hyperparameters determining LSTMs structure, has been optimized using Bayesian optimization. We used our proposed method to forecast rainfall for nine different weather stations of Bangladesh. Finally, the performance of the proposed model has been compared with some other LSTM with different lag-selection methods and some several popular machine learning and statistical forecasting models.",
        "comments": "19 pages in total",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08070"
    },
    {
        "doc_id": 180,
        "title": "A new model of trust based on neural information processing",
        "authors": [
            "Scott E. Allen",
            "Ren\u00e9 F. Kizilcec",
            "A. David Redish"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction",
            "Neurons and Cognition"
        ],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08064"
    },
    {
        "doc_id": 181,
        "title": "A Day-to-Day Dynamical Approach to the Most Likely User Equilibrium Problem",
        "authors": [
            "Jiayang Li",
            "Qianni Wang",
            "Liyang Feng",
            "Jun Xie",
            "Yu Marco Nie"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Multiagent Systems",
            "General Economics"
        ],
        "abstract": "The lack of a unique user equilibrium (UE) route flow in traffic assignment has posed a significant challenge to many transportation applications. The maximum-entropy principle, which advocates for the consistent selection of the most likely solution as a representative, is often used to address the challenge. Built on a recently proposed day-to-day (DTD) discrete-time dynamical model called cumulative logit (CULO), this study provides a new behavioral underpinning for the maximum-entropy UE (MEUE) route flow. It has been proven that CULO can reach a UE state without presuming travelers are perfectly rational. Here, we further establish that CULO always converges to the MEUE route flow if (i) travelers have zero prior information about routes and thus are forced to give all routes an equal choice probability, or (ii) all travelers gather information from the same source such that the so-called general proportionality condition is satisfied. Thus, CULO may be used as a practical solution algorithm for the MEUE problem. To put this idea into practice, we propose to eliminate the route enumeration requirement of the original CULO model through an iterative route discovery scheme. We also examine the discrete-time versions of four popular continuous-time dynamical models and compare them to CULO. The analysis shows that the replicator dynamic is the only one that has the potential to reach the MEUE solution with some regularity. The analytical results are confirmed through numerical experiments.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08013"
    },
    {
        "doc_id": 182,
        "title": "Inequality leads to the evolution of intolerance in reputation-based populations",
        "authors": [
            "Luis A. Martinez-Vaquero"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "This work studies the impact of economic inequality on the evolution of intolerance through a reputation-based model of indirect reciprocity. Results show that economic inequality is a powerful enhancer of intolerance, inducing the escalation of out-group discrimination even without the presence of new intolerant mutants. It also generates behavior modifications within tolerant disfavored minorities: their members either relax punishments against the uncooperative or prioritize helping the wealthy, even suffering discrimination in return. On the other hand, the redistribution of wealth is proved as a viable solution to avoid the spread of intolerance as long as it increases equality and is implemented before intolerance permeates part of the population.",
        "comments": "Journal ref:        Chaos 33 (3), 033119 (2023)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07873"
    },
    {
        "doc_id": 183,
        "title": "Evolutionary dynamics of organised crime and terrorist networks",
        "authors": [
            "Luis A. Martinez-Vaquero",
            "Valerio Dolci",
            "Vito Trianni"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "Crime is pervasive into modern societies, although with different levels of diffusion across regions. Its dynamics are dependent on various socio-economic factors that make the overall picture particularly complex. While several theories have been proposed to account for the establishment of criminal behaviour, from a modelling perspective organised crime and terrorist networks received much less attention. In particular, the dynamics of recruitment into such organisations deserve specific considerations, as recruitment is the mechanism that makes crime and terror proliferate. We propose a framework able to model such processes in both organised crime and terrorist networks from an evolutionary game theoretical perspective. By means of a stylised model, we are able to study a variety of different circumstances and factors influencing the growth or decline of criminal organisations and terrorist networks, and observe the convoluted interplay between agents that decide to get associated to illicit groups, criminals that prefer to act on their own, and the rest of the civil society.",
        "comments": "Journal ref:        Sci Rep 9, 9727 (2019)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07869"
    },
    {
        "doc_id": 184,
        "title": "A General Approach for Computing a Consensus in Group Decision Making That Integrates Multiple Ethical Principles",
        "authors": [
            "Francisco Salas-Molina",
            "Filippo Bistaffa",
            "Juan A. Rodriguez-Aguilar"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We tackle the problem of computing a consensus according to multiple ethical principles -- which can include, for example, the principle of maximum freedom associated with the Benthamite doctrine and the principle of maximum fairness associated with the Rawlsian principles -- among the preferences of different individuals in the context of Group-Decision-Making. More formally, we put forward a novel formalisation of the above-mentioned problem based on a multinorm approximation problem that aims at minimising multiple p-metric distance functions, where each parameter p represents a given ethical principle. Our contribution incurs obvious benefits from a social-choice perspective. Firstly, our approach significantly generalises state-of-the-art approaches that were limited to only two ethical principles (p set to one, for maximum freedom, and p set to infinity, for maximum fairness). Secondly, our experimental results considering an established test case demonstrate that our approach is capable, thanks to a novel re-weighting scheme, to compute a multi-norm consensus that takes into account each ethical principle in a balanced way, in contrast with state-of-the-art approaches that were heavily biased towards the p=1 ethical principle",
        "comments": "20 pages, 1 table, 1 figure",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07818"
    },
    {
        "doc_id": 185,
        "title": "Improving OCR Quality in 19th Century Historical Documents Using a Combined Machine Learning Based Approach",
        "authors": [
            "David Fleischhacker",
            "Wolfgang Goederle",
            "Roman Kern"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "This paper addresses a major challenge to historical research on the 19th century. Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind. Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus. It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries. Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible. We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible. We chose Faster R-CNN as base for the ML architecture for structure recognition. In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model. The model was then fine-tuned with a smaller set of manually annotated historical source data. We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process. Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better). Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).",
        "comments": "29 pages, 23 figures, 7 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07787"
    },
    {
        "doc_id": 186,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 187,
        "title": "Impermanent Loss Conditions: An Analysis of Decentralized Exchange Platforms",
        "authors": [
            "Matthias Hafner",
            "Helmut Dietl"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Decentralized exchanges are widely used platforms for trading crypto assets. The most common types work with automated market makers (AMM), allowing traders to exchange assets without needing to find matching counterparties. Thereby, traders exchange against asset reserves managed by smart contracts. These assets are provided by liquidity providers in exchange for a fee. Static analysis shows that small price changes in one of the assets can result in losses for liquidity providers. Despite the success of AMMs, it is claimed that liquidity providers often suffer losses. However, the literature does not adequately consider the dynamic effects of fees over time. Therefore, we investigate the impermanent loss problem in a dynamic setting using Monte Carlo simulations. Our findings indicate that price changes do not necessarily lead to losses. Fees paid by traders and arbitrageurs are equally important. In this respect, we can show that an arbitrage-friendly environment benefits the liquidity provider. Thus, we suggest that AMM developers should promote an arbitrage-friendly environment rather than trying to prevent arbitrage.",
        "comments": "This paper was presented at the CfC 2024 Academic Track Conference",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07689"
    },
    {
        "doc_id": 188,
        "title": "Spatial clusters for demand and supply of childcare services in Italy",
        "authors": [
            "Andreella Angela",
            "Aliverti Emanuele",
            "Caldura Federico",
            "Campostrini Stefano"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "The availability of affordable and high-quality childcare services has become a significant concern in recent years. Such services can facilitate the balance between work and family life, increasing participation in the workforce and promoting gender equality. Furthermore, childcare can also help address the issue of decreasing fertility rates by making it more affordable for parents to have children while maintaining their careers. This is critical, especially for countries that are facing ultralow fertility rates like Italy. The Italian government has included within the recovery and resilience plan financed with Next Generations EU funds an unprecedented investment in order to increase the supply of children's education services and make it more equitably distributed across the country. In this article, we estimate groups of spatial areas with similar structures in terms of coverage (availability of childcare services at the municipality level), public expenditure rates in childcare, as well as other socio-demographic and economic factors, such as female employment, education, and grandparent rates. Our empirical findings confirm how Italy is characterized by a large number of \"sub-regional models\" and how some of these clusters are shared across multiple regions. We provide a preliminary attempt to explain how such patterns are driven by socio-demographic factors and argue that these very different conditions necessitate specific policy decisions. The work highlights the need for regional governance of the children's educational system.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07600"
    },
    {
        "doc_id": 189,
        "title": "Existence of MMS Allocations with Mixed Manna",
        "authors": [
            "Kevin Hsu"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "Maximin share (MMS) allocations are a popular relaxation of envy-free allocations that have received wide attention in the context of the fair division of indivisible items. Although MMS allocations can fail to exist [1], previous work has found conditions under which they exist. Specifically, MMS allocations exist whenever $m \\leq n+5$ in the context of goods allocation, and this bound is tight in the sense that MMS allocations can fail to exist when $m = n+6$ [2]. Unfortunately, the technique used to establish this result does not generalize readily to the chores and mixed manna settings. This paper generalizes this result to the chores setting and provides a partial solution for the mixed manna setting. Our results depend on the presence of certain types of agents. Specifically, an agent $i$ is a goods agent (resp. chores agent) if every item is a good (resp. chore) to $i$, and a non-negative mixed agent if $i$ is neither a goods nor a chores agent and the MMS guarantee of $i$ is non-negative. In this paper, we prove that an MMS allocation exists if $m \\leq n+5$ and there exists a goods agent, a non-negative mixed agent, or only chores agents.\n  [1] David Kurokawa, Ariel D Procaccia, and Junxing Wang. When can the maximin share guarantee be guaranteed? In Thirtieth AAAI Conference on Artificial Intelligence, 2016.\n  [2] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for mms fair allocations. In International Conference on Web and Internet Economics, pages 355-372. Springer, 2021.",
        "comments": "11 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07490"
    },
    {
        "doc_id": 190,
        "title": "Unemployment Volatility: When Workers Pay Costs upon Accepting Jobs",
        "authors": [
            "Rich Ryan"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "When a firm hires a worker, adding the new hire to payroll is costly. These costs reduce the amount of resources that can go to recruiting workers and amplify how unemployment responds to changes in productivity. Workers also incur up-front costs upon accepting jobs. Examples include moving expenses and regulatory fees. I establish that workers' costs lessen the response of unemployment to productivity changes and do not subtract from resources available for recruitment. The influence of workers' costs is bounded by properties of a matching function, which describes how job openings and unemployment produce hires. Using data on job finding that are adjusted for workers' transitions between employment and unemployment and for how the Job Openings and Labor Turnover Survey records hires, I estimate a bound that ascribes limited influence to workers' costs. The results demonstrate that costs paid by workers upon accepting jobs affect outcomes in the labor market (firms threaten workers with paying the up-front costs again if wage negotiations fail), but their influence on volatility is less important than firms' costs.",
        "comments": "31 pages, 3 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07423"
    },
    {
        "doc_id": 191,
        "title": "A Comparative Examination of Network and Contract-Based Blockchain Storage Solutions for Decentralized Applications",
        "authors": [
            "Lipeng He"
        ],
        "subjects": [
            "Networking and Internet Architecture"
        ],
        "abstract": "Decentralized applications (DApps), which are innovative blockchain-powered software systems designed to serve as the fundamental building blocks for the next generation of Internet services, have witnessed exponential growth in recent years. This paper thoroughly compares and analyzes two blockchain-based decentralized storage networks (DSNs), which are crucial foundations for DApp and blockchain ecosystems. The study examines their respective mechanisms for data persistence, strategies for enforcing data retention, and token economics. In addition to delving into technical details, the suitability of each storage solution for decentralized application development is assessed, taking into consideration network performance, storage costs, and existing use cases. By evaluating these factors, the paper aims to provide insights into the effectiveness of these technologies in supporting the desirable properties of truly decentralized blockchain applications. In conclusion, the findings of this research are discussed and synthesized, offering valuable perspectives on the capabilities of these technologies. It sheds light on their potential to facilitate the development of DApps and provides an understanding of the ongoing trends in blockchain development.",
        "comments": "13 pages, 1 figure, published in Proceedings of the 3rd International Conference on Digital Economy and Computer Application (DECA 2023)",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07417"
    },
    {
        "doc_id": 192,
        "title": "Learning to be Homo Economicus: Can an LLM Learn Preferences from Choice",
        "authors": [
            "Jeongbin Kim",
            "Matthew Kovach",
            "Kyu-Min Lee",
            "Euncheol Shin",
            "Hector Tzavellas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper explores the use of Large Language Models (LLMs) as decision aids, with a focus on their ability to learn preferences and provide personalized recommendations. To establish a baseline, we replicate standard economic experiments on choice under risk (Choi et al., 2007) with GPT, one of the most prominent LLMs, prompted to respond as (i) a human decision maker or (ii) a recommendation system for customers. With these baselines established, GPT is provided with a sample set of choices and prompted to make recommendations based on the provided data. From the data generated by GPT, we identify its (revealed) preferences and explore its ability to learn from data. Our analysis yields three results. First, GPT's choices are consistent with (expected) utility maximization theory. Second, GPT can align its recommendations with people's risk aversion, by recommending less risky portfolios to more risk-averse decision makers, highlighting GPT's potential as a personalized decision aid. Third, however, GPT demonstrates limited alignment when it comes to disappointment aversion.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07345"
    },
    {
        "doc_id": 193,
        "title": "Individual and Collective Welfare in Risk Sharing with Many States",
        "authors": [
            "Federico Echenique",
            "Farzad Pourbabaee"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory"
        ],
        "abstract": "We provide a quantitative assessment of welfare in the classical model of risk-sharing and exchange under uncertainty. We prove three kinds of results. First, that in an equilibrium allocation, the scope for improving individual welfare by a given margin (an $\\ve$-improvement) vanishes as the number of states increases. Second, that the scope for a change in aggregate resources that may be distributed to enhance individual welfare by a given margin also vanishes. Equivalently: in an inefficient allocation, for a given level of resource sub-optimality (as measured by the coefficient of resource under-utilization), the possibilities for enhancing welfare by perturbing aggregate resources decrease exponentially to zero with the number of states. Finally, we consider efficient risk-sharing in standard models of uncertainty aversion with multiple priors, and show that, in an inefficient allocation, certain sets of priors shrink with the size of the state space.",
        "comments": "MSC Class:          91B50                          ACM Class:          J.4",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07337"
    },
    {
        "doc_id": 194,
        "title": "Utilitarian Beliefs in Social Networks: Explaining the Emergence of Hatred",
        "authors": [
            "Houda Nait El Barj",
            "Theophile Sautory"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study the dynamics of opinions in a setting where a leader has a payoff that depends on agents' beliefs and where agents derive psychological utility from their beliefs. Agents sample a signal that maximises their utility and then communicate with each other through a network formed by disjoint social groups. The leader has a choice to target a finite set of social groups with a specific signal to influence their beliefs and maximise his returns. Heterogeneity in agents' preferences allows us to analyse the evolution of opinions as a dynamical system with asymmetric forces. We apply our model to explain the emergence of hatred and the spread of racism in a society. We show that when information is restricted, the equilibrium level of hatred is determined solely by the belief of the most extremist agent in the group regardless of the inherent structure of the network. On the contrary, when information is dense, the space is completely polarised in equilibrium with the presence of multiple \"local truths\" which oscillate in periodic cycles. We find that when preferences are uniformly distributed, the equilibrium level of hatred depends solely on the value of the practical punishment associated with holding a hate belief. Our finding suggests that an optimal policy to reduce hatred should focus on increasing the cost associated with holding a racist belief.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07178"
    },
    {
        "doc_id": 195,
        "title": "A Note on Uncertainty Quantification for Maximum Likelihood Parameters Estimated with Heuristic Based Optimization Algorithms",
        "authors": [
            "Zachary Porreca"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Gradient-based solvers risk convergence to local optima, leading to incorrect researcher inference. Heuristic-based algorithms are able to ``break free\" of these local optima to eventually converge to the true global optimum. However, given that they do not provide the gradient/Hessian needed to approximate the covariance matrix and that the significantly longer computational time they require for convergence likely precludes resampling procedures for inference, researchers often are unable to quantify uncertainty in the estimates they derive with these methods. This note presents a simple and relatively fast two-step procedure to estimate the covariance matrix for parameters estimated with these algorithms. This procedure relies on automatic differentiation, a computational means of calculating derivatives that is popular in machine learning applications. A brief empirical example demonstrates the advantages of this procedure relative to bootstrapping and shows the similarity in standard error estimates between this procedure and that which would normally accompany maximum likelihood estimation with a gradient-based algorithm.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07176"
    },
    {
        "doc_id": 196,
        "title": "Inference for Synthetic Controls via Refined Placebo Tests",
        "authors": [
            "Lihua Lei",
            "Timothy Sudijono"
        ],
        "subjects": [
            "Methodology",
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The synthetic control method is often applied to problems with one treated unit and a small number of control units. A common inferential task in this setting is to test null hypotheses regarding the average treatment effect on the treated. Inference procedures that are justified asymptotically are often unsatisfactory due to (1) small sample sizes that render large-sample approximation fragile and (2) simplification of the estimation procedure that is implemented in practice. An alternative is permutation inference, which is related to a common diagnostic called the placebo test. It has provable Type-I error guarantees in finite samples without simplification of the method, when the treatment is uniformly assigned. Despite this robustness, the placebo test suffers from low resolution since the null distribution is constructed from only $N$ reference estimates, where $N$ is the sample size. This creates a barrier for statistical inference at a common level like $\u03b1= 0.05$, especially when $N$ is small. We propose a novel leave-two-out procedure that bypasses this issue, while still maintaining the same finite-sample Type-I error guarantee under uniform assignment for a wide range of $N$. Unlike the placebo test whose Type-I error always equals the theoretical upper bound, our procedure often achieves a lower unconditional Type-I error than theory suggests; this enables useful inference in the challenging regime when $\u03b1< 1/N$. Empirically, our procedure achieves a higher power when the effect size is reasonably large and a comparable power otherwise. We generalize our procedure to non-uniform assignments and show how to conduct sensitivity analysis. From a methodological perspective, our procedure can be viewed as a new type of randomization inference different from permutation or rank-based inference, which is particularly effective in small samples.",
        "comments": "36 pages. Comments welcome",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07152"
    },
    {
        "doc_id": 197,
        "title": "Causal machine learning in public policy evaluation -- an application to the conditioning of cash transfers in Morocco",
        "authors": [
            "Patrick Rehill",
            "Nicholas Biddle"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Causal machine learning methods can be used to search for treatment effect heterogeneity in high-dimensional datasets even where we lack a strong enough theoretical framework to select variables or make parametric assumptions about data. This paper uses causal machine learning methods to estimate heterogeneous treatment effects in the case of an experimental study carried out in Morocco which evaluated the effect of conditionalizing a cash transfer program on school attendance compared to a labelled cash transfer. We show that there is little heterogeneity in effects with the average treatment effect across three different conditioning policies all being negative. We then explore if there are any variables in the dataset of 1936 pre-treatment variables that are particularly strong predictors of heterogeneity to try to understand this effect. While there are some variables we expected to be important here based on our theoretical framework, most are atheoretical variables whose effects are difficult to interpret. Household spending variables and child time-use variables are particularly important, however no variables have particularly large effects. The second purpose of this paper is to demonstrate and reflect upon a causal machine learning approach to policy evaluation. In this vein we suggest that findings that are difficult to interpret in this way are not surprising given the atheoretical methodology. We reflect that causal machine learning methods should not replace existing evaluation methodologies, but rather could be a useful tool for working with high-dimensional data and generating hypotheses.",
        "comments": "20 pages, 10 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07075"
    },
    {
        "doc_id": 198,
        "title": "A Dynamic Agent Based Model of the Real Economy with Monopolistic Competition, Perfect Product Differentiation, Heterogeneous Agents, Increasing Returns to Scale and Trade in Disequilibrium",
        "authors": [
            "Subhamon Supantha",
            "Naresh Kumar Sharma"
        ],
        "subjects": [
            "Theoretical Economics",
            "Multiagent Systems"
        ],
        "abstract": "We have used agent-based modeling as our numerical method to artificially simulate a dynamic real economy where agents are rational maximizers of an objective function of Cobb-Douglas type. The economy is characterised by heterogeneous agents, acting out of local or imperfect information, monopolistic competition, perfect product differentiation, allowance for increasing returns to scale technology and trade in disequilibrium. An algorithm for economic activity in each period is devised and a general purpose open source agent-based model is developed which allows for counterfactual inquiries, testing out treatments, analysing causality of various economic processes, outcomes and studying emergent properties. 10,000 simulations, with 10 firms and 80 consumers are run with varying parameters and the results show that from only a few initial conditions the economy reaches equilibrium while in most of the other cases it remains in perpetual disequilibrium. It also shows that from a few initial conditions the economy reaches a disaster where all the consumer wealth falls to zero or only a single producer remains. Furthermore, from some initial conditions, an ideal economy with high wage rate, high consumer utility and no unemployment is also reached. It was also observed that starting from an equal endowment of wealth in consumers and in producers, inequality emerged in the economy. In majority of the cases most of the firms(6-7) shut down because they were not profitable enough and only a few firms remained. Our results highlight that all these varying outcomes are possible for a decentralized market economy with rational optimizing agents.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07070"
    },
    {
        "doc_id": 199,
        "title": "A simple stochastic nonlinear AR model with application to bubble",
        "authors": [
            "Xuanling Yang",
            "Dong Li",
            "Ting Zhang"
        ],
        "subjects": [
            "Statistics Theory",
            "Econometrics"
        ],
        "abstract": "Economic and financial time series can feature locally explosive behavior when a bubble is formed. The economic or financial bubble, especially its dynamics, is an intriguing topic that has been attracting longstanding attention. To illustrate the dynamics of the local explosion itself, the paper presents a novel, simple, yet useful time series model, called the stochastic nonlinear autoregressive model, which is always strictly stationary and geometrically ergodic and can create long swings or persistence observed in many macroeconomic variables. When a nonlinear autoregressive coefficient is outside of a certain range, the model has periodically explosive behaviors and can then be used to portray the bubble dynamics. Further, the quasi-maximum likelihood estimation (QMLE) of our model is considered, and its strong consistency and asymptotic normality are established under minimal assumptions on innovation. A new model diagnostic checking statistic is developed for model fitting adequacy. In addition two methods for bubble tagging are proposed, one from the residual perspective and the other from the null-state perspective. Monte Carlo simulation studies are conducted to assess the performances of the QMLE and the two bubble tagging methods in finite samples. Finally, the usefulness of the model is illustrated by an empirical application to the monthly Hang Seng Index.",
        "comments": "41 pages, 6 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07038"
    },
    {
        "doc_id": 200,
        "title": "Reference-dependent asset pricing with a stochastic consumption-dividend ratio",
        "authors": [
            "Luca De Gennaro Aquino",
            "Xuedong He",
            "Moris Simon Strub",
            "Yuting Yang"
        ],
        "subjects": [
            "Mathematical Finance",
            "General Finance"
        ],
        "abstract": "We study a discrete-time consumption-based capital asset pricing model under expectations-based reference-dependent preferences. More precisely, we consider an endowment economy populated by a representative agent who derives utility from current consumption and from gains and losses in consumption with respect to a forward-looking, stochastic reference point. First, we consider a general model in which the agent's preferences include both contemporaneous gain-loss utility, that is, utility from the difference between current consumption and previously held expectations about current consumption, and prospective gain-loss utility, that is, utility from the difference between intertemporal beliefs about future consumption. A semi-closed form solution for equilibrium asset prices is derived for this case. We then specialize to a model in which the agent derives contemporaneous gain-loss utility only, obtaining equilibrium asset prices in closed form. Extensive numerical experiments show that, with plausible values of risk aversion and loss aversion, our models can generate equity premia that match empirical estimates. Interestingly, the models turn out to be consistent with some well-known empirical facts, namely procyclical variation in the price-dividend ratio and countercyclical variation in the conditional expected equity premium and in the conditional volatility of the equity premium. Furthermore, we find that prospective gain-loss utility is necessary for the model to predict reasonable values of the price-dividend ratio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12856"
    },
    {
        "doc_id": 201,
        "title": "New approximate stochastic dominance approaches for Enhanced Indexation models",
        "authors": [
            "Francesco Cesarone",
            "Justo Puerto"
        ],
        "subjects": [
            "Portfolio Management",
            "Computational Finance",
            "General Finance"
        ],
        "abstract": "In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczynski (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12669"
    },
    {
        "doc_id": 202,
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "authors": [
            "Henri Arno",
            "Klaas Mulier",
            "Joke Baeck",
            "Thomas Demeester"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Computational Finance"
        ],
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.",
        "comments": "Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12652"
    },
    {
        "doc_id": 203,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 204,
        "title": "General duality and dual attainment for adapted transport",
        "authors": [
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "We investigate duality and existence of dual optimizers for several adapted optimal transport problems under minimal assumptions. This includes the causal and bicausal transport, the barycenter problem, and a general multimarginal problem incorporating causality constraints. Moreover, we discuss applications of our results in robust finance. We consider a non-dominated model of several financial markets where stocks are traded dynamically, but the joint stock dynamics are unknown. We show that a no-arbitrage assumption in a quasi-sure sense naturally leads to sets of multicausal couplings. Consequently, computing the robust superhedging price is equivalent to solving an adapted transport problem, and finding a superhedging strategy means solving the corresponding dual.",
        "comments": "32 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11958"
    },
    {
        "doc_id": 205,
        "title": "Forecasting and Backtesting Gradient Allocations of Expected Shortfall",
        "authors": [
            "Takaaki Koike",
            "Cathy W. S. Chen",
            "Edward M. H. Lin"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Capital allocation is a procedure for quantifying the contribution of each source of risk to aggregated risk. The gradient allocation rule, also known as the Euler principle, is a prevalent rule of capital allocation under which the allocated capital captures the diversification benefit of the marginal risk as a component of overall risk. This research concentrates on Expected Shortfall (ES) as a regulatory standard and focuses on the gradient allocations of ES, also called ES contributions. We achieve the comprehensive treatment of backtesting the tuple of ES contributions in the framework of the traditional and comparative backtests based on the concepts of joint identifiability and multi-objective elicitability. For robust forecast evaluation against the choice of scoring function, we further develop Murphy diagrams for ES contributions as graphical tools to check whether one forecast dominates another under a class of scoring functions. Finally, leveraging the recent concept of multi-objective elicitability, we propose a novel semiparametric model for forecasting dynamic ES contributions based on a compositional regression model. In an empirical analysis of stock returns we evaluate and compare a variety of models for forecasting dynamic ES contributions and demonstrate the outstanding performance of the proposed model.",
        "comments": "MSC Class:          62F07; 62P05; 91B30",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11701"
    },
    {
        "doc_id": 206,
        "title": "A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting",
        "authors": [
            "Riaz Ud Din",
            "Salman Ahmed",
            "Saddam Hussain Khan"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.",
        "comments": "30 pages, 16 Figures, 4 Tables",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11621"
    },
    {
        "doc_id": 207,
        "title": "The geometry of multi-curve interest rate models",
        "authors": [
            "Claudio Fontana",
            "Giacomo Lanaro",
            "Agatha Murgoci"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We study the problems of consistency and of the existence of finite-dimensional realizations for multi-curve interest rate models of Heath-Jarrow-Morton type, generalizing the geometric approach developed by T. Bj\u00f6rk and co-authors in the classical single-curve setting. We characterize when a multi-curve interest rate model is consistent with a given parameterized family of forward curves and spreads and when a model can be realized by a finite-dimensional state process. We illustrate the general theory in a number of model classes and examples, providing explicit constructions of finite-dimensional realizations. Based on these theoretical results, we perform the calibration of a three-curve Hull-White model to market data and analyse the stability of the estimated parameters.",
        "comments": "28 pages, 2 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11619"
    },
    {
        "doc_id": 208,
        "title": "Functional Limit Theorems for Hawkes Processes",
        "authors": [
            "Ulrich Horst",
            "Wei Xu"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritical processes critical ones with heavily dispersed child events display long-range dependencies.",
        "comments": "59 pages; Keywords and phrases: Hawkes process, functional limit theorem, regular variation, convergence rate",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11495"
    },
    {
        "doc_id": 209,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 210,
        "title": "Data-driven Option Pricing",
        "authors": [
            "Min Dai",
            "Hanqing Jin",
            "Xi Yang"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "We propose an innovative data-driven option pricing methodology that relies exclusively on the dataset of historical underlying asset prices. While the dataset is rooted in the objective world, option prices are commonly expressed as discounted expectations of their terminal payoffs in a risk-neutral world. Bridging this gap motivates us to identify a pricing kernel process, transforming option pricing into evaluating expectations in the objective world. We recover the pricing kernel by solving a utility maximization problem, and evaluate the expectations in terms of a functional optimization problem. Leveraging the deep learning technique, we design data-driven algorithms to solve both optimization problems over the dataset. Numerical experiments are presented to demonstrate the efficiency of our methodology.",
        "comments": "15 pages, 3 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11158"
    },
    {
        "doc_id": 211,
        "title": "BioFinBERT: Finetuning Large Language Models (LLMs) to Analyze Sentiment of Press Releases and Financial Text Around Inflection Points of Biotech Stocks",
        "authors": [
            "Valentina Aparicio",
            "Daniel Gordon",
            "Sebastian G. Huayamares",
            "Yuhuai Luo"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "Large language models (LLMs) are deep learning algorithms being used to perform natural language processing tasks in various fields, from social sciences to finance and biomedical sciences. Developing and training a new LLM can be very computationally expensive, so it is becoming a common practice to take existing LLMs and finetune them with carefully curated datasets for desired applications in different fields. Here, we present BioFinBERT, a finetuned LLM to perform financial sentiment analysis of public text associated with stocks of companies in the biotechnology sector. The stocks of biotech companies developing highly innovative and risky therapeutic drugs tend to respond very positively or negatively upon a successful or failed clinical readout or regulatory approval of their drug, respectively. These clinical or regulatory results are disclosed by the biotech companies via press releases, which are followed by a significant stock response in many cases. In our attempt to design a LLM capable of analyzing the sentiment of these press releases,we first finetuned BioBERT, a biomedical language representation model designed for biomedical text mining, using financial textual databases. Our finetuned model, termed BioFinBERT, was then used to perform financial sentiment analysis of various biotech-related press releases and financial text around inflection points that significantly affected the price of biotech stocks.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11011"
    },
    {
        "doc_id": 212,
        "title": "Forecasting Cryptocurrency Staking Rewards",
        "authors": [
            "Sauren Gupta",
            "Apoorva Hathi Katharaki",
            "Yifan Xu",
            "Bhaskar Krishnamachari",
            "Rajarshi Gupta"
        ],
        "subjects": [
            "Statistical Finance",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This research explores a relatively unexplored area of predicting cryptocurrency staking rewards, offering potential insights to researchers and investors. We investigate two predictive methodologies: a) a straightforward sliding-window average, and b) linear regression models predicated on historical data. The findings reveal that ETH staking rewards can be forecasted with an RMSE within 0.7% and 1.1% of the mean value for 1-day and 7-day look-aheads respectively, using a 7-day sliding-window average approach. Additionally, we discern diverse prediction accuracies across various cryptocurrencies, including SOL, XTZ, ATOM, and MATIC. Linear regression is identified as superior to the moving-window average for perdicting in the short term for XTZ and ATOM. The results underscore the generally stable and predictable nature of staking rewards for most assets, with MATIC presenting a noteworthy exception.",
        "comments": "9 pages, 18 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10931"
    },
    {
        "doc_id": 213,
        "title": "Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock",
        "authors": [
            "Dengxin Huang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "This document presents a stock market analysis conducted on a dataset consisting of 750 instances and 16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section, feature engineering, data preparation, model selection, and insights from the analysis. The Fama French 3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear regression being the best-performing model.",
        "comments": "9 pages, 7 figures",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10903"
    },
    {
        "doc_id": 214,
        "title": "Stylized Facts and Market Microstructure: An In-Depth Exploration of German Bond Futures Market",
        "authors": [
            "Hamza Bodor",
            "Laurent Carlier"
        ],
        "subjects": [
            "Statistical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper presents an in-depth analysis of stylized facts in the context of futures on German bonds. The study examines four futures contracts on German bonds: Schatz, Bobl, Bund and Buxl, using tick-by-tick limit order book datasets. It uncovers a range of stylized facts and empirical observations, including the distribution of order sizes, patterns of order flow, and inter-arrival times of orders. The findings reveal both commonalities and unique characteristics across the different futures, thereby enriching our understanding of these markets. Furthermore, the paper introduces insightful realism metrics that can be used to benchmark market simulators. The study contributes to the literature on financial stylized facts by extending empirical observations to this class of assets, which has been relatively underexplored in existing research. This work provides valuable guidance for the development of more accurate and realistic market simulators.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10722"
    },
    {
        "doc_id": 215,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 216,
        "title": "Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review",
        "authors": [
            "Lars Ericson",
            "Xuejun Zhu",
            "Xusi Han",
            "Rao Fu",
            "Shuang Li",
            "Steve Guo",
            "Ping Hu"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "In the financial services industry, forecasting the risk factor distribution conditional on the history and the current market environment is the key to market risk modeling in general and value at risk (VaR) model in particular. As one of the most widely adopted VaR models in commercial banks, Historical simulation (HS) uses the empirical distribution of daily returns in a historical window as the forecast distribution of risk factor returns in the next day. The objectives for financial time series generation are to generate synthetic data paths with good variety, and similar distribution and dynamics to the original historical data. In this paper, we apply multiple existing deep generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for conditional time series generation, and propose and test two new methods for conditional multi-step time series generation, namely Encoder-Decoder CGAN and Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a set of KPIs to measure the quality of the generated time series for financial modeling. The KPIs cover distribution distance, autocorrelation and backtesting. All models (HS, parametric and neural networks) are tested on both historical USD yield curve data and additional data simulated from GARCH and CIR processes. The study shows that top performing models are HS, GARCH and CWGAN models. Future research directions in this area are also discussed.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10370"
    },
    {
        "doc_id": 217,
        "title": "Interplay between Cryptocurrency Transactions and Online Financial Forums",
        "authors": [
            "Ana Fern\u00e1ndez Vilas",
            "Rebeca P. D\u00edaz Redondo",
            "Daniel Couto Cancela",
            "Alejandro Torrado Pazos"
        ],
        "subjects": [
            "General Finance",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Cryptocurrencies are a type of digital money meant to provide security and anonymity while using cryptography techniques. Although cryptocurrencies represent a breakthrough and provide some important benefits, their usage poses some risks that are a result of the lack of supervising institutions and transparency. Because disinformation and volatility is discouraging for personal investors, cryptocurrencies emerged hand-in-hand with the proliferation of online users' communities and forums as places to share information that can alleviate users' mistrust. This research focuses on the study of the interplay between these cryptocurrency forums and fluctuations in cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin (BTC) and a related active discussion community, Bitcointalk, are analyzed. This study shows that the activity of Bitcointalk forum keeps a direct relationship with the trend in the values of BTC, therefore analysis of this interaction would be a perfect base to support personal investments in a non-regulated market and, to confirm whether cryptocurrency forums show evidences to detect abnormal behaviors in BTC values as well as to predict or estimate these values. The experiment highlights that forum data can explain specific events in the financial field. It also underlines the relevance of quotes (regular mechanism to response a post) at periods: (1) when there is a high concentration of posts around certain topics; (2) when peaks in the BTC price are observed; and, (3) when the BTC price gradually shifts downwards and users intend to sell.",
        "comments": "Journal ref:        Mathematics 2021, 9(4), 411;",
        "date": "27 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10238"
    },
    {
        "doc_id": 218,
        "title": "An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)",
        "authors": [
            "Garvit Arora",
            "Shubhangi Shubhangi",
            "Ying Wu",
            "Xuan Mei"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10162"
    },
    {
        "doc_id": 219,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 220,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 221,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 222,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 223,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 224,
        "title": "Mean-Field SDEs driven by $G$-Brownian Motion",
        "authors": [
            "Karl-Wilhelm Georg Bollweg",
            "Thilo Meyer-Brandis"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We extend the notion of mean-field SDEs to SDEs driven by $G$-Brownian motion. More precisely, we consider a $G$-SDE where the coefficients depend not only on time and the current state but also on the solution as random variable.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09113"
    },
    {
        "doc_id": 225,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 226,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 227,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 228,
        "title": "Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Xi Chen",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "subjects": [
            "General Finance",
            "Cryptography and Security"
        ],
        "abstract": "Lido, the leading Liquid Staking Derivative (LSD) provider on Ethereum, allows users to stake an arbitrary amount of ETH to receive stETH, which can be integrated with Decentralized Finance (DeFi) protocols such as Aave. The composability between Lido and Aave enables a novel strategy called \"leverage staking\", where users stake ETH on Lido to acquire stETH, utilize stETH as collateral on Aave to borrow ETH, and then restake the borrowed ETH on Lido. Users can iteratively execute this process to optimize potential returns based on their risk profile.\n  This paper systematically studies the opportunities and risks associated with leverage staking. We are the first to formalize the leverage staking strategy within the Lido-Aave ecosystem. Our empirical study identifies 262 leverage staking positions on Ethereum, with an aggregated staking amount of 295,243 ETH (482M USD). We discover that 90.13% of leverage staking positions have achieved higher returns than conventional staking. Furthermore, we perform stress tests to evaluate the risk introduced by leverage staking under extreme conditions. We find that leverage staking significantly amplifies the risk of cascading liquidations. We hope this paper can inform and encourage the development of robust risk management approaches to protect the Lido-Aave LSD ecosystem.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08610"
    },
    {
        "doc_id": 229,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 230,
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We consider two data driven approaches, Reinforcement Learning (RL) and Deep Trajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call option without and with transaction cost according to a quadratic hedging P&L objective at maturity (\"variance-optimal hedging\" or \"final quadratic hedging\"). We study the performance of the two approaches under various market environments (modeled via the Black-Scholes and/or the log-normal SABR model) to understand their advantages and limitations. Without transaction costs and in the Black-Scholes model, both approaches match the performance of the variance-optimal Delta hedge. In the log-normal SABR model without transaction costs, they match the performance of the variance-optimal Barlett's Delta hedge. Agents trained on Black-Scholes trajectories with matching initial volatility but used on SABR trajectories match the performance of Bartlett's Delta hedge in average cost, but show substantially wider variance. To apply RL approaches to these problems, P&L at maturity is written as sum of step-wise contributions and variants of RL algorithms are implemented and used that minimize expectation of second moments of such sums.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.07996",
        "date": "20 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08600"
    },
    {
        "doc_id": 231,
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Organizations use cash management models to control balances to both avoid overdrafts and obtain a profit from short-term investments. Most management models are based on control bounds which are derived from the assumption of a particular cash flow probability distribution. In this paper, we relax this strong assumption to fit cash management models to data by means of stochastic and linear programming. We also introduce ensembles of random cash management models which are built by randomly selecting a subsequence of the original cash flow data set. We illustrate our approach by means of a real case study showing that a small random sample of data is enough to fit sufficiently good bound-based models.",
        "comments": "19 pages,6 figures, 1 table",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08548"
    },
    {
        "doc_id": 232,
        "title": "Dynamic portfolio selection under generalized disappointment aversion",
        "authors": [
            "Zongxia Liang",
            "Sheng Wang",
            "Jianming Xia",
            "Fengyi Yuan"
        ],
        "subjects": [
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "This paper addresses the continuous-time portfolio selection problem under generalized disappointment aversion (GDA). The implicit definition of the certainty equivalent within GDA preferences introduces time inconsistency to this problem. We provide the sufficient and necessary conditions for a strategy to be an equilibrium by a fully nonlinear ordinary differential equation (ODE). Through an exploration of the existence and uniqueness of solution to the ODE, we establish the existence and uniqueness of the equilibrium. Our findings indicate that under disappointment aversion (DA) preferences, non-participation in the stock market is the unique equilibrium. The numerical analysis reveals that, under GDA preferences, the investment proportion in the stock market consistently remains smaller than the investment proportion under the classical Expected Utility (EU) theory.",
        "comments": "27 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08323"
    },
    {
        "doc_id": 233,
        "title": "Do backrun auctions protect traders?",
        "authors": [
            "Andrew W. Macpherson"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Distributed, Parallel, and Cluster Computing",
            "Computer Science and Game Theory"
        ],
        "abstract": "We study a new \"laminated\" queueing model for orders on batched trading venues such as decentralised exchanges. The model aims to capture and generalise transaction queueing infrastructure that has arisen to organise MEV activity on public blockchains such as Ethereum, providing convenient channels for sophisticated agents to extract value by acting on end-user order flow by performing arbitrage and related HFT activities. In our model, market orders are interspersed with orders created by arbitrageurs that under idealised conditions reset the marginal price to a global equilibrium between each trade, improving predictability of execution for liquidity traders.\n  If an arbitrageur has a chance to land multiple opportunities in a row, he may attempt to manipulate the execution price of the intervening market order by a probabilistic blind sandwiching strategy. To study how bad this manipulation can get, we introduce and bound a price manipulation coefficient that measures the deviation from global equilibrium of local pricing quoted by a rational arbitrageur. We exhibit cases in which this coefficient is well approximated by a \"zeta value' with interpretable and empirically measurable parameters.",
        "comments": "Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08302"
    },
    {
        "doc_id": 234,
        "title": "Optimal Insurance to Maximize Exponential Utility when Premium is Computed by a Convex Functional",
        "authors": [
            "Jingyi Cao",
            "Dongchen Li",
            "Virginia R. Young",
            "Bin Zou"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Risk Management"
        ],
        "abstract": "We find the optimal indemnity to maximize the expected utility of terminal wealth of a buyer of insurance whose preferences are modeled by an exponential utility. The insurance premium is computed by a convex functional. We obtain a necessary condition for the optimal indemnity; then, because the candidate optimal indemnity is given implicitly, we use that necessary condition to develop a numerical algorithm to compute it. We prove that the numerical algorithm converges to a unique indemnity that, indeed, equals the optimal policy. We also illustrate our results with numerical examples.",
        "comments": "12 pages, 3 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08094"
    },
    {
        "doc_id": 235,
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option Pricing",
        "authors": [
            "Ce Wang"
        ],
        "subjects": [
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two regression models fitted at each time step to price game options. Although the original LSMC can be used to price game options with an enlarged range of path in regression and a modified cashflow updating rule, we identified a drawback of such approach, which motivated us to propose our approach. We implemented numerical examples with benchmarks using binomial tree and numerical PDE, and it showed that our method produces more reliable results comparing to the original LSMC.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08093"
    },
    {
        "doc_id": 236,
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "authors": [
            "Shubham Singh",
            "Mayur Bhat"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Pricing of Securities"
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "comments": "12 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08077"
    },
    {
        "doc_id": 237,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 238,
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "authors": [
            "Samuel Vandak",
            "Geoffrey Goodell"
        ],
        "subjects": [
            "Computers and Society",
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "comments": "34 pages, 19 figures, 5 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07682"
    },
    {
        "doc_id": 239,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 240,
        "title": "Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Design/methodology/approach This research evaluated the databases of SQL, No-SQL and graph databases to compare and contrast efficiency and performance. To perform this experiment the data were collected from multiple sources including stock price and financial news. Python is used as an interface to connect and query databases (to create database structures according to the feed file structure, to load data into tables, objects, to read data , to connect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM (Large language model) including RAG (Retrieval Augmented Generation) with Machine Learning, deep learning, NLP (natural language processing) or Decision Analytics are computationally expensive. Finding a better option to consume less resources and time to get the result. Findings The Graph database of ESG (Environmental, Social and Governance) is comparatively better and can be considered for extended analytics to integrate ESG in business and investment. Practical implications A graph ML with a RAG architecture model can be introduced as a new framework with less computationally expensive LLM application in the equity filtering process for portfolio management. Originality/value Filtering out selective stocks out of two thousand or more listed companies in any stock exchange for active investment, consuming less resource consumption especially memory and energy to integrate artificial intelligence and ESG in business and investment.",
        "comments": "10 pages, 17 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07483"
    },
    {
        "doc_id": 241,
        "title": "Herd Behavior in Optimal Investment: A Dual-Agent Approach with Investment Opinion and Rational Decision Decomposition",
        "authors": [
            "Huisheng Wang",
            "H. Vicky Zhao"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control",
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "In this paper, we study the optimal investment problem involving two agents, where the decision of one agent is influenced by the other. To measure the distance between two agents' decisions, we introduce the average deviation. We formulate the stochastic optimal control problem considering herd behavior and derive the analytical solution through the variational method. We theoretically analyze the impact of users' herd behavior on the optimal decision by decomposing it into their rational decisions, which is called the rational decision decomposition. Furthermore, to quantify the preference for their rational decision over that of the other agent, we introduce the agent's investment opinion. Our study is validated through simulations on real stock data.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07183"
    },
    {
        "doc_id": 242,
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Chris Tanner"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Research in quantitative reasoning within the financial domain indeed necessitates the use of realistic tasks and data, primarily because of the significant impact of decisions made in business and finance. Financial professionals often interact with documents hundreds of pages long, but most research datasets drastically reduce this context length. To address this, we introduce a long-document financial QA task. We augment 7,621 questions from the existing FinQA dataset with full-document context, extending the average context length for each question from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and long-context language models on the augmented data. Our results show that DocFinQA provides challenges for even the strongest, state-of-the-art systems.",
        "comments": "13 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06915"
    },
    {
        "doc_id": 243,
        "title": "A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assessed in a series of numerical experiments involving the Merton jump-diffusion model.",
        "comments": "16 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06740"
    },
    {
        "doc_id": 244,
        "title": "Equity auction dynamics: latent liquidity models with activity acceleration",
        "authors": [
            "Mohammed Salek",
            "Damien Challet",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Finance"
        ],
        "abstract": "Equity auctions display several distinctive characteristics in contrast to continuous trading. As the auction time approaches, the rate of events accelerates causing a substantial liquidity buildup around the indicative price. This, in turn, results in a reduced price impact and decreased volatility of the indicative price. In this study, we adapt the latent/revealed order book framework to the specifics of equity auctions. We provide precise measurements of the model parameters, including order submissions, cancellations, and diffusion rates. Our setup allows us to describe the full dynamics of the average order book during closing auctions in Euronext Paris. These findings support the relevance of the latent liquidity framework in describing limit order book dynamics. Lastly, we analyze the factors contributing to a sub-diffusive indicative price and demonstrate the absence of indicative price predictability.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06724"
    },
    {
        "doc_id": 245,
        "title": "SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks",
        "authors": [
            "Alessio Brini",
            "Giacomo Toscano"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents financial assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with high-frequency prices of the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net shows improved accuracy, compared to alternative econometric and machine-learning-based models. Further, our results show that SpotV2Net maintains accuracy when performing intraday multi-step forecasts. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer, a model-agnostic interpretability tool and thereby uncover subgraphs that are critical to a node's predictions.",
        "comments": "34 pages, 9 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06249"
    },
    {
        "doc_id": 246,
        "title": "CNN-DRL for Scalable Actions in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Haseebullah Jumakhan",
            "Amir Mirzaeinia"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "The published MLP-based DRL in finance has difficulties in learning the dynamics of the environment when the action scale increases. If the buying and selling increase to one thousand shares, the MLP agent will not be able to effectively adapt to the environment. To address this, we designed a CNN agent that concatenates the data from the last ninety days of the daily feature vector to create the CNN input matrix. Our extensive experiments demonstrate that the MLP-based agent experiences a loss corresponding to the initial environment setup, while our designed CNN remains stable, effectively learns the environment, and leads to an increase in rewards.",
        "comments": "10th Annual Conf. on Computational Science & Computational Intelligence",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06179"
    },
    {
        "doc_id": 247,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 248,
        "title": "Multimodal Gen-AI for Fundamental Investment Research",
        "authors": [
            "Lezhi Li",
            "Ting-Yu Chang",
            "Hai Wang"
        ],
        "subjects": [
            "General Finance",
            "Machine Learning"
        ],
        "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.",
        "comments": " ",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06164"
    },
    {
        "doc_id": 249,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 250,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 251,
        "title": "StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks",
        "authors": [
            "Bohan Ma",
            "Yiheng Wang",
            "Yuchao Lu",
            "Tianzixuan Hu",
            "Jinling Xu",
            "Patrick Houlihan"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Machine Learning"
        ],
        "abstract": "Amidst ongoing market recalibration and increasing investor optimism, the U.S. stock market is experiencing a resurgence, prompting the need for sophisticated tools to protect and grow portfolios. Addressing this, we introduce \"Stockformer,\" a cutting-edge deep learning framework optimized for swing trading, featuring the TopKDropout method for enhanced stock selection. By integrating STL decomposition and self-attention networks, Stockformer utilizes the S&P 500's complex data to refine stock return predictions. Our methodology entailed segmenting data for training and validation (January 2021 to January 2023) and testing (February to June 2023). During testing, Stockformer's predictions outperformed ten industry models, achieving superior precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a remarkable accuracy rate of 62.39% in detecting market trends. In our backtests, Stockformer's swing trading strategy yielded a cumulative return of 13.19% and an annualized return of 30.80%, significantly surpassing current state-of-the-art models. Stockformer has emerged as a beacon of innovation in these volatile times, offering investors a potent tool for market forecasting. To advance the field and foster community collaboration, we have open-sourced Stockformer, available at https://github.com/Eric991005/Stockformer.",
        "comments": "Currently under consideration for publication in the International Journal of Forecasting",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06139"
    },
    {
        "doc_id": 252,
        "title": "Quantum Probability Theoretic Asset Return Modeling: A Novel Schr\u00f6dinger-Like Trading Equation and Multimodal Distribution",
        "authors": [
            "Li Lin"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "Quantum theory provides a comprehensive framework for quantifying uncertainty, often applied in quantum finance to explore the stochastic nature of asset returns. This perspective likens returns to microscopic particle motion, governed by quantum probabilities akin to physical laws. However, such approaches presuppose specific microscopic quantum effects in return changes, a premise criticized for lack of guarantee. This paper diverges by asserting that quantum probability is a mathematical extension of classical probability to complex numbers. It isn't exclusively tied to microscopic quantum phenomena, bypassing the need for quantum effects in returns.By directly linking quantum probability's mathematical structure to traders' decisions and market behaviors, it avoids assuming quantum effects for returns and invoking the wave function. The complex phase of quantum probability, capturing transitions between long and short decisions while considering information interaction among traders, offers an inherent advantage over classical probability in characterizing the multimodal distribution of asset returns.Utilizing Fourier decomposition, we derive a Schr\u00f6dinger-like trading equation, where each term explicitly corresponds to implications of market trading. The equation indicates discrete energy levels in financial trading, with returns following a normal distribution at the lowest level. As the market transitions to higher trading levels, a phase shift occurs in the return distribution, leading to multimodality and fat tails. Empirical research on the Chinese stock market supports the existence of energy levels and multimodal distributions derived from this quantum probability asset returns model.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05823"
    },
    {
        "doc_id": 253,
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "authors": [
            "Frank Xing"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Multiagent Systems",
            "General Finance"
        ],
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
        "comments": "15 pages",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05799"
    },
    {
        "doc_id": 254,
        "title": "Super-hedging-pricing formulas and Immediate-Profit arbitrage for market models under random horizon",
        "authors": [
            "Tahir Choulli",
            "Emmanuel Lepinette"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Probability",
            "Pricing of Securities"
        ],
        "abstract": "In this paper, we consider the discrete-time setting, and the market model described by (S,F,T)$. Herein F is the ``public\" flow of information which is available to all agents overtime, S is the discounted price process of d-tradable assets, and T is an arbitrary random time whose occurrence might not be observable via F. Thus, we consider the larger flow G which incorporates F and makes T an observable random time. This framework covers the credit risk theory setting, the life insurance setting and the setting of employee stock option valuation. For the stopped model (S^T,G) and for various vulnerable claims, based on this model, we address the super-hedging pricing valuation problem and its intrinsic Immediate-Profit arbitrage (IP hereafter for short). Our first main contribution lies in singling out the impact of change of prior and/or information on conditional essential supremum, which is a vital tool in super-hedging pricing. The second main contribution consists of describing as explicit as possible how the set of super-hedging prices expands under the stochasticity of T and its risks, and we address the IP arbitrage for (S^T,G) as well. The third main contribution resides in elaborating as explicit as possible pricing formulas for vulnerable claims, and singling out the various informational risks in the prices' dynamics.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05713"
    },
    {
        "doc_id": 255,
        "title": "Boundary conditions at infinity for Black-Scholes equations",
        "authors": [
            "Yukihiro Tsuzuki"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance"
        ],
        "abstract": "We propose numerical procedures for computing the prices of forward contracts where the underlying asset price is a Markovian local martingale. If the underlying process is a strict local martingale, multiple solutions exist for the corresponding Black-Scholes equations, and the derivative prices are characterized as the minimal solutions. Our prices are upper and lower bounds obtained using numerical methods on a finite grid under the respective boundary conditions. These bounds and the boundary values converge to the exact value as the underlying price approaches infinity. The proposed procedures are demonstrated through numerical tests.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05549"
    },
    {
        "doc_id": 256,
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "authors": [
            "Baptiste Lefort",
            "Eric Benhamou",
            "Jean-Jacques Ohana",
            "David Saltiel",
            "Beatrice Guez",
            "Damien Challet"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence"
        ],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05447"
    },
    {
        "doc_id": 257,
        "title": "An adaptive network-based approach for advanced forecasting of cryptocurrency values",
        "authors": [
            "Ali Mehrban",
            "Pegah Ahadian"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This paper describes an architecture for predicting the price of cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy Inference System (ANFIS). Historical data of cryptocurrencies and indexes that are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D), and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach the data are hybrid and backpropagation algorithms, as well as grid partition, subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which are used in data clustering. The architectural performance designed in this paper has been compared with different inputs and neural network models in terms of statistical evaluation criteria. Finally, the proposed method can predict the price of digital currencies in a short time.",
        "comments": "11 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05441"
    },
    {
        "doc_id": 258,
        "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification",
        "authors": [
            "Zinuo You",
            "Pengju Zhang",
            "Jin Zheng",
            "John Cartlidge"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).",
        "comments": "5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05430"
    },
    {
        "doc_id": 259,
        "title": "Introduction of L0 norm and application of L1 and C1 norm in the study of time-series",
        "authors": [
            "Victor Ujaldon Garcia"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Four markets are considered: Cryptocurrencies / South American exchange rate / Spanish Banking indices and European Indices and studied using TDA (Topological Data Analysis) tools. These tools are used to predict and showcase both strengths and weakness of the current TDA tools. In this paper a new tool $L0$ norm is defined and complemented with the already existing $C1$ norm.",
        "comments": "14 pages 8 figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05423"
    },
    {
        "doc_id": 260,
        "title": "Multiple-bubble testing in the cryptocurrency market: a case study of bitcoin",
        "authors": [
            "Sanaz Behzadi",
            "Mahmonir Bayanati",
            "Hamed Nozari"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Economic periods and financial crises have highlighted the importance of evaluating financial markets to investors and researchers in recent decades.",
        "comments": " ",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05417"
    },
    {
        "doc_id": 261,
        "title": "On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors",
        "authors": [
            "Xinshuai Dong",
            "Haoyue Dai",
            "Yewen Fan",
            "Songyao Jin",
            "Sathyamoorthy Rajendran",
            "Kun Zhang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Financial data is generally time series in essence and thus suffers from three fundamental issues: the mismatch in time resolution, the time-varying property of the distribution - nonstationarity, and causal factors that are important but unknown/unobserved. In this paper, we follow a causal perspective to systematically look into these three demons in finance. Specifically, we reexamine these issues in the context of causality, which gives rise to a novel and inspiring understanding of how the issues can be addressed. Following this perspective, we provide systematic solutions to these problems, which hopefully would serve as a foundation for future research in the area.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05414"
    },
    {
        "doc_id": 262,
        "title": "RIVCoin: an alternative, integrated, CeFi/DeFi-Vaulted Cryptocurrency",
        "authors": [
            "Roberto Rivera",
            "Guido Rocco",
            "Massimiliano Marzo",
            "Enrico Talin"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "This whitepaper introduces RIVCoin, a cryptocurrency built on Cosmos, fully stabilized by a diversified portfolio of both CeFi and DeFi assets, available in a digital, non-custodial wallet called RIV Wallet, that aims to provide Users an easy way to access the cryptocurrency markets, compliant to the strictest AML laws and regulations up to date. The token is a cryptocurrency at any time stabilized by a basket of assets: reserves are invested in a portfolio composed long term by 50% of CeFi assets, comprised of Fixed Income, Equity, Mutual and Hedge Funds and 50% of diversified strategies focused on digital assets, mainly staking and LP farming on the major, battle tested DeFi protocols. The cryptocurrency, as well as the dollar before Bretton Woods, is always fully stabilized by vaulted proof of assets: it is born and managed as a decentralized token, minted by a Decentralized Autonomous Organization, and entirely stabilized by assets evaluated by professional independent third parties. Users will trade, pool, and exchange the token without any intermediary, being able to merge them into a Liquidity Pool whose rewards will be composed by both the trading fees and the liquidity rewards derived from the reserve's seigniorage.\n  Users who wish and decide to pool RIVCoin in the Liquidity Pool will receive additional RIVCoin for themselves, and new RIVCoin are minted when the reserves increase in value or in case of purchase of new RIVCoin. The proposed model allows for alignment of incentives: decreasing the risk exposure by wealthier Users, but implicitly increasing that of smaller ones to a level perceived by them as still sustainable. Users indirectly benefit from the access to the rewards of sophisticated cryptocurrency portfolios hitherto precluded to them, without this turning into a disadvantage for the wealthy User.",
        "comments": " ",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05393"
    },
    {
        "doc_id": 263,
        "title": "Optimal Linear Signal: An Unsupervised Machine Learning Framework to Optimize PnL with Linear Signals",
        "authors": [
            "Pierre Renucci"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "This study presents an unsupervised machine learning approach for optimizing Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL generated from signals constructed linearly from exogenous variables. The methodology employs a linear relationship between exogenous variables and the trading signal, with the objective of maximizing the Sharpe Ratio through parameter optimization. Empirical application on an ETF representing U.S. Treasury bonds demonstrates the model's effectiveness, supported by regularization techniques to mitigate overfitting. The study concludes with potential avenues for further development, including generalized time steps and enhanced corrective terms.",
        "comments": "The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05337"
    },
    {
        "doc_id": 264,
        "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks",
        "authors": [
            "Zhang Chern Lee",
            "Wei Yun Tan",
            "Hoong Khen Koo",
            "Wilson Pang"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio",
        "comments": "19 pages, 5 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05264"
    },
    {
        "doc_id": 265,
        "title": "A Mean Field Game between Informed Traders and a Broker",
        "authors": [
            "Philippe Bergault",
            "Leandro S\u00e1nchez-Betancourt"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Optimization and Control"
        ],
        "abstract": "We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G\u00e2teaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05257"
    },
    {
        "doc_id": 266,
        "title": "On the Martingale Schr\u00f6dinger Bridge between Two Distributions",
        "authors": [
            "Marcel Nutz",
            "Johannes Wiesel"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We study a martingale Schr\u00f6dinger bridge problem: given two probability distributions, find their martingale coupling with minimal relative entropy. Our main result provides Schr\u00f6dinger potentials for this coupling. Namely, under certain conditions, the log-density of the optimal coupling is given by a triplet of real functions representing the marginal and martingale constraints. The potentials are also described as the solution of a dual problem.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05209"
    },
    {
        "doc_id": 267,
        "title": "Markowitz Portfolio Construction at Seventy",
        "authors": [
            "Stephen Boyd",
            "Kasper Johansson",
            "Ronald Kahn",
            "Philipp Schiele",
            "Thomas Schmelzer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "More than seventy years ago Harry Markowitz formulated portfolio construction as an optimization problem that trades off expected return and risk, defined as the standard deviation of the portfolio returns. Since then the method has been extended to include many practical constraints and objective terms, such as transaction cost or leverage limits. Despite several criticisms of Markowitz's method, for example its sensitivity to poor forecasts of the return statistics, it has become the dominant quantitative method for portfolio construction in practice. In this article we describe an extension of Markowitz's method that addresses many practical effects and gracefully handles the uncertainty inherent in return statistics forecasting. Like Markowitz's original formulation, the extension is also a convex optimization problem, which can be solved with high reliability and speed.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05080"
    },
    {
        "doc_id": 268,
        "title": "Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin",
        "authors": [
            "Didier Sornette",
            "Yu Zhang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least $200$ weeks with an exponent approximately equal to $0.9$, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between $0.3$ and $2.5$ depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to $-1.5$, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04702"
    },
    {
        "doc_id": 269,
        "title": "Proof of Efficient Liquidity: A Staking Mechanism for Capital Efficient Liquidity",
        "authors": [
            "Arman Abgaryan",
            "Utkarsh Sharma",
            "Joshua Tobkin"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "The Proof of Efficient Liquidity (PoEL) protocol, designed for specialised Proof of Stake (PoS) consensus-based blockchain infrastructures that incorporate intrinsic DeFi applications, aims to support sustainable liquidity bootstrapping and network security. This innovative mechanism efficiently utilises budgeted staking rewards to attract and sustain liquidity through a risk structuring engine and incentive allocation strategy, both of which are designed to maximise capital efficiency. The proposed protocol seeks to serve the dual objective of - (i) capital creation, by efficiently attracting risk capital, and maximising its operational utility for intrinsic DeFi applications, thereby asserting sustainability; and (ii) enhancing the adopting blockchain network's economic security, by augmenting their staking (PoS) mechanism with a harmonious layer seeking to attract a diversity of digital assets. Finally, in the appendix, we seek to generalise the financial incentivisation protocol to the notion of service fee credits, such that it utilises the network's auxiliary services as a means to propagate incentives to attract liquidity and facilitate the network to achieve the critical mass of usage necessary for sustained operations and growth.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04521"
    },
    {
        "doc_id": 270,
        "title": "Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks",
        "authors": [
            "Zan Yu",
            "Lianzeng Zhang"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Risk Management"
        ],
        "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.",
        "comments": "23 pages; 5 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04378"
    },
    {
        "doc_id": 271,
        "title": "Expiring Assets in Automated Market Makers",
        "authors": [
            "Kenan Wood",
            "Maurice Herlihy",
            "Hammurabi Mendes",
            "Jonad Pulaj"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Mathematical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "An automated market maker (AMM) is a state machine that manages pools of assets, allowing parties to buy and sell those assets according to a fixed mathematical formula. AMMs are typically implemented as smart contracts on blockchains, and its prices are kept in line with the overall market price by arbitrage: if the AMM undervalues an asset with respect to the market, an \"arbitrageur\" can make a risk-free profit by buying just enough of that asset to bring the AMM's price back in line with the market.\n  AMMs, however, are not designed for assets that expire: that is, assets that cannot be produced or resold after a specified date. As assets approach expiration, arbitrage may not be able to reconcile supply and demand, and the liquidity providers that funded the AMM may have excessive exposure to risk due to rapid price variations.\n  This paper formally describes the design of a decentralized exchange (DEX) for assets that expire, combining aspects of AMMs and limit-order books. We ensure liveness and market clearance, providing mechanisms for liquidity providers to control their exposure to risk and adjust prices dynamically in response to situations where arbitrage may fail.",
        "comments": "33 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04289"
    },
    {
        "doc_id": 272,
        "title": "Economic Forces in Stock Returns",
        "authors": [
            "Yue Chen",
            "Mohan Li"
        ],
        "subjects": [
            "General Economics",
            "Statistical Finance"
        ],
        "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.",
        "comments": "11 pages, 10 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04132"
    },
    {
        "doc_id": 273,
        "title": "Decomposing Smiles: A Time Change Approach",
        "authors": [
            "Liexin Cheng",
            "Xue Cheng"
        ],
        "subjects": [
            "Pricing of Securities",
            "Mathematical Finance"
        ],
        "abstract": "We develop a novel time-change approach to study the shape of implied volatility smiles. The method is applicable to common semimartingale models, including jump-diffusion, rough volatility and infinite activity models. We approximate the at-the-money skew and curvature with an improved moment-based formula. The moments are further explicitly computed under a time change framework. The limiting skew and curvature for several models are considered. We also test the accuracy of the short-term approximation results on models via numerical methods and on empirical data. Finally, we apply the method to the calibration problem.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03776"
    },
    {
        "doc_id": 274,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "subjects": [
            "Computational Finance",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation with S&P 100 stocks, MarketSenseAI outperformed the benchmark index by 13%, achieving returns up to 40%, while maintaining a risk profile comparable to the market. These results demonstrate the efficacy of Large Language Models in complex financial decision-making and mark a significant advancement in the integration of AI into financial analysis and investment strategies. This research contributes to the financial AI field, presenting an innovative approach and underscoring the transformative potential of AI in revolutionizing traditional financial analysis investment methodologies.",
        "comments": "15 pages, 12 figures, 12 tables",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03737"
    },
    {
        "doc_id": 275,
        "title": "Structured factor copulas for modeling the systemic risk of European and United States banks",
        "authors": [
            "Hoang Nguyen",
            "Audron\u0117 Virbickait\u0117",
            "M. Concepci\u00f3n Aus\u00edn",
            "Pedro Galeano"
        ],
        "subjects": [
            "Statistical Finance",
            "Applications"
        ],
        "abstract": "In this paper, we employ Credit Default Swaps (CDS) to model the joint and conditional distress probabilities of banks in Europe and the U.S. using factor copulas. We propose multi-factor, structured factor, and factor-vine models where the banks in the sample are clustered according to their geographic location. We find that within each region, the co-dependence between banks is best described using both, systematic and idiosyncratic, financial contagion channels. However, if we consider the banking system as a whole, then the systematic contagion channel prevails, meaning that the distress probabilities are driven by a latent global factor and region-specific factors. In all cases, the co-dependence structure of bank CDS spreads is highly correlated in the tail. The out-of-sample forecasts of several measures of systematic risk allow us to identify the periods of distress in the banking sector over the recent years including the COVID-19 pandemic, the interest rate hikes in 2022, and the banking crisis in 2023.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03443"
    },
    {
        "doc_id": 276,
        "title": "Modelling and Predicting the Conditional Variance of Bitcoin Daily Returns: Comparsion of Markov Switching GARCH and SV Models",
        "authors": [
            "Dennis Koch",
            "Vahidin Jeleskovic",
            "Zahid I. Younas"
        ],
        "subjects": [
            "Statistical Finance",
            "Risk Management"
        ],
        "abstract": "This paper introduces a unique and valuable research design aimed at analyzing Bitcoin price volatility. To achieve this, a range of models from the Markov Switching-GARCH and Stochastic Autoregressive Volatility (SARV) model classes are considered and their out-of-sample forecasting performance is thoroughly examined. The paper provides insights into the rationale behind the recommendation for a two-stage estimation approach, emphasizing the separate estimation of coefficients in the mean and variance equations. The results presented in this paper indicate that Stochastic Volatility models, particularly SARV models, outperform MS-GARCH models in forecasting Bitcoin price volatility. Moreover, the study suggests that in certain situations, persistent simple GARCH models may even outperform Markov-Switching GARCH models in predicting the variance of Bitcoin log returns. These findings offer valuable guidance for risk management experts, highlighting the potential advantages of SARV models in managing and forecasting Bitcoin price volatility.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03393"
    },
    {
        "doc_id": 277,
        "title": "Volatility models in practice: Rough, Path-dependent or Markovian?",
        "authors": [
            "Eduardo Abi Jaber",
            "Shaun",
            "Li"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "An extensive empirical study of the class of Volterra Bergomi models using SPX options data between 2011 and 2022 reveals the following fact-check on two fundamental claims echoed in the rough volatility literature:\n  Do rough volatility models with Hurst index $H \\in (0,1/2)$ really capture well SPX implied volatility surface with very few parameters? No, rough volatility models are inconsistent with the global shape of SPX smiles. They suffer from severe structural limitations imposed by the roughness component, with the Hurst parameter $H \\in (0,1/2)$ controlling the smile in a poor way. In particular, the SPX at-the-money skew is incompatible with the power-law shape generated by rough volatility models. The skew of rough volatility models increases too fast on the short end, and decays too slow on the longer end where \"negative\" $H$ is sometimes needed.\n  Do rough volatility models really outperform consistently their classical Markovian counterparts? No, for short maturities they underperform their one-factor Markovian counterpart with the same number of parameters. For longer maturities, they do not systematically outperform the one-factor model and significantly underperform when compared to an under-parametrized two-factor Markovian model with only one additional calibratable parameter.\n  On the positive side: our study identifies a (non-rough) path-dependent Bergomi model and an under-parametrized two-factor Markovian Bergomi model that consistently outperform their rough counterpart in capturing SPX smiles between one week and three years with only 3 to 4 calibratable parameters. \\end{abstract}",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03345"
    },
    {
        "doc_id": 278,
        "title": "Negatively dependent optimal risk sharing",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Risk Management"
        ],
        "abstract": "We analyze the problem of optimally sharing risk using allocations that exhibit counter-monotonicity, the most extreme form of negative dependence. Counter-monotonic allocations take the form of either \"winner-takes-all\" lotteries or \"loser-loses-all\" lotteries, and we respectively refer to these (normalized) cases as jackpot or scapegoat allocations. Our main theorem, the counter-monotonic improvement theorem, states that for a given set of random variables that are either all bounded from below or all bounded from above, one can always find a set of counter-monotonic random variables such that each component is greater or equal than its counterpart in the convex order. We show that Pareto optimal allocations, if they exist, must be jackpot allocations when all agents are risk seeking. We essentially obtain the opposite when all agents have discontinuous Bernoulli utility functions, as scapegoat allocations maximize the probability of being above the discontinuity threshold. We also consider the case of rank-dependent expected utility (RDU) agents and find conditions which guarantee that RDU agents prefer jackpot allocations. We provide an application for the mining of cryptocurrencies and show that in contrast to risk-averse miners, RDU miners with small computing power never join a mining pool. Finally, we characterize the competitive equilibria with risk-seeking agents, providing a first and second fundamental theorem of welfare economics where all equilibrium allocations are jackpot allocations.",
        "comments": "35 pages, 1 figure, Keywords: Pareto optimality, Risk sharing, Counter-monotonicity, Risk seeking, Rank-dependent expected utility, Cryptocurrency mining pools",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03328"
    },
    {
        "doc_id": 279,
        "title": "Optimal Order Execution subject to Reservation Strategies under Execution Risk",
        "authors": [
            "Xue Cheng",
            "Peng Guo",
            "Tai-ho Wang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under order fill uncertainty. A broker-dealer agency is authorized to execute an order of trading on client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reservation strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon. Optimal strategy in feedback form is obtained in closed form. In the absence of execution risk, the optimal strategies subject to reservation strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reservation strategies using implementation shortfall and target close orders as basis. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03305"
    },
    {
        "doc_id": 280,
        "title": "Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning",
        "authors": [
            "Hong-Gi Shin",
            "Sukhyun Jeong",
            "Eui-Yeon Kim",
            "Sungho Hong",
            "Young-Jin Cho",
            "Yong-Hoon Choi"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence"
        ],
        "abstract": "Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.",
        "comments": "Accepted by ICOIN 2024",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02710"
    },
    {
        "doc_id": 281,
        "title": "Displaying risk in mergers: a diagrammatic approach for exchange ratio determination",
        "authors": [
            "Alessandra Mainini",
            "Enrico Moretto",
            "Daniela Visetti"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This article extends, in a stochastic setting, previous results in the determination of feasible exchange ratios for merging companies. A first outcome is that shareholders of the companies involved in the merging process face both an upper and a lower bounds for acceptable exchange ratios. Secondly, in order for the improved `bargaining region' to be intelligibly displayed, the diagrammatic approach developed by Kulpa is exploited.",
        "comments": " ",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02681"
    },
    {
        "doc_id": 282,
        "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization Approach",
        "authors": [
            "Albert Dorador"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02601"
    },
    {
        "doc_id": 283,
        "title": "Opinion formation in the world trade network",
        "authors": [
            "C\u00e9lestin Coquid\u00e9",
            "Jos\u00e9 Lages",
            "Dima L. Shepelyansky"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Mechanics",
            "Social and Information Networks",
            "Physics and Society"
        ],
        "abstract": "We extend the opinion formation approach to probe the world influence of economical organizations. Our opinion formation model mimics a battle between currencies within the international trade network. Based on the United Nations Comtrade database, we construct the world trade network for the years of the last decade from 2010 to 2020. We consider different core groups constituted by countries preferring to trade in a specific currency. We will consider principally two core groups, namely, 5 Anglo-Saxon countries which prefer to trade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical currency, hereafter called BRI, pegged to their economies. We determine the trade currency preference of the other countries via a Monte Carlo process depending on the direct transactions between the countries. The results obtained in the frame of this mathematical model show that starting from year 2014 the majority of the world countries would have preferred to trade in BRI than USD. The Monte Carlo process reaches a steady state with 3 distinct groups: two groups of countries preferring, whatever is the initial distribution of the trade currency preferences, to trade, one in BRI and the other in USD, and a third group of countries swinging as a whole between USD and BRI depending on the initial distribution of the trade currency preferences. We also analyze the battle between USD, EUR and BRI, and present the reduced Google matrix description of the trade relations between the Anglo-Saxon countries and the BRICS+.",
        "comments": "16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02378"
    },
    {
        "doc_id": 284,
        "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
        "authors": [
            "Zeynep Hilal Kilimci",
            "Mustafa Yalcin"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02124"
    },
    {
        "doc_id": 285,
        "title": "Forecasting Bitcoin Volatility: A Comparative Analysis of Volatility Approaches",
        "authors": [
            "Cristina Chinazzo",
            "Vahidin Jeleskovic"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper conducts an extensive analysis of Bitcoin return series, with a primary focus on three volatility metrics: historical volatility (calculated as the sample standard deviation), forecasted volatility (derived from GARCH-type models), and implied volatility (computed from the emerging Bitcoin options market). These measures of volatility serve as indicators of market expectations for conditional volatility and are compared to elucidate their differences and similarities. The central finding of this study underscores a notably high expected level of volatility, both on a daily and annual basis, across all the methodologies employed. However, it's crucial to emphasize the potential challenges stemming from suboptimal liquidity in the Bitcoin options market. These liquidity constraints may lead to discrepancies in the computed values of implied volatility, particularly in scenarios involving extreme moneyness or maturity. This analysis provides valuable insights into Bitcoin's volatility landscape, shedding light on the unique characteristics and dynamics of this cryptocurrency within the context of financial markets.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02049"
    },
    {
        "doc_id": 286,
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "subjects": [
            "Computational Finance",
            "Numerical Analysis"
        ],
        "abstract": "This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01758"
    },
    {
        "doc_id": 287,
        "title": "Text mining arXiv: a look through quantitative finance papers",
        "authors": [
            "Michele Leonardo Bianchi"
        ],
        "subjects": [
            "Digital Libraries",
            "Information Retrieval",
            "General Finance"
        ],
        "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01751"
    },
    {
        "doc_id": 288,
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "authors": [
            "Lioba Heimbach",
            "Vabuk Pahari",
            "Eric Schertenleib"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.\n  In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum's biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 137 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum's total block value and outline possible mitigations.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01622"
    },
    {
        "doc_id": 289,
        "title": "An arbitrage driven price dynamics of Automated Market Makers in the presence of fees",
        "authors": [
            "Joseph Najnudel",
            "Shen-Ning Tung",
            "Kazutoshi Yamazaki",
            "Ju-Yi Yen"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",
        "comments": " ",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01526"
    },
    {
        "doc_id": 290,
        "title": "Nash Equilibria in Greenhouse Gas Offset Credit Markets",
        "authors": [
            "Liam Welsh",
            "Sebastian Jaimungal"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "In response to the global climate crisis, governments worldwide are introducing legislation to reduce greenhouse gas (GHG) emissions to help mitigate environmental catastrophes. One method to encourage emission reductions is to incentivize carbon capturing and carbon reducing projects while simultaneously penalising excess GHG output. Firms that invest in carbon capturing projects or reduce their emissions can receive offset credits (OCs) in return. These OCs can be used for regulatory purposes to offset their excess emissions in a compliance period. OCs may also be traded between firms. Thus, firms have the choice between investing in projects to generate OCs or to trade OCs. In this work, we present a novel market framework and characterise the optimal behaviour of GHG OC market participants in both single-player and two-player settings. We analyse both a single-period and multi-period setting. As the market model does not elicit a closed form solution, we develop a numerical methodology to estimate players' optimal behaviours in accordance to the Nash equilibria. Our findings indicate the actions players take are dependent on the scale of their project opportunities as well as their fellow market participants. We demonstrate the importance of behaving optimally via simulations in order to offset emission penalties and the importance of investing in GHG reducing or capturing projects from a financial perspective.",
        "comments": "MSC Class:          91G99; 35Q91; 91-08; 91A80; 91B74",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01427"
    },
    {
        "doc_id": 291,
        "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces",
        "authors": [
            "Farshud Sorourifar",
            "Thomas Banker",
            "Joel A. Paulson"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.",
        "comments": "9 pages, 2 figures consisting of 6 and 4 plots, accepted to NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01398"
    },
    {
        "doc_id": 292,
        "title": "Almost Perfect Shadow Prices",
        "authors": [
            "Eberhard Mayerhofer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a na\u00efve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",
        "comments": "15 pages",
        "date": "1 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00970"
    },
    {
        "doc_id": 293,
        "title": "A Portfolio's Common Causal Conditional Risk-neutral PDE",
        "authors": [
            "Alejandro Rodriguez Dominguez"
        ],
        "subjects": [
            "Portfolio Management",
            "Mathematical Finance"
        ],
        "abstract": "Portfolio's optimal drivers for diversification are common causes of the constituents' correlations. A closed-form formula for the conditional probability of the portfolio given its optimal common drivers is presented, with each pair constituent-common driver joint distribution modelled by Gaussian copulas. A conditional risk-neutral PDE is obtained for this conditional probability as a system of copulas' PDEs, allowing for dynamical risk management of a portfolio as shown in the experiments. Implied conditional portfolio volatilities and implied weights are new risk metrics that can be dynamically monitored from the PDEs or obtained from their solution.",
        "comments": "6 pages, 4 figures, Mathematical and Statistical Methods for Actuarial Sciences and Finance - MAF2024",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00949"
    },
    {
        "doc_id": 294,
        "title": "Intraday Trading Algorithm for Predicting Cryptocurrency Price Movements Using Twitter Big Data Analysis",
        "authors": [
            "Vahidin Jeleskovic",
            "Stephen Mackay"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Cryptocurrencies have emerged as a novel financial asset garnering significant attention in recent years. A defining characteristic of these digital currencies is their pronounced short-term market volatility, primarily influenced by widespread sentiment polarization, particularly on social media platforms such as Twitter. Recent research has underscored the correlation between sentiment expressed in various networks and the price dynamics of cryptocurrencies. This study delves into the 15-minute impact of informative tweets disseminated through foundation channels on trader behavior, with a focus on potential outcomes related to sentiment polarization. The primary objective is to identify factors that can predict positive price movements and potentially be leveraged through a trading algorithm. To accomplish this objective, we conduct a conditional examination of return and excess return rates within the 15 minutes following tweet publication. The empirical findings reveal statistically significant increases in return rates, particularly within the initial three minutes following tweet publication. Notably, adverse effects resulting from the messages were not observed. Surprisingly, sentiments were found to have no discerni-ble impact on cryptocurrency price movements. Our analysis further identifies that inves-tors are primarily influenced by the quality of tweet content, as reflected in the choice of words and tweet volume. While the basic trading algorithm presented in this study does yield some benefits within the 15-minute timeframe, these benefits are not statistically significant. Nevertheless, it serves as a foundational framework for potential enhance-ments and further investigations.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00603"
    },
    {
        "doc_id": 295,
        "title": "On the implied volatility of Inverse and Quanto Inverse options under stochastic volatility models",
        "authors": [
            "Elisa Al\u00f2s",
            "Eulalia Nualart",
            "Makar Pravosud"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "In this paper we study short-time behavior of the at-the-money implied volatility for Inverse and Quanto Inverse European options with fixed strike price. The asset price is assumed to follow a general stochastic volatility process. Using techniques of the Malliavin calculus such as the anticipating Ito's formula we first compute the level of the implied volatility of the option when the maturity converges to zero. Then, we find a short maturity asymptotic formula for the skew of the implied volatility that depends on the roughness of the volatility model. We apply our general results to the SABR and fractional Bergomi models, and provide some numerical simulations that confirm the accurateness of the asymptotic formula for the skew.",
        "comments": "arXiv admin note: text overlap with arXiv:2308.15341, arXiv:2208.01353",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00539"
    },
    {
        "doc_id": 296,
        "title": "Financial Time-Series Forecasting: Towards Synergizing Performance And Interpretability Within a Hybrid Machine Learning Approach",
        "authors": [
            "Shun Liu",
            "Kexin Wu",
            "Chufeng Jiang",
            "Bin Huang",
            "Danqing Ma"
        ],
        "subjects": [
            "Machine Learning",
            "Statistical Finance"
        ],
        "abstract": "In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered substantial attention due to its potential impact on financial markets and investment strategies. This paper propose a comparative study on hybrid machine learning algorithms and leverage on enhancing model interpretability. Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM), decision tree regressors are introduced. Through the grounded experiments, we observe linear regressor achieves the best performance among candidate models. For the interpretability, we carry out a systematic overview on the preprocessing techniques of time-series statistics, including decomposition, auto-correlational function, exponential triple forecasting, which aim to excavate latent relations and complex patterns appeared in the financial time-series forecasting. We believe this work may derive more attention and inspire more researches in the realm of time-series analysis and its realistic applications.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00534"
    },
    {
        "doc_id": 297,
        "title": "Optimization of portfolios with cryptocurrencies: Markowitz and GARCH-Copula model approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Claudio Latini",
            "Zahid I. Younas",
            "Mamdouh A. S. Al-Faryan"
        ],
        "subjects": [
            "Portfolio Management",
            "Applications"
        ],
        "abstract": "The growing interest in cryptocurrencies has drawn the attention of the financial world to this innovative medium of exchange. This study aims to explore the impact of cryptocurrencies on portfolio performance. We conduct our analysis retrospectively, assessing the performance achieved within a specific time frame by three distinct portfolios: one consisting solely of equities, bonds, and commodities; another composed exclusively of cryptocurrencies; and a third, which combines both 'traditional' assets and the best-performing cryptocurrency from the second portfolio.To achieve this, we employ the classic variance-covariance approach, utilizing the GARCH-Copula and GARCH-Vine Copula methods to calculate the risk structure. The optimal asset weights within the optimized portfolios are determined through the Markowitz optimization problem. Our analysis predominantly reveals that the portfolio comprising both cryptocurrency and traditional assets exhibits a higher Sharpe ratio from a retrospective viewpoint and demonstrates more stable performances from a prospective perspective. We also provide an explanation for our choice of portfolio optimization based on the Markowitz approach rather than CVaR and ES.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00507"
    },
    {
        "doc_id": 298,
        "title": "A framework for the valuation of insurance liabilities by production cost",
        "authors": [
            "Christoph Moehr"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "This paper sets out a framework for the valuation of insurance liabilities that is intended to be economically realistic, elementary, reasonably practically applicable, and as a special case to provide a basis for the valuation in regulatory solvency systems such as Solvency II and the SST. The valuation framework is based on the cost of producing the liabilities to an insurance company that is subject to solvency regulation (regulatory solvency capital requirements) and insolvency laws (consequences of failure) in finite discrete time. Starting from the replication approach of classical no-arbitrage theory, the framework additionally considers the nature and cost of capital (expressed by a ``financiability condition\"), that the liabilities may be required to be fulfilled only ``in sufficiently many cases\" (expressed by a ``fulfillment condition\"), production using ``fully illiquid\" assets in addition to tradables, and the asymmetry between assets and liabilities. We identify necessary and sufficient conditions on the capital investment under which the framework recovers the market prices of tradables, investigate extending production to take account of insolvency, implications of using illiquid assets in the production, and show how Solvency II and SST valuation can be derived with specific assumptions.",
        "comments": "35 pages, no figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00263"
    },
    {
        "doc_id": 299,
        "title": "Enhancing CVaR portfolio optimisation performance with GAM factor models",
        "authors": [
            "Davide Lauria",
            "W. Brent Lindquist",
            "Svetlozar T. Rachev"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "We propose a discrete-time econometric model that combines autoregressive filters with factor regressions to predict stock returns for portfolio optimisation purposes. In particular, we test both robust linear regressions and general additive models on two different investment universes composed of the Dow Jones Industrial Average and the Standard & Poor's 500 indexes, and we compare the out-of-sample performances of mean-CVaR optimal portfolios over a horizon of six years. The results show a substantial improvement in portfolio performances when the factor model is estimated with general additive models.",
        "comments": " ",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00188"
    },
    {
        "doc_id": 300,
        "title": "Zero-Shot Learning for the Primitives of 3D Affordance in General Objects",
        "authors": [
            "Hyeonwoo Kim",
            "Sookwan Han",
            "Patrick Kwon",
            "Hanbyul Joo"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "One of the major challenges in AI is teaching machines to precisely respond and utilize environmental functionalities, thereby achieving the affordance awareness that humans possess. Despite its importance, the field has been lagging in terms of learning, especially in 3D, as annotating affordance accompanies a laborious process due to the numerous variations of human-object interaction. The low availability of affordance data limits the learning in terms of generalization for object categories, and also simplifies the representation of affordance, capturing only a fraction of the affordance. To overcome these challenges, we propose a novel, self-supervised method to generate the 3D affordance examples given only a 3D object, without any manual annotations. The method starts by capturing the 3D object into images and creating 2D affordance images by inserting humans into the image via inpainting diffusion models, where we present the Adaptive Mask algorithm to enable human insertion without altering the original details of the object. The method consequently lifts inserted humans back to 3D to create 3D human-object pairs, where the depth ambiguity is resolved within a depth optimization framework that utilizes pre-generated human postures from multiple viewpoints. We also provide a novel affordance representation defined on relative orientations and proximity between dense human and object points, that can be easily aggregated from any 3D HOI datasets. The proposed representation serves as a primitive that can be manifested to conventional affordance representations via simple transformations, ranging from physically exerted affordances to nonphysical ones. We demonstrate the efficacy of our method and representation by generating the 3D affordance samples and deriving high-quality affordance examples from the representation, including contact, orientation, and spatial occupancies.",
        "comments": "Project Page: https://sshowbiz.github.io/ZSP3A/",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12978"
    },
    {
        "doc_id": 301,
        "title": "IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images",
        "authors": [
            "Zhi-Hao Lin",
            "Jia-Bin Huang",
            "Zhengqin Li",
            "Zhao Dong",
            "Christian Richardt",
            "Tuotuo Li",
            "Michael Zollh\u00f6fer",
            "Johannes Kopf",
            "Shenlong Wang",
            "Changil Kim"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Graphics"
        ],
        "abstract": "While numerous 3D reconstruction and novel-view synthesis methods allow for photorealistic rendering of a scene from multi-view images easily captured with consumer cameras, they bake illumination in their representations and fall short of supporting advanced applications like material editing, relighting, and virtual object insertion. The reconstruction of physically based material properties and lighting via inverse rendering promises to enable such applications.\n  However, most inverse rendering techniques require high dynamic range (HDR) images as input, a setting that is inaccessible to most users. We present a method that recovers the physically based material properties and spatially-varying HDR lighting of a scene from multi-view, low-dynamic-range (LDR) images. We model the LDR image formation process in our inverse rendering pipeline and propose a novel optimization strategy for material, lighting, and a camera response model. We evaluate our approach with synthetic and real scenes compared to the state-of-the-art inverse rendering methods that take either LDR or HDR input. Our method outperforms existing methods taking LDR images as input, and allows for highly realistic relighting and object insertion.",
        "comments": "Project Website: https://irisldr.github.io/",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12977"
    },
    {
        "doc_id": 302,
        "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments",
        "authors": [
            "Qinhong Zhou",
            "Sunli Chen",
            "Yisong Wang",
            "Haozhe Xu",
            "Weihua Du",
            "Hongxin Zhang",
            "Yilun Du",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language"
        ],
        "abstract": "Recent advances in high-fidelity virtual environments serve as one of the major driving forces for building intelligent embodied agents to perceive, reason and interact with the physical world. Typically, these environments remain unchanged unless agents interact with them. However, in real-world scenarios, agents might also face dynamically changing environments characterized by unexpected events and need to rapidly take action accordingly. To remedy this gap, we propose a new simulated embodied benchmark, called HAZARD, specifically designed to assess the decision-making abilities of embodied agents in dynamic situations. HAZARD consists of three unexpected disaster scenarios, including fire, flood, and wind, and specifically supports the utilization of large language models (LLMs) to assist common sense reasoning and decision-making. This benchmark enables us to evaluate autonomous agents' decision-making capabilities across various pipelines, including reinforcement learning (RL), rule-based, and search-based methods in dynamically changing environments. As a first step toward addressing this challenge using large language models, we further develop an LLM-based agent and perform an in-depth analysis of its promise and challenge of solving these challenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.",
        "comments": "ICLR 2024. The first two authors contributed equally to this work",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12975"
    },
    {
        "doc_id": 303,
        "title": "The classical limit of Quantum Max-Cut",
        "authors": [
            "Vir B. Bulchandani",
            "Stephen Piddock"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks",
            "Statistical Mechanics",
            "Strongly Correlated Electrons"
        ],
        "abstract": "It is well-known in physics that the limit of large quantum spin $S$ should be understood as a semiclassical limit. This raises the question of whether such emergent classicality facilitates the approximation of computationally hard quantum optimization problems, such as the local Hamiltonian problem. We demonstrate this explicitly for spin-$S$ generalizations of Quantum Max-Cut ($\\mathrm{QMaxCut}_S$), equivalent to the problem of finding the ground state energy of an arbitrary spin-$S$ quantum Heisenberg antiferromagnet ($\\mathrm{AFH}_S$). We prove that approximating the value of $\\mathrm{AFH}_S$ to inverse polynomial accuracy is QMA-complete for all $S$, extending previous results for $S=1/2$. We also present two distinct families of classical approximation algorithms for $\\mathrm{QMaxCut}_S$ based on rounding the output of a semidefinite program to a product of Bloch coherent states. The approximation ratios for both our proposed algorithms strictly increase with $S$ and converge to the Bri\u00ebt-Oliveira-Vallentin approximation ratio $\u03b1_{\\mathrm{BOV}} \\approx 0.956$ from below as $S \\to \\infty$.",
        "comments": "19+4 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12968"
    },
    {
        "doc_id": 304,
        "title": "Proton-cluster femtoscopy with the HADES experiment",
        "authors": [
            "Maria Stefaniak"
        ],
        "subjects": [
            "Nuclear Experiment",
            "High Energy Physics - Experiment"
        ],
        "abstract": "The matter created in Ag+Ag collisions at $\\sqrt{s_{NN}}$ = 2.55 GeV, as measured with the HADES experiment, can be characterized by similar thermodynamic quantities as Neutron Star Mergers, thus becoming an essential reference for the understanding of these compact stellar objects. One of the methods applied to investigate heavy-ion collisions are femtoscopic correlations. They are a unique tool for the determination of the interactions between hadrons and allow to search for possible exited or unbound states of nuclear matter. We performed precise experimental studies of the correlations between protons and different clusters and compared them with the existing theoretical descriptions.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12966"
    },
    {
        "doc_id": 305,
        "title": "Workspace Optimization Techniques to Improve Prediction of Human Motion During Human-Robot Collaboration",
        "authors": [
            "Yi-Shiuan Tung",
            "Matthew B. Luebbers",
            "Alessandro Roncone",
            "Bradley Hayes"
        ],
        "subjects": [
            "Robotics"
        ],
        "abstract": "Understanding human intentions is critical for safe and effective human-robot collaboration. While state of the art methods for human goal prediction utilize learned models to account for the uncertainty of human motion data, that data is inherently stochastic and high variance, hindering those models' utility for interactions requiring coordination, including safety-critical or close-proximity tasks. Our key insight is that robot teammates can deliberately configure shared workspaces prior to interaction in order to reduce the variance in human motion, realizing classifier-agnostic improvements in goal prediction. In this work, we present an algorithmic approach for a robot to arrange physical objects and project \"virtual obstacles\" using augmented reality in shared human-robot workspaces, optimizing for human legibility over a given set of tasks. We compare our approach against other workspace arrangement strategies using two human-subjects studies, one in a virtual 2D navigation domain and the other in a live tabletop manipulation domain involving a robotic manipulator arm. We evaluate the accuracy of human motion prediction models learned from each condition, demonstrating that our workspace optimization technique with virtual obstacles leads to higher robot prediction accuracy using less training data.",
        "comments": "International Conference on Human-Robot Interaction",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12965"
    },
    {
        "doc_id": 306,
        "title": "AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents",
        "authors": [
            "Michael Ahn",
            "Debidatta Dwibedi",
            "Chelsea Finn",
            "Montse Gonzalez Arenas",
            "Keerthana Gopalakrishnan",
            "Karol Hausman",
            "Brian Ichter",
            "Alex Irpan",
            "Nikhil Joshi",
            "Ryan Julian",
            "Sean Kirmani",
            "Isabel Leal",
            "Edward Lee",
            "Sergey Levine",
            "Yao Lu",
            "Isabel Leal",
            "Sharath Maddineni",
            "Kanishka Rao",
            "Dorsa Sadigh",
            "Pannag Sanketi",
            "Pierre Sermanet",
            "Quan Vuong",
            "Stefan Welker",
            "Fei Xia",
            "Ted Xiao",
            "et al. (3 additional authors not shown)"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multiple buildings and collecting 77k real robot episodes via both teleoperation and autonomous robot policies. We experimentally show that such \"in-the-wild\" data collected by AutoRT is significantly more diverse, and that AutoRT's use of LLMs allows for instruction following data collection robots that can align to human preferences.",
        "comments": "26 pages, 9 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12963"
    },
    {
        "doc_id": 307,
        "title": "Framework for the Quantum Mechanical Sum of Possibilities and Meaning for Field Theory and Gravity",
        "authors": [
            "Artem Averin"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "In quantum mechanics, the measureable quantities of a given theory are predicted by performing a weighted sum over possibilities. We show how to arrange the possibilities into bundles such that the associated subsums can be viewed as well-defined theories on their own right. These bundles are submani$\\textit{folds}$ of $\\textit{possi}$bilities which we call possifolds. We collect and prove some basic facts about possifolds. Especially, we show that possifolds are ensembles of what in a certain broadly defined sense that we explain can be regarded as soliton excitations (soliton-possifold correspondence). We provide an outlook on some applications. Among other things, we illustrate the use of the developed framework for the example of the Lieb-Liniger model. It describes non-relativistic bosons with an attractive interaction. We derive a dual theory describing the lowest-lying energy excitation modes. While the standard Bogoliubov-approximation breaks down at the critical point, our derived summation prescription stays regular. In the Bogoliubov-limit we observe the summation to possess an enhanced symmetry at this point while the summation cannot be ignored there. We finally provide a glimpse on the restrictions black hole physics implies in this context for the gravitational path integral.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12960"
    },
    {
        "doc_id": 308,
        "title": "Non-Gaussianity consistency relations and their consequences for the peaks",
        "authors": [
            "Mohammad Hossein Namjoo",
            "Bahar Nikbakht"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics",
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Theory"
        ],
        "abstract": "Strong deviations from scale invariance and the appearance of high peaks in the primordial power spectrum have been extensively studied for generating primordial black holes (PBHs) or gravitational waves (GWs). It is also well-known that the effect of non-linearities can be significant in both phenomena. In this paper, we advocate the existence of a general single-field consistency relation that relates the amplitude of non-Gaussianity in the squeezed limit $f_{\\text{NL}}$ to the power spectrum and remains valid when almost all other consistency relations are violated. In particular, it is suitable for studying scenarios where scale invariance is strongly violated. We discuss the general and model-independent consequences of the consistency relation on the behavior of $f_{\\text{NL}}$ at different scales. Specifically, we study the size, sign and slope of $f_{\\text{NL}}$ at the scales where the power spectrum peaks and argue that generally the peaks of $f_{\\text{NL}}$ and the power spectrum occur at different scales. As an implication of our results, we argue that non-linearities can shift or extend the range of scales responsible for the production of PBHs or GWs, relative to the window as determined by the largest peak of the power spectrum, and may also open up new windows for both phenomena.",
        "comments": "18 pages, 4 figures, an appendix",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12958"
    },
    {
        "doc_id": 309,
        "title": "Symmetry Duality: Exploring Exotic Oscillators And Dissipative Dynamics Through The Glass Of Newton-Hooke",
        "authors": [
            "Sayan Kumar Pal",
            "Partha Nandi"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Other Condensed Matter",
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "Motivated by the symmetry in the non-relativistic limit of anti-de Sitter geometry, we employ planar dynamical models featuring exotic (deformed) harmonic oscillators, presented through direct and indirect Lagrangian representations. The latter introduces Bateman dissipative oscillator system. Analyzing these dynamic systems with a first-order Lagrangian scheme, our phase-space-based approach utilizes the moment map components to reveal the underlying symmetry algebra. This obtained algebra, interpreted as an extended version of Newton-Hooke (NH) cosmological symmetry algebras, has the potential to cast an augmented non-relativistic shadow over the expanding universe, offering an insightful perspective on extended NH spacetime in 2+1 dimensions through our dynamical realizations.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12957"
    },
    {
        "doc_id": 310,
        "title": "Observation of topologically protected compact edge states in flux-dressed graphene photonic lattices",
        "authors": [
            "Gabriel C\u00e1ceres-Aravena",
            "Milica Nedi\u0107",
            "Paloma Vildoso",
            "Goran Gligori\u0107",
            "Jovana Petrovic",
            "Rodrigo A. Vicencio",
            "Aleksandra Maluckov"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Optics"
        ],
        "abstract": "Systems with engineered flatband spectra are a postulate of high-capacity transmission links and a candidate for high-temperature superconductivity. However, their operation relies on the edge or surface modes susceptible to fluctuations and fabrication errors. While the mode robustness can be enhanced by a combination of Aharonov-Bohm caging and topological insulation, the design of the corresponding flatbands requires approaches beyond the standard $k$-vector-based methods. Here, we propose a synthetic-flux probe as a solution to this problem and a route to the realization of ultra-stable modes. We prove the concept in a laser-fabricated graphene-like ribbon photonic lattice with the band-flattening flux induced by \"P\" waveguide coupling. The topological non-triviality is witnessed by an integer Zak phase derived from the mean chiral displacement. Mode stability is evidenced by excellent mode localization and the robustness to fabrication tolerances and variations of the input phase. Our results can serve as a basis for the development of multi-flat-band materials for low-energy electronics.",
        "comments": "12 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12949"
    },
    {
        "doc_id": 311,
        "title": "Modern nuclear and astrophysical constraints of dense matter in a renormalized chiral approach",
        "authors": [
            "Rajesh Kumar",
            "Yuhan Wang",
            "Nikolas Cruz Camacho",
            "Arvind Kumar",
            "Jacquelyn Noronha-Hostler",
            "Veronica Dexheimer"
        ],
        "subjects": [
            "Nuclear Theory",
            "High Energy Astrophysical Phenomena",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We explore the Quantum Chromodynamics (QCD) phase diagram's complexities, including quark deconfinement transitions, liquid-gas phase changes, and critical points, using the chiral mean-field (CMF) model that is able to capture all these features. We introduce a vector meson renormalization within the CMF framework, enabling precise adjustments of meson masses and coupling strengths related to vector meson interactions. Performing a new fit to the deconfinement potential, we are able to replicate recent lattice QCD results, low energy nuclear physics properties, neutron star observational data, and key phase diagram features as per modern constraints. This approach enhances our understanding of vector mesons' roles in mediating nuclear interactions and their impact on the equation of state, contributing to a more comprehensive understanding of the QCD phase diagram and its implications for nuclear and astrophysical phenomena.",
        "comments": "19 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12944"
    },
    {
        "doc_id": 312,
        "title": "Nonlinear dynamics in neuromorphic photonic networks: physical simulation in Verilog-A",
        "authors": [
            "Hugh Morison",
            "Jagmeet Singh",
            "Nayem Al Kayed",
            "A. Aadhi",
            "Maryam Moridsadat",
            "Marcus Tamura",
            "Alexander N. Tait",
            "Bhavin J. Shastri"
        ],
        "subjects": [
            "Emerging Technologies",
            "Applied Physics",
            "Optics"
        ],
        "abstract": "Advances in silicon photonics technology have enabled the field of neuromorphic photonics, where analog neuron-like processing elements are implemented in silicon photonics technology. Accurate and scalable simulation tools for photonic integrated circuits are critical for designing neuromorphic photonic circuits. This is especially important when designing networks with recurrent connections, where the dynamics of the system may give rise to unstable and oscillatory solutions which need to be accurately modelled. These tools must simultaneously simulate the analog electronics and the multi-channel (wavelength-division-multiplexed) photonics contained in a photonic neuron to accurately predict on-chip behaviour. In this paper, we utilize a Verilog-A model of the photonic neural network to investigate the dynamics of recurrent integrated circuits. We begin by reviewing the theory of continuous-time recurrent neural networks as dynamical systems and the relation of these dynamics to important physical features of photonic neurons such as cascadability. We then present the neural dynamics of systems of one and two neurons in the simulated Verilog-A circuit, which are compared to the expected dynamics of the abstract CTRNN model. Due to the presence of parasitic circuit elements in the Verilog-A simulation, it is seen that there is a topological equivalence, but not an exact isomorphism, between the theoretical model and the simulated model. The implications of these discrepancies for the design of neuromorphic photonic circuits are discussed. Our findings pave the way for the practical implementation of large-scale silicon photonic recurrent neural networks.",
        "comments": "17 pages, 9 figures. Submitted to Physical Review Applied",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12942"
    },
    {
        "doc_id": 313,
        "title": "Long-range three-dimensional tracking of nanoparticles using interferometric scattering (iSCAT) microscopy",
        "authors": [
            "Kiarash Kasaian",
            "Mahdi Mazaheri",
            "Vahid Sandoghdar"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Tracking nanoparticle movement is highly desirable in many scientific areas, and various imaging methods have been employed to achieve this goal. Interferometric scattering (iSCAT) microscopy has been particularly successful in combining very high spatial and temporal resolution for tracking small nanoparticles in all three dimensions. However, previous works have been limited to an axial range of only a few hundred nanometers. Here, we present a robust and efficient strategy for localizing nanoparticles recorded in high-speed iSCAT videos in three dimensions over tens of micrometers. We showcase the performance of our algorithm by tracking gold nanoparticles as small as 10 nm diffusing in water while maintaining 5 \u03bcs temporal resolution and nanometer axial localization precision. Our results hold promise for applications in cell biology and material science, where the three-dimensional motion of nanoparticles in complex media is of interest.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12939"
    },
    {
        "doc_id": 314,
        "title": "Analytic Nuclear Gradients for Complete Active Space Linearized Pair-Density Functional Theory",
        "authors": [
            "Matthew R. Hennefarth",
            "Matthew R. Hermes",
            "Donald G. Truhlar",
            "Laura Gagliardi"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Accurately modeling photochemical reactions is difficult due to the presence of conical intersections and locally avoided crossings as well as the inherently multiconfigurational character of excited states. As such, one needs a multi-state method that incorporates state interaction in order to accurately model the potential energy surface at all nuclear coordinates. The recently developed linearized pair-density functional theory (L-PDFT) is a multi-state extension of multiconfiguration PDFT, and it has been shown to be a cost-effective post-MCSCF method (as compared to more traditional and expensive multireference many-body perturbation methods or multireference configuration interaction methods) that can accurately model potential energy surfaces in regions of strong nuclear-electronic coupling in addition to accurately predicting Franck-Condon vertical excitations. In this paper, we report the derivation of analytic gradients for L-PDFT and their implementation in the PySCF-forge software, and we illustrate the utility of these gradients for predicting ground- and excited-state equilibrium geometries and adiabatic excitation energies for formaldehyde, s-trans-butadiene, phenol, and cytosine.",
        "comments": "23 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12933"
    },
    {
        "doc_id": 315,
        "title": "Unveiling the Role of Electron-Phonon Scattering in Dephasing High-Order Harmonics in Solids",
        "authors": [
            "Viacheslav Korolev",
            "Thomas Lettau",
            "Vipin Krishna",
            "Alexander Croy",
            "Michael Zuerch",
            "Christian Spielmann",
            "Maria Waechtler",
            "Ulf Peschel",
            "Stefanie Graefe",
            "Giancarlo Soavi",
            "Daniil Kartashov"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "High-order harmonic generation (HHG) in solids is profoundly influenced by the dephasing of the coherent electron-hole motion driven by an external laser field. The exact physical mechanisms underlying this dephasing, crucial for accurately understanding and modelling HHG spectra, have remained elusive and controversial, often regarded more as an empirical observation than a firmly established principle. In this work, we present comprehensive experimental findings on the wavelength-dependency of HHG in both single-atomic-layer and bulk semiconductors. These findings are further corroborated by rigorous numerical simulations, employing ab initio real-time, real-space time-dependent density functional theory and semiconductor Bloch equations. Our experimental observations necessitate the introduction of a novel concept: a momentum-dependent dephasing time in HHG. Through detailed analysis, we pinpoint momentum-dependent electron-phonon scattering as the predominant mechanism driving dephasing. This insight significantly advances the understanding of dephasing phenomena in solids, addressing a long-standing debate in the field. Furthermore, our findings pave the way for a novel, all-optical measurement technique to determine electron-phonon scattering rates and establish fundamental limits to the efficiency of HHG in condensed matter.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12929"
    },
    {
        "doc_id": 316,
        "title": "The fiber bundle structure of General Relativity in Ashtekar variables",
        "authors": [
            "Matteo Bruno"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "In this review, we aim to analyze the mathematical interpretation of the Ashtekar-Barbero-Immirzi formulation of General Relativity. Along with a brief introduction to the necessary mathematical structures and tools, we illustrate some relevant physical theory quantities as geometrical objects within the framework of principal bundle theory.",
        "comments": "27 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12927"
    },
    {
        "doc_id": 317,
        "title": "Flow structure beneath periodic waves with constant vorticity under strong horizontal electric Fields",
        "authors": [
            "M. V. Flamarion",
            "E. Kochurin",
            "R. Ribeiro-Jr",
            "N. Zubarev"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "While several articles have been written on Electrohydrodynamics (EHD) flows or flows with constant vorticity separately, little is known about the extent to which the combined effects of EHD and constant vorticity affect the flow. This study aims to fill this gap by investigating how a horizontal electric field and constant vorticity jointly influence the free surface and the emergence of stagnation points. Using the Euler equations framework, we employ conformal mapping and pseudo-spectral numerical methods. Our findings reveal that increasing the electric field intensity eliminates stagnation points and smoothen the wave profile. This implies that a horizontal electric field acts as a mechanism for the elimination of stagnation points within the fluid body.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12922"
    },
    {
        "doc_id": 318,
        "title": "Active Inference as a Model of Agency",
        "authors": [
            "Lancelot Da Costa",
            "Samuel Tenka",
            "Dominic Zhao",
            "Noor Sajid"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \\emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \\emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an explainable mixture of exploration and exploitation under a generative world model, and all differences in behaviour are explicit in differences in world model. \\emph{c}) This framework is universal in the sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of active inference as an active inference algorithm. Thus, active inference can be used as a tool to uncover and compare the commitments and assumptions of more specific models of agency.",
        "comments": "Accepted in RLDM2022 for the workshop 'RL as a model of agency'",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12917"
    },
    {
        "doc_id": 319,
        "title": "Episodic X-ray Outflows from the Tidal Disruption Event ASASSN-14li",
        "authors": [
            "Yukta Ajay",
            "Dheeraj R. Pasham",
            "Thomas Wevers",
            "Eric R. Coughlin",
            "Francesco Tombesi",
            "Muryel Guolo",
            "James F. Steiner"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Astrophysics of Galaxies"
        ],
        "abstract": "ASASSN-14li is a low-redshift ($z= 0.0206$) tidal disruption event (TDE) that has been studied extensively across the entire electromagnetic spectrum, and has provided one of the most sensitive measurements of a TDE to-date. Its X-ray spectrum is soft and thermal (kT$\\sim$ 0.05 keV) and shows a residual broad absorption-like feature between 0.6-0.8 keV, which can be associated with a blue-shifted O VII (rest-frame energy 0.57 keV) resulting from an ultrafast outflow (UFO) at early times (within 40 days of optical discovery). By carefully accounting for pile-up and using precise XSTAR photo-ionization table models, we analyze the entire archival X-ray data from XMM-Newton and track the evolution of this absorption feature for $\\sim$4.5 years post disruption. Our main finding is that, contrary to the previous literature, the absorption feature is transient and intermittent. Assuming the same underlying physical basis (i.e. outflows) for the recurring absorption feature in ASASSN-14li, the outflow is seen to disappear and reappear multiple times during the first $\\sim$2 years of its evolution. No observable spectral imprint is detected thereafter. While theoretical studies suggest the launch of outflows in the early phases of the outburst during the super-Eddington regime, the outflow's intermittent behavior for multiple years after disruption is unusual. We discuss this peculiar behavior within the context of varying inner disk truncation, radiation pressure, and magnetically-driven outflow scenarios.",
        "comments": "14 pages, 6 figures (Main text) + Appendix; Under review in ApJ Letters",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12908"
    },
    {
        "doc_id": 320,
        "title": "Unbounded quantum advantage in communication complexity measured by distinguishability",
        "authors": [
            "Satyaki Manna",
            "Anubhav Chaturvedi",
            "Debashis Saha"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Communication complexity is a pivotal element in information science, with quantum theory presenting a significant edge over classical approaches. The standard quantification of one-way communication complexity relies on the minimal dimension of the systems that the sender communicates to accomplish the designated task. In this study, we adopt a novel perspective, measuring the complexity of the communication by the distinguishability of the sender's input without constraining the dimension of the communicated systems. This measure becomes especially pertinent when maintaining the confidentiality of the sender's input is essential. After establishing the generic framework, we focus on two important categories of communication complexity tasks - the general version of random access codes and equality problems defined by graphs. We derive lower bounds on the distinguishability of the sender's input as a function of the success metric of these tasks in classical communication. Notably, we show that the ratio between the distinguishability in classical and quantum communication to achieve the same success metric escalates with the complexity of these tasks, reaching arbitrarily large values. Besides, we demonstrate the quantum advantage by employing qubits in solving equality problems associated with odd-cycle graphs. Furthermore, we derive lower bounds on distinguishability for another class of communication tasks, namely, pair-distinguishability tasks, and present several instances of the quantum advantage.",
        "comments": "10 pages. First draft. Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12903"
    },
    {
        "doc_id": 321,
        "title": "How Chaotic is the Dynamics Induced by a Hermitian Matrix?",
        "authors": [
            "Sven Gnutzmann",
            "Uzy Smilansky"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics",
            "Chaotic Dynamics"
        ],
        "abstract": "Given an arbitrary \\(V \\times V\\) Hermitian matrix, considered as a finite discrete quantum Hamiltonian, we use methods from graph and ergodic theories to construct a corresponding stochastic classical dynamics on an appropriate discrete phase space. It consists of the directed edges of a graph with \\(V\\) vertices that are in one-to-one correspondence with the non-vanishing off-diagonal elements of \\(H\\). The classical dynamics is a stochastic variant of a Poincar\u00e9 map at an energy \\(E\\) and an alternative to standard quantum-classical correspondence based on a classical limit \\(\\hbar \\to 0\\). Most importantly it can be constructed where no such limit exists. Using standard methods from ergodic theory we then proceed to define an expression for the Lyapunov exponent \\(\u039b(E)\\) of the classical map. It measures the rate of separation of stochastic classical trajectories in phase space. We suggest to use this Lyapunov exponent to quantify the amount of chaos in a finite quantum system.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12898"
    },
    {
        "doc_id": 322,
        "title": "Anomalous Behavior in the Nucleation of Ice at Negative Pressures",
        "authors": [
            "Valentino Bianco",
            "Pablo Montero de Hijes",
            "Cintia P. Lamas",
            "Eduardo Sanz",
            "Carlos Vega"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Ice nucleation is a phenomenon that, despite the relevant implications for life, atmospheric sciences, and technological applications, is far from being completely understood, especially under extreme thermodynamic conditions. In this work we present a computational investigation of the homogeneous ice nucleation at negative pressures. By means of the seeding technique we estimate the size of the ice critical nucleus Nc for the TIP4P/Ice water model. This is done along the isotherms 230, 240, and 250 K, from positive to negative pressures until reaching the liquid-gas kinetic stability limit (where cavitation cannot be avoided). We find that Nc is nonmonotonic upon depressurization, reaching a minimum at negative pressures in the doubly metastable region of water. According to classical nucleation theory we establish the nucleation rate J and the surface tension gamma, revealing a retracing behavior of both when the liquid-gas kinetic stability limit is approached. We also predict a reentrant behavior of the homogeneous nucleation line. The reentrance of these properties is related to the reentrance of the coexistence line at negative pressure, revealing new anomalies of water. The results of this work suggest the possibility of having metastable samples of liquid water for long times at negative pressure provided that heterogeneous nucleation is suppressed.",
        "comments": "Journal ref:        Physical Review Letters 126, 015704 (2021)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12896"
    },
    {
        "doc_id": 323,
        "title": "NICA prospects in searches for light exotics from hidden sectors: the cases of hidden photons and axion-like particles",
        "authors": [
            "Dmitry Gorbunov",
            "Dmitry Kalashnikov"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We present first estimates of NICA sensitivity to Standard Model extensions with light hypothetical particles singlet under the known gauge transformations. Our analysis reveals that NICA can explore new regions in the parameter spaces of models with a hidden vector and models with an axion-like particle of masses about 30-500\\,MeV. Some of these regions seem unreachable by other ongoing and approved future projects. NICA has good prospects in discovery ($5\u03c3$) of the new physics after 1 year of data taking.",
        "comments": "12 pages, 7 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12893"
    },
    {
        "doc_id": 324,
        "title": "Fully dynamic G3W2 self-energy for finite systems: Formulas and benchmark",
        "authors": [
            "Fabien Bruneval",
            "Arno F\u00f6rster"
        ],
        "subjects": [
            "Computational Physics",
            "Chemical Physics"
        ],
        "abstract": "Over the years, Hedin's $GW$ self-energy has been proven to be a rather accurate and simple approximation to evaluate electronic quasiparticle energies in solids and in molecules. Attempts to improve over the simple $GW$ approximation, the so-called vertex corrections, have been constantly proposed in the literature. Here, we derive, analyze, and benchmark the complete second-order term in the screened Coulomb interaction $W$ for finite systems. This self-energy named $G3W2$ contains all the possible time orderings that combine 3 Green's functions $G$ and 2 dynamic $W$. We present the analytic formula and its imaginary frequency counterpart, the latter allowing us to treat larger molecules. The accuracy of the $G3W2$ self-energy is evaluated on well-established benchmarks (GW100, Acceptor 24 and Core 65) for valence and core quasiparticle energies. Its link with the simpler static approximation, named SOSEX for static screened second-order exchange, is analyzed, which leads us to propose a more consistent approximation named 2SOSEX. In the end, we find that neither the $G3W2$ self-energy nor any of the investigated approximations to it improve over one-shot $G_0W_0$ with a good starting point. Only quasi-particle self-consistent $GW$ HOMO energies are slightly improved by addition of the $G3W2$ self-energy correction. We show that this is due to the self-consistent update of the screened Coulomb interaction leading to an overall sign change of the vertex correction to the frontier quasiparticle energies.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12892"
    },
    {
        "doc_id": 325,
        "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic Conservation Laws",
        "authors": [
            "Jake J. Harmon",
            "Svetlana Tokareva",
            "Anatoly Zlotnik",
            "Pieter J. Swart"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolic partial differential equations (PDEs) under uncertainty. Constructed around the framework of stochastic finite volume (SFV) methods, our approach circumvents sampling schemes or simulation ensembles while also preserving fundamental properties, in particular hyperbolicity of the resulting systems and conservation of the discrete solutions. Furthermore, we augment the existing SFV theory with a priori convergence results for statistical quantities, in particular push-forward densities, which we demonstrate through numerical experiments. By linking refinement indicators to regions of the physical and stochastic spaces, we drive anisotropic refinements of the discretizations, introducing new degrees of freedom (DoFs) where deemed profitable. To illustrate our proposed method, we consider a series of numerical examples for non-linear hyperbolic PDEs based on Burgers' and Euler's equations.",
        "comments": "Report number:          LA-UR 23-32498                          MSC Class:          35L60; 35L67; 65C30; 65M50; 65M60",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12880"
    },
    {
        "doc_id": 326,
        "title": "A Unified Generation-Registration Framework for Improved MR-based CT Synthesis in Proton Therapy",
        "authors": [
            "Xia Li",
            "Renato Bellotti",
            "Barbara Bachtiary",
            "Jan Hrbacek",
            "Damien C. Weber",
            "Antony J. Lomax",
            "Joachim M. Buhmann",
            "Ye Zhang"
        ],
        "subjects": [
            "Medical Physics"
        ],
        "abstract": "Background: In MR-guided proton therapy planning, aligning MR and CT images is key for MR-based CT synthesis, especially in mobile regions like the head-and-neck. Misalignments here can lead to less accurate synthetic CT (sCT) images, impacting treatment precision. Purpose: This study introduces a novel network that cohesively unifies image generation and registration processes to enhance the quality and anatomical fidelity of sCTs derived from better-aligned MR images. Methods: The approach synergizes a generation network (G) with a deformable registration network (R), optimizing them jointly in MR-to-CT synthesis. This goal is achieved by alternately minimizing the discrepancies between the generated/registered CT images and their corresponding reference CT counterparts. The generation network employs a UNet architecture, while the registration network leverages an implicit neural representation of the Deformable Vector Fields (DVFs). We validated this method on a dataset comprising 60 Head-and-Neck patients, reserving 12 cases for holdout testing. Results: Compared to the baseline Pix2Pix method with MAE 124.95\\pm 30.74 HU, the proposed technique demonstrated 80.98\\pm 7.55 HU. The unified translation-registration network produced sharper and more anatomically congruent outputs, showing superior efficacy in converting MR images to sCTs. Additionally, from a dosimetric perspective, the plan recalculated on the resulting sCTs resulted in a remarkably reduced discrepancy to the reference proton plans. Conclusions: This study conclusively demonstrates that a holistic MR-based CT synthesis approach, integrating both image-to-image translation and deformable registration, significantly improves the precision and quality of sCT generation, particularly for the challenging body area with varied anatomic changes between corresponding MR and CT.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12878"
    },
    {
        "doc_id": 327,
        "title": "Optimal compilation of parametrised quantum circuits",
        "authors": [
            "John van de Wetering",
            "Richie Yeung",
            "Tuomas Laakkonen",
            "Aleks Kissinger"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Parametrised quantum circuits contain phase gates whose phase is determined by a classical algorithm prior to running the circuit on a quantum device. Such circuits are used in variational algorithms like QAOA and VQE. In order for these algorithms to be as efficient as possible it is important that we use the fewest number of parameters. We show that, while the general problem of minimising the number of parameters is NP-hard, when we restrict to circuits that are Clifford apart from parametrised phase gates and where each parameter is used just once, we can efficiently find the optimal parameter count. We show that when parameter transformations are required to be sufficiently well-behaved that the only rewrites that reduce parameters correspond to simple 'fusions'. Using this we find that a previous circuit optimisation strategy by some of the authors [Kissinger, van de Wetering. PRA (2019)] finds the optimal number of parameters. Our proof uses the ZX-calculus. We also prove that the standard rewrite rules of the ZX-calculus suffice to prove any equality between parametrised Clifford circuits.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12877"
    },
    {
        "doc_id": 328,
        "title": "Di-electron production at the LHC: Unravelling virtual-photon and heavy-flavour contributions",
        "authors": [
            "Anton Andronic",
            "Tom\u00e1\u0161 Je\u017eo",
            "Michael Klasen",
            "Christian Klein-B\u00f6sing",
            "Alexander Puck Neuwirth"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The production of virtual photons is a very sensitive probe of the properties of the quark-gluon plasma. As they are experimentally detected by lepton pairs, they suffer from a large background arising from hadron decays. Light-flavour hadrons dominate at low invariant masses below $m_{ee}\\sim0.5$ GeV and heavy flavours above. These contributions must therefore also be taken into account in experimental analyses at the LHC. In this paper, we calculate the direct contribution from virtual photons produced in the Drell-Yan process with an additional jet in POWHEG and find that it is significant at low invariant masses. We also simulate the background contributions from $c\\bar c$ and $b \\bar b$ production with POWHEG and quantify the theoretical uncertainties due to variations of the perturbative scales and parton distribution functions. We find larger relative and absolute uncertainties for the lighter $c$ quarks than for heavier $b$ quarks.",
        "comments": "25 pages, 16 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12875"
    },
    {
        "doc_id": 329,
        "title": "Unlocking the Potential: Multi-task Deep Learning for Spaceborne Quantitative Monitoring of Fugitive Methane Plumes",
        "authors": [
            "Guoxin Si",
            "Shiliang Fu",
            "Wei Yao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "With the intensification of global warming, the monitoring of methane emission and detection of gas plumes from landfills have increasingly received attention. We decompose methane emission monitoring into three sub-tasks: methane concentration inversion, plume segmentation, and emission rate estimation. Conventional algorithms have limitations: methane concentration inversion usually uses the matched filter, which is sensitive to global spectrum distribution and contains a large amount of noises. There is limited research on plume segmentation, with many studies resorting to manual segmentation that is likely to be subjective. The estimation of methane emission rate often utilizes IME algorithm, which relies on obtaining meteorological measurement data. Using the WENT landfill site in Hong Kong and PRISMA hyperspectral satellite imagery, we propose a new deep learning-based framework for quantitative monitoring of methane emissions from remote sensing images based on physical simulation. We generate simulated methane plumes using large eddy simulation (LES) and different concentration maps of fugitive emission using the radiative transfer equation (RTE), while combining augmentation techniques to create a simulated PRISMA dataset. We train a U-Net network for methane concentration inversion, a Mask R-CNN network for methane plume segmentation, and a ResNet-50 network for methane emission rate estimation. All three deep networks achieve higher validation accuracy compared to conventional algorithms. We further respectively combine the first two sub-tasks and the last two sub-tasks to design the multi-task learning models - MTL-01 and MTL-02, both of which achieve higher accuracy than single-task models. Our research serves as a demonstration of applying multi-task deep learning to quantitative methane monitoring and can be extended to a broad range of methane monitoring tasks.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12870"
    },
    {
        "doc_id": 330,
        "title": "A database of physical therapy exercises with variability of execution collected by wearable sensors",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This document introduces the PHYTMO database, which contains data from physical therapies recorded with inertial sensors, including information from an optical reference system. PHYTMO includes the recording of 30 volunteers, aged between 20 and 70 years old. A total amount of 6 exercises and 3 gait variations were recorded. The volunteers performed two series with a minimum of 8 repetitions in each one. PHYTMO includes magneto-inertial data, together with a highly accurate location and orientation in the 3D space provided by the optical system. The files were stored in CSV format to ensure its usability. The aim of this dataset is the availability of data for two main purposes: the analysis of techniques for the identification and evaluation of exercises using inertial sensors and the validation of inertial sensor-based algorithms for human motion monitoring. Furthermore, the database stores enough data to apply Machine Learning-based algorithms. The participants' age range is large enough to establish age-based metrics for the exercises evaluation or the study of differences in motions between different groups.",
        "comments": "ACM Class:          E.5",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12868"
    },
    {
        "doc_id": 331,
        "title": "Self-induced light emission in solid-state memristors replicates neuronal biophotons",
        "authors": [
            "K. Malchow",
            "T. Zellweger",
            "B. Cheng",
            "A. Leray",
            "J. Leuthold",
            "A. Bouhelier"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "Key pre-synaptic and post-synaptic biological functions have been successfully implemented in various hardware systems. A noticeable example are neuronal networks constructed from memristors, which are emulating complex electro-chemical biological dynamics such a neuron's efficacy and plasticity. Neurons are highly active cells, communicating with chemical and electrical stimuli, but also emit light. These photons are suspected to be a complementary vehicle to transport information across the brain. Here, we show that a memristor also releases photons akin to the production of neuronal light. Critical attributes of so-called biophotons such as self-generation, origin, stochasticity, spectral coverage, sparsity and correlation with the neuron's activity are replicated by our solid-state approach. Our findings further extend the emulating capability of a memristor to encompass neuronal biophoton emission and open the possibility to construct a bimodal electro-optical platform with the assistance of atomic-scale devices capable of handling electrons and photons as information carriers.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12867"
    },
    {
        "doc_id": 332,
        "title": "Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing",
        "authors": [
            "Ralf Bruns",
            "Jeremias D\u00f6tterl",
            "J\u00fcrgen Dunkel",
            "Sascha Ossowski"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Multiagent Systems"
        ],
        "abstract": "Mobile crowdsourcing refers to systems where the completion of tasks necessarily requires physical movement of crowdworkers in an on-demand workforce. Evidence suggests that in such systems, tasks often get assigned to crowdworkers who struggle to complete those tasks successfully, resulting in high failure rates and low service quality. A promising solution to ensure higher quality of service is to continuously adapt the assignment and respond to failure-causing events by transferring tasks to better-suited workers who use different routes or vehicles. However, implementing task transfers in mobile crowdsourcing is difficult because workers are autonomous and may reject transfer requests. Moreover, task outcomes are uncertain and need to be predicted. In this paper, we propose different mechanisms to achieve outcome prediction and task coordination in mobile crowdsourcing. First, we analyze different data stream learning approaches for the prediction of task outcomes. Second, based on the suggested prediction model, we propose and evaluate two different approaches for task coordination with different degrees of autonomy: an opportunistic approach for crowdshipping with collaborative, but non-autonomous workers, and a market-based model with autonomous workers for crowdsensing.",
        "comments": "Journal ref:        Sensors 2023, 23(2), 614",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12866"
    },
    {
        "doc_id": 333,
        "title": "Threshold Quantum State Tomography",
        "authors": [
            "Daniele Binosi",
            "Giovanni Garberoglio",
            "Diego Maragnano",
            "Maurizio Dapor",
            "Marco Liscidini"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Quantum state tomography (QST) aims at reconstructing the state of a quantum system. However in conventional QST the number of measurements scales exponentially with the number of qubits. Here we propose a QST protocol, in which the introduction of a threshold allows one to drastically reduce the number of measurements required for the reconstruction of the state density matrix without compromising the result accuracy. In addition, one can also use the same approach to reconstruct an approximated density matrix depending on the available resources. We experimentally demonstrate this protocol by performing the tomography of states up to 7 qubits. We show that our approach can lead to the same accuracy of QST even when the number of measurements is reduced by more than two orders of magnitudes.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12864"
    },
    {
        "doc_id": 334,
        "title": "Secure Communication with Unreliable Entanglement Assistance",
        "authors": [
            "Meir Lederman",
            "Uzi Pereg"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory"
        ],
        "abstract": "Secure communication is considered with unreliable entanglement assistance, where the adversary may intercept the legitimate receiver's entanglement resource before communication takes place. The communication setting of unreliable assistance, without security aspects, was originally motivated by the extreme photon loss in practical communication systems. The operational principle is to adapt the transmission rate to the availability of entanglement assistance, without resorting to feedback and repetition. Here, we require secrecy as well. An achievable secrecy rate region is derived for general quantum wiretap channels, and a multi-letter secrecy capacity formula for the special class of degraded channels.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12861"
    },
    {
        "doc_id": 335,
        "title": "28 THz soliton frequency comb in a continuous-wave pumped fiber Fabry-Perot resonator",
        "authors": [
            "Thomas Bunel",
            "Matteo Conforti",
            "Zoheir Ziani",
            "Julien Lumeau",
            "Antonin Moreau",
            "Arnaud Fernandez",
            "Olivier Llopis",
            "Germain Bourcier",
            "Arnaud Mussot"
        ],
        "subjects": [
            "Optics",
            "Pattern Formation and Solitons"
        ],
        "abstract": "We report the generation of an optical frequency comb featuring 28 THz bandwidth, sustained by a single 80 fs cavity soliton recirculating in a fiber Fabry-Perot resonator. This large spectrum is comparable to frequency combs obtained with microresonators operating in the anomalous dispersion regime. Thanks to the compact design and the easy coupling of the resonator, cavity solitons can be generated in an all-fiber experimental setup with a continuous wave pumping scheme. We also observe the generation of a dispersive wave at higher frequencies which is supported by higher-order dispersion. These observations align remarkably well with both numerical simulations and the established theory of cavity solitons.",
        "comments": "6 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12858"
    },
    {
        "doc_id": 336,
        "title": "Simultaneous exercise recognition and evaluation in prescribed routines: Approach to virtual coaches",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Signal Processing"
        ],
        "abstract": "Home-based physical therapies are effective if the prescribed exercises are correctly executed and patients adhere to these routines. This is specially important for older adults who can easily forget the guidelines from therapists. Inertial Measurement Units (IMUs) are commonly used for tracking exercise execution giving information of patients' motion data. In this work, we propose the use of Machine Learning techniques to recognize which exercise is being carried out and to assess if the recognized exercise is properly executed by using data from four IMUs placed on the person limbs. To the best of our knowledge, both tasks have never been addressed together as a unique complex task before. However, their combination is needed for the complete characterization of the performance of physical therapies. We evaluate the performance of six machine learning classifiers in three contexts: recognition and evaluation in a single classifier, recognition of correct exercises, excluding the wrongly performed exercises, and a two-stage approach that first recognizes the exercise and then evaluates it. We apply our proposal to a set of 8 exercises of the upper-and lower-limbs designed for maintaining elderly people health status. To do so, the motion of volunteers were monitored with 4 IMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initial scenarios. In the third one, the recognition provides an accuracy of 96.2 \\%, whereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This work proves the feasibility of IMUs for a complete monitoring of physical therapies in which we can get information of which exercise is being performed and its quality, as a basis for designing virtual coaches.",
        "comments": "ACM Class:          I.2.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12857"
    },
    {
        "doc_id": 337,
        "title": "On the relevance of quantum corrections to the matter stress-energy tensor in eternally expanding universes",
        "authors": [
            "E. T. Akhmedov",
            "A. V. Anokhin",
            "K. A. Kazarnovskii"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "We study a toy-model of continuous infinite expansion of space-time with the flat start. We use as the gravitational background a conformaly flat metric with an exponentially growing factor in conformal time. We aim to clarify some properties of quantum fields in such a gravitational background. In particular, we calculate one-loop corrections to the Keldysh propagator to verify the fact of secular growth of the occupation number and anomalous quantum average in the massless scalar field theory with selfinteractions. We perform the calculation in arbitrary dimensions with the use of the Schwinger-Keldysh technique. We get a secular growth which is not of a kinetic type. We provide some results for the case of generic interaction $\\frac\u03bb{b!}\u03c6^b$.",
        "comments": "21 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12855"
    },
    {
        "doc_id": 338,
        "title": "Optimization and Stabilization of Functional Renormalization Group Flows",
        "authors": [
            "Niklas Zorbach",
            "Jonas Stoll",
            "Jens Braun"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Theory",
            "Nuclear Theory"
        ],
        "abstract": "We revisit optimization of functional renormalization group flows by analyzing regularized loop integrals. This leads us to a principle, the Principle of Strongest Singularity, and a corresponding order relation which allows to order existing regularization schemes with respect to the stability of renormalization group flows. Moreover, the order relation can be used to construct new regulators in a systematic fashion. For studies of critical behavior, which require to follow renormalization group flows down to the deep infrared regime, such new regulators may turn out to be particularly useful. The general application of this principle is demonstrated with the aid of a scalar field theory which is solved over a wide range of scales with novel methods borrowed from numerical fluid dynamics.",
        "comments": "15 pages, 5 figures, 1 table",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12854"
    },
    {
        "doc_id": 339,
        "title": "Hyper-Realist Rendering: A Theoretical Framework",
        "authors": [
            "Ergun Akleman",
            "Murat Kurt",
            "Derya Akleman",
            "Gary Bruins",
            "Sitong Deng",
            "Meena Subramanian"
        ],
        "subjects": [
            "Graphics"
        ],
        "abstract": "This is the first paper in a series on hyper-realist rendering. In this paper, we introduce the concept of hyper-realist rendering and present a theoretical framework to obtain hyper-realist images. We are using the term Hyper-realism as an umbrella word that captures all types of visual artifacts that can evoke an impression of reality. The hyper-realist artifacts are visual representations that are not necessarily created by following logical and physical principles and can still be perceived as representations of reality. This idea stems from the principles of representational arts, which attain visually acceptable renderings of scenes without implementing strict physical laws of optics and materials. The objective of this work is to demonstrate that it is possible to obtain visually acceptable illusions of reality by employing such artistic approaches. With representational art methods, we can even obtain an alternate illusion of reality that looks more real even when it is not real. This paper demonstrates that it is common to create illusions of reality in visual arts with examples of paintings by representational artists. We propose an approach to obtain expressive local and global illuminations to obtain these stylistic illusions with a set of well-defined and formal methods.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12853"
    },
    {
        "doc_id": 340,
        "title": "A new binning method to choose a standard set of Quasars",
        "authors": [
            "Maria Giovanna Dainotti",
            "Aleksander Lukasz Lenart",
            "Mina Godsi Yengejeh",
            "Satyajit Chakraborty",
            "Nissim Fraija",
            "Eleonora Di Valentino",
            "Giovanni Montani"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Although the Lambda Cold Dark Matter model is the most accredited cosmological model, information at intermediate redshifts (z) between type Ia Supernovae (z = 2.26) and the Cosmic Microwave Background (z = 1100) is crucial to validate this model further. Here, we present a detailed and reliable methodology for binning the quasars (QSO) data that allows the identification of a golden sample of QSOs to be used as standard candles. This procedure has the advantage of being very general. Thus, it can be applied to any astrophysical sources at cosmological distances. This methodology allows us to avoid the circularity problem since it involves a flux-flux relation and includes the analysis of removing selection biases and the redshift evolution. With this method, we have discovered a sample of 1253 quasars up to z = 7.54 with reduced intrinsic dispersion of the relation between Ultraviolet and X-ray fluxes, with $\u03b4_{int} = 0.096\\pm 0.003$ (56\\% less than the original sample where $\u03b4_{int} =0.22$). Once the luminosities are corrected for selection biases and redshift evolution, this `gold' sample allows us to determine the matter density parameter to be $\u03a9_M=0.240 \\pm 0.064$. This value is aligned with the results of the $\u039bCDM$ model obtained with SNe Ia.",
        "comments": "accepted in Physics of the Dark Universe, 16 figures and 1 table",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12847"
    },
    {
        "doc_id": 341,
        "title": "Gelation and localization in multicomponent coagulation with multiplicative kernel through branching processes",
        "authors": [
            "Jochem Hoogendijk",
            "Ivan Kryven",
            "Camillo Schenone"
        ],
        "subjects": [
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "The multicomponent coagulation equation is a generalisation of the Smoluchowski coagulation equation in which size of a particle is described by a vector. As with the original Smoluchowski equation, the multicomponent coagulation equation features gelation when supplied with a multiplicative kernel. Additionally, a new type of behaviour called localization is observed due to the multivariate nature of the particle size distribution. Here we extend and apply the branching process representation technique, which we introduced to study differential equations in our previous work, to find a concise probabilistic solution of the multicomponent coagulation equation supplied with monodisperse initial conditions and provide short proofs for the gelation time and localization.",
        "comments": "12 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12844"
    },
    {
        "doc_id": 342,
        "title": "Understanding Gravitational Form Factors with the Weizs\u00e4cker-Williams Method",
        "authors": [
            "Yoshikazu Hagiwara",
            "Xuan-Bo Tong",
            "Bo-Wen Xiao"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Experiment",
            "Nuclear Theory"
        ],
        "abstract": "Understanding the internal structure of nucleons and nuclei has been a topic of enduring interest in high-energy physics. Gravitational form factors~(GFFs) provide an important portal for us to probe the energy-momentum/mass distribution of nucleons and nuclei. This letter presents the study of the photon and gluon momentum GFFs, also known as the A-GFFs, of relativistic hadrons using the Weizs\u00e4cker-Williams method. To begin, we express the photon A-GFFs in terms of charge form factors and discuss the corresponding photon radius. Furthermore, an integral relation between the gluon A-GFF and the Laplacian of dipole scattering amplitude is derived in the small-$x$ framework, and it allows us to unravel the gluon energy momentum distribution inside hadrons through measurements at the upcoming Electron-Ion Collider. In addition, we generalize the analysis to study the A-GFF of nuclei and propose employing the nuclear gluon mean square radius, together with the charge distribution, to constrain the neutron distribution for large nuclei. This work provides an interesting perspective into the fundamental structure of high-energy hadrons.",
        "comments": "8 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12840"
    },
    {
        "doc_id": 343,
        "title": "Attenuation proxy hidden in surface brightness-colour diagrams. A new strategy for the LSST era",
        "authors": [
            "K. Ma\u0142ek",
            "Junais",
            "A. Pollo",
            "M. Boquien",
            "V. Buat",
            "S. Salim",
            "S. Brough",
            "R. Demarco",
            "A. W. Graham",
            "M. Hamed",
            "J. R. Mullaney",
            "M. Romano",
            "C. Sif\u00f3n",
            "M. Aravena",
            "J. A. Benavides",
            "I. Bus\u00e0",
            "D. Donevski",
            "O. Dorey",
            "H. M. Hernandez-Toledo",
            "A. Nanni",
            "W. J. Pearson",
            "F. Pistis",
            "R. Ragusa",
            "G. Riccio",
            "J. Rom\u00e1n"
        ],
        "subjects": [
            "Astrophysics of Galaxies"
        ],
        "abstract": "Large future sky surveys, such as the LSST, will provide optical photometry for billions of objects. This paper aims to construct a proxy for the far ultraviolet attenuation (AFUVp) from the optical data alone, enabling the rapid estimation of the star formation rate (SFR) for galaxies that lack UV or IR data. To mimic LSST observations, we use the deep panchromatic optical coverage of the SDSS Photometric Catalogue DR~12, complemented by the estimated physical properties for the SDSS galaxies from the GALEX-SDSS-WISE Legacy Catalog (GSWLC) and inclination information obtained from the SDSS DR7. We restricted our sample to the 0.025-0.1 z-spec range and investigated relations among surface brightness, colours, and dust attenuation in the far UV range for star-forming galaxies obtained from the spectral energy distribution (SED). {Dust attenuation is best correlated with (u-r) colour and the surface brightness in the u band ($\\rm \u03bc_{u}$). We provide a dust attenuation proxy for galaxies on the star-forming main sequence, which can be used for the LSST or any other type of broadband optical survey. The mean ratio between the catalogue values of SFR and those estimated using optical-only SDSS data with the AFUVp prior calculated as $\u0394$SFR=log(SFR$_{\\tiny{\\mbox{this work}}}$/SFR$_{\\tiny{}\\texttt{GSWLC}}$) is found to be less than 0.1~dex, while runs without priors result in an SFR overestimation larger than 0.3~dex. The presence or absence of theAFUVp has a negligible influence on the stellar mass estimation (with $\u0394$M$_{star}$ in the range from 0 to $-0.15$ dex). Forthcoming deep optical observations of the LSST Deep Drilling Fields, which also have multi-wavelength data, will enable one to calibrate the obtained relation for higher redshift galaxies and, possibly, extend the study towards other types of galaxies, such as early-type galaxies off the main sequence.",
        "comments": "18 pages, accepted for publication in Astronomy and Astrophysics",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12831"
    },
    {
        "doc_id": 344,
        "title": "A non-unitary solar constraint for long-baseline neutrino experiments",
        "authors": [
            "Andres Lopez Moreno"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Long-baseline neutrino oscillation experiments require external constraints on $\\sin^2\u03b8_{12}$ and $\u0394m_{21}^2$ to make precision measurements of the leptonic mixing matrix. These constraints come from measurements of the Mikheyev-Smirnov-Wolfenstein (MSW) mixing in solar neutrinos. Here we develop an MSW large mixing angle approximation in the presence of heavy neutral leptons which adds a single new parameter ($\u03b1_{11}$) representing the magnitude of the mixing between the $\u03bd_e$ state and the heavy sector. We use data from the Borexino, SNO and KamLAND collaborations to find a solar constraint appropriate for heavy neutral lepton searches in long-baseline oscillation experiments. Solar data limits the magnitude of the non-unitary parameter to $(1-\u03b1_{11}) < 0.046$ at the $99\\%$ credible interval and yields a strongly correlated constraint on the solar mass splitting and the magnitude of $\u03bd_e$ non-unitary mixing.",
        "comments": "8 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12829"
    },
    {
        "doc_id": 345,
        "title": "Advancing on-chip Kerr optical parametric oscillation towards coherent applications covering the green gap",
        "authors": [
            "Yi Sun",
            "Jordan Stone",
            "Xiyuan Lu",
            "Feng Zhou",
            "Zhimin Shi",
            "Kartik Srinivasan"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Optical parametric oscillation (OPO) in Kerr microresonators can efficiently transfer near-infrared laser light into the visible spectrum. To date, however, chromatic dispersion has mostly limited output wavelengths to >560 nm, and robust access to the whole green light spectrum has not been demonstrated. In fact, wavelengths between 532 nm and 633 nm, commonly referred to as the \"green gap\", are especially challenging to produce with conventional laser gain. Hence, there is motivation to extend the Kerr OPO wavelength range and develop reliable device designs. Here, we experimentally show how to robustly access the entire green gap with Kerr OPO in silicon nitride microrings pumped near 780 nm. Our microring geometries are optimized for green-gap emission; in particular, we introduce a dispersion engineering technique, based on partially undercutting the microring, which not only expands wavelength access but also proves robust to variations in resonator dimensions, in particular, the microring width. Using just two devices, we generate >100 wavelengths evenly distributed throughout the green gap, as predicted by our dispersion simulations. Moreover, we establish the usefulness of Kerr OPO to coherent applications by demonstrating continuous frequency tuning (>50 GHz) and narrow optical linewidths (<1 MHz). Our work represents an important step in the quest to bring nonlinear nanophotonics and its advantages to the visible spectrum.",
        "comments": "12 pages, 8 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12823"
    },
    {
        "doc_id": 346,
        "title": "Interplay between an absorbing phase transition and synchronization in a driven granular system",
        "authors": [
            "R. Maire",
            "A. Plati",
            "M. Stockinger",
            "E. Trizac",
            "F. Smallenburg",
            "G. Foffi"
        ],
        "subjects": [
            "Statistical Mechanics"
        ],
        "abstract": "Absorbing phase transitions (APTs) are widespread in non-equilibrium systems, spanning condensed matter, epidemics, earthquakes, ecology, and chemical reactions. APTs feature an absorbing state in which the system becomes entrapped, along with a transition, either continuous or discontinuous, to an active state. Understanding which physical mechanisms determine the order of these transitions represents a challenging open problem in non-equilibrium statistical mechanics. Here, by numerical simulations and mean-field analysis, we show that a quasi-2d vibrofluidized granular system exhibits a novel form of APT. The absorbing phase is observed in the horizontal dynamics below a critical packing fraction, and can be continuous or discontinuous based on the emergent degree of synchronization in the vertical motion. Our results provide a direct representation of a feasible experimental scenario, showcasing a surprising interplay between dynamic phase transition and synchronization.",
        "comments": "4 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12817"
    },
    {
        "doc_id": 347,
        "title": "Ray-Singer Torsion, Topological Strings and Black Holes",
        "authors": [
            "Cumrun Vafa"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "Genus one amplitude for topological strings on Calabi-Yau 3-folds can be computed using mirror symmetry: The partition function at genus one gets mapped to a holomorphic version of Ray-Singer torsion on the mirror Calabi-Yau. On the other hand it can be shown by a physical argument that this gives a curvature squared correction term to the gravitational action. This in paticular leads to an effective quantum gravity cutoff known as the species scale, which varies over moduli space of Calabi-Yau manifolds. This resolves some of the puzzles associated to the entropy of small black holes when there are a large number of light species of particles. Thus Ray-Singer torsion, via its connection to topological strings at genus one, provides a measure of light degrees of freedom of four dimensional N=2 supergravity theories. Based on a talk given on May 12th, 2023 at the Singer Memorial Conference, MIT.",
        "comments": "11 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12816"
    },
    {
        "doc_id": 348,
        "title": "$b$-Hurwitz numbers from Whittaker vectors for $\\mathcal{W}$-algebras",
        "authors": [
            "Nitin K. Chidambaram",
            "Maciej Do\u0142\u0119ga",
            "Kento Osuga"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Mathematical Physics",
            "Combinatorics",
            "Representation Theory"
        ],
        "abstract": "We show that $b$-Hurwitz numbers with a rational weight are obtained by taking an explicit limit of a Whittaker vector for the $\\mathcal{W}$-algebra of type $A$. Our result is a vast generalization of several previous results that treated the monotone case, and the cases of quadratic and cubic polynomial weights. It also provides an interpretation of the associated Whittaker vector in terms of generalized branched coverings that might be of independent interest. Our result is new even in the special case $b=0$ that corresponds to classical hypergeometric Hurwitz numbers, and implies that they are governed by the topological recursion of Eynard-Orantin. This gives an independent proof of the recent result of Bychkov-Dunin-Barkowski-Kazarian-Shadrin.",
        "comments": "40 pages, comments welcome!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12814"
    },
    {
        "doc_id": 349,
        "title": "Binary structured physics-informed neural networks for solving equations with rapidly changing solutions",
        "authors": [
            "Yanzhi Liu",
            "Ruifan Wu",
            "Ying Jiang"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Physics-informed neural networks (PINNs), rooted in deep learning, have emerged as a promising approach for solving partial differential equations (PDEs). By embedding the physical information described by PDEs into feedforward neural networks, PINNs are trained as surrogate models to approximate solutions without the need for label data. Nevertheless, even though PINNs have shown remarkable performance, they can face difficulties, especially when dealing with equations featuring rapidly changing solutions. These difficulties encompass slow convergence, susceptibility to becoming trapped in local minima, and reduced solution accuracy. To address these issues, we propose a binary structured physics-informed neural network (BsPINN) framework, which employs binary structured neural network (BsNN) as the neural network component. By leveraging a binary structure that reduces inter-neuron connections compared to fully connected neural networks, BsPINNs excel in capturing the local features of solutions more effectively and efficiently. These features are particularly crucial for learning the rapidly changing in the nature of solutions. In a series of numerical experiments solving Burgers equation, Euler equation, Helmholtz equation, and high-dimension Poisson equation, BsPINNs exhibit superior convergence speed and heightened accuracy compared to PINNs. From these experiments, we discover that BsPINNs resolve the issues caused by increased hidden layers in PINNs resulting in over-smoothing, and prevent the decline in accuracy due to non-smoothness of PDEs solutions.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12806"
    },
    {
        "doc_id": 350,
        "title": "Electronic transport properties of few-layer graphene",
        "authors": [
            "Biswajit Datta"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "In this thesis we will focus on a particular variant of few-layer graphene -- ABA-stacked trilayer graphene. Bernal (ABA) stacked trilayer graphene (TLG) is a multiband system consisting of a pair of Dirac-like massless linear bands and a pair of massive quadratic bands. We have studied the electronic properties of this system in detail and unfolded many interesting physics problems. The whole thesis is structured in the following way. In chapter 2 and chapter 3 we discuss the theoretical ingredients we will need to understand the experimental data presented in this thesis. Chapter 2 focuses on the band structure of graphene and few-layer graphene. In chapter 3 we focus on quantum Hall effect of graphene and few-layer graphene. In chapter 4 we discuss the device fabrication and characterization. Chapter 5, Chapter 6 and Chapter 7 present the original works which are published as papers.",
        "comments": "PhD Dissertation",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12804"
    },
    {
        "doc_id": 351,
        "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach",
        "authors": [
            "Rohit Singh",
            "Anil Kumar Yerrapragada",
            "Jeeva Keshav S",
            "Radha Krishna Ganti"
        ],
        "subjects": [
            "Information Theory",
            "Artificial Intelligence",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Random Access is an important step in enabling the initial attachment of a User Equipment (UE) to a Base Station (gNB). The UE identifies itself by embedding a Preamble Index (RAPID) in the phase rotation of a known base sequence, which it transmits on the Physical Random Access Channel (PRACH). The signal on the PRACH also enables the estimation of propagation delay, often known as Timing Advance (TA), which is induced by virtue of the UE's position. Traditional receivers estimate the RAPID and TA using correlation-based techniques. This paper presents an alternative receiver approach that uses AI/ML models, wherein two neural networks are proposed, one for the RAPID and one for the TA. Different from other works, these two models can run in parallel as opposed to sequentially. Experiments with both simulated data and over-the-air hardware captures highlight the improved performance of the proposed AI/ML-based techniques compared to conventional correlation methods.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12803"
    },
    {
        "doc_id": 352,
        "title": "Deep Learning in Physical Layer: Review on Data Driven End-to-End Communication Systems and their Enabling Semantic Applications",
        "authors": [
            "Nazmul Islam",
            "Seokjoo Shin"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Machine Learning"
        ],
        "abstract": "Deep Learning (DL) has enabled a paradigm shift in wireless communication system with data driven end-to-end (E2E) learning and optimization of the Physical Layer (PHY). By leveraging the representation learning of DL, E2E systems exhibit enhanced adaptability and performance in complex wireless environments, fulfilling the demands of 5G and beyond network systems and applications. The evolution of data-driven techniques in the PHY has enabled advanced semantic applications across various modalities including text, image, audio, video, and multi-modal transmissions. These applications transcend from traditional bit-level communication to semantic-level intelligent communication systems, which are capable of understanding and adapting to the context and intent of the data transmission. Although PHY as a DL architecture for data-driven E2E communication is a key factor in enabling semantic communication systems (SemCom), and various studies in recent years have surveyed them separately, their combination has not been thoroughly reviewed. Additionally, these are emerging fields that are still in their infancy, with several techniques having been developed and evolved in recent years. Therefore, this article provides a holistic review of data-driven PHY for E2E communication system, and their enabling semantic applications across different modalities. Furthermore, it identifies critical challenges and prospective research directions, providing a pivotal reference for future development of DL in PHY and SemCom.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12800"
    },
    {
        "doc_id": 353,
        "title": "A New Precise Determination of the Primordial Abundance of Deuterium: Measurement in the metal-poor sub-DLA system at z=3.42 towards quasar J1332+0052",
        "authors": [
            "P. A. Kislitsyn",
            "S. A. Balashev",
            "M. T. Murphy",
            "C. Ledoux",
            "P. Noterdaeme",
            "A. V. Ivanchik"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "The theory of Big Bang nucleosynthesis, coupled with an estimate of the primordial deuterium abundance (D/H)_pr, offers insights into the baryon density of the Universe. Independently, the baryon density can be constrained during a different cosmological era through the analysis of cosmic microwave background (CMB) anisotropy. The comparison of these estimates serves as a rigorous test for the self-consistency of the Standard Cosmological Model and stands as a potent tool in the quest for new physics beyond the Standard Model of Particle Physics. For a meaningful comparison, a clear understanding of the various systematic errors affecting deuterium measurements is crucial. Given the limited number of D/H measurements, each new estimate carries significant weight. This study presents the detection of DI absorption lines in a metal-poor sub-Damped Lyman-alpha system ([O/H]=-1.71+-0.02, logN(HI)=19.304+-0.004) at z_abs=3.42 towards the quasar J1332+0052. Through simultaneous fitting of HI and DI Lyman-series lines, as well as low-ionization metal lines, observed at high spectral resolution and high signal-to-noise using VLT/UVES and Keck/HIRES, we derive log(DI/HI)=-4.622+-0.014, accounting for statistical and systematic uncertainties of 0.008dex and 0.012dex, respectively. Thanks to negligible ionization corrections and minimal deuterium astration at low metallicity, this D/H ratio provides a robust measurement of the primordial deuterium abundance, consistent and competitive with previous works. Incorporating all prior measurements, the best estimate of the primordial deuterium abundance is constrained as: (D/H)_pr=(2.533+-0.024)*10^-5. This represents a 5% improvement in precision over previous studies and reveals a moderate tension with the expectation from the Standard Model (~2.2sig). This discrepancy underscores the importance of further measurements in the pursuit of new physics.",
        "comments": "15 pages, 18 figures. Accepted for publication in MNRAS",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12797"
    },
    {
        "doc_id": 354,
        "title": "Integrals for relativistic nonadiabatic energies of H$_2$ in exponential basis",
        "authors": [
            "Krzysztof Pachucki",
            "Jacek Komasa"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Accurate predictions for hydrogen molecular levels require the treatment of electrons and nuclei on an equal footing. While nonrelativistic theory has been effectively formulated this way, calculation of relativistic and quantum electrodynamic effects using an exponential basis with explicit correlations that ensure well-controlled numerical precision is much more challenging. In this work, we derive a complete set of integrals for the relativistic correction and demonstrate their application to several of the lowest rovibrational levels. Together with similar advancements for quantum electrodynamic corrections, this will improve the accuracy beyond $10^{-9}$ and hopefully explain discrepancies with recent experimental values.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12795"
    },
    {
        "doc_id": 355,
        "title": "Extremal Tsirelson inequalities",
        "authors": [
            "Barizien Victor",
            "Bancal Jean-Daniel"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "It is well-known that the set of statistics that can be observed in a Bell-type experiment is limited by quantum theory. Unfortunately, tools are missing to identify the precise boundary of this set. Here, we propose to study the set of quantum statistics from a dual perspective. By considering all Bell expressions saturated by a given realization, we show that the CHSH expression can be decomposed in terms of extremal Tsirelson inequalities that we identify. This brings novel insight into the geometry of the quantum set in the (2,2,2) scenario. Furthermore, this allows us to identify all the Bell expressions that are able to self-test the Tsirelson realization.",
        "comments": "5+5 pages ; 2+1 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12791"
    },
    {
        "doc_id": 356,
        "title": "Wide-range resistivity characterization of semiconductors with terahertz time-domain spectroscopy",
        "authors": [
            "Joshua Hennig",
            "Jens Klier",
            "Stefan Duran",
            "Kuei-Shen Hsu",
            "Jan Beyer",
            "Christian R\u00f6der",
            "Franziska C. Beyer",
            "Nadine Sch\u00fcler",
            "Nico Vieweg",
            "Katja Dutzi",
            "Georg von Freymann",
            "Daniel Molter"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Resistivity is one of the most important characteristics in the semiconductor industry. The most common way to measure resistivity is the four-point probe method, which requires physical contact with the material under test. Terahertz time domain spectroscopy, a fast and non-destructive measurement method, is already well established in the characterization of dielectrics. In this work, we demonstrate the potential of two Drude model-based approaches to extract resistivity values from terahertz time-domain spectroscopy measurements of silicon in a wide range from about 10$^{-3}$ $\u03a9$cm to 10$^{2}$ $\u03a9$cm. One method is an analytical approach and the other is an optimization approach. Four-point probe measurements are used as a reference. In addition, the spatial resistivity distribution is imaged by X-Y scanning of the samples to detect inhomogeneities in the doping distribution.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12787"
    },
    {
        "doc_id": 357,
        "title": "Light-cone and quasi generalized parton distributions in the 't Hooft model",
        "authors": [
            "Yu Jia",
            "Zhewen Mo",
            "Xiaonu Xiong",
            "Rui Yu"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We present a comprehensive study of the light-cone generalized parton distribution (GPD) and quasi-GPD of a flavor-neutral meson in the 't Hooft model, {\\it i.e.}, two-dimensional QCD (\\QCDtw) in the $N_c\\to\\infty$ limit. With the aid of the Hamiltonian approach, we construct the light-cone GPD in terms of the meson's light-cone wave function in the framework of light-front quantization, and express the quasi-GPD in terms of the meson's Bars-Green wave functions and the chiral angle in the framework of equal-time quantization. We show that, both analytically and numerically, the quasi-GPD does approach the light-cone GPD when the meson is boosted to the infinite momentum frame, which justifies the tenet underlying the large momentum effective theory for the off-forward parton distribution. Upon taking the forward limit, the light-cone and quasi-GPDs reduce to the light-cone and quasi-PDFs. As a bonus, we take this chance to correct the incomplete expression of the quasi-PDFs in the 't Hooft model reported in our preceding work [Y. Jia et al. Phys. Rev. D 98, 054011 (2018)].",
        "comments": "31 pages, 14 figures, 1 table",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12786"
    },
    {
        "doc_id": 358,
        "title": "Extended imaginary gauge transformation in a general nonreciprocal lattice",
        "authors": [
            "Yunyao Qi",
            "Jinghui Pi",
            "Yuquan Wu",
            "Heng Lin",
            "Chao Zheng",
            "Guilu Long"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Imaginary gauge transformation (IGT) provides a clear understanding of the non-Hermitian skin effect by transforming the non-Hermitian Hamiltonians with real spectra into Hermitian ones. In this work, we extend this approach to the complex spectrum regime in a general nonreciprocal lattice model. We unveil the validity of IGT hinges on a class of pseudo-Hermitian symmetry. The generalized Brillouin zone of Hamiltonian respect such pseudo-Hermiticity is demonstrated to be a circle, which enables easy access to the continuum bands, localization length of skin modes, and relevant topological numbers. Furthermore, we investigate the applicability of IGT and the underlying pseudo-Hermiticity beyond nearest-neighbour hopping, offering a graphical interpretation. Our theoretical framework is applied to establish bulk-boundary correspondence in the nonreciprocal trimer Su-Schrieffer-Heeger model and analyze the localization behaviors of skin modes in the two-dimensional Hatano-Nelson model.",
        "comments": "16 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12785"
    },
    {
        "doc_id": 359,
        "title": "Understanding atom probe's analytical performance for iron oxides using correlation histograms and ab initio calculations",
        "authors": [
            "Se-Ho Kim",
            "Shalini Bhatt",
            "Daniel K. Schreiber",
            "J\u00f6rg Neugebauer",
            "Christoph Freysoldt",
            "Baptiste Gault",
            "Shyam Katnagallu"
        ],
        "subjects": [
            "Materials Science",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Field evaporation from ionic or covalently bonded materials often leads to the emission of molecular ions. The metastability of these molecular ions, particularly under the influence of the intense electrostatic field (1010 Vm-1), makes them prone to dissociation with or without an exchange of energy amongst them. These processes can affect the analytical performance of atom probe tomography (APT). For instance, neutral species formed through dissociation may not be detected at all or with a time of flight no longer related to their mass, causing their loss from the analysis. Here, we evaluated the changes in the measured composition of FeO, Fe2O3 and Fe3O4 across a wide range of analysis conditions. Possible dissociation reactions are predicted by density-functional theory (DFT) calculations considering the spin states of the molecules. The energetically favoured reactions are traced on to the multi-hit ion correlation histograms, to confirm their existence within experiments, using an automated Python-based routine. The detected reactions are carefully analysed to reflect upon the influence of these neutrals from dissociation reactions on the performance of APT for analysing iron oxides.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12784"
    },
    {
        "doc_id": 360,
        "title": "FeynGame-2.1 -- Feynman diagrams made easy",
        "authors": [
            "Robert Harlander",
            "Sven Yannick Klein",
            "Magnus Schaaf"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Physics Education"
        ],
        "abstract": "FeynGame is an open-source software tool to draw Feynman diagrams, but also to get acquainted with their structure. This article reports on a number of new features which have been added to FeynGame since its first release. These include full support of LaTeX for the line and vertex labels, the possibility to automatically include momentum arrows, new graphical elements, and new pedagogical features. FeynGame is freely available as jar or MacOS app file from https://web.physik.rwth-aachen.de/user/harlander/software/feyngame, and as source code from https://gitlab.com/feyngame/FeynGame.",
        "comments": "6 pages, 2 figures. Contribution submitted to the proceedings of EPS-HEP 2023, Hamburg, Germany. See also https://www.youtube.com/@FeynGame-tp3if",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12778"
    },
    {
        "doc_id": 361,
        "title": "First spectral emissivity study of a solar selective coating in the 150 to 600 C temperature range",
        "authors": [
            "I\u00f1igo Setien-Fern\u00e1ndez",
            "Telmo Ech\u00e1niz",
            "Luis Gonz\u00e1lez-Fern\u00e1ndez",
            "Ra\u00fal Benjam\u00edn P\u00e9rez-S\u00e1ez",
            "Eva C\u00e9spedes",
            "Jose \u00c1ngel S\u00e1nchez-Garc\u00eda",
            "Leo \u00c1lvarez-Fraga",
            "Ram\u00f3n Escobar Galindo",
            "Jos\u00e9 Mar\u00eda Albella",
            "Carlos Prieto",
            "MJ Tello"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "A complete experimental study of temperature dependence of the total spectral emissivity has been performed, for the first time, for absorber reflector selective coatings used in concentrated solar power (CSP) systems for energy harvesting. The coating consist of double cermet layers of silicon oxide with different amounts of molybdenum over a silver infrared mirror layer. The experimental measurements were carried out by a high accurate radiometer (HAIRL) with controlled atmosphere in the mid-infrared and for temperatures between 150 and 600 C. The spectral emissivity is nearly constant in this temperature range. Therefore, the temperature dependence of the total emissivity is given by Planck function. These results were compared with those obtained with the usual calculus using room temperature reflectance spectrum. Finally, the performance of the coating was analyzed by comparison of coated respect to non-coated stainless steel.",
        "comments": "6 pages, 10 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12777"
    },
    {
        "doc_id": 362,
        "title": "On $p$-adic Hurwitz-type spectral zeta functions",
        "authors": [
            "Su Hu",
            "Min-Soo Kim"
        ],
        "subjects": [
            "Number Theory",
            "Mathematical Physics",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Let $\\left\\{E_n\\right\\}_{n=1}^{\\infty}$ be the set of energy levels corresponding to a Hamiltonian $H$.\n  Denote by $$\u03bb_{0}=0~~\\textrm{and}~~\u03bb_{n}=E_{n}$$\n  for $n\\in\\mathbb N.$ In this paper, we shall construct and investigate the $p$-adic counterparts of the Hurwitz-type spectral zeta function \\begin{equation} \u03b6^{H}(s,\u03bb)=\\sum_{n=0}^{\\infty}\\frac{1}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} and its alternating form \\begin{equation} \u03b6_{E}^{H}(s,\u03bb)=2\\sum_{n=0}^{\\infty}\\frac{(-1)^{n}}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} in a parallel way.",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12775"
    },
    {
        "doc_id": 363,
        "title": "Boosting macroscopic diffusion with local resetting",
        "authors": [
            "Henry Alston",
            "Thibault Bertrand"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Biological Physics"
        ],
        "abstract": "Stochastic interactions generically enhance self-diffusivity in living and biological systems, e.g. optimizing navigation strategies and controlling material properties of cellular tissues and bacterial aggregates. Despite this, the physical mechanisms underlying this nonequilibrium behavior are poorly understood. Here, we introduce a model of interactions between an agent and its environment in the form of a local stochastic resetting mechanism, in which the agent's position is set to the nearest of a predetermined array of sites with a fixed rate. We derive analytic results for the self-diffusion coefficient, showing explicitly that this mechanism enhances diffusivity. Strikingly, we show analytically that this enhancement is optimized by regular arrays of resetting sites. Altogether, our results ultimately provide the conditions for the optimization of the macroscopic transport properties of diffusive systems with local random binding interactions.",
        "comments": "6 pages (3 figures) of main text + 9 pages (4 figures) of supplementary information",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12772"
    },
    {
        "doc_id": 364,
        "title": "Deep Learning-based Intraoperative MRI Reconstruction",
        "authors": [
            "Jon Andr\u00e9 Ottesen",
            "Tryggve Storas",
            "Svein Are Sirirud Vatnehol",
            "Grethe L\u00f8vland",
            "Einar O. Vik-Mo",
            "Till Schellhorn",
            "Karoline Skogen",
            "Christopher Larsson",
            "Atle Bj\u00f8rnerud",
            "Inge Rasmus Groote-Eindbaas",
            "Matthan W. A. Caan"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Medical Physics"
        ],
        "abstract": "Purpose: To evaluate the quality of deep learning reconstruction for prospectively accelerated intraoperative magnetic resonance imaging (iMRI) during resective brain tumor surgery.\n  Materials and Methods: Accelerated iMRI was performed during brain surgery using dual surface coils positioned around the area of resection. A deep learning (DL) model was trained on the fastMRI neuro dataset to mimic the data from the iMRI protocol. Evaluation was performed on imaging material from 40 patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during tumor resection surgery. A comparative analysis was conducted between the conventional compressed sense (CS) method and the trained DL reconstruction method. Blinded evaluation of multiple image quality metrics was performed by two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the favored reconstruction variant.\n  Results: The DL reconstruction was strongly favored or favored over the CS reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3, respectively. Two of three readers consistently assigned higher ratings for the DL reconstructions, and the DL reconstructions had a higher score than their respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2, and 3, respectively. Still, the DL reconstructions exhibited shortcomings such as a striping artifact and reduced signal.\n  Conclusion: DL shows promise to allow for high-quality reconstructions of intraoperative MRI with equal to or improved perceived spatial resolution, signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and spatial resolution compared to compressed sense.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12771"
    },
    {
        "doc_id": 365,
        "title": "Improving single-molecule conductance measurements with change point detection from the econometrics toolbox",
        "authors": [
            "Joseph M. Hamill",
            "William Bro-J\u00f8rgensen",
            "Zolt\u00e1n Balogh",
            "Haixing Li",
            "Susanne Leitherer",
            "David Solomon",
            "Andr\u00e1s Halbritter",
            "Gemma Solomon"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Soft Condensed Matter"
        ],
        "abstract": "Structural breaks occur in timeseries data across a broad range of fields, from economics to nanosciences. For measurements of single-molecule break junctions, structural breaks in conductance versus displacement data occur when the molecular junction ruptures. This moment is significant because the molecule is likely in its most extended geometry, and therefore resembles most closely the geometry used in theoretical predictions. Conventional single-molecule break junction data analysis, on the other hand, typically uses the entire molecular plateau to estimate the single-molecule conductance, which skews the estimate when the plateau is sloped. Borrowing from econometrics, where the study of structural breaks is well established, we present change point detection (CPD) as a tool to search for junction rupture in single-molecule break junction data, and improve estimates in single-molecule conductance. We demonstrate that using CPD instead of the conventional 1D conductance histogram to determine the mean molecular conductance yields a standard deviation in the estimate of typically half that of the conventional approach, greatly improving accuracy. We apply CPD to three separate data sets, two on 4,4'-bipyridine and one on a silane, two at room temperature and one at 4 K, two in one lab, one in another, to show the wide applicability of even the simplest of CPD algorithms: the Chow test. This versatility and better accuracy will propagate into more accurate theoretical simulations. These improved metrics, in turn, will further improve any downstream analyses, including all emerging machine learning approaches.",
        "comments": "33 pages and 11 figures and supporting material of 8 pages and 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12769"
    },
    {
        "doc_id": 366,
        "title": "Dynamics of a two-level atom in the presence of a medium-assisted thermal field",
        "authors": [
            "Gonouiezadeh Razieh",
            "Hassan Safari"
        ],
        "subjects": [
            "Atomic Physics"
        ],
        "abstract": "In this paper the time evolution of a two-level atom in the presence of medium-assisted thermal field is explored through which, the formula of decay rate of an excited atom is generalized in two aspects. The obtained formula applies for the thermal electromagnetic field as well as the presence of arbitrary arrangement of magneto-electric media. In order to be general with respect to the material environment, the Green's function approach is used. It is seen that the non-zero temperature contributes to the decay rate via an additive term that is equal to the zero-temperature result multiplied by two times of photon number at atomic transition frequency.",
        "comments": "5 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12762"
    },
    {
        "doc_id": 367,
        "title": "Microresonator-referenced soliton microcombs with zeptosecond-level timing noise",
        "authors": [
            "Xing Jin",
            "Zhenyu Xie",
            "Xiangpeng Zhang",
            "Hanfei Hou",
            "Fangxing Zhang",
            "Xuanyi Zhang",
            "Lin Chang",
            "Qihuang Gong",
            "Qi-Fan Yang"
        ],
        "subjects": [
            "Optics",
            "Applied Physics"
        ],
        "abstract": "Optical frequency division relies on optical frequency combs to coherently translate ultra-stable optical frequency references to the microwave domain. This technology has enabled microwave synthesis with ultralow timing noise, but the required instruments are too bulky for real-world applications. Here, we develop a compact optical frequency division system using microresonator-based frequency references and comb generators. The soliton microcomb formed in an integrated Si$_3$N$_4$ microresonator is stabilized to two lasers referenced to an ultrahigh-$Q$ MgF$_2$ microresonator. Photodetection of the soliton pulse train produces 25 GHz microwaves with absolute phase noise of -141 dBc/Hz (547 zs Hz$^{-1/2}$) at 10 kHz offset frequency. The synthesized microwaves are tested as local oscillators in jammed communication channels, resulting in improved fidelity compared with those derived from electronic oscillators. Our work demonstrates unprecedented coherence in miniature microwave oscillators, providing key building blocks for next-generation timekeeping, navigation, and satellite communication systems.",
        "comments": "8 pages, 7 figures and tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12760"
    },
    {
        "doc_id": 368,
        "title": "Integration of High-Tc Superconductors with High Q Factor Oxide Mechanical Resonators",
        "authors": [
            "Nicola Manca",
            "Alexei Kalaboukhov",
            "Alejandro E. Plaza",
            "Leon\u00e9lio Cichetto Jr",
            "Emilio Bellingeri",
            "Francesco Bisio",
            "Floriana Lombardi",
            "Daniele Marr\u00e9",
            "Luca Pellegrino"
        ],
        "subjects": [
            "Applied Physics",
            "Superconductivity"
        ],
        "abstract": "Micro-mechanical resonators are building blocks of a variety of applications in basic science and applied electronics. This device technology is mainly based on well-established and reproducible silicon-based fabrication processes with outstanding performances in term of mechanical Q factor and sensitivity to external perturbations. Broadening the functionalities of MEMS by the integration of functional materials is a key step for both applied and fundamental science. However, combining functional materials and silicon-based compounds is challenging. An alternative approach is fabricating MEMS based on complex heterostructures made of materials inherently showing a variety of physical properties such as transition metal oxides. Here, we report on the integration of a high-Tc superconductor YBa2Cu3O7 (YBCO) with high Q factor micro-bridge resonator made of a single-crystal LaAlO3 (LAO) thin film. LAO resonators are tensile strained, with a stress of 345 MPa, show Q factor in the range of tens of thousands, and have low roughness. The topmost YBCO layer deposited by Pulse Laser Deposition shows a superconducting transition starting at 90 K with zero resistance below 78 K. This result opens new possibilities towards the development of advanced transducers, such as bolometers or magnetic field detectors, as well as basic science experiments in solid state physics, material science, and quantum opto-mechanics.",
        "comments": "5 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12758"
    },
    {
        "doc_id": 369,
        "title": "Circulation in turbulent flow through a contraction",
        "authors": [
            "Vivek Mugundhan",
            "Sigurdur T. Thoroddsen"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "We study experimentally the statistical properties and evolution of circulation in a turbulent flow passing through a smooth 2-D contraction. The turbulence is generated with an active grids to reach $Re_\u03bb \\simeq 220$ at the inlet to the 2.5:1 contraction. We employ time-resolved 3-D Lagrangian Particle Tracking technique with the Shake-The-Box algorithm to obtain volumetric velocity fields which we use to calculate the simultaneous circulation in three perpendicular planes. Forming a circulation vector and studying the PDFs of the relative strength of its components, we can quantify how the mean strain enhances and orients coherent vortical structures with the streamwise direction. This is further studied with streamwise space and time correlations of the circulations over a range of loop sizes. The streamwise component of the circulation, over same-size square loops, shows increased integral length, while the other two components are less affected. The circulation around the compressive direction weakens and reaches prominent negative correlation values, suggesting buckling or sharp reorientation of transverse vortices. The PDFs of circulation transit from non-Gaussian to Gaussian behavior as the loop size is increased from dissipative to large scales.",
        "comments": "Journal ref:        V. Mugundhan and S. T. Thoroddsen, Circulation in turbulent flow through a contraction, Journal of Turbulence, 24, Issue 11-12, p. 577-612 (2023)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12757"
    },
    {
        "doc_id": 370,
        "title": "Research on the knee region of cosmic ray by using a novel type of electron-neutron detector array",
        "authors": [
            "Bing-Bing Li",
            "Xin-Hua Ma",
            "Shu-Wang Cui",
            "Hao-Kun Chen",
            "Tian-Lu Chen",
            "Danzengluobu",
            "Wei Gao",
            "Hai-Bing Hu",
            "Denis Kuleshov",
            "Kirill Kurinov",
            "Hu Liu",
            "Mao-Yuan Liu",
            "Ye Liu",
            "Da-Yu Peng",
            "Yao-Hui Qi",
            "Oleg Shchegolev",
            "Yuri Stenkin",
            "Li-Qiao Yin",
            "Heng-Yu Zhang",
            "Liang-Wei Zhang"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Instrumentation and Methods for Astrophysics",
            "Instrumentation and Detectors"
        ],
        "abstract": "By accurately measuring composition and energy spectrum of cosmic ray, the origin problem of so called \"keen\" region (energy > 1 PeV) can be solved. However, up to the present, the results of the spectrum in the knee region obtained by several previous experiments have shown obvious differences, so they cannot give effective evidence for judging the theoretical models on the origin of the knee. Recently, the Large High Altitude Air Shower Observatory (LHAASO) has reported several major breakthroughs and important results in astro-particle physics field. Relying on its advantages of wide-sky survey, high altitude location and large area detector arrays, the research content of LHAASO experiment mainly includes ultra high-energy gamma-ray astronomy, measurement of cosmic ray spectra in the knee region, searching for dark matter and new phenomena of particle physics at higher energy. The electron and Thermal Neutron detector (EN-Detector) is a new scintillator detector which applies thermal neutron detection technology to measure cosmic ray extensive air shower (EAS). This technology is an extension of LHAASO. The EN-Detector Array (ENDA) can highly efficiently measure thermal neutrons generated by secondary hadrons so called \"skeleton\" of EAS. In this paper, we perform the optimization of ENDA configuration, and obtain expectations on the ENDA results, including thermal neutron distribution, trigger efficiency and capability of cosmic ray composition separation. The obtained real data results are consistent with those by the Monte Carlo simulation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12754"
    },
    {
        "doc_id": 371,
        "title": "Approximation of sea surface velocity field by fitting surrogate two-dimensional flow to scattered measurements",
        "authors": [
            "Karlo Jakac",
            "Luka Lan\u010da",
            "Ante Sikirica",
            "Stefan Ivi\u0107"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Optimization and Control"
        ],
        "abstract": "In this paper, a rapid approximation method is introduced to estimate the sea surface velocity field based on scattered measurements. The method uses a simplified two-dimensional flow model as a surrogate model, which mimics the real submesoscale flow. The proposed approach treats the interpolation of the flow velocities as an optimization problem, aiming to fit the flow model to the scattered measurements. To ensure consistency between the simulated velocity field and the measured values, the boundary conditions in the numerical simulations are adjusted during the optimization process. Additionally, the relevance of quantity and quality of the scattered measurements is assessed, emphasizing the importance of the measurement locations within the domain as well as explaining how these measurements contribute to the accuracy and reliability of the sea surface velocity field approximation. The proposed methodology has been successfully tested in both synthetic and real-world scenarios, leveraging measurements obtained from GPS drifters and HF-radar systems. The adaptability of this approach for different domains, measurement types and conditions implies that it is suitable for real-world submesoscale scenarios where only an approximation of the sea surface velocity field is sufficient.",
        "comments": "22 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12746"
    },
    {
        "doc_id": 372,
        "title": "Controlling thermal emission with metasurfaces and its applications",
        "authors": [
            "Qiongqiong Chu",
            "Fan Zhong",
            "Xiaohe Shang",
            "Ye Zhang",
            "Shining Zhu",
            "Hui Liu"
        ],
        "subjects": [
            "Optics",
            "Materials Science",
            "Applied Physics"
        ],
        "abstract": "Thermal emission caused by the thermal motion of the charged particles is commonly broadband, un-polarized, and incoherent, like a melting pot of electromagnetic waves, which makes it unsuitable for infrared applications in many cases requiring specific thermal emission properties. Metasurfaces, characterized by two-dimensional subwavelength artificial nanostructures, have been extensively investigated for their flexibility in tuning optical properties, which provide an ideal platform for shaping thermal emission. Recently, remarkable progress was achieved not only in tuning thermal emission in multiple degrees of freedom, such as wavelength, polarization, radiation angle, coherence, and so on but also in applications of compact and integrated optical devices. Here, we review the recent advances in the regulation of thermal emission through metasurfaces and corresponding infrared applications, such as infrared sensing, radiative cooling, and thermophotovoltaic devices.",
        "comments": "28 pages, 10 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12737"
    },
    {
        "doc_id": 373,
        "title": "Experimental verification of the anomalous skin effect in copper using emissivity measurements",
        "authors": [
            "Telmo Ech\u00e1niz",
            "I\u00f1igo Seti\u00e9n-Fern\u00e1ndez",
            "Ra\u00fal Benjam\u00edn P\u00e9rez-S\u00e1ez",
            "Manuel Jos\u00e9 Tello"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Spectral directional emissivity has been measured in copper between 3 and 24 \u03bcm above room temperature. The experimental spectrum shows a weak broad peak between 7 and 14 \u03bcm, which is much more acute for higher emission angles. However, the peak width and position are both independent of the emission angle. The experimental results are in very good agreement with the semiclassical theory of the optical properties of metals in the regime of the anomalous skin effect, in particular with the asymptotic approximation. This comparison suggests that this work shows an optical experimental evidence of the anomalous skin effect.",
        "comments": "4 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12727"
    },
    {
        "doc_id": 374,
        "title": "On A Proof of the ADKMV Conjecture",
        "authors": [
            "Zhiyuan Wang",
            "Chenglang Yang",
            "Jian Zhou"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Algebraic Geometry",
            "Exactly Solvable and Integrable Systems"
        ],
        "abstract": "We present a mathematical proof of a conjectural formula due to Aganagic, Dijkgraaf, Klemm, Mari\u00f1o and Vafa, expressing the topological vertex as a Bogoliubov transform of the fermionic vacuum. In our proof we introduce a boson-fermionic field assignment which generalizes the well-known boson-fermion correspondence. The proof also works for the generalization to the framed topological vertex made by Deng and Zhou. As a consequence, partition functions of toric Calabi-Yau threefolds are related to tau-functions of multi-component KP hierarchy.",
        "comments": "36 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12726"
    },
    {
        "doc_id": 375,
        "title": "A regular MOG black hole's impact on shadows and gravitational weak lensing in the presence of quintessence field",
        "authors": [
            "Ahmad Al-Badawi",
            "Sanjar Shaymatov",
            "Mirzabek Alloqulov",
            "Anzhong Wang"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "We investigate the impact of the modified gravity (MOG) field and the quintessence scalar field on horizon evolution, black hole (BH) shadow and the weak gravitational lensing around a static spherically symmetric BH. We first begin to write the BH metric associated with the MOG parameter and quintessence scalar field. We then determine the BH shadow and obtain numerical solutions for the photon sphere and shadow radius. We show that the MOG ($\u03b1$) and the quintessence ($c$) parameters have a significant impact on BH shadow and photon sphere. Based on the analysis, we further show that the combined effects of the MOG parameter and quintessential field can increase the values of BH shadow and photon sphere radii. We also obtain constraints on the BH parameters by applying the observational data of Sgr A$^{\\star}$ and M87$^{\\star}$. Finally, we consider the weak deflection angle of BH within the context of the Gauss-Bonnet theorem (GBT) and show that the combined effects of the MOG and quintessence parameters do make the value of the deflection angle grow, referring to remarkable property being in well agreement with the physical meaning of both parameters that can maintain the strong gravitational field in the surrounding environment of BH.",
        "comments": "14 pages, 2 tables, 9 captioned figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12723"
    },
    {
        "doc_id": 376,
        "title": "Device-independent quantum state discrimination",
        "authors": [
            "Lin Chen",
            "Xinyu Qiu"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Quantum state discrimination depicts the general progress of extracting classical information from quantum systems. We show that quantum state discrimination can be realized in a device-independent scenario using tools of self-testing results. That is, the states can be discriminated credibly with the untrusted experiment devices by the correspondence between quantum correlations and states. In detail, we show that two arbitrary states can be discriminated in a device-independent manner when they are not conjugate with each other, while other states can be discriminated measurement-device-independently. To fulfill the device-independent requirement, the measurements are restricted on Pauli observables. The influence of this restriction is acceptable based on the guessing probability analysis for minimum error discrimination.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12719"
    },
    {
        "doc_id": 377,
        "title": "Gas trap prediction from 3D seismic and well test data using machine learning",
        "authors": [
            "Dmitry Ivlev"
        ],
        "subjects": [
            "Geophysics",
            "Machine Learning"
        ],
        "abstract": "The aim of this work is to create and apply a methodological approach for predicting gas traps from 3D seismic data and gas well testing. The paper formalizes the approach to creating a training dataset by selecting volumes with established gas saturation and filtration properties within the seismic wavefield. The training dataset thus created is used in a process stack of sequential application of data processing methods and ensemble machine learning algorithms. As a result, a cube of calibrated probabilities of belonging of the study space to gas reservoirs was obtained. The high efficiency of this approach is shown on a delayed test sample of three wells (blind wells). The final value of the gas reservoir prediction quality metric f1 score was 0.893846.",
        "comments": "11 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12717"
    },
    {
        "doc_id": 378,
        "title": "On positively divisible non-Markovian processes",
        "authors": [
            "Bilal Canturk",
            "Heinz-Peter Breuer"
        ],
        "subjects": [
            "Probability",
            "Mathematical Physics"
        ],
        "abstract": "There are some positively divisible non-Markovian processes whose transition matrices satisfy the Chapman-Kolmogorov equation. These processes should also satisfy the Kolmogorov consistency conditions, an essential requirement for a process to be classified as a stochastic process. Combining the Kolmogorov consistency conditions with the Chapman-Kolmogorov equation, we derive a necessary condition for positively divisible stochastic processes on a finite sample space. This necessary condition enables a systematic approach to the manipulation of certain Markov processes in order to obtain a positively divisible non-Markovian process. We illustrate this idea by an example and, in addition, analyze a classic example given by Feller in the light of our approach.",
        "comments": "14 pages, 1 figure",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12715"
    },
    {
        "doc_id": 379,
        "title": "New spectral-parameter dependent solutions of the Yang-Baxter equation",
        "authors": [
            "Alexander. S. Garkun",
            "Suvendu K. Barik",
            "Aleksey K. Fedorov",
            "Vladimir Gritsev"
        ],
        "subjects": [
            "Quantum Physics",
            "Exactly Solvable and Integrable Systems"
        ],
        "abstract": "The Yang-Baxter Equation (YBE) plays a crucial role for studying integrable many-body quantum systems. Many known YBE solutions provide various examples ranging from quantum spin chains to superconducting systems. Models of solvable statistical mechanics and their avatars are also based on YBE. Therefore, new solutions of the YBE could be used to construct new interesting 1D quantum or 2D classical systems with many other far-reaching applications. In this work, we attempt to find (almost) exhaustive set of solutions for the YBE in the lowest dimensions corresponding to a two-qubit case. We develop an algorithm, which can potentially be used for generating new higher-dimensional solutions of the YBE.",
        "comments": "28 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12710"
    },
    {
        "doc_id": 380,
        "title": "An ion trap design for a space-deployable strontium-ion optical clock",
        "authors": [
            "Alessio Spampinato",
            "Jonathan Stacey",
            "Sean Mulholland",
            "Billy I. Robertson",
            "Hugh A. Klein",
            "Guilong Huang",
            "Geoffrey P. Barwood",
            "Patrick Gill"
        ],
        "subjects": [
            "Atomic Physics",
            "Quantum Physics"
        ],
        "abstract": "Optical atomic clocks demonstrate a better stability and lower systematic uncertainty than the highest performance microwave atomic clocks. However, the best performing optical clocks have a large footprint in a laboratory environment and require specialist skills to maintain continuous operation. Growing and evolving needs across several sectors are increasing the demand for compact robust and portable devices at this capability level. In this paper we discuss the design of a physics package for a compact laser-cooled 88Sr+ optical clock that would, with further development, be suitable for space deployment. We review the design parameters to target a relative frequency uncertainty at the low parts in 10^18 with this system. We then explain the results of finite element modelling to simulate the response of the ion trap and vacuum chamber to vibration, shock and thermal conditions expected during launch and space deployment. Additionally, an electrostatic model has been developed to investigate the relationship between the ion trap geometrical tolerances and the trapping efficiency. We present the results from these analyses that have led to the design of a more robust prototype ready for experimental testing.",
        "comments": "21 Pages, 20 Figures, Approved for publication in \"Proceedings of the Royal Society A\"",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12706"
    },
    {
        "doc_id": 381,
        "title": "Curvature effect induce topological phase transitions in two dimensional topological superconductor",
        "authors": [
            "Huan-Wen Lai",
            "Meng-Chien Wang",
            "Ching-Ray Chang",
            "Seng-Ghee Tan"
        ],
        "subjects": [
            "Superconductivity"
        ],
        "abstract": "Recently, topological superconductor is one of the important topics in condensed matter physics due to the exotic features of quasiparticles resided on the edge, surface and vortex core. In our work, we analyze the two dimensional s+p wave noncentrosymmetric superconductor(NCS) with Rashba spin-orbit coupling in 2D cylindrical coordinate to find the relationship between the topological phase transition and the curvature. With analytical calculation and numerical analyze, we confirm that the topological phase transition in s+p wave NCS in 2D cylindrical coordinate is related to the curvature from band theory perspective.",
        "comments": "9 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12705"
    },
    {
        "doc_id": 382,
        "title": "Quandles as pre-Lie skew braces, set-theoretic Hopf algebras & universal R-matrices",
        "authors": [
            "Anastasia Doikou",
            "Bernard Rybolowicz",
            "Paola Stefanelli"
        ],
        "subjects": [
            "Quantum Algebra",
            "Mathematical Physics",
            "Rings and Algebras"
        ],
        "abstract": "We present connections between left non-degenerate solutions of set-theoretic Yang-Baxter equation and left shelves using certain maps called Drinfel'd homomorphisms. We further generalise the notion of affine quandle, by using heap endomorphisms and metahomomorphisms, and identify the Yang-Baxter algebra for solutions of the braid equation associated to a given quandle. We introduce the notion of the pre-Lie skew brace and identify certain affine quandles that give rise to pre-Lie skew braces. Generalisations of the braiding of a group, associated to set-theoretic solutions of the braid equation is also presented. These generalized structures encode part of the underlying Hopf algebra. Indeed, we also introduce the quasi-triangular Hopf algebras and the universal R-matrices for quandle algebras and for set-theoretic Yang-Baxter algebras. In fact, we obtain the universal R-matrix for the set-theoretic Yang-Baxter algebras after identifying the associated admissible Drinfel'd twist. Generic set-theoretic solutions coming from heap endomorphisms are also identified.",
        "comments": "36 pages LaTex",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12704"
    },
    {
        "doc_id": 383,
        "title": "Imaging of Antiferroelectric Dark Modes in an Inverted Plasmonic Lattice",
        "authors": [
            "Javier Rodriguez Alvarez",
            "Amilcar Labarta",
            "Juan Carlos Idrobo",
            "Rossana Dell Anna",
            "Alessandro Cian",
            "Damiano Giubertoni",
            "Xavier Borrise",
            "Albert Guerrero",
            "Francesc Perez Murano",
            "Arantxa Fraile Rodriguez",
            "Xavier Batlle"
        ],
        "subjects": [
            "Optics",
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "Plasmonic lattice nanostructures are of technological interest because of their capacity to manipulate light below the diffraction limit. Here, we present a detailed study of dark and bright modes in the visible and near-infrared energy regime of an inverted plasmonic honeycomb lattice by a combination of Au+ focused ion beam lithography with nanometric resolution, optical and electron spectroscopy, and finite-difference time-domain simulations. The lattice consists of slits carved in a gold thin film, exhibiting hotspots and a set of bright and dark modes. We proposed that some of the dark modes detected by electron energy-loss spectroscopy are caused by antiferroelectric arrangements of the slit polarizations with two times the size of the hexagonal unit cell. The plasmonic resonances take place within the 0.5_2 eV energy range, indicating that they could be suitable for a synergistic coupling with excitons in two-dimensional transition metal dichalcogenides materials or for designing nanoscale sensing platforms based on near-field enhancement over a metallic surface.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12702"
    },
    {
        "doc_id": 384,
        "title": "Optical Snake States in Photonic Graphene",
        "authors": [
            "O. M. Bahrova",
            "S. V. Koniakhin",
            "A. V. Nalitov",
            "E. D. Cherotchenko"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Quantum Gases",
            "Optics"
        ],
        "abstract": "We propose an optical analogue of electron snake states based on artificial gauge magnetic field in photonic graphene with effective strain implemented by varying distance between pillars. We develop an intuitive and exhaustive continuous model based on tight-binding approximation and compare it with numerical simulations of a realistic photonic structure. The allowed lateral propagation direction is shown to be strongly coupled to the valley degree of freedom and the proposed photonic structure may be used a valley filter.",
        "comments": "5+4 pages, 4+5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12695"
    },
    {
        "doc_id": 385,
        "title": "The effect of contact angle hysteresis on a droplet in a viscoelastic two-phase system",
        "authors": [
            "Kazem Bazesefidpar",
            "Outi Tammisola"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "We investigate the dynamic behaviour of a two-dimensional (2D) droplet adhering to a wall in Poiseuille flow at low Reynolds numbers, in a system where either the droplet is viscoelastic (V/N) or the surrounding medium (N/V). The results reveal that the deformation of the viscoelastic drop over time is changed due to the presence of polymeric molecules. In the first stage, the viscoelastic droplet speeds up and deforms faster, while in the second stage, the Newtonian counterpart accelerates and its deformation outpaces the viscoelastic droplet. The deformation of viscoelastic drop is retarded significantly in the second stage with increasing Deborah number $De$. In the V/N case, the viscous bending is enhanced on the receding side for small $De$, but it is weakened by further increase in $De$, and this non-monotonic behavior brings about an increase in the receding contact line velocity at small $De$ and a decrease at large $De$. On the advancing side, the viscous bending is decreased monotonically for $Ca<0.25$, and hence the advancing contact line velocity is decreased with increasing $De$; however, the viscous bending presents a non-monotonic behavior for $Ca=0.25$ at the advancing side. The non-monotonic behavior on the receding side is attributed to the emergence of outward pulling stresses in the vicinity of the receding contact line and the inception of strain-hardening at higher $De$, while the reduction in the viscous bending at the advancing side is the result of just strain-hardening due to the presence of dominant extensional flow on the advancing side. Finally, in the N/V system, the viscoelasticity of the medium suppresses the droplet deformation on both receding and advancing sides, and this effect is more pronounced with increasing De; the weakening effect of viscous bending is enhanced significantly at the advancing side by increasing the Giesekus mobility parameter.",
        "comments": "35 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12693"
    },
    {
        "doc_id": 386,
        "title": "Effect of variable crustal density on the surface magnetic field of Radio Pulsars",
        "authors": [
            "Kathleen Sellick",
            "Subharthi Ray"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "We study the surface magnetic field fluctuations due to radial oscillations as a viable cause for the micro structures of the radio pulsar pulse patterns. The electrical conductivity of matter in the outer layer of the crust of a neutron star (NS) plays a crucial role in the resulting surface magnetic field if we assume that the magnetic field is confined to this layer. This outer layer has a rapidly varying matter density - that changes the micro-physics of the material affecting the electrical conductivity at every stage of the density change. In this study, the varying electrical conductivity in this rapidly varying density regime of the outer layer of the NS crust - from $\\sim 10^{11}~g~cm^{-3}$ to about $10^4~g~cm^{-3}$ - has been used to calculate the surface magnetic field using the induction equation. A finite effect of the strong gravitational field at the NS surface has also been taken into account. The equations have been solved in MATLAB using the method of lines. Any minor radial fluctuation due to stellar oscillation, in particular the radial oscillations, leads to a fluctuation of the electrical conductivity in the outer layer of the crust. This leads to fluctuations in the surface magnetic field with a frequency equal to the frequency of the stellar oscillation. We find that not only the variation of the surface magnetic field is substantial, but also it does not remain constant throughout the lifetime of the NS.",
        "comments": "9 pages, 6 figures, 1 table. Accepted for publication in Monthly Notices of Royal Astronomical Society",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12692"
    },
    {
        "doc_id": 387,
        "title": "Uncertainty quantification in the machine-learning inference from neutron star probability distribution to the equation of state",
        "authors": [
            "Yuki Fujimoto",
            "Kenji Fukushima",
            "Syo Kamata",
            "Koichi Murase"
        ],
        "subjects": [
            "Nuclear Theory",
            "High Energy Astrophysical Phenomena",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We discuss the machine-learning inference and uncertainty quantification for the equation of state (EoS) of the neutron star (NS) matter directly using the NS probability distribution from the observations. We previously proposed a prescription for uncertainty quantification based on ensemble learning by evaluating output variance from independently trained models. We adopt a different principle for uncertainty quantification to confirm the reliability of our previous results. To this end, we carry out the MC sampling of data to infer an EoS and take the convolution with the probability distribution of the observational data. In this newly proposed method, we can deal with arbitrary probability distribution not relying on the Gaussian approximation. We incorporate observational data from the recent multimessenger sources including precise mass measurements and radius measurements. We also quantify the importance of data augmentation and the effects of prior dependence.",
        "comments": "34 pages, 2 tables, 13 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12688"
    },
    {
        "doc_id": 388,
        "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
        "authors": [
            "Zhishuai Li",
            "Yunhao Nie",
            "Ziyue Li",
            "Lei Bai",
            "Yisheng Lv",
            "Rui Zhao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Kriging aims at estimating the attributes of unsampled geo-locations from observations in the spatial vicinity or physical connections, which helps mitigate skewed monitoring caused by under-deployed sensors. Existing works assume that neighbors' information offers the basis for estimating the attributes of the unobserved target while ignoring non-neighbors. However, non-neighbors could also offer constructive information, and neighbors could also be misleading. To this end, we propose ``Contrastive-Prototypical'' self-supervised learning for Kriging (KCP) to refine valuable information from neighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we conduct the Kriging task from a new perspective of representation: we aim to first learn robust and general representations and then recover attributes from representations. A neighboring contrastive module is designed that coarsely learns the representations by narrowing the representation distance between the target and its neighbors while pushing away the non-neighbors. In parallel, a prototypical module is introduced to identify similar representations via exchanged prediction, thus refining the misleading neighbors and recycling the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. To encourage the two modules above to learn general and robust representations, we design an adaptive augmentation module that incorporates data-driven attribute augmentation and centrality-based topology augmentation over the spatiotemporal Kriging graph data. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness. The code is available at https://github.com/bonaldli/KCP",
        "comments": "Accepted in AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12681"
    },
    {
        "doc_id": 389,
        "title": "Analysis of the isospin eigenstate $\\bar D \u03a3_c$, $\\bar D^{*} \u03a3_c$, and $\\bar D \u03a3_c^{*}$ pentaquarks by their electromagnetic properties",
        "authors": [
            "U. \u00d6zdem"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "High Energy Physics - Lattice"
        ],
        "abstract": "To shed light on the nature of the controversial and not yet fully understood exotic states, we are carrying out a systematic study of their electromagnetic properties. The magnetic moment of a hadron state is as fundamental a dynamical quantity as its mass and contains valuable information on the deep underlying structure. In this study, we use the QCD light-cone sum rule to extract the magnetic moments of the $\\mathrm{P_{c}(4312)}$, $\\mathrm{P_{c}(4380)}$, and $\\mathrm{P_{c}(4440)}$ pentaquarks by considering them as the molecular picture with spin-parity $\\mathrm{J^P= \\frac{1}{2}^-}$, $\\mathrm{J^P= \\frac{3}{2}^-}$, and $\\mathrm{J^P= \\frac{3}{2}^-}$, respectively. We define the isospin of the interpolating currents of these states, which is the key to solving the puzzle of the hidden-charm pentaquark states, in order to make these analyses more precise and reliable. We have compared our results with other theoretical predictions that could be a useful complementary tool for the interpretation of the hidden-charm pentaquark sector, and we observe that they are not in mutual agreement with each other. We have also calculated higher multipole moments for spin-3/2 $\\bar D^{*} \u03a3_c$ and $\\bar D \u03a3_c^{*}$ pentaquarks, indicating a non-spherical charge distribution.",
        "comments": "12 pages, 2 tables and 1 figure",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12678"
    },
    {
        "doc_id": 390,
        "title": "Anti-resonant acoustic waveguides enabled tailorable Brillouin scattering on chip",
        "authors": [
            "Peng Lei",
            "Mingyu Xu",
            "Yunhui Bai",
            "Zhangyuan Chen",
            "Xiaopeng Xie"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Empowering independent control of optical and acoustic modes and enhancing the photon-phonon interaction, integrated photonics boosts the advancements of on-chip stimulated Brillouin scattering (SBS). However, achieving acoustic waveguides with low loss, tailorability, and easy fabrication remains a challenge. Here, inspired by the optical anti-resonance in hollow-core fibers, we propose suspended anti-resonant acoustic waveguides (SARAWs) with superior confinement and high selectivity of acoustic modes, supporting both forward and backward SBS on chip. Furthermore, this structure streamlines the design and fabrication processes. Leveraging the advantages of SARAWs, we have showcased a series of record-breaking results for SBS within a compact footprint on the silicon-on-insulator platform. For forward SBS, a centimeter-scale SARAW supports a large net gain exceeding 6.4 dB. For backward SBS, we have observed an unprecedented Brillouin frequency shift of 27.6 GHz and a mechanical quality factor of up to 1,960 in silicon waveguides. This paradigm of acoustic waveguide propels SBS into a new era, unlocking new opportunities in the fields of optomechanics, phononic circuits, and hybrid quantum systems.",
        "comments": "18 pages, 13 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12677"
    },
    {
        "doc_id": 391,
        "title": "Chern numbers in two-dimensional systems with spiral boundary conditions",
        "authors": [
            "Masaaki Nakamura",
            "Shohei Masuda"
        ],
        "subjects": [
            "Strongly Correlated Electrons"
        ],
        "abstract": "We discuss methods for calculating Chern numbers of two-dimensional lattice systems using spiral boundary conditions, which sweep all lattice sites in one-dimensional order. Specifically, we establish the one-dimensional representation of Fukui-Hatsugai-Suzuki's method, based on lattice gauge theory, and the Coh-Vanderbilt's method, which relates to electronic polarization. The essential point of this discussion is that the insertion of flux into the extended one-dimensional chain generates an effective current in the perpendicular direction. These methods are valuable not only for a unified understanding of topological physics in different dimensions but also for numerical calculations, including the density matrix renormalization group.",
        "comments": "10 pages, 7 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12674"
    },
    {
        "doc_id": 392,
        "title": "Wavelength dependence of nitrogen-vacancy center charge cycling",
        "authors": [
            "A. A. Wood",
            "A. Lozovoi",
            "R. M. Goldblatt",
            "C. A. Meriles",
            "A. M. Martin"
        ],
        "subjects": [
            "Applied Physics",
            "Quantum Physics"
        ],
        "abstract": "Optically-active spin qubits in wide-bandgap semiconductors exist in several charge states, though typically only specific charge states exhibit desirable spin or photonic properties. An understanding of how interconversion between different charge states occurs is important for most applications seeking to employ such defects in quantum sensing and information processing, and additionally serves as a means of testing and verifying models of the defect electronic structure. Here, we use charge-sensitive confocal imaging to study the wavelength dependence of optical carrier generation in diamonds hosting nitrogen-vacancy (NV) centers, silicon vacancy (SiV) centers and substitutional nitrogen (N). We study the generation of distinctive charge-capture patterns formed when photogenerated charge carriers are captured by photoluminescent defects, using light spanning 405-633\\,nm (1.96-3.06\\,eV). We observe distinct regimes where one- or two-photon ionization or recombination processes dominate, and a third regime where anti-Stokes mediated recombination drives weak NV charge cycling with red light. We then compare red-induced charge cycling to fast charge carrier transport between isolated single NV centers driven with green and blue light. This work reports new optically-mediated charge cycling processes of the NV centers, and has consequences for schemes using charge transfer to identify non-luminescent defects and photoelectric detection, where ambiguity exists as to the source of photocurrent.",
        "comments": "12 pages, 5 figures, comments welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12668"
    },
    {
        "doc_id": 393,
        "title": "How do ionic superdiscs self-assemble in nanopores?",
        "authors": [
            "Zhuoqing Li",
            "Aileen R. Raab",
            "Mohamed A. Kolmangadi",
            "Mark Busch",
            "Marco Grunwald",
            "Felix Demel",
            "Florian Bertram",
            "Andriy V. Kityk",
            "Andreas Schoenhals",
            "Sabine Laschat",
            "Patrick Huber"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Mesoscale and Nanoscale Physics",
            "Materials Science",
            "Applied Physics",
            "Chemical Physics"
        ],
        "abstract": "Discotic ionic liquid crystals (DILCs) consist of self-assembled superdiscs of cations and anions that spontaneously stack in linear columns with high one-dimensional ionic and electronic charge mobility, making them prominent model systems for functional soft matter. Unfortunately, a homogeneous alignment of DILCs on the macroscale is often not achievable, which significantly limits their applicability. Infiltration into nanoporous solid scaffolds can in principle overcome this drawback. However, due to the extreme experimental challenges to scrutinise liquid crystalline order in extreme spatial confinement, little is known about the structures of DILCs in nanopores. Here, we present temperature-dependent high-resolution optical birefringence measurement and 3D reciprocal space mapping based on synchrotron-based X-ray scattering to investigate the thermotropic phase behaviour of dopamine-based ionic liquid crystals confined in cylindrical channels of 180~nm diameter in macroscopic anodic aluminum oxide (AAO) membranes. As a function of the membranes' hydrophilicity and thus the molecular anchoring to the pore walls (edge-on or face-on) and the variation of the hydrophilic-hydrophobic balance between the aromatic cores and the alkyl side chain motifs of the superdiscs by tailored chemical synthesis, we find a particularly rich phase behaviour, which is not present in the bulk state. It is governed by a complex interplay of liquid crystalline elastic energies (bending and splay deformations), polar interactions and pure geometric confinement, and includes textural transitions between radial and axial alignment of the columns with respect to the long nanochannel axis.",
        "comments": "19 pages, 9 figures, 1 ancillary file",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12663"
    },
    {
        "doc_id": 394,
        "title": "Negative cosmological constant in the dark energy sector: tests from JWST photometric and spectroscopic observations of high-redshift galaxies",
        "authors": [
            "Nicola Menci",
            "Shahnawaz A. Adil",
            "Upala Mukhopadhyay",
            "Anjan A. Sen",
            "Sunny Vagnozzi"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics",
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Early observations with the James Webb Space Telescope (JWST) have revealed the existence of an unexpectedly large abundance of extremely massive galaxies at redshifts $z \\gtrsim 5$: these observations are in tension with the predictions not only of the standard $\u039b$CDM cosmology, but also with those of a wide class of dynamical dark energy (DE) models, and are generally in better agreement with models characterized by a phantom behaviour. Here we consider a model, inspired by string theory and the ubiquity of anti-de Sitter vacua therein, featuring an evolving DE component with positive energy density on top of a negative cosmological constant, argued in an earlier exploratory analysis to potentially be able to explain the JWST observations. We perform a robust comparison of this model against JWST data, considering both photometric observations from the CEERS program, and spectroscopic observations from the FRESCO survey. We show that the model is able to accommodate the JWST observations, with a consistency probability of up to $98\\%$, even in the presence of an evolving component with a quintessence-like behaviour (easier to accommodate theoretically compared to phantom DE), while remaining consistent with standard low-redshift probes. Our results showcase the tremendous potential of measurements of high-redshift galaxy abundances in tests of fundamental physics, and their valuable complementarity with standard cosmological probes.",
        "comments": "19 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12659"
    },
    {
        "doc_id": 395,
        "title": "A length scale for non-local multi-scale gradient interactions in isotropic turbulence",
        "authors": [
            "Miguel P. Encinar"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "Three-dimensional turbulent flows enhance velocity gradients via strong non-linear interactions of the rate-of-strain tensor with the vorticity vector, and with itself. For statistically homogeneous flows, their total contributions to gradient production are related to each other by conservation of mass, and so are the total enstrophy and total dissipation. However, locally they do not obey this relation and have different (often extreme) values, and for this reason both production mechanisms have been subject to numerous studies, often decomposed in multiscale interactions. In general lines, their dynamics and contributions to the cascade processes and turbulent kinetic dissipation are different, which posses a difficulty for turbulence modelling. In this paper, we explore the consequence of the 'Betchov' relations locally, and show that they implicitly define a length scale. This length scale is found to be about three times the size of the turbulent structures and their interactions. It is also found that while the non-locality of the dissipation and enstrophy at a given scale comes mostly from larger scales that do not cancel, the non-local production of strain and vorticity comes from multiscale interactions. An important consequence of this work is that isotropic cascade models need not distinguish between vortex stretching and strain self-amplification, but can instead consider both entities part of a more complex transfer mechanism, provided that their detailed point-value is not required and a local average of reasonable size is sufficient.",
        "comments": "11 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12658"
    },
    {
        "doc_id": 396,
        "title": "Electronic and magnetic excitations in La$_3$Ni$_2$O$_7$",
        "authors": [
            "Xiaoyang Chen",
            "Jaewon Choi",
            "Zhicheng Jiang",
            "Jiong Mei",
            "Kun Jiang",
            "Jie Li",
            "Stefano Agrestini",
            "Mirian Garcia-Fernandez",
            "Xing Huang",
            "Hualei Sun",
            "Dawei Shen",
            "Meng Wang",
            "Jiangping Hu",
            "Yi Lu",
            "Ke-Jin Zhou",
            "Donglai Feng"
        ],
        "subjects": [
            "Superconductivity"
        ],
        "abstract": "The striking discovery of high-temperature superconductivity (HTSC) of 80 K in a bilayer nickelate La$_3$Ni$_2$O$_7$ under a moderately high pressure of about 14 GPa ignited a new wave of studying HTSC in nickelates. The properties of the parental phase at ambient pressure may contain key information on basic interactions therein and bosons that may mediate pairing giving birth to superconductivity. Moreover, the bilayer structure of La$_3$Ni$_2$O$_7$ may suggest a distinct minimal model in comparison to cuprate superconductors. Here using X-ray absorption spectroscopy and resonant inelastic X-ray scattering, we studied La$_3$Ni$_2$O$_7$ at ambient pressure, and found that Ni 3$d_{x^2-y^2}$, Ni 3$d_{z^2}$, and ligand oxygen 2$p$ orbitals dominate the low-energy physics with a small charge-transfer energy. Remarkably, well-defined optical-like magnetic excitations were found to soften into a quasi-static spin-density-wave ordering, evidencing the strong electronic correlations and rich magnetic properties. Based on a Heisenberg spin model, we found that the inter-layer effective magnetic superexchange interaction is much larger than the intra-layer ones, and proposed two viable magnetic structures. Our results set the foundation for further exploration of La$_3$Ni$_2$O$_7$ superconductor.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12657"
    },
    {
        "doc_id": 397,
        "title": "Brillouin nonlinearity characterizations of a high-refractive index silicon oxynitride platform",
        "authors": [
            "Kaixuan Ye",
            "Akshay Keloth",
            "Yvan Klaver",
            "Alessio Baldazzi",
            "Gioele Piccoli",
            "Matteo Sanna",
            "Lorenzo Pavesi",
            "Mher Ghulinyan",
            "David Marpaung"
        ],
        "subjects": [
            "Optics",
            "Applied Physics"
        ],
        "abstract": "Silicon oxynitride (SiON) is a low-loss and versatile material for linear and nonlinear photonics applications. Controlling the oxygen-to-nitrogen (O/N) ratio in SiON provides an effective way to engineer its optical and mechanical properties, making it a great platform for the investigation of on-chip optomechanical interactions, especially the stimulated Brillouin scattering (SBS). Here we report the Brillouin nonlinearity characterization of a SiON platform with a specific O/N ratio (characterized by a refractive index of $n=1.65$). First, we introduce this particular SiON platform with fabrication details. Subsequently, we discuss various techniques for the on-chip Brillouin nonlinearity characterizations. In particular, we focus on the intensity-modulated pump-probe lock-in amplifier technique, which enables ultra-sensitive characterization. Finally, we analyze the Brillouin nonlinearities of this SiON platform and compare them with other SiON platforms. This work underscores the potential of SiON for on-chip Brillouin-based applications. Moreover, it paves the way for Brillouin nonlinearity characterization across various material platforms.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12651"
    },
    {
        "doc_id": 398,
        "title": "Geometry of Mechanics",
        "authors": [
            "Miguel C. Mu\u00f1oz-Lecanda",
            "Narciso Rom\u00e1n-Roy"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "We study the geometry underlying mechanics and its application to describe autonomous and nonautonomous conservative dynamical systems of different types; as well as dissipative dynamical systems. We use different geometric descriptions to study the main properties and characteristics of these systems; such as their Lagrangian, Hamiltonian and unified formalisms, their symmetries, the variational principles, and others. The study is done mainly for the regular case, although some comments and explanations about singular systems are also included.",
        "comments": "237 pages. This is a draft version of a future book. Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12650"
    },
    {
        "doc_id": 399,
        "title": "On the physical nature of pseudogap phase and anomalous transfer of spectral weight in underdoped cuprates",
        "authors": [
            "Kirill Mitsen",
            "Olga Ivanenko"
        ],
        "subjects": [
            "Superconductivity"
        ],
        "abstract": "It is shown that many anomalies observed in underdoped cuprates, including anomalous spectral weight transfer and a large pseudogap, appear to have a common nature due to both the cluster structure of the underdoped phase and the specific mechanism of superconducting pairing. The combined action of these factors leads to the fact that at a temperature T lying in a certain temperature range Tc<T<T*, the crystal contains small isolated clusters that can exist both in superconducting and normal states, randomly switching between them. In this case, below Tc with a very high probability the cluster is in a superconducting state, and above T* it is in a normal state, and the interval Tc<T<T* is the region of existence of the so-called pseudogap phase. The temperatures Tc and T* for YBa2Cu3O6+d were calculated depending on the doping level d. The calculation results are in good agreement with experiment without the use of fitting parameters. At a given T in the same temperature range, the time sequence of randomly arising superfluid density pulses from each cluster can be represented as a random process. The effective width of the spectrum of such a random process will be determined by a correlation time, i.e. the characteristic time between successive on/off superconductivity in two different clusters. This time, according to the estimate, is ~10^(-15) sec, which corresponds to the effective width of the spectrum ~1 eV and explains the effect of spectral weight transfer to the high-frequency region. This approach also makes it possible to explain other anomalies observed in the vicinity of Tc: the reversibility of magnetization curves in a certain temperature range below Tc, the anomalous Nernst effect and anomalous diamagnetism above Tc.",
        "comments": "17 pages, 7 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12647"
    }
]