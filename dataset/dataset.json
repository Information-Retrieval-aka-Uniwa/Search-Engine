[
    {
        "doc_id": 0,
        "title": "Non-perturbative Wavefunction of the Universe in Inflation with (Resonant) Features",
        "authors": [
            "Paolo Creminelli",
            "S\u00e9bastien Renaux-Petel",
            "Giovanni Tambalo",
            "Vicharit Yingcharoenrat"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Cosmology and Nongalactic Astrophysics",
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "We study the statistics of scalar perturbations in models of inflation with small and rapid oscillations in the inflaton potential (resonant non-Gaussianity). We do so by deriving the wavefunction $\u03a8[\u03b6(\\boldsymbol{x})]$ non-perturbatively in $\u03b6$, but at first order in the amplitude of the oscillations. The expression of the wavefunction of the universe (WFU) is explicit and does not require solving partial differential equations. One finds qualitative deviations from perturbation theory for $ |\u03b6| \\gtrsim \u03b1^{-2}$, where $\u03b1\\gg 1$ is the number of oscillations per Hubble time. Notably, the WFU exhibits distinct behaviours for negative and positive values of $\u03b6$ (troughs and peaks respectively). While corrections for $\u03b6<0$ remain relatively small, of the order of the oscillation amplitude, positive $\u03b6$ yields substantial effects, growing exponentially as $e^{\u03c0\u03b1/2}$ in the limit of large $\u03b6$. This indicates that even minute oscillations give large effects on the tail of the distribution.",
        "comments": "56 pages, 10 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10212"
    },
    {
        "doc_id": 1,
        "title": "Maximal-Capacity Discrete Memoryless Channel Identification",
        "authors": [
            "Maximilian Egger",
            "Rawad Bitar",
            "Antonia Wachter-Zeh",
            "Deniz G\u00fcnd\u00fcz",
            "Nir Weinberger"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning"
        ],
        "abstract": "The problem of identifying the channel with the highest capacity among several discrete memoryless channels (DMCs) is considered. The problem is cast as a pure-exploration multi-armed bandit problem, which follows the practical use of training sequences to sense the communication channel statistics. A capacity estimator is proposed and tight confidence bounds on the estimator error are derived. Based on this capacity estimator, a gap-elimination algorithm termed BestChanID is proposed, which is oblivious to the capacity-achieving input distribution and is guaranteed to output the DMC with the largest capacity, with a desired confidence. Furthermore, two additional algorithms NaiveChanSel and MedianChanEl, that output with certain confidence a DMC with capacity close to the maximal, are introduced. Each of those algorithms is beneficial in a different regime and can be used as a subroutine in BestChanID. The sample complexity of all algorithms is analyzed as a function of the desired confidence parameter, the number of channels, and the channels' input and output alphabet sizes. The cost of best channel identification is shown to scale quadratically with the alphabet size, and a fundamental lower bound for the required number of channel senses to identify the best channel with a certain confidence is derived.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10204"
    },
    {
        "doc_id": 2,
        "title": "Functional Conditional Gaussian Graphical Models",
        "authors": [
            "Rita Fici",
            "Luigi Augugliaro",
            "Ernst-Jan Camiel Wit"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Functional data has become a commonly encountered data type. In this paper, we contribute to the literature on functional graphical modelling by extending the notion of conditional Gaussian Graphical models and proposing a double-penalized estimator by which to recover the edge-set of the corresponding graph. Penalty parameters play a crucial role in determining the precision matrices for the response variables and the regression matrices. The performance and model selection process in the proposed framework are investigated using information criteria. Moreover, we propose a novel version of the Kullback-Leibler cross-validation designed for conditional joint Gaussian Graphical Models. The evaluation of model performance is done in terms of Kullback-Leibler divergence and graph recovery power.",
        "comments": "19 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10196"
    },
    {
        "doc_id": 3,
        "title": "tinyVAST: R package with an expressive interface to specify lagged and simultaneous effects in multivariate spatio-temporal models",
        "authors": [
            "James T. Thorson",
            "Sean C. Anderson",
            "Pamela Goddard",
            "Christopher N. Rooper"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "Multivariate spatio-temporal models are widely applicable, but specifying their structure is complicated and may inhibit wider use. We introduce the R package tinyVAST from two viewpoints: the software user and the statistician. From the user viewpoint, tinyVAST adapts a widely used formula interface to specify generalized additive models, and combines this with arguments to specify spatial and spatio-temporal interactions among variables. These interactions are specified using arrow notation (from structural equation models), or an extended arrow-and-lag notation that allows simultaneous, lagged, and recursive dependencies among variables over time. The user also specifies a spatial domain for areal (gridded), continuous (point-count), or stream-network data. From the statistician viewpoint, tinyVAST constructs sparse precision matrices representing multivariate spatio-temporal variation, and parameters are estimated by specifying a generalized linear mixed model (GLMM). This expressive interface encompasses vector autoregressive, empirical orthogonal functions, spatial factor analysis, and ARIMA models. To demonstrate, we fit to data from two survey platforms sampling corals, sponges, rockfishes, and flatfishes in the Gulf of Alaska and Aleutian Islands. We then compare eight alternative model structures using different assumptions about habitat drivers and survey detectability. Model selection suggests that towed-camera and bottom trawl gears have spatial variation in detectability but sample the same underlying density of flatfishes and rockfishes, and that rockfishes are positively associated with sponges while flatfishes are negatively associated with corals. We conclude that tinyVAST can be used to test complicated dependencies representing alternative structural assumptions for research and real-world policy evaluation.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10193"
    },
    {
        "doc_id": 4,
        "title": "Generalized Decomposition Priors on R2",
        "authors": [
            "Javier Enrique Aguilar",
            "Paul-Christian B\u00fcrkner"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The adoption of continuous shrinkage priors in high-dimensional linear models has gained momentum, driven by their theoretical and practical advantages. One of these shrinkage priors is the R2D2 prior, which comes with intuitive hyperparameters and well understood theoretical properties. The core idea is to specify a prior on the percentage of explained variance $R^2$ and to conduct a Dirichlet decomposition to distribute the explained variance among all the regression terms of the model. Due to the properties of the Dirichlet distribution, the competition among variance components tends to gravitate towards negative dependence structures, fully determined by the individual components' means. Yet, in reality, specific coefficients or groups may compete differently for the total variability than the Dirichlet would allow for. In this work we address this limitation by proposing a generalization of the R2D2 prior, which we term the Generalized Decomposition R2 (GDR2) prior.\n  Our new prior provides great flexibility in expressing dependency structures as well as enhanced shrinkage properties. Specifically, we explore the capabilities of variance decomposition via logistic normal distributions. Through extensive simulations and real-world case studies, we demonstrate that GDR2 priors yield strongly improved out-of-sample predictive performance and parameter recovery compared to R2D2 priors with similar hyper-parameter choices.",
        "comments": "31 pages, 12 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10180"
    },
    {
        "doc_id": 5,
        "title": "Building a Life Cycle Assessment Model using Bayesian Networks",
        "authors": [
            "Cedric Fraces Gasmi",
            "Wennan Long"
        ],
        "subjects": [
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "This paper introduces the Oilfield Pollutant Graphical Model (OPGM), an innovative approach designed to improve the benchmarking and uncertainty analysis of greenhouse gas (GHG) emissions in oilfields. Building on the robust foundation provided by the Oil Production Greenhouse Gas Emission Estimator (OPGEE) framework, OPGM retains all essential functionalities of the latest OPGEE iteration (v3.0c), while offering substantial improvements in user experience and computational performance. Key advances of OPGM include a streamlined user interface for more intuitive interaction, which facilitates transparent visualization of intermediate results and thus contributes to a more interpretable and accessible analysis process. A notable feature of the OPGM is its ability to naturally perform sensitivity analyzes. This is achieved by allowing users to seamlessly transition nodes from deterministic to probabilistic, thereby integrating uncertainty directly into the core structure of the model. OPGM achieves remarkable computational efficiency, executing analyzes at a speed 1e+5 times faster than the Excel-based OPGEE, thus facilitating rapid large-scale emissions assessments. This leap in processing speed represents a significant step forward in emissions modeling, enabling more agile and accurate environmental impact assessments. The integration of OPGM into existing Life Cycle Assessment (LCA) practices holds the promise of significantly improving the precision and speed of environmental impact analyses, offering a vital tool for policymakers and industry stakeholders in their efforts to better understand and manage the environmental impacts of oilfield operations.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10170"
    },
    {
        "doc_id": 6,
        "title": "DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks",
        "authors": [
            "Nikolaos Koursioumpas",
            "Lina Magoula",
            "Ioannis Stavrakakis",
            "Nancy Alonistioti",
            "M. A. Gutierrez-Estevez",
            "Ramin Khalili"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Artificial Intelligence",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Machine Learning"
        ],
        "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use cases and applications that depend on a certain level of Quality of Service (QoS) to operate smoothly. Predicting the QoS in a timely manner is of high importance, especially for safety-critical applications as in the case of vehicular communications. Although until recent years the QoS prediction has been carried out by centralized Artificial Intelligence (AI) solutions, a number of privacy, computational, and operational concerns have emerged. Alternative solutions have been surfaced (e.g. Split Learning, Federated Learning), distributing AI tasks of reduced complexity across nodes, while preserving the privacy of the data. However, new challenges rise when it comes to scalable distributed learning approaches, taking into account the heterogeneous nature of future wireless networks. The current work proposes DISTINQT, a privacy-aware distributed learning framework for QoS prediction. Our framework supports multiple heterogeneous nodes, in terms of data types and model architectures, by sharing computations across them. This, enables the incorporation of diverse knowledge into a sole learning process that will enhance the robustness and generalization capabilities of the final QoS prediction model. DISTINQT also contributes to data privacy preservation by encoding any raw input data into a non-linear latent representation before any transmission. Evaluation results showcase that our framework achieves a statistically identical performance compared to its centralized version and an average performance improvement of up to 65% against six state-of-the-art centralized baseline solutions in the Tele-Operated Driving use case.",
        "comments": "11 Pages Double Column, 9 Figures, Submitted for possible publication in the IEEE Transactions on Vehicular Technology (IEEE TVT)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10158"
    },
    {
        "doc_id": 7,
        "title": "Lower Ricci Curvature for Efficient Community Detection",
        "authors": [
            "Yun Jin Park",
            "Didong Li"
        ],
        "subjects": [
            "Methodology",
            "Social and Information Networks",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, making it well-suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through comprehensive simulations and applications on real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10124"
    },
    {
        "doc_id": 8,
        "title": "Time-Dependent Urn Models reproduce the full spectrum of novelties discovery",
        "authors": [
            "Alessandro Bellina",
            "Giordano De Marzo",
            "Vittorio Loreto"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Probability"
        ],
        "abstract": "Systems driven by innovation, a pivotal force in human society, present various intriguing statistical regularities, from the Heaps' law to logarithmic scaling or somewhat different patterns for the innovation rates. The Urn Model with Triggering (UMT) has been instrumental in modelling these innovation dynamics. Yet, a generalisation is needed to capture the richer empirical phenomenology. Here, we introduce a Time-dependent Urn Model with Triggering (TUMT), a generalisation of the UMT that crucially integrates time-dependent parameters for reinforcement and triggering to offer a broader framework for modelling innovation in non-stationary systems. Through analytical computation and numerical simulations, we show that the TUMT reconciles various behaviours observed in a broad spectrum of systems, from patenting activity to the analysis of gene mutations. We highlight how the TUMT features a \"critical\" region where both Heaps' and Zipf's laws coexist, for which we compute the exponents.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10114"
    },
    {
        "doc_id": 9,
        "title": "The Interaction between Solar Convection and Rotation",
        "authors": [
            "Haibin Chen",
            "Rong Wu"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Fluid Dynamics"
        ],
        "abstract": "The rotational energy of a fluid parcel changes during isotropic expansion or compression. In solar convection, rotation absorbs energy from convection and inhibits it, causing the motion of fluid parcels larger than a critical size to become vibration. Turbulence and inertial oscillations can cause the deformation of fluid parcels to deviate from isotropic, altering the equilibrium position of the vibration and forming motion larger than the critical size, respectively, the large granules within the granules and probably the mesogranulation. The change in rotational energy of granules during convection causes their rotation speed to differ from the local speed, forming a statistically significant solar radial differential rotation. The meridional circulation driven by radial differential rotation transports angular momentum towards the equator, forming the latitudinal differential rotation. A model constructed by combining mixing length theory explains why granule size and temperature distribution are independent of latitude, and the structure produced by this mechanism is similar to the characteristics of supergranules.",
        "comments": "13pages,2figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10105"
    },
    {
        "doc_id": 10,
        "title": "Counterfactual Reasoning with Probabilistic Graphical Models for Analyzing Socioecological Systems",
        "authors": [
            "Rafael Caba\u00f1as",
            "Ana D. Maldonado",
            "Mar\u00eda Morales",
            "Pedro A. Aguilera",
            "Antonio Salmer\u00f3n"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Probability",
            "Applications"
        ],
        "abstract": "Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios. This is particularly useful in domains where experimental data are usually not available. In the context of environmental and ecological sciences, causality enables us, for example, to predict how an ecosystem would respond to hypothetical interventions. A structural causal model is a class of probabilistic graphical models for causality, which, due to its intuitive nature, can be easily understood by experts in multiple fields. However, certain queries, called unidentifiable, cannot be calculated in an exact and precise manner. This paper proposes applying a novel and recent technique for bounding unidentifiable queries within the domain of socioecological systems. Our findings indicate that traditional statistical analysis, including probabilistic graphical models, can identify the influence between variables. However, such methods do not offer insights into the nature of the relationship, specifically whether it involves necessity or sufficiency. This is where counterfactual reasoning becomes valuable.",
        "comments": "34 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10101"
    },
    {
        "doc_id": 11,
        "title": "Statistics of ranks, determinants and characteristic polynomials of rational matrices",
        "authors": [
            "Muhammad Afifurrahman",
            "Alina Ostafe",
            "Igor E. Shparlinski"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We consider the set of $n\\times n$ matrices with rational entries having numerator and denominator of size at most $H$ and obtain upper and lower bounds on the number of such matrices of a given rank and then apply them to count such matrices with a given determinant, or a given characteristic polynomial.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10086"
    },
    {
        "doc_id": 12,
        "title": "A locally statistical active contour model for SAR image segmentation can be solved by denoising algorithms",
        "authors": [
            "Guangming Liu",
            "Quanying Sun",
            "Jing Liang",
            "Qi Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In this paper, we propose a novel locally statistical variational active contour model based on I-divergence-TV denoising model, which hybrides geodesic active contour (GAC) model with active contours without edges (ACWE) model, and can be used to segment images corrupted by multiplicative gamma noise. By adding a diffusion term into the level set evolution (LSE) equation of the proposed model, we construct a reaction-diffusion (RD) equation, which can gradually regularize the level set function (LSF) to be piecewise constant in each segment domain and gain the stable solution. We further transform the proposed model into classic ROF model by adding a proximity term. Inspired by a fast denoising algorithm proposed by Jia-Zhao recently, we propose two fast fixed point algorithms to solve SAR image segmentation question. Experimental results for real SAR images show that the proposed image segmentation model can efficiently stop the contours at weak or blurred edges, and can automatically detect the exterior and interior boundaries of images with multiplicative gamma noise. The proposed FPRD1/FPRD2 models are about 1/2 (or less than) of the time required for the SBRD model based on the Split Bregman technique.",
        "comments": "18 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2312.11849, arXiv:2312.08376, arXiv:2312.09365",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10083"
    },
    {
        "doc_id": 13,
        "title": "Preoperative Prediction of Catheter Ablation Outcome in Persistent Atrial Fibrillation Patients through Spectral Organization Analysis of the Surface Fibrillatory Waves",
        "authors": [
            "P. Escribano",
            "J. Rodenas",
            "M. Garcia",
            "M. A. Arias",
            "V. M. Hidalgo",
            "S. Calero",
            "J. J. Rieta",
            "R. Alcaraz"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Catheter ablation (CA) is a commonly used treatment for persistent atrial fibrillation (AF). Since its medium/long-term success rate remains limited, preoperative prediction of its outcome is gaining clinical interest to optimally select candidates for the procedure. Among predictors based on the surface electrocardiogram, the dominant frequency (DF) and harmonic exponential decay (g) of the fibrillatory waves ( f -waves) have reported promising but clinically insufficient results. Hence, the main goal of this work was to conduct a broader analysis of the f -wave harmonic spectral structure to improve CA outcome prediction through several entropy-based measures computed on different frequency bands. On a database of 151 persistent AF patients under radio-frequency CA and a follow-up of 9 months, the newly introduced parameters discriminated between patients who relapsed to AF and those who maintained SR at about 70%, which was statistically superior to the DF and approximately similar to g. They also provided complementary information to g through different combinations in multivariate models based on lineal discriminant analysis and report classification performance improvement of about 5%. These results suggest that the presence of larger harmonics and a proportionally smaller DF peak is associated with a decreased probability of AF recurrence after CA.",
        "comments": "Journal ref:        J. Pers. Med. 2022, 12, 1721",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10081"
    },
    {
        "doc_id": 14,
        "title": "Level spacing distribution of localized phases induced by quasiperiodic potentials",
        "authors": [
            "Chao Yang",
            "Yucheng Wang"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Mathematical Physics",
            "Quantum Physics"
        ],
        "abstract": "Level statistics is a crucial tool in the exploration of localization physics. The level spacing distribution of localized states in disordered systems follows Poisson statistics, and many studies naturally apply it to the localization induced by quasiperiodic potentials. Taking the Aubry-Andr\u00e9 model as an example, we investigate the level spacing distribution of the localized phase caused by quasiperiodic potential. We analytically and numerically calculate its level spacing distribution and find that it does not adhere to Poisson statistics. Moreover, based on this level statistics, we derive the ratio of adjacent gaps and find that for a single sample, it is a $\u03b4-$function, which is in excellent agreement with numerical studies. Additionally, unlike disordered systems, in quasiperiodic systems, there are variations in the level spacing distribution across different regions of the spectrum, and increasing the size and increasing the sample are non-equivalent. Our findings carry significant implications for the reevaluation of level statistics in quasiperiodic systems and a profound understanding of the distinct effects of quasiperiodic potentials and disorder-induced localization.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10067"
    },
    {
        "doc_id": 15,
        "title": "Poisson approximation for stochastic processes summed over amenable groups",
        "authors": [
            "Haoyu Ye",
            "Peter Orbanz",
            "Morgane Austern"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "We generalize the Poisson limit theorem to binary functions of random objects whose law is invariant under the action of an amenable group. Examples include stationary random fields, exchangeable sequences, and exchangeable graphs. A celebrated result of E. Lindenstrauss shows that normalized sums over certain increasing subsets of such groups approximate expectations. Our results clarify that the corresponding unnormalized sums of binary statistics are asymptotically Poisson, provided suitable mixing conditions hold. They extend further to randomly subsampled sums and also show that strict invariance of the distribution is not needed if the requisite mixing condition defined by the group holds. We illustrate the results with applications to random fields, Cayley graphs, and Poisson processes on groups.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10060"
    },
    {
        "doc_id": 16,
        "title": "A method for characterizing disease emergence curves from paired pathogen detection and serology data",
        "authors": [
            "Joshua Hewitt",
            "Grete Wilson-Henjum",
            "Derek T. Collins",
            "Jourdan M. Ringenberg",
            "Christopher A. Quintanal",
            "Robert Pleszewski",
            "Jeffrey C. Chandler",
            "Thomas J. DeLiberto",
            "Kim M. Pepin"
        ],
        "subjects": [
            "Methodology",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "Wildlife disease surveillance programs and research studies track infection and identify risk factors for wild populations, humans, and agriculture. Often, several types of samples are collected from individuals to provide more complete information about an animal's infection history. Methods that jointly analyze multiple data streams to study disease emergence and drivers of infection via epidemiological process models remain underdeveloped. Joint-analysis methods can more thoroughly analyze all available data, more precisely quantifying epidemic processes, outbreak status, and risks. We contribute a paired data modeling approach that analyzes multiple samples from individuals. We use \"characterization maps\" to link paired data to epidemiological processes through a hierarchical statistical observation model. Our approach can provide both Bayesian and frequentist estimates of epidemiological parameters and state. We motivate our approach through the need to use paired pathogen and antibody detection tests to estimate parameters and infection trajectories for the widely applicable susceptible, infectious, recovered (SIR) model. We contribute general formulas to link characterization maps to arbitrary process models and datasets and an extended SIR model that better accommodates paired data. We find via simulation that paired data can more efficiently estimate SIR parameters than unpaired data, requiring samples from 5-10 times fewer individuals. We then study SARS-CoV-2 in wild White-tailed deer (Odocoileus virginianus) from three counties in the United States. Estimates for average infectious times corroborate captive animal studies. Our methods use general statistical theory to let applications extend beyond the SIR model we consider, and to more complicated examples of paired data.",
        "comments": "20 pages, 5 figures, 1 table",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10057"
    },
    {
        "doc_id": 17,
        "title": "Gender Bias in Machine Translation and The Era of Large Language Models",
        "authors": [
            "Eva Vanmassenhove"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ],
        "abstract": "This chapter examines the role of Machine Translation in perpetuating gender bias, highlighting the challenges posed by cross-linguistic settings and statistical dependencies. A comprehensive overview of relevant existing work related to gender bias in both conventional Neural Machine Translation approaches and Generative Pretrained Transformer models employed as Machine Translation systems is provided. Through an experiment using ChatGPT (based on GPT-3.5) in an English-Italian translation context, we further assess ChatGPT's current capacity to address gender bias. The findings emphasize the ongoing need for advancements in mitigating bias in Machine Translation systems and underscore the importance of fostering fairness and inclusivity in language technologies.",
        "comments": "24 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10016"
    },
    {
        "doc_id": 18,
        "title": "A global kernel estimator for partially linear varying coefficient additive hazards models",
        "authors": [
            "Hoi Min Ng",
            "Kin Yau Wong"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In biomedical studies, we are often interested in the association between different types of covariates and the times to disease events. Because the relationship between the covariates and event times is often complex, standard survival models that assume a linear covariate effect are inadequate. A flexible class of models for capturing complex interaction effects among types of covariates is the varying coefficient models, where the effects of a type of covariates can be modified by another type of covariates. In this paper, we study kernel-based estimation methods for varying coefficient additive hazards models. Unlike many existing kernel-based methods that use a local neighborhood of subjects for the estimation of the varying coefficient function, we propose a novel global approach that is generally more efficient. We establish theoretical properties of the proposed estimators and demonstrate their superior performance compared with existing local methods through large-scale simulation studies. To illustrate the proposed method, we provide an application to a motivating cancer genomic study.",
        "comments": "27 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10010"
    },
    {
        "doc_id": 19,
        "title": "Regime change detection in irregularly sampled time series",
        "authors": [
            "Norbert Marwan",
            "Deniz Eroglu",
            "Ibrahim Ozken",
            "Thomas Stemler",
            "Karl-Heinz Wyrwoll",
            "J\u00fcrgen Kurths"
        ],
        "subjects": [
            "Data Analysis, Statistics and Probability",
            "Chaotic Dynamics",
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Irregular sampling is a common problem in palaeoclimate studies. We propose a method that provides regularly sampled time series and at the same time a difference filtering of the data. The differences between successive time instances are derived by a transformation costs procedure. A subsequent recurrence analysis is used to investigate regime transitions. This approach is applied on speleothem based palaeoclimate proxy data from the Indonesian-Australian monsoon region. We can clearly identify Heinrich events in the palaeoclimate as characteristic changes in the dynamics.",
        "comments": "12 pages, 3 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10006"
    },
    {
        "doc_id": 20,
        "title": "Bayesian modeling of spatial ordinal data from health surveys",
        "authors": [
            "Miguel \u00c1ngel Beltr\u00e1n S\u00e1nchez",
            "Miguel \u00c1ngel Mart\u00ednez Beneito",
            "Ana Corber\u00e1n Vallet"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Health surveys allow exploring health indicators that are of great value from a public health point of view and that cannot normally be studied from regular health registries. These indicators are usually coded as ordinal variables and may depend on covariates associated with individuals. In this paper, we propose a Bayesian individual-level model for small-area estimation of survey-based health indicators. A categorical likelihood is used at the first level of the model hierarchy to describe the ordinal data, and spatial dependence among small areas is taken into account by using a conditional autoregressive (CAR) distribution. Post-stratification of the results of the proposed individual-level model allows extrapolating the results to any administrative areal division, even for small areas. We apply this methodology to the analysis of the Health Survey of the Region of Valencia (Spain) of 2016 to describe the geographical distribution of a self-perceived health indicator of interest in this region.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09994"
    },
    {
        "doc_id": 21,
        "title": "The diversity of spectral shapes of hydrogen Lyman lines and Mg II lines in a quiescent prominence",
        "authors": [
            "P. Schwartz",
            "S. Gunar",
            "J. Koza",
            "P. Heinzel"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "Broad sets of spectroscopic observations comprising multiple lines represent an excellent opportunity for diagnostics of the properties of the prominence plasma and the dynamics of their fine structures. However, they also bring significant challenges when they are compared with synthetic spectra provided by radiative transfer modeling. In this work, we provide a statistical spectroscopic analysis of a unique dataset of coordinated prominence observations in the Lyman lines (Ly_alpha to Ly_delta) and the Mg II k and h lines. The observed data were obtained by the Solar Ultraviolet Measurements of Emitted Radiation (SUMER) spectrograph on board of the Solar and Heliospheric Observatory (SoHO) satellite and the Interface Region Imaging Spectrograph (IRIS) on 22 October 2013. We focus on the following profile characteristics: the shape of the observed line profiles based on the number of distinct peaks, the integrated line intensity, the center-to-peak ratio describing the depth of the reversal of two-peaked profiles, and the asymmetry of these peaks. We show that the presence of noise has a negligible effect on the integrated intensity of all observed lines, but it significantly affects the classification of spectral profiles using the number of distinct peaks, the reversal depth, and also the peak asymmetry. We also demonstrate that by taking the influence of noise into account, we can assess which profile characteristics in which spectral lines are suitable for diagnostics of different properties of the observed prominence.",
        "comments": "20 pages in main part of the paper, 6 additional pages in Appendices A and B, 9 figures and 4 tables in main part of the paper plus 3 figures and 3 tables in Appendices A and B",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09992"
    },
    {
        "doc_id": 22,
        "title": "Power Grid Parameter Estimation Without Phase Measurements: Theory and Empirical Validation",
        "authors": [
            "Jean-S\u00e9bastien Brouillon",
            "Keith Moffat",
            "Florian D\u00f6rfler",
            "Giancarlo Ferrari-trecate"
        ],
        "subjects": [
            "Systems and Control",
            "Applications"
        ],
        "abstract": "Reliable integration and operation of renewable distributed energy resources requires accurate distribution grid models. However, obtaining precise models is often prohibitively expensive, given their large scale and the ongoing nature of grid operations. To address this challenge, considerable efforts have been devoted to harnessing abundant consumption data for automatic model inference. The primary result of the paper is that, while the impedance of a line or a network can be estimated without synchronized phase angle measurements in a consistent way, the admittance cannot. Furthermore, a detailed statistical analysis is presented, quantifying the expected estimation errors of four prevalent admittance estimation methods. Such errors constitute fundamental model inference limitations that cannot be resolved with more data. These findings are empirically validated using synthetic data and real measurements from the town of Walenstadt, Switzerland, confirming the theory. The results contribute to our understanding of grid estimation limitations and uncertainties, offering guidance for both practitioners and researchers in the pursuit of more reliable and cost-effective solutions.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09989"
    },
    {
        "doc_id": 23,
        "title": "False Discovery Rate Control for Gaussian Graphical Models via Neighborhood Screening",
        "authors": [
            "Taulant Koka",
            "Jasin Machkour",
            "Michael Muma"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Gaussian graphical models emerge in a wide range of fields. They model the statistical relationships between variables as a graph, where an edge between two variables indicates conditional dependence. Unfortunately, well-established estimators, such as the graphical lasso or neighborhood selection, are known to be susceptible to a high prevalence of false edge detections. False detections may encourage inaccurate or even incorrect scientific interpretations, with major implications in applications, such as biomedicine or healthcare. In this paper, we introduce a nodewise variable selection approach to graph learning and provably control the false discovery rate of the selected edge set at a self-estimated level. A novel fusion method of the individual neighborhoods outputs an undirected graph estimate. The proposed method is parameter-free and does not require tuning by the user. Benchmarks against competing false discovery rate controlling methods in numerical experiments considering different graph topologies show a significant gain in performance.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09979"
    },
    {
        "doc_id": 24,
        "title": "Biases in Expected Goals Models Confound Finishing Ability",
        "authors": [
            "Jesse Davis",
            "Pieter Robberechts"
        ],
        "subjects": [
            "Machine Learning",
            "Applications"
        ],
        "abstract": "Expected Goals (xG) has emerged as a popular tool for evaluating finishing skill in soccer analytics. It involves comparing a player's cumulative xG with their actual goal output, where consistent overperformance indicates strong finishing ability. However, the assessment of finishing skill in soccer using xG remains contentious due to players' difficulty in consistently outperforming their cumulative xG. In this paper, we aim to address the limitations and nuances surrounding the evaluation of finishing skill using xG statistics. Specifically, we explore three hypotheses: (1) the deviation between actual and expected goals is an inadequate metric due to the high variance of shot outcomes and limited sample sizes, (2) the inclusion of all shots in cumulative xG calculation may be inappropriate, and (3) xG models contain biases arising from interdependencies in the data that affect skill measurement. We found that sustained overperformance of cumulative xG requires both high shot volumes and exceptional finishing, including all shot types can obscure the finishing ability of proficient strikers, and that there is a persistent bias that makes the actual and expected goals closer for excellent finishers than it really is. Overall, our analysis indicates that we need more nuanced quantitative approaches for investigating a player's finishing ability, which we achieved using a technique from AI fairness to learn an xG model that is calibrated for multiple subgroups of players. As a concrete use case, we show that (1) the standard biased xG model underestimates Messi's GAX by 17% and (2) Messi's GAX is 27% higher than the typical elite high-shot-volume attacker, indicating that Messi is even a more exceptional finisher than people commonly believed.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09940"
    },
    {
        "doc_id": 25,
        "title": "A Quantile Nelson-Siegel model",
        "authors": [
            "Matteo Iacopini",
            "Aubrey Poon",
            "Luca Rossini",
            "Dan Zhu"
        ],
        "subjects": [
            "Applications",
            "Econometrics"
        ],
        "abstract": "A widespread approach to modelling the interaction between macroeconomic variables and the yield curve relies on three latent factors usually interpreted as the level, slope, and curvature (Diebold et al., 2006). This approach is inherently focused on the conditional mean of the yields and postulates a dynamic linear model where the latent factors smoothly change over time. However, periods of deep crisis, such as the Great Recession and the recent pandemic, have highlighted the importance of statistical models that account for asymmetric shocks and are able to forecast the tails of a variable's distribution. A new version of the dynamic three-factor model is proposed to address this issue based on quantile regressions. The novel approach leverages the potential of quantile regression to model the entire (conditional) distribution of the yields instead of restricting to its mean. An application to US data from the 1970s shows the significant heterogeneity of the interactions between financial and macroeconomic variables across different quantiles. Moreover, an out-of-sample forecasting exercise showcases the proposed method's advantages in predicting the yield distribution tails compared to the standard conditional mean model. Finally, by inspecting the posterior distribution of the three factors during the recent major crises, new evidence is found that supports the greater and longer-lasting negative impact of the great recession on the yields compared to the COVID-19 pandemic.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09874"
    },
    {
        "doc_id": 26,
        "title": "Wealth dynamics in a multi-aggregate closed monetary system",
        "authors": [
            "Andrea Monaco",
            "Matteo Ghio",
            "Adamaria Perrotta"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We examine the statistical properties of a closed monetary economy with multi-aggregates interactions. Building upon Yakovenko's single-agent monetary model (Dragulescu and Yakovenko, 2000), we investigate the joint equilibrium distribution of aggregate size and wealth. By comparing theoretical and simulated data, we validate our findings and investigate the influence of both micro dynamics and macro characteristics of the system on the distribution. Additionally, we analyze the system's convergence towards equilibrium under various conditions. Our laboratory model may offer valuable insights into macroeconomic phenomena allowing to reproduce typical wealth distribution features observed in real economy.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09871"
    },
    {
        "doc_id": 27,
        "title": "Efficient Computation of Large-Scale Statistical Solutions to Incompressible Fluid Flows",
        "authors": [
            "Tobias Rohner",
            "Siddhartha Mishra"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "This work presents the development, performance analysis and subsequent optimization of a GPU-based spectral hyperviscosity solver for turbulent flows described by the three dimensional incompressible Navier-Stokes equations. The method solves for the fluid velocity fields directly in Fourier space, eliminating the need to solve a large-scale linear system of equations in order to find the pressure field. Special focus is put on the communication intensive transpose operation required by the Fast Fourier transform when using distributed memory parallelism. After multiple iterations of benchmarking and improving the code, the simulation achieves close to optimal performance on the Piz Daint supercomputer cluster, even outperforming the Cray MPI implementation on Piz Daint in its communication routines. This optimal performance enables the computation of large-scale statistical solutions of incompressible fluid flows in three space dimensions.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09843"
    },
    {
        "doc_id": 28,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 29,
        "title": "Jackknife empirical likelihood ratio test for testing the equality of semivariance",
        "authors": [
            "Saparya",
            "S",
            "Sudheesh",
            "K K"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Semivariance is a measure of the dispersion of all observations that fall above the mean or target value of a random variable and it plays an important role in life-length, actuarial and income studies. In this paper, we develop a new non-parametric test for equality of upper semi-variance. We use the U-statistic theory to derive the test statistic and then study the asymptotic properties of the test statistic. We also develop a jackknife empirical likelihood (JEL) ratio test for equality of upper Semivariance. Extensive Monte Carlo simulation studies are carried out to validate the performance of the proposed JEL-based test. We illustrate the test procedure using real data.",
        "comments": "MSC Class:          62G10",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09816"
    },
    {
        "doc_id": 30,
        "title": "Querying Easily Flip-flopped Samples for Deep Active Learning",
        "authors": [
            "Seong Jin Cho",
            "Gwangsu Kim",
            "Junghyun Lee",
            "Jinwoo Shin",
            "Chang D. Yoo"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Active learning is a machine learning paradigm that aims to improve the performance of a model by strategically selecting and querying unlabeled data. One effective selection strategy is to base it on the model's predictive uncertainty, which can be interpreted as a measure of how informative a sample is. The sample's distance to the decision boundary is a natural measure of predictive uncertainty, but it is often intractable to compute, especially for complex decision boundaries formed in multiclass classification tasks. To address this issue, this paper proposes the {\\it least disagree metric} (LDM), defined as the smallest probability of disagreement of the predicted label, and an estimator for LDM proven to be asymptotically consistent under mild assumptions. The estimator is computationally efficient and can be easily implemented for deep learning models using parameter perturbation. The LDM-based active learning is performed by querying unlabeled data with the smallest LDM. Experimental results show that our LDM-based active learning algorithm obtains state-of-the-art overall performance on all considered datasets and deep architectures.",
        "comments": "34 pages, 17 figures, 5 tables. Accepted to the 12th International Conference on Learning Representations (ICLR 2024)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09787"
    },
    {
        "doc_id": 31,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 32,
        "title": "Impact of Limited Statistics on the Measured Hyper-Order Cumulants of Net-Proton Distributions in Heavy-Ion Collisions",
        "authors": [
            "Lizhu Chen",
            "Ye-Yin Zhao",
            "Yunshan Cheng",
            "Gang Wang",
            "Zhiming Li",
            "Yuanfang Wu"
        ],
        "subjects": [
            "Nuclear Theory",
            "Nuclear Experiment"
        ],
        "abstract": "Hyper-order cumulants $C_5/C_1$ and $C_6/C_2$ of net-baryon distributions are anticipated to offer crucial insights into the phase transition from quark-gluon plasma to hadronic matter in heavy-ion collisions. However, the accuracy of $C_5$ and $C_6$ is highly contingent on the fine shape of the distribution's tail, the detectable range of which could be essentially truncated by low statistics. In this paper, we use the fast Skellam-based simulations, as well as the Ultrarelativistic Quantum Molecular Dynamics model, to assess the impact of limited statistics on the measurements of $C_5/C_1$ and $C_6/C_2$ of net-proton distributions at lower RHIC energies. Both ratios decrease from the unity baseline as we reduce statistics, and could even turn negative without a pertinent physics mechanism. By incorporating statistics akin to experimental data, we can replicate the net-proton $C_5/C_1$ and $C_6/C_2$ values comparable to the corresponding measurements for Au+Au collisions at $\\sqrt{s_{NN}} =$ 7.7, 11.5 and 14.5 GeV. Our findings underscore a caveat to the interpretation of the observed beam energy dependence of hyper-order cumulants.",
        "comments": "6 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09745"
    },
    {
        "doc_id": 33,
        "title": "Kernel-based multi-marker tests of association based on the accelerated failure time model",
        "authors": [
            "Chenxi Li",
            "Di Wu",
            "Qing Lu"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Kernel-based multi-marker tests for survival outcomes use primarily the Cox model to adjust for covariates. The proportional hazards assumption made by the Cox model could be unrealistic, especially in the long-term follow-up. We develop a suite of novel multi-marker survival tests for genetic association based on the accelerated failure time model, which is a popular alternative to the Cox model due to its direct physical interpretation. The tests are based on the asymptotic distributions of their test statistics and are thus computationally efficient. The association tests can account for the heterogeneity of genetic effects across sub-populations/individuals to increase the power. All the new tests can deal with competing risks and left truncation. Moreover, we develop small-sample corrections to the tests to improve their accuracy under small samples. Extensive numerical experiments show that the new tests perform very well in various scenarios. An application to a genetic dataset of Alzheimer's disease illustrates the tests' practical utility.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09719"
    },
    {
        "doc_id": 34,
        "title": "Fast Variational Inference of Latent Space Models for Dynamic Networks Using Bayesian P-Splines",
        "authors": [
            "Joshua Daniel Loyal"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "Latent space models (LSMs) are often used to analyze dynamic (time-varying) networks that evolve in continuous time. Existing approaches to Bayesian inference for these models rely on Markov chain Monte Carlo algorithms, which cannot handle modern large-scale networks. To overcome this limitation, we introduce a new prior for continuous-time LSMs based on Bayesian P-splines that allows the posterior to adapt to the dimension of the latent space and the temporal variation in each latent position. We propose a stochastic variational inference algorithm to estimate the model parameters. We use stochastic optimization to subsample both dyads and observed time points to design a fast algorithm that is linear in the number of edges in the dynamic network. Furthermore, we establish non-asymptotic error bounds for point estimates derived from the variational posterior. To our knowledge, this is the first such result for Bayesian estimators of continuous-time LSMs. Lastly, we use the method to analyze a large data set of international conflicts consisting of 4,456,095 relations from 2018 to 2022.",
        "comments": "75 pages, 8 figures, and 2 tables",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09715"
    },
    {
        "doc_id": 35,
        "title": "Rejection Sampling with Vertical Weighted Strips",
        "authors": [
            "Andrew M. Raim",
            "James A. Livsey",
            "Kyle M. Irimata"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "A number of distributions that arise in statistical applications can be expressed in the form of a weighted density: the product of a base density and a nonnegative weight function. Generating variates from such a distribution may be nontrivial and can involve an intractable normalizing constant. Rejection sampling may be used to generate exact draws, but requires formulation of a suitable proposal distribution. To be practically useful, the proposal must both be convenient to sample from and not reject candidate draws too frequently. A well-known approach to design a proposal involves decomposing the target density into a finite mixture, whose components may correspond to a partition of the support. This work considers such a construction that focuses on majorization of the weight function. This approach may be applicable when assumptions for adaptive rejection sampling and related algorithms are not met. An upper bound for the rejection probability based on this construction can be expressed to evaluate the efficiency of the proposal before sampling. A method to partition the support is considered where regions are bifurcated based on their contribution to the bound. Examples based on the von Mises Fisher distribution and Gaussian Process regression are provided to illustrate the method.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09696"
    },
    {
        "doc_id": 36,
        "title": "Harnessing Density Ratios for Online Reinforcement Learning",
        "authors": [
            "Philip Amortila",
            "Dylan J. Foster",
            "Nan Jiang",
            "Ayush Sekhari",
            "Tengyang Xie"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "The theories of offline and online reinforcement learning, despite having evolved in parallel, have begun to show signs of the possibility for a unification, with algorithms and analysis techniques for one setting often having natural counterparts in the other. However, the notion of density ratio modeling, an emerging paradigm in offline RL, has been largely absent from online RL, perhaps for good reason: the very existence and boundedness of density ratios relies on access to an exploratory dataset with good coverage, but the core challenge in online RL is to collect such a dataset without having one to start. In this work we show -- perhaps surprisingly -- that density ratio-based algorithms have online counterparts. Assuming only the existence of an exploratory distribution with good coverage, a structural condition known as coverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses density ratio realizability and value function realizability to perform sample-efficient online exploration. GLOW addresses unbounded density ratios via careful use of truncation, and combines this with optimism to guide exploration. GLOW is computationally inefficient; we complement it with a more efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022) wherein online RL is augmented with additional offline data. HyGLOW is derived as a special case of a more general meta-algorithm that provides a provable black-box reduction from hybrid RL to offline RL, which may be of independent interest.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09681"
    },
    {
        "doc_id": 37,
        "title": "Easy JavaScript Simulation (EJSS) Data Analytics for Singapore",
        "authors": [
            "Loo Kang Wee",
            "Darren Tan",
            "F\u00e9lix Jes\u00fas Garcia Clemente",
            "Francisco Eequembre"
        ],
        "subjects": [
            "Physics Education",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "We have integrated Easy JavaScript Simulation (EJSS) Data Analytics into the national Learning Management System for Singapore schools, known as the Singapore Student Learning Space (SLS). EJSS Data Analytics enhances the teaching and learning experience for educators and students by enabling educators to monitor and evaluate students interactions with interactive computer simulations. The data analytics and visualisation capabilities are delivered using the Moodle platform and version 1.3 of the specifications for Learning Tools Interoperability (LTI). In this paper, we showcase the potential for EJSS Data Analytics to identify students learning difficulties and misconceptions. Four examples of EJSS Data Analytics applications are provided to illustrate insights on aspects that include understanding a students sequential actions leading to specific task outcomes, the frequency of task attempts by each student, and the ratio of students achieving correct versus incorrect task completions. We identify five key considerations for designing the EJSS teacher dashboard. These considerations relate to Student Thought Process, Student Behaviour, Student Engagement, Student Choice, and Teacher Feedback. These five facets provide a framework for aligning our design efforts with the needs of students and teachers, also drawing upon research in data analytics for education.",
        "comments": "10 pages, 12 figures, 26th International Conference on Multimedia in Physics Teaching and Learning (MPTL'26)",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09676"
    },
    {
        "doc_id": 38,
        "title": "Data-Driven Assessment of the County-Level Breast Cancer Incidence in the United States: Impacts of Modifiable and Non-Modifiable Factors",
        "authors": [
            "Tingting Zhao",
            "Qing Han",
            "Jinfeng Zhang"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Female breast cancer (FBC) incidence rate (IR) varies greatly by counties across the United States (US). Factors responsible for such high spatial disparities are not well understood, making it challenging to design effective intervention strategies. We predicted FBC IRs using prevailing machine learning techniques for 1,754 US counties with a female population over 10,000. Outlier counties with the unexpectedly high or low FBC IRs were identified by controlling the non-modifiable factors (demographics and socioeconomics). Impacts of the modifiable factors (lifestyle, healthcare accessibility, and environment) were mapped. Our study also shed light on hidden FBC risk factors at the regional scale. Methods developed in our study may be used to discover the place-specific, population-level, modifiable factors for the intervention of other types of cancer or chronic diseases.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09660"
    },
    {
        "doc_id": 39,
        "title": "Elementary Particles and Plasma in the First Hour of the Early Universe",
        "authors": [
            "Cheng Tao Yang"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "This dissertation aims to deepen the understanding of the primordial composition of the Universe in the temperature range 300 MeV>T>0.02 MeV. I exploit known properties of elementary particles and apply methods of kinetic theory and statistical physics to advance the understanding of the cosmic plasma.\n  Within the Big Bang model, we begin by considering the Universe being a highly energetic fireball, an ultra-relativistic plasma exhibiting distinct properties. Fundamental particles such as quarks, leptons, and even heavier gauge bosons play a crucial role in the understanding of the early Universe. Our research focuses on the investigation of these fundamental particles as constituents of the dense Universe plasma during the epoch which transits from primordial quark-gluon plasma to the era of normal hadron matter, passing through the decoupling of neutrinos and addressing in detail the electron-positron antimatter plasma.",
        "comments": "PhD thesis, 150 pages, 31 figures. Includes work done in collaboration with Andrew Steinmetz, Christopher Grayson, Martin Formanek, Jeremiah Birrell, and Johann Rafelski Martin Formanek, Cheng Tao Yang, and Johann Rafelski",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09653"
    },
    {
        "doc_id": 40,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 41,
        "title": "Multiple Locally Linear Kernel Machines",
        "authors": [
            "David Picard"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "In this paper we propose a new non-linear classifier based on a combination of locally linear classifiers. A well known optimization formulation is given as we cast the problem in a $\\ell_1$ Multiple Kernel Learning (MKL) problem using many locally linear kernels. Since the number of such kernels is huge, we provide a scalable generic MKL training algorithm handling streaming kernels. With respect to the inference time, the resulting classifier fits the gap between high accuracy but slow non-linear classifiers (such as classical MKL) and fast but low accuracy linear classifiers.",
        "comments": "This paper was written in 2014 and was originally submitted but rejected at ICML'15",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09629"
    },
    {
        "doc_id": 42,
        "title": "Evaluating tree-based imputation methods as an alternative to MICE PMM for drawing inference in empirical studies",
        "authors": [
            "Jakob Schwerter",
            "Ketevan Gurtskaia",
            "Andr\u00e9s Romero",
            "Birgit Zeyer-Gliozzo",
            "Markus Pauly"
        ],
        "subjects": [
            "Applications",
            "Machine Learning"
        ],
        "abstract": "Dealing with missing data is an important problem in statistical analysis that is often addressed with imputation procedures. The performance and validity of such methods are of great importance for their application in empirical studies. While the prevailing method of Multiple Imputation by Chained Equations (MICE) with Predictive Mean Matching (PMM) is considered standard in the social science literature, the increase in complex datasets may require more advanced approaches based on machine learning. In particular, tree-based imputation methods have emerged as very competitive approaches. However, the performance and validity are not completely understood, particularly compared to the standard MICE PMM. This is especially true for inference in linear models. In this study, we investigate the impact of various imputation methods on coefficient estimation, Type I error, and power, to gain insights that can help empirical researchers deal with missingness more effectively. We explore MICE PMM alongside different tree-based methods, such as MICE with Random Forest (RF), Chained Random Forests with and without PMM (missRanger), and Extreme Gradient Boosting (MIXGBoost), conducting a realistic simulation study using the German National Educational Panel Study (NEPS) as the original data source. Our results reveal that Random Forest-based imputations, especially MICE RF and missRanger with PMM, consistently perform better in most scenarios. Standard MICE PMM shows partially increased bias and overly conservative test decisions, particularly with non-true zero coefficients. Our results thus underscore the potential advantages of tree-based imputation methods, albeit with a caveat that all methods perform worse with an increased missingness, particularly missRanger.",
        "comments": "The project \"From Prediction to Agile Interventions in the Social Sciences (FAIR)\" is receiving funding from the programme \"Profilbildung 2020'', an initiative of the Ministry of Culture and Science of the State of Northrhine Westphalia. The sole responsibility for the content of this publication lies with the authors",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09602"
    },
    {
        "doc_id": 43,
        "title": "Statistical Analysis and Optimization of a Fifth-Percentile User Rate Constrained Design for FFR/SFR-Aided OFDMA-Based Cellular Networks",
        "authors": [
            "Jan Garc\u00eda Morales",
            "Guillem Femenias",
            "Felip Riera Palou"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Interference mitigation strategies are deemed to play a key role in the context of the next generation (B4G/5G) of multicellular networks based on orthogonal frequency division multiple access. Fractional and soft frequency reuse (FFR, SFR) constitute two powerful mechanisms for intercell interference coordination that have been already adopted by emerging cellular deployments as an efficient way to improve the throughput performance perceived by cell-edge users. This paper presents a novel optimal fifth-percentile user rate constrained design for FFR/SFR-based networks that, by appropriately dimensioning the center and edge regions of the cell, rightly splitting the available bandwidth among these two areas while assigning the corresponding transmit power, allows a tradeoff between cell throughput performance and fairness to be established. To this end, both the cumulative distribution function of the user throughput and the average spectral efficiency of the system are derived assuming the use of the ubiquitous proportional fair scheduling policy. The mathematical framework is then used to obtain numerical results showing that the novel proposed design clearly outperforms previous schemes in terms of throughput fairness control due to a more rational compromise between average cell throughput and cell-edge ICIC.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09600"
    },
    {
        "doc_id": 44,
        "title": "Asymptotic Online FWER Control for Dependent Test Statistics",
        "authors": [
            "Vincent Jankovic",
            "Lasse Fischer",
            "Werner Brannath"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In online multiple testing, an a priori unknown number of hypotheses are tested sequentially, i.e. at each time point a test decision for the current hypothesis has to be made using only the data available so far. Although many powerful test procedures have been developed for online error control in recent years, most of them are designed solely for independent or at most locally dependent test statistics. In this work, we provide a new framework for deriving online multiple test procedures which ensure asymptotical (with respect to the sample size) control of the familywise error rate (FWER), regardless of the dependence structure between test statistics. In this context, we give a few concrete examples of such test procedures and discuss their properties. Furthermore, we conduct a simulation study in which the type I error control of these test procedures is also confirmed for a finite sample size and a gain in power is indicated.",
        "comments": "18 pages, 6 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09559"
    },
    {
        "doc_id": 45,
        "title": "A Volume-Limited Sample of Ultracool Dwarfs. II. The Substellar Age and Mass Functions in the Solar Neighborhood",
        "authors": [
            "William M. J. Best",
            "Aniket Sanghi",
            "Michael C. Liu",
            "Eugene A. Magnier",
            "Trent J. Dupuy"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Earth and Planetary Astrophysics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "We present the most precise constraints to date for the mass and age distributions of single ultracool dwarfs in the solar neighborhood, based on an updated volume-limited sample of 504 L, T, and Y dwarfs within 25 pc. We develop a Monte Carlo approach using the $\\langle V/V_{\\rm max}\\rangle$ statistic to correct for incompleteness and obtain a space density of $(1.83_{-0.15}^{+0.16})\\times10^{-2}$ pc$^{-3}$ for spectral types L0-Y2. We calculate bolometric luminosities for our sample, using an updated \"super-magnitude\" method for the faintest objects. We use our resulting luminosity function and a likelihood-based population synthesis approach to simultaneously constrain the mass and age distributions. We employ the fraction of young L0-L7 dwarfs as a novel input for this analysis that is crucial for constraining the age distribution. For a power-law mass function $\\frac{dN}{dM} \\propto M^{-\u03b1}$ we find $\u03b1=0.58_{-0.20}^{+0.16}$, indicating an increase in numbers toward lower masses, consistent with measurements in nearby star-forming regions. For an exponential age distribution $b(t) \\propto e^{-\u03b2t}$ we find $\u03b2=-0.44\\pm0.14$, i.e., a population with fewer old objects than often assumed, which may reflect dynamical heating of the Galactic plane as much as the historical brown dwarf birthrate. We compare our analysis to Kirkpatrick et al. (2021), who used a similar volume-limited sample. Although our mass function measurements are numerically consistent, their assumption of a flat age distribution is disfavored by our analysis, and we identify several important methodological differences between our two studies. Our calculation of the age distribution of solar neighborhood brown dwarfs is the first based on a volume-limited sample.",
        "comments": "Accepted to ApJ. 49 pages, 14 figures, 6 tables",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09535"
    },
    {
        "doc_id": 46,
        "title": "Learning New Physics from Data -- a Symmetrized Approach",
        "authors": [
            "Shikma Bressler",
            "Inbar Savoray",
            "Yuval Zurgil"
        ],
        "subjects": [
            "High Energy Physics - Experiment",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Thousands of person-years have been invested in searches for New Physics (NP), the majority of them motivated by theoretical considerations. Yet, no evidence of beyond the Standard Model (BSM) physics has been found. This suggests that model-agnostic searches might be an important key to explore NP, and help discover unexpected phenomena which can inspire future theoretical developments. A possible strategy for such searches is identifying asymmetries between data samples that are expected to be symmetric within the Standard Model (SM). We propose exploiting neural networks (NNs) to quickly fit and statistically test the differences between two samples. Our method is based on an earlier work, originally designed for inferring the deviations of an observed dataset from that of a much larger reference dataset. We present a symmetric formalism, generalizing the original one; avoiding fine-tuning of the NN parameters and any constraints on the relative sizes of the samples. Our formalism could be used to detect small symmetry violations, extending the discovery potential of current and future particle physics experiments.",
        "comments": "34 pages, 10 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09530"
    },
    {
        "doc_id": 47,
        "title": "The Beam-Dump Ceiling and Its Experimental Implication: The Case of a Portable Experiment",
        "authors": [
            "Doojin Kim",
            "Jaehoon Yu",
            "Jong-Chul Park",
            "Hyunyong Kim"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We generalize the nature of the so-called beam-dump \"ceiling\" beyond which the improvement on the sensitivity reach in the search for fast-decaying mediators dramatically slows down, and point out its experimental implications that motivate tabletop-size beam-dump experiments for the search. Light (bosonic) mediators are well-motivated new-physics particles as they can appear in dark-sector portal scenarios and models to explain various laboratory-based anomalies. Due to their low mass and feebly interacting nature, beam-dump-type experiments, utilizing high-intensity particle beams can play a crucial role in probing the parameter space of visibly decaying such mediators, in particular, the ``prompt-decay'' region where the mediators feature relatively large coupling and mass. We present a general and semi-analytic proof that the ceiling effectively arises in the prompt-decay region of an experiment and show its insensitivity to data statistics, background estimates, and systematic uncertainties, considering a concrete example, the search for axion-like particles interacting with ordinary photons at three benchmark beam facilities, PIP-II at FNAL and SPS and LHC-dump at CERN. We then identify optimal criteria to perform a cost-effective and short-term experiment to reach the ceiling, demonstrating that very short-baseline compact experiments enable access to the parameter space unreachable thus far.",
        "comments": "6 pages, 2 figures, 1 table",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09529"
    },
    {
        "doc_id": 48,
        "title": "Universal Vortex Statistics and Stochastic Geometry of Bose-Einstein Condensation",
        "authors": [
            "Mithun Thudiyangal",
            "Adolfo del Campo"
        ],
        "subjects": [
            "Quantum Gases",
            "Statistical Mechanics",
            "Quantum Physics"
        ],
        "abstract": "The cooling of a Bose gas in finite time results in the formation of a Bose-Einstein condensate that is spontaneously proliferated with vortices. We propose that the vortex spatial statistics is described by a homogeneous Poisson point process (PPP) with a density dictated by the Kibble-Zurek mechanism (KZM). We validate this model using numerical simulations of the two-dimensional stochastic Gross-Pitaevskii equation (SGPE) for both a homogeneous and a hard-wall trapped condensate. The KZM scaling of the average vortex number with the cooling rate is established along with the universal character of the vortex number distribution. The spatial statistics between vortices is characterized by analyzing the two-point defect-defect correlation function, the corresponding spacing distributions, and the random tessellation of the vortex pattern using the Voronoi cell area statistics. Combining the PPP description with the KZM, we derive universal theoretical predictions for each of these quantities and find them in agreement with the SGPE simulations. Our results establish the universal character of the spatial statistics of point-like topological defects generated during a continuous phase transition and the associated stochastic geometry.",
        "comments": "16 pages, 16 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09525"
    },
    {
        "doc_id": 49,
        "title": "4D-ONIX: A deep learning approach for reconstructing 3D movies from sparse X-ray projections",
        "authors": [
            "Yuhe Zhang",
            "Zisheng Yao",
            "Robert Kl\u00f6fkorn",
            "Tobias Ritschel",
            "Pablo Villanueva-Perez"
        ],
        "subjects": [
            "Image and Video Processing",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "The X-ray flux provided by X-ray free-electron lasers and storage rings offers new spatiotemporal possibilities to study in-situ and operando dynamics, even using single pulses of such facilities. X-ray Multi-Projection Imaging (XMPI) is a novel technique that enables volumetric information using single pulses of such facilities and avoids centrifugal forces induced by state-of-the-art time-resolved 3D methods such as time-resolved tomography. As a result, XMPI can acquire 3D movies (4D) at least three orders of magnitude faster than current methods. However, no algorithm can reconstruct 4D from highly sparse projections acquired by XMPI. Here, we present 4D-ONIX, a Deep Learning (DL)-based approach that learns to reconstruct 3D movies (4D) from an extremely limited number of projections. It combines the computational physical model of X-ray interaction with matter and state-of-the-art DL methods. We demonstrate the potential of 4D-ONIX to generate high-quality 4D by generalizing over multiple experiments with only two projections per timestamp for binary droplet collisions. We envision that 4D-ONIX will become an enabling tool for 4D analysis, offering new spatiotemporal resolutions to study processes not possible before.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09508"
    },
    {
        "doc_id": 50,
        "title": "Large sensory analysis of vegetables from conventional, organic and no-till practices",
        "authors": [
            "S\u00e9bastien Loustau",
            "F Lefer",
            "S Ducos"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "There is a growing interest in agriculture to address soil deterioration issues and achieve a sustainable agrosystem. Many producers introduce no-till techniques and show significant yields with better ecosystem functioning, as well as improved carbon and water cycles. However, sensory analysis to compare vegetables from these practices are scarce. In this paper, we conduct triangle and hedonic tests over 15 panels of consumers for a total of more than 950 consumers. Based on statistical hypothesis testing and maximum likelihood estimation, significant statistical differences (P < 0.05 and less) are produced for both triangle tests and hedonic ranking in some specific cases. These results show a trend for sensory preferences of no-till practices.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09503"
    },
    {
        "doc_id": 51,
        "title": "Functional Autoencoder for Smoothing and Representation Learning",
        "authors": [
            "Sidi Wu",
            "C\u00e9dric Beaulac",
            "Jiguo Cao"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A common pipeline in functional data analysis is to first convert the discretely observed data to smooth functions, and then represent the functions by a finite-dimensional vector of coefficients summarizing the information. Existing methods for data smoothing and dimensional reduction mainly focus on learning the linear mappings from the data space to the representation space, however, learning only the linear representations may not be sufficient. In this study, we propose to learn the nonlinear representations of functional data using neural network autoencoders designed to process data in the form it is usually collected without the need of preprocessing. We design the encoder to employ a projection layer computing the weighted inner product of the functional data and functional weights over the observed timestamp, and the decoder to apply a recovery layer that maps the finite-dimensional vector extracted from the functional data back to functional space using a set of predetermined basis functions. The developed architecture can accommodate both regularly and irregularly spaced data. Our experiments demonstrate that the proposed method outperforms functional principal component analysis in terms of prediction and classification, and maintains superior smoothing ability and better computational efficiency in comparison to the conventional autoencoders under both linear and nonlinear settings.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09499"
    },
    {
        "doc_id": 52,
        "title": "Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian Process Regression",
        "authors": [
            "Rub\u00e9n Antonio Garc\u00eda-Ruiz",
            "Jos\u00e9 Luis Blanco-Claraco",
            "Javier L\u00f3pez-Mart\u00ednez",
            "\u00c1ngel Jes\u00fas Callej\u00f3n-Ferre"
        ],
        "subjects": [
            "Machine Learning",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "Expensive ultrasonic anemometers are usually required to measure wind speed accurately. The aim of this work is to overcome the loss of accuracy of a low cost hot-wire anemometer caused by the changes of air temperature, by means of a probabilistic calibration using Gaussian Process Regression. Gaussian Process Regression is a non-parametric, Bayesian, and supervised learning method designed to make predictions of an unknown target variable as a function of one or more known input variables. Our approach is validated against real datasets, obtaining a good performance in inferring the actual wind speed values. By performing, before its real use in the field, a calibration of the hot-wire anemometer taking into account air temperature, permits that the wind speed can be estimated for the typical range of ambient temperatures, including a grounded uncertainty estimation for each speed measure.",
        "comments": "10 pages, 6 figures, Published in \"IEEE Sensors Journal\"",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09492"
    },
    {
        "doc_id": 53,
        "title": "3DMASC: Accessible, explainable 3D point clouds classification. Application to Bi-spectral Topo-bathymetric lidar data",
        "authors": [
            "Mathilde Letard",
            "Dimitri Lague",
            "Arthur Le Guennec",
            "S\u00e9bastien Lef\u00e8vre",
            "Baptiste Feldmann",
            "Paul Leroy",
            "Daniel Girardeau-Montaut",
            "Thomas Corpetti"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "Three-dimensional data have become increasingly present in earth observation over the last decades. However, many 3D surveys are still underexploited due to the lack of accessible and explainable automatic classification methods, for example, new topo-bathymetric lidar data. In this work, we introduce explainable machine learning for 3D data classification using Multiple Attributes, Scales, and Clouds under 3DMASC, a new workflow. This workflow introduces multi-cloud classification through dual-cloud features, encrypting local spectral and geometrical ratios and differences. 3DMASC uses classical multi-scale descriptors adapted to all types of 3D point clouds and new ones based on their spatial variations. In this paper, we present the performances of 3DMASC for multi-class classification of topo-bathymetric lidar data in coastal and fluvial environments. We show how multivariate and embedded feature selection allows the building of optimized predictor sets of reduced complexity, and we identify features particularly relevant for coastal and riverine scene descriptions. Our results show the importance of dual-cloud features, lidar return-based attributes averaged over specific scales, and of statistics of dimensionality-based and spectral features. Additionally, they indicate that small to medium spherical neighbourhood diameters (<7 m) are sufficient to build effective classifiers, namely when combined with distance-to-ground or distance-to-water-surface features. Without using optional RGB information, and with a maximum of 37 descriptors, we obtain classification accuracies between 91 % for complex multi-class tasks and 98 % for lower-level processing using models trained on less than 2000 samples per class. Comparisons with classical point cloud classification methods show that 3DMASC features have a significantly improved descriptive power. Our contributions are made available through a plugin in the CloudCompare software, allowing non-specialist users to create classifiers for any type of 3D data characterized by 1 or 2 point clouds (airborne or terrestrial lidar, structure from motion), and two labelled topo-bathymetric lidar datasets, available on https://opentopography.org/.",
        "comments": "Journal ref:        ISPRS Journal of Photogrammetry and Remote Sensing, 2024, 207, pp.175-197",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09481"
    },
    {
        "doc_id": 54,
        "title": "Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep Learning",
        "authors": [
            "Rahul Vishwakarma",
            "Amin Rezaei"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The risk of hardware Trojans being inserted at various stages of chip production has increased in a zero-trust fabless era. To counter this, various machine learning solutions have been developed for the detection of hardware Trojans. While most of the focus has been on either a statistical or deep learning approach, the limited number of Trojan-infected benchmarks affects the detection accuracy and restricts the possibility of detecting zero-day Trojans. To close the gap, we first employ generative adversarial networks to amplify our data in two alternative representation modalities, a graph and a tabular, ensuring that the dataset is distributed in a representative manner. Further, we propose a multimodal deep learning approach to detect hardware Trojans and evaluate the results from both early fusion and late fusion strategies. We also estimate the uncertainty quantification metrics of each prediction for risk-aware decision-making. The outcomes not only confirms the efficacy of our proposed hardware Trojan detection method but also opens a new door for future studies employing multimodality and uncertainty quantification to address other hardware security challenges.",
        "comments": "2024 Design, Automation and Test in Europe Conference | The European Event for Electronic System Design & Test (accepted)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09479"
    },
    {
        "doc_id": 55,
        "title": "Parametric Constraints for Bayesian Knowledge Tracing from First Principles",
        "authors": [
            "Denis Shchepakin",
            "Sreecharan Sankaranarayanan",
            "Dawn Zimmaro"
        ],
        "subjects": [
            "Computers and Society",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's state of mastery corresponding to a knowledge component. It considers the learner's state of mastery as a \"hidden\" or latent binary variable and updates this state based on the observed correctness of the learner's response using parameters that represent transition probabilities between states. BKT is often represented as a Hidden Markov Model and the Expectation-Maximization (EM) algorithm is used to infer these parameters. However, this algorithm can suffer from several issues including producing multiple viable sets of parameters, settling into a local minima, producing degenerate parameter values, and a high computational cost during fitting. This paper takes a \"from first principles\" approach to deriving constraints that can be imposed on the BKT parameter space. Starting from the basic mathematical truths of probability and building up to the behaviors expected of the BKT parameters in real systems, this paper presents a mathematical derivation that results in succinct constraints that can be imposed on the BKT parameter space. Since these constraints are necessary conditions, they can be applied prior to fitting in order to reduce computational cost and the likelihood of issues that can emerge from the EM procedure. In order to see that promise through, the paper further introduces a novel algorithm for estimating BKT parameters subject to the newly defined constraints. While the issue of degenerate parameter values has been reported previously, this paper is the first, to our best knowledge, to derive the constrains from first principles while also presenting an algorithm that respects those constraints.",
        "comments": "MSC Class:          62F15 (Primary) 62M05; 60J20; 68T30; 91E40 (Secondary)",
        "date": "22 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09456"
    },
    {
        "doc_id": 56,
        "title": "Reasoning with random sets: An agenda for the future",
        "authors": [
            "Fabio Cuzzolin"
        ],
        "subjects": [
            "Statistics Theory",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "In this paper, we discuss a potential agenda for future work in the theory of random sets and belief functions, touching upon a number of focal issues: the development of a fully-fledged theory of statistical reasoning with random sets, including the generalisation of logistic regression and of the classical laws of probability; the further development of the geometric approach to uncertainty, to include general random sets, a wider range of uncertainty measures and alternative geometric representations; the application of this new theory to high-impact areas such as climate change, machine learning and statistical learning theory.",
        "comments": "94 pages, 17 figures",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09435"
    },
    {
        "doc_id": 57,
        "title": "Randomized Kaczmarz with geometrically smoothed momentum",
        "authors": [
            "Seth J. Alderman",
            "Roan W. Luikart",
            "Nicholas F. Marshall"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "This paper studies the effect of adding geometrically smoothed momentum to the randomized Kaczmarz algorithm, which is an instance of stochastic gradient descent on a linear least squares loss function. We prove a result about the expected error in the direction of singular vectors of the matrix defining the least squares loss. We present several numerical examples illustrating the utility of our result and pose several questions.",
        "comments": "21 pages, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09415"
    },
    {
        "doc_id": 58,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 59,
        "title": "Yielding and plasticity in amorphous solids",
        "authors": [
            "Ludovic Berthier",
            "Giulio Biroli",
            "M. Lisa Manning",
            "Francesco Zamponi"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Disordered Systems and Neural Networks",
            "Soft Condensed Matter"
        ],
        "abstract": "The physics of disordered media, from metallic glasses to colloidal suspensions, granular matter and biological tissues, offers difficult challenges because it often occurs far from equilibrium, in materials lacking symmetries and evolving through complex energy landscapes. Here, we review recent theoretical efforts to provide microscopic insights into the mechanical properties of amorphous media using approaches from statistical mechanics as unifying frameworks. We cover both the initial regime corresponding to small deformations, and the yielding transition marking a change between elastic response and plastic flow. We discuss the specific features arising for systems evolving near a jamming transition, and extend our discussion to recent studies of the rheology of dense biological and active materials.",
        "comments": "20 pages, 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09385"
    },
    {
        "doc_id": 60,
        "title": "Modelling clusters in network time series with an application to presidential elections in the USA",
        "authors": [
            "Guy Nason",
            "Daniel Salnikov",
            "Mario Cortina-Borja"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "Network time series are becoming increasingly relevant in the study of dynamic processes characterised by a known or inferred underlying network structure. Generalised Network Autoregressive (GNAR) models provide a parsimonious framework for exploiting the underlying network, even in the high-dimensional setting. We extend the GNAR framework by introducing the $\\textit{community}$-$\u03b1$ GNAR model that exploits prior knowledge and/or exogenous variables for identifying and modelling dynamic interactions across communities in the underlying network. We further analyse the dynamics of $\\textit{Red, Blue}$ and $\\textit{Swing}$ states throughout presidential elections in the USA. Our analysis shows that dynamics differ among the state-wise clusters.",
        "comments": "18 pages, 12 figures. Pre-print",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09381"
    },
    {
        "doc_id": 61,
        "title": "Merging uncertainty sets via majority vote",
        "authors": [
            "Matteo Gasparin",
            "Aaditya Ramdas"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Given $K$ uncertainty sets that are arbitrarily dependent -- for example, confidence intervals for an unknown parameter obtained with $K$ different estimators, or prediction sets obtained via conformal prediction based on $K$ different algorithms on shared data -- we address the question of how to efficiently combine them in a black-box manner to produce a single uncertainty set. We present a simple and broadly applicable majority vote procedure that produces a merged set with nearly the same error guarantee as the input sets. We then extend this core idea in a few ways: we show that weighted averaging can be a powerful way to incorporate prior information, and a simple randomization trick produces strictly smaller merged sets without altering the coverage guarantee. Along the way, we prove an intriguing result that R\u00fcger's combination rules (eg: twice the median of dependent p-values is a p-value) can be strictly improved with randomization. When deployed in online settings, we show how the exponential weighted majority algorithm can be employed in order to learn a good weighting over time. We then combine this method with adaptive conformal inference to deliver a simple conformal online model aggregation (COMA) method for nonexchangeable data.",
        "comments": "26 pages, 10 figures, 2 tables",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09379"
    },
    {
        "doc_id": 62,
        "title": "Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter Paradigm for Performance Estimation in Online and Static Settings",
        "authors": [
            "Kevin Slote",
            "Elaine Lee"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "In the realm of machine learning and statistical modeling, practitioners often work under the assumption of accessible, static, labeled data for evaluation and training. However, this assumption often deviates from reality where data may be private, encrypted, difficult- to-measure, or unlabeled. In this paper, we bridge this gap by adapting the Hui-Walter paradigm, a method traditionally applied in epidemiology and medicine, to the field of machine learning. This approach enables us to estimate key performance metrics such as false positive rate, false negative rate, and priors in scenarios where no ground truth is available. We further extend this paradigm for handling online data, opening up new possibilities for dynamic data environments. Our methodology involves partitioning data into latent classes to simulate multiple data populations (if natural populations are unavailable) and independently training models to replicate multiple tests. By cross-tabulating binary outcomes across ensemble categorizers and multiple populations, we are able to estimate unknown parameters through Gibbs sampling, eliminating the need for ground-truth or labeled data. This paper showcases the potential of our methodology to transform machine learning practices by allowing for accurate model assessment under dynamic and uncertain data conditions.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09376"
    },
    {
        "doc_id": 63,
        "title": "Anticipating Tipping Points for Disordered Traffic: Critical Slowing Down on the Onset of Congestion",
        "authors": [
            "Shankha Narayan Chattopadhyay",
            "Arvind Kumar Gupta"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "Regime shifts are quite common in complex systems like cell regulations, disease transmissions, ecosystems, marine ice instability, etc. Several statistical indicators known as early warning signals (EWS) have been theorized to anticipate these abrupt transitions in advance. These regime shifts happen because they cross some critical value of the parameter that influences the overall dynamics. This critical threshold is known as tipping point. In the vicinity of a tipping point, perturbations gradually increases, and as a consequence, system-state extensively swing around the quasi-static attractor, and the local dynamics become progressively slow, which is known as critical slowing down (CSD). Because of this CSD, statistical measures known as early warning signals (EWS) such as variance and lag-1 autocorrelation increase. From the point of view of physics, a free flow can become congested when the mean car density crosses its tipping point. Recently, for lane-based traffic system using continuum model, study reveals that analysis of the generic EWSs serve as a good measure to predict upstream stop-and-go traffic jams. Now, we introduce EWSs to anticipate traffic jam for heterogeneous disordered traffic relevant for non-lane-based systems. We have analyzed a lattice hydrodynamic area occupancy model with passing and through numerical simulations, we have shown emergence of kink or chaotic jam. Also, we provided proper framework for prediction of traffic jams via different EWSs. From simulated data, we demonstrated that EWSs are sensitive as tipping is approached.",
        "comments": "12 pages, 4 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09364"
    },
    {
        "doc_id": 64,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 65,
        "title": "Potential Energy Landscape of a Flexible Water Model: Equation-of-State, Configurational Entropy, and Adam-Gibbs Relationship",
        "authors": [
            "Ali Eltareb",
            "Gustavo E. Lopez",
            "Nicolas Giovambattista"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Chemical Physics"
        ],
        "abstract": "The potential energy landscape (PEL) formalism is a tool within statistical mechanics that has been used in the past to calculate the equation of states (EOS) of classical rigid model liquids at low temperatures, where computer simulations may be challenging. In this work, we use classical molecular dynamics (MD) simulations and the PEL formalism to calculate the EOS of the flexible q-TIP4P/F water model. This model exhibits a liquid-liquid critical point (LLCP) in the supercooled regime, at ($P_c = 150$ MPa, $T_c = 190$ K, $\u03c1_c = 1.04$ g/cm$^3$) [using the reaction field technique]. The PEL-EOS of q-TIP4P/F water, and the corresponding location of the LLCP, are in very good agreement with the MD simulations. We show that the PEL of q-TIP4P/F water is Gaussian which allows us to calculate the configurational entropy of the system, $S_{conf}$. The $S_{conf}$ of q-TIP4P/F water is surprisingly similar to that reported previously for rigid water models, suggesting that intramolecular flexibility does not necessarily add roughness to the PEL. We also show that the Adam-Gibbs relation, which relates the diffusion coefficient $D$ with $S_{conf}$, holds for the flexible q-TIP4P/F water model. Overall, our results indicate that the PEL formalism can be used to study molecular systems that include molecular flexibility, the common case in standard force fields. This is not trivial since the introduction of large bending/stretching mode frequencies is problematic in classical statistical mechanics. For example, as shown previously, we find that such high-frequencies lead to an unphysical (negative) entropy for q-TIP4P/F water (yet the PEL formalism can be applied successfully).",
        "comments": "38 pages, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09355"
    },
    {
        "doc_id": 66,
        "title": "High Confidence Level Inference is Almost Free using Parallel Stochastic Optimization",
        "authors": [
            "Wanrong Zhu",
            "Zhipeng Lou",
            "Ziyang Wei",
            "Wei Biao Wu"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Uncertainty quantification for estimation through stochastic optimization solutions in an online setting has gained popularity recently. This paper introduces a novel inference method focused on constructing confidence intervals with efficient computation and fast convergence to the nominal level. Specifically, we propose to use a small number of independent multi-runs to acquire distribution information and construct a t-based confidence interval. Our method requires minimal additional computation and memory beyond the standard updating of estimates, making the inference process almost cost-free. We provide a rigorous theoretical guarantee for the confidence interval, demonstrating that the coverage is approximately exact with an explicit convergence rate and allowing for high confidence level inference. In particular, a new Gaussian approximation result is developed for the online estimators to characterize the coverage properties of our confidence intervals in terms of relative errors. Additionally, our method also allows for leveraging parallel computing to further accelerate calculations using multiple cores. It is easy to implement and can be integrated with existing stochastic algorithms without the need for complicated modifications.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09346"
    },
    {
        "doc_id": 67,
        "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications",
        "authors": [
            "Jie Hu",
            "Vishwaraj Doshi",
            "Do Young Eun"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approximation using Markovian samples and show their identical asymptotic performance, a perspective not evident from current finite-time bounds.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09339"
    },
    {
        "doc_id": 68,
        "title": "On the structure of the large-$N$ expansion in SU($N$) Yang-Mills theory",
        "authors": [
            "Marco Bochicchio",
            "Mauro Papinutto",
            "Francesco Scardino"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Recently, we have computed the short-distance asymptotics of the generating functional of Euclidean correlators of single-trace twist-$2$ operators in the large-$N$ expansion of SU($N$) Yang-Mills (YM) theory to the leading-nonplanar order. Remarkably, it has the structure of the logarithm of a functional determinant, but with the sign opposite to the one that would follow from the spin-statistics theorem for the glueballs. In order to solve this sign puzzle, we have reconsidered the proof in the literature that in the 't Hooft topological expansion of large-$N$ YM theory the leading-nonplanar contribution to the generating functional consists of the sum over punctures of $n$-punctured tori. We have discovered that for twist-$2$ operators it contains -- in addition to the $n$-punctured tori -- the normalization of tori with $1 \\leq p \\leq n$ pinches and $n-p$ punctures. Once the existence of the new sector is taken into account, the violation of the spin-statistics theorem disappears. Moreover, the new sector contributes trivially to the nonperturbative $S$ matrix because -- for example -- the $n$-pinched torus represents nonperturbatively a loop of $n$ glueball propagators with no external leg. This opens the way for an exact solution limited to the new sector that may be solvable thanks to the vanishing $S$ matrix.",
        "comments": "12 pages, 16 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09312"
    },
    {
        "doc_id": 69,
        "title": "Asymmetric games on networks: mapping to Ising models and bounded rationality",
        "authors": [
            "Filippo Zimmaro",
            "Serge Galam",
            "Marco Alberto Javarone"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "We investigate the dynamics of coordination and consensus in an agent population. Considering agents endowed with bounded rationality, we study asymmetric coordination games using a mapping to random field Ising models. In doing so, we investigate the relationship between group coordination and agent rationality. Analytical calculations and numerical simulations of the proposed model lead to novel insight into opinion dynamics. For instance, we find that bounded rationality and preference intensity can determine a series of possible scenarios with different levels of opinion polarization. To conclude, we deem our investigation opens a new avenue for studying game dynamics through methods of statistical physics.",
        "comments": "15 pages, 4 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09310"
    },
    {
        "doc_id": 70,
        "title": "Simultaneously search for multi-target Galactic binary gravitational waves in reduced parameter space with LMPSO-CV",
        "authors": [
            "Pin Gao",
            "Xilong Fan",
            "Zhoujian Cao"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Astrophysical Phenomena",
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "We propose an innovative approach to the concurrent exploration of gravitational waves originating from Galactic binaries through the development of a new Local Maxima Particle Swarm Optimization (LMPSO) algorithm. Our methodology employs strategic Create Voids (CV) to streamline parameter space, maximizing the identification of local maxima for the $\\mathcal{F}$-statistic even in the overlapped signals case. Subsequently, a ``find-real-$\\mathcal{F}$-statistic-analysis\", which implements the astrophysical models and properties of $\\mathcal{F}$-statistic in parameter space, is conducted to reveal Galactic binary gravitational wave signals within the dataset. Our new approach eliminates inaccuracies associated with signal subtraction contamination, which is a challenge for traditional iterative-subtraction methods when addressing low signal-to-noise ratio signals (e.g., SNR $<$ 15). To demonstrate the efficacy of our approach, we utilize the residuals from the LISA mock data challenge (LDC1-4), where 10982 injection sources with optimal SNR $>$ 15 have been eliminated. The LMPSO-CV method efficiently identifies 8995 signals with a 47.7\\% false source fraction or 3463 signals with a 26.9\\% false source fraction when the correlation coefficient threshold is set to 0.8.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09300"
    },
    {
        "doc_id": 71,
        "title": "Spectral Distribution Complexity of the Surface Fibrillatory Waves Predicts Post-Catheter Ablation Relapse in Persistent Atrial Fibrillation",
        "authors": [
            "Pilar Escribano",
            "Juan Rodenas",
            "Manuel Garcia",
            "Miguel A Arias",
            "Jose J Rieta",
            "Raul Alcaraz"
        ],
        "subjects": [
            "Signal Processing",
            "Medical Physics"
        ],
        "abstract": "As for most of cardiac arrhythmias, atrial fibrillation (AF) is primarily treated by catheter ablation (CA). However, the mid-term recurrence rate of this procedure in persistent AF patients is still limited and the preoperative prediction of its outcome is clinically interesting to select candidates who could benefit the most from the intervention. This context encouraged the study of C0 complexity as a novel predictor, because it estimates organization of the power spectral distribution (PSD) of the fibrillatory waves (f-waves). For that purpose, the PSD was divided into two divergent components using a threshold, theta, which was considered by multiplying the mean value of the PSD by a factor, alpha, ranging between 1.5 and 2.5. On a database of 74 patients, the values of C0 complexity computed for all alpha factors reported statistically significant differences between the patients who maintained sinus rhythm and those who relapsed to AF after a follow-up of 9 months. They also showed higher values of sensitivity (Se), specificity (Sp), and accuracy (Acc) than the well known predictors of the dominant frequency (DF) and f-wave amplitude. Moreover, the combination of the DF and the C0 complexity computed with alpha = 2, via a decision tree, improved classification until values of Se, Sp and Acc of 75.33, 77.33 and 76.58%, respectively. These results manifests the relevance of the f-wave PSD distribution to anticipate CA outcome in persistent AF patients.",
        "comments": "Journal ref:        Computing in Cardiology 2022; Vol 49",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09297"
    },
    {
        "doc_id": 72,
        "title": "Using pairwise comparisons to determine consumer preferences in hotel selection",
        "authors": [
            "N. Krivulin",
            "A. Prinkov",
            "I. Gladkikh"
        ],
        "subjects": [
            "Optimization and Control",
            "Applications"
        ],
        "abstract": "We consider the problem of evaluating preferences for criteria used by university students when selecting a hotel for accommodation during a professional development program in a foreign country. Input data for analysis come from a survey of 202 respondents, who indicated their age, sex and whether they have previously visited the country. The criteria under evaluation are location, accommodation cost, typical guests, free breakfast, room amenities and courtesy of staff. The respondents assess the criteria both directly by providing estimates of absolute ratings and ranks, and indirectly by relative estimates using ratios of pairwise comparisons. To improve the accuracy of ratings derived from pairwise comparisons, we concurrently apply the principal eigenvector method, the geometric mean method and the method of log-Chebyshev approximation. Then, the results from the direct and indirect evaluation of ratings and ranks are examined together to analyze how the results from pairwise comparisons may differ from each other and from the results of direct assessment by respondents. We apply statistical techniques, such as estimation of means, standard deviations and correlations, to the vectors of ratings and ranks provided directly or indirectly by respondents, and then use the estimates to make accurate assessment of the criteria under study.",
        "comments": "27 pages, 16 tables",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09287"
    },
    {
        "doc_id": 73,
        "title": "A New Approach to Find the B\u00f6hm-Vitense gap",
        "authors": [
            "Tahereh Ramezani",
            "Ernst Paunzen",
            "Martin Piecka",
            "Michal Kajan"
        ],
        "subjects": [
            "Astrophysics of Galaxies"
        ],
        "abstract": "This paper discusses the B\u00f6hm-Vitense gap, a gap in the colours of stars that occurs when the atmosphere changes from radiative to convective in deep layers. We are using different algorithms for detecting gaps in colour-magnitude diagrams (CMDs), including the k-nearest neighbours (k-NN) and UniDip algorithms. We propose using a combination of the k-NN algorithm and the UniDip algorithm and manual verification to identify gaps unlikely to be of a statistical origin. Using the $Gaia$ photometric system, i.e. BP-RP, we took the data of 130 star clusters and searched for gaps in the ranges of 0.40 to 0.47 mag, and 0.56 to 0.60 mag, respectively. We analysed all data statistically and identified the gaps in the individual clusters. Finally, we applied the kernel density estimator to see how the gaps are distributed.",
        "comments": "arXiv admin note: text overlap with arXiv:astro-ph/9802204 by other authors",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09264"
    },
    {
        "doc_id": 74,
        "title": "Mitigating distribution shift in machine learning-augmented hybrid simulation",
        "authors": [
            "Jiaxi Zhao",
            "Qianxiao Li"
        ],
        "subjects": [
            "Numerical Analysis",
            "Dynamical Systems",
            "Machine Learning"
        ],
        "abstract": "We study the problem of distribution shift generally arising in machine-learning augmented hybrid simulation, where parts of simulation algorithms are replaced by data-driven surrogates. We first establish a mathematical framework to understand the structure of machine-learning augmented hybrid simulation problems, and the cause and effect of the associated distribution shift. We show correlations between distribution shift and simulation error both numerically and theoretically. Then, we propose a simple methodology based on tangent-space regularized estimator to control the distribution shift, thereby improving the long-term accuracy of the simulation results. In the linear dynamics case, we provide a thorough theoretical analysis to quantify the effectiveness of the proposed method. Moreover, we conduct several numerical experiments, including simulating a partially known reaction-diffusion equation and solving Navier-Stokes equations using the projection method with a data-driven pressure solver. In all cases, we observe marked improvements in simulation accuracy under the proposed method, especially for systems with high degrees of distribution shift, such as those with relatively strong non-linear reaction mechanisms, or flows at large Reynolds numbers.",
        "comments": "MSC Class:          68T99; 65M15; 37M05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09259"
    },
    {
        "doc_id": 75,
        "title": "Accurate Memory Kernel Extraction from Discretized Time Series Data",
        "authors": [
            "Lucas Tepper",
            "Benjamin Dalton",
            "Roland R. Netz"
        ],
        "subjects": [
            "Data Analysis, Statistics and Probability",
            "Computational Physics"
        ],
        "abstract": "Memory effects emerge as a fundamental consequence of dimensionality reduction when low-dimensional observables are used to describe the dynamics of complex many-body systems. In the context of molecular dynamics (MD) data analysis, accounting for memory effects using the framework of the generalized Langevin equation (GLE) has proven efficient, accurate and insightful, particularly when working with high-resolution time series data. However, in experimental systems, high-resolution data is often unavailable, raising questions about the impact of the data resolution on the estimated GLE parameters. This study demonstrates that direct memory extraction remains accurate when the discretization time is below the memory time. To obtain memory functions reliably even when the discretization time exceeds the memory time, we introduce a Gaussian Process Optimization (GPO) scheme. This scheme minimizes the deviation of discretized two-point correlation functions between MD and GLE simulations and is able to estimate accurate memory kernels as long as the discretization time stays below the longest time scale in the data, typically the barrier crossing time.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09249"
    },
    {
        "doc_id": 76,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 77,
        "title": "An Optimal Transport Approach for Computing Adversarial Training Lower Bounds in Multiclass Classification",
        "authors": [
            "Nicolas Garcia Trillos",
            "Matt Jacobs",
            "Jakwang Kim",
            "Matthew Werenski"
        ],
        "subjects": [
            "Machine Learning",
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CIFAR-$10$, which demonstrate the tractability of our approach.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09191"
    },
    {
        "doc_id": 78,
        "title": "Exploring the Role of Convolutional Neural Networks (CNN) in Dental Radiography Segmentation: A Comprehensive Systematic Literature Review",
        "authors": [
            "Walid Brahmi",
            "Imen Jdey",
            "Fadoua Drira"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "In the field of dentistry, there is a growing demand for increased precision in diagnostic tools, with a specific focus on advanced imaging techniques such as computed tomography, cone beam computed tomography, magnetic resonance imaging, ultrasound, and traditional intra-oral periapical X-rays. Deep learning has emerged as a pivotal tool in this context, enabling the implementation of automated segmentation techniques crucial for extracting essential diagnostic data. This integration of cutting-edge technology addresses the urgent need for effective management of dental conditions, which, if left undetected, can have a significant impact on human health. The impressive track record of deep learning across various domains, including dentistry, underscores its potential to revolutionize early detection and treatment of oral health issues. Objective: Having demonstrated significant results in diagnosis and prediction, deep convolutional neural networks (CNNs) represent an emerging field of multidisciplinary research. The goals of this study were to provide a concise overview of the state of the art, standardize the current debate, and establish baselines for future research. Method: In this study, a systematic literature review is employed as a methodology to identify and select relevant studies that specifically investigate the deep learning technique for dental imaging analysis. This study elucidates the methodological approach, including the systematic collection of data, statistical analysis, and subsequent dissemination of outcomes. Conclusion: This work demonstrates how Convolutional Neural Networks (CNNs) can be employed to analyze images, serving as effective tools for detecting dental pathologies. Although this research acknowledged some limitations, CNNs utilized for segmenting and categorizing teeth exhibited their highest level of performance overall.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09190"
    },
    {
        "doc_id": 79,
        "title": "A Two-Scale Complexity Measure for Deep Learning Models",
        "authors": [
            "Massimiliano Datres",
            "Gian Paolo Leonardi",
            "Alessio Figalli",
            "David Sutter"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We introduce a novel capacity measure 2sED for statistical models based on the effective dimension. The new quantity provably bounds the generalization error under mild assumptions on the model. Furthermore, simulations on standard data sets and popular model architectures show that 2sED correlates well with the training error. For Markovian models, we show how to efficiently approximate 2sED from below through a layerwise iterative approach, which allows us to tackle deep learning models with a large number of parameters. Simulation results suggest that the approximation is good for different prominent models and data sets.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09184"
    },
    {
        "doc_id": 80,
        "title": "Splitting the spacetime: A systematic analysis of foliation dependence in cosmic averaging",
        "authors": [
            "Pierre Mourier",
            "Asta Heinesen"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "It is a fundamental unsolved question in general relativity how to unambiguously characterize the effective collective dynamics of an ensemble of fluid elements sourcing the local geometry, in the absence of exact symmetries. In a cosmological context this is sometimes referred to as the averaging problem. At the heart of this problem in relativity is the non-uniqueness of the choice of foliation within which the statistical properties of the local spacetime are quantified, which can lead to ambiguity in the formulated average theory. This has led to debate in the literature on how to best construct and view such a coarse-grained hydrodynamic theory. Here, we address this ambiguity by performing the first quantitative investigation of foliation dependence in cosmological spatial averaging. Starting from the aim of constructing slicing-independent integral functionals (volume, mass, entropy, etc.) as well as average functionals (mean density, average curvature, etc.) defined on spatial volume sections, we investigate infinitesimal foliation variations and derive results on the foliation dependence of functionals and on extremal leaves. Our results show that one may only identify fully foliation-independent integral functionals in special scenarios, requiring the existence of associated conserved currents. We then derive bounds on the foliation dependence of integral functionals for general scalar quantities under finite variations within physically motivated classes of foliations. Our findings provide tools that are useful for quantifying, eliminating or constraining the foliation dependence in cosmological averaging.",
        "comments": "32 pages. Comments welcome",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09170"
    },
    {
        "doc_id": 81,
        "title": "Your blush gives you away: detecting hidden mental states with remote photoplethysmography and thermal imaging",
        "authors": [
            "Ivan Liu",
            "Fangyuan Liu",
            "Qi Zhong",
            "Fei Ma",
            "Shiguang Ni"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "Multimodal emotion recognition techniques are increasingly essential for assessing mental states. Image-based methods, however, tend to focus predominantly on overt visual cues and often overlook subtler mental state changes. Psychophysiological research has demonstrated that HR and skin temperature are effective in detecting ANS activities, thereby revealing these subtle changes. However, traditional HR tools are generally more costly and less portable, while skin temperature analysis usually necessitates extensive manual processing. Advances in remote-PPG and automatic thermal ROI detection algorithms have been developed to address these issues, yet their accuracy in practical applications remains limited. This study aims to bridge this gap by integrating r-PPG with thermal imaging to enhance prediction performance. Ninety participants completed a 20-minute questionnaire to induce cognitive stress, followed by watching a film aimed at eliciting moral elevation. The results demonstrate that the combination of r-PPG and thermal imaging effectively detects emotional shifts. Using r-PPG alone, the prediction accuracy was 77% for cognitive stress and 61% for moral elevation, as determined by SVM. Thermal imaging alone achieved 79% accuracy for cognitive stress and 78% for moral elevation, utilizing a RF algorithm. An early fusion strategy of these modalities significantly improved accuracies, achieving 87% for cognitive stress and 83% for moral elevation using RF. Further analysis, which utilized statistical metrics and explainable machine learning methods including SHAP, highlighted key features and clarified the relationship between cardiac responses and facial temperature variations. Notably, it was observed that cardiovascular features derived from r-PPG models had a more pronounced influence in data fusion, despite thermal imaging's higher predictive accuracy in unimodal analysis.",
        "comments": "28 pages, 6 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09145"
    },
    {
        "doc_id": 82,
        "title": "Monitoring Machine Learning Forecasts for Platform Data Streams",
        "authors": [
            "Jeroen Rombouts",
            "Ines Wilms"
        ],
        "subjects": [
            "Applications",
            "Machine Learning"
        ],
        "abstract": "Data stream forecasts are essential inputs for decision making at digital platforms. Machine learning algorithms are appealing candidates to produce such forecasts. Yet, digital platforms require a large-scale forecast framework that can flexibly respond to sudden performance drops. Re-training ML algorithms at the same speed as new data batches enter is usually computationally too costly. On the other hand, infrequent re-training requires specifying the re-training frequency and typically comes with a severe cost of forecast deterioration. To ensure accurate and stable forecasts, we propose a simple data-driven monitoring procedure to answer the question when the ML algorithm should be re-trained. Instead of investigating instability of the data streams, we test if the incoming streaming forecast loss batch differs from a well-defined reference batch. Using a novel dataset constituting 15-min frequency data streams from an on-demand logistics platform operating in London, we apply the monitoring procedure to popular ML algorithms including random forest, XGBoost and lasso. We show that monitor-based re-training produces accurate forecasts compared to viable benchmarks while preserving computational feasibility. Moreover, the choice of monitoring procedure is more important than the choice of ML algorithm, thereby permitting practitioners to combine the proposed monitoring procedure with one's favorite forecasting algorithm.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09144"
    },
    {
        "doc_id": 83,
        "title": "Understanding Heterophily for Graph Neural Networks",
        "authors": [
            "Junfu Wang",
            "Yuanfang Guo",
            "Liang Yang",
            "Yunhong Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Graphs with heterophily have been regarded as challenging scenarios for Graph Neural Networks (GNNs), where nodes are connected with dissimilar neighbors through various patterns. In this paper, we present theoretical understandings of the impacts of different heterophily patterns for GNNs by incorporating the graph convolution (GC) operations into fully connected networks via the proposed Heterophilous Stochastic Block Models (HSBM), a general random graph model that can accommodate diverse heterophily patterns. Firstly, we show that by applying a GC operation, the separability gains are determined by two factors, i.e., the Euclidean distance of the neighborhood distributions and $\\sqrt{\\mathbb{E}\\left[\\operatorname{deg}\\right]}$, where $\\mathbb{E}\\left[\\operatorname{deg}\\right]$ is the averaged node degree. It reveals that the impact of heterophily on classification needs to be evaluated alongside the averaged node degree. Secondly, we show that the topological noise has a detrimental impact on separability, which is equivalent to degrading $\\mathbb{E}\\left[\\operatorname{deg}\\right]$. Finally, when applying multiple GC operations, we show that the separability gains are determined by the normalized distance of the $l$-powered neighborhood distributions. It indicates that the nodes still possess separability as $l$ goes to infinity in a wide range of regimes. Extensive experiments on both synthetic and real-world data verify the effectiveness of our theory.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09125"
    },
    {
        "doc_id": 84,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 85,
        "title": "Fixed-Budget Differentially Private Best Arm Identification",
        "authors": [
            "Zhirui Chen",
            "P. N. Karthik",
            "Yeow Meng Chee",
            "Vincent Y. F. Tan"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Information Theory",
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "We study best arm identification (BAI) in linear bandits in the fixed-budget regime under differential privacy constraints, when the arm rewards are supported on the unit interval. Given a finite budget $T$ and a privacy parameter $\\varepsilon>0$, the goal is to minimise the error probability in finding the arm with the largest mean after $T$ sampling rounds, subject to the constraint that the policy of the decision maker satisfies a certain {\\em $\\varepsilon$-differential privacy} ($\\varepsilon$-DP) constraint. We construct a policy satisfying the $\\varepsilon$-DP constraint (called {\\sc DP-BAI}) by proposing the principle of {\\em maximum absolute determinants}, and derive an upper bound on its error probability. Furthermore, we derive a minimax lower bound on the error probability, and demonstrate that the lower and the upper bounds decay exponentially in $T$, with exponents in the two bounds matching order-wise in (a) the sub-optimality gaps of the arms, (b) $\\varepsilon$, and (c) the problem complexity that is expressible as the sum of two terms, one characterising the complexity of standard fixed-budget BAI (without privacy constraints), and the other accounting for the $\\varepsilon$-DP constraint. Additionally, we present some auxiliary results that contribute to the derivation of the lower bound on the error probability. These results, we posit, may be of independent interest and could prove instrumental in proving lower bounds on error probabilities in several other bandit problems. Whereas prior works provide results for BAI in the fixed-budget regime without privacy constraints or in the fixed-confidence regime with privacy constraints, our work fills the gap in the literature by providing the results for BAI in the fixed-budget regime under the $\\varepsilon$-DP constraint.",
        "comments": "Accepted to ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09073"
    },
    {
        "doc_id": 86,
        "title": "Accelerating HEP simulations with Neural Importance Sampling",
        "authors": [
            "Nicolas Deutschmann",
            "Niklas G\u00f6tz"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "High Energy Physics - Theory",
            "Computational Physics",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Virtually all high-energy-physics (HEP) simulations for the LHC rely on Monte Carlo using importance sampling by means of the VEGAS algorithm. However, complex high-precision calculations have become a challenge for the standard toolbox. As a result, there has been keen interest in HEP for modern machine learning to power adaptive sampling. Despite previous work proving that normalizing-flow-powered neural importance sampling (NIS) sometimes outperforms VEGAS, existing research has still left major questions open, which we intend to solve by introducing Z\u00fcNIS, a fully automated NIS library. We first show how to extend the original formulation of NIS to reuse samples over multiple gradient steps, yielding a significant improvement for slow functions. We then benchmark Z\u00fcNIS over a range of problems and show high performance with limited fine-tuning. The library can be used by non-experts with minimal effort, which is crucial to become a mature tool for the wider HEP public.",
        "comments": "28 pages, 11 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09069"
    },
    {
        "doc_id": 87,
        "title": "IRS-Enhanced Anti-Jamming Precoding Against DISCO Physical Layer Jamming Attacks",
        "authors": [
            "Huan Huang",
            "Hongliang Zhang",
            "Yi Cai",
            "Yunjing Zhang",
            "A. Lee Swindlehurst",
            "Zhu Han"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Illegitimate intelligent reflective surfaces (IRSs) can pose significant physical layer security risks on multi-user multiple-input single-output (MU-MISO) systems. Recently, a DISCO approach has been proposed an illegitimate IRS with random and time-varying reflection coefficients, referred to as a \"disco\" IRS (DIRS). Such DIRS can attack MU-MISO systems without relying on either jamming power or channel state information (CSI), and classical anti-jamming techniques are ineffective for the DIRS-based fully-passive jammers (DIRS-based FPJs). In this paper, we propose an IRS-enhanced anti-jamming precoder against DIRS-based FPJs that requires only statistical rather than instantaneous CSI of the DIRS-jammed channels. Specifically, a legitimate IRS is introduced to reduce the strength of the DIRS-based jamming relative to the transmit signals at a legitimate user (LU). In addition, the active beamforming at the legitimate access point (AP) is designed to maximize the signal-to-jamming-plus-noise ratios (SJNRs). Numerical results are presented to evaluate the effectiveness of the proposed IRS-enhanced anti-jamming precoder against DIRS-based FPJs.",
        "comments": "This paper has been accepted by IEEE ICC 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09036"
    },
    {
        "doc_id": 88,
        "title": "A Novel Interpretable Fusion Analytic Framework for Investigating Functional Brain Connectivity Differences in Cognitive Impairments",
        "authors": [
            "Yeseul Jeon",
            "Jeong-Jae Kim",
            "SuMin Yu",
            "Junggu Choi",
            "Sanghoon Han"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Functional magnetic resonance imaging (fMRI) data is characterized by its complexity and high--dimensionality, encompassing signals from various regions of interests (ROIs) that exhibit intricate correlations. Analyzing fMRI data directly proves challenging due to its intricate structure. Nevertheless, ROIs convey crucial information about brain activities through their connections, offering insights into distinctive brain activity characteristics between different groups. To address this, we propose a cutting-edge interpretable fusion analytic framework that facilitates the identification and understanding of ROI connectivity disparities between two groups, thereby revealing their unique features. Our novel approach encompasses three key steps. Firstly, we construct ROI functional connectivity networks (FCNs) to effectively manage fMRI data. Secondly, employing the FCNs, we utilize a self--attention deep learning model for binary classification, generating an attention distribution that encodes group differences. Lastly, we employ a latent space item-response model to extract group representative ROI features, visualizing these features on the group summary FCNs. We validate the effectiveness of our framework by analyzing four types of cognitive impairments, showcasing its capability to identify significant ROIs contributing to the differences between the two disease groups. This novel interpretable fusion analytic framework holds immense potential for advancing our understanding of cognitive impairments and could pave the way for more targeted therapeutic interventions.",
        "comments": "arXiv admin note: text overlap with arXiv:2207.01581",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09028"
    },
    {
        "doc_id": 89,
        "title": "Fast parallel sampling under isoperimetry",
        "authors": [
            "Nima Anari",
            "Sinho Chewi",
            "Thuy-Duong Vuong"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "We show how to sample in parallel from a distribution $\u03c0$ over $\\mathbb R^d$ that satisfies a log-Sobolev inequality and has a smooth log-density, by parallelizing the Langevin (resp. underdamped Langevin) algorithms. We show that our algorithm outputs samples from a distribution $\\hat\u03c0$ that is close to $\u03c0$ in Kullback--Leibler (KL) divergence (resp. total variation (TV) distance), while using only $\\log(d)^{O(1)}$ parallel rounds and $\\widetilde{O}(d)$ (resp. $\\widetilde O(\\sqrt d)$) gradient evaluations in total. This constitutes the first parallel sampling algorithms with TV distance guarantees.\n  For our main application, we show how to combine the TV distance guarantees of our algorithms with prior works and obtain RNC sampling-to-counting reductions for families of discrete distribution on the hypercube $\\{\\pm 1\\}^n$ that are closed under exponential tilts and have bounded covariance. Consequently, we obtain an RNC sampler for directed Eulerian tours and asymmetric determinantal point processes, resolving open questions raised in prior works.",
        "comments": "23 pages",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09016"
    },
    {
        "doc_id": 90,
        "title": "Estimation of Tsallis entropy for exponentially distributed several populations",
        "authors": [
            "Naveen Kumar",
            "Ambesh Dixit",
            "Vivek Vijay"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "We study the estimation of Tsallis entropy of a finite number of independent populations, each following an exponential distribution with the same scale parameter and distinct location parameters for $q>0$. We derive a Stein-type improved estimate, establishing the inadmissibility of the best affine equivariant estimate of the parameter function. A class of smooth estimates utilizing the Brewster technique is obtained, resulting in a significant improvement in the risk value. We computed the Brewster-Zidek estimates for both one and two populations, to illustrate the comparison with best affine equivariant and Stein-type estimates. We further derive that the Bayesian estimate, employing an inverse gamma prior, which takes the best affine equivariant estimate as a particular case. We provide a numerical illustration utilizing simulated samples for a single population. The purpose is to demonstrate the impact of sample size, location parameter, and entropic index on the estimates.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09009"
    },
    {
        "doc_id": 91,
        "title": "Enablers and Barriers of Empathy in Software Developer and User Interaction: A Mixed Methods Case Study",
        "authors": [
            "Hashini Gunatilake",
            "John Grundy",
            "Rashina Hoda",
            "Ingo Mueller"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Software engineering (SE) requires developers to collaborate with stakeholders, and understanding their emotions and perspectives is often vital. Empathy is a concept characterising a person's ability to understand and share the feelings of another. However, empathy continues to be an under-researched human aspect in SE. We studied how empathy is practised between developers and end users using a mixed methods case study. We used an empathy test, observations and interviews to collect data, and socio technical grounded theory and descriptive statistics to analyse data. We identified the nature of awareness required to trigger empathy and enablers of empathy. We discovered barriers to empathy and a set of potential strategies to overcome these barriers. We report insights on emerging relationships and present a set of recommendations and potential future works on empathy and SE for software practitioners and SE researchers.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09001"
    },
    {
        "doc_id": 92,
        "title": "Trade-off Between Dependence and Complexity for Nonparametric Learning -- an Empirical Process Approach",
        "authors": [
            "Nabarun Deb",
            "Debarghya Mukherjee"
        ],
        "subjects": [
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "Empirical process theory for i.i.d. observations has emerged as a ubiquitous tool for understanding the generalization properties of various statistical problems. However, in many applications where the data exhibit temporal dependencies (e.g., in finance, medical imaging, weather forecasting etc.), the corresponding empirical processes are much less understood. Motivated by this observation, we present a general bound on the expected supremum of empirical processes under standard $\u03b2/\u03c1$-mixing assumptions. Unlike most prior work, our results cover both the long and the short-range regimes of dependence. Our main result shows that a non-trivial trade-off between the complexity of the underlying function class and the dependence among the observations characterizes the learning rate in a large class of nonparametric problems. This trade-off reveals a new phenomenon, namely that even under long-range dependence, it is possible to attain the same rates as in the i.i.d. setting, provided the underlying function class is complex enough. We demonstrate the practical implications of our findings by analyzing various statistical estimators in both fixed and growing dimensions. Our main examples include a comprehensive case study of generalization error bounds in nonparametric regression over smoothness classes in fixed as well as growing dimension using neural nets, shape-restricted multivariate convex regression, estimating the optimal transport (Wasserstein) distance between two probability distributions, and classification under the Mammen-Tsybakov margin condition -- all under appropriate mixing assumptions. In the process, we also develop bounds on $L_r$ ($1\\le r\\le 2$)-localized empirical processes with dependent observations, which we then leverage to get faster rates for (a) tuning-free adaptation, and (b) set-structured learning problems.",
        "comments": "94 pages, 1 figure",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08978"
    },
    {
        "doc_id": 93,
        "title": "Nonparametric Mean and Variance Adaptive Classification Rule for High-Dimensional Data with Heteroscedastic Variances",
        "authors": [
            "Seungyeon Oh",
            "Hoyoung Park"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "In this study, we introduce an innovative methodology aimed at enhancing Fisher's Linear Discriminant Analysis (LDA) in the context of high-dimensional data classification scenarios, specifically addressing situations where each feature exhibits distinct variances. Our approach leverages Nonparametric Maximum Likelihood Estimation (NPMLE) techniques to estimate both the mean and variance parameters. By accommodating varying variances among features, our proposed method leads to notable improvements in classification performance. In particular, unlike numerous prior studies that assume the distribution of heterogeneous variances follows a right-skewed inverse gamma distribution, our proposed method demonstrates excellent performance even when the distribution of heterogeneous variances takes on left-skewed, symmetric, or right-skewed forms. We conducted a series of rigorous experiments to empirically validate the effectiveness of our approach. The results of these experiments demonstrate that our proposed methodology excels in accurately classifying high-dimensional data characterized by heterogeneous variances.",
        "comments": "25 pages and 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08975"
    },
    {
        "doc_id": 94,
        "title": "A Powerful and Precise Feature-level Filter using Group Knockoffs",
        "authors": [
            "Jiaqi Gu",
            "Zihuai He"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Selecting important features that have substantial effects on the response with provable type-I error rate control is a fundamental concern in statistics, with wide-ranging practical applications. Existing knockoff filters, although shown to provide theoretical guarantee on false discovery rate (FDR) control, often struggle to strike a balance between high power and precision in pinpointing important features when there exist large groups of strongly correlated features. To address this challenge, we develop a new filter using group knockoffs to achieve both powerful and precise selection of important features. Via experiments of simulated data and analysis of a real Alzheimer's disease genetic dataset, it is found that the proposed filter can not only control the proportion of false discoveries but also identify important features with comparable power and greater precision than the existing group knockoffs filter.",
        "comments": "34 pages, 5 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08941"
    },
    {
        "doc_id": 95,
        "title": "How do transportation professionals perceive the impacts of AI applications in transportation? A latent class cluster analysis",
        "authors": [
            "Yiheng Qian",
            "Tejaswi Polimetla",
            "Thomas W. Sanchez",
            "Xiang Yan"
        ],
        "subjects": [
            "Applications",
            "Computers and Society"
        ],
        "abstract": "Recent years have witnessed an increasing number of artificial intelligence (AI) applications in transportation. As a new and emerging technology, AI's potential to advance transportation goals and the full extent of its impacts on the transportation sector is not yet well understood. As the transportation community explores these topics, it is critical to understand how transportation professionals, the driving force behind AI Transportation applications, perceive AI's potential efficiency and equity impacts. Toward this goal, we surveyed transportation professionals in the United States and collected a total of 354 responses. Based on the survey responses, we conducted both descriptive analysis and latent class cluster analysis (LCCA). The former provides an overview of prevalent attitudes among transportation professionals, while the latter allows the identification of distinct segments based on their latent attitudes toward AI. We find widespread optimism regarding AI's potential to improve many aspects of transportation (e.g., efficiency, cost reduction, and traveler experience); however, responses are mixed regarding AI's potential to advance equity. Moreover, many respondents are concerned that AI ethics are not well understood in the transportation community and that AI use in transportation could exaggerate existing inequalities. Through LCCA, we have identified four latent segments: AI Neutral, AI Optimist, AI Pessimist, and AI Skeptic. The latent class membership is significantly associated with respondents' age, education level, and AI knowledge level. Overall, the study results shed light on the extent to which the transportation community as a whole is ready to leverage AI systems to transform current practices and inform targeted education to improve the understanding of AI among transportation professionals.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08915"
    },
    {
        "doc_id": 96,
        "title": "DCRMTA: Unbiased Causal Representation for Multi-touch Attribution",
        "authors": [
            "Jiaming Tang"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Methodology"
        ],
        "abstract": "Multi-touch attribution (MTA) currently plays a pivotal role in achieving a fair estimation of the contributions of each advertising touchpoint to-wards conversion behavior, deeply influencing budget allocation and advertising recommenda-tion. Traditional multi-touch attribution methods initially build a conversion prediction model, an-ticipating learning the inherent relationship be-tween touchpoint sequences and user purchasing behavior through historical data. Based on this, counterfactual touchpoint sequences are con-structed from the original sequence subset, and conversions are estimated using the prediction model, thus calculating advertising contributions. A covert assumption of these methods is the un-biased nature of conversion prediction models. However, due to confounding variables factors arising from user preferences and internet recom-mendation mechanisms such as homogenization of ad recommendations resulting from past shop-ping records, bias can easily occur in conversion prediction models trained on observational data. This paper redefines the causal effect of user fea-tures on conversions and proposes a novel end-to-end approach, Deep Causal Representation for MTA (DCRMTA). Our model while eliminating confounding variables, extracts features with causal relations to conversions from users. Fur-thermore, Extensive experiments on both synthet-ic and real-world Criteo data demonstrate DCRMTA's superior performance in converting prediction across varying data distributions, while also effectively attributing value across dif-ferent advertising channels",
        "comments": "9 pages, 7 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08875"
    },
    {
        "doc_id": 97,
        "title": "Benchmarking Particle Filter Algorithms for Efficient Velodyne-Based Vehicle Localization",
        "authors": [
            "Jose Luis Blanco-Claraco",
            "Francisco Ma\u00f1as-Alvarez",
            "Jose Luis Torres-Moreno",
            "Francisco Rodriguez",
            "Antonio Gimenez-Fernandez"
        ],
        "subjects": [
            "Robotics",
            "Applications"
        ],
        "abstract": "Keeping a vehicle well-localized within a prebuilt-map is at the core of any autonomous vehicle navigation system. In this work, we show that both standard SIR sampling and rejection-based optimal sampling are suitable for efficient (10 to 20 ms) real-time pose tracking without feature detection that is using raw point clouds from a 3D LiDAR. Motivated by the large amount of information captured by these sensors, we perform a systematic statistical analysis of how many points are actually required to reach an optimal ratio between efficiency and positioning accuracy. Furthermore, initialization from adverse conditions, e.g., poor GPS signal in urban canyons, we also identify the optimal particle filter settings required to ensure convergence. Our findings include that a decimation factor between 100 and 200 on incoming point clouds provides a large savings in computational cost with a negligible loss in localization accuracy for a VLP-16 scanner. Furthermore, an initial density of $\\sim$2 particles/m$^2$ is required to achieve 100% convergence success for large-scale ($\\sim$100,000 m$^2$), outdoor global localization without any additional hint from GPS or magnetic field sensors. All implementations have been released as open-source software.",
        "comments": "24 pages, 13 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08870"
    },
    {
        "doc_id": 98,
        "title": "The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images",
        "authors": [
            "Nicholas Konz",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing",
            "Machine Learning"
        ],
        "abstract": "This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic \"label sharpness\" ($K_F$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring the label sharpness of a training set: it is negatively correlated with the trained model's adversarial robustness, which notably leads to models for medical images having a substantially higher vulnerability to adversarial attack. Finally, we extend our $d_{data}$ formalism to the related metric of learned representation intrinsic dimension ($d_{repr}$), derive a generalization scaling law with respect to $d_{repr}$, and show that $d_{data}$ serves as an upper bound for $d_{repr}$. Our theoretical results are supported by thorough experiments with six models and eleven natural and medical imaging datasets over a range of training set sizes. Our findings offer insights into the influence of intrinsic dataset properties on generalization, representation learning, and robustness in deep neural networks.",
        "comments": "ICLR 2024. Code: https://github.com/mazurowski-lab/intrinsic-properties",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08865"
    },
    {
        "doc_id": 99,
        "title": "An Empirical Study of Counterfactual Visualization to Support Visual Causal Inference",
        "authors": [
            "Arran Zeyu Wang",
            "David Borland",
            "David Gotz"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "Counterfactuals -- expressing what might have been true under different circumstances -- have been widely applied in statistics and machine learning to help understand causal relationships. More recently, counterfactuals have begun to emerge as a technique being applied within visualization research. However, it remains unclear to what extent counterfactuals can aid with visual data communication. In this paper, we primarily focus on assessing the quality of users' understanding of data when provided with counterfactual visualizations. We propose a preliminary model of causality comprehension by connecting theories from causal inference and visual data communication. Leveraging this model, we conducted an empirical study to explore how counterfactuals can improve users' understanding of data in static visualizations. Our results indicate that visualizing counterfactuals had a positive impact on participants' interpretations of causal relations within datasets. These results motivate a discussion of how to more effectively incorporate counterfactuals into data visualizations.",
        "comments": "Accepted for publication in Information Visualization",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08822"
    },
    {
        "doc_id": 100,
        "title": "ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative Modeling of Human-Object Interactions",
        "authors": [
            "Jeonghwan Kim",
            "Jisoo Kim",
            "Jeonghyeon Na",
            "Hanbyul Joo"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "To enable machines to learn how humans interact with the physical world in our daily activities, it is crucial to provide rich data that encompasses the 3D motion of humans as well as the motion of objects in a learnable 3D representation. Ideally, this data should be collected in a natural setup, capturing the authentic dynamic 3D signals during human-object interactions. To address this challenge, we introduce the ParaHome system, designed to capture and parameterize dynamic 3D movements of humans and objects within a common home environment. Our system consists of a multi-view setup with 70 synchronized RGB cameras, as well as wearable motion capture devices equipped with an IMU-based body suit and hand motion capture gloves. By leveraging the ParaHome system, we collect a novel large-scale dataset of human-object interaction. Notably, our dataset offers key advancement over existing datasets in three main aspects: (1) capturing 3D body and dexterous hand manipulation motion alongside 3D object movement within a contextual home environment during natural activities; (2) encompassing human interaction with multiple objects in various episodic scenarios with corresponding descriptions in texts; (3) including articulated objects with multiple parts expressed with parameterized articulations. Building upon our dataset, we introduce new research tasks aimed at building a generative model for learning and synthesizing human-object interactions in a real-world room setting.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10232"
    },
    {
        "doc_id": 101,
        "title": "Simultaneous Tactile Estimation and Control for Extrinsic Dexterity",
        "authors": [
            "Antonia Bronars",
            "Sangwoon Kim",
            "Parag Patre",
            "Alberto Rodriguez"
        ],
        "subjects": [
            "Robotics"
        ],
        "abstract": "We introduce a novel approach that combines tactile estimation and control for in-hand object manipulation. By integrating measurements from robot kinematics and an image-based tactile sensor, our framework estimates and tracks object pose while simultaneously generating motion plans to control the pose of a grasped object. This approach consists of a discrete pose estimator that uses the Viterbi decoding algorithm to find the most likely sequence of object poses in a coarsely discretized grid, and a continuous pose estimator-controller to refine the pose estimate and accurately manipulate the pose of the grasped object. Our method is tested on diverse objects and configurations, achieving desired manipulation objectives and outperforming single-shot methods in estimation accuracy. The proposed approach holds potential for tasks requiring precise manipulation in scenarios where visual perception is limited, laying the foundation for closed-loop behavior applications such as assembly and tool use. Please see supplementary videos for real-world demonstration at https://sites.google.com/view/texterity.",
        "comments": "8 pages, 5 figures, submitted to ICRA 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10230"
    },
    {
        "doc_id": 102,
        "title": "OMG-Seg: Is One Model Good Enough For All Segmentation?",
        "authors": [
            "Xiangtai Li",
            "Haobo Yuan",
            "Wei Li",
            "Henghui Ding",
            "Size Wu",
            "Wenwei Zhang",
            "Yining Li",
            "Kai Chen",
            "Chen Change Loy"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In this work, we address various segmentation tasks, each traditionally tackled by distinct or partially unified models. We propose OMG-Seg, One Model that is Good enough to efficiently and effectively handle all the segmentation tasks, including image semantic, instance, and panoptic segmentation, as well as their video counterparts, open vocabulary settings, prompt-driven, interactive segmentation like SAM, and video object segmentation. To our knowledge, this is the first model to handle all these tasks in one model and achieve satisfactory performance. We show that OMG-Seg, a transformer-based encoder-decoder architecture with task-specific queries and outputs, can support over ten distinct segmentation tasks and yet significantly reduce computational and parameter overhead across various tasks and datasets. We rigorously evaluate the inter-task influences and correlations during co-training. Code and models are available at https://github.com/lxtGH/OMG-Seg.",
        "comments": "Project Page: https://lxtgh.github.io/project/omg_seg/",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10229"
    },
    {
        "doc_id": 103,
        "title": "RAP-SAM: Towards Real-Time All-Purpose Segment Anything",
        "authors": [
            "Shilin Xu",
            "Haobo Yuan",
            "Qingyu Shi",
            "Lu Qi",
            "Jingbo Wang",
            "Yibo Yang",
            "Yining Li",
            "Kai Chen",
            "Yunhai Tong",
            "Bernard Ghanem",
            "Xiangtai Li",
            "Ming-Hsuan Yang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Advanced by transformer architecture, vision foundation models (VFMs) achieve remarkable progress in performance and generalization ability. Segment Anything Model (SAM) is one remarkable model that can achieve generalized segmentation. However, most VFMs cannot run in realtime, which makes it difficult to transfer them into several products. On the other hand, current real-time segmentation mainly has one purpose, such as semantic segmentation on the driving scene. We argue that diverse outputs are needed for real applications. Thus, this work explores a new real-time segmentation setting, named all-purpose segmentation in real-time, to transfer VFMs in real-time deployment. It contains three different tasks, including interactive segmentation, panoptic segmentation, and video segmentation. We aim to use one model to achieve the above tasks in real-time. We first benchmark several strong baselines. Then, we present Real-Time All Purpose SAM (RAP-SAM). It contains an efficient encoder and an efficient decoupled decoder to perform prompt-driven decoding. Moreover, we further explore different training strategies and tuning methods to boost co-training performance further. Our code and model are available at https://github.com/xushilin1/RAP-SAM/.",
        "comments": "Project Page: https://xushilin1.github.io/rap_sam/",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10228"
    },
    {
        "doc_id": 104,
        "title": "A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask Inpainting",
        "authors": [
            "Wouter Van Gansbeke",
            "Bert De Brabandere"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Panoptic and instance segmentation networks are often trained with specialized object detection modules, complex loss functions, and ad-hoc post-processing steps to handle the permutation-invariance of the instance masks. This work builds upon Stable Diffusion and proposes a latent diffusion approach for panoptic segmentation, resulting in a simple architecture which omits these complexities. Our training process consists of two steps: (1) training a shallow autoencoder to project the segmentation masks to latent space; (2) training a diffusion model to allow image-conditioned sampling in latent space. The use of a generative model unlocks the exploration of mask completion or inpainting, which has applications in interactive segmentation. The experimental validation yields promising results for both panoptic segmentation and mask inpainting. While not setting a new state-of-the-art, our model's simplicity, generality, and mask completion capability are desirable properties.",
        "comments": "Code: https://github.com/segments-ai/latent-diffusion-segmentation",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10227"
    },
    {
        "doc_id": 105,
        "title": "Towards Language-Driven Video Inpainting via Multimodal Large Language Models",
        "authors": [
            "Jianzong Wu",
            "Xiangtai Li",
            "Chenyang Si",
            "Shangchen Zhou",
            "Jingkang Yang",
            "Jiangning Zhang",
            "Yining Li",
            "Kai Chen",
            "Yunhai Tong",
            "Ziwei Liu",
            "Chen Change Loy"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We introduce a new task -- language-driven video inpainting, which uses natural language instructions to guide the inpainting process. This approach overcomes the limitations of traditional video inpainting methods that depend on manually labeled binary masks, a process often tedious and labor-intensive. We present the Remove Objects from Videos by Instructions (ROVI) dataset, containing 5,650 videos and 9,091 inpainting results, to support training and evaluation for this task. We also propose a novel diffusion-based language-driven video inpainting framework, the first end-to-end baseline for this task, integrating Multimodal Large Language Models to understand and execute complex language-based inpainting requests effectively. Our comprehensive results showcase the dataset's versatility and the model's effectiveness in various language-instructed inpainting scenarios. We will make datasets, code, and models publicly available.",
        "comments": "Project Page: https://jianzongwu.github.io/projects/rovi",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10226"
    },
    {
        "doc_id": 106,
        "title": "ChatQA: Building GPT-4 Level Conversational QA Models",
        "authors": [
            "Zihan Liu",
            "Wei Ping",
            "Rajarshi Roy",
            "Peng Xu",
            "Mohammad Shoeybi",
            "Bryan Catanzaro"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Information Retrieval",
            "Machine Learning"
        ],
        "abstract": "In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10225"
    },
    {
        "doc_id": 107,
        "title": "The Manga Whisperer: Automatically Generating Transcriptions for Comics",
        "authors": [
            "Ragav Sachdeva",
            "Andrew Zisserman"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In the past few decades, Japanese comics, commonly referred to as Manga, have transcended both cultural and linguistic boundaries to become a true worldwide sensation. Yet, the inherent reliance on visual cues and illustration within manga renders it largely inaccessible to individuals with visual impairments. In this work, we seek to address this substantial barrier, with the aim of ensuring that manga can be appreciated and actively engaged by everyone. Specifically, we tackle the problem of diarisation i.e. generating a transcription of who said what and when, in a fully automatic way.\n  To this end, we make the following contributions: (1) we present a unified model, Magi, that is able to (a) detect panels, text boxes and character boxes, (b) cluster characters by identity (without knowing the number of clusters apriori), and (c) associate dialogues to their speakers; (2) we propose a novel approach that is able to sort the detected text boxes in their reading order and generate a dialogue transcript; (3) we annotate an evaluation benchmark for this task using publicly available [English] manga pages. The code, evaluation datasets and the pre-trained model can be found at: https://github.com/ragavsachdeva/magi.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10224"
    },
    {
        "doc_id": 108,
        "title": "Supervised Fine-tuning in turn Improves Visual Foundation Models",
        "authors": [
            "Xiaohu Jiang",
            "Yixiao Ge",
            "Yuying Ge",
            "Chun Yuan",
            "Ying Shan"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Image-text training like CLIP has dominated the pretraining of vision foundation models in recent years. Subsequent efforts have been made to introduce region-level visual learning into CLIP's pretraining but face scalability challenges due to the lack of large-scale region-level datasets. Drawing inspiration from supervised fine-tuning (SFT) in natural language processing such as instruction tuning, we explore the potential of fine-grained SFT in enhancing the generation of vision foundation models after their pretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash the fine-grained knowledge of vision foundation models. In ViSFT, the vision foundation model is enhanced by performing visual joint learning on some in-domain tasks and then tested on out-of-domain benchmarks. With updating using ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over 4.4B parameters shows improvements across various out-of-domain benchmarks including vision and vision-linguistic scenarios.",
        "comments": "14 pages, 3 figures, Project page: https://github.com/TencentARC/ViSFT/tree/main",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10222"
    },
    {
        "doc_id": 109,
        "title": "AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data",
        "authors": [
            "Caroline Choi",
            "Yoonho Lee",
            "Annie Chen",
            "Allan Zhou",
            "Aditi Raghunathan",
            "Chelsea Finn"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Foundation models encode rich representations that can be adapted to a desired task by fine-tuning on task-specific data. However, fine-tuning a model on one particular data distribution often compromises the model's original performance on other distributions. Current methods for robust fine-tuning utilize hand-crafted regularization techniques to constrain the fine-tuning process towards the base foundation model. Yet, it is hard to precisely specify what characteristics of the foundation model to retain during fine-tuning, as this depends on how the pre-training, fine-tuning, and evaluation data distributions relate to each other. We propose AutoFT, a data-driven approach for guiding foundation model fine-tuning. AutoFT optimizes fine-tuning hyperparameters to maximize performance on a small out-of-distribution (OOD) validation set. To guide fine-tuning in a granular way, AutoFT searches a highly expressive hyperparameter space that includes weight coefficients for many different losses, in addition to learning rate and weight decay values. We evaluate AutoFT on nine natural distribution shifts which include domain shifts and subpopulation shifts. Our experiments show that AutoFT significantly improves generalization to new OOD data, outperforming existing robust fine-tuning methods. Notably, AutoFT achieves new state-of-the-art performance on the WILDS-iWildCam and WILDS-FMoW benchmarks, outperforming the previous best methods by $6.0\\%$ and $1.5\\%$, respectively.",
        "comments": "16 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10220"
    },
    {
        "doc_id": 110,
        "title": "Edit One for All: Interactive Batch Image Editing",
        "authors": [
            "Thao Nguyen",
            "Utkarsh Ojha",
            "Yuheng Li",
            "Haotian Liu",
            "Yong Jae Lee"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In recent years, image editing has advanced remarkably. With increased human control, it is now possible to edit an image in a plethora of ways; from specifying in text what we want to change, to straight up dragging the contents of the image in an interactive point-based manner. However, most of the focus has remained on editing single images at a time. Whether and how we can simultaneously edit large batches of images has remained understudied. With the goal of minimizing human supervision in the editing process, this paper presents a novel method for interactive batch image editing using StyleGAN as the medium. Given an edit specified by users in an example image (e.g., make the face frontal), our method can automatically transfer that edit to other test images, so that regardless of their initial state (pose), they all arrive at the same final state (e.g., all facing front). Extensive experiments demonstrate that edits performed using our method have similar visual quality to existing single-image-editing methods, while having more visual consistency and saving significant time and human effort.",
        "comments": "Project page: https://thaoshibe.github.io/edit-one-for-all/",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10219"
    },
    {
        "doc_id": 111,
        "title": "An inversely designed mode-multiplexed photonic integrated vector dot-product core",
        "authors": [
            "Zheyuan Zhu",
            "Raktim Sarma",
            "Seth Smith-Dryden",
            "Guifang Li",
            "Shuo Pang"
        ],
        "subjects": [
            "Optics",
            "Signal Processing"
        ],
        "abstract": "Photonic computing has the potential of harnessing the full degrees of freedom (DOFs) of the light field, including wavelength, spatial mode, spatial location, phase quadrature, and polarization, to achieve higher level of computation parallelization and scalability than digital electronic processors. While multiplexing using wavelength and other DOFs can be readily integrated on silicon photonics platforms with compact footprints, conventional mode-division multiplexed (MDM) photonic designs occupy areas exceeding tens to hundreds of microns for a few spatial modes, significantly limiting their scalability. Here we utilize inverse design to demonstrate an ultracompact photonic computing core that calculates vector dot-products based on MDM coherent mixing within a nominal footprint of 5 um x 3 um. Our dot-product core integrates the functionalities of 2 mode multiplexers and 1 multi-mode coherent mixers, all within the footprint, and could be applied to various computation and computer vision tasks, with high computing throughput density. We experimentally demonstrate computing examples on the fabricated core, including complex number multiplication and motion estimation using optical flow.",
        "comments": "17 pages, 8 figures. Initial submission to ACS Nano Letters",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10218"
    },
    {
        "doc_id": 112,
        "title": "Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions",
        "authors": [
            "Namitha Padmanabhan",
            "Matthew Gwilliam",
            "Pulkit Kumar",
            "Shishira R Maiya",
            "Max Ehrlich",
            "Abhinav Shrivastava"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The many variations of Implicit Neural Representations (INRs), where a neural network is trained as a continuous representation of a signal, have tremendous practical utility for downstream tasks including novel view synthesis, video compression, and image superresolution. Unfortunately, the inner workings of these networks are seriously under-studied. Our work, eXplaining the Implicit Neural Canvas (XINC), is a unified framework for explaining properties of INRs by examining the strength of each neuron's contribution to each output pixel. We call the aggregate of these contribution maps the Implicit Neural Canvas and we use this concept to demonstrate that the INRs which we study learn to ''see'' the frames they represent in surprising ways. For example, INRs tend to have highly distributed representations. While lacking high-level object semantics, they have a significant bias for color and edges, and are almost entirely space-agnostic. We arrive at our conclusions by examining how objects are represented across time in video INRs, using clustering to visualize similar neurons across layers and architectures, and show that this is dominated by motion. These insights demonstrate the general usefulness of our analysis framework. Our project page is available at https://namithap10.github.io/xinc.",
        "comments": "Project site: https://namithap10.github.io/xinc",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10217"
    },
    {
        "doc_id": 113,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 114,
        "title": "GPAvatar: Generalizable and Precise Head Avatar from Image(s)",
        "authors": [
            "Xuangeng Chu",
            "Yu Li",
            "Ailing Zeng",
            "Tianyu Yang",
            "Lijian Lin",
            "Yunfei Liu",
            "Tatsuya Harada"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Head avatar reconstruction, crucial for applications in virtual reality, online meetings, gaming, and film industries, has garnered substantial attention within the computer vision community. The fundamental objective of this field is to faithfully recreate the head avatar and precisely control expressions and postures. Existing methods, categorized into 2D-based warping, mesh-based, and neural rendering approaches, present challenges in maintaining multi-view consistency, incorporating non-facial information, and generalizing to new identities. In this paper, we propose a framework named GPAvatar that reconstructs 3D head avatars from one or several images in a single forward pass. The key idea of this work is to introduce a dynamic point-based expression field driven by a point cloud to precisely and effectively capture expressions. Furthermore, we use a Multi Tri-planes Attention (MTA) fusion module in the tri-planes canonical field to leverage information from multiple input images. The proposed method achieves faithful identity reconstruction, precise expression control, and multi-view consistency, demonstrating promising results for free-viewpoint rendering and novel view synthesis.",
        "comments": "ICLR 2024, code is available at https://github.com/xg-chu/GPAvatar",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10215"
    },
    {
        "doc_id": 115,
        "title": "Tailoring Semantic Communication at Network Edge: A Novel Approach Using Dynamic Knowledge Distillation",
        "authors": [
            "Abdullatif Albaseer",
            "Mohamed Abdallah"
        ],
        "subjects": [
            "Networking and Internet Architecture"
        ],
        "abstract": "Semantic Communication (SemCom) systems, empowered by deep learning (DL), represent a paradigm shift in data transmission. These systems prioritize the significance of content over sheer data volume. However, existing SemCom designs face challenges when applied to diverse computational capabilities and network conditions, particularly in time-sensitive applications. A key challenge is the assumption that diverse devices can uniformly benefit from a standard, large DL model in SemCom systems. This assumption becomes increasingly impractical, especially in high-speed, high-reliability applications such as industrial automation or critical healthcare. Therefore, this paper introduces a novel SemCom framework tailored for heterogeneous, resource-constrained edge devices and computation-intensive servers. Our approach employs dynamic knowledge distillation (KD) to customize semantic models for each device, balancing computational and communication constraints while ensuring Quality of Service (QoS). We formulate an optimization problem and develop an adaptive algorithm that iteratively refines semantic knowledge on edge devices, resulting in better models tailored to their resource profiles. This algorithm strategically adjusts the granularity of distilled knowledge, enabling devices to maintain high semantic accuracy for precise inference tasks, even under unstable network conditions. Extensive simulations demonstrate that our approach significantly reduces model complexity for edge devices, leading to better semantic extraction and achieving the desired QoS.",
        "comments": "Accepted for the International Conference on Communications (ICC) 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10214"
    },
    {
        "doc_id": 116,
        "title": "Improving automatic detection of driver fatigue and distraction using machine learning",
        "authors": [
            "Dongjiang Wu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Changes and advances in information technology have played an important role in the development of intelligent vehicle systems in recent years. Driver fatigue and distracted driving are important factors in traffic accidents. Thus, onboard monitoring of driving behavior has become a crucial component of advanced driver assistance systems for intelligent vehicles. In this article, we present techniques for simultaneously detecting fatigue and distracted driving behaviors using vision-based and machine learning-based approaches. In driving fatigue detection, we use facial alignment networks to identify facial feature points in the images, and calculate the distance of the facial feature points to detect the opening and closing of the eyes and mouth. Furthermore, we use a convolutional neural network (CNN) based on the MobileNet architecture to identify various distracted driving behaviors. Experiments are performed on a PC based setup with a webcam and results are demonstrated using public datasets as well as custom datasets created for training and testing. Compared to previous approaches, we build our own datasets and provide better results in terms of accuracy and computation time.",
        "comments": "Master's thesis, 55 pages",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10213"
    },
    {
        "doc_id": 117,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 118,
        "title": "Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction",
        "authors": [
            "Anup Shakya",
            "Vasile Rus",
            "Deepak Venugopal"
        ],
        "subjects": [
            "Computers and Society",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Predicting the strategy (sequence of concepts) that a student is likely to use in problem-solving helps Adaptive Instructional Systems (AISs) better adapt themselves to different types of learners based on their learning abilities. This can lead to a more dynamic, engaging, and personalized experience for students. To scale up training a prediction model (such as LSTMs) over large-scale education datasets, we develop a non-parametric approach to cluster symmetric instances in the data. Specifically, we learn a representation based on Node2Vec that encodes symmetries over mastery or skill level since, to solve a problem, it is natural that a student's strategy is likely to involve concepts in which they have gained mastery. Using this representation, we use DP-Means to group symmetric instances through a coarse-to-fine refinement of the clusters. We apply our model to learn strategies for Math learning from large-scale datasets from MATHia, a leading AIS for middle-school math learning. Our results illustrate that our approach can consistently achieve high accuracy using a small sample that is representative of the full dataset. Further, we show that this approach helps us learn strategies with high accuracy for students at different skill levels, i.e., leveraging symmetries improves fairness in the prediction model.",
        "comments": "Proceedings of 37th AAAI Conference on Artificial Intelligence Artificial Intelligence for Education. arXiv admin note: substantial text overlap with arXiv:2308.03892",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10210"
    },
    {
        "doc_id": 119,
        "title": "MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer",
        "authors": [
            "Changyao Tian",
            "Xizhou Zhu",
            "Yuwen Xiong",
            "Weiyun Wang",
            "Zhe Chen",
            "Wenhai Wang",
            "Yuntao Chen",
            "Lewei Lu",
            "Tong Lu",
            "Jie Zhou",
            "Hongsheng Li",
            "Yu Qiao",
            "Jifeng Dai"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ],
        "abstract": "Developing generative models for interleaved image-text data has both research and practical value. It requires models to understand the interleaved sequences and subsequently generate images and text. However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios. To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data. It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process. MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora. It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions. Experiments demonstrate the versatility of MM-Interleaved in recognizing visual details following multi-modal instructions and generating consistent images following both textual and visual conditions. Code and models are available at \\url{https://github.com/OpenGVLab/MM-Interleaved}.",
        "comments": "20 pages, 9 figures, 17 tables",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10208"
    },
    {
        "doc_id": 120,
        "title": "Eclectic Rule Extraction for Explainability of Deep Neural Network based Intrusion Detection Systems",
        "authors": [
            "Jesse Ables",
            "Nathaniel Childers",
            "William Anderson",
            "Sudip Mittal",
            "Shahram Rahimi",
            "Ioana Banicescu",
            "Maria Seale"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "This paper addresses trust issues created from the ubiquity of black box algorithms and surrogate explainers in Explainable Intrusion Detection Systems (X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance transparency, black box surrogate explainers, such as Local Interpretable Model-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are difficult to trust. The black box nature of these surrogate explainers makes the process behind explanation generation opaque and difficult to understand. To avoid this problem, one can use transparent white box algorithms such as Rule Extraction (RE). There are three types of RE algorithms: pedagogical, decompositional, and eclectic. Pedagogical methods offer fast but untrustworthy white-box explanations, while decompositional RE provides trustworthy explanations with poor scalability. This work explores eclectic rule extraction, which strikes a balance between scalability and trustworthiness. By combining techniques from pedagogical and decompositional approaches, eclectic rule extraction leverages the advantages of both, while mitigating some of their drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as a white box surrogate explainer for black box Deep Neural Networks (DNN). The presented eclectic RE algorithm extracts human-readable rules from hidden layers, facilitating explainable and trustworthy rulesets. Evaluations on UNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to generate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions of this work include the hybrid X-IDS architecture, the eclectic rule extraction algorithm applicable to intrusion detection datasets, and a thorough analysis of performance and explainability, demonstrating the trade-offs involved in rule extraction speed and accuracy.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10207"
    },
    {
        "doc_id": 121,
        "title": "Effective Communication of Scientific Results",
        "authors": [
            "Jos\u00e9 Nelson Amaral"
        ],
        "subjects": [
            "Digital Libraries"
        ],
        "abstract": "Communication is essential for the advancement of Science. Technology advances and the proliferation of personal devices have changed the ways in which people communicate in all aspects of life. Scientific communication has also been profoundly affected by such changes, and thus it is important to reflect on effective ways to communicate scientific results to scientists that are flooded with information. This article advocates for receiver-oriented communication in Science, discusses how effective oral presentations should be prepared and delivered, provides advice on the thought process that can lead to scientific papers that communicate effectively, discusses suitable methodology to produce experimental data that is relevant and offers advice on how to present such data in ways that lead to the formulation of correct claims that are supported by the data.",
        "comments": "14 pages manuscript",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10205"
    },
    {
        "doc_id": 122,
        "title": "Maximal-Capacity Discrete Memoryless Channel Identification",
        "authors": [
            "Maximilian Egger",
            "Rawad Bitar",
            "Antonia Wachter-Zeh",
            "Deniz G\u00fcnd\u00fcz",
            "Nir Weinberger"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning"
        ],
        "abstract": "The problem of identifying the channel with the highest capacity among several discrete memoryless channels (DMCs) is considered. The problem is cast as a pure-exploration multi-armed bandit problem, which follows the practical use of training sequences to sense the communication channel statistics. A capacity estimator is proposed and tight confidence bounds on the estimator error are derived. Based on this capacity estimator, a gap-elimination algorithm termed BestChanID is proposed, which is oblivious to the capacity-achieving input distribution and is guaranteed to output the DMC with the largest capacity, with a desired confidence. Furthermore, two additional algorithms NaiveChanSel and MedianChanEl, that output with certain confidence a DMC with capacity close to the maximal, are introduced. Each of those algorithms is beneficial in a different regime and can be used as a subroutine in BestChanID. The sample complexity of all algorithms is analyzed as a function of the desired confidence parameter, the number of channels, and the channels' input and output alphabet sizes. The cost of best channel identification is shown to scale quadratically with the alphabet size, and a fundamental lower bound for the required number of channel senses to identify the best channel with a certain confidence is derived.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10204"
    },
    {
        "doc_id": 123,
        "title": "Quantum State Obfuscation from Classical Oracles",
        "authors": [
            "James Bartusek",
            "Zvika Brakerski",
            "Vinod Vaikuntanathan"
        ],
        "subjects": [
            "Quantum Physics",
            "Cryptography and Security"
        ],
        "abstract": "A major unresolved question in quantum cryptography is whether it is possible to obfuscate arbitrary quantum computation. Indeed, there is much yet to understand about the feasibility of quantum obfuscation even in the classical oracle model, where one is given for free the ability to obfuscate any classical circuit.\n  In this work, we develop a new array of techniques that we use to construct a quantum state obfuscator, a powerful notion formalized recently by Coladangelo and Gunn (arXiv:2311.07794) in their pursuit of better software copy-protection schemes. Quantum state obfuscation refers to the task of compiling a quantum program, consisting of a quantum circuit $C$ with a classical description and an auxiliary quantum state $\\ket\u03c8$, into a functionally-equivalent obfuscated quantum program that hides as much as possible about $C$ and $\\ket\u03c8$. We prove the security of our obfuscator when applied to any pseudo-deterministic quantum program, i.e. one that computes a (nearly) deterministic classical input / classical output functionality. Our security proof is with respect to an efficient classical oracle, which may be heuristically instantiated using quantum-secure indistinguishability obfuscation for classical circuits.\n  Our result improves upon the recent work of Bartusek, Kitagawa, Nishimaki and Yamakawa (STOC 2023) who also showed how to obfuscate pseudo-deterministic quantum circuits in the classical oracle model, but only ones with a completely classical description. Furthermore, our result answers a question of Coladangelo and Gunn, who provide a construction of quantum state indistinguishability obfuscation with respect to a quantum oracle. Indeed, our quantum state obfuscator together with Coladangelo-Gunn gives the first candidate realization of a ``best-possible'' copy-protection scheme for all polynomial-time functionalities.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10200"
    },
    {
        "doc_id": 124,
        "title": "Divide and not forget: Ensemble of selectively trained experts in Continual Learning",
        "authors": [
            "Grzegorz Rype\u015b\u0107",
            "Sebastian Cygert",
            "Valeriya Khan",
            "Tomasz Trzci\u0144ski",
            "Bartosz Zieli\u0144ski",
            "Bart\u0142omiej Twardowski"
        ],
        "subjects": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Class-incremental learning is becoming more popular as it helps models widen their applicability while not forgetting what they already know. A trend in this area is to use a mixture-of-expert technique, where different models work together to solve the task. However, the experts are usually trained all at once using whole task data, which makes them all prone to forgetting and increasing computational burden. To address this limitation, we introduce a novel approach named SEED. SEED selects only one, the most optimal expert for a considered task, and uses data from this task to fine-tune only this expert. For this purpose, each expert represents each class with a Gaussian distribution, and the optimal expert is selected based on the similarity of those distributions. Consequently, SEED increases diversity and heterogeneity within the experts while maintaining the high stability of this ensemble method. The extensive experiments demonstrate that SEED achieves state-of-the-art performance in exemplar-free settings across various scenarios, showing the potential of expert diversification through data in continual learning.",
        "comments": "Accepted to ICLR2024 (main track), code is available at: https://github.com/grypesc/SEED",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10191"
    },
    {
        "doc_id": 125,
        "title": "A Kaczmarz-inspired approach to accelerate the optimization of neural network wavefunctions",
        "authors": [
            "Gil Goldshlager",
            "Nilin Abrahamsen",
            "Lin Lin"
        ],
        "subjects": [
            "Computational Physics",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "Neural network wavefunctions optimized using the variational Monte Carlo method have been shown to produce highly accurate results for the electronic structure of atoms and small molecules, but the high cost of optimizing such wavefunctions prevents their application to larger systems. We propose the Subsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to reduce this bottleneck. SPRING combines ideas from the recently introduced minimum-step stochastic reconfiguration optimizer (MinSR) and the classical randomized Kaczmarz method for solving linear least-squares problems. We demonstrate that SPRING outperforms both MinSR and the popular Kronecker-Factored Approximate Curvature method (KFAC) across a number of small atoms and molecules, given that the learning rates of all methods are optimally tuned. For example, on the oxygen atom, SPRING attains chemical accuracy after forty thousand training iterations, whereas both MinSR and KFAC fail to do so even after one hundred thousand iterations.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10190"
    },
    {
        "doc_id": 126,
        "title": "Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction",
        "authors": [
            "Qingyun Wang",
            "Zixuan Zhang",
            "Hongxiang Li",
            "Xuan Liu",
            "Jiawei Han",
            "Heng Ji",
            "Huimin Zhao"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction process. Finally, we release ChemNER+, a new fine-grained chemical entity extraction dataset that is annotated by domain experts with the ChemNER schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets show that our newly proposed framework has contributed up to 8.26% and 6.84% absolute F1-score gains respectively.",
        "comments": "16 pages. Accepted by Findings of the Association for Computational Linguistics: EACL 2024. Code and resources are available at https://github.com/EagleW/Chem-FINESE",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10189"
    },
    {
        "doc_id": 127,
        "title": "Fast Kronecker Matrix-Matrix Multiplication on GPUs",
        "authors": [
            "Abhinav Jangda",
            "Mohit Yadav"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Kronecker Matrix-Matrix Multiplication (Kron-Matmul) is the multiplication of a matrix with the Kronecker Product of several smaller matrices. Kron-Matmul is a core operation for many scientific and machine learning computations. State-of-the-art Kron-Matmul implementations utilize existing tensor algebra operations, such as matrix multiplication, transpose, and tensor matrix multiplication. However, this design choice prevents several Kron-Matmul specific optimizations, thus, leaving significant performance on the table. To address this issue, we present FastKron, an efficient technique for Kron-Matmul on single and multiple GPUs. FastKron is independent of linear algebra operations enabling several new optimizations for Kron-Matmul. Thus, it performs up to 40.7x and 7.85x faster than existing implementations on 1 and 16 GPUs respectively.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10187"
    },
    {
        "doc_id": 128,
        "title": "Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation",
        "authors": [
            "Zden\u011bk Kasner",
            "Ond\u0159ej Du\u0161ek"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data. To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs. We leverage reference-free evaluation metrics and LLMs' in-context learning capabilities, allowing us to test the models with no human-written references. Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4. Our systematic examination of the models' behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings. However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs of open LLMs contain a semantic error according to human annotators (91% according to GPT-4). Our code, data, and model outputs are available at https://d2t-llm.github.io.",
        "comments": "26 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10186"
    },
    {
        "doc_id": 129,
        "title": "Transfer Learning in Human Activity Recognition: A Survey",
        "authors": [
            "Sourish Gunesh Dhekane",
            "Thomas Ploetz"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Sensor-based human activity recognition (HAR) has been an active research area, owing to its applications in smart environments, assisted living, fitness, healthcare, etc. Recently, deep learning based end-to-end training has resulted in state-of-the-art performance in domains such as computer vision and natural language, where large amounts of annotated data are available. However, large quantities of annotated data are not available for sensor-based HAR. Moreover, the real-world settings on which the HAR is performed differ in terms of sensor modalities, classification tasks, and target users. To address this problem, transfer learning has been employed extensively. In this survey, we focus on these transfer learning methods in the application domains of smart home and wearables-based HAR. In particular, we provide a problem-solution perspective by categorizing and presenting the works in terms of their contributions and the challenges they address. We also present an updated view of the state-of-the-art for both application domains. Based on our analysis of 205 papers, we highlight the gaps in the literature and provide a roadmap for addressing them. This survey provides a reference to the HAR community, by summarizing the existing works and providing a promising research agenda.",
        "comments": "40 pages, 5 figures, 7 tables",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10185"
    },
    {
        "doc_id": 130,
        "title": "Comparing Traditional and LLM-based Search for Image Geolocation",
        "authors": [
            "Albatool Wazzan",
            "Stephen MacNeil",
            "Richard Souvenir"
        ],
        "subjects": [
            "Information Retrieval",
            "Human-Computer Interaction"
        ],
        "abstract": "Web search engines have long served as indispensable tools for information retrieval; user behavior and query formulation strategies have been well studied. The introduction of search engines powered by large language models (LLMs) suggested more conversational search and new types of query strategies. In this paper, we compare traditional and LLM-based search for the task of image geolocation, i.e., determining the location where an image was captured. Our work examines user interactions, with a particular focus on query formulation strategies. In our study, 60 participants were assigned either traditional or LLM-based search engines as assistants for geolocation. Participants using traditional search more accurately predicted the location of the image compared to those using the LLM-based search. Distinct strategies emerged between users depending on the type of assistant. Participants using the LLM-based search issued longer, more natural language queries, but had shorter search sessions. When reformulating their search queries, traditional search participants tended to add more terms to their initial queries, whereas participants using the LLM-based search consistently rephrased their initial queries.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10184"
    },
    {
        "doc_id": 131,
        "title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological Receptive Fields",
        "authors": [
            "Zahra Babaiee",
            "Peyman M. Kiasari",
            "Daniela Rus",
            "Radu Grosu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "In this study, we present evidence suggesting that depthwise convolutional kernels are effectively replicating the structural intricacies of the biological receptive fields observed in the mammalian retina. We provide analytics of trained kernels from various state-of-the-art models substantiating this evidence. Inspired by this intriguing discovery, we propose an initialization scheme that draws inspiration from the biological receptive fields. Experimental analysis of the ImageNet dataset with multiple CNN architectures featuring depthwise convolutions reveals a marked enhancement in the accuracy of the learned model when initialized with biologically derived weights. This underlies the potential for biologically inspired computational models to further our understanding of vision processing systems and to improve the efficacy of convolutional networks.",
        "comments": "Journal ref:        Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (2024) 8216-8225",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10178"
    },
    {
        "doc_id": 132,
        "title": "Comprehensive OOD Detection Improvements",
        "authors": [
            "Anish Lakkapragada",
            "Amol Khanna",
            "Edward Raff",
            "Nathan Inkawhich"
        ],
        "subjects": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "As machine learning becomes increasingly prevalent in impactful decisions, recognizing when inference data is outside the model's expected input distribution is paramount for giving context to predictions. Out-of-distribution (OOD) detection methods have been created for this task. Such methods can be split into representation-based or logit-based methods from whether they respectively utilize the model's embeddings or predictions for OOD detection. In contrast to most papers which solely focus on one such group, we address both. We employ dimensionality reduction on feature embeddings in representation-based methods for both time speedups and improved performance. Additionally, we propose DICE-COL, a modification of the popular logit-based method Directed Sparsification (DICE) that resolves an unnoticed flaw. We demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark framework, where they significantly improve performance and set state-of-the-art results.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10176"
    },
    {
        "doc_id": 133,
        "title": "DualTake: Predicting Takeovers across Mobilities for Future Personalized Mobility Services",
        "authors": [
            "Zhaobo Zheng",
            "Kumar Akash",
            "Teruhisa Misu"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "A hybrid society is expected to emerge in the near future, with different mobilities interacting together, including cars, micro-mobilities, pedestrians, and robots. People may utilize multiple types of mobilities in their daily lives. As vehicle automation advances, driver modeling flourishes to provide personalized intelligent services. Thus, modeling drivers across mobilities would pave the road for future society mobility-as-a-service, and it is particularly interesting to predict driver behaviors in newer mobilities with traditional mobility data. In this work, we present takeover prediction on a micro-mobility, with car simulation data.The promising model performance demonstrates the feasibility of driver modeling across mobilities, as the first in the field.",
        "comments": "4 pages, 6 figures. Accepted to IEEE Human Robot Interaction (HRI)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10175"
    },
    {
        "doc_id": 134,
        "title": "SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild",
        "authors": [
            "Andreas Engelhardt",
            "Amit Raj",
            "Mark Boss",
            "Yunzhi Zhang",
            "Abhishek Kar",
            "Yuanzhen Li",
            "Deqing Sun",
            "Ricardo Martin Brualla",
            "Jonathan T. Barron",
            "Hendrik P. A. Lensch",
            "Varun Jampani"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Graphics"
        ],
        "abstract": "We present SHINOBI, an end-to-end framework for the reconstruction of shape, material, and illumination from object images captured with varying lighting, pose, and background. Inverse rendering of an object based on unconstrained image collections is a long-standing challenge in computer vision and graphics and requires a joint optimization over shape, radiance, and pose. We show that an implicit shape representation based on a multi-resolution hash encoding enables faster and robust shape reconstruction with joint camera alignment optimization that outperforms prior work. Further, to enable the editing of illumination and object reflectance (i.e. material) we jointly optimize BRDF and illumination together with the object's shape. Our method is class-agnostic and works on in-the-wild image collections of objects to produce relightable 3D assets for several use cases such as AR/VR, movies, games, etc. Project page: https://shinobi.aengelhardt.com Video: https://www.youtube.com/watch?v=iFENQ6AcYd8&feature=youtu.be",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10171"
    },
    {
        "doc_id": 135,
        "title": "VMamba: Visual State Space Model",
        "authors": [
            "Yue Liu",
            "Yunjie Tian",
            "Yuzhong Zhao",
            "Hongtian Yu",
            "Lingxi Xie",
            "Yaowei Wang",
            "Qixiang Ye",
            "Yunfan Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as the two most popular foundation models for visual representation learning. While CNNs exhibit remarkable scalability with linear complexity w.r.t. image resolution, ViTs surpass them in fitting capabilities despite contending with quadratic complexity. A closer inspection reveals that ViTs achieve superior visual modeling performance through the incorporation of global receptive fields and dynamic weights. This observation motivates us to propose a novel architecture that inherits these components while enhancing computational efficiency. To this end, we draw inspiration from the recently introduced state space model and propose the Visual State Space Model (VMamba), which achieves linear complexity without sacrificing global receptive fields. To address the encountered direction-sensitive issue, we introduce the Cross-Scan Module (CSM) to traverse the spatial domain and convert any non-causal visual image into order patch sequences. Extensive experimental results substantiate that VMamba not only demonstrates promising capabilities across various visual perception tasks, but also exhibits more pronounced advantages over established benchmarks as the image resolution increases. Source code has been available at https://github.com/MzeroMiko/VMamba.",
        "comments": "13 pages, 6 figures, 4 tables",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10166"
    },
    {
        "doc_id": 136,
        "title": "DISTINQT: A Distributed Privacy Aware Learning Framework for QoS Prediction for Future Mobile and Wireless Networks",
        "authors": [
            "Nikolaos Koursioumpas",
            "Lina Magoula",
            "Ioannis Stavrakakis",
            "Nancy Alonistioti",
            "M. A. Gutierrez-Estevez",
            "Ramin Khalili"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Artificial Intelligence",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Machine Learning"
        ],
        "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use cases and applications that depend on a certain level of Quality of Service (QoS) to operate smoothly. Predicting the QoS in a timely manner is of high importance, especially for safety-critical applications as in the case of vehicular communications. Although until recent years the QoS prediction has been carried out by centralized Artificial Intelligence (AI) solutions, a number of privacy, computational, and operational concerns have emerged. Alternative solutions have been surfaced (e.g. Split Learning, Federated Learning), distributing AI tasks of reduced complexity across nodes, while preserving the privacy of the data. However, new challenges rise when it comes to scalable distributed learning approaches, taking into account the heterogeneous nature of future wireless networks. The current work proposes DISTINQT, a privacy-aware distributed learning framework for QoS prediction. Our framework supports multiple heterogeneous nodes, in terms of data types and model architectures, by sharing computations across them. This, enables the incorporation of diverse knowledge into a sole learning process that will enhance the robustness and generalization capabilities of the final QoS prediction model. DISTINQT also contributes to data privacy preservation by encoding any raw input data into a non-linear latent representation before any transmission. Evaluation results showcase that our framework achieves a statistically identical performance compared to its centralized version and an average performance improvement of up to 65% against six state-of-the-art centralized baseline solutions in the Tele-Operated Driving use case.",
        "comments": "11 Pages Double Column, 9 Figures, Submitted for possible publication in the IEEE Transactions on Vehicular Technology (IEEE TVT)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10158"
    },
    {
        "doc_id": 137,
        "title": "Model-Assisted Learning for Adaptive Cooperative Perception of Connected Autonomous Vehicles",
        "authors": [
            "Kaige Qu",
            "Weihua Zhuang",
            "Qiang Ye",
            "Wen Wu",
            "Xuemin Shen"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Signal Processing"
        ],
        "abstract": "Cooperative perception (CP) is a key technology to facilitate consistent and accurate situational awareness for connected and autonomous vehicles (CAVs). To tackle the network resource inefficiency issue in traditional broadcast-based CP, unicast-based CP has been proposed to associate CAV pairs for cooperative perception via vehicle-to-vehicle transmission. In this paper, we investigate unicast-based CP among CAV pairs. With the consideration of dynamic perception workloads and channel conditions due to vehicle mobility and dynamic radio resource availability, we propose an adaptive cooperative perception scheme for CAV pairs in a mixed-traffic autonomous driving scenario with both CAVs and human-driven vehicles. We aim to determine when to switch between cooperative perception and stand-alone perception for each CAV pair, and allocate communication and computing resources to cooperative CAV pairs for maximizing the computing efficiency gain under perception task delay requirements. A model-assisted multi-agent reinforcement learning (MARL) solution is developed, which integrates MARL for an adaptive CAV cooperation decision and an optimization model for communication and computing resource allocation. Simulation results demonstrate the effectiveness of the proposed scheme in achieving high computing efficiency gain, as compared with benchmark schemes.",
        "comments": "Accepted by IEEE Transactions on Wireless Communications",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10156"
    },
    {
        "doc_id": 138,
        "title": "A novel hybrid time-varying graph neural network for traffic flow forecasting",
        "authors": [
            "Ben Ao Dai",
            "Bao-Lin Ye"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Real-time and accurate traffic flow prediction is the foundation for ensuring the efficient operation of intelligent transportation systems.In existing traffic flow prediction methods based on graph neural networks (GNNs), pre-defined graphs were usually used to describe the spatial correlations of different traffic nodes in urban road networks. However, the ability of pre-defined graphs used to describe spatial correlation was limited by prior knowledge and graph generation methods. Although time-varying graphs based on data-driven learning can partially overcome the drawbacks of pre-defined graphs, the learning ability of existing adaptive graphs was limited. For example, time-varying graphs cannot adequately capture the inherent spatial correlations in traffic flow data.In order to solve these problems, we have proposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow prediction.",
        "comments": "12 pages 1figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10155"
    },
    {
        "doc_id": 139,
        "title": "In Memory of Martin Davis",
        "authors": [
            "Wesley Calvert",
            "Valentina Harizanov",
            "Eugenio G. Omodeo",
            "Alberto Policriti",
            "Alexandra Shlapentokh"
        ],
        "subjects": [
            "History and Overview",
            "Logic in Computer Science",
            "Logic",
            "Number Theory"
        ],
        "abstract": "The present paper gives an account for the general mathematical reader of the life and work of Martin Davis. Since two rather comprehensive autobiographical accounts and two long biographical interviews already exist, the present work focusses on Davis's scientific achievements, including work on computably enumerable sets, universal Turing machines, the hyperarithmetical hierarchy, neural networks, Hilbert's Tenth Problem, and automated reasoning.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10154"
    },
    {
        "doc_id": 140,
        "title": "Importance-Aware Image Segmentation-based Semantic Communication for Autonomous Driving",
        "authors": [
            "Jie Lv",
            "Haonan Tong",
            "Qiang Pan",
            "Zhilong Zhang",
            "Xinxin He",
            "Tao Luo",
            "Changchuan Yin"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "This article studies the problem of image segmentation-based semantic communication in autonomous driving. In real traffic scenes, detecting the key objects (e.g., vehicles, pedestrians and obstacles) is more crucial than that of other objects to guarantee driving safety. Therefore, we propose a vehicular image segmentation-oriented semantic communication system, termed VIS-SemCom, where image segmentation features of important objects are transmitted to reduce transmission redundancy. First, to accurately extract image semantics, we develop a semantic codec based on Swin Transformer architecture, which expands the perceptual field thus improving the segmentation accuracy. Next, we propose a multi-scale semantic extraction scheme via assigning the number of Swin Transformer blocks for diverse resolution features, thus highlighting the important objects' accuracy. Furthermore, the importance-aware loss is invoked to emphasize the important objects, and an online hard sample mining (OHEM) strategy is proposed to handle small sample issues in the dataset. Experimental results demonstrate that the proposed VIS-SemCom can achieve a coding gain of nearly 6 dB with a 60% mean intersection over union (mIoU), reduce the transmitted data amount by up to 70% with a 60% mIoU, and improve the segmentation intersection over union (IoU) of important objects by 4%, compared to traditional transmission scheme.",
        "comments": "10 pages, 8 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10153"
    },
    {
        "doc_id": 141,
        "title": "Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation",
        "authors": [
            "Changgu Chen",
            "Junwei Shu",
            "Lianggangxu Chen",
            "Gaoqi He",
            "Changbo Wang",
            "Yang Li"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Recent large-scale pre-trained diffusion models have demonstrated a powerful generative ability to produce high-quality videos from detailed text descriptions. However, exerting control over the motion of objects in videos generated by any video diffusion model is a challenging problem. In this paper, we propose a novel zero-shot moving object trajectory control framework, Motion-Zero, to enable a bounding-box-trajectories-controlled text-to-video diffusion model.To this end, an initial noise prior module is designed to provide a position-based prior to improve the stability of the appearance of the moving object and the accuracy of position. In addition, based on the attention map of the U-net, spatial constraints are directly applied to the denoising process of diffusion models, which further ensures the positional and spatial consistency of moving objects during the inference. Furthermore, temporal consistency is guaranteed with a proposed shift temporal attention mechanism. Our method can be flexibly applied to various state-of-the-art video diffusion models without any training process. Extensive experiments demonstrate our proposed method can control the motion trajectories of objects and generate high-quality videos.",
        "comments": "9 pages, 4 figures, IJCAI paper",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10150"
    },
    {
        "doc_id": 142,
        "title": "Multi-Agent Reinforcement Learning for Maritime Operational Technology Cyber Security",
        "authors": [
            "Alec Wilson",
            "Ryan Menzies",
            "Neela Morarji",
            "David Foster",
            "Marco Casassa Mont",
            "Esin Turkbeyler",
            "Lisa Gralewski"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Multiagent Systems"
        ],
        "abstract": "This paper demonstrates the potential for autonomous cyber defence to be applied on industrial control systems and provides a baseline environment to further explore Multi-Agent Reinforcement Learning's (MARL) application to this problem domain. It introduces a simulation environment, IPMSRL, of a generic Integrated Platform Management System (IPMS) and explores the use of MARL for autonomous cyber defence decision-making on generic maritime based IPMS Operational Technology (OT). OT cyber defensive actions are less mature than they are for Enterprise IT. This is due to the relatively brittle nature of OT infrastructure originating from the use of legacy systems, design-time engineering assumptions, and lack of full-scale modern security controls. There are many obstacles to be tackled across the cyber landscape due to continually increasing cyber-attack sophistication and the limitations of traditional IT-centric cyber defence solutions. Traditional IT controls are rarely deployed on OT infrastructure, and where they are, some threats aren't fully addressed. In our experiments, a shared critic implementation of Multi Agent Proximal Policy Optimisation (MAPPO) outperformed Independent Proximal Policy Optimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of 1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome mean of 0.966 after one million timesteps. Hyperparameter tuning greatly improved training performance. Across one million timesteps the tuned hyperparameters reached an optimal policy whereas the default hyperparameters only managed to win sporadically, with most simulations resulting in a draw. We tested a real-world constraint, attack detection alert success, and found that when alert success probability is reduced to 0.75 or 0.9, the MARL defenders were still able to win in over 97.5% or 99.5% of episodes, respectively.",
        "comments": "13 pages, 7 figures, Proceedings of the Conference on Applied Machine Learning in Information Security 2023 (CAMLIS)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10149"
    },
    {
        "doc_id": 143,
        "title": "Explicitly Disentangled Representations in Object-Centric Learning",
        "authors": [
            "Riccardo Majellaro",
            "Jonathan Collu",
            "Aske Plaat",
            "Thomas M. Moerland"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Extracting structured representations from raw visual data is an important and long-standing challenge in machine learning. Recently, techniques for unsupervised learning of object-centric representations have raised growing interest. In this context, enhancing the robustness of the latent features can improve the efficiency and effectiveness of the training of downstream tasks. A promising step in this direction is to disentangle the factors that cause variation in the data. Previously, Invariant Slot Attention disentangled position, scale, and orientation from the remaining features. Extending this approach, we focus on separating the shape and texture components. In particular, we propose a novel architecture that biases object-centric models toward disentangling shape and texture components into two non-overlapping subsets of the latent space dimensions. These subsets are known a priori, hence before the training process. Experiments on a range of object-centric benchmarks reveal that our approach achieves the desired disentanglement while also numerically improving baseline performance in most cases. In addition, we show that our method can generate novel textures for a specific object or transfer textures between objects with distinct shapes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10148"
    },
    {
        "doc_id": 144,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 145,
        "title": "Model Compression Techniques in Biometrics Applications: A Survey",
        "authors": [
            "Eduarda Caldeira",
            "Pedro C. Neto",
            "Marco Huber",
            "Naser Damer",
            "Ana F. Sequeira"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "The development of deep learning algorithms has extensively empowered humanity's task automatization capacity. However, the huge improvement in the performance of these models is highly correlated with their increasing level of complexity, limiting their usefulness in human-oriented applications, which are usually deployed in resource-constrained devices. This led to the development of compression techniques that drastically reduce the computational and memory costs of deep learning models without significant performance degradation. This paper aims to systematize the current literature on this topic by presenting a comprehensive survey of model compression techniques in biometrics applications, namely quantization, knowledge distillation and pruning. We conduct a critical analysis of the comparative value of these techniques, focusing on their advantages and disadvantages and presenting suggestions for future work directions that can potentially improve the current methods. Additionally, we discuss and analyze the link between model bias and model compression, highlighting the need to direct compression research toward model fairness in future works.",
        "comments": "Under review at IEEE Journal",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10139"
    },
    {
        "doc_id": 146,
        "title": "The Role of Data Filtering in Open Source Software Ranking and Selection",
        "authors": [
            "Addi Malviya-Thakur",
            "Audris Mockus"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Faced with over 100M open source projects most empirical investigations select a subset. Most research papers in leading venues investigated filtering projects by some measure of popularity with explicit or implicit arguments that unpopular projects are not of interest, may not even represent \"real\" software projects, or that less popular projects are not worthy of study. However, such filtering may have enormous effects on the results of the studies if and precisely because the sought-out response or prediction is in any way related to the filtering criteria.\n  We exemplify the impact of this practice on research outcomes: how filtering of projects listed on GitHub affects the assessment of their popularity. We randomly sample over 100,000 repositories and use multiple regression to model the number of stars (a proxy for popularity) based on the number of commits, the duration of the project, the number of authors, and the number of core developers. Comparing control with the entire dataset with a filtered model projects having ten or more authors we find that while certain characteristics of the repository consistently predict popularity, the filtering process significantly alters the relation ships between these characteristics and the response. The number of commits exhibited a positive correlation with popularity in the control sample but showed a negative correlation in the filtered sample. These findings highlight the potential biases introduced by data filtering and emphasize the need for careful sample selection in empirical research of mining software repositories. We recommend that empirical work should either analyze complete datasets such as World of Code, or employ stratified random sampling from a complete dataset to ensure that filtering is not biasing the results.",
        "comments": "International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE 2024)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10136"
    },
    {
        "doc_id": 147,
        "title": "Spatial-Temporal Large Language Model for Traffic Prediction",
        "authors": [
            "Chenxi Liu",
            "Sun Yang",
            "Qianxiong Xu",
            "Zhishuai Li",
            "Cheng Long",
            "Ziyue Li",
            "Rui Zhao"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language"
        ],
        "abstract": "Traffic prediction, a critical component for intelligent transportation systems, endeavors to foresee future traffic at specific locations using historical data. Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not seen improvements accordingly. Recently, Large Language Models (LLMs) have shown outstanding capabilities in time series analysis. Differing from existing models, LLMs progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic prediction. Specifically, ST-LLM redefines the timesteps at each location as tokens and incorporates a spatial-temporal embedding module to learn the spatial location and global temporal representations of tokens. Then these representations are fused to provide each token with unified spatial and temporal information. Furthermore, we propose a novel partially frozen attention strategy of the LLM, which is designed to capture spatial-temporal dependencies for traffic prediction. Comprehensive experiments on real traffic datasets offer evidence that ST-LLM outperforms state-of-the-art models. Notably, the ST-LLM also exhibits robust performance in both few-shot and zero-shot prediction scenarios.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10134"
    },
    {
        "doc_id": 148,
        "title": "Interplay between Sensing and Communication in Cell-Free Massive MIMO with URLLC Users",
        "authors": [
            "Zinat Behdad",
            "\u00d6zlem Tu\u011ffe Demir",
            "Ki Won Sung",
            "Cicek Cavdar"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper studies integrated sensing and communication (ISAC) in the downlink of a cell-free massive multiple-input multiple-output (MIMO) system with multi-static sensing and ultra-reliable low-latency communication (URLLC) users. We propose a successive convex approximation-based power allocation algorithm that maximizes energy efficiency while satisfying the sensing and URLLC requirements. In addition, we provide a new definition for network availability, which accounts for both sensing and URLLC requirements. The impact of blocklength, sensing requirement, and required reliability as a function of decoding error probability on network availability and energy efficiency is investigated. The proposed power allocation algorithm is compared to a communication-centric approach where only the URLLC requirement is considered. It is shown that the URLLC-only approach is incapable of meeting sensing requirements, while the proposed ISAC algorithm fulfills both sensing and URLLC requirements, albeit with an associated increase in energy consumption. This increment can be reduced up to 75% by utilizing additional symbols for sensing. It is also demonstrated that larger blocklengths enhance network availability and offer greater robustness against stringent reliability requirements.",
        "comments": "6 pages, 3 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10133"
    },
    {
        "doc_id": 149,
        "title": "Few-shot learning for COVID-19 Chest X-Ray Classification with Imbalanced Data: An Inter vs. Intra Domain Study",
        "authors": [
            "Alejandro Gal\u00e1n-Cuenca",
            "Antonio Javier Gallego",
            "Marcelo Saval-Calvo",
            "Antonio Pertusa"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Medical image datasets are essential for training models used in computer-aided diagnosis, treatment planning, and medical research. However, some challenges are associated with these datasets, including variability in data distribution, data scarcity, and transfer learning issues when using models pre-trained from generic images. This work studies the effect of these challenges at the intra- and inter-domain level in few-shot learning scenarios with severe data imbalance. For this, we propose a methodology based on Siamese neural networks in which a series of techniques are integrated to mitigate the effects of data scarcity and distribution imbalance. Specifically, different initialization and data augmentation methods are analyzed, and four adaptations to Siamese networks of solutions to deal with imbalanced data are introduced, including data balancing and weighted loss, both separately and combined, and with a different balance of pairing ratios. Moreover, we also assess the inference process considering four classifiers, namely Histogram, $k$NN, SVM, and Random Forest. Evaluation is performed on three chest X-ray datasets with annotated cases of both positive and negative COVID-19 diagnoses. The accuracy of each technique proposed for the Siamese architecture is analyzed separately and their results are compared to those obtained using equivalent methods on a state-of-the-art CNN. We conclude that the introduced techniques offer promising improvements over the baseline in almost all cases, and that the selection of the technique may vary depending on the amount of data available and the level of imbalance.",
        "comments": "Submited to Pattern Analysis and Applications",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10129"
    },
    {
        "doc_id": 150,
        "title": "Sub2Full: split spectrum to boost OCT despeckling without clean data",
        "authors": [
            "Lingyun Wang",
            "Jose A Sahel",
            "Shaohua Pi"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Optical coherence tomography (OCT) suffers from speckle noise, causing the deterioration of image quality, especially in high-resolution modalities like visible light OCT (vis-OCT). The potential of conventional supervised deep learning denoising methods is limited by the difficulty of obtaining clean data. Here, we proposed an innovative self-supervised strategy called Sub2Full (S2F) for OCT despeckling without clean data. This approach works by acquiring two repeated B-scans, splitting the spectrum of the first repeat as a low-resolution input, and utilizing the full spectrum of the second repeat as the high-resolution target. The proposed method was validated on vis-OCT retinal images visualizing sublaminar structures in outer retina and demonstrated superior performance over conventional Noise2Noise and Noise2Void schemes. The code is available at https://github.com/PittOCT/Sub2Full-OCT-Denoising.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10128"
    },
    {
        "doc_id": 151,
        "title": "Lower Ricci Curvature for Efficient Community Detection",
        "authors": [
            "Yun Jin Park",
            "Didong Li"
        ],
        "subjects": [
            "Methodology",
            "Social and Information Networks",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, making it well-suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through comprehensive simulations and applications on real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10124"
    },
    {
        "doc_id": 152,
        "title": "Differentially Private Approval-Based Committee Voting",
        "authors": [
            "Zhechen Li",
            "Zimai Guo",
            "Lirong Xia",
            "Yongzhi Cao",
            "Hanpin Wang"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "In this paper, we investigate tradeoffs between differential privacy (DP) and several voting axioms for approval-based committee voting, including proportionality, Pareto efficiency, Condorcet criterion, and strategyproofness. For all the axioms except strategyproofness, we show their incompatibility with DP, and provide both upper and lower bounds for their tradeoffs with DP. Furthermore, we show that any $\u03b5$-DP mechanism satisfies $e^{-\u03b5}$-cardinality strategyproofness, and the satisfaction can be further improved if the mechanism satisfies monotonicity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10122"
    },
    {
        "doc_id": 153,
        "title": "Towards Principled Graph Transformers",
        "authors": [
            "Luis M\u00fcller",
            "Christopher Morris"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10119"
    },
    {
        "doc_id": 154,
        "title": "Techniques for Authenticating Quantile Digests",
        "authors": [
            "Alessandro Scala"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "We investigate two possible techniques to authenticate the q-digest data structure, along with a worst-case study of the computational complexity both in time and space of the proposed solutions, and considerations on the feasibility of the presented approaches in real-world scenarios. We conclude the discussion by presenting some considerations on the information complexity of the queries in the two proposed approaches, and by presenting some interesting ideas that could be the subject of future studies on the topic.",
        "comments": "ACM Class:          E.1",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10118"
    },
    {
        "doc_id": 155,
        "title": "Exposing Lip-syncing Deepfakes from Mouth Inconsistencies",
        "authors": [
            "Soumyya Kanti Datta",
            "Shan Jia",
            "Siwei Lyu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "A lip-syncing deepfake is a digitally manipulated video in which a person's lip movements are created convincingly using AI models to match altered or entirely new audio. Lip-syncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern. In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region. These inconsistencies are seen in the adjacent frames and throughout the video. Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10113"
    },
    {
        "doc_id": 156,
        "title": "Marrying Adapters and Mixup to Efficiently Enhance the Adversarial Robustness of Pre-Trained Language Models for Text Classification",
        "authors": [
            "Tuc Nguyen",
            "Thai Le"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Existing works show that augmenting training data of neural networks using both clean and adversarial examples can enhance their generalizability under adversarial attacks. However, this training approach often leads to performance degradation on clean inputs. Additionally, it requires frequent re-training of the entire model to account for new attack types, resulting in significant and costly computations. Such limitations make adversarial training mechanisms less practical, particularly for complex Pre-trained Language Models (PLMs) with millions or even billions of parameters. To overcome these challenges while still harnessing the theoretical benefits of adversarial training, this study combines two concepts: (1) adapters, which enable parameter-efficient fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs data pairs. Intuitively, we propose to fine-tune PLMs through convex combinations of non-data pairs of fine-tuned adapters, one trained with clean and another trained with adversarial examples. Our experiments show that the proposed method achieves the best trade-off between training efficiency and predictive performance, both with and without attacks compared to other baselines on a variety of downstream tasks.",
        "comments": "10 pages and 2 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10111"
    },
    {
        "doc_id": 157,
        "title": "VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text Recognition",
        "authors": [
            "Xianfu Cheng",
            "Weixiao Zhou",
            "Xiang Li",
            "Xiaoming Chen",
            "Jian Yang",
            "Tongliang Li",
            "Zhoujun Li"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Scene Text Recognition (STR) is a challenging task that involves recognizing text within images of natural scenes. Although current state-of-the-art models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders. In this work, we propose the VIsion Permutable extractor for fast and efficient scene Text Recognition (VIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR. Specifically, VIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by multiple self-attention layers, while eschewing the traditional sequence decoder. This design choice results in a lightweight and efficient model capable of handling inputs of varying sizes. Extensive experimental results on various standard datasets for both Chinese and English scene text recognition validate the superiority of VIPTR. Notably, the VIPTR-T (Tiny) variant delivers highly competitive accuracy on par with other lightweight models and achieves SOTA inference speeds. Meanwhile, the VIPTR-L (Large) variant attains greater recognition accuracy, while maintaining a low parameter count and favorable inference speed. Our proposed method provides a compelling solution for the STR challenge, which blends high accuracy with efficiency and greatly benefits real-world applications requiring fast and reliable text recognition. The code is publicly available at https://github.com/cxfyxl/VIPTR.",
        "comments": "arXiv admin note: text overlap with arXiv:2205.00159 by other authors",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10110"
    },
    {
        "doc_id": 158,
        "title": "Information sets from defining sets for Reed-Muller codes of first and second order",
        "authors": [
            "Jos\u00e9 Joaqu\u00edn Bernal",
            "Juan Jacobo Sim\u00f3n"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "Reed-Muller codes belong to the family of affine-invariant codes. As such codes they have a defining set that determines them uniquely, and they are extensions of cyclic group codes. In this paper we identify those cyclic codes with multidimensional abelian codes and we use the techniques introduced in \\cite{BS} to construct information sets for them from their defining set. For first and second order Reed-Muller codes, we describe a direct method to construct information sets in terms of their basic parameters.",
        "comments": "18 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10109"
    },
    {
        "doc_id": 159,
        "title": "Comparison analysis between standard polysomnographic data and in-ear-EEG signals: A preliminary study",
        "authors": [
            "Gianpaolo Palo",
            "Luigi Fiorillo",
            "Giuliana Monachino",
            "Michal Bechny",
            "Mark Melnykowycz",
            "Athina Tzovara",
            "Valentina Agostini",
            "Francesca Dalia Faraci"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Medical Physics"
        ],
        "abstract": "Study Objectives: Polysomnography (PSG) currently serves as the benchmark for evaluating sleep disorders. Its discomfort, impracticality for home-use, and introduction of bias in sleep quality assessment necessitate the exploration of less invasive, cost-effective, and portable alternatives. One promising contender is the in-ear-EEG sensor, which offers advantages in terms of comfort, fixed electrode positions, resistance to electromagnetic interference, and user-friendliness. This study aims to establish a methodology to assess the similarity between the in-ear-EEG signal and standard PSG.\n  Methods: We assess the agreement between the PSG and in-ear-EEG derived hypnograms. We extract features in the time- and frequency- domain from PSG and in-ear-EEG 30-second epochs. We only consider the epochs where the PSG-scorers and the in-ear-EEG-scorers were in agreement. We introduce a methodology to quantify the similarity between PSG derivations and the single-channel in-ear-EEG. The approach relies on a comparison of distributions of selected features -- extracted for each sleep stage and subject on both PSG and the in-ear-EEG signals -- via a Jensen-Shannon Divergence Feature-based Similarity Index (JSD-FSI).\n  Results: We found a high intra-scorer variability, mainly due to the uncertainty the scorers had in evaluating the in-ear-EEG signals. We show that the similarity between PSG and in-ear-EEG signals is high (JSD-FSI: 0.61 +/- 0.06 in awake, 0.60 +/- 0.07 in NREM and 0.51 +/- 0.08 in REM), and in line with the similarity values computed independently on standard PSG-channel-combinations.\n  Conclusions: In-ear-EEG is a valuable solution for home-based sleep monitoring, however further studies with a larger and more heterogeneous dataset are needed.",
        "comments": "29 pages, 12 figures, 1 table",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10107"
    },
    {
        "doc_id": 160,
        "title": "Counterfactual Reasoning with Probabilistic Graphical Models for Analyzing Socioecological Systems",
        "authors": [
            "Rafael Caba\u00f1as",
            "Ana D. Maldonado",
            "Mar\u00eda Morales",
            "Pedro A. Aguilera",
            "Antonio Salmer\u00f3n"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Probability",
            "Applications"
        ],
        "abstract": "Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios. This is particularly useful in domains where experimental data are usually not available. In the context of environmental and ecological sciences, causality enables us, for example, to predict how an ecosystem would respond to hypothetical interventions. A structural causal model is a class of probabilistic graphical models for causality, which, due to its intuitive nature, can be easily understood by experts in multiple fields. However, certain queries, called unidentifiable, cannot be calculated in an exact and precise manner. This paper proposes applying a novel and recent technique for bounding unidentifiable queries within the domain of socioecological systems. Our findings indicate that traditional statistical analysis, including probabilistic graphical models, can identify the influence between variables. However, such methods do not offer insights into the nature of the relationship, specifically whether it involves necessity or sufficiency. This is where counterfactual reasoning becomes valuable.",
        "comments": "34 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10101"
    },
    {
        "doc_id": 161,
        "title": "Learning shallow quantum circuits",
        "authors": [
            "Hsin-Yuan Huang",
            "Yunchao Liu",
            "Michael Broughton",
            "Isaac Kim",
            "Anurag Anshu",
            "Zeph Landau",
            "Jarrod R. McClean"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Machine Learning"
        ],
        "abstract": "Despite fundamental interests in learning quantum circuits, the existence of a computationally efficient algorithm for learning shallow quantum circuits remains an open question. Because shallow quantum circuits can generate distributions that are classically hard to sample from, existing learning algorithms do not apply. In this work, we present a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit shallow quantum circuit $U$ (with arbitrary unknown architecture) within a small diamond distance using single-qubit measurement data on the output states of $U$. We also provide a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit state $\\lvert \u03c8\\rangle = U \\lvert 0^n \\rangle$ prepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small trace distance using single-qubit measurements on copies of $\\lvert \u03c8\\rangle$. Our approach uses a quantum circuit representation based on local inversions and a technique to combine these inversions. This circuit representation yields an optimization landscape that can be efficiently navigated and enables efficient learning of quantum circuits that are classically hard to simulate.",
        "comments": "10 pages, 14 figures (7 inline; 7 floating) + 76-page appendix",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10095"
    },
    {
        "doc_id": 162,
        "title": "Power in Numbers: Robust reading comprehension by finetuning with four adversarial sentences per example",
        "authors": [
            "Ariel Marcus"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Recent models have achieved human level performance on the Stanford Question Answering Dataset when using F1 scores to evaluate the reading comprehension task. Yet, teaching machines to comprehend text has not been solved in the general case. By appending one adversarial sentence to the context paragraph, past research has shown that the F1 scores from reading comprehension models drop almost in half. In this paper, I replicate past adversarial research with a new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops from 83.9% to 29.2%. To improve ELECTRA-Small's resistance to this attack, I finetune the model on SQuAD v1.1 training examples with one to five adversarial sentences appended to the context paragraph. Like past research, I find that the finetuned model on one adversarial sentence does not generalize well across evaluation datasets. However, when finetuned on four or five adversarial sentences the model attains an F1 score of more than 70% on most evaluation datasets with multiple appended and prepended adversarial sentences. The results suggest that with enough examples we can make models robust to adversarial attacks.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10091"
    },
    {
        "doc_id": 163,
        "title": "Cross-Modality Perturbation Synergy Attack for Person Re-identification",
        "authors": [
            "Yunpeng Gong",
            "others"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In recent years, there has been significant research focusing on addressing security concerns in single-modal person re-identification (ReID) systems that are based on RGB images. However, the safety of cross-modality scenarios, which are more commonly encountered in practical applications involving images captured by infrared cameras, has not received adequate attention. The main challenge in cross-modality ReID lies in effectively dealing with visual differences between different modalities. For instance, infrared images are typically grayscale, unlike visible images that contain color information. Existing attack methods have primarily focused on the characteristics of the visible image modality, overlooking the features of other modalities and the variations in data distribution among different modalities. This oversight can potentially undermine the effectiveness of these methods in image retrieval across diverse modalities. This study represents the first exploration into the security of cross-modality ReID models and proposes a universal perturbation attack specifically designed for cross-modality ReID. This attack optimizes perturbations by leveraging gradients from diverse modality data, thereby disrupting the discriminator and reinforcing the differences between modalities. We conducted experiments on two widely used cross-modality datasets, namely RegDB and SYSU, which not only demonstrated the effectiveness of our method but also provided insights for future enhancements in the robustness of cross-modality ReID systems.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10090"
    },
    {
        "doc_id": 164,
        "title": "CLIP feature-based randomized control using images and text for multiple tasks and robots",
        "authors": [
            "Kazuki Shibata",
            "Hideki Deguchi",
            "Shun Taguchi"
        ],
        "subjects": [
            "Robotics"
        ],
        "abstract": "This study presents a control framework leveraging vision language models (VLMs) for multiple tasks and robots. Notably, existing control methods using VLMs have achieved high performance in various tasks and robots in the training environment. However, these methods incur high costs for learning control policies for tasks and robots other than those in the training environment. Considering the application of industrial and household robots, learning in novel environments where robots are introduced is challenging. To address this issue, we propose a control framework that does not require learning control policies. Our framework combines the vision-language CLIP model with a randomized control. CLIP computes the similarity between images and texts by embedding them in the feature space. This study employs CLIP to compute the similarity between camera images and text representing the target state. In our method, the robot is controlled by a randomized controller that simultaneously explores and increases the similarity gradients. Moreover, we fine-tune the CLIP to improve the performance of the proposed method. Consequently, we confirm the effectiveness of our approach through a multitask simulation and a real robot experiment using a two-wheeled robot and robot arm.",
        "comments": "13 pages, 5 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10085"
    },
    {
        "doc_id": 165,
        "title": "A locally statistical active contour model for SAR image segmentation can be solved by denoising algorithms",
        "authors": [
            "Guangming Liu",
            "Quanying Sun",
            "Jing Liang",
            "Qi Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In this paper, we propose a novel locally statistical variational active contour model based on I-divergence-TV denoising model, which hybrides geodesic active contour (GAC) model with active contours without edges (ACWE) model, and can be used to segment images corrupted by multiplicative gamma noise. By adding a diffusion term into the level set evolution (LSE) equation of the proposed model, we construct a reaction-diffusion (RD) equation, which can gradually regularize the level set function (LSF) to be piecewise constant in each segment domain and gain the stable solution. We further transform the proposed model into classic ROF model by adding a proximity term. Inspired by a fast denoising algorithm proposed by Jia-Zhao recently, we propose two fast fixed point algorithms to solve SAR image segmentation question. Experimental results for real SAR images show that the proposed image segmentation model can efficiently stop the contours at weak or blurred edges, and can automatically detect the exterior and interior boundaries of images with multiplicative gamma noise. The proposed FPRD1/FPRD2 models are about 1/2 (or less than) of the time required for the SBRD model based on the Split Bregman technique.",
        "comments": "18 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2312.11849, arXiv:2312.08376, arXiv:2312.09365",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10083"
    },
    {
        "doc_id": 166,
        "title": "Analyzing and Improving Hardware Modeling of Accel-Sim",
        "authors": [
            "Rodrigo Huerta",
            "Mojtaba Abaie Shoushtary",
            "Antonio Gonz\u00e1lez"
        ],
        "subjects": [
            "Hardware Architecture"
        ],
        "abstract": "GPU architectures have become popular for executing general-purpose programs. Their many-core architecture supports a large number of threads that run concurrently to hide the latency among dependent instructions. In modern GPU architectures, each SM/core is typically composed of several sub-cores, where each sub-core has its own independent pipeline.\n  Simulators are a key tool for investigating novel concepts in computer architecture. They must be performance-accurate and have a proper model related to the target hardware to explore the different bottlenecks properly.\n  This paper presents a wide analysis of different parts of Accel-sim, a popular GPGPU simulator, and some improvements of its model. First, we focus on the front-end and developed a more realistic model. Then, we analyze the way the result bus works and develop a more realistic one. Next, we describe the current memory pipeline model and propose a model for a more cost-effective design. Finally, we discuss other areas of improvement of the simulator.",
        "comments": "6 pages, 7 figures, presented in the 1st Workshop on Computer Architecture Modeling and Simulation (CAMS 2023) (co-located with MICRO 2023)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10082"
    },
    {
        "doc_id": 167,
        "title": "Lower Bounds for Maximum Weight Bisections of Graphs with Bounded Degrees",
        "authors": [
            "Stefanie Gerke",
            "Gregory Gutin",
            "Anders Yeo",
            "Yacong Zhou"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics"
        ],
        "abstract": "A bisection in a graph is a cut in which the number of vertices in the two parts differ by at most 1. In this paper, we give lower bounds for the maximum weight of bisections of edge-weighted graphs with bounded maximum degree. Our results improve a bound of Lee, Loh, and Sudakov (J. Comb. Th. Ser. B 103 (2013)) for (unweighted) maximum bisections in graphs whose maximum degree is either even or equals 3, and for almost all graphs. We show that a tight lower bound for maximum size of bisections in 3-regular graphs obtained by Bollob\u00e1s and Scott (J. Graph Th. 46 (2004)) can be extended to weighted subcubic graphs. We also consider edge-weighted triangle-free subcubic graphs and show that a much better lower bound (than for edge-weighted subcubic graphs) holds for such graphs especially if we exclude $K_{1,3}$. We pose three conjectures.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10074"
    },
    {
        "doc_id": 168,
        "title": "Communication-Efficient Personalized Federated Learning for Speech-to-Text Tasks",
        "authors": [
            "Yichao Du",
            "Zhirui Zhang",
            "Linan Yue",
            "Xu Huang",
            "Yuqing Zhang",
            "Tong Xu",
            "Linli Xu",
            "Enhong Chen"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "To protect privacy and meet legal regulations, federated learning (FL) has gained significant attention for training speech-to-text (S2T) systems, including automatic speech recognition (ASR) and speech translation (ST). However, the commonly used FL approach (i.e., \\textsc{FedAvg}) in S2T tasks typically suffers from extensive communication overhead due to multi-round interactions based on the whole model and performance degradation caused by data heterogeneity among clients.To address these issues, we propose a personalized federated S2T framework that introduces \\textsc{FedLoRA}, a lightweight LoRA module for client-side tuning and interaction with the server to minimize communication overhead, and \\textsc{FedMem}, a global model equipped with a $k$-nearest-neighbor ($k$NN) classifier that captures client-specific distributional shifts to achieve personalization and overcome data heterogeneity. Extensive experiments based on Conformer and Whisper backbone models on CoVoST and GigaSpeech benchmarks show that our approach significantly reduces the communication overhead on all S2T tasks and effectively personalizes the global model to overcome data heterogeneity.",
        "comments": "ICASSP 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10070"
    },
    {
        "doc_id": 169,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 170,
        "title": "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs",
        "authors": [
            "Haritz Puerto",
            "Martin Tutek",
            "Somak Aditya",
            "Xiaodan Zhu",
            "Iryna Gurevych"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Reasoning is a fundamental component for achieving language understanding. Among the multiple types of reasoning, conditional reasoning, the ability to draw different conclusions depending on some condition, has been understudied in large language models (LLMs). Recent prompting methods, such as chain of thought, have significantly improved LLMs on reasoning tasks. Nevertheless, there is still little understanding of what triggers reasoning abilities in LLMs. We hypothesize that code prompts can trigger conditional reasoning in LLMs trained on text and code. We propose a chain of prompts that transforms a natural language problem into code and prompts the LLM with the generated code. Our experiments find that code prompts exhibit a performance boost between 2.6 and 7.7 points on GPT 3.5 across multiple datasets requiring conditional reasoning. We then conduct experiments to discover how code prompts elicit conditional reasoning abilities and through which features. We observe that prompts need to contain natural language text accompanied by high-quality code that closely represents the semantics of the instance text. Furthermore, we show that code prompts are more efficient, requiring fewer demonstrations, and that they trigger superior state tracking of variables or key entities.",
        "comments": "Code, prompt templates, prompts, and outputs are publicly available at https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10065"
    },
    {
        "doc_id": 171,
        "title": "DiffusionGPT: LLM-Driven Text-to-Image Generation System",
        "authors": [
            "Jie Qin",
            "Jie Wu",
            "Weifeng Chen",
            "Yuxi Ren",
            "Huixia Li",
            "Hefeng Wu",
            "Xuefeng Xiao",
            "Rui Wang",
            "Shilei Wen"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Diffusion models have opened up new avenues for the field of image generation, resulting in the proliferation of high-quality models shared on open-source platforms. However, a major challenge persists in current text-to-image systems are often unable to handle diverse inputs, or are limited to single model results. Current unified attempts often fall into two orthogonal aspects: i) parse Diverse Prompts in input stage; ii) activate expert model to output. To combine the best of both worlds, we propose DiffusionGPT, which leverages Large Language Models (LLM) to offer a unified generation system capable of seamlessly accommodating various types of prompts and integrating domain-expert models. DiffusionGPT constructs domain-specific Trees for various generative models based on prior knowledge. When provided with an input, the LLM parses the prompt and employs the Trees-of-Thought to guide the selection of an appropriate model, thereby relaxing input constraints and ensuring exceptional performance across diverse domains. Moreover, we introduce Advantage Databases, where the Tree-of-Thought is enriched with human feedback, aligning the model selection process with human preferences. Through extensive experiments and comparisons, we demonstrate the effectiveness of DiffusionGPT, showcasing its potential for pushing the boundaries of image synthesis in diverse domains.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10061"
    },
    {
        "doc_id": 172,
        "title": "ContextMix: A context-aware data augmentation method for industrial visual inspection systems",
        "authors": [
            "Hyungmin Kim",
            "Donghun Kim",
            "Pyunghwan Ahn",
            "Sungho Suh",
            "Hansang Cho",
            "Junmo Kim"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "While deep neural networks have achieved remarkable performance, data augmentation has emerged as a crucial strategy to mitigate overfitting and enhance network performance. These techniques hold particular significance in industrial manufacturing contexts. Recently, image mixing-based methods have been introduced, exhibiting improved performance on public benchmark datasets. However, their application to industrial tasks remains challenging. The manufacturing environment generates massive amounts of unlabeled data on a daily basis, with only a few instances of abnormal data occurrences. This leads to severe data imbalance. Thus, creating well-balanced datasets is not straightforward due to the high costs associated with labeling. Nonetheless, this is a crucial step for enhancing productivity. For this reason, we introduce ContextMix, a method tailored for industrial applications and benchmark datasets. ContextMix generates novel data by resizing entire images and integrating them into other images within the batch. This approach enables our method to learn discriminative features based on varying sizes from resized images and train informative secondary features for object recognition using occluded images. With the minimal additional computation cost of image resizing, ContextMix enhances performance compared to existing augmentation techniques. We evaluate its effectiveness across classification, detection, and segmentation tasks using various network architectures on public benchmark datasets. Our proposed method demonstrates improved results across a range of robustness tasks. Its efficacy in real industrial environments is particularly noteworthy, as demonstrated using the passive component dataset.",
        "comments": "Accepted to EAAI",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10050"
    },
    {
        "doc_id": 173,
        "title": "Antonym vs Synonym Distinction using InterlaCed Encoder NETworks (ICE-NET)",
        "authors": [
            "Muhammad Asif Ali",
            "Yan Hu",
            "Jianbin Qin",
            "Di Wang"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Antonyms vs synonyms distinction is a core challenge in lexico-semantic analysis and automated lexical resource construction. These pairs share a similar distributional context which makes it harder to distinguish them. Leading research in this regard attempts to capture the properties of the relation pairs, i.e., symmetry, transitivity, and trans-transitivity. However, the inability of existing research to appropriately model the relation-specific properties limits their end performance. In this paper, we propose InterlaCed Encoder NETworks (i.e., ICE-NET) for antonym vs synonym distinction, that aim to capture and model the relation-specific properties of the antonyms and synonyms pairs in order to perform the classification task in a performance-enhanced manner. Experimental evaluation using the benchmark datasets shows that ICE-NET outperforms the existing research by a relative score of upto 1.8% in F1-measure. We release the codes for ICE-NET at https://github.com/asif6827/ICENET.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10045"
    },
    {
        "doc_id": 174,
        "title": "Deep spatial context: when attention-based models meet spatial regression",
        "authors": [
            "Paulina Tomaszewska",
            "El\u017cbieta Sienkiewicz",
            "Mai P. Hoang",
            "Przemys\u0142aw Biecek"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We propose 'Deep spatial context' (DSCon) method, which serves for investigation of the attention-based vision models using the concept of spatial context. It was inspired by histopathologists, however, the method can be applied to various domains. The DSCon allows for a quantitative measure of the spatial context's role using three Spatial Context Measures: $SCM_{features}$, $SCM_{targets}$, $SCM_{residuals}$ to distinguish whether the spatial context is observable within the features of neighboring regions, their target values (attention scores) or residuals, respectively. It is achieved by integrating spatial regression into the pipeline. The DSCon helps to verify research questions. The experiments reveal that spatial relationships are much bigger in the case of the classification of tumor lesions than normal tissues. Moreover, it turns out that the larger the size of the neighborhood taken into account within spatial regression, the less valuable contextual information is. Furthermore, it is observed that the spatial context measure is the largest when considered within the feature space as opposed to the targets and residuals.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10044"
    },
    {
        "doc_id": 175,
        "title": "BlockAMC: Scalable In-Memory Analog Matrix Computing for Solving Linear Systems",
        "authors": [
            "Lunshuai Pan",
            "Pushen Zuo",
            "Yubiao Luo",
            "Zhong Sun",
            "Ru Huang"
        ],
        "subjects": [
            "Hardware Architecture",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Recently, in-memory analog matrix computing (AMC) with nonvolatile resistive memory has been developed for solving matrix problems in one step, e.g., matrix inversion of solving linear systems. However, the analog nature sets up a barrier to the scalability of AMC, due to the limits on the manufacturability and yield of resistive memory arrays, non-idealities of device and circuit, and cost of hardware implementations. Aiming to deliver a scalable AMC approach for solving linear systems, this work presents BlockAMC, which partitions a large original matrix into smaller ones on different memory arrays. A macro is designed to perform matrix inversion and matrix-vector multiplication with the block matrices, obtaining the partial solutions to recover the original solution. The size of block matrices can be exponentially reduced by performing multiple stages of divide-and-conquer, resulting in a two-stage solver design that enhances the scalability of this approach. BlockAMC is also advantageous in alleviating the accuracy issue of AMC, especially in the presence of device and circuit non-idealities, such as conductance variations and interconnect resistances. Compared to a single AMC circuit solving the same problem, BlockAMC improves the area and energy efficiency by 48.83% and 40%, respectively.",
        "comments": "This paper has been accepted to the conference DATE 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10042"
    },
    {
        "doc_id": 176,
        "title": "CMFN: Cross-Modal Fusion Network for Irregular Scene Text Recognition",
        "authors": [
            "Jinzhi Zheng",
            "Ruyi Ji",
            "Libo Zhang",
            "Yanjun Wu",
            "Chen Zhao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Scene text recognition, as a cross-modal task involving vision and text, is an important research topic in computer vision. Most existing methods use language models to extract semantic information for optimizing visual recognition. However, the guidance of visual cues is ignored in the process of semantic mining, which limits the performance of the algorithm in recognizing irregular scene text. To tackle this issue, we propose a novel cross-modal fusion network (CMFN) for irregular scene text recognition, which incorporates visual cues into the semantic mining process. Specifically, CMFN consists of a position self-enhanced encoder, a visual recognition branch and an iterative semantic recognition branch. The position self-enhanced encoder provides character sequence position encoding for both the visual recognition branch and the iterative semantic recognition branch. The visual recognition branch carries out visual recognition based on the visual features extracted by CNN and the position encoding information provided by the position self-enhanced encoder. The iterative semantic recognition branch, which consists of a language recognition module and a cross-modal fusion gate, simulates the way that human recognizes scene text and integrates cross-modal visual cues for text recognition. The experiments demonstrate that the proposed CMFN algorithm achieves comparable performance to state-of-the-art algorithms, indicating its effectiveness.",
        "comments": "Accepted to ICONIP 2023",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10041"
    },
    {
        "doc_id": 177,
        "title": "Large Language Models for Scientific Information Extraction: An Empirical Study for Virology",
        "authors": [
            "Mahsa Shamsabadi",
            "Jennifer D'Souza",
            "S\u00f6ren Auer"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Digital Libraries",
            "Information Theory"
        ],
        "abstract": "In this paper, we champion the use of structured and semantic content representation of discourse-based scholarly communication, inspired by tools like Wikipedia infoboxes or structured Amazon product descriptions. These representations provide users with a concise overview, aiding scientists in navigating the dense academic landscape. Our novel automated approach leverages the robust text generation capabilities of LLMs to produce structured scholarly contribution summaries, offering both a practical solution and insights into LLMs' emergent abilities.\n  For LLMs, the prime focus is on improving their general intelligence as conversational agents. We argue that these models can also be applied effectively in information extraction (IE), specifically in complex IE tasks within terse domains like Science. This paradigm shift replaces the traditional modular, pipelined machine learning approach with a simpler objective expressed through instructions. Our results show that finetuned FLAN-T5 with 1000x fewer parameters than the state-of-the-art GPT-davinci is competitive for the task.",
        "comments": "8 pages, 6 figures, Accepted as Findings of the ACL: EACL 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10040"
    },
    {
        "doc_id": 178,
        "title": "GPT4Ego: Unleashing the Potential of Pre-trained Models for Zero-Shot Egocentric Action Recognition",
        "authors": [
            "Guangzhao Dai",
            "Xiangbo Shu",
            "Wenhao Wu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Vision-Language Models (VLMs), pre-trained on large-scale datasets, have shown impressive performance in various visual recognition tasks. This advancement paves the way for notable performance in Zero-Shot Egocentric Action Recognition (ZS-EAR). Typically, VLMs handle ZS-EAR as a global video-text matching task, which often leads to suboptimal alignment of vision and linguistic knowledge. We propose a refined approach for ZS-EAR using VLMs, emphasizing fine-grained concept-description alignment that capitalizes on the rich semantic and contextual details in egocentric videos. In this paper, we introduce GPT4Ego, a straightforward yet remarkably potent VLM framework for ZS-EAR, designed to enhance the fine-grained alignment of concept and description between vision and language. Extensive experiments demonstrate GPT4Ego significantly outperforms existing VLMs on three large-scale egocentric video benchmarks, i.e., EPIC-KITCHENS-100 (33.2%, +9.4%), EGTEA (39.6%, +5.5%), and CharadesEgo (31.5%, +2.6%).",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10039"
    },
    {
        "doc_id": 179,
        "title": "Depth Over RGB: Automatic Evaluation of Open Surgery Skills Using Depth Camera",
        "authors": [
            "Ido Zuckerman",
            "Nicole Werner",
            "Jonathan Kouchly",
            "Emma Huston",
            "Shannon DiMarco",
            "Paul DiMusto",
            "Shlomi Laufer"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Purpose: In this paper, we present a novel approach to the automatic evaluation of open surgery skills using depth cameras. This work is intended to show that depth cameras achieve similar results to RGB cameras, which is the common method in the automatic evaluation of open surgery skills. Moreover, depth cameras offer advantages such as robustness to lighting variations, camera positioning, simplified data compression, and enhanced privacy, making them a promising alternative to RGB cameras.\n  Methods: Experts and novice surgeons completed two simulators of open suturing. We focused on hand and tool detection, and action segmentation in suturing procedures. YOLOv8 was used for tool detection in RGB and depth videos. Furthermore, UVAST and MSTCN++ were used for action segmentation. Our study includes the collection and annotation of a dataset recorded with Azure Kinect.\n  Results: We demonstrated that using depth cameras in object detection and action segmentation achieves comparable results to RGB cameras. Furthermore, we analyzed 3D hand path length, revealing significant differences between experts and novice surgeons, emphasizing the potential of depth cameras in capturing surgical skills. We also investigated the influence of camera angles on measurement accuracy, highlighting the advantages of 3D cameras in providing a more accurate representation of hand movements.\n  Conclusion: Our research contributes to advancing the field of surgical skill assessment by leveraging depth cameras for more reliable and privacy evaluations. The findings suggest that depth cameras can be valuable in assessing surgical skills and provide a foundation for future research in this area.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10037"
    },
    {
        "doc_id": 180,
        "title": "LOCALINTEL: Generating Organizational Threat Intelligence from Global and Local Cyber Knowledge",
        "authors": [
            "Shaswata Mitra",
            "Subash Neupane",
            "Trisha Chakraborty",
            "Sudip Mittal",
            "Aritran Piplai",
            "Manas Gaur",
            "Shahram Rahimi"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Information Retrieval",
            "Logic in Computer Science"
        ],
        "abstract": "Security Operations Center (SoC) analysts gather threat reports from openly accessible global threat databases and customize them manually to suit a particular organization's needs. These analysts also depend on internal repositories, which act as private local knowledge database for an organization. Credible cyber intelligence, critical operational details, and relevant organizational information are all stored in these local knowledge databases. Analysts undertake a labor intensive task utilizing these global and local knowledge databases to manually create organization's unique threat response and mitigation strategies. Recently, Large Language Models (LLMs) have shown the capability to efficiently process large diverse knowledge sources. We leverage this ability to process global and local knowledge databases to automate the generation of organization-specific threat intelligence.\n  In this work, we present LOCALINTEL, a novel automated knowledge contextualization system that, upon prompting, retrieves threat reports from the global threat repositories and uses its local knowledge database to contextualize them for a specific organization. LOCALINTEL comprises of three key phases: global threat intelligence retrieval, local knowledge retrieval, and contextualized completion generation. The former retrieves intelligence from global threat repositories, while the second retrieves pertinent knowledge from the local knowledge database. Finally, the fusion of these knowledge sources is orchestrated through a generator to produce a contextualized completion.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10036"
    },
    {
        "doc_id": 181,
        "title": "Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap",
        "authors": [
            "Xingyu Wu",
            "Sheng-hao Wu",
            "Jibin Wu",
            "Liang Feng",
            "Kay Chen Tan"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Artificial Intelligence",
            "Computation and Language"
        ],
        "abstract": "Large Language Models (LLMs), built upon Transformer-based architectures with massive pretraining on diverse data, have not only revolutionized natural language processing but also extended their prowess to various domains, marking a significant stride towards artificial general intelligence. The interplay between LLMs and Evolutionary Algorithms (EAs), despite differing in objectives and methodologies, reveals intriguing parallels, especially in their shared optimization nature, black-box characteristics, and proficiency in handling complex problems. Meanwhile, EA can not only provide an optimization framework for LLM's further enhancement under black-box settings but also empower LLM with flexible global search and iterative mechanism in applications. On the other hand, LLM's abundant domain knowledge enables EA to perform smarter searches, while its text processing capability assist in deploying EA across various tasks. Based on their complementary advantages, this paper presents a comprehensive review and forward-looking roadmap, categorizing their mutual inspiration into LLM-enhanced evolutionary optimization and EA-enhanced LLM. Some integrated synergy methods are further introduced to exemplify the amalgamation of LLMs and EAs in various application scenarios, including neural architecture search, code generation, software engineering, and text generation. As the first comprehensive review specifically focused on the EA research in the era of LLMs, this paper provides a foundational stepping stone for understanding and harnessing the collaborative potential of LLMs and EAs. By presenting a comprehensive review, categorization, and critical analysis, we contribute to the ongoing discourse on the cross-disciplinary study of these two powerful paradigms. The identified challenges and future directions offer guidance to unlock the full potential of this innovative collaboration.",
        "comments": "evolutionary algorithm (EA), large language model (LLM), optimization problem, prompt optimization, architecture search, code generation",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10034"
    },
    {
        "doc_id": 182,
        "title": "FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder",
        "authors": [
            "Tan Dat Nguyen",
            "Ji-Hoon Kim",
            "Youngjoon Jang",
            "Jaehun Kim",
            "Joon Son Chung"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Artificial Intelligence",
            "Signal Processing"
        ],
        "abstract": "The goal of this paper is to generate realistic audio with a lightweight and fast diffusion-based vocoder, named FreGrad. Our framework consists of the following three key components: (1) We employ discrete wavelet transform that decomposes a complicated waveform into sub-band wavelets, which helps FreGrad to operate on a simple and concise feature space, (2) We design a frequency-aware dilated convolution that elevates frequency awareness, resulting in generating speech with accurate frequency information, and (3) We introduce a bag of tricks that boosts the generation quality of the proposed model. In our experiments, FreGrad achieves 3.7 times faster training time and 2.2 times faster inference speed compared to our baseline while reducing the model size by 0.6 times (only 1.78M parameters) without sacrificing the output quality. Audio samples are available at: https://mm.kaist.ac.kr/projects/FreGrad.",
        "comments": "Accepted to ICASSP 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10032"
    },
    {
        "doc_id": 183,
        "title": "Framing Analysis of Health-Related Narratives: Conspiracy versus Mainstream Media",
        "authors": [
            "Markus Reiter-Haas",
            "Beate Kl\u00f6sch",
            "Markus Hadler",
            "Elisabeth Lex"
        ],
        "subjects": [
            "Computation and Language",
            "Computers and Society"
        ],
        "abstract": "Understanding how online media frame issues is crucial due to their impact on public opinion. Research on framing using natural language processing techniques mainly focuses on specific content features in messages and neglects their narrative elements. Also, the distinction between framing in different sources remains an understudied problem. We address those issues and investigate how the framing of health-related topics, such as COVID-19 and other diseases, differs between conspiracy and mainstream websites. We incorporate narrative information into the framing analysis by introducing a novel frame extraction approach based on semantic graphs. We find that health-related narratives in conspiracy media are predominantly framed in terms of beliefs, while mainstream media tend to present them in terms of science. We hope our work offers new ways for a more nuanced frame analysis.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10030"
    },
    {
        "doc_id": 184,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 185,
        "title": "Self-Rewarding Language Models",
        "authors": [
            "Weizhe Yuan",
            "Richard Yuanzhe Pang",
            "Kyunghyun Cho",
            "Sainbayar Sukhbaatar",
            "Jing Xu",
            "Jason Weston"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal. Current approaches commonly train reward models from human preferences, which may then be bottlenecked by human performance level, and secondly these separate frozen reward models cannot then learn to improve during LLM training. In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study, this work opens the door to the possibility of models that can continually improve in both axes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10020"
    },
    {
        "doc_id": 186,
        "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
        "authors": [
            "Tongxin Yuan",
            "Zhiwei He",
            "Lingzhong Dong",
            "Yiming Wang",
            "Ruijie Zhao",
            "Tian Xia",
            "Lizhen Xu",
            "Binglin Zhou",
            "Fangqi Li",
            "Zhuosheng Zhang",
            "Rui Wang",
            "Gongshen Liu"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on LLM-generated content safety in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging safety risks given agent interaction records. R-Judge comprises 162 agent interaction records, encompassing 27 key risk scenarios among 7 application categories and 10 risk types. It incorporates human consensus on safety with annotated safety risk labels and high-quality risk descriptions. Utilizing R-Judge, we conduct a comprehensive evaluation of 8 prominent LLMs commonly employed as the backbone for agents. The best-performing model, GPT-4, achieves 72.29% in contrast to the human score of 89.38%, showing considerable room for enhancing the risk awareness of LLMs. Notably, leveraging risk descriptions as environment feedback significantly improves model performance, revealing the importance of salient safety risk feedback. Furthermore, we design an effective chain of safety analysis technique to help the judgment of safety risks and conduct an in-depth case study to facilitate future research. R-Judge is publicly available at https://github.com/Lordog/R-Judge.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10019"
    },
    {
        "doc_id": 187,
        "title": "Text Region Multiple Information Perception Network for Scene Text Detection",
        "authors": [
            "Jinzhi Zheng",
            "Libo Zhang",
            "Yanjun Wu",
            "Chen Zhao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Segmentation-based scene text detection algorithms can handle arbitrary shape scene texts and have strong robustness and adaptability, so it has attracted wide attention. Existing segmentation-based scene text detection algorithms usually only segment the pixels in the center region of the text, while ignoring other information of the text region, such as edge information, distance information, etc., thus limiting the detection accuracy of the algorithm for scene text. This paper proposes a plug-and-play module called the Region Multiple Information Perception Module (RMIPM) to enhance the detection performance of segmentation-based algorithms. Specifically, we design an improved module that can perceive various types of information about scene text regions, such as text foreground classification maps, distance maps, direction maps, etc. Experiments on MSRA-TD500 and TotalText datasets show that our method achieves comparable performance with current state-of-the-art algorithms.",
        "comments": "Accepted to ICASSP 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10017"
    },
    {
        "doc_id": 188,
        "title": "Gender Bias in Machine Translation and The Era of Large Language Models",
        "authors": [
            "Eva Vanmassenhove"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Computers and Society"
        ],
        "abstract": "This chapter examines the role of Machine Translation in perpetuating gender bias, highlighting the challenges posed by cross-linguistic settings and statistical dependencies. A comprehensive overview of relevant existing work related to gender bias in both conventional Neural Machine Translation approaches and Generative Pretrained Transformer models employed as Machine Translation systems is provided. Through an experiment using ChatGPT (based on GPT-3.5) in an English-Italian translation context, we further assess ChatGPT's current capacity to address gender bias. The findings emphasize the ongoing need for advancements in mitigating bias in Machine Translation systems and underscore the importance of fostering fairness and inclusivity in language technologies.",
        "comments": "24 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10016"
    },
    {
        "doc_id": 189,
        "title": "Towards Hierarchical Spoken Language Dysfluency Modeling",
        "authors": [
            "Jiachen Lian",
            "Gopala Anumanchipalli"
        ],
        "subjects": [
            "Computation and Language",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech dysfluency modeling is the bottleneck for both speech therapy and language learning. However, there is no AI solution to systematically tackle this problem. We first propose to define the concept of dysfluent speech and dysfluent speech modeling. We then present Hierarchical Unconstrained Dysfluency Modeling (H-UDM) approach that addresses both dysfluency transcription and detection to eliminate the need for extensive manual annotation. Furthermore, we introduce a simulated dysfluent dataset called VCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our experimental results demonstrate the effectiveness and robustness of our proposed methods in both transcription and detection tasks.",
        "comments": "2024 EACL Long (main conference). arXiv admin note: substantial text overlap with arXiv:2312.12810",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10015"
    },
    {
        "doc_id": 190,
        "title": "Optimizing Medication Decisions for Patients with Atrial Fibrillation through Path Development Network",
        "authors": [
            "Tian Xie"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Atrial fibrillation (AF) is a common cardiac arrhythmia characterized by rapid and irregular contractions of the atria. It significantly elevates the risk of strokes due to slowed blood flow in the atria, especially in the left atrial appendage, which is prone to blood clot formation. Such clots can migrate into cerebral arteries, leading to ischemic stroke. To assess whether AF patients should be prescribed anticoagulants, doctors often use the CHA2DS2-VASc scoring system. However, anticoagulant use must be approached with caution as it can impact clotting functions. This study introduces a machine learning algorithm that predicts whether patients with AF should be recommended anticoagulant therapy using 12-lead ECG data. In this model, we use STOME to enhance time-series data and then process it through a Convolutional Neural Network (CNN). By incorporating a path development layer, the model achieves a specificity of 30.6% under the condition of an NPV of 1. In contrast, LSTM algorithms without path development yield a specificity of only 2.7% under the same NPV condition.",
        "comments": "Master's thesis",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10014"
    },
    {
        "doc_id": 191,
        "title": "CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly Supervised Text-based Person Re-Identification",
        "authors": [
            "Yanwei Zheng",
            "Xinpeng Zhao",
            "Chuanlin Lan",
            "Xiaowei Zhang",
            "Bowen Huang",
            "Jibin Yang",
            "Dongxiao Yu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Weakly supervised text-based person re-identification (TPRe-ID) seeks to retrieve images of a target person using textual descriptions, without relying on identity annotations and is more challenging and practical. The primary challenge is the intra-class differences, encompassing intra-modal feature variations and cross-modal semantic gaps. Prior works have focused on instance-level samples and ignored prototypical features of each person which are intrinsic and invariant. Toward this, we propose a Cross-Modal Prototypical Contrastive Learning (CPCL) method. In practice, the CPCL introduces the CLIP model to weakly supervised TPRe-ID for the first time, mapping visual and textual instances into a shared latent space. Subsequently, the proposed Prototypical Multi-modal Memory (PMM) module captures associations between heterogeneous modalities of image-text pairs belonging to the same person through the Hybrid Cross-modal Matching (HCM) module in a many-to-many mapping fashion. Moreover, the Outlier Pseudo Label Mining (OPLM) module further distinguishes valuable outlier samples from each modality, enhancing the creation of more reliable clusters by mining implicit relationships between image-text pairs. Experimental results demonstrate that our proposed CPCL attains state-of-the-art performance on all three public datasets, with a significant improvement of 11.58%, 8.77% and 5.25% in Rank@1 accuracy on CUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively. The code is available at https://github.com/codeGallery24/CPCL.",
        "comments": "9 pages, 6 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10011"
    },
    {
        "doc_id": 192,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 193,
        "title": "Attack tree metrics are operad algebras",
        "authors": [
            "Milan Lopuha\u00e4-Zwakenberg"
        ],
        "subjects": [
            "Cryptography and Security",
            "Category Theory"
        ],
        "abstract": "Attack Trees (ATs) are a widely used tool for security analysis. ATs can be employed in quantitative security analysis through metrics, which assign a security value to an AT. Many different AT metrics exist, and there exist multiple general definitions that aim to study a wide variety of AT metrics at once. However, these all have drawbacks: they do not capture all metrics, and they do not easily generalize to extensions of ATs. In this paper, we introduce a definition of AT metrics based on category theory, specifically operad algebras. This encompasses all previous definitions of AT metrics, and is easily generalized to extensions of ATs. Furthermore, we show that under easily expressed operad-theoretic conditions, existing metric calculation algorithms can be extended in considerable generality.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10008"
    },
    {
        "doc_id": 194,
        "title": "Spintronic logic: from transducers to logic gates and circuits",
        "authors": [
            "Christoph Adelmann",
            "Florin Ciubotaru",
            "Fanfan Meng",
            "Sorin Cotofana",
            "Sebastien Couet"
        ],
        "subjects": [
            "Emerging Technologies"
        ],
        "abstract": "While magnetic solid-state memory has found commercial applications to date, magnetic logic has rather remained on a conceptual level so far. Here, we discuss open challenges of different spintronic logic approaches, which use magnetic excitations for computation. While different logic gate designs have been proposed and proof of concept experiments have been reported, no nontrivial operational spintronic circuit has been demonstrated due to many open challenges in spintronic circuit and system design. Furthermore, the integration of spintronic circuits in CMOS systems will require the usage of transducers between the electric (CMOS) and magnetic domains. We show that these transducers can limit the performance as well as the energy consumption of hybrid CMOS-spintronic systems. Hence, the optimization of transducer efficiency will be a major step towards competitive spintronic logic system.",
        "comments": "This work has received funding from the European Union's Horizon 2020 research and innovation program within the project CHIRON (grant agreement no. 801055) as well as from the Horizon Europe research and innovation program within the project SPIDER (grant agreement no. 101070417)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10007"
    },
    {
        "doc_id": 195,
        "title": "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation",
        "authors": [
            "Kohei Uehara",
            "Nabarun Goswami",
            "Hanqin Wang",
            "Toshiaki Baba",
            "Kohtaro Tanaka",
            "Tomohiro Hashimoto",
            "Kai Wang",
            "Rei Ito",
            "Takagi Naoya",
            "Ryo Umagami",
            "Yingyi Wen",
            "Tanachai Anakewat",
            "Tatsuya Harada"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language"
        ],
        "abstract": "The increasing demand for intelligent systems capable of interpreting and reasoning about visual content requires the development of Large Multi-Modal Models (LMMs) that are not only accurate but also have explicit reasoning capabilities. This paper presents a novel approach to imbue an LMM with the ability to conduct explicit reasoning based on visual content and textual instructions. We introduce a system that can ask a question to acquire necessary knowledge, thereby enhancing the robustness and explicability of the reasoning process. Our method comprises the development of a novel dataset generated by a Large Language Model (LLM), designed to promote chain-of-thought reasoning combined with a question-asking mechanism. We designed an LMM, which has high capabilities on region awareness to address the intricate requirements of image-text alignment. The model undergoes a three-stage training phase, starting with large-scale image-text alignment using a large-scale datasets, followed by instruction tuning, and fine-tuning with a focus on chain-of-thought reasoning. The results demonstrate a stride toward a more robust, accurate, and interpretable LMM, capable of reasoning explicitly and seeking information proactively when confronted with ambiguous visual input.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10005"
    },
    {
        "doc_id": 196,
        "title": "Distantly Supervised Morpho-Syntactic Model for Relation Extraction",
        "authors": [
            "Nicolas Gutehrl\u00e9",
            "Iana Atanassova"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "The task of Information Extraction (IE) involves automatically converting unstructured textual content into structured data. Most research in this field concentrates on extracting all facts or a specific set of relationships from documents. In this paper, we present a method for the extraction and categorisation of an unrestricted set of relationships from text. Our method relies on morpho-syntactic extraction patterns obtained by a distant supervision method, and creates Syntactic and Semantic Indices to extract and classify candidate graphs. We evaluate our approach on six datasets built on Wikidata and Wikipedia. The evaluation shows that our approach can achieve Precision scores of up to 0.85, but with lower Recall and F1 scores. Our approach allows to quickly create rule-based systems for Information Extraction and to build annotated datasets to train machine-learning and deep-learning based classifiers.",
        "comments": "Preprint",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10002"
    },
    {
        "doc_id": 197,
        "title": "BPDO:Boundary Points Dynamic Optimization for Arbitrary Shape Scene Text Detection",
        "authors": [
            "Jinzhi Zheng",
            "Libo Zhang",
            "Yanjun Wu",
            "Chen Zhao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Arbitrary shape scene text detection is of great importance in scene understanding tasks. Due to the complexity and diversity of text in natural scenes, existing scene text algorithms have limited accuracy for detecting arbitrary shape text. In this paper, we propose a novel arbitrary shape scene text detector through boundary points dynamic optimization(BPDO). The proposed model is designed with a text aware module (TAM) and a boundary point dynamic optimization module (DOM). Specifically, the model designs a text aware module based on segmentation to obtain boundary points describing the central region of the text by extracting a priori information about the text region. Then, based on the idea of deformable attention, it proposes a dynamic optimization model for boundary points, which gradually optimizes the exact position of the boundary points based on the information of the adjacent region of each boundary point. Experiments on CTW-1500, Total-Text, and MSRA-TD500 datasets show that the model proposed in this paper achieves a performance that is better than or comparable to the state-of-the-art algorithm, proving the effectiveness of the model.",
        "comments": "Accepted to ICASSP 2024",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09997"
    },
    {
        "doc_id": 198,
        "title": "Developing an AI-based Integrated System for Bee Health Evaluation",
        "authors": [
            "Andrew Liang"
        ],
        "subjects": [
            "Machine Learning",
            "Computer Vision and Pattern Recognition",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Honey bees pollinate about one-third of the world's food supply, but bee colonies have alarmingly declined by nearly 40% over the past decade due to several factors, including pesticides and pests. Traditional methods for monitoring beehives, such as human inspection, are subjective, disruptive, and time-consuming. To overcome these limitations, artificial intelligence has been used to assess beehive health. However, previous studies have lacked an end-to-end solution and primarily relied on data from a single source, either bee images or sounds. This study introduces a comprehensive system consisting of bee object detection and health evaluation. Additionally, it utilized a combination of visual and audio signals to analyze bee behaviors. An Attention-based Multimodal Neural Network (AMNN) was developed to adaptively focus on key features from each type of signal for accurate bee health assessment. The AMNN achieved an overall accuracy of 92.61%, surpassing eight existing single-signal Convolutional Neural Networks and Recurrent Neural Networks. It outperformed the best image-based model by 32.51% and the top sound-based model by 13.98% while maintaining efficient processing times. Furthermore, it improved prediction robustness, attaining an F1-score higher than 90% across all four evaluated health conditions. The study also shows that audio signals are more reliable than images for assessing bee health. By seamlessly integrating AMNN with image and sound data in a comprehensive bee health monitoring system, this approach provides a more efficient and non-invasive solution for the early detection of bee diseases and the preservation of bee colonies.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09988"
    },
    {
        "doc_id": 199,
        "title": "A-KIT: Adaptive Kalman-Informed Transformer",
        "authors": [
            "Nadav Cohen",
            "Itzik Klein"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Systems and Control"
        ],
        "abstract": "The extended Kalman filter (EKF) is a widely adopted method for sensor fusion in navigation applications. A crucial aspect of the EKF is the online determination of the process noise covariance matrix reflecting the model uncertainty. While common EKF implementation assumes a constant process noise, in real-world scenarios, the process noise varies, leading to inaccuracies in the estimated state and potentially causing the filter to diverge. To cope with such situations, model-based adaptive EKF methods were proposed and demonstrated performance improvements, highlighting the need for a robust adaptive approach. In this paper, we derive and introduce A-KIT, an adaptive Kalman-informed transformer to learn the varying process noise covariance online. The A-KIT framework is applicable to any type of sensor fusion. Here, we present our approach to nonlinear sensor fusion based on an inertial navigation system and Doppler velocity log. By employing real recorded data from an autonomous underwater vehicle, we show that A-KIT outperforms the conventional EKF by more than 49.5% and model-based adaptive EKF by an average of 35.4% in terms of position accuracy.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09987"
    },
    {
        "doc_id": 200,
        "title": "An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)",
        "authors": [
            "Garvit Arora",
            "Shubhangi Shubhangi",
            "Ying Wu",
            "Xuan Mei"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10162"
    },
    {
        "doc_id": 201,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 202,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 203,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 204,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 205,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 206,
        "title": "Mean-Field SDEs driven by $G$-Brownian Motion",
        "authors": [
            "Karl-Wilhelm Georg Bollweg",
            "Thilo Meyer-Brandis"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We extend the notion of mean-field SDEs to SDEs driven by $G$-Brownian motion. More precisely, we consider a $G$-SDE where the coefficients depend not only on time and the current state but also on the solution as random variable.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09113"
    },
    {
        "doc_id": 207,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 208,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 209,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 210,
        "title": "Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Xi Chen",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "subjects": [
            "General Finance",
            "Cryptography and Security"
        ],
        "abstract": "Lido, the leading Liquid Staking Derivative (LSD) provider on Ethereum, allows users to stake an arbitrary amount of ETH to receive stETH, which can be integrated with Decentralized Finance (DeFi) protocols such as Aave. The composability between Lido and Aave enables a novel strategy called \"leverage staking\", where users stake ETH on Lido to acquire stETH, utilize stETH as collateral on Aave to borrow ETH, and then restake the borrowed ETH on Lido. Users can iteratively execute this process to optimize potential returns based on their risk profile.\n  This paper systematically studies the opportunities and risks associated with leverage staking. We are the first to formalize the leverage staking strategy within the Lido-Aave ecosystem. Our empirical study identifies 262 leverage staking positions on Ethereum, with an aggregated staking amount of 295,243 ETH (482M USD). We discover that 90.13% of leverage staking positions have achieved higher returns than conventional staking. Furthermore, we perform stress tests to evaluate the risk introduced by leverage staking under extreme conditions. We find that leverage staking significantly amplifies the risk of cascading liquidations. We hope this paper can inform and encourage the development of robust risk management approaches to protect the Lido-Aave LSD ecosystem.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08610"
    },
    {
        "doc_id": 211,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 212,
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We consider two data driven approaches, Reinforcement Learning (RL) and Deep Trajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call option without and with transaction cost according to a quadratic hedging P&L objective at maturity (\"variance-optimal hedging\" or \"final quadratic hedging\"). We study the performance of the two approaches under various market environments (modeled via the Black-Scholes and/or the log-normal SABR model) to understand their advantages and limitations. Without transaction costs and in the Black-Scholes model, both approaches match the performance of the variance-optimal Delta hedge. In the log-normal SABR model without transaction costs, they match the performance of the variance-optimal Barlett's Delta hedge. Agents trained on Black-Scholes trajectories with matching initial volatility but used on SABR trajectories match the performance of Bartlett's Delta hedge in average cost, but show substantially wider variance. To apply RL approaches to these problems, P&L at maturity is written as sum of step-wise contributions and variants of RL algorithms are implemented and used that minimize expectation of second moments of such sums.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.07996",
        "date": "20 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08600"
    },
    {
        "doc_id": 213,
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Organizations use cash management models to control balances to both avoid overdrafts and obtain a profit from short-term investments. Most management models are based on control bounds which are derived from the assumption of a particular cash flow probability distribution. In this paper, we relax this strong assumption to fit cash management models to data by means of stochastic and linear programming. We also introduce ensembles of random cash management models which are built by randomly selecting a subsequence of the original cash flow data set. We illustrate our approach by means of a real case study showing that a small random sample of data is enough to fit sufficiently good bound-based models.",
        "comments": "19 pages,6 figures, 1 table",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08548"
    },
    {
        "doc_id": 214,
        "title": "Dynamic portfolio selection under generalized disappointment aversion",
        "authors": [
            "Zongxia Liang",
            "Sheng Wang",
            "Jianming Xia",
            "Fengyi Yuan"
        ],
        "subjects": [
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "This paper addresses the continuous-time portfolio selection problem under generalized disappointment aversion (GDA). The implicit definition of the certainty equivalent within GDA preferences introduces time inconsistency to this problem. We provide the sufficient and necessary conditions for a strategy to be an equilibrium by a fully nonlinear ordinary differential equation (ODE). Through an exploration of the existence and uniqueness of solution to the ODE, we establish the existence and uniqueness of the equilibrium. Our findings indicate that under disappointment aversion (DA) preferences, non-participation in the stock market is the unique equilibrium. The numerical analysis reveals that, under GDA preferences, the investment proportion in the stock market consistently remains smaller than the investment proportion under the classical Expected Utility (EU) theory.",
        "comments": "27 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08323"
    },
    {
        "doc_id": 215,
        "title": "Do backrun auctions protect traders?",
        "authors": [
            "Andrew W. Macpherson"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Distributed, Parallel, and Cluster Computing",
            "Computer Science and Game Theory"
        ],
        "abstract": "We study a new \"laminated\" queueing model for orders on batched trading venues such as decentralised exchanges. The model aims to capture and generalise transaction queueing infrastructure that has arisen to organise MEV activity on public blockchains such as Ethereum, providing convenient channels for sophisticated agents to extract value by acting on end-user order flow by performing arbitrage and related HFT activities. In our model, market orders are interspersed with orders created by arbitrageurs that under idealised conditions reset the marginal price to a global equilibrium between each trade, improving predictability of execution for liquidity traders.\n  If an arbitrageur has a chance to land multiple opportunities in a row, he may attempt to manipulate the execution price of the intervening market order by a probabilistic blind sandwiching strategy. To study how bad this manipulation can get, we introduce and bound a price manipulation coefficient that measures the deviation from global equilibrium of local pricing quoted by a rational arbitrageur. We exhibit cases in which this coefficient is well approximated by a \"zeta value' with interpretable and empirically measurable parameters.",
        "comments": "Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08302"
    },
    {
        "doc_id": 216,
        "title": "Optimal Insurance to Maximize Exponential Utility when Premium is Computed by a Convex Functional",
        "authors": [
            "Jingyi Cao",
            "Dongchen Li",
            "Virginia R. Young",
            "Bin Zou"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Risk Management"
        ],
        "abstract": "We find the optimal indemnity to maximize the expected utility of terminal wealth of a buyer of insurance whose preferences are modeled by an exponential utility. The insurance premium is computed by a convex functional. We obtain a necessary condition for the optimal indemnity; then, because the candidate optimal indemnity is given implicitly, we use that necessary condition to develop a numerical algorithm to compute it. We prove that the numerical algorithm converges to a unique indemnity that, indeed, equals the optimal policy. We also illustrate our results with numerical examples.",
        "comments": "12 pages, 3 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08094"
    },
    {
        "doc_id": 217,
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option Pricing",
        "authors": [
            "Ce Wang"
        ],
        "subjects": [
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two regression models fitted at each time step to price game options. Although the original LSMC can be used to price game options with an enlarged range of path in regression and a modified cashflow updating rule, we identified a drawback of such approach, which motivated us to propose our approach. We implemented numerical examples with benchmarks using binomial tree and numerical PDE, and it showed that our method produces more reliable results comparing to the original LSMC.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08093"
    },
    {
        "doc_id": 218,
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "authors": [
            "Shubham Singh",
            "Mayur Bhat"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Pricing of Securities"
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "comments": "12 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08077"
    },
    {
        "doc_id": 219,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 220,
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "authors": [
            "Samuel Vandak",
            "Geoffrey Goodell"
        ],
        "subjects": [
            "Computers and Society",
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "comments": "34 pages, 19 figures, 5 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07682"
    },
    {
        "doc_id": 221,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 222,
        "title": "Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Design/methodology/approach This research evaluated the databases of SQL, No-SQL and graph databases to compare and contrast efficiency and performance. To perform this experiment the data were collected from multiple sources including stock price and financial news. Python is used as an interface to connect and query databases (to create database structures according to the feed file structure, to load data into tables, objects, to read data , to connect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM (Large language model) including RAG (Retrieval Augmented Generation) with Machine Learning, deep learning, NLP (natural language processing) or Decision Analytics are computationally expensive. Finding a better option to consume less resources and time to get the result. Findings The Graph database of ESG (Environmental, Social and Governance) is comparatively better and can be considered for extended analytics to integrate ESG in business and investment. Practical implications A graph ML with a RAG architecture model can be introduced as a new framework with less computationally expensive LLM application in the equity filtering process for portfolio management. Originality/value Filtering out selective stocks out of two thousand or more listed companies in any stock exchange for active investment, consuming less resource consumption especially memory and energy to integrate artificial intelligence and ESG in business and investment.",
        "comments": "10 pages, 17 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07483"
    },
    {
        "doc_id": 223,
        "title": "Herd Behavior in Optimal Investment: A Dual-Agent Approach with Investment Opinion and Rational Decision Decomposition",
        "authors": [
            "Huisheng Wang",
            "H. Vicky Zhao"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control",
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "In this paper, we study the optimal investment problem involving two agents, where the decision of one agent is influenced by the other. To measure the distance between two agents' decisions, we introduce the average deviation. We formulate the stochastic optimal control problem considering herd behavior and derive the analytical solution through the variational method. We theoretically analyze the impact of users' herd behavior on the optimal decision by decomposing it into their rational decisions, which is called the rational decision decomposition. Furthermore, to quantify the preference for their rational decision over that of the other agent, we introduce the agent's investment opinion. Our study is validated through simulations on real stock data.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07183"
    },
    {
        "doc_id": 224,
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Chris Tanner"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Research in quantitative reasoning within the financial domain indeed necessitates the use of realistic tasks and data, primarily because of the significant impact of decisions made in business and finance. Financial professionals often interact with documents hundreds of pages long, but most research datasets drastically reduce this context length. To address this, we introduce a long-document financial QA task. We augment 7,621 questions from the existing FinQA dataset with full-document context, extending the average context length for each question from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and long-context language models on the augmented data. Our results show that DocFinQA provides challenges for even the strongest, state-of-the-art systems.",
        "comments": "13 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06915"
    },
    {
        "doc_id": 225,
        "title": "A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assessed in a series of numerical experiments involving the Merton jump-diffusion model.",
        "comments": "16 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06740"
    },
    {
        "doc_id": 226,
        "title": "Equity auction dynamics: latent liquidity models with activity acceleration",
        "authors": [
            "Mohammed Salek",
            "Damien Challet",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Finance"
        ],
        "abstract": "Equity auctions display several distinctive characteristics in contrast to continuous trading. As the auction time approaches, the rate of events accelerates causing a substantial liquidity buildup around the indicative price. This, in turn, results in a reduced price impact and decreased volatility of the indicative price. In this study, we adapt the latent/revealed order book framework to the specifics of equity auctions. We provide precise measurements of the model parameters, including order submissions, cancellations, and diffusion rates. Our setup allows us to describe the full dynamics of the average order book during closing auctions in Euronext Paris. These findings support the relevance of the latent liquidity framework in describing limit order book dynamics. Lastly, we analyze the factors contributing to a sub-diffusive indicative price and demonstrate the absence of indicative price predictability.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06724"
    },
    {
        "doc_id": 227,
        "title": "SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks",
        "authors": [
            "Alessio Brini",
            "Giacomo Toscano"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents financial assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with high-frequency prices of the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net shows improved accuracy, compared to alternative econometric and machine-learning-based models. Further, our results show that SpotV2Net maintains accuracy when performing intraday multi-step forecasts. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer, a model-agnostic interpretability tool and thereby uncover subgraphs that are critical to a node's predictions.",
        "comments": "34 pages, 9 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06249"
    },
    {
        "doc_id": 228,
        "title": "CNN-DRL for Scalable Actions in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Haseebullah Jumakhan",
            "Amir Mirzaeinia"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "The published MLP-based DRL in finance has difficulties in learning the dynamics of the environment when the action scale increases. If the buying and selling increase to one thousand shares, the MLP agent will not be able to effectively adapt to the environment. To address this, we designed a CNN agent that concatenates the data from the last ninety days of the daily feature vector to create the CNN input matrix. Our extensive experiments demonstrate that the MLP-based agent experiences a loss corresponding to the initial environment setup, while our designed CNN remains stable, effectively learns the environment, and leads to an increase in rewards.",
        "comments": "10th Annual Conf. on Computational Science & Computational Intelligence",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06179"
    },
    {
        "doc_id": 229,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 230,
        "title": "Multimodal Gen-AI for Fundamental Investment Research",
        "authors": [
            "Lezhi Li",
            "Ting-Yu Chang",
            "Hai Wang"
        ],
        "subjects": [
            "General Finance",
            "Machine Learning"
        ],
        "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.",
        "comments": " ",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06164"
    },
    {
        "doc_id": 231,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 232,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 233,
        "title": "StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks",
        "authors": [
            "Bohan Ma",
            "Yiheng Wang",
            "Yuchao Lu",
            "Tianzixuan Hu",
            "Jinling Xu",
            "Patrick Houlihan"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Machine Learning"
        ],
        "abstract": "Amidst ongoing market recalibration and increasing investor optimism, the U.S. stock market is experiencing a resurgence, prompting the need for sophisticated tools to protect and grow portfolios. Addressing this, we introduce \"Stockformer,\" a cutting-edge deep learning framework optimized for swing trading, featuring the TopKDropout method for enhanced stock selection. By integrating STL decomposition and self-attention networks, Stockformer utilizes the S&P 500's complex data to refine stock return predictions. Our methodology entailed segmenting data for training and validation (January 2021 to January 2023) and testing (February to June 2023). During testing, Stockformer's predictions outperformed ten industry models, achieving superior precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a remarkable accuracy rate of 62.39% in detecting market trends. In our backtests, Stockformer's swing trading strategy yielded a cumulative return of 13.19% and an annualized return of 30.80%, significantly surpassing current state-of-the-art models. Stockformer has emerged as a beacon of innovation in these volatile times, offering investors a potent tool for market forecasting. To advance the field and foster community collaboration, we have open-sourced Stockformer, available at https://github.com/Eric991005/Stockformer.",
        "comments": "Currently under consideration for publication in the International Journal of Forecasting",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06139"
    },
    {
        "doc_id": 234,
        "title": "Quantum Probability Theoretic Asset Return Modeling: A Novel Schr\u00f6dinger-Like Trading Equation and Multimodal Distribution",
        "authors": [
            "Li Lin"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "Quantum theory provides a comprehensive framework for quantifying uncertainty, often applied in quantum finance to explore the stochastic nature of asset returns. This perspective likens returns to microscopic particle motion, governed by quantum probabilities akin to physical laws. However, such approaches presuppose specific microscopic quantum effects in return changes, a premise criticized for lack of guarantee. This paper diverges by asserting that quantum probability is a mathematical extension of classical probability to complex numbers. It isn't exclusively tied to microscopic quantum phenomena, bypassing the need for quantum effects in returns.By directly linking quantum probability's mathematical structure to traders' decisions and market behaviors, it avoids assuming quantum effects for returns and invoking the wave function. The complex phase of quantum probability, capturing transitions between long and short decisions while considering information interaction among traders, offers an inherent advantage over classical probability in characterizing the multimodal distribution of asset returns.Utilizing Fourier decomposition, we derive a Schr\u00f6dinger-like trading equation, where each term explicitly corresponds to implications of market trading. The equation indicates discrete energy levels in financial trading, with returns following a normal distribution at the lowest level. As the market transitions to higher trading levels, a phase shift occurs in the return distribution, leading to multimodality and fat tails. Empirical research on the Chinese stock market supports the existence of energy levels and multimodal distributions derived from this quantum probability asset returns model.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05823"
    },
    {
        "doc_id": 235,
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "authors": [
            "Frank Xing"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Multiagent Systems",
            "General Finance"
        ],
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
        "comments": "15 pages",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05799"
    },
    {
        "doc_id": 236,
        "title": "Super-hedging-pricing formulas and Immediate-Profit arbitrage for market models under random horizon",
        "authors": [
            "Tahir Choulli",
            "Emmanuel Lepinette"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Probability",
            "Pricing of Securities"
        ],
        "abstract": "In this paper, we consider the discrete-time setting, and the market model described by (S,F,T)$. Herein F is the ``public\" flow of information which is available to all agents overtime, S is the discounted price process of d-tradable assets, and T is an arbitrary random time whose occurrence might not be observable via F. Thus, we consider the larger flow G which incorporates F and makes T an observable random time. This framework covers the credit risk theory setting, the life insurance setting and the setting of employee stock option valuation. For the stopped model (S^T,G) and for various vulnerable claims, based on this model, we address the super-hedging pricing valuation problem and its intrinsic Immediate-Profit arbitrage (IP hereafter for short). Our first main contribution lies in singling out the impact of change of prior and/or information on conditional essential supremum, which is a vital tool in super-hedging pricing. The second main contribution consists of describing as explicit as possible how the set of super-hedging prices expands under the stochasticity of T and its risks, and we address the IP arbitrage for (S^T,G) as well. The third main contribution resides in elaborating as explicit as possible pricing formulas for vulnerable claims, and singling out the various informational risks in the prices' dynamics.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05713"
    },
    {
        "doc_id": 237,
        "title": "Boundary conditions at infinity for Black-Scholes equations",
        "authors": [
            "Yukihiro Tsuzuki"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance"
        ],
        "abstract": "We propose numerical procedures for computing the prices of forward contracts where the underlying asset price is a Markovian local martingale. If the underlying process is a strict local martingale, multiple solutions exist for the corresponding Black-Scholes equations, and the derivative prices are characterized as the minimal solutions. Our prices are upper and lower bounds obtained using numerical methods on a finite grid under the respective boundary conditions. These bounds and the boundary values converge to the exact value as the underlying price approaches infinity. The proposed procedures are demonstrated through numerical tests.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05549"
    },
    {
        "doc_id": 238,
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "authors": [
            "Baptiste Lefort",
            "Eric Benhamou",
            "Jean-Jacques Ohana",
            "David Saltiel",
            "Beatrice Guez",
            "Damien Challet"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence"
        ],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05447"
    },
    {
        "doc_id": 239,
        "title": "An adaptive network-based approach for advanced forecasting of cryptocurrency values",
        "authors": [
            "Ali Mehrban",
            "Pegah Ahadian"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This paper describes an architecture for predicting the price of cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy Inference System (ANFIS). Historical data of cryptocurrencies and indexes that are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D), and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach the data are hybrid and backpropagation algorithms, as well as grid partition, subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which are used in data clustering. The architectural performance designed in this paper has been compared with different inputs and neural network models in terms of statistical evaluation criteria. Finally, the proposed method can predict the price of digital currencies in a short time.",
        "comments": "11 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05441"
    },
    {
        "doc_id": 240,
        "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification",
        "authors": [
            "Zinuo You",
            "Pengju Zhang",
            "Jin Zheng",
            "John Cartlidge"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).",
        "comments": "5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05430"
    },
    {
        "doc_id": 241,
        "title": "Introduction of L0 norm and application of L1 and C1 norm in the study of time-series",
        "authors": [
            "Victor Ujaldon Garcia"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Four markets are considered: Cryptocurrencies / South American exchange rate / Spanish Banking indices and European Indices and studied using TDA (Topological Data Analysis) tools. These tools are used to predict and showcase both strengths and weakness of the current TDA tools. In this paper a new tool $L0$ norm is defined and complemented with the already existing $C1$ norm.",
        "comments": "14 pages 8 figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05423"
    },
    {
        "doc_id": 242,
        "title": "Multiple-bubble testing in the cryptocurrency market: a case study of bitcoin",
        "authors": [
            "Sanaz Behzadi",
            "Mahmonir Bayanati",
            "Hamed Nozari"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Economic periods and financial crises have highlighted the importance of evaluating financial markets to investors and researchers in recent decades.",
        "comments": " ",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05417"
    },
    {
        "doc_id": 243,
        "title": "On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors",
        "authors": [
            "Xinshuai Dong",
            "Haoyue Dai",
            "Yewen Fan",
            "Songyao Jin",
            "Sathyamoorthy Rajendran",
            "Kun Zhang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Financial data is generally time series in essence and thus suffers from three fundamental issues: the mismatch in time resolution, the time-varying property of the distribution - nonstationarity, and causal factors that are important but unknown/unobserved. In this paper, we follow a causal perspective to systematically look into these three demons in finance. Specifically, we reexamine these issues in the context of causality, which gives rise to a novel and inspiring understanding of how the issues can be addressed. Following this perspective, we provide systematic solutions to these problems, which hopefully would serve as a foundation for future research in the area.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05414"
    },
    {
        "doc_id": 244,
        "title": "RIVCoin: an alternative, integrated, CeFi/DeFi-Vaulted Cryptocurrency",
        "authors": [
            "Roberto Rivera",
            "Guido Rocco",
            "Massimiliano Marzo",
            "Enrico Talin"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "This whitepaper introduces RIVCoin, a cryptocurrency built on Cosmos, fully stabilized by a diversified portfolio of both CeFi and DeFi assets, available in a digital, non-custodial wallet called RIV Wallet, that aims to provide Users an easy way to access the cryptocurrency markets, compliant to the strictest AML laws and regulations up to date. The token is a cryptocurrency at any time stabilized by a basket of assets: reserves are invested in a portfolio composed long term by 50% of CeFi assets, comprised of Fixed Income, Equity, Mutual and Hedge Funds and 50% of diversified strategies focused on digital assets, mainly staking and LP farming on the major, battle tested DeFi protocols. The cryptocurrency, as well as the dollar before Bretton Woods, is always fully stabilized by vaulted proof of assets: it is born and managed as a decentralized token, minted by a Decentralized Autonomous Organization, and entirely stabilized by assets evaluated by professional independent third parties. Users will trade, pool, and exchange the token without any intermediary, being able to merge them into a Liquidity Pool whose rewards will be composed by both the trading fees and the liquidity rewards derived from the reserve's seigniorage.\n  Users who wish and decide to pool RIVCoin in the Liquidity Pool will receive additional RIVCoin for themselves, and new RIVCoin are minted when the reserves increase in value or in case of purchase of new RIVCoin. The proposed model allows for alignment of incentives: decreasing the risk exposure by wealthier Users, but implicitly increasing that of smaller ones to a level perceived by them as still sustainable. Users indirectly benefit from the access to the rewards of sophisticated cryptocurrency portfolios hitherto precluded to them, without this turning into a disadvantage for the wealthy User.",
        "comments": " ",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05393"
    },
    {
        "doc_id": 245,
        "title": "Optimal Linear Signal: An Unsupervised Machine Learning Framework to Optimize PnL with Linear Signals",
        "authors": [
            "Pierre Renucci"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "This study presents an unsupervised machine learning approach for optimizing Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL generated from signals constructed linearly from exogenous variables. The methodology employs a linear relationship between exogenous variables and the trading signal, with the objective of maximizing the Sharpe Ratio through parameter optimization. Empirical application on an ETF representing U.S. Treasury bonds demonstrates the model's effectiveness, supported by regularization techniques to mitigate overfitting. The study concludes with potential avenues for further development, including generalized time steps and enhanced corrective terms.",
        "comments": "The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05337"
    },
    {
        "doc_id": 246,
        "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks",
        "authors": [
            "Zhang Chern Lee",
            "Wei Yun Tan",
            "Hoong Khen Koo",
            "Wilson Pang"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio",
        "comments": "19 pages, 5 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05264"
    },
    {
        "doc_id": 247,
        "title": "A Mean Field Game between Informed Traders and a Broker",
        "authors": [
            "Philippe Bergault",
            "Leandro S\u00e1nchez-Betancourt"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Optimization and Control"
        ],
        "abstract": "We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G\u00e2teaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05257"
    },
    {
        "doc_id": 248,
        "title": "On the Martingale Schr\u00f6dinger Bridge between Two Distributions",
        "authors": [
            "Marcel Nutz",
            "Johannes Wiesel"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We study a martingale Schr\u00f6dinger bridge problem: given two probability distributions, find their martingale coupling with minimal relative entropy. Our main result provides Schr\u00f6dinger potentials for this coupling. Namely, under certain conditions, the log-density of the optimal coupling is given by a triplet of real functions representing the marginal and martingale constraints. The potentials are also described as the solution of a dual problem.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05209"
    },
    {
        "doc_id": 249,
        "title": "Markowitz Portfolio Construction at Seventy",
        "authors": [
            "Stephen Boyd",
            "Kasper Johansson",
            "Ronald Kahn",
            "Philipp Schiele",
            "Thomas Schmelzer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "More than seventy years ago Harry Markowitz formulated portfolio construction as an optimization problem that trades off expected return and risk, defined as the standard deviation of the portfolio returns. Since then the method has been extended to include many practical constraints and objective terms, such as transaction cost or leverage limits. Despite several criticisms of Markowitz's method, for example its sensitivity to poor forecasts of the return statistics, it has become the dominant quantitative method for portfolio construction in practice. In this article we describe an extension of Markowitz's method that addresses many practical effects and gracefully handles the uncertainty inherent in return statistics forecasting. Like Markowitz's original formulation, the extension is also a convex optimization problem, which can be solved with high reliability and speed.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05080"
    },
    {
        "doc_id": 250,
        "title": "Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin",
        "authors": [
            "Didier Sornette",
            "Yu Zhang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least $200$ weeks with an exponent approximately equal to $0.9$, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between $0.3$ and $2.5$ depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to $-1.5$, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04702"
    },
    {
        "doc_id": 251,
        "title": "Proof of Efficient Liquidity: A Staking Mechanism for Capital Efficient Liquidity",
        "authors": [
            "Arman Abgaryan",
            "Utkarsh Sharma",
            "Joshua Tobkin"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "The Proof of Efficient Liquidity (PoEL) protocol, designed for specialised Proof of Stake (PoS) consensus-based blockchain infrastructures that incorporate intrinsic DeFi applications, aims to support sustainable liquidity bootstrapping and network security. This innovative mechanism efficiently utilises budgeted staking rewards to attract and sustain liquidity through a risk structuring engine and incentive allocation strategy, both of which are designed to maximise capital efficiency. The proposed protocol seeks to serve the dual objective of - (i) capital creation, by efficiently attracting risk capital, and maximising its operational utility for intrinsic DeFi applications, thereby asserting sustainability; and (ii) enhancing the adopting blockchain network's economic security, by augmenting their staking (PoS) mechanism with a harmonious layer seeking to attract a diversity of digital assets. Finally, in the appendix, we seek to generalise the financial incentivisation protocol to the notion of service fee credits, such that it utilises the network's auxiliary services as a means to propagate incentives to attract liquidity and facilitate the network to achieve the critical mass of usage necessary for sustained operations and growth.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04521"
    },
    {
        "doc_id": 252,
        "title": "Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks",
        "authors": [
            "Zan Yu",
            "Lianzeng Zhang"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Risk Management"
        ],
        "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.",
        "comments": "23 pages; 5 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04378"
    },
    {
        "doc_id": 253,
        "title": "Expiring Assets in Automated Market Makers",
        "authors": [
            "Kenan Wood",
            "Maurice Herlihy",
            "Hammurabi Mendes",
            "Jonad Pulaj"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Mathematical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "An automated market maker (AMM) is a state machine that manages pools of assets, allowing parties to buy and sell those assets according to a fixed mathematical formula. AMMs are typically implemented as smart contracts on blockchains, and its prices are kept in line with the overall market price by arbitrage: if the AMM undervalues an asset with respect to the market, an \"arbitrageur\" can make a risk-free profit by buying just enough of that asset to bring the AMM's price back in line with the market.\n  AMMs, however, are not designed for assets that expire: that is, assets that cannot be produced or resold after a specified date. As assets approach expiration, arbitrage may not be able to reconcile supply and demand, and the liquidity providers that funded the AMM may have excessive exposure to risk due to rapid price variations.\n  This paper formally describes the design of a decentralized exchange (DEX) for assets that expire, combining aspects of AMMs and limit-order books. We ensure liveness and market clearance, providing mechanisms for liquidity providers to control their exposure to risk and adjust prices dynamically in response to situations where arbitrage may fail.",
        "comments": "33 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04289"
    },
    {
        "doc_id": 254,
        "title": "Economic Forces in Stock Returns",
        "authors": [
            "Yue Chen",
            "Mohan Li"
        ],
        "subjects": [
            "General Economics",
            "Statistical Finance"
        ],
        "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.",
        "comments": "11 pages, 10 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04132"
    },
    {
        "doc_id": 255,
        "title": "Decomposing Smiles: A Time Change Approach",
        "authors": [
            "Liexin Cheng",
            "Xue Cheng"
        ],
        "subjects": [
            "Pricing of Securities",
            "Mathematical Finance"
        ],
        "abstract": "We develop a novel time-change approach to study the shape of implied volatility smiles. The method is applicable to common semimartingale models, including jump-diffusion, rough volatility and infinite activity models. We approximate the at-the-money skew and curvature with an improved moment-based formula. The moments are further explicitly computed under a time change framework. The limiting skew and curvature for several models are considered. We also test the accuracy of the short-term approximation results on models via numerical methods and on empirical data. Finally, we apply the method to the calibration problem.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03776"
    },
    {
        "doc_id": 256,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "subjects": [
            "Computational Finance",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation with S&P 100 stocks, MarketSenseAI outperformed the benchmark index by 13%, achieving returns up to 40%, while maintaining a risk profile comparable to the market. These results demonstrate the efficacy of Large Language Models in complex financial decision-making and mark a significant advancement in the integration of AI into financial analysis and investment strategies. This research contributes to the financial AI field, presenting an innovative approach and underscoring the transformative potential of AI in revolutionizing traditional financial analysis investment methodologies.",
        "comments": "15 pages, 12 figures, 12 tables",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03737"
    },
    {
        "doc_id": 257,
        "title": "Structured factor copulas for modeling the systemic risk of European and United States banks",
        "authors": [
            "Hoang Nguyen",
            "Audron\u0117 Virbickait\u0117",
            "M. Concepci\u00f3n Aus\u00edn",
            "Pedro Galeano"
        ],
        "subjects": [
            "Statistical Finance",
            "Applications"
        ],
        "abstract": "In this paper, we employ Credit Default Swaps (CDS) to model the joint and conditional distress probabilities of banks in Europe and the U.S. using factor copulas. We propose multi-factor, structured factor, and factor-vine models where the banks in the sample are clustered according to their geographic location. We find that within each region, the co-dependence between banks is best described using both, systematic and idiosyncratic, financial contagion channels. However, if we consider the banking system as a whole, then the systematic contagion channel prevails, meaning that the distress probabilities are driven by a latent global factor and region-specific factors. In all cases, the co-dependence structure of bank CDS spreads is highly correlated in the tail. The out-of-sample forecasts of several measures of systematic risk allow us to identify the periods of distress in the banking sector over the recent years including the COVID-19 pandemic, the interest rate hikes in 2022, and the banking crisis in 2023.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03443"
    },
    {
        "doc_id": 258,
        "title": "Modelling and Predicting the Conditional Variance of Bitcoin Daily Returns: Comparsion of Markov Switching GARCH and SV Models",
        "authors": [
            "Dennis Koch",
            "Vahidin Jeleskovic",
            "Zahid I. Younas"
        ],
        "subjects": [
            "Statistical Finance",
            "Risk Management"
        ],
        "abstract": "This paper introduces a unique and valuable research design aimed at analyzing Bitcoin price volatility. To achieve this, a range of models from the Markov Switching-GARCH and Stochastic Autoregressive Volatility (SARV) model classes are considered and their out-of-sample forecasting performance is thoroughly examined. The paper provides insights into the rationale behind the recommendation for a two-stage estimation approach, emphasizing the separate estimation of coefficients in the mean and variance equations. The results presented in this paper indicate that Stochastic Volatility models, particularly SARV models, outperform MS-GARCH models in forecasting Bitcoin price volatility. Moreover, the study suggests that in certain situations, persistent simple GARCH models may even outperform Markov-Switching GARCH models in predicting the variance of Bitcoin log returns. These findings offer valuable guidance for risk management experts, highlighting the potential advantages of SARV models in managing and forecasting Bitcoin price volatility.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03393"
    },
    {
        "doc_id": 259,
        "title": "Volatility models in practice: Rough, Path-dependent or Markovian?",
        "authors": [
            "Eduardo Abi Jaber",
            "Shaun",
            "Li"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "An extensive empirical study of the class of Volterra Bergomi models using SPX options data between 2011 and 2022 reveals the following fact-check on two fundamental claims echoed in the rough volatility literature:\n  Do rough volatility models with Hurst index $H \\in (0,1/2)$ really capture well SPX implied volatility surface with very few parameters? No, rough volatility models are inconsistent with the global shape of SPX smiles. They suffer from severe structural limitations imposed by the roughness component, with the Hurst parameter $H \\in (0,1/2)$ controlling the smile in a poor way. In particular, the SPX at-the-money skew is incompatible with the power-law shape generated by rough volatility models. The skew of rough volatility models increases too fast on the short end, and decays too slow on the longer end where \"negative\" $H$ is sometimes needed.\n  Do rough volatility models really outperform consistently their classical Markovian counterparts? No, for short maturities they underperform their one-factor Markovian counterpart with the same number of parameters. For longer maturities, they do not systematically outperform the one-factor model and significantly underperform when compared to an under-parametrized two-factor Markovian model with only one additional calibratable parameter.\n  On the positive side: our study identifies a (non-rough) path-dependent Bergomi model and an under-parametrized two-factor Markovian Bergomi model that consistently outperform their rough counterpart in capturing SPX smiles between one week and three years with only 3 to 4 calibratable parameters. \\end{abstract}",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03345"
    },
    {
        "doc_id": 260,
        "title": "Negatively dependent optimal risk sharing",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Risk Management"
        ],
        "abstract": "We analyze the problem of optimally sharing risk using allocations that exhibit counter-monotonicity, the most extreme form of negative dependence. Counter-monotonic allocations take the form of either \"winner-takes-all\" lotteries or \"loser-loses-all\" lotteries, and we respectively refer to these (normalized) cases as jackpot or scapegoat allocations. Our main theorem, the counter-monotonic improvement theorem, states that for a given set of random variables that are either all bounded from below or all bounded from above, one can always find a set of counter-monotonic random variables such that each component is greater or equal than its counterpart in the convex order. We show that Pareto optimal allocations, if they exist, must be jackpot allocations when all agents are risk seeking. We essentially obtain the opposite when all agents have discontinuous Bernoulli utility functions, as scapegoat allocations maximize the probability of being above the discontinuity threshold. We also consider the case of rank-dependent expected utility (RDU) agents and find conditions which guarantee that RDU agents prefer jackpot allocations. We provide an application for the mining of cryptocurrencies and show that in contrast to risk-averse miners, RDU miners with small computing power never join a mining pool. Finally, we characterize the competitive equilibria with risk-seeking agents, providing a first and second fundamental theorem of welfare economics where all equilibrium allocations are jackpot allocations.",
        "comments": "35 pages, 1 figure, Keywords: Pareto optimality, Risk sharing, Counter-monotonicity, Risk seeking, Rank-dependent expected utility, Cryptocurrency mining pools",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03328"
    },
    {
        "doc_id": 261,
        "title": "Optimal Order Execution subject to Reservation Strategies under Execution Risk",
        "authors": [
            "Xue Cheng",
            "Peng Guo",
            "Tai-ho Wang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under order fill uncertainty. A broker-dealer agency is authorized to execute an order of trading on client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reservation strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon. Optimal strategy in feedback form is obtained in closed form. In the absence of execution risk, the optimal strategies subject to reservation strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reservation strategies using implementation shortfall and target close orders as basis. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03305"
    },
    {
        "doc_id": 262,
        "title": "Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning",
        "authors": [
            "Hong-Gi Shin",
            "Sukhyun Jeong",
            "Eui-Yeon Kim",
            "Sungho Hong",
            "Young-Jin Cho",
            "Yong-Hoon Choi"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence"
        ],
        "abstract": "Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.",
        "comments": "Accepted by ICOIN 2024",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02710"
    },
    {
        "doc_id": 263,
        "title": "Displaying risk in mergers: a diagrammatic approach for exchange ratio determination",
        "authors": [
            "Alessandra Mainini",
            "Enrico Moretto",
            "Daniela Visetti"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This article extends, in a stochastic setting, previous results in the determination of feasible exchange ratios for merging companies. A first outcome is that shareholders of the companies involved in the merging process face both an upper and a lower bounds for acceptable exchange ratios. Secondly, in order for the improved `bargaining region' to be intelligibly displayed, the diagrammatic approach developed by Kulpa is exploited.",
        "comments": " ",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02681"
    },
    {
        "doc_id": 264,
        "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization Approach",
        "authors": [
            "Albert Dorador"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02601"
    },
    {
        "doc_id": 265,
        "title": "Opinion formation in the world trade network",
        "authors": [
            "C\u00e9lestin Coquid\u00e9",
            "Jos\u00e9 Lages",
            "Dima L. Shepelyansky"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Mechanics",
            "Social and Information Networks",
            "Physics and Society"
        ],
        "abstract": "We extend the opinion formation approach to probe the world influence of economical organizations. Our opinion formation model mimics a battle between currencies within the international trade network. Based on the United Nations Comtrade database, we construct the world trade network for the years of the last decade from 2010 to 2020. We consider different core groups constituted by countries preferring to trade in a specific currency. We will consider principally two core groups, namely, 5 Anglo-Saxon countries which prefer to trade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical currency, hereafter called BRI, pegged to their economies. We determine the trade currency preference of the other countries via a Monte Carlo process depending on the direct transactions between the countries. The results obtained in the frame of this mathematical model show that starting from year 2014 the majority of the world countries would have preferred to trade in BRI than USD. The Monte Carlo process reaches a steady state with 3 distinct groups: two groups of countries preferring, whatever is the initial distribution of the trade currency preferences, to trade, one in BRI and the other in USD, and a third group of countries swinging as a whole between USD and BRI depending on the initial distribution of the trade currency preferences. We also analyze the battle between USD, EUR and BRI, and present the reduced Google matrix description of the trade relations between the Anglo-Saxon countries and the BRICS+.",
        "comments": "16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02378"
    },
    {
        "doc_id": 266,
        "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
        "authors": [
            "Zeynep Hilal Kilimci",
            "Mustafa Yalcin"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02124"
    },
    {
        "doc_id": 267,
        "title": "Forecasting Bitcoin Volatility: A Comparative Analysis of Volatility Approaches",
        "authors": [
            "Cristina Chinazzo",
            "Vahidin Jeleskovic"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper conducts an extensive analysis of Bitcoin return series, with a primary focus on three volatility metrics: historical volatility (calculated as the sample standard deviation), forecasted volatility (derived from GARCH-type models), and implied volatility (computed from the emerging Bitcoin options market). These measures of volatility serve as indicators of market expectations for conditional volatility and are compared to elucidate their differences and similarities. The central finding of this study underscores a notably high expected level of volatility, both on a daily and annual basis, across all the methodologies employed. However, it's crucial to emphasize the potential challenges stemming from suboptimal liquidity in the Bitcoin options market. These liquidity constraints may lead to discrepancies in the computed values of implied volatility, particularly in scenarios involving extreme moneyness or maturity. This analysis provides valuable insights into Bitcoin's volatility landscape, shedding light on the unique characteristics and dynamics of this cryptocurrency within the context of financial markets.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02049"
    },
    {
        "doc_id": 268,
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "subjects": [
            "Computational Finance",
            "Numerical Analysis"
        ],
        "abstract": "This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01758"
    },
    {
        "doc_id": 269,
        "title": "Text mining arXiv: a look through quantitative finance papers",
        "authors": [
            "Michele Leonardo Bianchi"
        ],
        "subjects": [
            "Digital Libraries",
            "Information Retrieval",
            "General Finance"
        ],
        "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01751"
    },
    {
        "doc_id": 270,
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "authors": [
            "Lioba Heimbach",
            "Vabuk Pahari",
            "Eric Schertenleib"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.\n  In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum's biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 137 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum's total block value and outline possible mitigations.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01622"
    },
    {
        "doc_id": 271,
        "title": "An arbitrage driven price dynamics of Automated Market Makers in the presence of fees",
        "authors": [
            "Joseph Najnudel",
            "Shen-Ning Tung",
            "Kazutoshi Yamazaki",
            "Ju-Yi Yen"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",
        "comments": " ",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01526"
    },
    {
        "doc_id": 272,
        "title": "Nash Equilibria in Greenhouse Gas Offset Credit Markets",
        "authors": [
            "Liam Welsh",
            "Sebastian Jaimungal"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "In response to the global climate crisis, governments worldwide are introducing legislation to reduce greenhouse gas (GHG) emissions to help mitigate environmental catastrophes. One method to encourage emission reductions is to incentivize carbon capturing and carbon reducing projects while simultaneously penalising excess GHG output. Firms that invest in carbon capturing projects or reduce their emissions can receive offset credits (OCs) in return. These OCs can be used for regulatory purposes to offset their excess emissions in a compliance period. OCs may also be traded between firms. Thus, firms have the choice between investing in projects to generate OCs or to trade OCs. In this work, we present a novel market framework and characterise the optimal behaviour of GHG OC market participants in both single-player and two-player settings. We analyse both a single-period and multi-period setting. As the market model does not elicit a closed form solution, we develop a numerical methodology to estimate players' optimal behaviours in accordance to the Nash equilibria. Our findings indicate the actions players take are dependent on the scale of their project opportunities as well as their fellow market participants. We demonstrate the importance of behaving optimally via simulations in order to offset emission penalties and the importance of investing in GHG reducing or capturing projects from a financial perspective.",
        "comments": "MSC Class:          91G99; 35Q91; 91-08; 91A80; 91B74",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01427"
    },
    {
        "doc_id": 273,
        "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces",
        "authors": [
            "Farshud Sorourifar",
            "Thomas Banker",
            "Joel A. Paulson"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.",
        "comments": "9 pages, 2 figures consisting of 6 and 4 plots, accepted to NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01398"
    },
    {
        "doc_id": 274,
        "title": "Almost Perfect Shadow Prices",
        "authors": [
            "Eberhard Mayerhofer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a na\u00efve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",
        "comments": "15 pages",
        "date": "1 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00970"
    },
    {
        "doc_id": 275,
        "title": "A Portfolio's Common Causal Conditional Risk-neutral PDE",
        "authors": [
            "Alejandro Rodriguez Dominguez"
        ],
        "subjects": [
            "Portfolio Management",
            "Mathematical Finance"
        ],
        "abstract": "Portfolio's optimal drivers for diversification are common causes of the constituents' correlations. A closed-form formula for the conditional probability of the portfolio given its optimal common drivers is presented, with each pair constituent-common driver joint distribution modelled by Gaussian copulas. A conditional risk-neutral PDE is obtained for this conditional probability as a system of copulas' PDEs, allowing for dynamical risk management of a portfolio as shown in the experiments. Implied conditional portfolio volatilities and implied weights are new risk metrics that can be dynamically monitored from the PDEs or obtained from their solution.",
        "comments": "6 pages, 4 figures, Mathematical and Statistical Methods for Actuarial Sciences and Finance - MAF2024",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00949"
    },
    {
        "doc_id": 276,
        "title": "Intraday Trading Algorithm for Predicting Cryptocurrency Price Movements Using Twitter Big Data Analysis",
        "authors": [
            "Vahidin Jeleskovic",
            "Stephen Mackay"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Cryptocurrencies have emerged as a novel financial asset garnering significant attention in recent years. A defining characteristic of these digital currencies is their pronounced short-term market volatility, primarily influenced by widespread sentiment polarization, particularly on social media platforms such as Twitter. Recent research has underscored the correlation between sentiment expressed in various networks and the price dynamics of cryptocurrencies. This study delves into the 15-minute impact of informative tweets disseminated through foundation channels on trader behavior, with a focus on potential outcomes related to sentiment polarization. The primary objective is to identify factors that can predict positive price movements and potentially be leveraged through a trading algorithm. To accomplish this objective, we conduct a conditional examination of return and excess return rates within the 15 minutes following tweet publication. The empirical findings reveal statistically significant increases in return rates, particularly within the initial three minutes following tweet publication. Notably, adverse effects resulting from the messages were not observed. Surprisingly, sentiments were found to have no discerni-ble impact on cryptocurrency price movements. Our analysis further identifies that inves-tors are primarily influenced by the quality of tweet content, as reflected in the choice of words and tweet volume. While the basic trading algorithm presented in this study does yield some benefits within the 15-minute timeframe, these benefits are not statistically significant. Nevertheless, it serves as a foundational framework for potential enhance-ments and further investigations.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00603"
    },
    {
        "doc_id": 277,
        "title": "On the implied volatility of Inverse and Quanto Inverse options under stochastic volatility models",
        "authors": [
            "Elisa Al\u00f2s",
            "Eulalia Nualart",
            "Makar Pravosud"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "In this paper we study short-time behavior of the at-the-money implied volatility for Inverse and Quanto Inverse European options with fixed strike price. The asset price is assumed to follow a general stochastic volatility process. Using techniques of the Malliavin calculus such as the anticipating Ito's formula we first compute the level of the implied volatility of the option when the maturity converges to zero. Then, we find a short maturity asymptotic formula for the skew of the implied volatility that depends on the roughness of the volatility model. We apply our general results to the SABR and fractional Bergomi models, and provide some numerical simulations that confirm the accurateness of the asymptotic formula for the skew.",
        "comments": "arXiv admin note: text overlap with arXiv:2308.15341, arXiv:2208.01353",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00539"
    },
    {
        "doc_id": 278,
        "title": "Financial Time-Series Forecasting: Towards Synergizing Performance And Interpretability Within a Hybrid Machine Learning Approach",
        "authors": [
            "Shun Liu",
            "Kexin Wu",
            "Chufeng Jiang",
            "Bin Huang",
            "Danqing Ma"
        ],
        "subjects": [
            "Machine Learning",
            "Statistical Finance"
        ],
        "abstract": "In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered substantial attention due to its potential impact on financial markets and investment strategies. This paper propose a comparative study on hybrid machine learning algorithms and leverage on enhancing model interpretability. Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM), decision tree regressors are introduced. Through the grounded experiments, we observe linear regressor achieves the best performance among candidate models. For the interpretability, we carry out a systematic overview on the preprocessing techniques of time-series statistics, including decomposition, auto-correlational function, exponential triple forecasting, which aim to excavate latent relations and complex patterns appeared in the financial time-series forecasting. We believe this work may derive more attention and inspire more researches in the realm of time-series analysis and its realistic applications.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00534"
    },
    {
        "doc_id": 279,
        "title": "Optimization of portfolios with cryptocurrencies: Markowitz and GARCH-Copula model approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Claudio Latini",
            "Zahid I. Younas",
            "Mamdouh A. S. Al-Faryan"
        ],
        "subjects": [
            "Portfolio Management",
            "Applications"
        ],
        "abstract": "The growing interest in cryptocurrencies has drawn the attention of the financial world to this innovative medium of exchange. This study aims to explore the impact of cryptocurrencies on portfolio performance. We conduct our analysis retrospectively, assessing the performance achieved within a specific time frame by three distinct portfolios: one consisting solely of equities, bonds, and commodities; another composed exclusively of cryptocurrencies; and a third, which combines both 'traditional' assets and the best-performing cryptocurrency from the second portfolio.To achieve this, we employ the classic variance-covariance approach, utilizing the GARCH-Copula and GARCH-Vine Copula methods to calculate the risk structure. The optimal asset weights within the optimized portfolios are determined through the Markowitz optimization problem. Our analysis predominantly reveals that the portfolio comprising both cryptocurrency and traditional assets exhibits a higher Sharpe ratio from a retrospective viewpoint and demonstrates more stable performances from a prospective perspective. We also provide an explanation for our choice of portfolio optimization based on the Markowitz approach rather than CVaR and ES.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00507"
    },
    {
        "doc_id": 280,
        "title": "A framework for the valuation of insurance liabilities by production cost",
        "authors": [
            "Christoph Moehr"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "This paper sets out a framework for the valuation of insurance liabilities that is intended to be economically realistic, elementary, reasonably practically applicable, and as a special case to provide a basis for the valuation in regulatory solvency systems such as Solvency II and the SST. The valuation framework is based on the cost of producing the liabilities to an insurance company that is subject to solvency regulation (regulatory solvency capital requirements) and insolvency laws (consequences of failure) in finite discrete time. Starting from the replication approach of classical no-arbitrage theory, the framework additionally considers the nature and cost of capital (expressed by a ``financiability condition\"), that the liabilities may be required to be fulfilled only ``in sufficiently many cases\" (expressed by a ``fulfillment condition\"), production using ``fully illiquid\" assets in addition to tradables, and the asymmetry between assets and liabilities. We identify necessary and sufficient conditions on the capital investment under which the framework recovers the market prices of tradables, investigate extending production to take account of insolvency, implications of using illiquid assets in the production, and show how Solvency II and SST valuation can be derived with specific assumptions.",
        "comments": "35 pages, no figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00263"
    },
    {
        "doc_id": 281,
        "title": "Enhancing CVaR portfolio optimisation performance with GAM factor models",
        "authors": [
            "Davide Lauria",
            "W. Brent Lindquist",
            "Svetlozar T. Rachev"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "We propose a discrete-time econometric model that combines autoregressive filters with factor regressions to predict stock returns for portfolio optimisation purposes. In particular, we test both robust linear regressions and general additive models on two different investment universes composed of the Dow Jones Industrial Average and the Standard & Poor's 500 indexes, and we compare the out-of-sample performances of mean-CVaR optimal portfolios over a horizon of six years. The results show a substantial improvement in portfolio performances when the factor model is estimated with general additive models.",
        "comments": " ",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00188"
    },
    {
        "doc_id": 282,
        "title": "Representation of forward performance criteria with random endowment via FBSDE and application to forward optimized certainty equivalent",
        "authors": [
            "Gechun Liang",
            "Yifan Sun",
            "Thaleia Zariphopoulou"
        ],
        "subjects": [
            "Portfolio Management",
            "Probability"
        ],
        "abstract": "We extend the notion of forward performance criteria to settings with random endowment in incomplete markets. Building on these results, we introduce and develop the novel concept of forward optimized certainty equivalent (forward OCE), which offers a genuinely dynamic valuation mechanism that accommodates progressively adaptive market model updates, stochastic risk preferences, and incoming claims with arbitrary maturities.\n  In parallel, we develop a new methodology to analyze the emerging stochastic optimization problems by directly studying the candidate optimal control processes for both the primal and dual problems. Specifically, we derive two new systems of forward-backward stochastic differential equations (FBSDEs) and establish necessary and sufficient conditions for optimality, and various equivalences between the two problems. This new approach is general and complements the existing one based on backward stochastic partial differential equations (backward SPDEs) for the related value functions. We, also, consider representative examples for both forward performance criteria with random endowment and forward OCE, and for the case of exponential criteria, we investigate the connection between forward OCE and forward entropic risk measures.",
        "comments": "50 pages",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00103"
    },
    {
        "doc_id": 283,
        "title": "Synthetic Data Applications in Finance",
        "authors": [
            "Vamsi K. Potluru",
            "Daniel Borrajo",
            "Andrea Coletta",
            "Niccol\u00f2 Dalmasso",
            "Yousef El-Laham",
            "Elizabeth Fons",
            "Mohsen Ghassemi",
            "Sriram Gopalakrishnan",
            "Vikesh Gosai",
            "Eleonora Krea\u010di\u0107",
            "Ganapathy Mani",
            "Saheed Obitayo",
            "Deepak Paramanand",
            "Natraj Raman",
            "Mikhail Solonin",
            "Srijan Sood",
            "Svitlana Vyetrenko",
            "Haibei Zhu",
            "Manuela Veloso",
            "Tucker Balch"
        ],
        "subjects": [
            "Machine Learning",
            "General Finance"
        ],
        "abstract": "Synthetic data has made tremendous strides in various commercial settings including finance, healthcare, and virtual reality. We present a broad overview of prototypical applications of synthetic data in the financial sector and in particular provide richer details for a few select ones. These cover a wide variety of data modalities including tabular, time-series, event-series, and unstructured arising from both markets and retail financial applications. Since finance is a highly regulated industry, synthetic data is a potential approach for dealing with issues related to privacy, fairness, and explainability. Various metrics are utilized in evaluating the quality and effectiveness of our approaches in these applications. We conclude with open directions in synthetic data in the context of the financial domain.",
        "comments": "50 pages, journal submission",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00081"
    },
    {
        "doc_id": 284,
        "title": "Sector Rotation by Factor Model and Fundamental Analysis",
        "authors": [
            "Runjia Yang",
            "Beining Shi"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "This study presents an analytical approach to sector rotation, leveraging both factor models and fundamental metrics. We initiate with a systematic classification of sectors, followed by an empirical investigation into their returns. Through factor analysis, the paper underscores the significance of momentum and short-term reversion in dictating sectoral shifts. A subsequent in-depth fundamental analysis evaluates metrics such as PE, PB, EV-to-EBITDA, Dividend Yield, among others. Our primary contribution lies in developing a predictive framework based on these fundamental indicators. The constructed models, post rigorous training, exhibit noteworthy predictive capabilities. The findings furnish a nuanced understanding of sector rotation strategies, with implications for asset management and portfolio construction in the financial domain.",
        "comments": " ",
        "date": "18 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00001"
    },
    {
        "doc_id": 285,
        "title": "Causal Discovery in Financial Markets: A Framework for Nonstationary Time-Series Data",
        "authors": [
            "Agathe Sadeghi",
            "Achintya Gopal",
            "Mohammad Fesanghary"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "A deeper comprehension of financial markets necessitates understanding not only the statistical dependencies among various entities but also the causal dependencies. This paper extends the Constraint-based Causal Discovery from Heterogeneous Data algorithm to account for lagged relationships in time-series data (an algorithm we call CD-NOTS), shedding light on the complex causal relations between different financial assets and variables. We compare the performance of different algorithmic choices, such as the choice of conditional independence test, to give general advice on the effective way to use CD-NOTS. Using the results from the simulated data, we apply CD-NOTS to a broad range of indices and factors in order to identify causal connections among the entities, thereby showing how causal discovery can serve as a valuable tool for factor-based investing, portfolio diversification, and comprehension of market dynamics. Further, we show our algorithm is a more effective alternative to other causal discovery algorithms since the assumptions of our algorithm are more realistic in terms of financial data, a conclusion we find is statistically significant.",
        "comments": "24 pages, 25 figures",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2312.17375"
    },
    {
        "doc_id": 286,
        "title": "Discounting the distant future: What do historical bond prices imply about the long term discount rate?",
        "authors": [
            "J. Doyne Farmer",
            "John Geanakoplos",
            "Matteo G. Richiardi",
            "Miquel Montero",
            "Josep Perell\u00f3",
            "Jaume Masoliver"
        ],
        "subjects": [
            "Mathematical Finance",
            "General Economics",
            "Risk Management"
        ],
        "abstract": "We present a thorough empirical study on real interest rates by also including risk aversion through the introduction of the market price of risk. With the view of complex systems science and its multidisciplinary approach, we use the theory of bond pricing to study the long term discount rate. Century-long historical records of 3 month bonds, 10 year bonds, and inflation allow us to estimate real interest rates for the UK and the US. Real interest rates are negative about a third of the time and the real yield curves are inverted more than a third of the time, sometimes by substantial amounts. This rules out most of the standard bond pricing models, which are designed for nominal rates that are assumed to be positive. We therefore use the Ornstein-Uhlenbeck model which allows negative rates and gives a good match to inversions of the yield curve. We derive the discount function using the method of Fourier transforms and fit it to the historical data. The estimated long term discount rate is $1.7$ \\% for the UK and $2.2$ \\% for the US. The value of $1.4$ \\% used by Stern is less than a standard deviation from our estimated long run return rate for the UK, and less than two standard deviations of the estimated value for the US. All of this once more reinforces the support for immediate and substantial spending to combat climate change.",
        "comments": "27 pages, 6 figures",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.17157"
    },
    {
        "doc_id": 287,
        "title": "Bayesian Analysis of High Dimensional Vector Error Correction Model",
        "authors": [
            "Parley R Yang",
            "Alexander Y Shestopaloff"
        ],
        "subjects": [
            "Methodology",
            "Econometrics",
            "Statistical Finance"
        ],
        "abstract": "Vector Error Correction Model (VECM) is a classic method to analyse cointegration relationships amongst multivariate non-stationary time series. In this paper, we focus on high dimensional setting and seek for sample-size-efficient methodology to determine the level of cointegration. Our investigation centres at a Bayesian approach to analyse the cointegration matrix, henceforth determining the cointegration rank. We design two algorithms and implement them on simulated examples, yielding promising results particularly when dealing with high number of variables and relatively low number of observations. Furthermore, we extend this methodology to empirically investigate the constituents of the S&P 500 index, where low-volatility portfolios can be found during both in-sample training and out-of-sample testing periods.",
        "comments": " ",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.17061"
    },
    {
        "doc_id": 288,
        "title": "Price predictability at ultra-high frequency: Entropy-based randomness test",
        "authors": [
            "Andrey Shternshis",
            "Stefano Marmi"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "We use the statistical properties of Shannon entropy estimator and Neyman-Pearson statistics to study the predictability of ultra-high frequency financial data. We develop a statistical test for the predictability of a sequence based on empirical frequencies. We study stylized facts that cause price predictability such as persistence of order signs, autocorrelation of returns, and volatility clustering. We show that the degree of randomness grows with the increase of aggregation level in transaction time. We also find that predictable days are usually characterized by high trading activity, i.e., days with unusually high trading volumes and the number of price changes. We find a group of stocks for which predictability is caused by a frequent change of price direction. We perform multiple testing for sub-intervals of days to identify whether there is predictability at a specific time period during the day.",
        "comments": "27 pages, 9 figures",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16637"
    },
    {
        "doc_id": 289,
        "title": "Randomized Signature Methods in Optimal Portfolio Selection",
        "authors": [
            "Erdinc Akyildirim",
            "Matteo Gambara",
            "Josef Teichmann",
            "Syang Zhou"
        ],
        "subjects": [
            "Portfolio Management",
            "Artificial Intelligence",
            "Machine Learning",
            "Pricing of Securities"
        ],
        "abstract": "We present convincing empirical results on the application of Randomized Signature Methods for non-linear, non-parametric drift estimation for a multi-variate financial market. Even though drift estimation is notoriously ill defined due to small signal to noise ratio, one can still try to learn optimal non-linear maps from data to future returns for the purposes of portfolio optimization. Randomized Signatures, in contrast to classical signatures, allow for high dimensional market dimension and provide features on the same scale. We do not contribute to the theory of Randomized Signatures here, but rather present our empirical findings on portfolio selection in real world settings including real market data and transaction costs.",
        "comments": " ",
        "date": "27 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16448"
    },
    {
        "doc_id": 290,
        "title": "Increasing Profitability and Confidence by using Interpretable Model for Investment Decisions",
        "authors": [
            "Sahar Arshad",
            "Seemab Latif",
            "Ahmad Salman",
            "Saadia Irfan"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Financial forecasting plays an important role in making informed decisions for financial stakeholders, specifically in the stock exchange market. In a traditional setting, investors commonly rely on the equity research department for valuable reports on market insights and investment recommendations. The equity research department, however, faces challenges in effectuating decision-making due to the demanding cognitive effort required for analyzing the inherently volatile nature of market dynamics. Furthermore, financial forecasting systems employed by analysts pose potential risks in terms of interpretability and gaining the trust of all stakeholders. This paper presents an interpretable decision-making model leveraging the SHAP-based explainability technique to forecast investment recommendations. The proposed solution not only provides valuable insights into the factors that influence forecasted recommendations but also caters to investors of varying types, including those interested in daily and short-term investment opportunities. To ascertain the efficacy of the proposed model, a case study is devised that demonstrates a notable enhancement in investor's portfolio value, employing our trading strategies. The results highlight the significance of incorporating interpretability in forecasting models to boost stakeholders' confidence and foster transparency in the stock exchange domain.",
        "comments": " ",
        "date": "24 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16223"
    },
    {
        "doc_id": 291,
        "title": "Hawkes-based cryptocurrency forecasting via Limit Order Book data",
        "authors": [
            "Raffaele Giuseppe Cestari",
            "Filippo Barchi",
            "Riccardo Busetto",
            "Daniele Marazzina",
            "Simone Formentin"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Accurately forecasting the direction of financial returns poses a formidable challenge, given the inherent unpredictability of financial time series. The task becomes even more arduous when applied to cryptocurrency returns, given the chaotic and intricately complex nature of crypto markets. In this study, we present a novel prediction algorithm using limit order book (LOB) data rooted in the Hawkes model, a category of point processes. Coupled with a continuous output error (COE) model, our approach offers a precise forecast of return signs by leveraging predictions of future financial interactions. Capitalizing on the non-uniformly sampled structure of the original time series, our strategy surpasses benchmark models in both prediction accuracy and cumulative profit when implemented in a trading environment. The efficacy of our approach is validated through Monte Carlo simulations across 50 scenarios. The research draws on LOB measurements from a centralized cryptocurrency exchange where the stablecoin Tether is exchanged against the U.S. dollar.",
        "comments": " ",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16190"
    },
    {
        "doc_id": 292,
        "title": "Linear and nonlinear causality in financial markets",
        "authors": [
            "Haochun Ma",
            "Davide Prosperino",
            "Alexander Haluszczynski",
            "Christoph R\u00e4th"
        ],
        "subjects": [
            "Statistical Finance",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Identifying and quantifying co-dependence between financial instruments is a key challenge for researchers and practitioners in the financial industry. Linear measures such as the Pearson correlation are still widely used today, although their limited explanatory power is well known. In this paper we present a much more general framework for assessing co-dependencies by identifying and interpreting linear and nonlinear causalities in the complex system of financial markets. To do so, we use two different causal inference methods, transfer entropy and convergent cross-mapping, and employ Fourier transform surrogates to separate their linear and nonlinear contributions. We find that stock indices in Germany and the U.S. exhibit a significant degree of nonlinear causality and that correlation, while a very good proxy for linear causality, disregards nonlinear effects and hence underestimates causality itself. The presented framework enables the measurement of nonlinear causality, the correlation-causality fallacy, and motivates how causality can be used for inferring market signals, pair trading, and risk management of portfolios. Our results suggest that linear and nonlinear causality can be used as early warning indicators of abnormal market behavior, allowing for better trading strategies and risk management.",
        "comments": "14 pages, 10 figures",
        "date": "18 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16185"
    },
    {
        "doc_id": 293,
        "title": "European Football Player Valuation: Integrating Financial Models and Network Theory",
        "authors": [
            "Albert Cohen",
            "Jimmy Risk"
        ],
        "subjects": [
            "Physics and Society",
            "Computational Finance",
            "Pricing of Securities",
            "Applications"
        ],
        "abstract": "This paper presents a new framework for player valuation in European football by fusing principles from financial mathematics and network theory. The valuation model leverages a \"passing matrix\" to encapsulate player interactions on the field, utilizing centrality measures to quantify individual influence. Unlike traditional approaches, this model is both metric-driven and cohort-free, providing a dynamic and individualized framework for ascertaining a player's fair market value. The methodology is empirically validated through a case study in European football, employing real-world match and financial data. The paper advances the disciplines of sports analytics and financial mathematics by offering a cross-disciplinary mechanism for player valuation, and also links together two well-known econometric methods in marginal revenue product and expected present valuation.",
        "comments": "15 pages, 4 figures, 2 tables",
        "date": "15 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16179"
    },
    {
        "doc_id": 294,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This paper provides a general method to translate a standard economic model with a large number of agents into a field-formalism model. This formalism preserves the system's interactions and microeconomic features at the individual level but reveals the emergence of collective states.We apply this method to a simple microeconomic framework of investors and firms. Both macro and micro aspects of the formalism are studied.At the macro-scale, the field formalism shows that, in each sector, three patterns of capital accumulation may emerge. A distribution of patterns across sectors constitute a collective state. Any change in external parameters or expectations in one sector will affect neighbouring sectors, inducing transitions between collective states and generating permanent fluctuations in patterns and flows of capital. Although changes in expectations can cause abrupt changes in collective states, transitions may be slow to occur. Due to its relative inertia, the real economy is bound to be more affected by these constant variations than the financial markets.At the micro-scale we compute the transition functions of individual agents and study their probabilistic dynamics in a given collective state, as a function of their initial state. We show that capital accumulation of an individual agent depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Moreover, the firm must also consider the effects of competition in the intermediate sectors that tends to oust under-capitalized firm towards sectors with lower average capital. For investors, capital allocation depends on their short and long-term returns and investors will tend to reallocate their capital to maximize both. The higher their level of capital, the stronger the re-allocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2205.03087",
        "date": "1 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.16173"
    },
    {
        "doc_id": 295,
        "title": "Implied volatility (also) is path-dependent",
        "authors": [
            "Herv\u00e9 Andr\u00e8s",
            "Alexandre Boumezoued",
            "Benjamin Jourdain"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We propose a new model for the coherent forecasting of both the implied volatility surfaces and the underlying asset returns.In the spirit of Guyon and Lekeufack (2023) who are interested in the dependence of volatility indices (e.g. the VIX) on the paths of the associated equity indices (e.g. the S\\&P 500), we first study how implied volatility can be predicted using the past trajectory of the underlying asset price. Our empirical study reveals that a large part of the movements of the at-the-money-forward implied volatility for up to two years maturities can be explained using the past returns and their squares. Moreover, we show that up to four years of the past evolution of the underlying price should be used for the prediction and that this feedback effect gets weaker when the maturity increases. Building on this new stylized fact, we fit to historical data a parsimonious version of the SSVI parameterization (Gatheral and Jacquier, 2014) of the implied volatility surface relying on only four parameters and show that the two parameters ruling the at-the-money-forward implied volatility as a function of the maturity exhibit a path-dependent behavior with respect to the underlying asset price. Finally, we propose a model for the joint dynamics of the implied volatility surface and the underlying asset price. The latter is modelled using a variant of the path-dependent volatility model of Guyon and Lekeufack and the former is obtained by adding a feedback effect of the underlying asset price onto the two parameters ruling the at-the-money-forward implied volatility in the parsimonious SSVI parameterization and by specifying a hidden semi-Markov diffusion model for the residuals of these two parameters and the two other parameters. Thanks to this model, we are able to simulate highly realistic paths of implied volatility surfaces that are arbitrage-free.",
        "comments": " ",
        "date": "26 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.15950"
    },
    {
        "doc_id": 296,
        "title": "Deep Reinforcement Learning for Quantitative Trading",
        "authors": [
            "Maochun Xu",
            "Zixun Lan",
            "Zheng Tao",
            "Jiawei Du",
            "Zongao Ye"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) are transforming the domain of Quantitative Trading (QT) through the deployment of advanced algorithms capable of sifting through extensive financial datasets to pinpoint lucrative investment openings. AI-driven models, particularly those employing ML techniques such as deep learning and reinforcement learning, have shown great prowess in predicting market trends and executing trades at a speed and accuracy that far surpass human capabilities. Its capacity to automate critical tasks, such as discerning market conditions and executing trading strategies, has been pivotal. However, persistent challenges exist in current QT methods, especially in effectively handling noisy and high-frequency financial data. Striking a balance between exploration and exploitation poses another challenge for AI-driven trading agents. To surmount these hurdles, our proposed solution, QTNet, introduces an adaptive trading model that autonomously formulates QT strategies through an intelligent trading agent. Incorporating deep reinforcement learning (DRL) with imitative learning methodologies, we bolster the proficiency of our model. To tackle the challenges posed by volatile financial datasets, we conceptualize the QT mechanism within the framework of a Partially Observable Markov Decision Process (POMDP). Moreover, by embedding imitative learning, the model can capitalize on traditional trading tactics, nurturing a balanced synergy between discovery and utilization. For a more realistic simulation, our trading agent undergoes training using minute-frequency data sourced from the live financial market. Experimental findings underscore the model's proficiency in extracting robust market features and its adaptability to diverse market conditions.",
        "comments": " ",
        "date": "25 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.15730"
    },
    {
        "doc_id": 297,
        "title": "Discrete-Time Mean-Variance Strategy Based on Reinforcement Learning",
        "authors": [
            "Xiangyu Cui",
            "Xun Li",
            "Yun Shi",
            "Si Zhao"
        ],
        "subjects": [
            "Mathematical Finance",
            "Machine Learning",
            "Portfolio Management"
        ],
        "abstract": "This paper studies a discrete-time mean-variance model based on reinforcement learning. Compared with its continuous-time counterpart in \\cite{zhou2020mv}, the discrete-time model makes more general assumptions about the asset's return distribution. Using entropy to measure the cost of exploration, we derive the optimal investment strategy, whose density function is also Gaussian type. Additionally, we design the corresponding reinforcement learning algorithm. Both simulation experiments and empirical analysis indicate that our discrete-time model exhibits better applicability when analyzing real-world data than the continuous-time model.",
        "comments": "arXiv admin note: text overlap with arXiv:1904.11392 by other authors",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.15385"
    },
    {
        "doc_id": 298,
        "title": "Equilibrium stochastic control with implicitly defined objective functions",
        "authors": [
            "Zongxia Liang",
            "Jianming Xia",
            "Keyu Zhang"
        ],
        "subjects": [
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "This paper considers a class of stochastic control problems with implicitly defined objective functions, which are the sources of time-inconsistency. We study the closed-loop equilibrium solutions in a general controlled diffusion framework. First, we provide a sufficient and necessary condition for a strategy to be an equilibrium. Then, we apply the result to discuss two problems of dynamic portfolio selection for a class of betweenness preferences, allowing for closed convex constraints on portfolio weights and borrowing cost, respectively. The equilibrium portfolio strategies are explicitly characterized in terms of the solutions of some first-order ordinary differential equations for the case of deterministic market coefficients.",
        "comments": " ",
        "date": "26 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.15173"
    },
    {
        "doc_id": 299,
        "title": "Functional CLTs for subordinated stable L\u00e9vy models in physics, finance, and econometrics",
        "authors": [
            "Andreas S\u00f8jmark",
            "Fabrice Wunderlich"
        ],
        "subjects": [
            "Probability",
            "Econometrics",
            "Mathematical Physics",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We present a simple unifying treatment of a large class of applications from statistical mechanics, econometrics, mathematical finance, and insurance mathematics, where stable (possibly subordinated) L\u00e9vy noise arises as a scaling limit of some form of continuous-time random walk (CTRW). For each application, it is natural to rely on weak convergence results for stochastic integrals on Skorokhod space in Skorokhod's J1 or M1 topologies. As compared to earlier and entirely separate works, we are able to give a more streamlined account while also allowing for greater generality and providing important new insights. For each application, we first make clear how the fundamental conclusions for J1 convergent CTRWs emerge as special cases of the same general principles, and we then illustrate how the specific settings give rise to different results for strictly M1 convergent CTRWs.",
        "comments": "arXiv admin note: text overlap with arXiv:2309.12197",
        "date": "22 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2312.15119"
    },
    {
        "doc_id": 300,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 301,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 302,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 303,
        "title": "Correlating fluorescence microscopy, optical and magnetic tweezers to study single chiral biopolymers, tested on DNA plectoneme formation dynamics",
        "authors": [
            "Jack W Shepherd",
            "Sebastien Guilbaud",
            "Zhaokun Zhou",
            "Jamieson Howard",
            "Matthew Burman",
            "Charley Schaefer",
            "Adam Kerrigan",
            "Clare Steele-King",
            "Agnes Noy",
            "Mark C Leake"
        ],
        "subjects": [
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Biopolymer topology is critical for determining interactions inside cell environments, exemplified by DNA where its response to mechanical perturbation is as important as biochemical properties to its cellular roles. The dynamic structures of chiral biopolymers exhibit complex dependence with extension and torsion, however the physical mechanisms underpinning the emergence of structural motifs upon physiological twisting and stretching are poorly understood due to technological limitations in correlating force, torque and spatial localization information. We present COMBI-Tweez (Combined Optical and Magnetic BIomolecule TWEEZers), a transformative tool that overcomes these challenges by integrating optical trapping, time-resolved electromagnetic tweezers, and fluorescence microscopy, demonstrated on single DNA molecules, that can controllably form and visualise higher order structural motifs including plectonemes. This technology combined with cutting-edge MD simulations provides quantitative insight into complex dynamic structures relevant to DNA cellular processes and can be adapted to study a range of filamentous biopolymers.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10087"
    },
    {
        "doc_id": 304,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 305,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 306,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 307,
        "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
        "authors": [
            "Zofia Rudnicka",
            "Janusz Szczepanski",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in the medical image scan segmentation, and intelligent visual-content generation, i.e. computer-generated three-dimensional (3D) images in the context of Extended Reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes also with possible developments and open challenges in AI application in Extended Reality-based solutions. Finally, the future lines of research and development directions of Artificial Intelligence applications both in medical image segmentation and Extended Reality-based medical solutions are discussed",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09857"
    },
    {
        "doc_id": 308,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 309,
        "title": "The impact of Covid-19 vaccination in Aotearoa New Zealand: a modelling study",
        "authors": [
            "Samik Datta",
            "Giorgia Vattiato",
            "Oliver J Maclaren",
            "Ning Hua",
            "Andrew Sporle",
            "Michael J Plank"
        ],
        "subjects": [
            "Populations and Evolution",
            "Physics and Society"
        ],
        "abstract": "Aotearoa New Zealand implemented a Covid-19 elimination strategy in 2020 and 2021, which enabled a large majority of the population to be vaccinated before being exposed to the virus. This strategy delivered one of the lowest pandemic mortality rates in the world. However, quantitative estimates of the population-level health benefits of vaccination are lacking. Here, we use a validated mathematical model to investigate counterfactual scenarios with differing levels of vaccine coverage in different age and ethnicity groups. The model builds on earlier research by adding age- and time-dependent case ascertainment, the effect of antiviral medications, improved hospitalisation rate estimates, and the impact of relaxing control measures. The model was used for scenario analysis and policy advice for the New Zealand Government in 2022 and 2023. We compare the number of Covid-19 hospitalisations, deaths, and years of life lost in each counterfactual scenario to a baseline scenario that is fitted to epidemiological data between January 2022 and June 2023. Our results estimate that vaccines saved 6650 (95% credible interval [4424, 10180]) lives, and prevented 74500 [51000, 115400] years of life lost and 45100 [34400, 55600] hospitalisations during this 18-month period. Making the same comparison before the benefit of antiviral medications is accounted for, the estimated number of lives saved by vaccines increases to 7604 [5080, 11942]. Due to inequities in the vaccine rollout, vaccination rates among M\u0101ori were lower than in people of European ethnicity. Our results show that, if vaccination rates had been equitable, an estimated 11-26% of the 292 M\u0101ori Covid-19 deaths that were recorded in this time period could have been prevented. We conclude that Covid-19 vaccination greatly reduced health burden in New Zealand and that equity needs to be a key focus of future vaccination programmes.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09679"
    },
    {
        "doc_id": 310,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 311,
        "title": "Molecular causality in the advent of foundation models",
        "authors": [
            "Sebastian Lobentanzer",
            "Pablo Rodriguez-Mier",
            "Stefan Bauer",
            "Julio Saez-Rodriguez"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Correlation is not causation. As simple as this widely agreed-upon statement may seem, scientifically defining causality and using it to drive our modern biomedical research is immensely challenging. In this perspective, we attempt to synergise the partly disparate fields of systems biology, causal reasoning, and machine learning, to inform future approaches in the field of systems biology and molecular networks.",
        "comments": "22 pages, 0 figures, 87 references; submitted to MSB",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09558"
    },
    {
        "doc_id": 312,
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "Junhao Wen",
            "Mathilde Antoniades",
            "Zhijian Yang",
            "Gyujoon Hwang",
            "Ioanna Skampardoni",
            "Rongguang Wang",
            "Christos Davatzikos"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing",
            "Quantitative Methods"
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09517"
    },
    {
        "doc_id": 313,
        "title": "Is the Emergence of Life an Expected Phase Transition in the Evolving Universe?",
        "authors": [
            "Stuart Kauffman",
            "Andrea Roli"
        ],
        "subjects": [
            "Populations and Evolution",
            "Biological Physics"
        ],
        "abstract": "We propose a novel definition of life in terms of which its emergence in the universe is expected, and its ever-creative open-ended evolution is entailed by no law. Living organisms are Kantian Wholes that achieve Catalytic Closure, Constraint Closure, and Spatial Closure. We here unite for the first time two established mathematical theories, namely Collectively Autocatalytic Sets and the Theory of the Adjacent Possible. The former establishes that a first-order phase transition to molecular reproduction is expected in the chemical evolution of the universe where the diversity and complexity of molecules increases; the latter posits that, under loose hypotheses, if the system starts with a small number of beginning molecules, each of which can combine with copies of itself or other molecules to make new molecules, over time the number of kinds of molecules increases slowly but then explodes upward hyperbolically. Together these theories imply that life is expected as a phase transition in the evolving universe. The familiar distinction between software and hardware loses its meaning in living cells. We propose new ways to study the phylogeny of metabolisms, new astronomical ways to search for life on exoplanets, new experiments to seek the emergence of the most rudimentary life, and the hint of a coherent testable pathway to prokaryotes with template replication and coding.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09514"
    },
    {
        "doc_id": 314,
        "title": "Role of Upwelling on Larval Dispersal and Productivity of Gooseneck Barnacle Populations in the Cantabrian Sea: Management Implications",
        "authors": [
            "Antonella Rivera",
            "Nicolas Weidberg",
            "Antonio F. Pardi\u00f1as",
            "Ricardo Gonzalez-Gil",
            "Luc\u0131a Garc\u0131a- Florez",
            "Jose Luis Acu\u00f1a"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "The effect of coastal upwelling on the recruitment and connectivity of coastal marine populations has rarely been characterized to a level of detail to be included into sound fishery management strategies. The gooseneck barnacle (Pollicipes pollicipes) fishery at the Cantabrian Coast (Northern Spain) is located at the fringes of the NW Spanish Upwelling system. This fishery is being co-managed through a fine-scale, interspersed set of protected rocks where each rock receives a distinct level of protection. Such interspersion is potentially beneficial, but the extent to which such spacing is consistent with mean larval dispersal distances is as yet unknown. We have simulated the spread of gooseneck barnacle larvae in the Central Cantabrian Coast using a high-resolution time-series of current profiles measured at a nearshore location. During a year of high upwelling activity (2009), theoretical recruitment success was 94% with peak recruitment predicted 56 km west of the emission point. However, for a year of low upwelling activity (2011) theoretical recruitment success dropped to 15.4% and peak recruitment was expected 13 km east of the emission point. This is consistent with a positive correlation between catch rates and the Integrated Upwelling Index, using a 4-year lag to allow recruits to reach commercial size. Furthermore, a net long-term westward larval transport was estimated by means of mitochondrial cytochrome c oxidase subunit I (COI) sequences for five populations in the Cantabrian Sea. Our results call into question the role of long distance dispersal, driven by the mesoscale processes in the area, in gooseneck barnacle populations and point to the prevalent role of small-scale, asymmetric connectivity more consistent with the typical scale of the co-management process in this fishery.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09513"
    },
    {
        "doc_id": 315,
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Haotian Lu",
            "Yexin Wu",
            "Zexin Yuan",
            "Shengdian Jiang",
            "Jiaxiang Wu",
            "Yimin Wang",
            "Junchi Yan"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09500"
    },
    {
        "doc_id": 316,
        "title": "Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "Jiayu Chang",
            "Shiyu Wang",
            "Chen Ling",
            "Zhaohui Qin",
            "Liang Zhao"
        ],
        "subjects": [
            "Quantitative Methods",
            "Information Retrieval"
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations.",
        "comments": "This is the official paper accepted by AAAI 2024 Workshop on Large Language Models for Biological Discoveries",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09490"
    },
    {
        "doc_id": 317,
        "title": "The Interplay Between Logical Phenomena and the Cognitive System of the Mind",
        "authors": [
            "Kazem Haghnejad Azar"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In this article, we employ mathematical concepts as a tool to examine the phenomenon of consciousness experience and logical phenomena. Through our investigation, we aim to demonstrate that our experiences, while not confined to limitations, cannot be neatly encapsulated within a singular collection. Our conscious experience emerges as a result of the developmental and augmentative trajectory of our cognitive system. As our cognitive abilities undergo refinement and advancement, our capacity for logical thinking likewise evolves, thereby manifesting a heightened level of conscious experience. The primary objective of this article is to embark upon a profound exploration of the concept of logical experience, delving into the intricate process by which these experiences are derived from our mind.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09465"
    },
    {
        "doc_id": 318,
        "title": "Diffusion-Driven Generative Framework for Molecular Conformation Prediction",
        "authors": [
            "Bobin Yang",
            "Zhenghan Chen"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "The task of inferring three-dimensional molecular configurations from their two-dimensional graph representations is of critical significance in the domains of computational chemistry and the development of pharmaceuticals. It contributes fundamentally to our grasp of molecular mechanisms and interactions. The rapid evolution of machine learning, especially in the realm of deep generative networks, has catalyzed breakthroughs in the precision of such predictive modeling. Traditional methodologies typically employ a bifurcated strategy: initially estimating interatomic distances followed by sculpting the spatial molecular structure via solving a distance geometry problem. This sequential approach, however, occasionally fails to capture the intricacies of local atomic arrangements accurately, thus compromising the integrity of the resultant structural models. Addressing these deficiencies, this work introduces an avant-garde generative framework: \\method{}, which is predicated on the diffusion principles found in classical non-equilibrium thermodynamics. \\method{} envisages atoms as discrete entities and is adept at guiding the reversal of diffusion morphing a distribution of stochastic noise back into coherent molecular forms through a process akin to a Markov chain. This transformation begins with the initial representation of a molecular graph in an abstract latent space, progressing to the realization of the three-dimensional forms via an elaborate bilevel optimization scheme, tailored to respect the task's specific requirements.",
        "comments": "arXiv admin note: text overlap with arXiv:2105.07246 by other authors",
        "date": "22 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09451"
    },
    {
        "doc_id": 319,
        "title": "Regenerative Medicine for Tendon/Ligament Injuries: De Novo Equine Tendon/Ligament Neotissue Generation and Application",
        "authors": [
            "Takashi Taguchi"
        ],
        "subjects": [
            "Tissues and Organs"
        ],
        "abstract": "Tendon and ligament injuries are debilitating conditions across species. Poor regenerative capacities of these tissues limit restoration of original functions. The first study of this dissertation evaluated the effect of cellular administration on tendon/ligament injuries in horses using meta-analysis. The findings led to the second study that engineered implantable de novo tendon neotissue using equine adipose-derived multipotent stromal cells and collagen type I. The neotendon was evaluated for its biocompatibility and therapeutic potential in the third study using immunocompetent and immunocompromised rat bilateral calcaneal tendon elongation model. The fourth study investigated the therapeutic effects of neotendon in surgically-induced non-terminal equine accessory ligament of deep digital flexor tendon injury model.",
        "comments": " ",
        "date": "24 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09423"
    },
    {
        "doc_id": 320,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 321,
        "title": "Graph-based vulnerability assessment of resting-state functional brain networks in full-term neonates",
        "authors": [
            "Mahshid Fouladivanda",
            "Kamran Kazemi",
            "Habibollah Danyali",
            "Ardalan Aarabi"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Quantitative Methods"
        ],
        "abstract": "Network disruption during early brain development can result in long-term cognitive impairments. In this study, we investigated rich-club organization in resting-state functional brain networks in full-term neonates using a multiscale connectivity analysis. We further identified the most influential nodes, also called spreaders, having higher impacts on the flow of information throughout the network. The network vulnerability to damage to rich-club (RC) connectivity within and between resting-state networks was also assessed using a graph-based vulnerability analysis. Our results revealed a rich club organization and small-world topology for resting-state functional brain networks in full term neonates, regardless of the network size. Interconnected mostly through short-range connections, functional rich-club hubs were confined to sensory-motor, cognitive-attention-salience (CAS), default mode, and language-auditory networks with an average cross-scale overlap of 36%, 20%, 15% and 12%, respectively. The majority of the functional hubs also showed high spreading potential, except for several non-RC spreaders within CAS and temporal networks. The functional networks exhibited high vulnerability to loss of RC nodes within sensorimotor cortices, resulting in a significant increase and decrease in network segregation and integration, respectively. The network vulnerability to damage to RC nodes within the language-auditory, cognitive-attention-salience, and default mode networks was also significant but relatively less prominent. Our findings suggest that the network integration in neonates can be highly compromised by damage to RC connectivity due to brain immaturity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09255"
    },
    {
        "doc_id": 322,
        "title": "Reproducibility via neural fields of visual illusions induced by localized stimuli",
        "authors": [
            "Cyprien Tamekue",
            "Dario Prandi",
            "Yacine Chitour"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Pattern Formation and Solitons"
        ],
        "abstract": "This paper investigates the replication of experiments by Billock and Tsou [PNAS, 2007] using the controllability of neural fields of Amari-type modelling the cortical activity in the primary visual cortex (V1), focusing on a regular funnel pattern localised in the fovea or the peripheral visual field. The aim is to understand and model the visual phenomena observed in these experiments, emphasising their nonlinear nature. The study involves designing sensory inputs simulating the visual stimuli from Billock and Tsou's experiments. The after-images induced by these inputs are then theoretically and numerically studied to determine their capacity to replicate the experimentally observed visual effects. A key aspect of this research is investigating the effects induced by the nonlinear nature of neural responses. In particular, by highlighting the importance of both excitatory and inhibitory neurons in the emergence of certain visual phenomena, this study suggests that an interplay of both types of neuronal activities plays an essential role in visual processes, challenging the assumption that the latter is mainly driven by excitatory activities alone.",
        "comments": "MSC Class:          92C20; 35B36; 45A05; 45G15; 45K05; 65R20",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09108"
    },
    {
        "doc_id": 323,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 324,
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "authors": [
            "Ziyang Yu",
            "Wenbing Huang",
            "Yang Liu"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08986"
    },
    {
        "doc_id": 325,
        "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
        "authors": [
            "Zahra Sheikhbahaee",
            "Adam Safron",
            "Casper Hesp",
            "Guillaume Dumas"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08873"
    },
    {
        "doc_id": 326,
        "title": "Using i-vectors for subject-independent cross-session EEG transfer learning",
        "authors": [
            "Jonathan Lasko",
            "Jeff Ma",
            "Mike Nicoletti",
            "Jonathan Sussman-Fort",
            "Sooyoung Jeong",
            "William Hartmann"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Cognitive load classification is the task of automatically determining an individual's utilization of working memory resources during performance of a task based on physiologic measures such as electroencephalography (EEG). In this paper, we follow a cross-disciplinary approach, where tools and methodologies from speech processing are used to tackle this problem. The corpus we use was released publicly in 2021 as part of the first passive brain-computer interface competition on cross-session workload estimation. We present our approach which used i-vector-based neural network classifiers to accomplish inter-subject cross-session EEG transfer learning, achieving 18% relative improvement over equivalent subject-dependent models. We also report experiments showing how our subject-independent models perform competitively on held-out subjects and improve with additional subject data, suggesting that subject-dependent training is not required for effective cognitive load determination.",
        "comments": "11 pages",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08851"
    },
    {
        "doc_id": 327,
        "title": "On the maximum value of the stairs2 index",
        "authors": [
            "Bryan Currie",
            "Kristina Wicke"
        ],
        "subjects": [
            "Combinatorics",
            "Populations and Evolution"
        ],
        "abstract": "Measures of tree balance play an important role in different research areas such as mathematical phylogenetics or theoretical computer science. The balance of a tree is usually quantified in a single number, called a balance or imbalance index, and several such indices exist in the literature. Here, we focus on the stairs2 balance index for rooted binary trees, which was first introduced in the context of viral phylogenetics but has not been fully analyzed from a mathematical viewpoint yet. While it is known that the caterpillar tree uniquely minimizes the stairs2 index for all leaf numbers and the fully balanced tree uniquely maximizes the stairs2 index for leaf numbers that are powers of two, understanding the maximum value and maximal trees for arbitrary leaf numbers is an open problem in the literature. In this note, we fill this gap by showing that for all leaf numbers, there is a unique rooted binary tree maximizing the stairs2 index. Additionally, we obtain recursive and closed expressions for the maximum value of the stairs2 index of a rooted binary tree with $n$ leaves.",
        "comments": "12 pages, 1 figure",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08838"
    },
    {
        "doc_id": 328,
        "title": "Mechanical constraints and cell cycle regulation in models of collective cell migration",
        "authors": [
            "Carles Falc\u00f3",
            "Daniel J. Cohen",
            "Jos\u00e9 A. Carrillo",
            "Ruth E. Baker"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biological Physics"
        ],
        "abstract": "The spatiotemporal coordination and regulation of cell proliferation is fundamental in many aspects of development and tissue maintenance. Cells have the ability to adapt their division rates in response to mechanical checkpoints, yet we do not fully understand how cell proliferation regulation impacts cell migration phenomena. Here, we present a minimal continuum model of cell migration with cell cycle dynamics, which includes mechanical constraints and hence can account for cell proliferation regulation. By combining minimal mathematical modelling, Bayesian inference, and recent experimental data, we quantify the impact of mechanical constraints across different cell cycle stages in epithelial tissue expansion experiments. Our model suggests that cells sense local density and adapt cell cycle progression in response, during G1 and the combined S/G2/M phases, providing an explicit relationship between each cell cycle stage duration and local tissue density, which is consistent with several experimental observations. Finally, we compare our mathematical model predictions to different experiments studying cell cycle regulation and present a quantitative analysis on the impact of mechanical constraints on cell migration patterns. Our work presents a systematic approach for investigating and analysing cell cycle data, providing mechanistic insights into how individual cells regulate proliferation, based on population-based experimental measurements.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08805"
    },
    {
        "doc_id": 329,
        "title": "Machine Learning-Based Analysis of Ebola Virus' Impact on Gene Expression in Nonhuman Primates",
        "authors": [
            "Mostafa Rezapour",
            "Muhammad Khalid Khan Niazi",
            "Hao Lu",
            "Aarthi Narayanan",
            "Metin Nafi Gurcan"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "This study introduces the Supervised Magnitude-Altitude Scoring (SMAS) methodology, a machine learning-based approach, for analyzing gene expression data obtained from nonhuman primates (NHPs) infected with Ebola virus (EBOV). We utilize a comprehensive dataset of NanoString gene expression profiles from Ebola-infected NHPs, deploying the SMAS system for nuanced host-pathogen interaction analysis. SMAS effectively combines gene selection based on statistical significance and expression changes, employing linear classifiers such as logistic regression to accurately differentiate between RT-qPCR positive and negative NHP samples. A key finding of our research is the identification of IFI6 and IFI27 as critical biomarkers, demonstrating exceptional predictive performance with 100% accuracy and Area Under the Curve (AUC) metrics in classifying various stages of Ebola infection. Alongside IFI6 and IFI27, genes, including MX1, OAS1, and ISG15, were significantly upregulated, highlighting their essential roles in the immune response to EBOV. Our results underscore the efficacy of the SMAS method in revealing complex genetic interactions and response mechanisms during EBOV infection. This research provides valuable insights into EBOV pathogenesis and aids in developing more precise diagnostic tools and therapeutic strategies to address EBOV infection in particular and viral infection in general.",
        "comments": "28 pages, 8 figures, 2 tables",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08738"
    },
    {
        "doc_id": 330,
        "title": "Survival Analysis of Young Triple-Negative Breast Cancer Patients",
        "authors": [
            "M. Mehdi Owrang O",
            "Fariba Jafari Horestani",
            "Ginger Schwarz"
        ],
        "subjects": [
            "Quantitative Methods",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "Breast cancer prognosis is crucial for effective treatment, with the disease more common in women over 40 years old but rare under 40 years old, where less than 5 percent of cases occur in the U.S. Studies indicate a worse prognosis in younger women, which varies by ethnicity. Breast cancers are classified based on receptors like estrogen, progesterone, and HER2. Triple-negative breast cancer (TNBC), lacking these receptors, accounts for about 15 percent of cases and is more prevalent in younger patients, often resulting in poorer outcomes. Nevertheless, the impact of age on TNBC prognosis remains unclear. Factors like age, race, tumor grade, size, and lymph node status are studied for their role in TNBC's clinical outcomes, but current research is inconclusive about age-related differences. This study uses SEER data set to examine the influence of younger age on survivability in TNBC patients, aiming to determine if age is a significant prognostic factor. Our experimental results on SEER dataset confirm the existing research reports that TNBC patients have worse prognosis compared to non-TNBC based on age. Our main goal was to investigate whether younger age has any significance on the survivability of TNBC patients. Experimental results do not show that younger age has any significance on the prognosis and survival rate of the TNBC patients",
        "comments": "31 Pages, 11 Figures, 7 Tables, Peer-reviewed article",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08712"
    },
    {
        "doc_id": 331,
        "title": "On Image Search in Histopathology",
        "authors": [
            "H. R. Tizhoosh",
            "Liron Pantanowitz"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Quantitative Methods"
        ],
        "abstract": "Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for nuanced quantification of cellular structures across diverse tissue types, facilitating comparisons and enabling inferences about diagnosis, prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08699"
    },
    {
        "doc_id": 332,
        "title": "Concept Alignment",
        "authors": [
            "Sunayana Rane",
            "Polyphony J. Bruna",
            "Ilia Sucholutsky",
            "Christopher Kello",
            "Thomas L. Griffiths"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Neurons and Cognition"
        ],
        "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has focused on value alignment, broadly referring to creating AI systems that share human values. We argue that before we can even attempt to align values, it is imperative that AI systems and humans align the concepts they use to understand the world. We integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. We summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. Finally, we explain how we can leverage the tools already being developed in cognitive science and AI research to accelerate progress towards concept alignment.",
        "comments": "NeurIPS MP2 Workshop 2023",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08672"
    },
    {
        "doc_id": 333,
        "title": "Validation and Comparison of Non-Stationary Cognitive Models: A Diffusion Model Application",
        "authors": [
            "Lukas Schumacher",
            "Martin Schnuerch",
            "Andreas Voss",
            "Stefan T. Radev"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "Cognitive processes undergo various fluctuations and transient states across different temporal scales. Superstatistics are emerging as a flexible framework for incorporating such non-stationary dynamics into existing cognitive model classes. In this work, we provide the first experimental validation of superstatistics and formal comparison of four non-stationary diffusion decision models in a specifically designed perceptual decision-making task. Task difficulty and speed-accuracy trade-off were systematically manipulated to induce expected changes in model parameters. To validate our models, we assess whether the inferred parameter trajectories align with the patterns and sequences of the experimental manipulations. To address computational challenges, we present novel deep learning techniques for amortized Bayesian estimation and comparison of models with time-varying parameters. Our findings indicate that transition models incorporating both gradual and abrupt parameter shifts provide the best fit to the empirical data. Moreover, we find that the inferred parameter trajectories closely mirror the sequence of experimental manipulations. Posterior re-simulations further underscore the ability of the models to faithfully reproduce critical data patterns. Accordingly, our results suggest that the inferred non-stationary dynamics may reflect actual changes in the targeted psychological constructs. We argue that our initial experimental validation paves the way for the widespread application of superstatistics in cognitive modeling and beyond.",
        "comments": " ",
        "date": "7 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08626"
    },
    {
        "doc_id": 334,
        "title": "Dynamic Brain Behaviours in Stroke: A Longitudinal Investigation Based on fMRI Analysis",
        "authors": [
            "Kaichao Wu",
            "Beth Jelfs",
            "Katrina Neville",
            "Qiang Fang"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Background: The brain's functional network constantly adapts to external changes. However, the mechanisms underlying this dynamic adaptive behavior in stroke patients with motor injuries and its role in post-stroke motor recovery remain poorly understood.\n  Method: This study conducted a long-term investigation involving 15 first-stroke patients. Each participant underwent five fMRI scans distributed equally over a six-month period. Using functional neuroimaging data, time-varying functional modularity in post-stroke patients was detected, and subsequently, the dynamic brain behaviors, including recruitment, integration, and flexibility, along with their longitudinal changes, were assessed.\n  Results: Our findings reveal that stroke lesions lead to significant and enduring alterations in all three dynamic behaviors within functional brain networks. Furthermore, during the six-month recovery period, patients who exhibited good and poor recovery showed notable differences in recruitment and flexibility, indicating distinct recovery trajectories for these groups. Notably, when predicting post-stroke recovery status, whole-brain recruitment emerged as a robust and reliable feature, achieving an AUC of 85.93\n  Significance: Our study offers a comprehensive depiction of dynamic brain behavior in the post-ischemic-stroke brain, with a focus on longitudinal changes concurrent with functional recovery. These dynamic patterns hold promise as valuable tools for evaluating and predicting motor recovery following stroke.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08607"
    },
    {
        "doc_id": 335,
        "title": "Long cycles in linear thresholding systems",
        "authors": [
            "Anna Laddach",
            "Michael Shapiro"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Linear thresholding systems have been used as a model of neural activation and more recently proposed as a model of gene regulation. Here we exhibit linear thresholding systems whose dynamics produce surprisingly long cycles.",
        "comments": "3 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08605"
    },
    {
        "doc_id": 336,
        "title": "From Conceptual Spaces to Quantum Concepts: Formalising and Learning Structured Conceptual Models",
        "authors": [
            "Sean Tull",
            "Razin A. Shaikh",
            "Sara Sabrina Zemljic",
            "Stephen Clark"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence",
            "Quantum Physics"
        ],
        "abstract": "In this article we present a new modelling framework for structured concepts using a category-theoretic generalisation of conceptual spaces, and show how the conceptual representations can be learned automatically from data, using two very different instantiations: one classical and one quantum. A contribution of the work is a thorough category-theoretic formalisation of our framework. We claim that the use of category theory, and in particular the use of string diagrams to describe quantum processes, helps elucidate some of the most important features of our approach. We build upon Gardenfors' classical framework of conceptual spaces, in which cognition is modelled geometrically through the use of convex spaces, which in turn factorise in terms of simpler spaces called domains. We show how concepts from the domains of shape, colour, size and position can be learned from images of simple shapes, where concepts are represented as Gaussians in the classical implementation, and quantum effects in the quantum one. In the classical case we develop a new model which is inspired by the Beta-VAE model of concepts, but is designed to be more closely connected with language, so that the names of concepts form part of the graphical model. In the quantum case, concepts are learned by a hybrid classical-quantum network trained to perform concept classification, where the classical image processing is carried out by a convolutional neural network and the quantum representations are produced by a parameterised quantum circuit. Finally, we consider the question of whether our quantum models of concepts can be considered conceptual spaces in the Gardenfors sense.",
        "comments": "This article consolidates our previous reports on concept formalisation and learning: arXiv:2302.14822 and arXiv:2203.11216",
        "date": "6 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08585"
    },
    {
        "doc_id": 337,
        "title": "How cytoskeletal crosstalk makes cells move: bridging cell-free and cell studies",
        "authors": [
            "James P. Conboy",
            "Irene Ist\u00fariz Petitjean",
            "Anouk van der Net",
            "Gijsje H. Koenderink"
        ],
        "subjects": [
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "Cell migration is a fundamental process for life and is highly dependent on the dynamical and mechanical properties of the cytoskeleton. Intensive physical and biochemical crosstalk between actin, microtubules, and intermediate filaments ensures their coordination to facilitate and enable migration. In this review we discuss the different mechanical aspects that govern cell migration and provide, for each mechanical aspect, a novel perspective by juxtaposing two complementary approaches to the biophysical study of cytoskeletal crosstalk: live-cell studies (often referred to as top-down studies) and cell-free studies (often referred to as bottom-up studies). We summarize the main findings from both experimental approaches, and we provide our perspective on bridging the two perspectives to address the open questions of how cytoskeletal crosstalk governs cell migration and makes cells move.",
        "comments": "4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08368"
    },
    {
        "doc_id": 338,
        "title": "dabih -- encrypted data storage and sharing platform",
        "authors": [
            "Michael Huttner",
            "Jakob Simeth",
            "Renato Liguori",
            "Fulvia Ferrazzi",
            "Rainer Spang"
        ],
        "subjects": [
            "Cryptography and Security",
            "Software Engineering",
            "Genomics"
        ],
        "abstract": "Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research. Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges.\n  Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management. dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format. Its approach to data security involves a two-stage envelope encryption process. We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism. The private key necessary for decrypting the data remains exclusively on the owner's device. Thus, accessing data is impossible without explicit permission from the keyholder.\n  Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries. Documentation is available as part of the web application.\n  Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions. All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files.",
        "comments": "16 pages including 4 figures and 5 appendices",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08333"
    },
    {
        "doc_id": 339,
        "title": "Multifractal organization of EEG signals in Multiple Sclerosis",
        "authors": [
            "Marcin W\u0105torek",
            "Wojciech Tomczyk",
            "Magda Gaw\u0142owska",
            "Natalia Golonka-Afek",
            "Aleksandra \u017byrkowska",
            "Monika Marona",
            "Marcin Wnuk",
            "Agnieszka S\u0142owik",
            "Jeremi K. Ochab",
            "Magdalena Fafrowicz",
            "Tadeusz Marek",
            "Pawe\u0142 O\u015bwi\u0119cimka"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Disordered Systems and Neural Networks",
            "Adaptation and Self-Organizing Systems",
            "Quantitative Methods"
        ],
        "abstract": "Quantifying the complex/multifractal organization of the brain signals is crucial to fully understanding the brain processes and structure. In this contribution, we performed the multifractal analysis of the electroencephalographic (EEG) data obtained from a controlled multiple sclerosis (MS) study, focusing on the correlation between the degree of multifractality, disease duration, and disability level. Our results reveal a significant correspondence between the complexity of the time series and multiple sclerosis development, quantified respectively by scaling exponents and the Expanded Disability Status Scale (EDSS). Namely, for some brain regions, a well-developed multifractality and little persistence of the time series were identified in patients with a high level of disability, whereas the control group and patients with low EDSS were characterised by persistence and monofractality of the signals. The analysis of the cross-correlations between EEG signals supported these results, with the most significant differences identified for patients with EDSS $> 1$ and the combined group of patients with EDSS $\\leq 1$ and controls. No association between the multifractality and disease duration was observed, indicating that the multifractal organisation of the data is a hallmark of developing the disease. The observed complexity/multifractality of EEG signals is hypothetically a result of neuronal compensation -- i.e., of optimizing neural processes in the presence of structural brain degeneration. The presented study is highly relevant due to the multifractal formalism used to quantify complexity and due to scarce resting-state EEG evidence for cortical reorganization associated with compensation.",
        "comments": "39 pages, including supplementary materials (11 figures, 4 tables)",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08321"
    },
    {
        "doc_id": 340,
        "title": "Sources of HIV infections among MSM with a migration background: a viral phylogenetic case study in Amsterdam, the Netherlands",
        "authors": [
            "Alexandra Blenkinsop",
            "Nikos Pantazis",
            "Evangelia Georgia Kostaki",
            "Lysandros Sofocleous",
            "Ard van Sighem",
            "Daniela Bezemer",
            "Thijs van de Laar",
            "Marc van der Valk",
            "Peter Reiss",
            "Godelieve de Bree",
            "Oliver Ratmann"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Background: Men and women with a migration background comprise an increasing proportion of incident HIV cases across Western Europe. Several studies indicate a substantial proportion acquire HIV post-migration.\n  Methods: We used partial HIV consensus sequences with linked demographic and clinical data from the opt-out ATHENA cohort of people with HIV in the Netherlands to quantify population-level sources of transmission to Dutch-born and foreign-born Amsterdam men who have sex with men (MSM) between 2010-2021. We identified phylogenetically and epidemiologically possible transmission pairs in local transmission chains and interpreted these in the context of estimated infection dates, quantifying transmission dynamics between sub-populations by world region of birth.\n  Results: We estimate the majority of Amsterdam MSM who acquired their infection locally had a Dutch-born Amsterdam MSM source (56% [53-58%]). Dutch-born MSM were the predominant source population of infections among almost all foreign-born Amsterdam MSM sub-populations. Stratifying by two-year intervals indicated shifts in transmission dynamics, with a majority of infections originating from foreign-born MSM since 2018, although uncertainty ranges remained wide.\n  Conclusions: In the context of declining HIV incidence among Amsterdam MSM, our data suggest whilst native-born MSM have predominantly driven transmissions in 2010-2021, the contribution from foreign-born MSM living in Amsterdam is increasing.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08308"
    },
    {
        "doc_id": 341,
        "title": "Attention-Based CNN-BiLSTM for Sleep State Classification of Spatiotemporal Wide-Field Calcium Imaging Data",
        "authors": [
            "Xiaohui Zhang",
            "Eric C. Landsness",
            "Hanyang Miao",
            "Wei Chen",
            "Michelle Tang",
            "Lindsey M. Brier",
            "Joseph P. Culver",
            "Jin-Moo Lee",
            "Mark A. Anastasio"
        ],
        "subjects": [
            "Image and Video Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Background: Wide-field calcium imaging (WFCI) with genetically encoded calcium indicators allows for spatiotemporal recordings of neuronal activity in mice. When applied to the study of sleep, WFCI data are manually scored into the sleep states of wakefulness, non-REM (NREM) and REM by use of adjunct EEG and EMG recordings. However, this process is time-consuming, invasive and often suffers from low inter- and intra-rater reliability. Therefore, an automated sleep state classification method that operates on spatiotemporal WFCI data is desired. New Method: A hybrid network architecture consisting of a convolutional neural network (CNN) to extract spatial features of image frames and a bidirectional long short-term memory network (BiLSTM) with attention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Results: Sleep states were classified with an accuracy of 84% and Cohen's kappa of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while posterior area contributes most to the identification of wakefulness. The attention scores indicated that the proposed network focuses on short- and long-range temporal dependency in a state-specific manner. Comparison with Existing Method: On a 3-hour WFCI recording, the CNN-BiLSTM achieved a kappa of 0.67, comparable to a kappa of 0.65 corresponding to the human EEG/EMG-based scoring. Conclusions: The CNN-BiLSTM effectively classifies sleep states from spatiotemporal WFCI data and will enable broader application of WFCI in sleep.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08098"
    },
    {
        "doc_id": 342,
        "title": "A new model of trust based on neural information processing",
        "authors": [
            "Scott E. Allen",
            "Ren\u00e9 F. Kizilcec",
            "A. David Redish"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction",
            "Neurons and Cognition"
        ],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08064"
    },
    {
        "doc_id": 343,
        "title": "Understanding YTHDF2-mediated mRNA Degradation By m6A-BERT-Deg",
        "authors": [
            "Ting-He Zhang",
            "Sumin Jo",
            "Michelle Zhang",
            "Kai Wang",
            "Shou-Jiang Gao",
            "Yufei Huang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "N6-methyladenosine (m6A) is the most abundant mRNA modification within mammalian cells, holding pivotal significance in the regulation of mRNA stability, translation, and splicing. Furthermore, it plays a critical role in the regulation of RNA degradation by primarily recruiting the YTHDF2 reader protein. However, the selective regulation of mRNA decay of the m6A-methylated mRNA through YTHDF2 binding is poorly understood. To improve our understanding, we developed m6A-BERT-Deg, a BERT model adapted for predicting YTHDF2-mediated degradation of m6A-methylated mRNAs. We meticulously assembled a high-quality training dataset by integrating multiple data sources for the HeLa cell line. To overcome the limitation of small training samples, we employed a pre-training-fine-tuning strategy by first performing a self-supervised pre-training of the model on 427,760 unlabeled m6A site sequences. The test results demonstrated the importance of this pre-training strategy in enabling m6A-BERT-Deg to outperform other benchmark models. We further conducted a comprehensive model interpretation and revealed a surprising finding that the presence of co-factors in proximity to m6A sites may disrupt YTHDF2-mediated mRNA degradation, subsequently enhancing mRNA stability. We also extended our analyses to the HEK293 cell line, shedding light on the context-dependent YTHDF2-mediated mRNA degradation.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08004"
    },
    {
        "doc_id": 344,
        "title": "Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series Clustering",
        "authors": [
            "Hamid Ghaderi",
            "Brandon Foreman",
            "Chandan K. Reddy",
            "Vignesh Subbian"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses. While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap. Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates. Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets. Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets. Our analysis revealed three generalizable TBI phenotypes (\u03b1, \\b{eta}, and \u03b3), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays. Specifically, phenotype \u03b1 represents mild TBI with a remarkably consistent clinical presentation. In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype \u03b3 represents a moderate TBI profile in terms of severity and clinical diversity. Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates. Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations.",
        "comments": "25 pages, 10 figures, 4 tables, submitted to Computers in Biology and Medicine",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08002"
    },
    {
        "doc_id": 345,
        "title": "Integrate Any Omics: Towards genome-wide data integration for patient stratification",
        "authors": [
            "Shihao Ma",
            "Andy G. X. Zeng",
            "Benjamin Haibe-Kains",
            "Anna Goldenberg",
            "John E Dick",
            "Bo Wang"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "High-throughput omics profiling advancements have greatly enhanced cancer patient stratification. However, incomplete data in multi-omics integration presents a significant challenge, as traditional methods like sample exclusion or imputation often compromise biological diversity and dependencies. Furthermore, the critical task of accurately classifying new patients with partial omics data into existing subtypes is commonly overlooked. To address these issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised framework for integrating incomplete multi-omics data and classifying new samples. IntegrAO first combines partially overlapping patient graphs from diverse omics sources and utilizes graph neural networks to produce unified patient embeddings. Our systematic evaluation across five cancer cohorts involving six omics modalities demonstrates IntegrAO's robustness to missing data and its accuracy in classifying new samples with partial profiles. An acute myeloid leukemia case study further validates its capability to uncover biological and clinical heterogeneity in incomplete datasets. IntegrAO's ability to handle heterogeneous and incomplete data makes it an essential tool for precision oncology, offering a holistic approach to patient characterization.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07937"
    },
    {
        "doc_id": 346,
        "title": "Predicting heteropolymer interactions: demixing and hypermixing of disordered protein sequences",
        "authors": [
            "Kyosuke Adachi",
            "Kyogo Kawaguchi"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Cells contain multiple condensates which spontaneously form due to the heterotypic interactions between their components. Although the proteins and disordered region sequences that are responsible for condensate formation have been extensively studied, the rule of interactions between the components that allow demixing, i.e., the coexistence of multiple condensates, is yet to be elucidated. Here we construct an effective theory of the interaction between heteropolymers by fitting it to the molecular dynamics simulation results obtained for more than 200 sequences sampled from the disordered regions of human proteins. We find that the sum of amino acid pair interactions across two heteropolymers predicts the Boyle temperature qualitatively well, which can be quantitatively improved by the dimer pair approximation, where we incorporate the effect of neighboring amino acids in the sequences. The improved theory, combined with the finding of a metric that captures the effective interaction strength between distinct sequences, allowed the selection of up to three disordered region sequences that demix with each other in multicomponent simulations, as well as the generation of artificial sequences that demix with a given sequence. The theory points to a generic sequence design strategy to demix or hypermix thanks to the low dimensional nature of the space of the interactions that we identify. As a consequence of the geometric arguments in the space of interactions, we find that the number of distinct sequences that can demix with each other is strongly constrained, irrespective of the choice of the coarse-grained model. Altogether, we construct a theoretical basis for methods to estimate the effective interaction between heteropolymers, which can be utilized in predicting phase separation properties as well as rules of assignment in the localization and functions of disordered proteins.",
        "comments": "20 pages, 21 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07826"
    },
    {
        "doc_id": 347,
        "title": "Phenotyping calcification in vascular tissues using artificial intelligence",
        "authors": [
            "Mehdi Ramezanpour",
            "Anne M. Robertson",
            "Yasutaka Tobe",
            "Xiaowei Jia",
            "Juan R. Cebral"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Data Analysis, Statistics and Probability",
            "Quantitative Methods",
            "Tissues and Organs"
        ],
        "abstract": "Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke. A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools. Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies. Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes. However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets. Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues. The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology. This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours. Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues. By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07825"
    },
    {
        "doc_id": 348,
        "title": "Animal-associated marine Acidobacteria with a rich natural product repertoire",
        "authors": [
            "Stefan Leopold-Messer",
            "Clara Chepkirui",
            "Mathijs F. J. Mabesoone",
            "Joshua Mayer",
            "Lucas Paoli",
            "Shinichi Sunagawa",
            "Agustinus R. Uria",
            "Toshiyuki Wakimoto",
            "J\u00f6rn Piel"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Sponges have long been recognized as a rich source of bioactive natural products. Various studies suggest that many of these compounds are produced by symbiotic bacteria. However, substance supplies and functional insights about the producers remain limited because cultivation remains unsuccessful. To identify alternative, sustainable sources of sponge-derived polyketides, we computationally analyzed 5289 characterized and orphan trans-acyltransferase polyketide synthases, enzymes with widespread roles in polyketide biosynthesis by bacterial symbionts. The analytical workflow predicted marine animal-derived Acidobacteria of the family Acanthopleuribacteraceae with large sets of biosynthetic gene clusters to be enriched in sponge-type chemistry. Targeted compound isolation from a chiton-associated strain yielded new congeners of the phorboxazoles and calyculins, potent and scarce cytotoxins exclusively known from sponges. These first natural products of Acidobacteria and new coral metagenomic data on a third family member suggest animal-associated Acanthopleuribacteraceae as a rich source of sponge-type as well as novel metabolites",
        "comments": "Journal ref:        Chem, 9 (12), 2023, pp. 3696-3713",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07730"
    },
    {
        "doc_id": 349,
        "title": "Comprehensive Joint Modeling of First-Line Therapeutics in Non-Small Cell Lung Cancer",
        "authors": [
            "Benjamin Schneider",
            "S\u00e9bastien Benzekry",
            "Jonathan Mochel"
        ],
        "subjects": [
            "Cell Behavior",
            "Tissues and Organs"
        ],
        "abstract": "First-line antiproliferatives for non-small cell lung cancer (NSCLC) have a relatively high failure rate due to high intrinsic resistance rates and acquired resistance rates to therapy. 57% patients are diagnosed in late-stage disease due to the tendency of early-stage NSCLC to be asymptomatic. For patients first diagnosed with metastatic disease the 5-year survival rate is approximately 5%. To help accelerate the development of novel therapeutics and computer-based tools for optimizing individual therapy, we have collated data from 11 different clinical trials in NSCLC and developed a semi-mechanistic, clinical model of NSCLC growth and pharmacodynamics relative to the various therapeutics represented in the study. In this study, we have produced extremely precise estimates of clinical parameters fundamental to cancer modeling such as the rate of acquired resistance to various pharmaceuticals, the relationship between drug concentration and rate of cancer cell death, as well as the fine temporal dynamics of anti-VEGF therapy. In the simulation sets documented in this study, we have used the model to make meaningful descriptions of efficacy gain in making bevacizumab-antiproliferative combination therapy sequential, over a series of days, rather than concurrent.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07719"
    },
    {
        "doc_id": 350,
        "title": "Ion channels in critical membranes: clustering, cooperativity, and memory effects",
        "authors": [
            "Antonio Suma",
            "Daniel Sigg",
            "Seamus Gallagher",
            "Giuseppe Gonnella",
            "Vincenzo Carnevale"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Much progress has been made in elucidating the inner workings of voltage-gated ion channels, but less understood is the influence of lipid rafts on gating kinetics. Here we propose that state-dependent channel affinity for different lipid species provides a unified explanation for the experimentally observed behaviors of clustering, cooperativity, and hysteresis. We develop models of diffusing lipids and channels engaged in Ising-like interactions to investigate the collective behaviors driven by raft formation in critical membranes close to the demixing transition. The model channels demonstrate lipid-mediated long-range interactions, activation curve steepening, and long-term memory in ionic currents. These behaviors likely play a role in channel-mediated cellular signaling and suggest a universal mechanism for self-organization of biomolecular assemblies.",
        "comments": "14 pages, 6 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07660"
    },
    {
        "doc_id": 351,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 352,
        "title": "Measuring multisensory integration in reaction time: the relative entropy approach",
        "authors": [
            "Hans Colonius",
            "Adele Diederich"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "A classic definition of multisensory integration (MI) has been proposed as ``the presence of a (statistically) significant change in the response to a cross-modal stimulus complex compared to unimodal stimuli''. However, this general definition did not result in a broad consensus on how to quantify the amount of MI in the context of reaction time (RT). In this brief note, we argue that numeric measures of reaction times that only involve mean or median RTs do not uncover the information required to fully assess the effect of multisensory integration. We suggest instead novel measures that include the entire RT distributions functions. The central role is played by relative entropy (aka Kullback-Leibler divergence), a statistical concept in information theory, statistics, and machine learning to measure the (non-symmetric) distance between probability distributions. We provide a number of theoretical examples, but empirical applications and statistical testing are postponed to later study.",
        "comments": "9 pages, 1 figure",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07568"
    },
    {
        "doc_id": 353,
        "title": "Vitamin K content of Australian-grown horticultural commodities",
        "authors": [
            "Eleanor Dunlop",
            "Judy Cunningham",
            "Paul Adorno",
            "Georgios Dabos",
            "Stuart K Johnson",
            "Lucinda J Black"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Vitamin K is emerging as a multi-function vitamin that plays a role in bone, brain and vascular health. Vitamin K composition data remain limited globally and Australia has lacked nationally representative data for vitamin K1 (phylloquinone, PK) in horticultural commodities. Primary samples (n = 927) of 90 different Australian-grown fruit, vegetable and nut commodities were purchased in three Australian cities. We measured PK in duplicate in 95 composite samples using liquid chromatography with electrospray ionisation-tandem mass spectrometry. The greatest mean concentrations of PK were found in kale (565 ug/100 g), baby spinach (255 ug/100 g) and Brussels sprouts (195 ug/100 g). The data contribute to the global collection of vitamin K food composition data. They add to the evidence that PK concentrations vary markedly between geographic regions, supporting development of region-specific datasets for national food composition databases that do not yet contain data for vitamin K.",
        "comments": "22 pages, 2 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07473"
    },
    {
        "doc_id": 354,
        "title": "Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks",
        "authors": [
            "Maria Mircea",
            "Diego Garlaschelli",
            "Stefan Semrau"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning",
            "Molecular Networks"
        ],
        "abstract": "One of the main goals of developmental biology is to reveal the gene regulatory networks (GRNs) underlying the robust differentiation of multipotent progenitors into precisely specified cell types. Most existing methods to infer GRNs from experimental data have limited predictive power as the inferred GRNs merely reflect gene expression similarity or correlation. Here, we demonstrate, how physics-informed neural networks (PINNs) can be used to infer the parameters of predictive, dynamical GRNs that provide mechanistic understanding of biological processes. Specifically we study GRNs that exhibit bifurcation behavior and can therefore model cell differentiation. We show that PINNs outperform regular feed-forward neural networks on the parameter inference task and analyze two relevant experimental scenarios: 1. a system with cell communication for which gene expression trajectories are available and 2. snapshot measurements of a cell population in which cell communication is absent. Our analysis will inform the design of future experiments to be analyzed with PINNs and provides a starting point to explore this powerful class of neural network models further.",
        "comments": "25 pages, 8 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07379"
    },
    {
        "doc_id": 355,
        "title": "Robust Genomic Prediction and Heritability Estimation using Density Power Divergence",
        "authors": [
            "Upama Paul Chowdhury",
            "Susmita Das",
            "Abhik Ghosh"
        ],
        "subjects": [
            "Methodology",
            "Genomics",
            "Applications"
        ],
        "abstract": "This manuscript delves into the intersection of genomics and phenotypic prediction, focusing on the statistical innovation required to navigate the complexities introduced by noisy covariates and confounders. The primary emphasis is on the development of advanced robust statistical models tailored for genomic prediction from single nucleotide polymorphism (SNP) data collected from genome-wide association studies (GWAS) in plant and animal breeding and multi-field trials. The manuscript explores the limitations of traditional marker-assisted recurrent selection, highlighting the significance of incorporating all estimated effects of marker loci into the statistical framework and aiming to reduce the high dimensionality of GWAS data while preserving critical information. This paper introduces a new robust statistical framework for genomic prediction, employing one-stage and two-stage linear mixed model analyses along with utilizing the popular robust minimum density power divergence estimator (MDPDE) to estimate genetic effects on phenotypic traits. The study illustrates the superior performance of the proposed MDPDE-based genomic prediction and associated heritability estimation procedures over existing competitors through extensive empirical experiments on artificial datasets and application to a real-life maize breeding dataset. The results showcase the robustness and accuracy of the proposed MDPDE-based approaches, especially in the presence of data contamination, emphasizing their potential applications in improving breeding programs and advancing genomic prediction of phenotyping traits.",
        "comments": "Under Review",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07344"
    },
    {
        "doc_id": 356,
        "title": "Phenotypic switching mechanisms determine the structure of cell migration into extracellular matrix under the `go-or-grow' hypothesis",
        "authors": [
            "Rebecca M. Crossley",
            "Kevin J. Painter",
            "Tommaso Lorenzi",
            "Philip K. Maini",
            "Ruth E. Baker"
        ],
        "subjects": [
            "Cell Behavior"
        ],
        "abstract": "A fundamental feature of collective cell migration is phenotypic heterogeneity which, for example, influences tumour progression and relapse. While current mathematical models often consider discrete phenotypic structuring of the cell population, in-line with the `go-or-grow' hypothesis \\cite{hatzikirou2012go, stepien2018traveling}, they regularly overlook the role that the environment may play in determining the cells' phenotype during migration. Comparing a previously studied volume-filling model for a homogeneous population of generalist cells that can proliferate, move and degrade extracellular matrix (ECM) \\cite{crossley2023travelling} to a novel model for a heterogeneous population comprising two distinct sub-populations of specialist cells that can either move and degrade ECM or proliferate, this study explores how different hypothetical phenotypic switching mechanisms affect the speed and structure of the invading cell populations. Through a continuum model derived from its individual-based counterpart, insights into the influence of the ECM and the impact of phenotypic switching on migrating cell populations emerge. Notably, specialist cell populations that cannot switch phenotype show reduced invasiveness compared to generalist cell populations, while implementing different forms of switching significantly alters the structure of migrating cell fronts. This key result suggests that the structure of an invading cell population could be used to infer the underlying mechanisms governing phenotypic switching.",
        "comments": "34 pages, 11 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07279"
    },
    {
        "doc_id": 357,
        "title": "Balancing reaction-diffusion network for cell polarization pattern with stability and asymmetry",
        "authors": [
            "Yixuan Chen",
            "Guoye Guan",
            "Lei-Han Tang",
            "Chao Tang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Cell polarization is a critical process that separates molecules into two distinct regions in prokaryotic and eukaryotic cells, guiding biological processes such as cell division and cell differentiation. Although several underlying antagonistic reaction-diffusion networks capable of setting up cell polarization have been identified experimentally and theoretically, our understanding of how to manipulate pattern stability and asymmetry remains incomplete, especially when only a subset of network components are known. Here we present numerical results to show that the polarized pattern of an antagonistic 2-node network collapses into a homogeneous state when subjected to single-sided self-regulation, single-sided additional regulation, or unequal system parameters. However, polarity can be restored through a combination of two modifications that have opposing effects. Additionally, spatially inhomogeneous parameters favoring respective domains stabilize their interface at designated locations. To connect our findings to cell polarity studies of the nematode Caenorhabditis elegans zygote, we reconstituted a 5-node network where a 4-node circuit with full mutual inhibitions between anterior and posterior is modified by a mutual activation in the anterior and an additional mutual inhibition between the anterior and the posterior. Once again, a generic set of kinetic parameters moves the interface towards either the anterior or posterior end, yet a polarized pattern can be stabilized through spatial tuning of one or more parameters coupled to intracellular or extracellular cues. A user-friendly software, PolarSim, is introduced to facilitate the exploration of networks with alternative node numbers, parameter values, and regulatory pathways.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07227"
    },
    {
        "doc_id": 358,
        "title": "Dynamics of bacterial aggregates in microflows",
        "authors": [
            "Ana Carpio",
            "Baldvin Einarsson",
            "David R. Espeso"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Fluid Dynamics",
            "Cell Behavior"
        ],
        "abstract": "Biofilms are bacterial aggregates that grow on moist surfaces. Thin homogeneous biofilms naturally formed on the walls of conducts may serve as biosensors, providing information on the status of microsystems (MEMS) without disrupting them. However, uncontrolled biofilm growth may largely disturb the environment they develop in, increasing the drag and clogging the tubes. To ensure controlled biofilm expansion we need to understand the effect of external variables on their structure. We formulate a hybrid model for the computational study of biofilms growing in laminar microflows. Biomass evolves according to stochastic rules for adhesion, erosion and motion, informed by numerical approximations of the flow fields at each stage. The model is tested studying the formation of streamers in three dimensional corner flows, gaining some insight on the effect of external variables on their structure.",
        "comments": "Journal ref:        in Progress in Industrial Mathematics at ECMI 2014, Mathematics in Industry 22, 397-405, Springer 2016",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07138"
    },
    {
        "doc_id": 359,
        "title": "Biofilm growth on rugose surfaces",
        "authors": [
            "David Rodriguez",
            "Baldvin Einarsson",
            "Ana Carpio"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Computational Physics",
            "Cell Behavior"
        ],
        "abstract": "A stochastic model is used to assess the effect of external parameters on the development of submerged biofilms on smooth and rough surfaces. The model includes basic cellular mechanisms, such as division and spreading, together with an elementary description of the interaction with the surrounding flow and probabilistic rules for EPS matrix generation, cell decay and adhesion. Insight on the interplay of competing mechanisms as the flow or the nutrient concentration change is gained. Erosion and growth processes combined produce biofilm structures moving downstream. A rich variety of patterns are generated: shrinking biofilms, patches, ripple-like structures traveling downstream, fingers, mounds, streamer-like patterns, flat layers, porous and dendritic structures. The observed regimes depend on the carbon source and the type of bacteria.",
        "comments": "Journal ref:        Physical Review E 86(6), 061914, 2012",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07135"
    },
    {
        "doc_id": 360,
        "title": "IVIM-Morph: Motion-compensated quantitative Intra-voxel Incoherent Motion (IVIM) analysis for functional fetal lung maturity assessment from diffusion-weighted MRI data",
        "authors": [
            "Noga Kertes",
            "Yael Zaffrani-Reznikov",
            "Onur Afacan",
            "Sila Kurugol",
            "Simon K. Warfield",
            "Moti Freiman"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Quantitative analysis of pseudo-diffusion in diffusion-weighted magnetic resonance imaging (DWI) data shows potential for assessing fetal lung maturation and generating valuable imaging biomarkers. Yet, the clinical utility of DWI data is hindered by unavoidable fetal motion during acquisition. We present IVIM-morph, a self-supervised deep neural network model for motion-corrected quantitative analysis of DWI data using the Intra-voxel Incoherent Motion (IVIM) model. IVIM-morph combines two sub-networks, a registration sub-network, and an IVIM model fitting sub-network, enabling simultaneous estimation of IVIM model parameters and motion. To promote physically plausible image registration, we introduce a biophysically informed loss function that effectively balances registration and model-fitting quality. We validated the efficacy of IVIM-morph by establishing a correlation between the predicted IVIM model parameters of the lung and gestational age (GA) using fetal DWI data of 39 subjects. IVIM-morph exhibited a notably improved correlation with gestational age (GA) when performing in-vivo quantitative analysis of fetal lung DWI data during the canalicular phase. IVIM-morph shows potential in developing valuable biomarkers for non-invasive assessment of fetal lung maturity with DWI data. Moreover, its adaptability opens the door to potential applications in other clinical contexts where motion compensation is essential for quantitative DWI analysis. The IVIM-morph code is readily available at: https://github.com/TechnionComputationalMRILab/qDWI-Morph.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07126"
    },
    {
        "doc_id": 361,
        "title": "Incorporating Cellular Stochasticity in Solid--Fluid Mixture Biofilm Models",
        "authors": [
            "Ana Carpio",
            "Elena Cebrian"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "The dynamics of cellular aggregates is driven by the interplay of mechanochemical processes and cellular activity. Although deterministic models may capture mechanical features, local chemical fluctuations trigger random cell responses, which determine the overall evolution. Incorporating stochastic cellular behavior in macroscopic models of biological media is a challenging task. Herein, we propose hybrid models for bacterial biofilm growth, which couple a two phase solid/fluid mixture description of mechanical and chemical fields with a dynamic energy budget-based cellular automata treatment of bacterial activity. Thin film and plate approximations for the relevant interfaces allow us to obtain numerical solutions exhibiting behaviors observed in experiments, such as accelerated spread due to water intake from the environment, wrinkle formation, undulated contour development, and the appearance of inhomogeneous distributions of differentiated bacteria performing varied tasks.",
        "comments": "Journal ref:        Entropy 22(2), 188, 2020",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07088"
    },
    {
        "doc_id": 362,
        "title": "Biofilms as poroelastic materials",
        "authors": [
            "Ana Carpio",
            "Elena Cebrian",
            "Perfecto Vidal"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "Biofilms are bacterial aggregates encased in a self-produced polymeric matrix which attach to moist surfaces and are extremely resistant to chemicals and antibiotics. Recent experiments show that their structure is defined by the interplay of elastic deformations and liquid transport within the biofilm, in response to the cellular activity and the interaction with the surrounding environment. We propose a poroelastic model for elastic deformation and liquid transport in three dimensional biofilms spreading on agar surfaces. The motion of the boundaries can be described by the combined use of Von Karman type approximations for the agar/biofilm interface and thin film approximations for the biofilm/air interface. Bacterial activity informs the macroscopic continuous model through source terms and residual stresses, either phenomenological or derived from microscopic models. We present a procedure to estimate the structure of such residual stresses, based on a simple cellular automata description of bacterial activity. Inspired by image processing, we show that a filtering strategy effectively smooths out the rough tensors provided by the stochastic cellular automata rules, allowing us to insert them in the macroscopic model without numerical instability.",
        "comments": "Journal ref:        International Journal of Non-linear Mechanics 109, 1-8, 2019",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07060"
    },
    {
        "doc_id": 363,
        "title": "\"Bayesian anchoring\" and the fourfold pattern of risk attitudes",
        "authors": [
            "Francesco Fumarola",
            "Lukasz Kusmierz",
            "Ronald B. Dekker"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Experiments on decision making under uncertainty are known to display a classical pattern of risk aversion and risk seeking referred to as \"fourfold pattern\" (or \"reflection effect\") , but recent experiments varying the speed and order of mental processing have brought to light a more nuanced phenomenology. We model experiments though a Bayesian formalization of the anchor-and-adjust heuristic observed in empirical studies on cognitive bias. Using only elementary assumptions on constrained information processing, we are able to infer three separate effects found in recent observations: (1) the reported enhancement of the fourfold pattern for quicker decision processes; (2) the observed decrease of fluctuations for slower decision-making trials; (3) the reported dependence of the outcome on the order in which options are processed. The application of Bayesian modeling offers a solution to recent empirical riddles by bridging two heretofore separate domains of experimental inquiry on bounded rationality.",
        "comments": "26 pages, 7 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07023"
    },
    {
        "doc_id": 364,
        "title": "Iron role paradox in nerve degeneration and regeneration",
        "authors": [
            "Samira Bolandghamat",
            "Morteza Behnam-Rassouli"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Tissues and Organs"
        ],
        "abstract": "Iron accumulates in the neural tissue during peripheral nerve degeneration. Some studies have already been suggested that iron facilitates Wallerian degeneration (WD) events such as Schwann cell de-differentiation. On the other hand, intracellular iron levels remain elevated during nerve regeneration and gradually decrease. Iron enhances Schwann cell differentiation and axonal outgrowth. Therefore, there seems to be a paradox in the role of iron during nerve degeneration and regeneration. We explain this contradiction by suggesting that the increase in intracellular iron concentration during peripheral nerve degeneration is likely to prepare neural cells for the initiation of regeneration. Changes in iron levels are the result of changes in the expression of iron homeostasis proteins. In this review, we will first discuss the changes in the iron/iron homeostasis protein levels during peripheral nerve degeneration and regeneration and then explain how iron is related to nerve regeneration. This data may help better understand the mechanisms of peripheral nerve repair and find a solution to prevent or slow the progression of peripheral neuropathies.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07016"
    },
    {
        "doc_id": 365,
        "title": "Cramer-Rao bound and absolute sensitivity in chemical reaction networks",
        "authors": [
            "Dimitri Loutchko",
            "Yuki Sughiyama",
            "Tetsuya J. Kobayashi"
        ],
        "subjects": [
            "Molecular Networks",
            "Information Theory",
            "Biological Physics",
            "Chemical Physics"
        ],
        "abstract": "Chemical reaction networks (CRN) comprise an important class of models to understand biological functions such as cellular information processing, the robustness and control of metabolic pathways, circadian rhythms, and many more. However, any CRN describing a certain function does not act in isolation but is a part of a much larger network and as such is constantly subject to external changes. In [Shinar, Alon, and Feinberg. \"Sensitivity and robustness in chemical reaction networks.\" SIAM J App Math (2009): 977-998.], the responses of CRN to changes in the linear conserved quantities, called sensitivities, were studied in and the question of how to construct absolute, i.e., basis-independent, sensitivities was raised. In this article, by applying information geometric methods, such a construction is provided. The idea is to track how concentration changes in a particular chemical propagate to changes of all the other chemicals within a steady state. This is encoded in the matrix of absolute sensitivites. A linear algebraic characterization of the matrix of absolute sensitivities for quasi-thermostatic CRN is derived via a Cramer-Rao bound for CRN, which is based on the the analogy between quasi-thermostatic steady states and the exponential family of probability distributions.",
        "comments": "21 pages, 3 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06987"
    },
    {
        "doc_id": 366,
        "title": "NHANES-GCP: Leveraging the Google Cloud Platform and BigQuery ML for reproducible machine learning with data from the National Health and Nutrition Examination Survey",
        "authors": [
            "B. Ross Katz",
            "Abdul Khan",
            "James York-Winegar",
            "Alexander J. Titus"
        ],
        "subjects": [
            "Quantitative Methods",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "Summary: NHANES, the National Health and Nutrition Examination Survey, is a program of studies led by the Centers for Disease Control and Prevention (CDC) designed to assess the health and nutritional status of adults and children in the United States (U.S.). NHANES data is frequently used by biostatisticians and clinical scientists to study health trends across the U.S., but every analysis requires extensive data management and cleaning before use and this repetitive data engineering collectively costs valuable research time and decreases the reproducibility of analyses. Here, we introduce NHANES-GCP, a Cloud Development Kit for Terraform (CDKTF) Infrastructure-as-Code (IaC) and Data Build Tool (dbt) resources built on the Google Cloud Platform (GCP) that automates the data engineering and management aspects of working with NHANES data. With current GCP pricing, NHANES-GCP costs less than $2 to run and less than $15/yr of ongoing costs for hosting the NHANES data, all while providing researchers with clean data tables that can readily be integrated for large-scale analyses. We provide examples of leveraging BigQuery ML to carry out the process of selecting data, integrating data, training machine learning and statistical models, and generating results all from a single SQL-like query. NHANES-GCP is designed to enhance the reproducibility of analyses and create a well-engineered NHANES data resource for statistics, machine learning, and fine-tuning Large Language Models (LLMs).\n  Availability and implementation\" NHANES-GCP is available at https://github.com/In-Vivo-Group/NHANES-GCP",
        "comments": "7 pages, 1 figure",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06967"
    },
    {
        "doc_id": 367,
        "title": "Quantifying energy landscape of oscillatory systems: Explosion, pre-solution, and diffusion decomposition",
        "authors": [
            "Shirui Bian",
            "Ruisong Zhou",
            "Wei Lin",
            "Chunhe Li"
        ],
        "subjects": [
            "Quantitative Methods",
            "Molecular Networks"
        ],
        "abstract": "The energy landscape theory finds its both extensive and intensive application in studying stochastic dynamics of physical and biological systems. Although the weighted summation of the Gaussian approximation (WSGA) approach has been proposed for quantifying the energy landscape in multistable systems by solving the diffusion equation approximately from moment equations, we are still lacking an accurate approach for quantifying the energy landscape of the periodic oscillatory systems. To address this challenge, we propose an approach, called the diffusion decomposition of the Gaussian approximation (DDGA). Using typical oscillatory systems as examples, we demonstrate the efficacy of the proposed DDGA in quantifying the energy landscape of oscillatory systems and corresponding stochastic dynamics, in comparison with existing approaches. By further applying the DDGA to a high-dimensional cell cycle network, we are able to uncover more intricate biological mechanisms in cell cycle, which cannot be discerned using previously developed approaches.",
        "comments": "13 pages, 4 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06959"
    },
    {
        "doc_id": 368,
        "title": "Dynamics and numerical simulations to predict empirical antibiotic treatment of multi-resistant Pseudomonas aeruginosa infection",
        "authors": [
            "Javier L\u00f3pez-de-la-Cruz",
            "Mar\u00eda P\u00e9rez-Aranda",
            "Ana Alcudia",
            "Bel\u00e9n Begines",
            "Tom\u00e1s Caraballo",
            "Elo\u00edsa Pajuelo",
            "Pedro J. Ginel"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "This work discloses an epidemiological mathematical model to predict an empirical treatment for dogs infected by Pseudomonas aeruginosa. This dangerous pathogen is one of the leading causes of multi-resistant infections and can be transmitted from dogs to humans. Numerical simulations and appropriated codes were developed using Matlab software to gather information concerning long-time dynamics of the susceptible, infected and recovered individuals. All data compiled from the mathematical model was used to provide an appropriated antibiotic sensitivity panel for this specific infection. In this study, several variables have been included in this model to predict which treatment should be prescribed in emergency cases, when there is no time to perform an antibiogram or the cost of it could not be assumed. In particular, we highlight the use of this model aiming to become part of the convenient toolbox of Public Health research and decision-making in the design of the mitigation strategy of bacterial pathogens.",
        "comments": "MSC Class:          Primary: 34K28; 34A12. Secondary: 92B05",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06938"
    },
    {
        "doc_id": 369,
        "title": "Disease Transmission on Random Graphs Using Edge-Based Percolation",
        "authors": [
            "S. Zhao",
            "F. M. G. Magpantay"
        ],
        "subjects": [
            "Social and Information Networks",
            "Dynamical Systems",
            "Populations and Evolution"
        ],
        "abstract": "Edge-based percolation methods can be used to analyze disease transmission on complex social networks. This allows us to include complex social heterogeneity in our models while maintaining tractability. Here we review the seminal works on this field by Newman et al (2001); Newman (2002, 2003), and Miller et al (2012). We present a systematic discussion of the theoretical background behind these models, including an extensive derivation of the major results. We also connect these results relate back to the classical literature in random graph theory Molloy and Reed (1995, 1998). Finally, we also present an accompanying R package that takes epidemic and network parameters as input and generates estimates of the epidemic trajectory and final size. This manuscript and the R package was developed to help researchers easily understand and use network models to investigate the interaction between different community structures and disease transmission.",
        "comments": "MSC Class:          00A71; 37N25; 92D25; 92D30",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06872"
    },
    {
        "doc_id": 370,
        "title": "Interpretable deep learning in single-cell omics",
        "authors": [
            "Manoj M Wagle",
            "Siqu Long",
            "Carissa Chen",
            "Chunlei Liu",
            "Pengyi Yang"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "Recent developments in single-cell omics technologies have enabled the quantification of molecular profiles in individual cells at an unparalleled resolution. Deep learning, a rapidly evolving sub-field of machine learning, has instilled a significant interest in single-cell omics research due to its remarkable success in analysing heterogeneous high-dimensional single-cell omics data. Nevertheless, the inherent multi-layer nonlinear architecture of deep learning models often makes them `black boxes' as the reasoning behind predictions is often unknown and not transparent to the user. This has stimulated an increasing body of research for addressing the lack of interpretability in deep learning models, especially in single-cell omics data analyses, where the identification and understanding of molecular regulators are crucial for interpreting model predictions and directing downstream experimental validations. In this work, we introduce the basics of single-cell omics technologies and the concept of interpretable deep learning. This is followed by a review of the recent interpretable deep learning models applied to various single-cell omics research. Lastly, we highlight the current limitations and discuss potential future directions. We anticipate this review to bring together the single-cell and machine learning research communities to foster future development and application of interpretable deep learning in single-cell omics research.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06823"
    },
    {
        "doc_id": 371,
        "title": "Evaluation of Mean Shift, ComBat, and CycleGAN for Harmonizing Brain Connectivity Matrices Across Sites",
        "authors": [
            "Hanliang Xu",
            "Nancy R. Newlin",
            "Michael E. Kim",
            "Chenyu Gao",
            "Praitayini Kanakaraj",
            "Aravind R. Krishnan",
            "Lucas W. Remedios",
            "Nazirah Mohd Khairi",
            "Kimberly Pechman",
            "Derek Archer",
            "Timothy J. Hohman",
            "Angela L. Jefferson",
            "The BIOCARD Study Team",
            "Ivana Isgum",
            "Yuankai Huo",
            "Daniel Moyer",
            "Kurt G. Schilling",
            "Bennett A. Landman"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Image and Video Processing"
        ],
        "abstract": "Connectivity matrices derived from diffusion MRI (dMRI) provide an interpretable and generalizable way of understanding the human brain connectome. However, dMRI suffers from inter-site and between-scanner variation, which impedes analysis across datasets to improve robustness and reproducibility of results. To evaluate different harmonization approaches on connectivity matrices, we compared graph measures derived from these matrices before and after applying three harmonization techniques: mean shift, ComBat, and CycleGAN. The sample comprises 168 age-matched, sex-matched normal subjects from two studies: the Vanderbilt Memory and Aging Project (VMAP) and the Biomarkers of Cognitive Decline Among Normal Individuals (BIOCARD). First, we plotted the graph measures and used coefficient of variation (CoV) and the Mann-Whitney U test to evaluate different methods' effectiveness in removing site effects on the matrices and the derived graph measures. ComBat effectively eliminated site effects for global efficiency and modularity and outperformed the other two methods. However, all methods exhibited poor performance when harmonizing average betweenness centrality. Second, we tested whether our harmonization methods preserved correlations between age and graph measures. All methods except for CycleGAN in one direction improved correlations between age and global efficiency and between age and modularity from insignificant to significant with p-values less than 0.05.",
        "comments": "11 pages, 5 figures, to be published in SPIE Medical Imaging 2024: Image Processing",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06798"
    },
    {
        "doc_id": 372,
        "title": "Curiosity as a Self-Supervised Method to Improve Exploration in De novo Drug Design",
        "authors": [
            "Mohamed-Amine Chadi",
            "Hajar Mousannif",
            "Ahmed Aamouche"
        ],
        "subjects": [
            "Quantitative Methods",
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "In recent years, deep learning has demonstrated promising results in de novo drug design. However, the proposed techniques still lack an efficient exploration of the large chemical space. Most of these methods explore a small fragment of the chemical space of known drugs, if the desired molecules were not found, the process ends. In this work, we introduce a curiosity-driven method to force the model to navigate many parts of the chemical space, therefore, achieving higher desirability and diversity as well. At first, we train a recurrent neural network-based general molecular generator (G), then we fine-tune G to maximize curiosity and desirability. We define curiosity as the Tanimoto similarity between two generated molecules, a first molecule generated by G, and a second one generated by a copy of G (Gcopy). We only backpropagate the loss through G while keeping Gcopy unchanged. We benchmarked our approach against two desirable chemical properties related to drug-likeness and showed that the discovered chemical space can be significantly expanded, thus, discovering a higher number of desirable molecules with more diversity and potentially easier to synthesize. All Code and data used in this paper are available at https://github.com/amine179/Curiosity-RL-for-Drug-Design.",
        "comments": " ",
        "date": "24 September, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06771"
    },
    {
        "doc_id": 373,
        "title": "Pandemic infection forecasting through compartmental model and learning-based approaches",
        "authors": [
            "Marianna Karapitta",
            "Andreas Kasis",
            "Charithea Stylianides",
            "Kleanthis Malialis",
            "Panayiotis Kolios"
        ],
        "subjects": [
            "Populations and Evolution",
            "Optimization and Control",
            "Quantitative Methods"
        ],
        "abstract": "The emergence and spread of deadly pandemics has repeatedly occurred throughout history, causing widespread infections and loss of life. The rapid spread of pandemics have made governments across the world adopt a range of actions, including non-pharmaceutical measures to contain its impact. However, the dynamic nature of pandemics makes selecting intervention strategies challenging. Hence, the development of suitable monitoring and forecasting tools for tracking infected cases is crucial for designing and implementing effective measures. Motivated by this, we present a hybrid pandemic infection forecasting methodology that integrates compartmental model and learning-based approaches. In particular, we develop a compartmental model that includes time-varying infection rates, which are the key parameters that determine the pandemic's evolution. To identify the time-dependent infection rates, we establish a hybrid methodology that combines the developed compartmental model and tools from optimization and neural networks. Specifically, the proposed methodology estimates the infection rates by fitting the model to available data, regarding the COVID-19 pandemic in Cyprus, and then predicting their future values through either a) extrapolation, or b) feeding them to neural networks. The developed approach exhibits strong accuracy in predicting infections seven days in advance, achieving low average percentage errors both using the extrapolation (9.90%) and neural network (5.04%) approaches.",
        "comments": "13 pages, 7 figures, 12 tables",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06629"
    },
    {
        "doc_id": 374,
        "title": "Analysis and operating diagram of an interspecific density-dependent model",
        "authors": [
            "Tahani Mtar",
            "Radhouane Fekih-Salem"
        ],
        "subjects": [
            "Dynamical Systems",
            "Populations and Evolution"
        ],
        "abstract": "This paper studies a two microbial species model in competition for a single resource in the chemostat including general interspecific density-dependent growth rates with distinct removal rates for each species. We give the necessary and sufficient conditions of existence, uniqueness, and local stability of all steady states. We show that a positive steady state, if it exists, then it is unique and unstable. In this case, the system exhibits a bi-stability where the behavior of the process depends on the initial condition. Our mathematical analysis proves that at most one species can survive which confirms the competitive exclusion principle. We conclude that adding only interspecific competition in the classical chemostat model is not sufficient to show the coexistence of two species even considering mortality in the dynamics of two species. Otherwise, we focus on the study, theoretically and numerically, of the operating diagram which depicts the existence and the stability of each steady state according to the two operating parameters of the process which are the dilution rate and the input concentration of the substrate. Using our mathematical analysis, we construct analytically the operating diagram by plotting the curves that separate their various regions. Our numerical method using MATCONT software validates these theoretical results but it reveals new bifurcations that occur by varying two parameters as Bogdanov-Takens and Zero-Hopf bifurcations. The bifurcation analysis shows that all steady states can appear or disappear only through transcritical bifurcations.",
        "comments": "MSC Class:          34A34; 34D20; 37N25; 92B05",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06339"
    },
    {
        "doc_id": 375,
        "title": "Optimal control of ribosome population for gene expression under periodic nutrient intake",
        "authors": [
            "Cl\u00e9ment Soubrier",
            "Eric Foxall",
            "Luca Ciandrini",
            "Khanh Dao Duc"
        ],
        "subjects": [
            "Subcellular Processes"
        ],
        "abstract": "Translation of proteins is a fundamental part of gene expression that is mediated by ribosomes. As ribosomes significantly contribute to both cellular mass and energy consumption, achieving efficient management of the ribosome population is also crucial to metabolism and growth. Inspired by biological evidence for nutrient-dependent mechanisms that control both ribosome active degradation and genesis, we introduce a dynamical model of protein production, that includes the dynamics of resources and control over the ribosome population. Under the hypothesis that active degradation and biogenesis are optimal for maximizing and maintaining protein production, we aim to qualitatively reproduce empirical observations of the ribosome population dynamics. Upon formulating the associated optimization problem, we first analytically study the stability and global behaviour of solutions under constant resource input, and characterize the extent of oscillations and convergence rate to a global equilibrium. We further use these results to simplify and solve the problem under a quasi-static approximation. Using biophysical parameter values, we find that optimal control solutions lead to both control mechanisms and the ribosome population switching between periods of feeding and fasting, suggesting that the intense regulation of ribosome population observed in experiments allows to maximize and maintain protein production. Finally, we find some range for the control values over which such a regime can be observed, depending on the intensity of fasting.",
        "comments": "16 pages (plus 13 pages of appendices). 4 figures (plus 1 figure and 1 table in appendices). Submitted to the Journal of The Royal Society Interface",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06294"
    },
    {
        "doc_id": 376,
        "title": "Identifiability of Level-1 Species Networks from Gene Tree Quartets",
        "authors": [
            "Elizabeth S. Allman",
            "Hector Ba\u00f1os",
            "Marina Garrote-Lopez",
            "John A. Rhodes"
        ],
        "subjects": [
            "Populations and Evolution",
            "Statistics Theory"
        ],
        "abstract": "When hybridization or other forms of lateral gene transfer have occurred, evolutionary relationships of species are better represented by phylogenetic networks than by trees. While inference of such networks remains challenging, several recently proposed methods are based on quartet concordance factors -- the probabilities that a tree relating a gene sampled from the species displays the possible 4-taxon relationships. Building on earlier results, we investigate what level-1 network features are identifiable from concordance factors under the network multispecies coalescent model. We obtain results on both topological features of the network, and numerical parameters, uncovering a number of failures of identifiability related to 3-cycles in the network.",
        "comments": "27 pages + 11 pages Supplementary Materials",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06290"
    },
    {
        "doc_id": 377,
        "title": "Prediction of causal genes at GWAS loci with pleiotropic gene regulatory effects using sets of correlated instrumental variables",
        "authors": [
            "Mariyam Khan",
            "Adriaan Ludl",
            "Sean Bankier",
            "Johan Bjorkegren",
            "Tom Michoel"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods"
        ],
        "abstract": "Multivariate Mendelian randomization (MVMR) is a statistical technique that uses sets of genetic instruments to estimate the direct causal effects of multiple exposures on an outcome of interest. At genomic loci with pleiotropic gene regulatory effects, that is, loci where the same genetic variants are associated to multiple nearby genes, MVMR can potentially be used to predict candidate causal genes. However, consensus in the field dictates that the genetic instruments in MVMR must be independent, which is usually not possible when considering a group of candidate genes from the same locus.\n  We used causal inference theory to show that MVMR with correlated instruments satisfies the instrumental set condition. This is a classical result by Brito and Pearl (2002) for structural equation models that guarantees the identifiability of causal effects in situations where multiple exposures collectively, but not individually, separate a set of instrumental variables from an outcome variable. Extensive simulations confirmed the validity and usefulness of these theoretical results even at modest sample sizes. Importantly, the causal effect estimates remain unbiased and their variance small when instruments are highly correlated.\n  We applied MVMR with correlated instrumental variable sets at risk loci from genome-wide association studies (GWAS) for coronary artery disease using eQTL data from the STARNET study. Our method predicts causal genes at twelve loci, each associated with multiple colocated genes in multiple tissues. However, the extensive degree of regulatory pleiotropy across tissues and the limited number of causal variants in each locus still require that MVMR is run on a tissue-by-tissue basis, and testing all gene-tissue pairs at a given locus in a single model to predict causal gene-tissue combinations remains infeasible.",
        "comments": "26 pages, 5 figures, 3 supplementary figures. Code available at https://github.com/mariyam-khan/Causal_genes_GWAS_loci_CAD . Supporting data available at https://dataverse.no/dataset.xhtml?persistentId=doi:10.18710/VM0WKQ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06261"
    },
    {
        "doc_id": 378,
        "title": "xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein",
        "authors": [
            "Bo Chen",
            "Xingyi Cheng",
            "Pan Li",
            "Yangli-ao Geng",
            "Jing Gong",
            "Shen Li",
            "Zhilei Bei",
            "Xu Tan",
            "Boyan Wang",
            "Xin Zeng",
            "Chiming Liu",
            "Aohan Zeng",
            "Yuxiao Dong",
            "Jie Tang",
            "Le Song"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of tasks simultaneously through an innovative pre-training framework. Our key technical contribution is an exploration of the compatibility and the potential for joint optimization of the two types of objectives, which has led to a strategy for training xTrimoPGLM at an unprecedented scale of 100 billion parameters and 1 trillion training tokens. Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms other advanced baselines in 18 protein understanding benchmarks across four categories. The model also facilitates an atomic-resolution view of protein structures, leading to an advanced 3D structural prediction model that surpasses existing language model-based tools. 2) xTrimoPGLM not only can generate de novo protein sequences following the principles of natural ones, but also can perform programmable generation after supervised fine-tuning (SFT) on curated sequences. These results highlight the substantial capability and versatility of xTrimoPGLM in understanding and generating protein sequences, contributing to the evolving landscape of foundation models in protein science.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06199"
    },
    {
        "doc_id": 379,
        "title": "Prediction of Cellular Identities from Trajectory and Cell Fate Information",
        "authors": [
            "Baiyang Dai",
            "Jiamin Yang",
            "Hari Shroff",
            "Patrick La Riviere"
        ],
        "subjects": [
            "Quantitative Methods",
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "Determining cell identities in imaging sequences is an important yet challenging task. The conventional method for cell identification is via cell tracking, which is complex and can be time-consuming. In this study, we propose an innovative approach to cell identification during early C. elegans embryogenesis using machine learning. We employed random forest, MLP, and LSTM models, and tested cell classification accuracy on 3D time-lapse confocal datasets spanning the first 4 hours of embryogenesis. By leveraging a small number of spatial-temporal features of individual cells, including cell trajectory and cell fate information, our models achieve an accuracy of over 90%, even with limited data. We also determine the most important feature contributions and can interpret these features in the context of biological knowledge. Our research demonstrates the success of predicting cell identities in 4D imaging sequences directly from simple spatio-temporal features.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06182"
    },
    {
        "doc_id": 380,
        "title": "Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization",
        "authors": [
            "Jiahao Qiu",
            "Hui Yuan",
            "Jinghong Zhang",
            "Wentao Chen",
            "Huazheng Wang",
            "Mengdi Wang"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "While modern biotechnologies allow synthesizing new proteins and function measurements at scale, efficiently exploring a protein sequence space and engineering it remains a daunting task due to the vast sequence space of any given protein. Protein engineering is typically conducted through an iterative process of adding mutations to the wild-type or lead sequences, recombination of mutations, and running new rounds of screening. To enhance the efficiency of such a process, we propose a tree search-based bandit learning method, which expands a tree starting from the initial sequence with the guidance of a bandit machine learning model. Under simplified assumptions and a Gaussian Process prior, we provide theoretical analysis and a Bayesian regret bound, demonstrating that the combination of local search and bandit learning method can efficiently discover a near-optimal design. The full algorithm is compatible with a suite of randomized tree search heuristics, machine learning models, pre-trained embeddings, and bandit techniques. We test various instances of the algorithm across benchmark protein datasets using simulated screens. Experiment results demonstrate that the algorithm is both sample-efficient and able to find top designs using reasonably small mutation counts.",
        "comments": "AAAI 2024",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06173"
    },
    {
        "doc_id": 381,
        "title": "Deep Learning model predicts the c-Kit-11 mutational status of canine cutaneous mast cell tumors by HE stained histological slides",
        "authors": [
            "Chlo\u00e9 Puget",
            "Jonathan Ganz",
            "Julian Ostermaier",
            "Thomas Konrad",
            "Eda Parlak",
            "Christof Albert Bertram",
            "Matti Kiupel",
            "Katharina Breininger",
            "Marc Aubreville",
            "Robert Klopfleisch"
        ],
        "subjects": [
            "Biomolecules",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Numerous prognostic factors are currently assessed histopathologically in biopsies of canine mast cell tumors to evaluate clinical behavior. In addition, PCR analysis of the c-Kit exon 11 mutational status is often performed to evaluate the potential success of a tyrosine kinase inhibitor therapy. This project aimed at training deep learning models (DLMs) to identify the c-Kit-11 mutational status of MCTs solely based on morphology without additional molecular analysis. HE slides of 195 mutated and 173 non-mutated tumors were stained consecutively in two different laboratories and scanned with three different slide scanners. This resulted in six different datasets (stain-scanner variations) of whole slide images. DLMs were trained with single and mixed datasets and their performances was assessed under scanner and staining domain shifts. The DLMs correctly classified HE slides according to their c-Kit 11 mutation status in, on average, 87% of cases for the best-suited stain-scanner variant. A relevant performance drop could be observed when the stain-scanner combination of the training and test dataset differed. Multi-variant datasets improved the average accuracy but did not reach the maximum accuracy of algorithms trained and tested on the same stain-scanner variant. In summary, DLM-assisted morphological examination of MCTs can predict c-Kit-exon 11 mutational status of MCTs with high accuracy. However, the recognition performance is impeded by a change of scanner or staining protocol. Larger data sets with higher numbers of scans originating from different laboratories and scanners may lead to more robust DLMs to identify c-Kit mutations in HE slides.",
        "comments": "17 pages, 3 figures, 4 tables",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06169"
    },
    {
        "doc_id": 382,
        "title": "Adjustable Molecular Representation for Unified Pre-training Strategy",
        "authors": [
            "Yan Ding",
            "Hao Cheng",
            "Zeliang Ye",
            "Ruyi Feng",
            "Zhongze Gu"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "We propose a new large-scale molecular model, named AdaMR, which stands for Adjustable Molecular Representation for Unified Pre-training Strategy. Unlike recent large-scale molecular models that use a single molecular encoding, AdaMR employs a granularity-adjustable molecular encoder, learning molecular representations at both the atomic and substructure levels. For the pre-training process, we designed a task for molecular canonicalization, which involves transforming ltiple generic molecular representations into canonical representations. By adjusting the granularity of molecular encoding, the trained model can improve the effects on multiple downstream tasks, such as model attribute prediction and molecule generation. Substructure-level molecular representation retains information of specific atom groups or arrangements that determine chemical properties and have similar functions, which is beneficial for tasks like property prediction. Meanwhile, atomic-level representation, combined with generative molecular canonicalization pre-training tasks, enhances the validity, novelty, and uniqueness in generative tasks. These features of AdaMR demonstrate its strong performance in numerous downstream tasks. We use different molecular properties prediction tasks on six different datasets on MoleculeNet and two generative tasks on ZINC250K dataset to evaluate our proposed molecular encoding and pre-training methods, and obtain state-of-the-art (SOTA) results on five of these tasks.",
        "comments": " ",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06166"
    },
    {
        "doc_id": 383,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 384,
        "title": "Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes with SE(3)-Discrete Diffusion",
        "authors": [
            "Alex Morehead",
            "Jeffrey Ruffolo",
            "Aadyot Bhatnagar",
            "Ali Madani"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.",
        "comments": "15 pages, 11 figures, presented at the NeurIPS 2023 Machine Learning in Structural Biology (MLSB) workshop. Code available at https://github.com/Profluent-Internships/MMDiff",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06151"
    },
    {
        "doc_id": 385,
        "title": "Artificial Intelligence for Digital and Computational Pathology",
        "authors": [
            "Andrew H. Song",
            "Guillaume Jaume",
            "Drew F. K. Williamson",
            "Ming Y. Lu",
            "Anurag Vaidya",
            "Tiffany R. Miller",
            "Faisal Mahmood"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Advances in digitizing tissue slides and the fast-paced progress in artificial intelligence, including deep learning, have boosted the field of computational pathology. This field holds tremendous potential to automate clinical diagnosis, predict patient prognosis and response to therapy, and discover new morphological biomarkers from tissue images. Some of these artificial intelligence-based systems are now getting approved to assist clinical diagnosis; however, technical barriers remain for their widespread clinical adoption and integration as a research tool. This Review consolidates recent methodological advances in computational pathology for predicting clinical end points in whole-slide images and highlights how these developments enable the automation of clinical practice and the discovery of new biomarkers. We then provide future perspectives as the field expands into a broader range of clinical and research tasks with increasingly diverse modalities of clinical data.",
        "comments": "Journal ref:        Nature Reviews Bioengineering 2023",
        "date": "12 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06148"
    },
    {
        "doc_id": 386,
        "title": "A Wireless Ear EEG Drowsiness Monitor",
        "authors": [
            "Ryan Kaveh",
            "Carolyn Schwendeman",
            "Ana C. Arias",
            "Rikky Muller"
        ],
        "subjects": [
            "Quantitative Methods",
            "Signal Processing"
        ],
        "abstract": "Wireless, neural wearables can enable life-saving drowsiness, cognitive, and health monitoring for heavy machinery operators, pilots, and drivers. While existing systems use in-cabin sensors to alert operators before accidents, wearables may enable monitoring across many user environments. Current neural wearables are promising but limited by consumable electrodes and bulky, wired electronics. To improve neural wearable usability, scalability, and enable discreet use in daily and itinerant environments, this work showcases the end-to-end design of the first wireless, in-ear, dry-electrode drowsiness monitoring platform. The proposed platform integrates additive manufacturing processes for gold-plated dry electrodes, user-generic earpiece designs, wireless electronics, and low-complexity machine learning algorithms. To evaluate the platform, thirty-five hours of ExG data were recorded across nine subjects performing repetitive drowsiness-inducing tasks. The data was used to train three, offline classifier models (logistic regression, support vector machine, and random forest) and evaluated with three training regimes (user-specific, leave-one-trial-out, and leave-one-user-out). The support vector machine classifier achieved an average accuracy of 93.2% while evaluating users it has seen before and 93.3% when evaluating a never-before-seen user. These results demonstrate for the first time that dry, 3D printed, user-generic electrodes can be used with wireless electronics to rapidly prototype wearable systems and achieve comparable average accuracy (>90%) to existing state-of-the-art in-ear and scalp ExG systems that utilize wet electrodes and wired, benchtop electronics. Further, this work demonstrates the feasibility of using population-trained machine learning models in future, wearable ear ExG applications focused on cognitive health and wellness tracking.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06076"
    },
    {
        "doc_id": 387,
        "title": "How does the primate brain combine generative and discriminative computations in vision?",
        "authors": [
            "Benjamin Peters",
            "James J. DiCarlo",
            "Todd Gureckis",
            "Ralf Haefner",
            "Leyla Isik",
            "Joshua Tenenbaum",
            "Talia Konkle",
            "Thomas Naselaris",
            "Kimberly Stachenfeld",
            "Zenna Tavares",
            "Doris Tsao",
            "Ilker Yildirim",
            "Nikolaus Kriegeskorte"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Vision is widely understood as an inference problem. However, two contrasting conceptions of the inference process have each been influential in research on biological vision as well as the engineering of machine vision. The first emphasizes bottom-up signal flow, describing vision as a largely feedforward, discriminative inference process that filters and transforms the visual information to remove irrelevant variation and represent behaviorally relevant information in a format suitable for downstream functions of cognition and behavioral control. In this conception, vision is driven by the sensory data, and perception is direct because the processing proceeds from the data to the latent variables of interest. The notion of \"inference\" in this conception is that of the engineering literature on neural networks, where feedforward convolutional neural networks processing images are said to perform inference. The alternative conception is that of vision as an inference process in Helmholtz's sense, where the sensory evidence is evaluated in the context of a generative model of the causal processes giving rise to it. In this conception, vision inverts a generative model through an interrogation of the evidence in a process often thought to involve top-down predictions of sensory data to evaluate the likelihood of alternative hypotheses. The authors include scientists rooted in roughly equal numbers in each of the conceptions and motivated to overcome what might be a false dichotomy between them and engage the other perspective in the realm of theory and experiment. The primate brain employs an unknown algorithm that may combine the advantages of both conceptions. We explain and clarify the terminology, review the key empirical evidence, and propose an empirical research program that transcends the dichotomy and sets the stage for revealing the mysterious hybrid algorithm of primate vision.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06005"
    },
    {
        "doc_id": 388,
        "title": "Target search in the CRISPR/Cas9 system: Facilitated diffusion with target cues",
        "authors": [
            "Qiao Lu",
            "Simone Pigolotti"
        ],
        "subjects": [
            "Subcellular Processes",
            "Biomolecules"
        ],
        "abstract": "We study how Cas9, a central component of the CRISPR/Cas9 system, searches for a target sequence on the DNA. We propose a model that includes as key ingredients 3D diffusion, 1D sliding along the DNA, and the effect of short binding sequences preceding the target (protospacer adjacent sequences -- PAMs). This latter aspect constitutes the main difference with traditional facilitated diffusion of transcription factors. We solve our model, obtaining an expression for the average search time of Cas9 for its target. We find that experimentally measured kinetic parameters are close to the values yielding an optimal search time. Our results rationalize the role of PAMs in guiding the search process, and show that Cas9 searches for its targets in a nearly optimal way.",
        "comments": "9 pages, 6 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05714"
    },
    {
        "doc_id": 389,
        "title": "On the existence of funneled orientations for classes of rooted phylogenetic networks",
        "authors": [
            "Janosch D\u00f6cker",
            "Simone Linz"
        ],
        "subjects": [
            "Populations and Evolution",
            "Computational Complexity",
            "Data Structures and Algorithms"
        ],
        "abstract": "Recently, there has been a growing interest in the relationships between unrooted and rooted phylogenetic networks. In this context, a natural question to ask is if an unrooted phylogenetic network U can be oriented as a rooted phylogenetic network such that the latter satisfies certain structural properties. In a recent preprint, Bulteau et al. claim that it is computational hard to decide if U has a funneled (resp. funneled tree-child) orientation, for when the internal vertices of U have degree at most 5. Unfortunately, the proof of their funneled tree-child result appears to be incorrect. In this paper, we present a corrected proof and show that hardness remains for other popular classes of rooted phylogenetic networks such as funneled normal and funneled reticulation-visible. Additionally, our results hold regardless of whether U is rooted at an existing vertex or by subdividing an edge with the root.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05611"
    },
    {
        "doc_id": 390,
        "title": "Multi-Dimensional Framework for EEG Signal Processing and Denoising Through Tensor-based Architecture",
        "authors": [
            "Aryan Govil",
            "Eric Yao",
            "Christina R. Borao"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Electroencephalography (EEG) stands as a crucial tool in neuroscientific research and clinical diagnostics, providing valuable insights into the electrical activities of the brain. Traditional EEG signal processing techniques, predominantly linear and constrained to time-frequency analysis, often fail to capture the intricate, dynamic nature of brain signals. This paper introduces a tensor-based multi-dimensional framework for EEG signal processing and denoising, aimed at overcoming the limitations of current methods. Utilizing the advanced mathematical construct of tensors, this framework allows for a more holistic representation and analysis of EEG data, encompassing multiple dimensions such as time, electrode space, and frequency bands. We propose innovative algorithms for multi-dimensional Fourier transforms and adaptive thresholding, specifically tailored to address the challenges of non-stationary noise and complex signal artifacts in EEG data. The framework is further enriched with a time-slicing algorithm that facilitates real-time analysis, crucial for applications like seizure detection and brain-computer interfacing. Theoretical formulations and simulated scenarios demonstrate the potential of this framework in significantly enhancing the accuracy, efficiency, and speed of EEG signal processing. This approach not only holds promise for advanced EEG analysis but also sets the stage for future integrations with other neuroimaging modalities, paving the way for comprehensive and nuanced understanding of brain function.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05589"
    },
    {
        "doc_id": 391,
        "title": "Assessing High-Order Links in Cardiovascular and Respiratory Networks via Static and Dynamic Information Measures",
        "authors": [
            "Gorana Mijatovic",
            "Laura Sparacino",
            "Yuri Antonacci",
            "Michal Javorka",
            "Daniele Marinazzo",
            "Sebastiano Stramaglia",
            "Luca Faes"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods"
        ],
        "abstract": "The network representation is becoming increasingly popular for the description of cardiovascular interactions based on the analysis of multiple simultaneously collected variables. However, the traditional methods to assess network links based on pairwise interaction measures cannot reveal high-order effects involving more than two nodes, and are not appropriate to infer the underlying network topology. To address these limitations, here we introduce a framework which combines the assessment of high-order interactions with statistical inference for the characterization of the functional links sustaining physiological networks. The framework develops information-theoretic measures quantifying how two nodes interact in a redundant or synergistic way with the rest of the network, and employs these measures for reconstructing the functional structure of the network. The measures are implemented for both static and dynamic networks mapped respectively by random variables and random processes using plug-in and model-based entropy estimators. The validation on theoretical and numerical simulated networks documents the ability of the framework to represent high-order interactions as networks and to detect statistical structures associated to cascade, common drive and common target effects. The application to cardiovascular networks mapped by the beat-to-beat variability of heart rate, respiration, arterial pressure, cardiac output and vascular resistance allowed noninvasive characterization of several mechanisms of cardiovascular control operating in resting state and during orthostatic stress. Our approach brings to new comprehensive assessment of physiological interactions and complements existing strategies for the classification of pathophysiological states.",
        "comments": "14 pages, 8 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05556"
    },
    {
        "doc_id": 392,
        "title": "Modelling Species Distributions with Deep Learning to Predict Plant Extinction Risk and Assess Climate Change Impacts",
        "authors": [
            "Joaquim Estopinan",
            "Pierre Bonnet",
            "Maximilien Servajean",
            "Fran\u00e7ois Munoz",
            "Alexis Joly"
        ],
        "subjects": [
            "Populations and Evolution",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "The post-2020 global biodiversity framework needs ambitious, research-based targets. Estimating the accelerated extinction risk due to climate change is critical. The International Union for Conservation of Nature (IUCN) measures the extinction risk of species. Automatic methods have been developed to provide information on the IUCN status of under-assessed taxa. However, these compensatory methods are based on current species characteristics, mainly geographical, which precludes their use in future projections. Here, we evaluate a novel method for classifying the IUCN status of species benefiting from the generalisation power of species distribution models based on deep learning. Our method matches state-of-the-art classification performance while relying on flexible SDM-based features that capture species' environmental preferences. Cross-validation yields average accuracies of 0.61 for status classification and 0.78 for binary classification. Climate change will reshape future species distributions. Under the species-environment equilibrium hypothesis, SDM projections approximate plausible future outcomes. Two extremes of species dispersal capacity are considered: unlimited or null. The projected species distributions are translated into features feeding our IUCN classification method. Finally, trends in threatened species are analysed over time and i) by continent and as a function of average ii) latitude or iii) altitude. The proportion of threatened species is increasing globally, with critical rates in Africa, Asia and South America. Furthermore, the proportion of threatened species is predicted to peak around the two Tropics, at the Equator, in the lowlands and at altitudes of 800-1,500 m.",
        "comments": "18 pages, 5 figures. Coda and data: https://github.com/estopinj/IUCN_classification",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05470"
    },
    {
        "doc_id": 393,
        "title": "Detecting QT prolongation From a Single-lead ECG With Deep Learning",
        "authors": [
            "Ridwan Alam",
            "Aaron Aguirre",
            "Collin Stultz"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "For a number of antiarrhythmics, drug loading requires a 3 day hospitalization with monitoring for QT prolongation. Automated QT monitoring with wearable ECG monitors would facilitate out-of-hospital care. We develop a deep learning model that infers QT intervals from ECG lead-I - the lead most often acquired from ambulatory ECG monitors - and to use this model to detect clinically meaningful QT-prolongation episodes during Dofetilide drug loading. Using 4.22 million 12-lead ECG recordings from 903.6 thousand patients at the Massachusetts General Hospital, we develop a deep learning model, QTNet, that infers QT intervals from lead-I. Over 3 million ECGs from 653 thousand patients are used to train the model and an internal-test set containing 633 thousand ECGs from 135 thousand patients was used for testing. QTNet is further evaluated on an external-validation set containing 3.1 million ECGs from 667 thousand patients at another institution. QTNet was used to detect Dofetilide-induced QT prolongation in a publicly available database (ECGRDVQ-dataset) containing ECGs from subjects enrolled in a clinical trial evaluating the effects of antiarrhythmic drugs. QTNet achieves mean absolute errors of 12.63ms (internal-test) and 12.30ms (external-validation) for estimating absolute QT intervals. The associated Pearson correlation coefficients are 0.91 (internal-test) and 0.92 (external-validation). For the ECGRDVQ-dataset, QTNet detects Dofetilide-induced QTc prolongation with 87% sensitivity and 77% specificity. The negative predictive value of the model is greater than 95% when the pre-test probability of drug-induced QTc prolongation is below 25%. Drug-induced QT prolongation risk can be tracked from ECG lead-I using deep learning.",
        "comments": " ",
        "date": "17 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05378"
    },
    {
        "doc_id": 394,
        "title": "Autoregressive fragment-based diffusion for pocket-aware ligand design",
        "authors": [
            "Mahdi Ghorbani",
            "Leo Gendelev",
            "Paul Beroza",
            "Michael J. Keiser"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics",
            "Quantitative Methods"
        ],
        "abstract": "In this work, we introduce AutoFragDiff, a fragment-based autoregressive diffusion model for generating 3D molecular structures conditioned on target protein structures. We employ geometric vector perceptrons to predict atom types and spatial coordinates of new molecular fragments conditioned on molecular scaffolds and protein pockets. Our approach improves the local geometry of the resulting 3D molecules while maintaining high predicted binding affinity to protein targets. The model can also perform scaffold extension from user-provided starting molecular scaffold.",
        "comments": "Accepted, NeurIPS 2023 Generative AI and Biology Workshop. OpenReview: https://openreview.net/forum?id=E3HN48zjam",
        "date": "14 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05370"
    },
    {
        "doc_id": 395,
        "title": "Rethinking Performance Measures of RNA Secondary Structure Problems",
        "authors": [
            "Frederic Runge",
            "J\u00f6rg K. H. Franke",
            "Daniel Fertmann",
            "Frank Hutter"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Accurate RNA secondary structure prediction is vital for understanding cellular regulation and disease mechanisms. Deep learning (DL) methods have surpassed traditional algorithms by predicting complex features like pseudoknots and multi-interacting base pairs. However, traditional distance measures can hardly deal with such tertiary interactions and the currently used evaluation measures (F1 score, MCC) have limitations. We propose the Weisfeiler-Lehman graph kernel (WL) as an alternative metric. Embracing graph-based metrics like WL enables fair and accurate evaluation of RNA structure prediction algorithms. Further, WL provides informative guidance, as demonstrated in an RNA design experiment.",
        "comments": "12 pages, Accepted at the Machine Learning for Structural Biology Workshop, NeurIPS 2023",
        "date": "4 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05351"
    },
    {
        "doc_id": 396,
        "title": "Spectral Topological Data Analysis of Brain Signals",
        "authors": [
            "Anass B. El-Yaagoubi",
            "Shuhao Jiao",
            "Moo K. Chung",
            "Hernando Ombao"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "Topological data analysis (TDA) has become a powerful approach over the last twenty years, mainly due to its ability to capture the shape and the geometry inherent in the data. Persistence homology, which is a particular tool in TDA, has been demonstrated to be successful in analyzing functional brain connectivity. One limitation of standard approaches is that they use arbitrarily chosen threshold values for analyzing connectivity matrices. To overcome this weakness, TDA provides a filtration of the weighted brain network across a range of threshold values. However, current analyses of the topological structure of functional brain connectivity primarily rely on overly simplistic connectivity measures, such as the Pearson orrelation. These measures do not provide information about the specific oscillators that drive dependence within the brain network. Here, we develop a frequency-specific approach that utilizes coherence, a measure of dependence in the spectral domain, to evaluate the functional connectivity of the brain. Our approach, the spectral TDA (STDA), has the ability to capture more nuanced and detailed information about the underlying brain networks. The proposed STDA method leads to a novel topological summary, the spectral landscape, which is a 2D-generalization of the persistence landscape. Using the novel spectral landscape, we analyze the EEG brain connectivity of patients with attention deficit hyperactivity disorder (ADHD) and shed light on the frequency-specific differences in the topology of brain connectivity between the controls and ADHD patients.",
        "comments": "28 pages, 23 figures",
        "date": "1 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05343"
    },
    {
        "doc_id": 397,
        "title": "Most discriminative stimuli for functional cell type identification",
        "authors": [
            "Max F. Burg",
            "Thomas Zenkel",
            "Michaela Vystr\u010dilov\u00e1",
            "Jonathan Oesterle",
            "Larissa H\u00f6fling",
            "Konstantin F. Willeke",
            "Jan Lause",
            "Sarah M\u00fcller",
            "Paul G. Fahey",
            "Zhiwei Ding",
            "Kelli Restivo",
            "Shashwat Sridhar",
            "Tim Gollisch",
            "Philipp Berens",
            "Andreas S. Tolias",
            "Thomas Euler",
            "Matthias Bethge",
            "Alexander S. Ecker"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Identifying cell types and understanding their functional properties is crucial for unraveling the mechanisms underlying perception and cognition. In the retina, functional types can be identified by carefully selected stimuli, but this requires expert domain knowledge and biases the procedure towards previously known cell types. In the visual cortex, it is still unknown what functional types exist and how to identify them. Thus, for unbiased identification of the functional cell types in retina and visual cortex, new approaches are needed. Here we propose an optimization-based clustering approach using deep predictive models to obtain functional clusters of neurons using Most Discriminative Stimuli (MDS). Our approach alternates between stimulus optimization with cluster reassignment akin to an expectation-maximization algorithm. The algorithm recovers functional clusters in mouse retina, marmoset retina and macaque visual area V4. This demonstrates that our approach can successfully find discriminative stimuli across species, stages of the visual system and recording techniques. The resulting most discriminative stimuli can be used to assign functional cell types fast and on the fly, without the need to train complex predictive models or show a large natural scene dataset, paving the way for experiments that were previously limited by experimental time. Crucially, MDS are interpretable: they visualize the distinctive stimulus patterns that most unambiguously identify a specific type of neuron. We will make our code available online upon publication.",
        "comments": " ",
        "date": "29 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05342"
    },
    {
        "doc_id": 398,
        "title": "Stable Online and Offline Reinforcement Learning for Antibody CDRH3 Design",
        "authors": [
            "Yannick Vogt",
            "Mehdi Naouar",
            "Maria Kalweit",
            "Christoph Cornelius Miething",
            "Justus Duyster",
            "Roland Mertelsmann",
            "Gabriel Kalweit",
            "Joschka Boedecker"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "The field of antibody-based therapeutics has grown significantly in recent years, with targeted antibodies emerging as a potentially effective approach to personalized therapies. Such therapies could be particularly beneficial for complex, highly individual diseases such as cancer. However, progress in this field is often constrained by the extensive search space of amino acid sequences that form the foundation of antibody design. In this study, we introduce a novel reinforcement learning method specifically tailored to address the unique challenges of this domain. We demonstrate that our method can learn the design of high-affinity antibodies against multiple targets in silico, utilizing either online interaction or offline datasets. To the best of our knowledge, our approach is the first of its kind and outperforms existing methods on all tested antigens in the Absolut! database.",
        "comments": " ",
        "date": "29 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05341"
    },
    {
        "doc_id": 399,
        "title": "Biofilm mechanics and patterns",
        "authors": [
            "Ana Carpio",
            "Elena Cebrian",
            "David R. Espeso",
            "Perfecto Vidal"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "From multicellular tissues to bacterial colonies, three dimensional cellular structures arise through the interaction of cellular activities and mechanical forces. Simple bacterial communities provide model systems for analyzing such interaction. Biofilms are bacterial aggregates attached to wet surfaces and encased in a self-produced polymeric matrix. Biofilms in flows form filamentary structures that contrast with the wrinkled layers observed on air/solid interfaces. We are able to reproduce both types of shapes through elastic rod and plate models that incorporate information from the biomass production and differentiations process, such as growth rates, growth tensors or inner stresses, as well as constraints imposed by the interaction with environment. A more precise study of biofilm dynamics requires tackling water absorption from its surroundings and fluid transport within the biological system. This process alters the material properties of the biofilm and the overall stresses. We analyze whether poroelastic approaches can provide a suitable combined description of fluid-like and solid-like biofilm behavior.",
        "comments": "In: Bonilla, L., Kaxiras, E., Melnik, R. (eds) Coupled Mathematical Models for Physical and Biological Nanoscale Systems and Their Applications. BIRS-16w5069 2016. Springer Proceedings in Mathematics & Statistics, vol 232. Springer, Cham., 2018",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05323"
    },
    {
        "doc_id": 400,
        "title": "Free energy in spin glass models with conventional order",
        "authors": [
            "Hong-Bin Chen"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "Recently, [arXiv:2302.01361] considered spin glass models with additional conventional order parameters characterizing single-replica properties. These parameters are distinct from the standard order parameter used to measure correlations between replicas. A \"min-max\" formula for the free energy was prescribed in [arXiv:2302.01361]. We rigorously verify this prescription in the setting of vector spin glass models featuring additional deterministic spin interactions. Notably, our results can be viewed as a generalization of the Parisi formula for vector spin glass models in [arXiv:1512.04441], where the order parameter for self-overlap is already present.",
        "comments": "16 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10223"
    },
    {
        "doc_id": 401,
        "title": "On the Sum of the Sixth Powers of Fibonacci Numbers",
        "authors": [
            "Kunle Adegoke",
            "Olawanle Layeni"
        ],
        "subjects": [
            "General Mathematics"
        ],
        "abstract": "Let $(G_k)_{k\\in\\mathbb Z}$ be any sequence obeying the recurrence relation of the Fibonacci numbers. We derive formulas for $\\sum_{j=1}^n{G_{j + t}^6}$ and $\\sum_{j=1}^n{(-1)^{j - 1}G_{j + t}^5(G_{j + t - 1} + G_{j + t + 1})}$, thereby extending the results of Ohtsuka and Nakamura who found simple formulas for $\\sum_{j=1}^n{F_j^6}$ and $\\sum_{j=1}^n{L_j^6}$, where $F_k$ and $L_k$ are the $k$th Fibonacci and Lucas numbers. We also evaluate $\\sum_{j = 1}^n {G_{j + t}^3 G_{j + t + 1}^3 } $ and $\\sum_{j = 1}^n {G_{j + t - 1}^2 G_{j + t} G_{j + t + 1} G_{j + t + 2}^2 } $, of which the results of Treeby are particular cases.",
        "comments": "MSC Class:          11B39 (Primary); 11B37 (Secondary)",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10221"
    },
    {
        "doc_id": 402,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 403,
        "title": "Buried points of plane continua",
        "authors": [
            "David Lipham",
            "Jan van Mill",
            "Murat Tuncali",
            "Ed Tymchatyn",
            "Kirsten Valkenburg"
        ],
        "subjects": [
            "General Topology"
        ],
        "abstract": "Sets on the boundary of a complementary component of a continuum in the plane have been of interest since the early 1920's. Curry and Mayer defined the buried points of a plane continuum to be the points in the continuum which were not on the boundary of any complementary component. Motivated by their investigations of Julia sets, they asked what happens if the set of buried points of a plane continuum is totally disconnected and non-empty. Curry, Mayer and Tymchatyn showed that in that case the continuum is Suslinian, i.e. it does not contain an uncountable collection of non-degenerate pairwise disjoint subcontinua. In an answer to a question of Curry et al, van Mill and Tuncali constructed a plane continuum whose buried point set was totally disconnected, non-empty and one-dimensional at each point of a countably infinite set. In this paper we show that the van Mill-Tuncali example was best possible in the sense that whenever the buried set is totally disconnected, then it is one-dimensional at each of at most countably many points. As a corollary we find that the buried set cannot be almost zero-dimensional unless it is zero-dimensional. We also construct locally connected van Mill-Tuncali type examples.",
        "comments": "7 pages, 2 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10206"
    },
    {
        "doc_id": 404,
        "title": "Remarks on Fixed Point Assertions in Digital Topology, 8",
        "authors": [
            "Laurence Boxer"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "This paper continues a series in which we study deficiencies in previously published works concerning fixed point assertions for digital images.",
        "comments": "There is a lot of text quoted or paraphrased from other papers. Sources are given for all such text",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10203"
    },
    {
        "doc_id": 405,
        "title": "Energy-minimizing mappings of real projective spaces",
        "authors": [
            "Joseph Hoisington"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "We establish upper and lower bounds for the infimum of the energy in homotopy classes of mappings from real projective spaces to Riemannian manifolds. We also show, as a corollary of the work of White in [Wh86], that the infimum of the energy in a homotopy class of mappings of real projective $n$-space is determined by an associated class of mappings of the real projective plane.",
        "comments": "7 pages, comments welcome",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10201"
    },
    {
        "doc_id": 406,
        "title": "Envelopes in the class of Banach algebras of polynomial growth and $C^\\infty$-functions of a finite number of free variables",
        "authors": [
            "O. Yu. Aristov"
        ],
        "subjects": [
            "Functional Analysis",
            "Operator Algebras"
        ],
        "abstract": "We introduce the notion of envelope of a topological algebra (in particular, an arbitrary associative algebra) with respect to a class of Banach algebra. In the case of the class of real Banach algebras of polynomial growth, i.e., admitting a $C^\\infty$-functional calculus for every element, we get a functor that maps the algebra of polynomials in $k$ variables to the algebra of $C^\\infty$-functions on $\\mathbb{R}^k$. The envelope of a general commutative or non-commutative algebra can be treated as an algebra of $C^\\infty$-functions on some commutative or non-commutative space. In particular, we describe the envelopes of the universal enveloping algebra of finite-dimensional Lie algebras, the coordinate algebras of the quantum plane and quantum $SL(2)$ and also look at some commutative examples. A result on algebras of `free $C^\\infty$-functions', i.e., the envelopes of free associative algebras of finite rank $k$, is announced for general $k$ and proved for $k\\le 2$.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10199"
    },
    {
        "doc_id": 407,
        "title": "Polar multiplicities and integral dependence",
        "authors": [
            "Yairon Cid-Ruiz"
        ],
        "subjects": [
            "Commutative Algebra",
            "Algebraic Geometry"
        ],
        "abstract": "We provide new criteria for the integrality and birationality of an extension of graded algebras in terms of the general notion of polar multiplicities of Kleiman and Thorup. As an application, we obtain a new criterion for when a module is a reduction of another in terms of certain mixed Buchsbaum-Rim multiplicities. Furthermore, we prove several technical results regarding polar multiplicities.",
        "comments": "MSC Class:          13H15; 14C17; 13B22; 13D40; 13A30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10198"
    },
    {
        "doc_id": 408,
        "title": "Center and torsion of a quotient of the group of piecewise linear homeomorphisms of the real line",
        "authors": [
            "Swarup Bhowmik"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "In this article, we show that the group comprising piecewise-linear homeomorphisms of the real line with bounded slopes is not simple. Furthermore, we establish that a quotient of this group is torsion-free, and importantly, the center of that quotient group is indeed trivial.",
        "comments": "8 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10188"
    },
    {
        "doc_id": 409,
        "title": "Maximal stable lattices in representations over discretely valued fields",
        "authors": [
            "Amit Ophir",
            "Ariel Weiss"
        ],
        "subjects": [
            "Number Theory",
            "Group Theory",
            "Representation Theory"
        ],
        "abstract": "Let $\u03c1\\colon G\\to \\mathrm{GL}_n(K)$ be an continuous irreducible representation of a compact group over a complete discretely valued field $K$. Let $W_i,W_j$ be two irreducible subrepresentations of $\\overline\u03c1^{ss}$, the semisimplification of the residual representation. We study the structure of the $G$-stable lattices $\u039b\\subseteq K^n$ with a view to understanding the question of when $\u03c1$ realises a non-split extension of $W_i$ by $W_j$.\n  In particular, we introduce the notion of a maximal $G$-stable lattice and prove that any non-split extension of $W_i$ by $W_j$ that can be realised by $\u03c1$ can also be realised by a maximal lattice. As applications, we give a new proof and a strengthening of Bella\u00efche's generalisation of Ribet's Lemma, which assures the abundancy of non-split extensions that can be realised by $\u03c1$. On the other hand, we also show that, if the representations $W_i, W_j$ occur with multiplicity one in $\\overline\u03c1^{ss}$, then $\u03c1$ can realise at most one non-split extension of $W_i$ by $W_j$.",
        "comments": "13 pages, comments welcome!",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10183"
    },
    {
        "doc_id": 410,
        "title": "Equilibrium Multiplicity: A Systematic Approach using Homotopies, with an Application to Chicago",
        "authors": [
            "Amine C-L. Ouazad"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Discrete choice models with social interactions or spillovers may exhibit multiple equilibria. This paper provides a systematic approach to enumerating them for a quantitative spatial model with discrete locations, social interactions, and elastic housing supply. The approach relies on two homotopies. A homotopy is a smooth function that transforms the solutions of a simpler city where solutions are known, to a city with heterogeneous locations and finite supply elasticity. The first homotopy is that, in the set of cities with perfectly elastic floor surface supply, an economy with heterogeneous locations is homotopic to an economy with homogeneous locations, whose solutions can be comprehensively enumerated. Such an economy is epsilon close to an economy whose equilibria are the zeros of a system of polynomials. This is a well-studied area of mathematics where the enumeration of equilibria can be guaranteed. The second homotopy is that a city with perfectly elastic housing supply is homotopic to a city with an arbitrary supply elasticity. In a small number of cases, the path may bifurcate and a single path yields two or more equilibria. By running the method on thousands of cities, we obtain a large number of equilibria. Each equilibrium has different population distributions. We provide a method that is computationally feasible for economies with a large number of locations choices, with an empirical application to the City of Chicago. There exist multiple ``counterfactual Chicagos'' consistent with the estimated parameters. Population distribution, prices, and welfare are not uniquely pinned down by amenities. The paper's method can be applied to models in trade and IO. Further applications of algebraic geometry are suggested.",
        "comments": "MSC Class:          91; 90; 65                          ACM Class:          G.3; J.4; I.6",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10181"
    },
    {
        "doc_id": 411,
        "title": "An Invariance Principle for a Random Walk Among Moving Traps via Thermodynamic Formalism",
        "authors": [
            "Siva Athreya",
            "Alexander Drewitz",
            "Rongfeng Sun"
        ],
        "subjects": [
            "Probability",
            "Dynamical Systems"
        ],
        "abstract": "We consider a random walk among a Poisson cloud of moving traps on ${\\mathbb Z}^d$, where the walk is killed at a rate proportional to the number of traps occupying the same position. In dimension $d=1$, we have previously shown that under the annealed law of the random walk conditioned on survival up to time $t$, the walk is sub-diffusive. Here we show that in $d\\geq 6$ and under diffusive scaling, this annealed law satisfies an invariance principle with a positive diffusion constant if the killing rate is small. Our proof is based on the theory of thermodynamic formalism, where we extend some classic results for Markov shifts with a finite alphabet and a potential of summable variation to the case of an uncountable non-compact alphabet.",
        "comments": "41 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10179"
    },
    {
        "doc_id": 412,
        "title": "New-generation Maximum Entropy Method (ngMEM): a Lagrangian-based algorithm for dynamic reconstruction of interferometric data",
        "authors": [
            "A. Mus",
            "I. Mart\u00ed-Vidal"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "Imaging interferometric data in radio astronomy requires the use of non-linear algorithms that rely on different assumptions on the source structure and may produce non-unique results. This is especially true for Very Long Baseline Interferometry (VLBI) observations, where the sampling of Fourier space is very sparse. A basic tenet in standard VLBI imaging techniques is to assume that the observed source structure does not evolve during the observation. However, the recent VLBI results of the supermassive black hole (SMBH) at our Galactic Center (Sagittarius A$^*$, SgrA*), recently reported by the Event Horizon Telescope Collaboration (EHTC), require the development of dynamic imaging algorithms, since it exhibits variability at minute timescales. In this paper, we introduce a new non-convex optimization problem that extends the standard Maximum Entropy Method (MEM), for reconstructing intra-observation dynamical images from interferometric data that evolves in every integration time. We present a rigorous mathematical formalism to solve the problem via the primal-dual approach. We build a Newton strategy and we give its numerical complexity. We also give a strategy to iteratively improve the obtained solution and finally, we define a novel figure of merit to evaluate the quality of the recovered solution. Then, we test the algorithm, called ngMEM, in different synthetic datasets, with increasing difficulty. Finally, we compare it with another well-established dynamical imaging method. Within this comparison we identified a significant improvement of the ngMEM reconstructions. Moreover, the evaluation of the integration time evolution scheme and the time contribution showed to play a crucial role for obtaining good dynamic reconstructions.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10177"
    },
    {
        "doc_id": 413,
        "title": "On the Equivariant Derived Category of Perverse Sheaves",
        "authors": [
            "Geoff Vooys"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Category Theory"
        ],
        "abstract": "In this paper we extend Beilinson's realization formalism for triangulated categories and filtered triangulated categories to a pseudofunctorial and pseudonatural setting. As a consequence we prove an equivariant version of Beilinson's Theorem: for any algebraic group $G$ over an algebraically closed field $K$ and for any $G$-variety $X$, there is an equivalence of categories $D_G^b(X; \\overline{\\mathbb{Q}}_{\\ell}) \\simeq D_G^b(\\mathbf{Perv}(X;\\overline{\\mathbb{Q}}_{\\ell}))$ where $\\ell$ is an integer prime coprime to the characteristic of $K$. We also show that the equivariant analogues of the other non-$D$-module aspects of Beilinson's Theorem hold in the equivariant case.",
        "comments": "40 Pages. Comments welcome!",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10174"
    },
    {
        "doc_id": 414,
        "title": "Categories of Pseudocones and Equivariant Descent",
        "authors": [
            "Geoff Vooys"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Algebraic Topology",
            "Category Theory"
        ],
        "abstract": "In this monograph we provide an in-depth and systematic study of pseudolimits of pseudofunctors $F:\\mathscr{C}^{op} \\to \\mathfrak{Cat}$ in the $2$-category of categories where $\\mathscr{C}$ is a $1$-category and use this to give an explicit and careful study of the category theory used in representation theory, equivariant algebraic geometry, and equivariant algebraic topology and give a unifying language to study equivariant sheaves, equivariant perverse sheaves, and their equivariant derived categories. We show how to use the pseudocone construction $\\mathsf{Bicat}(\\mathscr{C}^{op},\\mathfrak{Cat})(\\operatorname{cnst}(1),F)$ in order to derive categorical and homological properties of the pseudolimit of $F$. We explicitly show when the pseudolimit of $F$ is complete, cocomplete, enriched in models of a Lawvere theory, (braided) monoidal, regular, triangulated, admits $t$-structures, and more. We use these various structural results to give a new category-theoretic proof and construction of the equivariant standard and pervese $t$-structures and equivariant six functor formalism for the equivariant derived category $D_G^b(X)$ in both the geometric and topological cases as well as for $D_G^b(X;\\overline{\\mathbb{Q}}_{\\ell})$ in the geometric case. We also show in what sense precise sense we can view the equivariant derived category in terms of localizations. After restricting to the case of group resolution categories, we show the existence of a natural isomorphism $\u0398:\u03b1_X^{\\ast} \\Rightarrow \u03c0_2^{\\ast}$ which satisfies a pseudofunctorial version of the cocycle condition $d_1^{\\ast}\u0398= d_2^{\\ast}\u0398\\circ d_0^{\\ast}\u0398$. We also use the pseudocone formalism to give an in-depth analysis of change of groups functors. We use the pseudocone formalism and $\u0398$ to develop a notion of equivariant trace with an eye towards the representation theory of $p$-adic groups.",
        "comments": "arXiv admin note: text overlap with arXiv:2110.01130",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10172"
    },
    {
        "doc_id": 415,
        "title": "On Taylor-like Estimates for $L^{2}$ Polynomial Approximations",
        "authors": [
            "Ale\u0161 Wodecki"
        ],
        "subjects": [
            "General Mathematics"
        ],
        "abstract": "Polynomial series approximations are a central theme in approximation theory. Two types of series, which are featured most prominently in pure and applied mathematics, are Taylor series expansions and expansions derived based on families of $L^{2}-$orthogonal polynomials on bounded intervals. The identity theorem implies that all such series agree on $\\mathbb{C}$ in the limit. This motivates an effort to derive properties, which relate the original function to a truncated series based on $L^{2}-$orthogonal polynomial approximation which hold on unbounded intervals. In particular, the Chebyshev series expansion of $e^{x}$ is studied and an algebraic criterion which can be used to confirm bounds analogous to the Taylor series upper and lower bound estimates for $x<0$ is provided. In addition to this, the generalizations to other settings involving different functions and alternative families of $L^{2}$-orthogonal polynomials are discussed.",
        "comments": "10 pages, 0 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10169"
    },
    {
        "doc_id": 416,
        "title": "Solving the $106$ years old $3^k$ points problem with the clockwise-algorithm",
        "authors": [
            "Marco Rip\u00e0"
        ],
        "subjects": [
            "General Mathematics"
        ],
        "abstract": "In this paper, we present the clockwise-algorithm that solves the extension in $k$-dimensions of the infamous nine-dot problem, the well-known two-dimensional thinking outside the box puzzle. We describe a general strategy that constructively produces minimum length covering trails, for any $k \\in \\mathbb{N}-\\{0\\}$, solving the NP-complete $(3 \\times 3 \\times \\cdots \\times 3)$-point problem inside $3 \\times 3 \\times \\cdots \\times 3$ hypercubes. In particular, using our algorithm, we explicitly draw different covering trails of minimal length $h(k)=\\frac{3^k-1}{2}$, for $k=3, 4, 5$. Furthermore, we conjecture that, for every $k \\geq 1$, it is possible to solve the $3^k$-point problem with $h(k)$ lines starting from any of the $3^k$ nodes, except from the central one. Finally, we cover a $3 \\times 3 \\times 3$ grid with a tree of size $12$.",
        "comments": "17 pages, 12 figures. A video animation of the solution from 1 to 4 dimensions can be found on YouTube (https://www.youtube.com/watch?v=SSL9R0hQRKM)",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10163"
    },
    {
        "doc_id": 417,
        "title": "A Set-Valued Lagrange Theorem based on a Process for Convex Vector Programming",
        "authors": [
            "Fernando Garc\u00eda-Casta\u00f1o",
            "M. A. Melguizo Padial"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "In this paper, we present a new set-valued Lagrange multiplier theorem for constrained convex set-valued optimization problems. We introduce the novel concept of Lagrange process. This concept is a natural extension of the classical concept of Lagrange multiplier where the conventional notion of linear continuous operator is replaced by the concept of closed convex process, its set-valued analogue. The behaviour of this new Lagrange multiplier based on a process is shown to be particularly appropriate for some types of proper minimal points and, in general, when it has a bounded base.",
        "comments": "MSC Class:          90C29; 90C25; 90C31; 90C48",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10161"
    },
    {
        "doc_id": 418,
        "title": "Derivations and the first Hochschild cohomology group of the quantum grassmannian",
        "authors": [
            "St\u00e9phane Launois",
            "Tom Lenagan"
        ],
        "subjects": [
            "Quantum Algebra",
            "Rings and Algebras"
        ],
        "abstract": "We calculate the derivations and the first Hochschild cohomology group of the quantum grassmannian over a field of characteristic zero in the generic case when the deformation parameter is not a root of unity. Using graded techniques and two special homogeneous normal elements of the quantum grassmannian, we reduce the problem to computing derivations of the quantum grassmannian that act trivially on these two normal elements. We then use the dehomogenisation equality which shows that a localisation of the quantum grassmannian is equal to a skew Laurent extension of quantum matrices. This equality is used to connect derivations of the quantum grassmannian with those of quantum matrices. More precisely, again using graded techniques, we show that derivations of the quantum grassmannian that act trivially on our two normal elements restrict to homogeneous derivations of quantum matrices. The derivations of quantum matrices are known in the square case and technical details needed to deal with the general case are given in an appendix. This allows us to explicitly describe the first Hochschild cohomology group of the quantum grassmannian.",
        "comments": "30 pages; comments welcome",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10159"
    },
    {
        "doc_id": 419,
        "title": "In Memory of Martin Davis",
        "authors": [
            "Wesley Calvert",
            "Valentina Harizanov",
            "Eugenio G. Omodeo",
            "Alberto Policriti",
            "Alexandra Shlapentokh"
        ],
        "subjects": [
            "History and Overview",
            "Logic in Computer Science",
            "Logic",
            "Number Theory"
        ],
        "abstract": "The present paper gives an account for the general mathematical reader of the life and work of Martin Davis. Since two rather comprehensive autobiographical accounts and two long biographical interviews already exist, the present work focusses on Davis's scientific achievements, including work on computably enumerable sets, universal Turing machines, the hyperarithmetical hierarchy, neural networks, Hilbert's Tenth Problem, and automated reasoning.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10154"
    },
    {
        "doc_id": 420,
        "title": "Sums of square roots that are close to an integer",
        "authors": [
            "Stefan Steinerberger"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Let $k \\in \\mathbb{N}$ and suppose we are given $k$ integers $1 \\leq a_1, \\dots, a_k \\leq n$. If $\\sqrt{a_1} + \\dots + \\sqrt{a_k}$ is not an integer, how close can it be to one? When $k=1$, the distance to the nearest integer is $\\gtrsim n^{-1/2}$. Angluin-Eisenstat observed the bound $\\gtrsim n^{-3/2}$ when $k=2$. We prove there is a universal $c>0$ such that, for all $k \\geq 2$, there exists a $c_k > 0$ and $k$ integers in $\\left\\{1,2,\\dots, n\\right\\}$ with $$ 0 <\\|\\sqrt{a_1} + \\dots + \\sqrt{a_k} \\| \\leq c_k\\cdot n^{-c \\cdot k^{1/3}},$$ where $\\| \\cdot \\|$ denotes the distance to the nearest integer. This is a case of the square-root sum problem in numerical analysis where the usual cancellation constructions do not apply: even for $k=3$, constructing explicit examples of integers whose square root sum is nearly an integer appears to be nontrivial.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10152"
    },
    {
        "doc_id": 421,
        "title": "Local gluing",
        "authors": [
            "Urs Frauenfelder",
            "Joa Weber"
        ],
        "subjects": [
            "Symplectic Geometry",
            "Classical Analysis and ODEs",
            "Differential Geometry",
            "Dynamical Systems",
            "Geometric Topology"
        ],
        "abstract": "In the local gluing one glues local neighborhoods around the critical point of the stable and unstable manifolds to gradient flow lines defined on a finite time interval $[-T,T]$ for large $T$. If the Riemannian metric around the critical point is locally Euclidean, the local gluing map can be written down explicitly. In the non-Euclidean case the construction of the local gluing map requires an intricate version of the implicit function theorem.\n  In this paper we explain a functional analytic approach how the local gluing map can be defined. For that we are working on infinite dimensional path spaces and also interpret stable and unstable manifolds as submanifolds of path spaces. The advantage of this approach is that similar functional analytical techniques can as well be generalized to infinite dimensional versions of Morse theory, for example Floer theory.\n  A crucial ingredient is the Newton-Picard map. We work out an abstract version of it which does not involve troublesome quadratic estimates.",
        "comments": "45 pages, 3 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10151"
    },
    {
        "doc_id": 422,
        "title": "Approximation by perfect complexes detects Rouquier dimension",
        "authors": [
            "Pat Lank",
            "Noah Olander"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Commutative Algebra"
        ],
        "abstract": "This work explores bounds on the Rouquier dimension in the bounded derived category of coherent sheaves on Noetherian schemes. By utilizing approximations, we exhibit that Rouquier dimension is inherently characterized by the number of cones required to build all perfect complexes. We use this to prove sharper bounds on Rouquier dimension of singular schemes. Firstly, we show Rouquier dimension doesn't go up along \u00e9tale extensions and is invariant under \u00e9tale covers of affine schemes admitting a dualizing complex. Secondly, we demonstrate that the Rouquier dimension of the bounded derived category for a curve, with a delta invariant of at most one at closed points, is no larger than two. Thirdly, we bound the Rouquier dimension for the bounded derived category of a (birational) derived splinter variety by that of a resolution of singularities.",
        "comments": "v1, comments welcome!",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10146"
    },
    {
        "doc_id": 423,
        "title": "Labelled calculi for the logics of rough concepts",
        "authors": [
            "Ineke van der Berg",
            "Andrea De Domenico",
            "Giuseppe Greco",
            "Krishna Manoorkar",
            "Alessandra Palmigiano",
            "Mattia Panettiere"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "We introduce sound and complete labelled sequent calculi for the basic normal non-distributive modal logic L and some of its axiomatic extensions, where the labels are atomic formulas of the first order language of enriched formal contexts, i.e., relational structures based on formal contexts which provide complete semantics for these logics. We also extend these calculi to provide a proof system for the logic of rough formal contexts.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10143"
    },
    {
        "doc_id": 424,
        "title": "Optimally truncated WKB approximation for the 1D stationary Schr\u00f6dinger equation in the highly oscillatory regime",
        "authors": [
            "Anton Arnold",
            "Christian Klein",
            "Jannis K\u00f6rner",
            "Jens Markus Melenk"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "This paper is dedicated to the efficient numerical computation of solutions to the 1D stationary Schr\u00f6dinger equation in the highly oscillatory regime. We compute an approximate solution based on the well-known WKB-ansatz, which relies on an asymptotic expansion w.r.t. the small parameter $\\varepsilon$. Assuming that the coefficient in the equation is analytic, we derive an explicit error estimate for the truncated WKB series, in terms of $\\varepsilon$ and the truncation order $N$. For any fixed $\\varepsilon$, this allows to determine the optimal truncation order $N_{opt}$ which turns out to be proportional to $\\varepsilon^{-1}$. When chosen this way, the resulting error of the optimally truncated WKB series behaves like $\\mathcal{O}(\\varepsilon^{-2}\\exp(-r/\\varepsilon))$, with some parameter $r>0$. The theoretical results established in this paper are confirmed by several numerical examples.",
        "comments": "38 pages, 10 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10141"
    },
    {
        "doc_id": 425,
        "title": "Residual Based Error Estimator for Chemical-Mechanically Coupled Battery Active Particles",
        "authors": [
            "Raphael Schoof",
            "Lennart Fl\u00fcr",
            "Florian Tuschner",
            "Willy D\u00f6rfler"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Adaptive finite element methods are a powerful tool to obtain numerical simulation results in a reasonable time. Due to complex chemical and mechanical couplings in lithium-ion batteries, numerical simulations are very helpful to investigate promising new battery active materials such as amorphous silicon featuring a higher energy density than graphite. Based on a thermodynamically consistent continuum model with large deformation and chemo-mechanically coupled approach, we compare three different spatial adaptive refinement strategies: Kelly-, gradient recovery- and residual based error estimation. For the residual based case, the strong formulation of the residual is explicitly derived. With amorphous silicon as example material, we investigate two 3D representative host particle geometries, reduced with symmetry assumptions to a 1D unit interval and a 2D elliptical domain. Our numerical studies show that the Kelly estimator overestimates the error, whereas the gradient recovery estimator leads to lower refinement levels and a good capture of the change of the lithium flux. The residual based error estimator reveals a strong dependency on the cell error part which can be improved by a more suitable choice of constants to be more efficient. In a 2D domain, the concentration has a larger influence on the mesh distribution than the Cauchy stress.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10135"
    },
    {
        "doc_id": 426,
        "title": "Biorthogonal measures, polymer partition functions, and random matrices",
        "authors": [
            "Mattia Cafasso",
            "Tom Claeys"
        ],
        "subjects": [
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Complex Variables",
            "Probability"
        ],
        "abstract": "We develop the study of a particular class of biorthogonal measures, encompassing at the same time several random matrix models and partition functions of polymers. This general framework allows us to characterize the partition functions of the Log Gamma polymer and the mixed polymer in terms of explicit biorthogonal measures, as it was previously done for the homogeneous O'Connell-Yor polymer by Imamura and Sasamoto. In addition, we show that the biorthogonal measures associated to these three polymer models (Log Gamma, O'Connell-Yor, and mixed polymer) converge to random matrix eigenvalue distributions in small temperature limits. We also clarify the connection between different Fredholm determinant representations and explain how our results might be useful for asymptotic analysis and large deviation estimates.",
        "comments": "46 pages, 3 figures, 1 table",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10130"
    },
    {
        "doc_id": 427,
        "title": "A Novel Noise-Aware Classical Optimizer for Variational Quantum Algorithms",
        "authors": [
            "Jeffrey Larson",
            "Matt Menickelly",
            "Jiahao Shi"
        ],
        "subjects": [
            "Quantum Physics",
            "Optimization and Control"
        ],
        "abstract": "A key component of variational quantum algorithms (VQAs) is the choice of classical optimizer employed to update the parameterization of an ansatz. It is well recognized that quantum algorithms will, for the foreseeable future, necessarily be run on noisy devices with limited fidelities. Thus, the evaluation of an objective function (e.g., the guiding function in the quantum approximate optimization algorithm (QAOA) or the expectation of the electronic Hamiltonian in variational quantum eigensolver (VQE)) required by a classical optimizer is subject not only to stochastic error from estimating an expected value but also to error resulting from intermittent hardware noise. Model-based derivative-free optimization methods have emerged as popular choices of a classical optimizer in the noisy VQA setting, based on empirical studies. However, these optimization methods were not explicitly designed with the consideration of noise. In this work we adapt recent developments from the ``noise-aware numerical optimization'' literature to these commonly used derivative-free model-based methods. We introduce the key defining characteristics of these novel noise-aware derivative-free model-based methods that separate them from standard model-based methods. We study an implementation of such noise-aware derivative-free model-based methods and compare its performance on demonstrative VQA simulations to classical solvers packaged in \\texttt{scikit-quant}.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10121"
    },
    {
        "doc_id": 428,
        "title": "Binary Quantum Control Optimization with Uncertain Hamiltonians",
        "authors": [
            "Xinyu Fei",
            "Lucas T. Brady",
            "Jeffrey Larson",
            "Sven Leyffer",
            "Siqian Shen"
        ],
        "subjects": [
            "Quantum Physics",
            "Optimization and Control"
        ],
        "abstract": "Optimizing the controls of quantum systems plays a crucial role in advancing quantum technologies. The time-varying noises in quantum systems and the widespread use of inhomogeneous quantum ensembles raise the need for high-quality quantum controls under uncertainties. In this paper, we consider a stochastic discrete optimization formulation of a binary optimal quantum control problem involving Hamiltonians with predictable uncertainties. We propose a sample-based reformulation that optimizes both risk-neutral and risk-averse measurements of control policies, and solve these with two gradient-based algorithms using sum-up-rounding approaches. Furthermore, we discuss the differentiability of the objective function and prove upper bounds of the gaps between the optimal solutions to binary control problems and their continuous relaxations. We conduct numerical studies on various sized problem instances based of two applications of quantum pulse optimization; we evaluate different strategies to mitigate the impact of uncertainties in quantum systems. We demonstrate that the controls of our stochastic optimization model achieve significantly higher quality and robustness compared to the controls of a deterministic model.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10120"
    },
    {
        "doc_id": 429,
        "title": "A Categorical Perspective on Gluing",
        "authors": [
            "Sophie Marques",
            "Damas Mgani"
        ],
        "subjects": [
            "Category Theory"
        ],
        "abstract": "This paper introduces the concept of gluing in a general category, enabling us to define categories that admit glued-up objects. To achieve this, we introduce the notion of a gluing index category. Subsequently, we provide an entirely abstract definition of a gluing data functor requiring only the given category to admit pushouts. We explore various characterizations of cones and limits over these functors. We introduce the concept of refined gluing, which in turn enables us to combine different gluing data effectively. Furthermore, we demonstrate that several categories of topological spaces admit glued-up objects. This, in turn, allows us to establish a concept of gluing covering and to prove that the collection of those coverings forms a Grothendieck topology.",
        "comments": "26 pages, 22 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10117"
    },
    {
        "doc_id": 430,
        "title": "Time-Dependent Urn Models reproduce the full spectrum of novelties discovery",
        "authors": [
            "Alessandro Bellina",
            "Giordano De Marzo",
            "Vittorio Loreto"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Probability"
        ],
        "abstract": "Systems driven by innovation, a pivotal force in human society, present various intriguing statistical regularities, from the Heaps' law to logarithmic scaling or somewhat different patterns for the innovation rates. The Urn Model with Triggering (UMT) has been instrumental in modelling these innovation dynamics. Yet, a generalisation is needed to capture the richer empirical phenomenology. Here, we introduce a Time-dependent Urn Model with Triggering (TUMT), a generalisation of the UMT that crucially integrates time-dependent parameters for reinforcement and triggering to offer a broader framework for modelling innovation in non-stationary systems. Through analytical computation and numerical simulations, we show that the TUMT reconciles various behaviours observed in a broad spectrum of systems, from patenting activity to the analysis of gene mutations. We highlight how the TUMT features a \"critical\" region where both Heaps' and Zipf's laws coexist, for which we compute the exponents.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10114"
    },
    {
        "doc_id": 431,
        "title": "A Bourgain-Brezis-Mironescu formula accounting for nonlocal antisymmetric exchange interactions",
        "authors": [
            "Elisa Davoli",
            "Giovanni Di Fratta",
            "Rossella Giorgio"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "The present study concerns the nonlocal-to-local convergence of a family of exchange energy functionals in the limit of very short-range interactions. The analysis accounts for both symmetric and antisymmetric exchange. Our result is twofold. First, we extend the Bourgain-Brezis-Mironescu formula to encompass the scenario where antisymmetric contributions are encoded into the energy. Second, we prove that, under physically relevant assumptions on the families of exchange kernels, the family of nonlocal functionals Gamma-converges to their local counterparts. As a byproduct of our analysis, we obtain a rigorous justification of Dzyaloshinskii-Moriya interactions in chiral magnets under the form commonly adopted in the variational theory of micromagnetism when modeling antisymmetric exchange interactions.",
        "comments": "MSC Class:          46E35; 49J45; 49S05",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10104"
    },
    {
        "doc_id": 432,
        "title": "Existence and Density Theorems of Henig Global Proper Efficient Points in Non-Convex Vector Optimization Problems",
        "authors": [
            "Fernando Garc\u00eda-Casta\u00f1o",
            "Miguel \u00c1ngel Melguizo-Padial"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "In this work, we provide some novel results that establish both the existence of Henig global proper efficient points and their density in the efficient set for vector optimization problems in arbitrary normed spaces. Our results do not require the assumption of convexity, and in certain cases, can be applied to unbounded sets. However, it is important to note that a weak compactness condition on the set (or on a section of it) and a separation property between the order cone and its conical neighborhoods remains necessary. The weak compactness condition ensures that certain convergence properties hold. The separation property enables the interpolation of a family of Bishop-Phelps cones between the order cone and each of its conic neighborhoods. This interpolation, combined with the proper handling of two distinct types of conic neighborhoods, plays a crucial role in the proofs of our results, which include as a particular case other results that have already been established under more restrictive conditions.",
        "comments": "MSC Class:          90C29; 90C30; 49J27; 46N10",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10103"
    },
    {
        "doc_id": 433,
        "title": "On dentability and cones with a large dual",
        "authors": [
            "Fernando Garc\u00eda-Casta\u00f1o",
            "M. A. Melguizo Padial"
        ],
        "subjects": [
            "Functional Analysis"
        ],
        "abstract": "In this paper, we provide some equivalences on dentability in normed spaces. Among others we prove: the origin is a denting point of a pointed cone $C$ if and only if it is a point of continuity for such a cone and $\\overline{C^*-C^*}=X^*$; $x$ is a denting point of a convex set $A$ if and only if $x$ is a point of continuity and a weakly strongly extreme point of $A$. We also analize how our results help us to shed some light on several open problems in the literature.",
        "comments": "MSC Class:          46B40; 46A40; 46B20",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10102"
    },
    {
        "doc_id": 434,
        "title": "Counterfactual Reasoning with Probabilistic Graphical Models for Analyzing Socioecological Systems",
        "authors": [
            "Rafael Caba\u00f1as",
            "Ana D. Maldonado",
            "Mar\u00eda Morales",
            "Pedro A. Aguilera",
            "Antonio Salmer\u00f3n"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Probability",
            "Applications"
        ],
        "abstract": "Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios. This is particularly useful in domains where experimental data are usually not available. In the context of environmental and ecological sciences, causality enables us, for example, to predict how an ecosystem would respond to hypothetical interventions. A structural causal model is a class of probabilistic graphical models for causality, which, due to its intuitive nature, can be easily understood by experts in multiple fields. However, certain queries, called unidentifiable, cannot be calculated in an exact and precise manner. This paper proposes applying a novel and recent technique for bounding unidentifiable queries within the domain of socioecological systems. Our findings indicate that traditional statistical analysis, including probabilistic graphical models, can identify the influence between variables. However, such methods do not offer insights into the nature of the relationship, specifically whether it involves necessity or sufficiency. This is where counterfactual reasoning becomes valuable.",
        "comments": "34 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10101"
    },
    {
        "doc_id": 435,
        "title": "Time-optimal state transfer for an open qubit",
        "authors": [
            "L. V. Lokutsievskiy",
            "A. N. Pechen",
            "M. I. Zelikin"
        ],
        "subjects": [
            "Quantum Physics",
            "Optimization and Control"
        ],
        "abstract": "Finding minimal time and establishing the structure of the corresponding optimal controls which can transfer a given initial state of a quantum system into a given target state is a key problem of quantum control. In this work, this problem is solved for a basic component of various quantum technology processes -- a qubit interacting with the environment and experiencing an arbitrary time-dependent coherent driving. We rigorously derive both upper and lower estimates for the minimal steering time. Surprisingly, we discover that the optimal controls have a very special form -- they consist of two impulses, at the beginning and at the end of the control period, which can be assisted by a smooth time-dependent control in between. Moreover, an important for practical applications explicit almost optimal state transfer protocol is provided which only consists of four impulses and gives an almost optimal time of motion. The results can be directly applied to a variety of experimental situations for estimation of the ultimate limits of state control for quantum technologies.",
        "comments": "MSC Class:          49N25",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10099"
    },
    {
        "doc_id": 436,
        "title": "Long time regularity for 3d gravity waves with vorticity",
        "authors": [
            "Daniel Ginsberg",
            "Fabio Pusateri"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider the Cauchy problem for the full free boundary Euler equations in $3$d with an initial small velocity of size $O(\u03b5_0)$, in a moving domain which is initially an $O(\u03b5_0)$ perturbation of a flat interface. We assume that the initial vorticity is of size $O(\u03b5_1)$ and prove a regularity result up to times of the order $\u03b5_1^{-1+}$, independent of $\u03b5_0$. A key part of our proof is a normal form type argument for the vorticity equation; this needs to be performed in the full three dimensional domain and is necessary to effectively remove the irrotational components from the quadratic stretching terms and uniformly control the vorticity. Another difficulty is to obtain sharp decay for the irrotational component of the velocity and the interface; to do this we perform a dispersive analysis on the boundary equations, which are forced by a singular contribution from the rotational component of the velocity. As a corollary of our result, when $\u03b5_1$ goes to zero we recover the celebrated global regularity results of Wu (Invent. Math. 2012) and Germain, Masmoudi and Shatah (Ann. of Math. 2013) in the irrotational case.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10096"
    },
    {
        "doc_id": 437,
        "title": "Donaldson-Thomas invariants for the Bridgeland-Smith correspondence",
        "authors": [
            "Omar Kidwai",
            "Nicholas J. Williams"
        ],
        "subjects": [
            "Algebraic Geometry",
            "High Energy Physics - Theory",
            "Geometric Topology",
            "Representation Theory"
        ],
        "abstract": "Famous work of Bridgeland and Smith shows that certain moduli spaces of quadratic differentials are isomorphic to spaces of stability conditions on particular $3$-Calabi-Yau triangulated categories. This result has subsequently been generalised and extended by several authors. One facet of this correspondence is that finite-length trajectories of the quadratic differential are related to categories of semistable objects of the corresponding stability condition, which have associated Donaldson-Thomas invariants. On the other hand, computations in the physics literature suggest certain values of these invariants according to the type of trajectory. In this paper, we show that the category recently constructed by Christ, Haiden, and Qiu gives Donaldson-Thomas invariants which agree with the predictions from physics; in particular, degenerate ring domains of the quadratic differential give rise to non-zero Donaldson-Thomas invariants. To calculate all of the Donaldson-Thomas invariants, we import techniques from representation theory not previously used for these purposes. As a corollary of our computations, we obtain a quantum dilogarithm identity.",
        "comments": "66 pages, 23 figures, 1 table",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10093"
    },
    {
        "doc_id": 438,
        "title": "Non-compact inaudibility of weak symmetry and commutativity via generalized Heisenberg groups",
        "authors": [
            "Teresa Arias-Marco",
            "Jos\u00e9 Manuel Fern\u00e1ndez-Barroso"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "Two Riemannian manifolds are said to be isospectral if there exists a unitary operator which intertwines their Laplace-Beltrami operator. In this paper, we prove in the non-compact setting the inaudibility of the weak symmetry property and the commutative property using an isospectral pair of 23 dimensional generalized Heisenberg groups.",
        "comments": "MSC Class:          58J53; 53C25; 58J50",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10092"
    },
    {
        "doc_id": 439,
        "title": "Polynomial approximations for the matrix logarithm with computation graphs",
        "authors": [
            "Elias Jarlebring",
            "Jorge Sastre",
            "J. Javier Ib\u00e1\u00f1ez Gonz\u00e1lez"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "The most popular method for computing the matrix logarithm is a combination of the inverse scaling and squaring method in conjunction with a Pad\u00e9 approximation, sometimes accompanied by the Schur decomposition. The main computational effort lies in matrix-matrix multiplications and left matrix division. In this work we illustrate that the number of such operations can be substantially reduced, by using a graph based representation of an efficient polynomial evaluation scheme. A technique to analyze the rounding error is proposed, and backward error analysis is adapted. We provide substantial simulations illustrating competitiveness both in terms of computation time and rounding errors.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10089"
    },
    {
        "doc_id": 440,
        "title": "Stability theory of TASE-Runge-Kutta methods with inexact Jacobian",
        "authors": [
            "D. Conte",
            "J. Martin-Vaquero",
            "G. Pagano",
            "B. Paternoster"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "This paper analyzes the stability of the class of Time-Accurate and Highly-Stable Explicit Runge-Kutta (TASE-RK) methods, introduced in 2021 by Bassenne et al. (J. Comput. Phys.) for the numerical solution of stiff Initial Value Problems (IVPs). Such numerical methods are easy to implement and require the solution of a limited number of linear systems per step, whose coefficient matrices involve the exact Jacobian $J$ of the problem. To significantly reduce the computational cost of TASE-RK methods without altering their consistency properties, it is possible to replace $J$ with a matrix $A$ (not necessarily tied to $J$) in their formulation, for instance fixed for a certain number of consecutive steps or even constant. However, the stability properties of TASE-RK methods strongly depend on this choice, and so far have been studied assuming $A=J$.\n  In this manuscript, we theoretically investigate the conditional and unconditional stability of TASE-RK methods by considering arbitrary $A$. To this end, we first split the Jacobian as $J=A+B$. Then, through the use of stability diagrams and their connections with the field of values, we analyze both the case in which $A$ and $B$ are simultaneously diagonalizable and not. Numerical experiments, conducted on Partial Differential Equations (PDEs) arising from applications, show the correctness and utility of the theoretical results derived in the paper, as well as the good stability and efficiency of TASE-RK methods when $A$ is suitably chosen.",
        "comments": "26 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10088"
    },
    {
        "doc_id": 441,
        "title": "Statistics of ranks, determinants and characteristic polynomials of rational matrices",
        "authors": [
            "Muhammad Afifurrahman",
            "Alina Ostafe",
            "Igor E. Shparlinski"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We consider the set of $n\\times n$ matrices with rational entries having numerator and denominator of size at most $H$ and obtain upper and lower bounds on the number of such matrices of a given rank and then apply them to count such matrices with a given determinant, or a given characteristic polynomial.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10086"
    },
    {
        "doc_id": 442,
        "title": "Quantitative equilibrium fluctuations for interacting particle systems",
        "authors": [
            "Chenlin Gu",
            "Jean-Christophe Mourrat",
            "Maximilian Nitzschner"
        ],
        "subjects": [
            "Probability",
            "Analysis of PDEs"
        ],
        "abstract": "We consider a class of interacting particle systems in continuous space of non-gradient type, which are reversible with respect to Poisson point processes with constant density. For these models, a rate of convergence was recently obtained in 10.1214/22-AOP1573 for certain finite-volume approximations of the bulk diffusion matrix. Here, we show how to leverage this to obtain quantitative versions of a number of results capturing the large-scale fluctuations of these systems, such as the convergence of two-point correlation functions and the Green-Kubo formula.",
        "comments": "28 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10080"
    },
    {
        "doc_id": 443,
        "title": "Weak and Strong Solutions to Nonlinear SPDEs with Unbounded Noise",
        "authors": [
            "Daniel Goodair"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Probability"
        ],
        "abstract": "We introduce an extended variational framework for nonlinear SPDEs with unbounded noise, defining three different solution types of increasing strength along with criteria to establish their existence. The three notions can be understood as probabilistically and analytically weak, probabilistically strong and analytically weak, as well as probabilistically and analytically strong. Our framework directly recovers several recent well-posedness results for the Navier-Stokes Equation with Stochastic Lie Transport, equipped with the no-slip and Navier boundary conditions. Moreover, a critical new existence result for strong solutions under the no-slip condition can be obtained.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.18836",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10076"
    },
    {
        "doc_id": 444,
        "title": "Lower Bounds for Maximum Weight Bisections of Graphs with Bounded Degrees",
        "authors": [
            "Stefanie Gerke",
            "Gregory Gutin",
            "Anders Yeo",
            "Yacong Zhou"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics"
        ],
        "abstract": "A bisection in a graph is a cut in which the number of vertices in the two parts differ by at most 1. In this paper, we give lower bounds for the maximum weight of bisections of edge-weighted graphs with bounded maximum degree. Our results improve a bound of Lee, Loh, and Sudakov (J. Comb. Th. Ser. B 103 (2013)) for (unweighted) maximum bisections in graphs whose maximum degree is either even or equals 3, and for almost all graphs. We show that a tight lower bound for maximum size of bisections in 3-regular graphs obtained by Bollob\u00e1s and Scott (J. Graph Th. 46 (2004)) can be extended to weighted subcubic graphs. We also consider edge-weighted triangle-free subcubic graphs and show that a much better lower bound (than for edge-weighted subcubic graphs) holds for such graphs especially if we exclude $K_{1,3}$. We pose three conjectures.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10074"
    },
    {
        "doc_id": 445,
        "title": "A second note on homological systems",
        "authors": [
            "Jes\u00fas Efr\u00e9n P\u00e9rez Terrazas",
            "Luis Fernando Tzec Poot"
        ],
        "subjects": [
            "Representation Theory"
        ],
        "abstract": "Let $\\left( \u0394; \u03a9, \\leq \\right)$ be a b-homological system and $\\widetilde{\\cal F} \\left( \u0394\\right)$ the category of the extended $\u0394-$filtered modules. Here there is a proof that $\\widetilde{\\cal F} \\left( \u0394\\right)$ is closed under direct summands.",
        "comments": "MSC Class:          16G99; 16E99",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10069"
    },
    {
        "doc_id": 446,
        "title": "$L^p$ continuity of eigenprojections for 2-d Dirichlet Laplacians under perturbations of the domain",
        "authors": [
            "Ryan L. Acosta Babb",
            "James C. Robinson"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We generalise results by Lamberti and Lanza de Cristoforis (2005) concerning the continuity of projections onto eigenspaces of self-adjoint differential operators with compact inverses as the (spatial) domain of the functions is perturbed in $\\mathbb{R}^2$. Our main case of interest is the Dirichlet Laplacian. We extend these results from bounds from $H_0^1$ to $H_0^1$ to bounds from $L^p$ to $L^p$ .",
        "comments": "25 pages, 1 figure",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10066"
    },
    {
        "doc_id": 447,
        "title": "Global regularity for the one-dimensional stochastic Quantum-Navier-Stokes equations",
        "authors": [
            "Donatella Donatelli",
            "Lorenzo Pescatore",
            "Stefano Spirito"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper we prove the global in time well-posedness of strong solutions to the Quantum-Navier-Stokes equation driven by random initial data and stochastic external force. In particular, we first give a general local well-posedness result. Then, by means of the Bresch-Desjardins entropy, higher order energy estimates, and a continuation argument we prove that the density never vanishes, and thus that local strong solutions are indeed global.",
        "comments": "55 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10064"
    },
    {
        "doc_id": 448,
        "title": "Poisson approximation for stochastic processes summed over amenable groups",
        "authors": [
            "Haoyu Ye",
            "Peter Orbanz",
            "Morgane Austern"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "We generalize the Poisson limit theorem to binary functions of random objects whose law is invariant under the action of an amenable group. Examples include stationary random fields, exchangeable sequences, and exchangeable graphs. A celebrated result of E. Lindenstrauss shows that normalized sums over certain increasing subsets of such groups approximate expectations. Our results clarify that the corresponding unnormalized sums of binary statistics are asymptotically Poisson, provided suitable mixing conditions hold. They extend further to randomly subsampled sums and also show that strict invariance of the distribution is not needed if the requisite mixing condition defined by the group holds. We illustrate the results with applications to random fields, Cayley graphs, and Poisson processes on groups.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10060"
    },
    {
        "doc_id": 449,
        "title": "Determining Optimal Lot Size, Reorder Point, and Quality Features for a Food Item in a Cold Warehouse: Data-Driven Optimization Approach",
        "authors": [
            "Atena Karimi",
            "Omid Ghorbani",
            "Reza Tashakkori",
            "Seyed Hamid Reza Pasandideh",
            "Milad Jasemi"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "We propose a nonlinear optimization model for determining the optimum lot size and reorder point for a food item distributed through a cold warehouse as well as the optimum quality features, namely temperature, humidity, packaging type, and level of environmental conditions. The item's quality is estimated based on the features mentioned earlier, and then it is used as a constraint in the optimization process. An assumption was made that the inventory is managed under a continuous review policy and the warehouse has limited space. The model seeks to minimize the annual total cost of managing the warehouse. The model will be a nonlinear mixed programming one, which is solved by Pyomo as a leading library in Python language programming. Numerical examples are used to demonstrate the use of the model and, through sensitivity analysis, develop insights into the operation of cold warehouses. This sensitive analysis opens the doors to managerial insight from which managers and policymakers can highly benefit.",
        "comments": "12 pages, 5 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10059"
    },
    {
        "doc_id": 450,
        "title": "Axiomatization of Boolean Connexive Logics with syncategorematic negation and modalities",
        "authors": [
            "Tomasz Jarmuzek",
            "Jacek Malinowski",
            "Aleksander Parol",
            "Nicolo Zamperlin"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "In the article we investigate three classes of extended Boolean Connexive Logics. Two of them are extensions of Modal and non-Modal Boolean Connexive Logics with a property of closure under an arbitrary number of negations. The remaining one is an extension of Modal Boolean Connexive Logic with a property of closure under the function of demodalization. In our work we provide a formal presentation of mentioned properties and axiom schemata that allow us to incorporate them into the axiomatic systems. The presented axiom systems are provided with proofs of soundness and completeness. The properties of closure under negation and demodalization are motivated by the syncategorematic view on the connective of negation and modalities, which is discussed in the paper.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10056"
    },
    {
        "doc_id": 451,
        "title": "Positive mass theorem on conical manifold with small cone angle",
        "authors": [
            "Yaoting Gui"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "We prove the positive mass theorem on conical manifold with small cone angle and co-dimensional two singularities under the assumption that the ambient manifold admits a spin structure and locally conformal flat",
        "comments": "9 pages, comments are welcome",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10055"
    },
    {
        "doc_id": 452,
        "title": "Interpolatory Necessary Optimality Conditions for Reduced-order Modeling of Parametric Linear Time-invariant Systems",
        "authors": [
            "Petar Mlinari\u0107",
            "Peter Benner",
            "Serkan Gugercin"
        ],
        "subjects": [
            "Optimization and Control",
            "Systems and Control",
            "Numerical Analysis"
        ],
        "abstract": "Interpolatory necessary optimality conditions for $\\mathcal{H}_2$-optimal reduced-order modeling of non-parametric linear time-invariant (LTI) systems are known and well-investigated. In this work, using the general framework of $\\mathcal{L}_2$-optimal reduced-order modeling of parametric stationary problems, we derive interpolatory $\\mathcal{H}_2 \\otimes \\mathcal{L}_2$-optimality conditions for parametric LTI systems with a general pole-residue form. We then specialize this result to recover known conditions for systems with parameter-independent poles and develop new conditions for a certain class of systems with parameter-dependent poles.",
        "comments": "8 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10047"
    },
    {
        "doc_id": 453,
        "title": "Drift Control with Discretionary Stopping for a Diffusion Process",
        "authors": [
            "V\u00e1clav E. Bene\u0161",
            "Georgy Gaitsgori",
            "Ioannis Karatzas"
        ],
        "subjects": [
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We consider stochastic control with discretionary stopping for the drift of a diffusion process over an infinite time horizon. The objective is to choose a control process and a stopping time to minimize the expectation of a convex terminal cost in the presence of a fixed operating cost and a control-dependent running cost per unit of elapsed time. Under appropriate conditions on the coefficients of the controlled diffusion, an optimal pair of control and stopping rules is shown to exist. Moreover, under the same assumptions, it is shown that the optimal control is a constant which can be computed fairly explicitly; and that it is optimal to stop the first time an appropriate interval is visited. We consider also a constrained version of the above problem, in which an upper bound on the expectation of available stopping times is imposed; we show that this constrained problem can be reduced to an unconstrained problem with some appropriate change of parameters and, as a result, solved by similar arguments.",
        "comments": "22 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10043"
    },
    {
        "doc_id": 454,
        "title": "Multirate control strategies for avoiding sample losses. Application to UGV path tracking",
        "authors": [
            "J. Salt",
            "J. Alcaina",
            "A. Cuenca",
            "A. Banyos"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "When in a digital control strategy there are samples lost due to limitations, diff t multirate (MR) control options can be used for solving the problem: Dual-rate inferential control (IC) and model-based dual-rate control (MBDR). The objective of this contribution is to analyze, compare, and to assess their behavior under different perspectives. Is a dual-rate inferential control better than a model-based dual-rate control? Both options lead to a periodically time-varying discrete-time system and for this reason a lifted modeling is considered. An efficient algorithm is used for computing a MR systems frequency response for these control structures. The robust performance and disturbance effects are studied in detail under sample losses and process uncertainty, and some considerations are reported. A new QFT (quantitative feedback theory) procedure for dual-rate systems analysis is also described. Analysis and simulation examples and experimental results for UGV path tracking are introduced in this work, revealing that MBDR outperforms IC when the model contains important uncertainties.",
        "comments": "41 pages, 24 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10038"
    },
    {
        "doc_id": 455,
        "title": "Polynomials as terms and the Boolean Independence Theorem",
        "authors": [
            "M. Klazar"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We develop a theory of formal multivariate polynomials over commutative rings by treating them as ring terms. Our main result is that two ring terms are s-equivalent (when expanded they yield the same standard polynomial) iff they are f-equivalent (one can be transformed in the other by a series of elementary transformations). We consider in the similar way Boolean terms (formulas) and prove a theorem that two events $a$ and $b$ in a probability space, which are built by two Boolean terms from respective tuples $A$ and $B$ of elementary events, are independent if the events in $A$ are independent of the events in $B$. We use the theorem to rigorize arguments in the Probabilistic Method in Combinatorics.",
        "comments": "37 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10033"
    },
    {
        "doc_id": 456,
        "title": "Pattern-avoiding modified ascent sequences",
        "authors": [
            "Giulio Cerbai"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We initiate an in-depth study of pattern avoidance on modified ascent sequences. Our main technique consists in using Stanley's standardization to obtain a transport theorem between primitive modified ascent sequences and permutations avoiding a bivincular pattern of length three. We enumerate some patterns via bijections with other combinatorial structures such as Fishburn permutations, lattice paths and set partitions. We settle the last remaining case of a conjecture by Duncan and Steingr\u00edmsson by proving that modified ascent sequences avoiding 2321 are counted by the Bell numbers.",
        "comments": "32 pages, 4 figures, 2 tables",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10027"
    },
    {
        "doc_id": 457,
        "title": "A first approach to the Burchnall-Chaundy theory for quadratic algebras having PBW bases",
        "authors": [
            "Arturo Ni\u00f1o",
            "Mar\u00eda Camila Ram\u00edrez",
            "Armando Reyes"
        ],
        "subjects": [
            "Rings and Algebras",
            "Quantum Algebra"
        ],
        "abstract": "In this paper, we present a first approach toward a Burchnall-Chaundy theory for the skew Ore polynomials of higher order generated by quadratic relations defined by Golovashkin and Maksimov \\cite{GolovashkinMaksimov1998}.",
        "comments": "24 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10023"
    },
    {
        "doc_id": 458,
        "title": "Parabolic optimal control problems with combinatorial switching constraints -- Part III: Branch-and-bound algorithm",
        "authors": [
            "Christoph Buchheim",
            "Alexandra Gr\u00fctering",
            "Christian Meyer"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "We present a branch-and-bound algorithm for globally solving parabolic optimal control problems with binary switches that have bounded variation and possibly need to satisfy further combinatorial constraints. More precisely, for a given tolerance $\\varepsilon>0$, we show how to compute in finite time an $\\varepsilon$-optimal solution in function space, independently of any prior discretization. The main ingredients in our approach are an appropriate branching strategy in infinite dimension, an a posteriori error estimation in order to obtain safe dual bounds, and an adaptive refinement strategy in order to allow arbitrary switching points in the limit. The performance of our approach is demonstrated by extensive experimental results.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10018"
    },
    {
        "doc_id": 459,
        "title": "Local entropy theory and applications",
        "authors": [
            "Felipe Garc\u00eda-Ramos",
            "Hanfeng Li"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "This paper is a survey about recent developments in the local entropy theory for topological dynamical systems and continuous group actions, with particular emphasis on the connections with other areas of dynamical systems and mathematics.",
        "comments": "MSC Class:          37B40; 37A05; 37A20; 37A25; 37A35; 37A55; 37B02; 54H05; 37B45",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10012"
    },
    {
        "doc_id": 460,
        "title": "Attack tree metrics are operad algebras",
        "authors": [
            "Milan Lopuha\u00e4-Zwakenberg"
        ],
        "subjects": [
            "Cryptography and Security",
            "Category Theory"
        ],
        "abstract": "Attack Trees (ATs) are a widely used tool for security analysis. ATs can be employed in quantitative security analysis through metrics, which assign a security value to an AT. Many different AT metrics exist, and there exist multiple general definitions that aim to study a wide variety of AT metrics at once. However, these all have drawbacks: they do not capture all metrics, and they do not easily generalize to extensions of ATs. In this paper, we introduce a definition of AT metrics based on category theory, specifically operad algebras. This encompasses all previous definitions of AT metrics, and is easily generalized to extensions of ATs. Furthermore, we show that under easily expressed operad-theoretic conditions, existing metric calculation algorithms can be extended in considerable generality.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10008"
    },
    {
        "doc_id": 461,
        "title": "Continuous Analogues for the Pochhammer Symbol",
        "authors": [
            "Rafael D\u00edaz"
        ],
        "subjects": [
            "Combinatorics",
            "Classical Analysis and ODEs",
            "Number Theory"
        ],
        "abstract": "We develop continuous analogues for the Pochhammer symbol following the line of research initiated by D\u00edaz and Cano on the construction of continuous analogues for combinatorial objects.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10004"
    },
    {
        "doc_id": 462,
        "title": "On the anti-concentration functions of some familiar families of distributions",
        "authors": [
            "Ze-Chun Hu",
            "Renming Song",
            "Yuan Tan"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "Let $\\{X_\u03b1\\}$ be a family of random variables following a certain type of distributions with finite expectation $\\mathbf{E}[X_\u03b1]$ and finite variance ${\\rm Var}(X_\u03b1)$, where $\u03b1$ is a parameter. Motivated by the recent paper of Hollom and Portier (arXiv: 2306.07811v1), we study the anti-concentration function $(0, \\infty)\\ni y\\to \\inf_\u03b1\\mathbf{P}\\left(|X_\u03b1-\\mathbf{E}[X_\u03b1]|\\geq y \\sqrt{{\\rm Var}(X_\u03b1)}\\right)$ and find its explicit expression. We show that, for certain familiar families of distributions, including uniform distributions, exponential distributions, non-degenerate Gaussian distributions and student's $t$-distribution, the anti-concentration function is not identically zero, while for some other familiar families of distributions, including binomial, Poisson, negative binomial, hypergeometric, Gamma, Pareto, Weibull, log-normal and Beta distributions, the anti-concentration function is identically zero.",
        "comments": "15 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09998"
    },
    {
        "doc_id": 463,
        "title": "Hypercontractivity and strips of convergence in Hardy spaces of general Dirichlet series",
        "authors": [
            "Daniel Carando",
            "Andreas Defant",
            "Felipe Marceca",
            "Ingo Schoolmann",
            "Pablo Sevilla-Peris"
        ],
        "subjects": [
            "Functional Analysis"
        ],
        "abstract": "For a general Dirichlet series $\\sum a_n e^{-\u03bb_n s}$ with frequency $\u03bb=(\u03bb_n)_n$, we study how horizontal translation (i.e. convolution with a Poisson kernel) improves its integrability properties. We characterize hypercontractive frequencies in terms of their additive structure answering some questions posed by Bayart. We also provide sharp bounds for the strips $S_p(\u03bb)$ that encode the minimum translation necessary for series in the Hardy space $\\mathcal{H}_p(\u03bb)$ to have absolutely convergent coefficients.",
        "comments": "MSC Class:          43A17; 30B50; 30H10",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09996"
    },
    {
        "doc_id": 464,
        "title": "Stated $SL_n$-skein modules, roots of unity, and TQFT",
        "authors": [
            "Zhihao Wang"
        ],
        "subjects": [
            "Quantum Algebra"
        ],
        "abstract": "For a pb surface $\u03a3$, two positive integers $m,n$ with $m\\mid n$, and two invertible elements $v,\u03b5$ in a commutative domain $R$ with $\u03b5^{2m} = 1$, we construct an $R$-linear isomorphism between the stated $SL_n$-skein algebras $S_n(\u03a3,v)$ and $S_n(\u03a3,\u03b5v)$, which restricts to an algebraic ismorphism between subalgebras of $S_n(\u03a3,v)$ and $S_n(\u03a3,\u03b5v)$. Using this linear isomorphism, we prove the splitting map $\u0398_{c}:S_n(\u03a3,v)\\rightarrow S_n(\\text{Cut}_c(\u03a3),v)$ for the pb surface $\u03a3$ and the ideal arc $c$ is injective when $v^{2m} = 1$ and $m\\mid n$.\n  We generalize Barrett's work to the $SL_n$-skein space and stated $SL_n$-skein space. As an application, we prove the splitting map for the marked 3-manifolds is always injective when the quantum parameter $v=-1$.\n  Let $(M,\\mathcal{N})$ be a connected marked 3-manifold with $\\mathcal{N}\\neq\\emptyset$, and let $(M,\\mathcal{N}')$ be obtained from $(M,\\mathcal{N})$ by adding one extra marking. When $v^4 =1$, we prove the $R$-linear map from $S_n(M,\\mathcal{N},v)$ to $S_n(M,\\mathcal{N}',v)$ induced by the embedding $(M,\\mathcal{N})\\rightarrow (M,\\mathcal{N}')$ is injective and $S_n(M.\\mathcal{N}',v) = S_n(M,\\mathcal{N},v)\\otimes_{R}O_{q_v}(SL_n)$, where $O_{q_v}(SL_n)$ is the quantization of the regular function ring of $SL_n$. This shows the splitting map for $S_n(M,\\mathcal{N},v)$ is always injective.\n  We formulate the stated $SL_n$-TQFT theory, which generalizes the Costantino and L\u00ea's stated $SL_2$-TQFT theory.",
        "comments": "28 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09995"
    },
    {
        "doc_id": 465,
        "title": "Second-order estimates for the $p$-Laplacian in RCD spaces",
        "authors": [
            "Luca Benatti",
            "Ivan Yuri Violo"
        ],
        "subjects": [
            "Metric Geometry",
            "Analysis of PDEs",
            "Differential Geometry"
        ],
        "abstract": "We establish quantitative second-order Sobolev regularity for functions having a $2$-integrable $p$-Laplacian in bounded RCD spaces, with $p$ in a suitable range. In the finite-dimensional case, we also obtain Lipschitz regularity under the assumption that $p$-Laplacian is sufficiently integrable. Our results cover both $p$-Laplacian eigenfunctions and $p$-harmonic functions having relatively compact level sets.",
        "comments": "Comments are welcome!",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09982"
    },
    {
        "doc_id": 466,
        "title": "Quantum Tomography and the Quantum Radon Transform",
        "authors": [
            "Alberto Ibort",
            "Alberto L\u00f3pez-Yela"
        ],
        "subjects": [
            "Quantum Physics",
            "Group Theory"
        ],
        "abstract": "A general framework in the setting of $C^*$-algebras for the tomographical description of states, that includes, among other tomographical schemes, the classical Radon transform, quantum state tomography and group quantum tomography, is presented.\n  Given a $C^*$-algebra, the main ingredients for a tomographical description of its states are identified: A generalized sampling theory and a positive transform. A generalization of the notion of dual tomographic pair provides the background for a sampling theory on $C^*$-algebras and, an extension of Bochner's theorem for functions of positive type, the positive transform.\n  The abstract theory is realized by using dynamical systems, that is, groups represented on $C^*$-algebra. Using a fiducial state and the corresponding GNS construction, explicit expressions for tomograms associated with states defined by density operators on the corresponding Hilbert spade are obtained. In particular a general quantum version of the classical definition of the Radon transform is presented. The theory is completed by proving that if the representation of the group is square integrable, the representation itself defines a dual tomographic map and explicit reconstruction formulas are obtained by making a judiciously use of the theory of frames. A few significant examples are discussed that illustrates the use and scope of the theory.",
        "comments": "Journal ref:        Inverse Problems & Imaging. 15(5), 893-928 (2021)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09978"
    },
    {
        "doc_id": 467,
        "title": "Zero noise limit for singular ODE regularized by fractional noise",
        "authors": [
            "\u0141ukasz M\u0105dry",
            "Paul Gassiat"
        ],
        "subjects": [
            "Probability",
            "Classical Analysis and ODEs"
        ],
        "abstract": "We consider scalar ODE with a power singularity at the origin, regularized by an additive fractional noise. We show that, as the intensity in front of the noise goes to $0$, the solution converges to the extremal solutions to the ODE (which exit the origin instantly), and we quantify this convergence with subexponential probability estimates. This extends classical results of Bafico and Baldi in the Brownian case. The main difficulty lies in the absence of the Markov property for the system. Our methods combine a dynamical approach due to Delarue and Flandoli, with techniques from the large time analysis of fractional SDE (due in particular to Panloup and Richard).",
        "comments": "33 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09970"
    },
    {
        "doc_id": 468,
        "title": "Design of Initial Guess Low Thrust Trajectories Using Clohessy-Wiltshire Equations",
        "authors": [
            "Madhusudan Vijayakumar",
            "William Skamser",
            "Ossama Abdelkhalik"
        ],
        "subjects": [
            "Optimization and Control",
            "Systems and Control",
            "Space Physics"
        ],
        "abstract": "The commercial interest in producing low-cost space missions by exploiting the superior propellant management of low-thrust propulsion technology has become increasingly popular. Typical to such missions is the design of transfer trajectories between desired targets. This is a complex and computationally expensive process. Additionally, the optimal solvers used to generate these trajectories are extremely sensitive to initial guesses. One way to overcome this challenge is to use a reasonably approximate trajectory as an initial guess on optimal solvers. This paper presents a flexible approach to generating very low thrust trajectories. The initial guess is obtained from a flexible semi-analytic approach that can provide both planar and three-dimensional initial guess trajectories for various design scenarios like orbit raising, orbit insertion, phasing, and rendezvous. NASA's Evolutionary Mission Trajectory Generator (EMTG) and General Mission Analysis Tool (GMAT) are used as optimal solvers in this analysis. Numerical case studies are presented in this paper.",
        "comments": "33rd AAS/AIAA Space Flight Mechanics Meeting, Austin, TX, January 15-19, 2023",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09969"
    },
    {
        "doc_id": 469,
        "title": "Ennola duality for decomposition of tensor products",
        "authors": [
            "Emmanuel Letellier",
            "Fernando Rodriguez-Villegas"
        ],
        "subjects": [
            "Representation Theory"
        ],
        "abstract": "The aim of this paper is to investigate Ennola duality for decomposition of tensor products of irreducible characters of finite general linear groups and finite unitary groups. We prove that Ennola duality holds generically and give a geometric interpretation using the cohomology of quiver varieties. We also investigate the case of unipotent characters (typically a non-generic situation).",
        "comments": "46 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09968"
    },
    {
        "doc_id": 470,
        "title": "Iteratively Reweighted Least Squares for Phase Unwrapping",
        "authors": [
            "Benjamin Dubois-Taine",
            "Roland Akiki",
            "Alexandre d'Aspremont"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "The 2D phase unwrapping problem seeks to recover a phase image from its observation modulo 2$\u03c0$, and is a crucial step in a variety of imaging applications. In particular, it is one of the most time-consuming steps in the interferometric synthetic aperture radar (InSAR) pipeline. In this work we tackle the $L^1$-norm phase unwrapping problem. In optimization terms, this is a simple sparsity-inducing problem, albeit in very large dimension. To solve this high-dimensional problem, we iteratively solve a series of numerically simpler weighted least squares problems, which are themselves solved using a preconditioned conjugate gradient method. Our algorithm guarantees a sublinear rate of convergence in function values, is simple to implement and can easily be ported to GPUs, where it significantly outperforms state of the art phase unwrapping methods.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09961"
    },
    {
        "doc_id": 471,
        "title": "On the gr-semistable filtration of orthogonal/symplectic $\u03bb$-connections",
        "authors": [
            "Mao Sheng",
            "Hao Sun",
            "Jianping Wang"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "In this paper, we study the existence of gr-semistable filtrations of orthogonal/symplectic $\u03bb$-connections. It is well-known that gr-semistable filtrations always exist for flat bundles. However, in the orthogonal case, we give a counterexample in positive characteristic. Inspired by this example, we introduce the concept of quasi gr-semistability and prove that gr-semistability of an orthogonal/symplectic $\u03bb$-connection is equivalent to the quasi gr-semistability. This provides a way to check whether an orthogonal/symplectic $\u03bb$-connection is gr-semistable. Moreover, we discuss lower rank case and make a classification when the rank is smaller than six.",
        "comments": "27 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09956"
    },
    {
        "doc_id": 472,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 473,
        "title": "Flow Structure near Three Phase Contact Line of Low-Contact-Angle Evaporating Droplets",
        "authors": [
            "Zhenying Wang",
            "George Karapetsas",
            "Prashant Valluri",
            "Chihiro Inoue"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Soft Condensed Matter"
        ],
        "abstract": "Flow structure near three phase contact line (TPCL) of evaporating liquids plays a significant role in liquid wetting and dewetting, liquid film evaporation and boiling, etc. Despite the wide focus it receives, the interacting mechanisms therein remain elusive and in specific cases, controversial. Here, we reveal the profile of internal flow and elucidate the dominating mechanisms near TPCL of evaporating droplets, using mathematical modelling, microPIV, and infrared thermography. We indicate that for less volatile liquids such as butanol, the flow pattern is dominated by capillary flow. With increasing liquid volatility, e.g., alcohol, the effect of evaporation cooling, under conditions, induces interfacial temperature gradient with cold droplet apex and warm edge. The temperature gradient leads to Marangoni flow that competes with outwarding capillary flow, resulting in the reversal of interfacial flow and the formation of a stagnation point near TPCL. The spatiotemporal variations of capillary velocity and Marangoni velocity are further quantified by mathematically decomposing the tangential velocity of interfacial flow. The conclusions can serve as a theoretical base for explaining deposition patterns from colloidal suspensions, and can be utilized as a benchmark in analyzing more complex liquid systems.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09950"
    },
    {
        "doc_id": 474,
        "title": "SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning",
        "authors": [
            "Ho Fung Tsoi",
            "Vladimir Loncar",
            "Sridhara Dasu",
            "Philip Harris"
        ],
        "subjects": [
            "Machine Learning",
            "High Energy Physics - Experiment",
            "Instrumentation and Detectors"
        ],
        "abstract": "Contrary to the use of genetic programming, the neural network approach to symbolic regression can scale well with high input dimension and leverage gradient methods for faster equation searching. Common ways of constraining expression complexity have relied on multistage pruning methods with fine-tuning, but these often lead to significant performance loss. In this work, we propose SymbolNet, a neural network approach to symbolic regression in a novel framework that enables dynamic pruning of model weights, input features, and mathematical operators in a single training, where both training loss and expression complexity are optimized simultaneously. We introduce a sparsity regularization term per pruning type, which can adaptively adjust its own strength and lead to convergence to a target sparsity level. In contrast to most existing symbolic regression methods that cannot efficiently handle datasets with more than $O$(10) inputs, we demonstrate the effectiveness of our model on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN (3072 inputs).",
        "comments": "11 pages. Submitted to IEEE TNNLS, under review",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09949"
    },
    {
        "doc_id": 475,
        "title": "The extremal problem for weighted combined energy and the generalization of Nitsche inequality",
        "authors": [
            "Xiaogao Feng",
            "Ruyue Tang",
            "Ting Peng"
        ],
        "subjects": [
            "Complex Variables"
        ],
        "abstract": "We consider the existence and uniqueness of a minimizer of the extremal problem for weighted combined energy between two concentric annuli and obtain that the extremal mapping is a certain radial mapping. Meanwhile, this in turn implies a Nitsche type phenomenon and we get a $\\frac{1}{|w|^\u03bb}-$Nitsche type inequality ($\u03bb\\neq1$). As an application, on the basis of the relationship between weighted combined energy and weighted combined distortion, we also investigate the extremal problem for weighted combined distortion on annuli. This extends the result obtained by Kalaj in \\cite{Ka1}.",
        "comments": "15 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09948"
    },
    {
        "doc_id": 476,
        "title": "On finite analogues of Euler's constant",
        "authors": [
            "Masanobu Kaneko",
            "Toshiki Matsusaka",
            "Shin-ichiro Seki"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We introduce and study finite analogues of Euler's constant in the same setting as finite multiple zeta values. We define a couple of candidate values from the perspectives of a ``regularized value of $\u03b6(1)$'' and of Mascheroni's and Kluyver--N\u00f6rlund's series expressions of Euler's constant using Gregory coefficients. Moreover, we reveal that the differences between them always lie in the $\\mathbb{Q}$-vector space spanned by 1 and values of a finite analogue of logarithm at positive integers.",
        "comments": "14 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09935"
    },
    {
        "doc_id": 477,
        "title": "Efficient Low Rank Matrix Recovery With Flexible Group Sparse Regularization",
        "authors": [
            "Quan Yu",
            "Minru Bai",
            "Xinzhen Zhang"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "In this paper, we present a novel approach to the low rank matrix recovery (LRMR) problem by casting it as a group sparsity problem. Specifically, we propose a flexible group sparse regularizer (FLGSR) that can group any number of matrix columns as a unit, whereas existing methods group each column as a unit. We prove the equivalence between the matrix rank and the FLGSR under some mild conditions, and show that the LRMR problem with either of them has the same global minimizers. We also establish the equivalence between the relaxed and the penalty formulations of the LRMR problem with FLGSR. We then propose an inexact restarted augmented Lagrangian method, which solves each subproblem by an extrapolated linearized alternating minimization method. We analyze the convergence of our method. Remarkably, our method linearizes each group of the variable separately and uses the information of the previous groups to solve the current group within the same iteration step. This strategy enables our algorithm to achieve fast convergence and high performance, which are further improved by the restart technique. Finally, we conduct numerical experiments on both grayscale images and high altitude aerial images to confirm the superiority of the proposed FLGSR and algorithm.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09934"
    },
    {
        "doc_id": 478,
        "title": "Expansions for random walks conditioned to stay positive",
        "authors": [
            "Denis Denisov",
            "Alexander Tarasov",
            "Vitali Wachtel"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "We consider a one-dimensional random walk $S_n$ with i.i.d. increments with zero mean and finite variance. We study the asymptotic expansion for the tail distribution $\\mathbf P(\u03c4_x>n)$ of the first passage times $\u03c4_x:=\\inf\\{n\\ge1:x+S_n\\le0\\}$ for $\\ x\\ge0.$ We also derive asymptotic expansion for local probabilities $\\mathbf P(S_n=x,\u03c4_0>n)$. Studying the asymptotic expansions we obtain a sequence of discrete polyharmonic functions and obtain analogues of renewal theorem for them.",
        "comments": "51 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09929"
    },
    {
        "doc_id": 479,
        "title": "L-values of elliptic curves twisted by cubic characters",
        "authors": [
            "David Kurniadi Angdinata"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Given a rational elliptic curve $ E $ of analytic rank zero, its L-function can be twisted by an even primitive Dirichlet character $ \u03c7$ of order $ q $, and in many cases its associated central algebraic L-value $ \\mathcal{L}(E, \u03c7) $ is known to be integral. This paper derives some arithmetic consequences from a congruence between $ \\mathcal{L}(E, 1) $ and $ \\mathcal{L}(E, \u03c7) $ arising from this integrality, with an emphasis on cubic characters $ \u03c7$. These include $ q $-adic valuations of the denominator of $ \\mathcal{L}(E, 1) $, determination of $ \\mathcal{L}(E, \u03c7) $ in terms of Birch--Swinnerton-Dyer invariants, and asymptotic densities of $ \\mathcal{L}(E, \u03c7) $ modulo $ q $ by varying $ \u03c7$.",
        "comments": "20 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09927"
    },
    {
        "doc_id": 480,
        "title": "Discretization of fractional fully nonlinear equations by powers of discrete Laplacians",
        "authors": [
            "Indranil Chowdhury",
            "Espen Robstad Jakobsen",
            "Robin \u00d8stern Lien"
        ],
        "subjects": [
            "Numerical Analysis",
            "Analysis of PDEs"
        ],
        "abstract": "We study discretizations of fractional fully nonlinear equations by powers of discrete Laplacians. Our problems are parabolic and of order $\u03c3\\in(0,2)$ since they involve fractional Laplace operators $(-\u0394)^{\u03c3/2}$. They arise e.g.~in control and game theory as dynamic programming equations, and solutions are non-smooth in general and should be interpreted as viscosity solutions. Our approximations are realized as finite-difference quadrature approximations and are 2nd order accurate for all values of $\u03c3$. The accuracy of previous approximations depend on $\u03c3$ and are worse when $\u03c3$ is close to $2$. We show that the schemes are monotone, consistent, $L^\\infty$-stable, and convergent using a priori estimates, viscosity solutions theory, and the method of half-relaxed limits. We present several numerical examples.",
        "comments": "19 pages, 5 figures, 1 table",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09926"
    },
    {
        "doc_id": 481,
        "title": "Variational aspects of the generalized Seiberg-Witten functional",
        "authors": [
            "Wanjun Ai",
            "Shuhan Jiang",
            "J\u00fcrgen Jost"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, as a step towards a unified mathematical treatment of the gauge functionals from quantum field theory that have found profound applications in mathematics, we generalize the Seiberg-Witten functional that in particular includes the Kapustin-Witten functional as a special case. We first demonstrate the smoothness of weak solutions to this generalized functional. We then establish the existence of weak solutions under the assumption that the structure group of the bundle is abelian, by verifying the Palais-Smale compactness.",
        "comments": "23 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09924"
    },
    {
        "doc_id": 482,
        "title": "Tractability of linear ill-posed problems in Hilbert space",
        "authors": [
            "Peter Math\u00e9",
            "Bernd Hofmann"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We introduce a notion of tractability for ill-posed operator equations in Hilbert space. For such operator equations the\n  asymptotics of the best possible rate of reconstruction in terms of the underlying noise level is known in many cases. However, the relevant question is, which level of discretization, again driven by the noise level, is required in order to\n  achieve this best possible accuracy. The proposed concept adapts the one from Information-based Complexity.\n  Several examples indicate the relevance of this concept in the light of the curse of dimensionality.",
        "comments": "15 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09919"
    },
    {
        "doc_id": 483,
        "title": "Super graphs on groups, II",
        "authors": [
            "G. Arunkumar",
            "Peter J. Cameron",
            "Rajat Kanti Nath"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "In an earlier paper, the authors considered three types of graphs, and three equivalence relations, defined on a group, viz.\\ the power graph, enhanced power graph, and commuting graph, and the relations of equality, conjugacy, and same order; for each choice of a graph type A and an equivalence relation B, there is a graph, the \\emph{B superA graph} defined on $G$. The resulting nine graphs (of which eight were shown to be in general distinct) form a two-dimensional hierarchy. In the present paper, we consider these graphs further. We prove universality properties for the conjugacy supergraphs of various types, adding the nilpotent, solvable and enhanced power graphs to the commuting graphs considered in the rest of the paper, and also examine their relation to the invariable generating graph of the group. We also show that supergraphs can be expressed as graph compositions, in the sense of Schwenk, and use this representation to calculate their Wiener index. We illustrate these by computing Wiener index of equality supercommuting and conjugacy supercommuting graphs for dihedral and quaternion groups.",
        "comments": "21 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09912"
    },
    {
        "doc_id": 484,
        "title": "One-to-one correspondences between discrete multivariate stationary, self-similar and stationary increment fields",
        "authors": [
            "Marko Voutilainen"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "In this article, we consider three important classes of $n$-variate fields indexed by the set of $N$ dimensional integers, namely stationary, stationary increment and self-similar fields. These classes are connected through bijective transformations. In addition, we introduce generalized AR$(1)$ type equations, whose unique stationary solutions are obtained via these transformations. Lastly, we apply the transformations in order to construct stationary fractional Ornstein-Uhlenbeck fields of the first and second kind.",
        "comments": "MSC Class:          60G60; 60G10; 60G18",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09909"
    },
    {
        "doc_id": 485,
        "title": "Interplay between depth and width for interpolation in neural ODEs",
        "authors": [
            "Antonio \u00c1lvarez-L\u00f3pez",
            "Arselane Hadj Slimane",
            "Enrique Zuazua Iriondo"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "Neural ordinary differential equations (neural ODEs) have emerged as a natural tool for supervised learning from a control perspective, yet a complete understanding of their optimal architecture remains elusive. In this work, we examine the interplay between their width $p$ and number of layer transitions $L$ (effectively the depth $L+1$). Specifically, we assess the model expressivity in terms of its capacity to interpolate either a finite dataset $D$ comprising $N$ pairs of points or two probability measures in $\\mathbb{R}^d$ within a Wasserstein error margin $\\varepsilon>0$. Our findings reveal a balancing trade-off between $p$ and $L$, with $L$ scaling as $O(1+N/p)$ for dataset interpolation, and $L=O\\left(1+(p\\varepsilon^d)^{-1}\\right)$ for measure interpolation.\n  In the autonomous case, where $L=0$, a separate study is required, which we undertake focusing on dataset interpolation. We address the relaxed problem of $\\varepsilon$-approximate controllability and establish an error decay of $\\varepsilon\\sim O(\\log(p)p^{-1/d})$. This decay rate is a consequence of applying a universal approximation theorem to a custom-built Lipschitz vector field that interpolates $D$. In the high-dimensional setting, we further demonstrate that $p=O(N)$ neurons are likely sufficient to achieve exact control.",
        "comments": "16 pages, 10 figures, double column",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09902"
    },
    {
        "doc_id": 486,
        "title": "Stationary solutions to stochastic 3D Euler equations in H\u00f6lder space",
        "authors": [
            "Lin L\u00fc",
            "Rongchan Zhu"
        ],
        "subjects": [
            "Probability",
            "Analysis of PDEs"
        ],
        "abstract": "We establish the existence of infinitely many global and stationary solutions in $C(\\mathbb{R};C^{\\vartheta})$ space for some $\\vartheta>0$ to the three dimensional Euler equations driven by an additive noise. The result is based on a new stochastic version of the convex integration method, incorporating the stochastic convex integration method developed in \\cite{HZZ22b} and pathwise estimates to derive uniform moment estimates independent of time.",
        "comments": "37 pages. arXiv admin note: text overlap with arXiv:2208.08290",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09894"
    },
    {
        "doc_id": 487,
        "title": "The Double Bubble Problem in the Hexagonal Norm",
        "authors": [
            "Parker Duncan",
            "Rory O'Dwyer",
            "Eviatar B. Procaccia"
        ],
        "subjects": [
            "Metric Geometry",
            "Geometric Topology"
        ],
        "abstract": "We study the double bubble problem where the perimeter is taken with respect to the hexagonal norm, i.e. the norm whose unit circle in $\\mathbb{R}^2$ is the regular hexagon. We provide an elementary proof for the existence of minimizing sets for volume ratio parameter $\u03b1\\in (0,1]$ by arguing that any minimizer must belong to a small family of parameterized sets. This family is further simplified by showing that $60^{\\circ}$ angles are not optimal as well as other geometric exclusions. We then provide a minimizer for all $\u03b1\\in(0,1]$ except at a single point, for which we find two minimizing configurations.",
        "comments": "42 pages, 57 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09893"
    },
    {
        "doc_id": 488,
        "title": "Identity in the presence of adjunction",
        "authors": [
            "Mateusz Stroi\u0144ski"
        ],
        "subjects": [
            "Category Theory",
            "Quantum Algebra",
            "Representation Theory"
        ],
        "abstract": "We develop a theory of adjunctions in semigroup categories, i.e. monoidal categories without a unit object. We show that a rigid semigroup category is promonoidal, and thus one can naturally adjoin a unit object to it. This extends the previous results of Houston in the symmetric case, and addresses a question of his. It also extends the results in the non-symmetric case with additional finiteness assumptions, obtained by Benson-Etingof-Ostrik, Coulembier and Ko-Mazorchuk-Zhang. We give an interpretation of these results using comonad cohomology, and, in the absence of finiteness conditions, using enriched traces of monoidal categories. As an application of our results, we give a characterization of finite tensor categories in terms of the finitary 2-representation theory of Mazorchuk-Miemietz.",
        "comments": "33 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09892"
    },
    {
        "doc_id": 489,
        "title": "Simplicial cell decompositions of $\\mathbb{CP}^{\\hspace{.3mm}n}$",
        "authors": [
            "Basudeb Datta",
            "Jonathan Spreer"
        ],
        "subjects": [
            "Combinatorics",
            "Geometric Topology"
        ],
        "abstract": "According to a well-known result in geometric topology, we have $\\left (\\mathbb{S}^2 \\right)^{n}\\!\\!/\\operatorname{Sym}(n) = \\mathbb{CP}^{n}$, where $\\operatorname{Sym}(n)$ acts on $\\left (\\mathbb{S}^2 \\right)^{n}$ by coordinate permutation. We use this fact to explicitly construct a regular simplicial cell decomposition of $\\mathbb{CP}^{n}$ for each $n \\geq 2$. In more detail, we take the standard two triangle crystallisation $S^2_3$ of the $2$-sphere $\\mathbb{S}^2$, in its $n$-fold Cartesian product. We then simplicially subdivide, and prove that naively taking the $\\operatorname{Sym}(n)$ quotient yields a simplicial cell decomposition of $\\mathbb{CP}^n$. Taking the first derived subdivision of this cell complex produces a triangulation of $\\mathbb{CP}^n$. To the best of our knowledge, this is the first explicit description of triangulations of $\\mathbb{CP}^n$ for $n \\geq 4$.",
        "comments": "14 pages, 1 figure, 16 pages of appendix",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09891"
    },
    {
        "doc_id": 490,
        "title": "NLS ground states on a hybrid plane",
        "authors": [
            "Riccardo Adami",
            "Filippo Boni",
            "Raffaele Carlone",
            "Lorenzo Tentarelli"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics",
            "Functional Analysis"
        ],
        "abstract": "We study the existence, the nonexistence, and the shape of the ground states of a Nonlinear Schr\u00f6dinger Equation on a manifold called hybrid plane, that consists of a half-line whose origin is connected to a plane. The nonlinearity is of power type, focusing and subcritical. The energy is the sum of the Nonlinear Schr\u00f6dinger energies with a contact interaction on the half-line and on the plane with an additional quadratic term that couples the two components. By ground state we mean every minimizer of the energy at a fixed mass.\n  As a first result, we single out the following rule: a ground state exists if and only if the confinement near the junction is energetically more convenient than escaping at infinity along the halfline, while escaping through the plane is shown to be never convenient. The problem of existence reduces then to a competition with the one-dimensional solitons.\n  By this criterion, we prove existence of ground states for large and small values of the mass. Moreover, we show that at given mass a ground state exists if one of the following conditions is satisfied: the interaction at the origin of the half-line is not too repulsive; the interaction at the origin of the plane is sufficiently attractive; the coupling between the half-line and the plane is strong enough. On the other hand, nonexistence holds if the contact interactions on the half-line and on the plane are repulsive enough and the coupling is not too strong.\n  Finally, we provide qualitative features of ground states. In particular, we show that in the presence of coupling every ground state is supported both on the half-line and on the plane and each component has the shape of a ground state at its mass for the related Nonlinear Schr\u00f6dinger energy with a suitable contact interaction.\n  These are the first results for the Nonlinear Schr\u00f6dinger Equation on a manifold of mixed dimensionality.",
        "comments": "31 pages, 1 figure. Keywords: hybrids, standing waves, nonlinear Schr\u00f6dinger, ground states, delta interaction, radially symmetric solutions, rearrangements",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09888"
    },
    {
        "doc_id": 491,
        "title": "Labelled calculi for lattice-based modal logics",
        "authors": [
            "Ineke van der Berg",
            "Andrea De Domenico",
            "Giuseppe Greco",
            "Krishna Manoorkar",
            "Alessandra Palmigiano",
            "Mattia Panettiere"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "We introduce labelled sequent calculi for the basic normal non-distributive modal logic L and 31 of its axiomatic extensions, where the labels are atomic formulas of a first order language which is interpreted on the canonical extensions of the algebras in the variety corresponding to the logic L. Modular proofs are presented that these calculi are all sound, complete and conservative w.r.t. L, and enjoy cut elimination and the subformula property. The introduction of these calculi showcases a general methodology for introducing labelled calculi for the class of LE-logics and their analytic axiomatic extensions in a principled and uniform way.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09887"
    },
    {
        "doc_id": 492,
        "title": "On manifold-like polyfolds as differential geometrical objects with applications in complex geometry",
        "authors": [
            "Per \u00c5hag",
            "Rafa\u0142\\ Czy\u017c",
            "H\u00e5kan Samuelsson Kalm",
            "Aron Persson"
        ],
        "subjects": [
            "Differential Geometry",
            "Complex Variables",
            "Symplectic Geometry"
        ],
        "abstract": "We argue for more widespread use of manifold-like polyfolds (M-polyfolds) as differential geometric objects. M-polyfolds possess a distinct advantage over differentiable manifolds, enabling a smooth and local change of dimension. To establish their utility, we introduce tensors and prove the existence of Riemannian metrics, symplectic structures, and almost complex structures within the M-polyfold framework. Drawing inspiration from a series of highly acclaimed articles by L\u00e1zl\u00f3 Lempert, we lay the foundation for advancing geometry and function theory in complex M-polyfolds.",
        "comments": "MSC Class:          Primary 58B99; 53C15; 53C56; Secondary 58C99; 46G20; 32Q60",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09875"
    },
    {
        "doc_id": 493,
        "title": "Well-posedness results for general reaction-diffusion transport of oxygen in encapsulated cells",
        "authors": [
            "Yuma Nakamura",
            "Kharisma Surya Putri",
            "Alef Sterk",
            "Thomas Geert de Jong"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we provide well-posedness results for nonlinear parabolic PDEs given by reaction-diffusion equations describing the concentration of oxygen in encapsulated cells. The cells are described in terms of a core and a shell, which introduces a discontinuous diffusion coefficient as the material properties of the core and shell differ. In addition, the cells are subject to general nonlinear consumption of oxygen. As no monotonicity condition is imposed on the consumption monotone operator theory cannot be used. Moreover, the discontinuity in the diffusion coefficient bars us to apply classical results. However, by directly applying a Galerkin method we obtain uniqueness and existence of the strong form solution. These results will provide the basis to study the dynamics of cells in critical states.",
        "comments": "MSC Class:          34K20; 92C45",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09863"
    },
    {
        "doc_id": 494,
        "title": "Small energy scattering for radial solutions to the generalized Zakharov system",
        "authors": [
            "Jun Kato",
            "Osamu Tojyo"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We prove the small energy scattering for the three-dimensional generalized Zakharov system with radial symmetry based on the idea by Guo and Nakanishi (2014), which treats the usual Zakharov system. For the proof, we use the frequency-localized normal form reduction, and the radially improved Strichartz estimates.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09855"
    },
    {
        "doc_id": 495,
        "title": "On the global well-posedness of 3D inhomogeneous incompressible Navier-Stokes system with density-dependent viscosity",
        "authors": [
            "Dongjuan Niu",
            "Lu Wang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we are concerned with the global well-posedness of 3D inhomogeneous incompressible Navier-Stokes equations with density-dependent viscosity when the initial velocity is sufficiently small in the critical Besov space $\\dot{B}^{\\frac 12}$. Compared with the previous result of Abidi and Zhang (Science China Mathematics 58 (6) (2015) 1129-1150), we remove the smallness assumption of the viscosity $\u03bc(\u03c1_0)-1$ in $L^{\\infty}$-norm.",
        "comments": "36 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09850"
    },
    {
        "doc_id": 496,
        "title": "Mixed-Integer Linear Optimization for Semi-Supervised Optimal Classification Trees",
        "authors": [
            "Jan Pablo Burgard",
            "Maria Eduarda Pinheiro",
            "Martin Schmidt"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "Decision trees are one of the most famous methods for solving classification problems, mainly because of their good interpretability properties. Moreover, due to advances in recent years in mixed-integer optimization, several models have been proposed to formulate the problem of computing optimal classification trees. The goal is, given a set of labeled points, to split the feature space with hyperplanes and assign a class to each partition. In certain scenarios, however, labels are exclusively accessible for a subset of the given points. Additionally, this subset may be non-representative, such as in the case of self-selection in a survey. Semi-supervised decision trees tackle the setting of labeled and unlabeled data and often contribute to enhancing the reliability of the results. Furthermore, undisclosed sources may provide extra information about the size of the classes. We propose a mixed-integer linear optimization model for computing semi-supervised optimal classification trees that cover the setting of labeled and unlabeled data points as well as the overall number of points in each class for a binary classification. Our numerical results show that our approach leads to a better accuracy and a better Matthews correlation coefficient for biased samples compared to other optimal classification trees, even if only few labeled points are available.",
        "comments": "22 pages, 6 figures. arXiv admin note: text overlap with arXiv:2303.12532",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09848"
    },
    {
        "doc_id": 497,
        "title": "Solutions to some sign change problems on the functions involving sums of divisors",
        "authors": [
            "Yuchen Ding",
            "Hao Pan",
            "Yu--Chen Sun"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "In this note, we solve some sign change problems on the functions involving sums of divisors posed by Pongsriiam recently.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09842"
    },
    {
        "doc_id": 498,
        "title": "Interior Schauder estimates for Stokes systems in non-divergence form",
        "authors": [
            "Rong Dong",
            "Dongsheng Li",
            "Lihe Wang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "The global Schauder estimates for Stokes systems are established by Solonnikov [15] and [16] while the interior ones may fail generally from Serrin's counterexample (cf. [14]). Nevertheless, this paper obtains interior $C^{2,\u03b1}$ estimates for velocity and interior $C^{1,\u03b1}$ estimates for pressure in spatial direction. Furthermore, the $C^{\u03b1, \\frac\u03b12}$ estimate is attained for derivatives of curl of velocity. The estimates for velocity can be achieved pointwisely. The results are sharp and surprising since no continuity in time variable is assumed for the coefficients and the righthand side terms.",
        "comments": "arXiv admin note: text overlap with arXiv:2304.03529",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09841"
    },
    {
        "doc_id": 499,
        "title": "Convergence of a spatial semidiscretization for a three-dimensional stochastic Allen-Cahn equation with multiplicative noise",
        "authors": [
            "Binjie Li",
            "Qin Zhou"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability"
        ],
        "abstract": "This paper studies the convergence of a spatial semidiscretization of a three-dimensional stochastic Allen-Cahn equation with multiplicative noise. For non-smooth initial values, the regularity of the mild solution is investigated, and an error estimate is derived with the spatial $ L^2 $-norm. For smooth initial values, two error estimates with the general spatial $ L^q $-norms are established.",
        "comments": "MSC Class:          65M60; 60H15; 60H35",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09834"
    }
]