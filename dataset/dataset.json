[
    {
        "doc_id": 0,
        "title": "GALA: Generating Animatable Layered Assets from a Single Scan",
        "authors": [
            "Taeksoo Kim",
            "Byungjun Kim",
            "Shunsuke Saito",
            "Hanbyul Joo"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We present GALA, a framework that takes as input a single-layer clothed 3D human mesh and decomposes it into complete multi-layered 3D assets. The outputs can then be combined with other assets to create novel clothed human avatars with any pose. Existing reconstruction approaches often treat clothed humans as a single-layer of geometry and overlook the inherent compositionality of humans with hairstyles, clothing, and accessories, thereby limiting the utility of the meshes for downstream applications. Decomposing a single-layer mesh into separate layers is a challenging task because it requires the synthesis of plausible geometry and texture for the severely occluded regions. Moreover, even with successful decomposition, meshes are not normalized in terms of poses and body shapes, failing coherent composition with novel identities and poses. To address these challenges, we propose to leverage the general knowledge of a pretrained 2D diffusion model as geometry and appearance prior for humans and other assets. We first separate the input mesh using the 3D surface segmentation extracted from multi-view 2D segmentations. Then we synthesize the missing geometry of different layers in both posed and canonical spaces using a novel pose-guided Score Distillation Sampling (SDS) loss. Once we complete inpainting high-fidelity 3D geometry, we also apply the same SDS loss to its texture to obtain the complete appearance including the initially occluded regions. Through a series of decomposition steps, we obtain multiple layers of 3D assets in a shared canonical space normalized in terms of poses and human shapes, hence supporting effortless composition to novel identities and reanimation with novel poses. Our experiments demonstrate the effectiveness of our approach for decomposition, canonicalization, and composition tasks compared to existing solutions.",
        "comments": "The project page is available at https://snuvclab.github.io/gala/",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12979"
    },
    {
        "doc_id": 1,
        "title": "Zero-Shot Learning for the Primitives of 3D Affordance in General Objects",
        "authors": [
            "Hyeonwoo Kim",
            "Sookwan Han",
            "Patrick Kwon",
            "Hanbyul Joo"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "One of the major challenges in AI is teaching machines to precisely respond and utilize environmental functionalities, thereby achieving the affordance awareness that humans possess. Despite its importance, the field has been lagging in terms of learning, especially in 3D, as annotating affordance accompanies a laborious process due to the numerous variations of human-object interaction. The low availability of affordance data limits the learning in terms of generalization for object categories, and also simplifies the representation of affordance, capturing only a fraction of the affordance. To overcome these challenges, we propose a novel, self-supervised method to generate the 3D affordance examples given only a 3D object, without any manual annotations. The method starts by capturing the 3D object into images and creating 2D affordance images by inserting humans into the image via inpainting diffusion models, where we present the Adaptive Mask algorithm to enable human insertion without altering the original details of the object. The method consequently lifts inserted humans back to 3D to create 3D human-object pairs, where the depth ambiguity is resolved within a depth optimization framework that utilizes pre-generated human postures from multiple viewpoints. We also provide a novel affordance representation defined on relative orientations and proximity between dense human and object points, that can be easily aggregated from any 3D HOI datasets. The proposed representation serves as a primitive that can be manifested to conventional affordance representations via simple transformations, ranging from physically exerted affordances to nonphysical ones. We demonstrate the efficacy of our method and representation by generating the 3D affordance samples and deriving high-quality affordance examples from the representation, including contact, orientation, and spatial occupancies.",
        "comments": "Project Page: https://sshowbiz.github.io/ZSP3A/",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12978"
    },
    {
        "doc_id": 2,
        "title": "IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images",
        "authors": [
            "Zhi-Hao Lin",
            "Jia-Bin Huang",
            "Zhengqin Li",
            "Zhao Dong",
            "Christian Richardt",
            "Tuotuo Li",
            "Michael Zollh\u00f6fer",
            "Johannes Kopf",
            "Shenlong Wang",
            "Changil Kim"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Graphics"
        ],
        "abstract": "While numerous 3D reconstruction and novel-view synthesis methods allow for photorealistic rendering of a scene from multi-view images easily captured with consumer cameras, they bake illumination in their representations and fall short of supporting advanced applications like material editing, relighting, and virtual object insertion. The reconstruction of physically based material properties and lighting via inverse rendering promises to enable such applications.\n  However, most inverse rendering techniques require high dynamic range (HDR) images as input, a setting that is inaccessible to most users. We present a method that recovers the physically based material properties and spatially-varying HDR lighting of a scene from multi-view, low-dynamic-range (LDR) images. We model the LDR image formation process in our inverse rendering pipeline and propose a novel optimization strategy for material, lighting, and a camera response model. We evaluate our approach with synthetic and real scenes compared to the state-of-the-art inverse rendering methods that take either LDR or HDR input. Our method outperforms existing methods taking LDR images as input, and allows for highly realistic relighting and object insertion.",
        "comments": "Project Website: https://irisldr.github.io/",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12977"
    },
    {
        "doc_id": 3,
        "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments",
        "authors": [
            "Qinhong Zhou",
            "Sunli Chen",
            "Yisong Wang",
            "Haozhe Xu",
            "Weihua Du",
            "Hongxin Zhang",
            "Yilun Du",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Computation and Language"
        ],
        "abstract": "Recent advances in high-fidelity virtual environments serve as one of the major driving forces for building intelligent embodied agents to perceive, reason and interact with the physical world. Typically, these environments remain unchanged unless agents interact with them. However, in real-world scenarios, agents might also face dynamically changing environments characterized by unexpected events and need to rapidly take action accordingly. To remedy this gap, we propose a new simulated embodied benchmark, called HAZARD, specifically designed to assess the decision-making abilities of embodied agents in dynamic situations. HAZARD consists of three unexpected disaster scenarios, including fire, flood, and wind, and specifically supports the utilization of large language models (LLMs) to assist common sense reasoning and decision-making. This benchmark enables us to evaluate autonomous agents' decision-making capabilities across various pipelines, including reinforcement learning (RL), rule-based, and search-based methods in dynamically changing environments. As a first step toward addressing this challenge using large language models, we further develop an LLM-based agent and perform an in-depth analysis of its promise and challenge of solving these challenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.",
        "comments": "ICLR 2024. The first two authors contributed equally to this work",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12975"
    },
    {
        "doc_id": 4,
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "authors": [
            "Hanxue Gu",
            "Roy Colglazier",
            "Haoyu Dong",
            "Jikai Zhang",
            "Yaqian Chen",
            "Zafer Yildiz",
            "Yuwen Chen",
            "Lin Li",
            "Jichen Yang",
            "Jay Willhite",
            "Alex M. Meyer",
            "Brian Guo",
            "Yashvi Atul Shah",
            "Emily Luo",
            "Shipra Rajput",
            "Sally Kuehn",
            "Clark Bulleit",
            "Kevin A. Wu",
            "Jisoo Lee",
            "Brandon Ramirez",
            "Darui Lu",
            "Jay M. Levin",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "comments": "15 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12974"
    },
    {
        "doc_id": 5,
        "title": "In-Context Language Learning: Arhitectures and Algorithms",
        "authors": [
            "Ekin Aky\u00fcrek",
            "Bailin Wang",
            "Yoon Kim",
            "Jacob Andreas"
        ],
        "subjects": [
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Large-scale neural language models exhibit a remarkable capacity for in-context learning (ICL): they can infer novel functions from datasets provided as input. Most of our current understanding of when and how ICL arises comes from LMs trained on extremely simple learning problems like linear regression and associative recall. There remains a significant gap between these model problems and the \"real\" ICL exhibited by LMs trained on large text corpora, which involves not just retrieval and function approximation but free-form generation of language and other structured outputs. In this paper, we study ICL through the lens of a new family of model problems we term in context language learning (ICLL). In ICLL, LMs are presented with a set of strings from a formal language, and must generate additional strings from the same language. We focus on in-context learning of regular languages generated by random finite automata. We evaluate a diverse set of neural sequence models (including several RNNs, Transformers, and state-space model variants) on regular ICLL tasks, aiming to answer three questions: (1) Which model classes are empirically capable of ICLL? (2) What algorithmic solutions do successful models implement to perform ICLL? (3) What architectural changes can improve ICLL in less performant models? We first show that Transformers significantly outperform neural sequence models with recurrent or convolutional representations on ICLL tasks. Next, we provide evidence that their ability to do so relies on specialized \"n-gram heads\" (higher-order variants of induction heads) that compute input-conditional next-token distributions. Finally, we show that hard-wiring these heads into recurrent and convolutional models improves performance not just on ICLL, but natural language modeling -- improving the perplexity of 340M-parameter models by up to 1.14 points (6.7%) on the SlimPajama dataset.",
        "comments": "29 pages, 8 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12973"
    },
    {
        "doc_id": 6,
        "title": "On the Efficacy of Text-Based Input Modalities for Action Anticipation",
        "authors": [
            "Apoorva Beedu",
            "Karan Samel",
            "Irfan Essa"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "Although the task of anticipating future actions is highly uncertain, information from additional modalities help to narrow down plausible action choices. Each modality provides different environmental context for the model to learn from. While previous multi-modal methods leverage information from modalities such as video and audio, we primarily explore how text inputs for actions and objects can also enable more accurate action anticipation. Therefore, we propose a Multi-modal Anticipative Transformer (MAT), an attention-based video transformer architecture that jointly learns from multi-modal features and text captions. We train our model in two-stages, where the model first learns to predict actions in the video clip by aligning with captions, and during the second stage, we fine-tune the model to predict future actions. Compared to existing methods, MAT has the advantage of learning additional environmental context from two kinds of text inputs: action descriptions during the pre-training stage, and the text inputs for detected objects and actions during modality feature fusion. Through extensive experiments, we evaluate the effectiveness of the pre-training stage, and show that our model outperforms previous methods on all datasets. In addition, we examine the impact of object and action information obtained via text and perform extensive ablations. We evaluate the performance on on three datasets: EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that text descriptions do indeed aid in more effective action anticipation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12972"
    },
    {
        "doc_id": 7,
        "title": "Raidar: geneRative AI Detection viA Rewriting",
        "authors": [
            "Chengzhi Mao",
            "Carl Vondrick",
            "Hao Wang",
            "Junfeng Yang"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "We find that large language models (LLMs) are more likely to modify human-written text than AI-generated text when tasked with rewriting. This tendency arises because LLMs often perceive AI-generated text as high-quality, leading to fewer modifications. We introduce a method to detect AI-generated content by prompting LLMs to rewrite text and calculating the editing distance of the output. We dubbed our geneRative AI Detection viA Rewriting method Raidar. Raidar significantly improves the F1 detection scores of existing AI content detection models -- both academic and commercial -- across various domains, including News, creative writing, student essays, code, Yelp reviews, and arXiv papers, with gains of up to 29 points. Operating solely on word symbols without high-dimensional features, our method is compatible with black box LLMs, and is inherently robust on new content. Our results illustrate the unique imprint of machine-generated text through the lens of the machines themselves.",
        "comments": "Accepted by ICLR 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12970"
    },
    {
        "doc_id": 8,
        "title": "Workspace Optimization Techniques to Improve Prediction of Human Motion During Human-Robot Collaboration",
        "authors": [
            "Yi-Shiuan Tung",
            "Matthew B. Luebbers",
            "Alessandro Roncone",
            "Bradley Hayes"
        ],
        "subjects": [
            "Robotics"
        ],
        "abstract": "Understanding human intentions is critical for safe and effective human-robot collaboration. While state of the art methods for human goal prediction utilize learned models to account for the uncertainty of human motion data, that data is inherently stochastic and high variance, hindering those models' utility for interactions requiring coordination, including safety-critical or close-proximity tasks. Our key insight is that robot teammates can deliberately configure shared workspaces prior to interaction in order to reduce the variance in human motion, realizing classifier-agnostic improvements in goal prediction. In this work, we present an algorithmic approach for a robot to arrange physical objects and project \"virtual obstacles\" using augmented reality in shared human-robot workspaces, optimizing for human legibility over a given set of tasks. We compare our approach against other workspace arrangement strategies using two human-subjects studies, one in a virtual 2D navigation domain and the other in a live tabletop manipulation domain involving a robotic manipulator arm. We evaluate the accuracy of human motion prediction models learned from each condition, demonstrating that our workspace optimization technique with virtual obstacles leads to higher robot prediction accuracy using less training data.",
        "comments": "International Conference on Human-Robot Interaction",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12965"
    },
    {
        "doc_id": 9,
        "title": "AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents",
        "authors": [
            "Michael Ahn",
            "Debidatta Dwibedi",
            "Chelsea Finn",
            "Montse Gonzalez Arenas",
            "Keerthana Gopalakrishnan",
            "Karol Hausman",
            "Brian Ichter",
            "Alex Irpan",
            "Nikhil Joshi",
            "Ryan Julian",
            "Sean Kirmani",
            "Isabel Leal",
            "Edward Lee",
            "Sergey Levine",
            "Yao Lu",
            "Isabel Leal",
            "Sharath Maddineni",
            "Kanishka Rao",
            "Dorsa Sadigh",
            "Pannag Sanketi",
            "Pierre Sermanet",
            "Quan Vuong",
            "Stefan Welker",
            "Fei Xia",
            "Ted Xiao",
            "et al. (3 additional authors not shown)"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Foundation models that incorporate language, vision, and more recently actions have revolutionized the ability to harness internet scale data to reason about useful tasks. However, one of the key challenges of training embodied foundation models is the lack of data grounded in the physical world. In this paper, we propose AutoRT, a system that leverages existing foundation models to scale up the deployment of operational robots in completely unseen scenarios with minimal human supervision. AutoRT leverages vision-language models (VLMs) for scene understanding and grounding, and further uses large language models (LLMs) for proposing diverse and novel instructions to be performed by a fleet of robots. Guiding data collection by tapping into the knowledge of foundation models enables AutoRT to effectively reason about autonomy tradeoffs and safety while significantly scaling up data collection for robot learning. We demonstrate AutoRT proposing instructions to over 20 robots across multiple buildings and collecting 77k real robot episodes via both teleoperation and autonomous robot policies. We experimentally show that such \"in-the-wild\" data collected by AutoRT is significantly more diverse, and that AutoRT's use of LLMs allows for instruction following data collection robots that can align to human preferences.",
        "comments": "26 pages, 9 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12963"
    },
    {
        "doc_id": 10,
        "title": "Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via Cyclic Schedulers",
        "authors": [
            "Sahan Liyanaarachchi",
            "Sennur Ulukus",
            "Nail Akar"
        ],
        "subjects": [
            "Information Theory",
            "Networking and Internet Architecture",
            "Systems and Control"
        ],
        "abstract": "In a communication setting where multiple sources share a single channel to provide status updates to a remote monitor, source transmissions need to be scheduled appropriately to maintain timely communication between each of the sources and the monitor. We consider age-agnostic scheduling policies which are advantageous due to their simplicity of implementation. Further, we focus on a special class of age-agnostic policies, called cyclic schedulers, where each source is scheduled based on a fixed cyclic pattern. We use weighted average age of information (AoI) to quantify the timeliness of communication. We develop a Markov chain formulation to compute the exact mean AoI for the case of two-source cyclic schedulers. Based on the obtained age expression, we develop an algorithm that generates near-optimal cyclic schedulers to minimize the weighted average AoI for two heterogeneous sources, in the presence of channel errors.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12962"
    },
    {
        "doc_id": 11,
        "title": "Chatterbox: Robust Transport for LLM Token Streaming under Unstable Network",
        "authors": [
            "Hanchen Li",
            "Yuhan Liu",
            "Yihua Cheng",
            "Siddhant Ray",
            "Kuntai Du",
            "Junchen Jiang"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Machine Learning"
        ],
        "abstract": "To render each generated token in real time, the LLM server generates response tokens one by one and streams each generated token (or group of a few tokens) through the network to the user right after it is generated, which we refer to as LLM token streaming. However, under unstable network conditions, the LLM token streaming experience could suffer greatly from stalls since one packet loss could block the rendering of tokens contained in subsequent packets even if they arrive on time. With a real-world measurement study, we show that current applications including ChatGPT, Claude, and Bard all suffer from increased stall under unstable network.\n  For this emerging token streaming problem in LLM Chatbots, we propose a novel transport layer scheme, called Chatterbox, which puts new generated tokens as well as currently unacknowledged tokens in the next outgoing packet. This ensures that each packet contains some new tokens and can be independently rendered when received, thus avoiding aforementioned stalls caused by missing packets. Through simulation under various network conditions, we show Chatterbox reduces stall ratio (proportion of token rendering wait time) by 71.0% compared to the token streaming method commonly used by real chatbot applications and by 31.6% compared to a custom packet duplication scheme. By tailoring Chatterbox to fit the token-by-token generation of LLM, we enable the Chatbots to respond like an eloquent speaker for users to better enjoy pervasive AI.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12961"
    },
    {
        "doc_id": 12,
        "title": "Understanding Emojis :) in Useful Code Review Comments",
        "authors": [
            "Sharif Ahmed",
            "Nasir U. Eisty"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Emojis and emoticons serve as non-verbal cues and are increasingly prevalent across various platforms, including Modern Code Review. These cues often carry emotive or instructive weight for developers. Our study dives into the utility of Code Review comments (CR comments) by scrutinizing the sentiments and semantics conveyed by emojis within these comments. To assess the usefulness of CR comments, we augment traditional 'textual' features and pre-trained embeddings with 'emoji-specific' features and pre-trained embeddings. To fortify our inquiry, we expand an existing dataset with emoji annotations, guided by existing research on GitHub emoji usage, and re-evaluate the CR comments accordingly. Our models, which incorporate textual and emoji-based sentiment features and semantic understandings of emojis, substantially outperform baseline metrics. The often-overlooked emoji elements in CR comments emerge as key indicators of usefulness, suggesting that these symbols carry significant weight.",
        "comments": "This paper has been accepted for inclusion in the Proceedings of the 3rd Intl. Workshop on NL-based Software Engineering co-located at 46th International Conference on Software Engineering (NLBSE@ICSE 2024)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12959"
    },
    {
        "doc_id": 13,
        "title": "Examining the Role of Peer Acknowledgements on Social Annotations: Unraveling the Psychological Underpinnings",
        "authors": [
            "Xiaoshan Huang",
            "Haolun Wu",
            "Xue Liu",
            "Susanne Lajoie"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "This study explores the impact of peer acknowledgement on learner engagement and implicit psychological attributes in written annotations on an online social reading platform. Participants included 91 undergraduates from a large North American University. Using log file data, we analyzed the relationship between learners' received peer acknowledgement and their subsequent annotation behaviours using cross-lag regression. Higher peer acknowledgements correlate with increased initiation of annotations and responses to peer annotations. By applying text mining techniques and calculating Shapley values to analyze 1,969 social annotation entries, we identified prominent psychological themes within three dimensions (i.e., affect, cognition, and motivation) that foster peer acknowledgment in digital social annotation. These themes include positive affect, openness to learning and discussion, and expression of motivation. The findings assist educators in improving online learning communities and provide guidance to technology developers in designing effective prompts, drawing from both implicit psychological cues and explicit learning behaviours.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12956"
    },
    {
        "doc_id": 14,
        "title": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding",
        "authors": [
            "Mirac Suzgun",
            "Adam Tauman Kalai"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Human-Computer Interaction"
        ],
        "abstract": "We introduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct \"expert\" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly enhancing its performance across a wide array of tasks. The zero-shot, task-agnostic nature of meta-prompting greatly simplifies user interaction by obviating the need for detailed, task-specific instructions. Furthermore, our research demonstrates the seamless integration of external tools, such as a Python interpreter, into the meta-prompting framework, thereby broadening its applicability and utility. Through rigorous experimentation with GPT-4, we establish the superiority of meta-prompting over conventional scaffolding methods: When averaged across all tasks, including the Game of 24, Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented with a Python interpreter functionality, surpasses standard prompting by 17.1%, expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.",
        "comments": "https://github.com/suzgunmirac/meta-prompting",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12954"
    },
    {
        "doc_id": 15,
        "title": "Bayesian Semi-structured Subspace Inference",
        "authors": [
            "Daniel Dold",
            "David R\u00fcgamer",
            "Beate Sick",
            "Oliver D\u00fcrr"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach's efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.",
        "comments": "Accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12950"
    },
    {
        "doc_id": 16,
        "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
        "authors": [
            "Dylan Zhang",
            "Curt Tigges",
            "Zory Zhang",
            "Stella Biderman",
            "Maxim Raginsky",
            "Talia Ringer"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Formal Languages and Automata Theory",
            "Logic in Computer Science",
            "Programming Languages"
        ],
        "abstract": "This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \\textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \\textit{semantics} -- one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture.\n  With our framework as a powerful conceptual tool, we identify different issues under various set-ups. The models trained to emulate recursive computations cannot fully capture the recursion yet instead fit short-cut algorithms and thus cannot solve certain edge cases that are under-represented in the training distribution. In addition, it is difficult for state-of-the-art large language models (LLMs) to mine recursive rules from in-context demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating reduction (step-wise computation) of the recursive function.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.14699",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12947"
    },
    {
        "doc_id": 17,
        "title": "Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization",
        "authors": [
            "Zimeng Wang",
            "Zhiyang Dou",
            "Rui Xu",
            "Cheng Lin",
            "Yuan Liu",
            "Xiaoxiao Long",
            "Shiqing Xin",
            "Lingjie Liu",
            "Taku Komura",
            "Xiaoming Yuan",
            "Wenping Wang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computational Geometry",
            "Graphics"
        ],
        "abstract": "We introduce Coverage Axis++, a novel and efficient approach to 3D shape skeletonization. The current state-of-the-art approaches for this task often rely on the watertightness of the input or suffer from substantial computational costs, thereby limiting their practicality. To address this challenge, Coverage Axis++ proposes a heuristic algorithm to select skeletal points, offering a high-accuracy approximation of the Medial Axis Transform (MAT) while significantly mitigating computational intensity for various shape representations. We introduce a simple yet effective strategy that considers both shape coverage and uniformity to derive skeletal points. The selection procedure enforces consistency with the shape structure while favoring the dominant medial balls, which thus introduces a compact underlying shape representation in terms of MAT. As a result, Coverage Axis++ allows for skeletonization for various shape representations (e.g., water-tight meshes, triangle soups, point clouds), specification of the number of skeletal points, few hyperparameters, and highly efficient computation with improved reconstruction accuracy. Extensive experiments across a wide range of 3D shapes validate the efficiency and effectiveness of Coverage Axis++. The code will be publicly available once the paper is published.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12946"
    },
    {
        "doc_id": 18,
        "title": "Lumiere: A Space-Time Diffusion Model for Video Generation",
        "authors": [
            "Omer Bar-Tal",
            "Hila Chefer",
            "Omer Tov",
            "Charles Herrmann",
            "Roni Paiss",
            "Shiran Zada",
            "Ariel Ephrat",
            "Junhwa Hur",
            "Yuanzhen Li",
            "Tomer Michaeli",
            "Oliver Wang",
            "Deqing Sun",
            "Tali Dekel",
            "Inbar Mosseri"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We introduce Lumiere -- a text-to-video diffusion model designed for synthesizing videos that portray realistic, diverse and coherent motion -- a pivotal challenge in video synthesis. To this end, we introduce a Space-Time U-Net architecture that generates the entire temporal duration of the video at once, through a single pass in the model. This is in contrast to existing video models which synthesize distant keyframes followed by temporal super-resolution -- an approach that inherently makes global temporal consistency difficult to achieve. By deploying both spatial and (importantly) temporal down- and up-sampling and leveraging a pre-trained text-to-image diffusion model, our model learns to directly generate a full-frame-rate, low-resolution video by processing it in multiple space-time scales. We demonstrate state-of-the-art text-to-video generation results, and show that our design easily facilitates a wide range of content creation tasks and video editing applications, including image-to-video, video inpainting, and stylized generation.",
        "comments": "Webpage: https://lumiere-video.github.io/ | Video: https://www.youtube.com/watch?v=wxLr02Dz2Sc",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12945"
    },
    {
        "doc_id": 19,
        "title": "Nonlinear dynamics in neuromorphic photonic networks: physical simulation in Verilog-A",
        "authors": [
            "Hugh Morison",
            "Jagmeet Singh",
            "Nayem Al Kayed",
            "A. Aadhi",
            "Maryam Moridsadat",
            "Marcus Tamura",
            "Alexander N. Tait",
            "Bhavin J. Shastri"
        ],
        "subjects": [
            "Emerging Technologies",
            "Applied Physics",
            "Optics"
        ],
        "abstract": "Advances in silicon photonics technology have enabled the field of neuromorphic photonics, where analog neuron-like processing elements are implemented in silicon photonics technology. Accurate and scalable simulation tools for photonic integrated circuits are critical for designing neuromorphic photonic circuits. This is especially important when designing networks with recurrent connections, where the dynamics of the system may give rise to unstable and oscillatory solutions which need to be accurately modelled. These tools must simultaneously simulate the analog electronics and the multi-channel (wavelength-division-multiplexed) photonics contained in a photonic neuron to accurately predict on-chip behaviour. In this paper, we utilize a Verilog-A model of the photonic neural network to investigate the dynamics of recurrent integrated circuits. We begin by reviewing the theory of continuous-time recurrent neural networks as dynamical systems and the relation of these dynamics to important physical features of photonic neurons such as cascadability. We then present the neural dynamics of systems of one and two neurons in the simulated Verilog-A circuit, which are compared to the expected dynamics of the abstract CTRNN model. Due to the presence of parasitic circuit elements in the Verilog-A simulation, it is seen that there is a topological equivalence, but not an exact isomorphism, between the theoretical model and the simulated model. The implications of these discrepancies for the design of neuromorphic photonic circuits are discussed. Our findings pave the way for the practical implementation of large-scale silicon photonic recurrent neural networks.",
        "comments": "17 pages, 9 figures. Submitted to Physical Review Applied",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12942"
    },
    {
        "doc_id": 20,
        "title": "Multicultural Name Recognition For Previously Unseen Names",
        "authors": [
            "Alexandra Loessberg-Zahl"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "State of the art Named Entity Recognition (NER) models have achieved an impressive ability to extract common phrases from text that belong to labels such as location, organization, time, and person. However, typical NER systems that rely on having seen a specific entity in their training data in order to label an entity perform poorly on rare or unseen entities ta in order to label an entity perform poorly on rare or unseen entities (Derczynski et al., 2017). This paper attempts to improve recognition of person names, a diverse category that can grow any time someone is born or changes their name. In order for downstream tasks to not exhibit bias based on cultural background, a model should perform well on names from a variety of backgrounds. In this paper I experiment with the training data and input structure of an English Bi-LSTM name recognition model. I look at names from 103 countries to compare how well the model performs on names from different cultures, specifically in the context of a downstream task where extracted names will be matched to information on file. I find that a model with combined character and word input outperforms word-only models and may improve on accuracy compared to classical NER models that are not geared toward identifying unseen entity values.",
        "comments": "11 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12941"
    },
    {
        "doc_id": 21,
        "title": "Neural deformation fields for template-based reconstruction of cortical surfaces from MRI",
        "authors": [
            "Fabian Bongratz",
            "Anne-Marie Rickmann",
            "Christian Wachinger"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The reconstruction of cortical surfaces is a prerequisite for quantitative analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing segmentation-based methods separate the surface registration from the surface extraction, which is computationally inefficient and prone to distortions. We introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that learns a deformation field from a brain template to the cortical surfaces of an MRI scan. To this end, we present a geometric neural network that models the deformation-describing ordinary differential equation in a continuous manner. The network architecture comprises convolutional and graph-convolutional layers, which allows it to work with images and meshes at the same time. V2C-Flow is not only very fast, requiring less than two seconds to infer all four cortical surfaces, but also establishes vertex-wise correspondences to the template during reconstruction. In addition, V2C-Flow is the first approach for cortex reconstruction that models white matter and pial surfaces jointly, therefore avoiding intersections between them. Our comprehensive experiments on internal and external test data demonstrate that V2C-Flow results in cortical surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that the established correspondences are more consistent than in FreeSurfer and that they can directly be utilized for cortex parcellation and group analyses of cortical thickness.",
        "comments": "To appear in Medical Image Analysis",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12938"
    },
    {
        "doc_id": 22,
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "authors": [
            "Angela Zhou"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "comments": "conference version accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12934"
    },
    {
        "doc_id": 23,
        "title": "Segmentation of tibiofemoral joint tissues from knee MRI using MtRA-Unet and incorporating shape information: Data from the Osteoarthritis Initiative",
        "authors": [
            "Akshay Daydar",
            "Alik Pramanick",
            "Arijit Sur",
            "Subramani Kanagaraj"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Knee Osteoarthritis (KOA) is the third most prevalent Musculoskeletal Disorder (MSD) after neck and back pain. To monitor such a severe MSD, a segmentation map of the femur, tibia and tibiofemoral cartilage is usually accessed using the automated segmentation algorithm from the Magnetic Resonance Imaging (MRI) of the knee. But, in recent works, such segmentation is conceivable only from the multistage framework thus creating data handling issues and needing continuous manual inference rendering it unable to make a quick and precise clinical diagnosis. In order to solve these issues, in this paper the Multi-Resolution Attentive-Unet (MtRA-Unet) is proposed to segment the femur, tibia and tibiofemoral cartilage automatically. The proposed work has included a novel Multi-Resolution Feature Fusion (MRFF) and Shape Reconstruction (SR) loss that focuses on multi-contextual information and structural anatomical details of the femur, tibia and tibiofemoral cartilage. Unlike previous approaches, the proposed work is a single-stage and end-to-end framework producing a Dice Similarity Coefficient (DSC) of 98.5% for the femur, 98.4% for the tibia, 89.1% for Femoral Cartilage (FC) and 86.1% for Tibial Cartilage (TC) for critical MRI slices that can be helpful to clinicians for KOA grading. The time to segment MRI volume (160 slices) per subject is 22 sec. which is one of the fastest among state-of-the-art. Moreover, comprehensive experimentation on the segmentation of FC and TC which is of utmost importance for morphology-based studies to check KOA progression reveals that the proposed method has produced an excellent result with binary segmentation",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12932"
    },
    {
        "doc_id": 24,
        "title": "pyAKI - An Open Source Solution to Automated KDIGO classification",
        "authors": [
            "Christian Porschen",
            "Jan Ernsting",
            "Paul Brauckmann",
            "Raphael Weiss",
            "Till W\u00fcrdemann",
            "Hendrik Booke",
            "Wida Amini",
            "Ludwig Maidowski",
            "Benjamin Risse",
            "Tim Hahn",
            "Thilo von Groote"
        ],
        "subjects": [
            "Machine Learning",
            "Software Engineering"
        ],
        "abstract": "Acute Kidney Injury (AKI) is a frequent complication in critically ill patients, affecting up to 50% of patients in the intensive care units. The lack of standardized and open-source tools for applying the Kidney Disease Improving Global Outcomes (KDIGO) criteria to time series data has a negative impact on workload and study quality. This project introduces pyAKI, an open-source pipeline addressing this gap by providing a comprehensive solution for consistent KDIGO criteria implementation.\n  The pyAKI pipeline was developed and validated using a subset of the Medical Information Mart for Intensive Care (MIMIC)-IV database, a commonly used database in critical care research. We defined a standardized data model in order to ensure reproducibility. Validation against expert annotations demonstrated pyAKI's robust performance in implementing KDIGO criteria. Comparative analysis revealed its ability to surpass the quality of human labels.\n  This work introduces pyAKI as an open-source solution for implementing the KDIGO criteria for AKI diagnosis using time series data with high accuracy and performance.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12930"
    },
    {
        "doc_id": 25,
        "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
        "authors": [
            "Logan Engstrom",
            "Axel Feldmann",
            "Aleksander Madry"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with \"high quality\" data sources may not increase (and can even hurt) performance compared to randomly selecting data.\n  To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2x compute multiplier over baseline methods.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12926"
    },
    {
        "doc_id": 26,
        "title": "Emotion-Aware Contrastive Adaptation Network for Source-Free Cross-Corpus Speech Emotion Recognition",
        "authors": [
            "Yan Zhao",
            "Jincen Wang",
            "Cheng Lu",
            "Sunan Li",
            "Bj\u00f6rn Schuller",
            "Yuan Zong",
            "Wenming Zheng"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Cross-corpus speech emotion recognition (SER) aims to transfer emotional knowledge from a labeled source corpus to an unlabeled corpus. However, prior methods require access to source data during adaptation, which is unattainable in real-life scenarios due to data privacy protection concerns. This paper tackles a more practical task, namely source-free cross-corpus SER, where a pre-trained source model is adapted to the target domain without access to source data. To address the problem, we propose a novel method called emotion-aware contrastive adaptation network (ECAN). The core idea is to capture local neighborhood information between samples while considering the global class-level adaptation. Specifically, we propose a nearest neighbor contrastive learning to promote local emotion consistency among features of highly similar samples. Furthermore, relying solely on nearest neighborhoods may lead to ambiguous boundaries between clusters. Thus, we incorporate supervised contrastive learning to encourage greater separation between clusters representing different emotions, thereby facilitating improved class-level adaptation. Extensive experiments indicate that our proposed ECAN significantly outperforms state-of-the-art methods under the source-free cross-corpus SER setting on several speech emotion corpora.",
        "comments": "Accepted by ICASSP 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12925"
    },
    {
        "doc_id": 27,
        "title": "Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection",
        "authors": [
            "Ankan Kar",
            "Nirjhar Nath",
            "Utpalraj Kemprai",
            "Aman"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection systems, enabling prompt responses and improving disaster management. Moreover, the correlation between SVM accuracy and the difficulties presented by high-dimensional datasets is carefully investigated, demonstrated through a revealing case study. The relationship between accuracy scores and the different resolutions used for resizing the training datasets has also been discussed in this article. These comprehensive studies result in a definitive overview of the difficulties faced and the potential sectors requiring further improvement and focus.",
        "comments": "19 pages, 8 figures, accepted in IJCNS of SCIRP (not yet published)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12924"
    },
    {
        "doc_id": 28,
        "title": "Deep multitask neural networks for solving some stochastic optimal control problems",
        "authors": [
            "Christian Yeo"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.",
        "comments": "8 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12923"
    },
    {
        "doc_id": 29,
        "title": "Truck Parking Usage Prediction with Decomposed Graph Neural Networks",
        "authors": [
            "Rei Tamaru",
            "Yang Cheng",
            "Steven Parker",
            "Ernie Perry",
            "Bin Ran",
            "Soyoung Ahn"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Truck parking on freight corridors faces various challenges, such as insufficient parking spaces and compliance with Hour-of-Service (HOS) regulations. These constraints often result in unauthorized parking practices, causing safety concerns. To enhance the safety of freight operations, providing accurate parking usage prediction proves to be a cost-effective solution. Despite the existing research demonstrating satisfactory accuracy for predicting individual truck parking site usage, few approaches have been proposed for predicting usage with spatial dependencies of multiple truck parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN) as a predictive framework for assessing parking usage across the entire state to provide better truck parking information and mitigate unauthorized parking. The framework leverages the topological structures of truck parking site distributions and historical parking data to predict occupancy rates across a state. To achieve this, we introduce a Regional Decomposition approach, which effectively captures the geographical characteristics. We also introduce the spatial module working efficiently with the temporal module. Evaluation results demonstrate that the proposed model surpasses other baseline models, improving the performance by more than $20\\%$ compared with the original model. The proposed model allows truck parking sites' percipience of the topological structures and provides higher performance.",
        "comments": "10 pages, 5 figures, 3 tables, Manuscript for IEEE Transactions on Intelligent Transportation Systems",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12920"
    },
    {
        "doc_id": 30,
        "title": "Active Inference as a Model of Agency",
        "authors": [
            "Lancelot Da Costa",
            "Samuel Tenka",
            "Dominic Zhao",
            "Noor Sajid"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \\emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \\emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an explainable mixture of exploration and exploitation under a generative world model, and all differences in behaviour are explicit in differences in world model. \\emph{c}) This framework is universal in the sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of active inference as an active inference algorithm. Thus, active inference can be used as a tool to uncover and compare the commitments and assumptions of more specific models of agency.",
        "comments": "Accepted in RLDM2022 for the workshop 'RL as a model of agency'",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12917"
    },
    {
        "doc_id": 31,
        "title": "Red Teaming Visual Language Models",
        "authors": [
            "Mukai Li",
            "Lei Li",
            "Yuwei Yin",
            "Masood Ahmed",
            "Zhenguang Liu",
            "Qi Liu"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language Models) to accept multimodal inputs. Since it has been verified that LLMs can be induced to generate harmful or inaccurate content through specific test cases (termed as Red Teaming), how VLMs perform in similar scenarios, especially with their combination of textual and visual inputs, remains a question. To explore this problem, we present a novel red teaming dataset RTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal jail-breaking, face fairness, etc) under 4 primary aspects (faithfulness, privacy, safety, fairness). Our RTVLM is the first red-teaming dataset to benchmark current VLMs in terms of these 4 different aspects. Detailed analysis shows that 10 prominent open-sourced VLMs struggle with the red teaming in different degrees and have up to 31% performance gap with GPT-4V. Additionally, we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning (SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM test set, 13% in MM-Hal, and without noticeable decline in MM-Bench, overpassing other LLaVA-based models with regular alignment data. This reveals that current open-sourced VLMs still lack red teaming alignment. Our code and datasets will be open-source.",
        "comments": "Working in progress",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12915"
    },
    {
        "doc_id": 32,
        "title": "Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things",
        "authors": [
            "Salwa Mostafa",
            "Mateus P. Mota",
            "Alvaro Valcarce",
            "Mehdi Bennis"
        ],
        "subjects": [
            "Information Theory",
            "Artificial Intelligence",
            "Multiagent Systems"
        ],
        "abstract": "In this paper, we leverage a multi-agent reinforcement learning (MARL) framework to jointly learn a computation offloading decision and multichannel access policy with corresponding signaling. Specifically, the base station and industrial Internet of Things mobile devices are reinforcement learning agents that need to cooperate to execute their computation tasks within a deadline constraint. We adopt an emergent communication protocol learning framework to solve this problem. The numerical results illustrate the effectiveness of emergent communication in improving the channel access success rate and the number of successfully computed tasks compared to contention-based, contention-free, and no-communication approaches. Moreover, the proposed task offloading policy outperforms remote and local computation baselines.",
        "comments": "Journal ref:        GLOBECOM 2023",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12914"
    },
    {
        "doc_id": 33,
        "title": "Facing the Elephant in the Room: Visual Prompt Tuning or Full Finetuning?",
        "authors": [
            "Cheng Han",
            "Qifan Wang",
            "Yiming Cui",
            "Wenguan Wang",
            "Lifu Huang",
            "Siyuan Qi",
            "Dongfang Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "As the scale of vision models continues to grow, the emergence of Visual Prompt Tuning (VPT) as a parameter-efficient transfer learning technique has gained attention due to its superior performance compared to traditional full-finetuning. However, the conditions favoring VPT (the ``when\") and the underlying rationale (the ``why\") remain unclear. In this paper, we conduct a comprehensive analysis across 19 distinct datasets and tasks. To understand the ``when\" aspect, we identify the scenarios where VPT proves favorable by two dimensions: task objectives and data distributions. We find that VPT is preferrable when there is 1) a substantial disparity between the original and the downstream task objectives (e.g., transitioning from classification to counting), or 2) a similarity in data distributions between the two tasks (e.g., both involve natural images). In exploring the ``why\" dimension, our results indicate VPT's success cannot be attributed solely to overfitting and optimization considerations. The unique way VPT preserves original features and adds parameters appears to be a pivotal factor. Our study provides insights into VPT's mechanisms, and offers guidance for its optimal utilization.",
        "comments": "29 pages, 19 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12902"
    },
    {
        "doc_id": 34,
        "title": "Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network",
        "authors": [
            "Steven Rivetti",
            "Emil Bjornson",
            "Mikael Skoglund"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "In this paper, we study a cell-free multiple-input multiple-output network equipped with integrated sensing and communication (ISAC) access points (APs). The distributed APs are used to jointly serve the communication needs of user equipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve). To increase the system's robustness towards said Eve, we develop an ISAC waveform model that includes artificial noise (AN) aimed at degrading the Eve channel quality. The central processing unit receives the observations from each AP and calculates the optimal precoding and AN covariance matrices by solving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB) minimization problem. Simulation results highlight an underlying trade-off between sensing and communication performances: in particular, the UEs signal-to-noise and interference ratio and the maximum Eve's signal to noise ratio are directly proportional to the CRB. Furthermore, the optimal AN covariance matrix is rank-1 and has a peak in the eve's direction, leading to a surprising inverse-proportionality between the UEs-Eve distance and optimal-CRB magnitude.",
        "comments": "To appear at WCNC 2024. \\c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12901"
    },
    {
        "doc_id": 35,
        "title": "PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Creation with 3D Gaussian Splatting",
        "authors": [
            "Zhongyuan Zhao",
            "Zhenyu Bao",
            "Qing Li",
            "Guoping Qiu",
            "Kanglin Liu"
        ],
        "subjects": [
            "Graphics",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Despite much progress, creating real-time high-fidelity head avatar is still difficult and existing methods have to trade-off between speed and quality. 3DMM based methods often fail to model non-facial structures such as eyeglasses and hairstyles, while neural implicit models suffer from deformation inflexibility and rendering inefficiency.\n  Although 3D Gaussian has been demonstrated to possess promising capability for geometry representation and radiance field reconstruction, applying 3D Gaussian in head avatar creation remains a major challenge since it is difficult for 3D Gaussian to model the head shape variations caused by changing poses and expressions. In this paper, we introduce PSAvatar, a novel framework for animatable head avatar creation that utilizes discrete geometric primitive to create a parametric morphable shape model and employs 3D Gaussian for fine detail representation and high fidelity rendering. The parametric morphable shape model is a Point-based Morphable Shape Model (PMSM) which uses points instead of meshes for 3D representation to achieve enhanced representation flexibility. The PMSM first converts the FLAME mesh to points by sampling on the surfaces as well as off the meshes to enable the reconstruction of not only surface-like structures but also complex geometries such as eyeglasses and hairstyles. By aligning these points with the head shape in an analysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussian for fine detail representation and appearance modeling, thus enabling the creation of high-fidelity avatars. We show that PSAvatar can reconstruct high-fidelity head avatars of a variety of subjects and the avatars can be animated in real-time ($\\ge$ 25 fps at a resolution of 512 x 512 )",
        "comments": "13 pages, 10 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12900"
    },
    {
        "doc_id": 36,
        "title": "Anomalous Behavior in the Nucleation of Ice at Negative Pressures",
        "authors": [
            "Valentino Bianco",
            "Pablo Montero de Hijes",
            "Cintia P. Lamas",
            "Eduardo Sanz",
            "Carlos Vega"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Ice nucleation is a phenomenon that, despite the relevant implications for life, atmospheric sciences, and technological applications, is far from being completely understood, especially under extreme thermodynamic conditions. In this work we present a computational investigation of the homogeneous ice nucleation at negative pressures. By means of the seeding technique we estimate the size of the ice critical nucleus Nc for the TIP4P/Ice water model. This is done along the isotherms 230, 240, and 250 K, from positive to negative pressures until reaching the liquid-gas kinetic stability limit (where cavitation cannot be avoided). We find that Nc is nonmonotonic upon depressurization, reaching a minimum at negative pressures in the doubly metastable region of water. According to classical nucleation theory we establish the nucleation rate J and the surface tension gamma, revealing a retracing behavior of both when the liquid-gas kinetic stability limit is approached. We also predict a reentrant behavior of the homogeneous nucleation line. The reentrance of these properties is related to the reentrance of the coexistence line at negative pressure, revealing new anomalies of water. The results of this work suggest the possibility of having metastable samples of liquid water for long times at negative pressure provided that heterogeneous nucleation is suppressed.",
        "comments": "Journal ref:        Physical Review Letters 126, 015704 (2021)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12896"
    },
    {
        "doc_id": 37,
        "title": "ESC: Edge-attributed Skyline Community Search in Large-scale Bipartite Graphs",
        "authors": [
            "Fangda Guo",
            "Xuanpu Luo",
            "Yanghao Liu",
            "Guoxin Chen",
            "Yongqing Wang",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "subjects": [
            "Social and Information Networks",
            "Graphics"
        ],
        "abstract": "Due to the ability of modeling relationships between two different types of entities, bipartite graphs are naturally employed in many real-world applications. Community Search in bipartite graphs is a fundamental problem and has gained much attention. However, existing studies focus on measuring the structural cohesiveness between two sets of vertices, while either completely ignoring the edge attributes or only considering one-dimensional importance in forming communities. In this paper, we introduce a novel community model, named edge-attributed skyline community (ESC), which not only preserves the structural cohesiveness but unravels the inherent dominance brought about by multi-dimensional attributes on the edges of bipartite graphs. To search the ESCs, we develop an elegant peeling algorithm by iteratively deleting edges with the minimum attribute in each dimension. In addition, we also devise a more efficient expanding algorithm to further reduce the search space and speed up the filtering of unpromising vertices, where a upper bound is proposed and proven. Extensive experiments on real-world large-scale datasets demonstrate the efficiency, effectiveness, and scalability of the proposed ESC search algorithms. A case study was conducted to compare with existing community models, substantiating that our approach facilitates the precision and diversity of results.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12895"
    },
    {
        "doc_id": 38,
        "title": "Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies",
        "authors": [
            "Lincan Li",
            "Wei Shao",
            "Wei Dong",
            "Yijun Tian",
            "Kaixiang Yang",
            "Wenjie Zhang"
        ],
        "subjects": [
            "Robotics",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The aspiration of the next generation's autonomous driving (AD) technology relies on the dedicated integration and interaction among intelligent perception, prediction, planning, and low-level control. There has been a huge bottleneck regarding the upper bound of autonomous driving algorithm performance, a consensus from academia and industry believes that the key to surmount the bottleneck lies in data-centric autonomous driving technology. Recent advancement in AD simulation, closed-loop model training, and AD big data engine have gained some valuable experience. However, there is a lack of systematic knowledge and deep understanding regarding how to build efficient data-centric AD technology for AD algorithm self-evolution and better AD big data accumulation. To fill in the identified research gaps, this article will closely focus on reviewing the state-of-the-art data-driven autonomous driving technologies, with an emphasis on the comprehensive taxonomy of autonomous driving datasets characterized by milestone generations, key features, data acquisition settings, etc. Furthermore, we provide a systematic review of the existing benchmark closed-loop AD big data pipelines from the industrial frontier, including the procedure of closed-loop frameworks, key technologies, and empirical studies. Finally, the future directions, potential applications, limitations and concerns are discussed to arouse efforts from both academia and industry for promoting the further development of autonomous driving.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12888"
    },
    {
        "doc_id": 39,
        "title": "Model-Free $\u03b4$-Policy Iteration Based on Damped Newton Method for Nonlinear Continuous-Time H$\\infty$ Tracking Control",
        "authors": [
            "Qi Wang"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "This paper presents a \u03b4-PI algorithm which is based on damped Newton method for the H{\\infty} tracking control problem of unknown continuous-time nonlinear system. A discounted performance function and an augmented system are used to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJI equation is a nonlinear partial differential equation, traditional reinforcement learning methods for solving the tracking HJI equation are mostly based on the Newton method, which usually only satisfies local convergence and needs a good initial guess. Based upon the damped Newton iteration operator equation, a generalized tracking Bellman equation is derived firstly. The \u03b4-PI algorithm can seek the optimal solution of the tracking HJI equation by iteratively solving the generalized tracking Bellman equation. On-policy learning and off-policy learning \u03b4-PI reinforcement learning methods are provided, respectively. Off-policy version \u03b4-PI algorithm is a model-free algorithm which can be performed without making use of a priori knowledge of the system dynamics. NN-based implementation scheme for the off-policy \u03b4-PI algorithms is shown. The suitability of the model-free \u03b4-PI algorithm is illustrated with a nonlinear system simulation.",
        "comments": "10 pages, 8 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12882"
    },
    {
        "doc_id": 40,
        "title": "Computing Diameter+2 in Truly Subquadratic Time for Unit-Disk Graphs",
        "authors": [
            "Hsien-Chih Chang",
            "Jie Gao",
            "Hung Le"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Computational Geometry"
        ],
        "abstract": "Finding the diameter of a graph in general cannot be done in truly subquadratic assuming the Strong Exponential Time Hypothesis (SETH), even when the underlying graph is unweighted and sparse. When restricting to concrete classes of graphs and assuming SETH, planar graphs and minor-free graphs admit truly subquadratic algorithms, while geometric intersection graphs of unit balls, congruent equilateral triangles, and unit segments do not. Unit-disk graphs are one of the major open cases where the complexity of diameter computation remains unknown. More generally, it is conjectured that a truly subquadratic time algorithm exists for pseudo-disk graphs.\n  In this paper, we show a truly subquadratic algorithm of running time $\\tilde{O}(n^{2-1/18})$, for finding the diameter in a unit-disk graph, whose output differs from the optimal solution by at most 2. This is the first algorithm that provides an additive guarantee in distortion, independent of the size or the diameter of the graph. Our algorithm requires two important technical elements. First, we show that for the intersection graph of pseudo-disks, the graph VC-dimension, either of $k$-hop balls or the distance encoding vectors, is 4. This contracts to the VC dimension of the pseudo-disks themselves as geometric ranges (which is known to be 3). Second, we introduce a clique-based $r$-clustering for geometric intersection graphs, which is an analog of the $r$-division construction for planar graphs. We also showcase the new techniques by establishing new results for distance oracles for unit-disk graphs with subquadratic storage and $O(1)$ query time. The results naturally extend to unit $L_1$ or $L_\\infty$-disks and fat pseudo-disks of similar size. Last, if the pseudo-disks additionally have bounded ply, we have a truly subquadratic algorithm to find the exact diameter.",
        "comments": "28 pages, 7 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12881"
    },
    {
        "doc_id": 41,
        "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
        "authors": [
            "Haoyan Luo",
            "Lucia Specia"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "This survey paper delves into the burgeoning field of explainability for Large Language Models (LLMs), a critical yet challenging aspect of natural language processing. With LLMs playing a pivotal role in various applications, their \"black-box\" nature raises concerns about transparency and ethical use. This paper emphasizes the necessity for enhanced explainability in LLMs, addressing both the general public's trust and the technical community's need for a deeper understanding of these models. We concentrate on pre-trained Transformer-based LLMs, such as LLaMA, which present unique interpretability challenges due to their scale and complexity. Our review categorizes existing explainability methods and discusses their application in improving model transparency and reliability. We also discuss representative evaluation methods, highlighting their strengths and limitations. The goal of this survey is to bridge the gap between theoretical understanding and practical application, offering insights for future research and development in the field of LLM explainability.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12874"
    },
    {
        "doc_id": 42,
        "title": "Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model",
        "authors": [
            "Zhiwei He",
            "Xing Wang",
            "Wenxiang Jiao",
            "Zhuosheng Zhang",
            "Rui Wang",
            "Shuming Shi",
            "Zhaopeng Tu"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model (the QE-based reward model) to predict human preferences for feedback training. We first identify the overoptimization problem during QE-based feedback training, manifested as an increase in reward while translation quality declines. We examine the problem and argue that the vulnerability of the QE model might lead to high rewards for incorrect translations, resulting in overoptimization and error propagation. To address the problem, we adopt a simple yet effective method that uses heuristic rules to detect the incorrect translations and assigns a penalty term to the QE-based rewards for the detected incorrect translations. Experimental results show that the proposed QE-based feedback training achieves consistent and significant improvements across various settings, further verified through human preference studies. Our subsequent analysis demonstrates the high data efficiency of the proposed QE-based feedback training: the proposed approach using a small amount of monolingual data can outperform systems using larger parallel corpora.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12873"
    },
    {
        "doc_id": 43,
        "title": "FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging Active Visual Depth Manipulation",
        "authors": [
            "Chenyang Zhang",
            "Tiansu Chen",
            "Eric Shaffer",
            "Elahe Soltanaghai"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "Gaze interaction presents a promising avenue in Virtual Reality (VR) due to its intuitive and efficient user experience. Yet, the depth control inherent in our visual system remains underutilized in current methods. In this study, we introduce FocusFlow, a hands-free interaction method that capitalizes on human visual depth perception within the 3D scenes of Virtual Reality. We first develop a binocular visual depth detection algorithm to understand eye input characteristics. We then propose a layer-based user interface and introduce the concept of 'Virtual Window' that offers an intuitive and robust gaze-depth VR interaction, despite the constraints of visual depth accuracy and precision spatially at further distances. Finally, to help novice users actively manipulate their visual depth, we propose two learning strategies that use different visual cues to help users master visual depth control. Our user studies on 24 participants demonstrate the usability of our proposed virtual window concept as a gaze-depth interaction method. In addition, our findings reveal that the user experience can be enhanced through an effective learning process with adaptive visual cues, helping users to develop muscle memory for this brand-new input mechanism. We conclude the paper by discussing strategies to optimize learning and potential research topics of gaze-depth interaction.",
        "comments": "ACM CHI 2024 Paper",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12872"
    },
    {
        "doc_id": 44,
        "title": "Unlocking the Potential: Multi-task Deep Learning for Spaceborne Quantitative Monitoring of Fugitive Methane Plumes",
        "authors": [
            "Guoxin Si",
            "Shiliang Fu",
            "Wei Yao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "With the intensification of global warming, the monitoring of methane emission and detection of gas plumes from landfills have increasingly received attention. We decompose methane emission monitoring into three sub-tasks: methane concentration inversion, plume segmentation, and emission rate estimation. Conventional algorithms have limitations: methane concentration inversion usually uses the matched filter, which is sensitive to global spectrum distribution and contains a large amount of noises. There is limited research on plume segmentation, with many studies resorting to manual segmentation that is likely to be subjective. The estimation of methane emission rate often utilizes IME algorithm, which relies on obtaining meteorological measurement data. Using the WENT landfill site in Hong Kong and PRISMA hyperspectral satellite imagery, we propose a new deep learning-based framework for quantitative monitoring of methane emissions from remote sensing images based on physical simulation. We generate simulated methane plumes using large eddy simulation (LES) and different concentration maps of fugitive emission using the radiative transfer equation (RTE), while combining augmentation techniques to create a simulated PRISMA dataset. We train a U-Net network for methane concentration inversion, a Mask R-CNN network for methane plume segmentation, and a ResNet-50 network for methane emission rate estimation. All three deep networks achieve higher validation accuracy compared to conventional algorithms. We further respectively combine the first two sub-tasks and the last two sub-tasks to design the multi-task learning models - MTL-01 and MTL-02, both of which achieve higher accuracy than single-task models. Our research serves as a demonstration of applying multi-task deep learning to quantitative methane monitoring and can be extended to a broad range of methane monitoring tasks.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12870"
    },
    {
        "doc_id": 45,
        "title": "TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks",
        "authors": [
            "Zhiruo Wang",
            "Daniel Fried",
            "Graham Neubig"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Language models (LMs) can solve tasks such as answering questions about tables or images by writing programs. However, using primitive functions often leads to verbose and error-prone programs, and higher-level functions require expert design. To enable better solutions without human labor, we ask code LMs to curate reusable high-level functions, and use them to write solutions. We present TROVE, a training-free method of inducing a verifiable and efficient toolbox of functions, by generating via using, growing, and periodically trimming the toolbox. On 11 datasets from math, table question answering, and image reasoning tasks, TROVE consistently yields simpler solutions with higher accuracy than baselines using CODELLAMA and previous methods using GPT, while using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more accurate human verification than baselines. With the same pipeline, it creates diverse functions for varied tasks and datasets, providing insights into their individual characteristics.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12869"
    },
    {
        "doc_id": 46,
        "title": "Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing",
        "authors": [
            "Ralf Bruns",
            "Jeremias D\u00f6tterl",
            "J\u00fcrgen Dunkel",
            "Sascha Ossowski"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Multiagent Systems"
        ],
        "abstract": "Mobile crowdsourcing refers to systems where the completion of tasks necessarily requires physical movement of crowdworkers in an on-demand workforce. Evidence suggests that in such systems, tasks often get assigned to crowdworkers who struggle to complete those tasks successfully, resulting in high failure rates and low service quality. A promising solution to ensure higher quality of service is to continuously adapt the assignment and respond to failure-causing events by transferring tasks to better-suited workers who use different routes or vehicles. However, implementing task transfers in mobile crowdsourcing is difficult because workers are autonomous and may reject transfer requests. Moreover, task outcomes are uncertain and need to be predicted. In this paper, we propose different mechanisms to achieve outcome prediction and task coordination in mobile crowdsourcing. First, we analyze different data stream learning approaches for the prediction of task outcomes. Second, based on the suggested prediction model, we propose and evaluate two different approaches for task coordination with different degrees of autonomy: an opportunistic approach for crowdshipping with collaborative, but non-autonomous workers, and a market-based model with autonomous workers for crowdsensing.",
        "comments": "Journal ref:        Sensors 2023, 23(2), 614",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12866"
    },
    {
        "doc_id": 47,
        "title": "KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning",
        "authors": [
            "Debjyoti Mondal",
            "Suraj Modi",
            "Subhadarshi Panda",
            "Rituraj Singh",
            "Godawari Sudhakar Rao"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in natural language processing tasks by leveraging chain of thought (CoT) that enables step-by-step thinking. Extending LLMs with multimodal capabilities is the recent interest, but incurs computational cost and requires substantial hardware resources. To address these challenges, we propose KAM-CoT a framework that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a two-stage training process with KG grounding to generate effective rationales and answers. By incorporating external knowledge from KGs during reasoning, the model gains a deeper contextual understanding reducing hallucinations and enhancing the quality of answers. This knowledge-augmented CoT reasoning empowers the model to handle questions requiring external context, providing more informed answers. Experimental findings show KAM-CoT outperforms the state-of-the-art methods. On the ScienceQA dataset, we achieve an average accuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by 10%. Remarkably, KAM-CoT achieves these results with only 280M trainable parameters at a time, demonstrating its cost-efficiency and effectiveness.",
        "comments": "AAAI 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12863"
    },
    {
        "doc_id": 48,
        "title": "FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units",
        "authors": [
            "Shaoheng Fang",
            "Rui Ye",
            "Wenhao Wang",
            "Zuhong Liu",
            "Yuxiao Wang",
            "Yafei Wang",
            "Siheng Chen",
            "Yanfeng Wang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Roadside unit (RSU) can significantly improve the safety and robustness of autonomous vehicles through Vehicle-to-Everything (V2X) communication. Currently, the usage of a single RSU mainly focuses on real-time inference and V2X collaboration, while neglecting the potential value of the high-quality data collected by RSU sensors. Integrating the vast amounts of data from numerous RSUs can provide a rich source of data for model training. However, the absence of ground truth annotations and the difficulty of transmitting enormous volumes of data are two inevitable barriers to fully exploiting this hidden value. In this paper, we introduce FedRSU, an innovative federated learning framework for self-supervised scene flow estimation. In FedRSU, we present a recurrent self-supervision training paradigm, where for each RSU, the scene flow prediction of points at every timestamp can be supervised by its subsequent future multi-modality observation. Another key component of FedRSU is federated learning, where multiple devices collaboratively train an ML model while keeping the training data local and private. With the power of the recurrent self-supervised learning paradigm, FL is able to leverage innumerable underutilized data from RSU. To verify the FedRSU framework, we construct a large-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSU clients, covering various scenarios, modalities, and sensor settings. Based on RSU-SF, we show that FedRSU can greatly improve model performance in ITS and provide a comprehensive benchmark under diverse FL scenarios. To the best of our knowledge, we provide the first real-world LiDAR-camera multi-modal dataset and benchmark for the FL community.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12862"
    },
    {
        "doc_id": 49,
        "title": "Secure Communication with Unreliable Entanglement Assistance",
        "authors": [
            "Meir Lederman",
            "Uzi Pereg"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory"
        ],
        "abstract": "Secure communication is considered with unreliable entanglement assistance, where the adversary may intercept the legitimate receiver's entanglement resource before communication takes place. The communication setting of unreliable assistance, without security aspects, was originally motivated by the extreme photon loss in practical communication systems. The operational principle is to adapt the transmission rate to the availability of entanglement assistance, without resorting to feedback and repetition. Here, we require secrecy as well. An achievable secrecy rate region is derived for general quantum wiretap channels, and a multi-letter secrecy capacity formula for the special class of degraded channels.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12861"
    },
    {
        "doc_id": 50,
        "title": "Simultaneous exercise recognition and evaluation in prescribed routines: Approach to virtual coaches",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Signal Processing"
        ],
        "abstract": "Home-based physical therapies are effective if the prescribed exercises are correctly executed and patients adhere to these routines. This is specially important for older adults who can easily forget the guidelines from therapists. Inertial Measurement Units (IMUs) are commonly used for tracking exercise execution giving information of patients' motion data. In this work, we propose the use of Machine Learning techniques to recognize which exercise is being carried out and to assess if the recognized exercise is properly executed by using data from four IMUs placed on the person limbs. To the best of our knowledge, both tasks have never been addressed together as a unique complex task before. However, their combination is needed for the complete characterization of the performance of physical therapies. We evaluate the performance of six machine learning classifiers in three contexts: recognition and evaluation in a single classifier, recognition of correct exercises, excluding the wrongly performed exercises, and a two-stage approach that first recognizes the exercise and then evaluates it. We apply our proposal to a set of 8 exercises of the upper-and lower-limbs designed for maintaining elderly people health status. To do so, the motion of volunteers were monitored with 4 IMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initial scenarios. In the third one, the recognition provides an accuracy of 96.2 \\%, whereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This work proves the feasibility of IMUs for a complete monitoring of physical therapies in which we can get information of which exercise is being performed and its quality, as a basis for designing virtual coaches.",
        "comments": "ACM Class:          I.2.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12857"
    },
    {
        "doc_id": 51,
        "title": "Hyper-Realist Rendering: A Theoretical Framework",
        "authors": [
            "Ergun Akleman",
            "Murat Kurt",
            "Derya Akleman",
            "Gary Bruins",
            "Sitong Deng",
            "Meena Subramanian"
        ],
        "subjects": [
            "Graphics"
        ],
        "abstract": "This is the first paper in a series on hyper-realist rendering. In this paper, we introduce the concept of hyper-realist rendering and present a theoretical framework to obtain hyper-realist images. We are using the term Hyper-realism as an umbrella word that captures all types of visual artifacts that can evoke an impression of reality. The hyper-realist artifacts are visual representations that are not necessarily created by following logical and physical principles and can still be perceived as representations of reality. This idea stems from the principles of representational arts, which attain visually acceptable renderings of scenes without implementing strict physical laws of optics and materials. The objective of this work is to demonstrate that it is possible to obtain visually acceptable illusions of reality by employing such artistic approaches. With representational art methods, we can even obtain an alternate illusion of reality that looks more real even when it is not real. This paper demonstrates that it is common to create illusions of reality in visual arts with examples of paintings by representational artists. We propose an approach to obtain expressive local and global illuminations to obtain these stylistic illusions with a set of well-defined and formal methods.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12853"
    },
    {
        "doc_id": 52,
        "title": "Control-Aware Trajectory Predictions for Communication-Efficient Drone Swarm Coordination in Cluttered Environments",
        "authors": [
            "Longhao Yan",
            "Jingyuan Zhou",
            "Kaidi Yang"
        ],
        "subjects": [
            "Robotics"
        ],
        "abstract": "Swarms of Unmanned Aerial Vehicles (UAV) have demonstrated enormous potential in many industrial and commercial applications. However, before deploying UAVs in the real world, it is essential to ensure they can operate safely in complex environments, especially with limited communication capabilities. To address this challenge, we propose a control-aware learning-based trajectory prediction algorithm that can enable communication-efficient UAV swarm control in a cluttered environment. Specifically, our proposed algorithm can enable each UAV to predict the planned trajectories of its neighbors in scenarios with various levels of communication capabilities. The predicted planned trajectories will serve as input to a distributed model predictive control (DMPC) approach. The proposed algorithm combines (1) a trajectory compression and reconstruction model based on Variational Auto-Encoder, (2) a trajectory prediction model based on EvolveGCN, a graph convolutional network (GCN) that can handle dynamic graphs, and (3) a KKT-informed training approach that applies the Karush-Kuhn-Tucker (KKT) conditions in the training process to encode DMPC information into the trained neural network. We evaluate our proposed algorithm in a funnel-like environment. Results show that the proposed algorithm outperforms state-of-the-art benchmarks, providing close-to-optimal control performance and robustness to limited communication capabilities and measurement noises.",
        "comments": "15 pages, 15 figures, submitted to IEEE Transactions on Intelligent Vehicles",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12852"
    },
    {
        "doc_id": 53,
        "title": "Classification of grapevine varieties using UAV hyperspectral imaging",
        "authors": [
            "Alfonso L\u00f3pez",
            "Carlos Javier Ogayar",
            "Francisco Ram\u00f3n Feito",
            "Joaquim Jo\u00e3o Sousa"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The classification of different grapevine varieties is a relevant phenotyping task in Precision Viticulture since it enables estimating the growth of vineyard rows dedicated to different varieties, among other applications concerning the wine industry. This task can be performed with destructive methods that require time-consuming tasks, including data collection and analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a more efficient and less prohibitive approach to collecting hyperspectral data, despite acquiring noisier data. Therefore, the first task is the processing of these data to correct and downsample large amounts of data. In addition, the hyperspectral signatures of grape varieties are very similar. In this work, a Convolutional Neural Network (CNN) is proposed for classifying seventeen varieties of red and white grape variants. Rather than classifying single samples, these are processed together with their neighbourhood. Hence, the extraction of spatial and spectral features is addressed with 1) a spatial attention layer and 2) Inception blocks. The pipeline goes from processing to dataset elaboration, finishing with the training phase. The fitted model is evaluated in terms of response time, accuracy and data separability, and compared with other state-of-the-art CNNs for classifying hyperspectral data. Our network was proven to be much more lightweight with a reduced number of input bands, a lower number of trainable weights and therefore, reduced training time. Despite this, the evaluated metrics showed much better results for our network (~99% overall accuracy), in comparison with previous works barely achieving 81% OA.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12851"
    },
    {
        "doc_id": 54,
        "title": "Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization",
        "authors": [
            "Prachi Singh",
            "Sriram Ganapathy"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Artificial Intelligence",
            "Sound"
        ],
        "abstract": "Speaker diarization, the task of segmenting an audio recording based on speaker identity, constitutes an important speech pre-processing step for several downstream applications. The conventional approach to diarization involves multiple steps of embedding extraction and clustering, which are often optimized in an isolated fashion. While end-to-end diarization systems attempt to learn a single model for the task, they are often cumbersome to train and require large supervised datasets. In this paper, we propose an end-to-end supervised hierarchical clustering algorithm based on graph neural networks (GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The E-SHARC approach uses front-end mel-filterbank features as input and jointly learns an embedding extractor and the GNN clustering module, performing representation learning, metric learning, and clustering with end-to-end optimization. Further, with additional inputs from an external overlap detector, the E-SHARC approach is capable of predicting the speakers in the overlapping speech regions. The experimental evaluation on several benchmark datasets like AMI, VoxConverse and DISPLACE, illustrates that the proposed E-SHARC framework improves significantly over the state-of-art diarization systems.",
        "comments": "10 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12850"
    },
    {
        "doc_id": 55,
        "title": "Learning safety critics via a non-contractive binary bellman operator",
        "authors": [
            "Agustin Castellano",
            "Hancheng Min",
            "Juan Andr\u00e9s Bazerque",
            "Enrique Mallada"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "The inability to naturally enforce safety in Reinforcement Learning (RL), with limited failures, is a core challenge impeding its use in real-world applications. One notion of safety of vast practical relevance is the ability to avoid (unsafe) regions of the state space. Though such a safety goal can be captured by an action-value-like function, a.k.a. safety critics, the associated operator lacks the desired contraction and uniqueness properties that the classical Bellman operator enjoys. In this work, we overcome the non-contractiveness of safety critic operators by leveraging that safety is a binary property. To that end, we study the properties of the binary safety critic associated with a deterministic dynamical system that seeks to avoid reaching an unsafe region. We formulate the corresponding binary Bellman equation (B2E) for safety and study its properties. While the resulting operator is still non-contractive, we fully characterize its fixed points representing--except for a spurious solution--maximal persistently safe regions of the state space that can always avoid failure. We provide an algorithm that, by design, leverages axiomatic knowledge of safe data to avoid spurious fixed points.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12849"
    },
    {
        "doc_id": 56,
        "title": "Optimal Evasion from a Sensing-Limited Pursuer",
        "authors": [
            "Dipankar Maity",
            "Alexander Von Moll",
            "Daigo Shishika",
            "Michael Dorothy"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Systems and Control"
        ],
        "abstract": "This paper investigates a partial-information pursuit evasion game in which the Pursuer has a limited-range sensor to detect the Evader. Given a fixed final time, we derive the optimal evasion strategy for the Evader to maximize its distance from the pursuer at the end. Our analysis reveals that in certain parametric regimes, the optimal Evasion strategy involves a 'risky' maneuver, where the Evader's trajectory comes extremely close to the pursuer's sensing boundary before moving behind the Pursuer. Additionally, we explore a special case in which the Pursuer can choose the final time. In this scenario, we determine a (Nash) equilibrium pair for both the final time and the evasion strategy.",
        "comments": "Accepted for presentation at, and publication in the proceedings of, the 2024 American Control Conference",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12848"
    },
    {
        "doc_id": 57,
        "title": "How well can large language models explain business processes?",
        "authors": [
            "Dirk Fahland",
            "Fabian Fournier",
            "Lior Limonad",
            "Inna Skarbovsky",
            "Ava J. E. Swevels"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Large Language Models (LLMs) are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system's functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for SAX is also accompanied by a certain degree of doubt related to its capacity to adequately fulfill SAX along with its tendency for hallucination and lack of inherent capacity to reason, we pursued a methodological evaluation of the quality of the generated explanations. To this aim, we developed a designated scale and conducted a rigorous user study. Our findings show that the input presented to the LLMs aided with the guard-railing of its performance, yielding SAX explanations having better-perceived fidelity. This improvement is moderated by the perception of trust and curiosity. More so, this improvement comes at the cost of the perceived interpretability of the explanation.",
        "comments": "39 pages, 12 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12846"
    },
    {
        "doc_id": 58,
        "title": "An embedding-based distance for temporal graphs",
        "authors": [
            "Lorenzo Dall'Amico",
            "Alain Barrat",
            "Ciro Cattuto"
        ],
        "subjects": [
            "Social and Information Networks",
            "Machine Learning"
        ],
        "abstract": "We define a distance between temporal graphs based on graph embeddings built using time-respecting random walks. We study both the case of matched graphs, when there exists a known relation between the nodes, and the unmatched case, when such a relation is unavailable and the graphs may be of different sizes. We illustrate the interest of our distance definition, using both real and synthetic temporal network data, by showing its ability to discriminate between graphs with different structural and temporal properties. Leveraging state-of-the-art machine learning techniques, we propose an efficient implementation of distance computation that is viable for large-scale temporal graphs.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12843"
    },
    {
        "doc_id": 59,
        "title": "Iterated Relevance Matrix Analysis (IRMA) for the identification of class-discriminative subspaces",
        "authors": [
            "Sofie L\u00f6vdal",
            "Michael Biehl"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "We introduce and investigate the iterated application of Generalized Matrix Learning Vector Quantizaton for the analysis of feature relevances in classification problems, as well as for the construction of class-discriminative subspaces. The suggested Iterated Relevance Matrix Analysis (IRMA) identifies a linear subspace representing the classification specific information of the considered data sets using Generalized Matrix Learning Vector Quantization (GMLVQ). By iteratively determining a new discriminative subspace while projecting out all previously identified ones, a combined subspace carrying all class-specific information can be found. This facilitates a detailed analysis of feature relevances, and enables improved low-dimensional representations and visualizations of labeled data sets. Additionally, the IRMA-based class-discriminative subspace can be used for dimensionality reduction and the training of robust classifiers with potentially improved performance.",
        "comments": "17 pages, 5 figures, 1 table. Submitted to Neurocomputing. Extension of 2023 ESANN conference contribution",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12842"
    },
    {
        "doc_id": 60,
        "title": "SGTR+: End-to-end Scene Graph Generation with Transformer",
        "authors": [
            "Rongjie Li",
            "Songyang Zhang",
            "Xuming He"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Scene Graph Generation (SGG) remains a challenging visual understanding task due to its compositional property. Most previous works adopt a bottom-up, two-stage or point-based, one-stage approach, which often suffers from high time complexity or suboptimal designs. In this work, we propose a novel SGG method to address the aforementioned issues, formulating the task as a bipartite graph construction problem. To address the issues above, we create a transformer-based end-to-end framework to generate the entity and entity-aware predicate proposal set, and infer directed edges to form relation triplets. Moreover, we design a graph assembling module to infer the connectivity of the bipartite scene graph based on our entity-aware structure, enabling us to generate the scene graph in an end-to-end manner. Based on bipartite graph assembling paradigm, we further propose a new technical design to address the efficacy of entity-aware modeling and optimization stability of graph assembling. Equipped with the enhanced entity-aware design, our method achieves optimal performance and time-complexity. Extensive experimental results show that our design is able to achieve the state-of-the-art or comparable performance on three challenging benchmarks, surpassing most of the existing approaches and enjoying higher efficiency in inference. Code is available: https://github.com/Scarecrow0/SGTR",
        "comments": "Accepted by TPAMI: https://ieeexplore.ieee.org/document/10315230",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12835"
    },
    {
        "doc_id": 61,
        "title": "Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data",
        "authors": [
            "Salih Salihoglu",
            "Gulser Koksal",
            "Orhan Abar"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "In the modern transportation industry, accurate prediction of travelers' next destinations brings multiple benefits to companies, such as customer satisfaction and targeted marketing. This study focuses on developing a precise model that captures the sequential patterns and dependencies in travel data, enabling accurate predictions of individual travelers' future destinations. To achieve this, a novel model architecture with a sliding window approach based on Long Short-Term Memory (LSTM) is proposed for destination prediction in the transportation industry. The experimental results highlight satisfactory performance and high scores achieved by the proposed model across different data sizes and performance metrics. This research contributes to advancing destination prediction methods, empowering companies to deliver personalized recommendations and optimize customer experiences in the dynamic travel landscape.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12830"
    },
    {
        "doc_id": 62,
        "title": "Digital Twin-Based Network Management for Better QoE in Multicast Short Video Streaming",
        "authors": [
            "Xinyu Huang",
            "Shisheng Hu",
            "Haojun Yang",
            "Xinghan Wang",
            "Yingying Pei",
            "Xuemin Shen"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Image and Video Processing"
        ],
        "abstract": "Multicast short video streaming can enhance bandwidth utilization by enabling simultaneous video transmission to multiple users over shared wireless channels. The existing network management schemes mainly rely on the sequential buffering principle and general quality of experience (QoE) model, which may deteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporal variation. In this paper, we propose a digital twin (DT)-based network management scheme to enhance QoE. Firstly, user status emulated by the DT is utilized to estimate the transmission capabilities and watching probability distributions of sub-multicast groups (SMGs) for an adaptive segment buffering. The SMGs' buffers are aligned to the unique virtual buffers managed by the DT for a fine-grained buffer update. Then, a multicast QoE model consisting of rebuffering time, video quality, and quality variation is developed, by considering the mutual influence of segment buffering among SMGs. Finally, a joint optimization problem of segment version selection and slot division is formulated to maximize QoE. To efficiently solve the problem, a data-model-driven algorithm is proposed by integrating a convex optimization method and a deep reinforcement learning algorithm. Simulation results based on the real-world dataset demonstrate that the proposed DT-based network management scheme outperforms benchmark schemes in terms of QoE improvement.",
        "comments": "13 pages, 12 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12826"
    },
    {
        "doc_id": 63,
        "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage",
        "authors": [
            "Ying Song",
            "Balaji Palanisamy"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or privacy individually but few probe into their interplays. In this paper, we propose a novel model-agnostic debiasing framework named MAPPING (\\underline{M}asking \\underline{A}nd \\underline{P}runing and Message-\\underline{P}assing train\\underline{ING}) for fair node classification, in which we adopt the distance covariance($dCov$)-based fairness constraints to simultaneously reduce feature and topology biases in arbitrary dimensions, and combine them with adversarial debiasing to confine the risks of attribute inference attacks. Experiments on real-world datasets with different GNN variants demonstrate the effectiveness and flexibility of MAPPING. Our results show that MAPPING can achieve better trade-offs between utility and fairness, and mitigate privacy risks of sensitive information leakage.",
        "comments": "Finished May last year. Remember to submit all papers to arXiv early without compromising the principles of conferences",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12824"
    },
    {
        "doc_id": 64,
        "title": "Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms",
        "authors": [
            "Esmaeel Mohammadi",
            "Mikkel Stokholm-Bjerregaard",
            "Aviaja Anna Hansen",
            "Per Halkj\u00e6r Nielsen",
            "Daniel Ortiz-Arroyo",
            "Petar Durdevic"
        ],
        "subjects": [
            "Systems and Control",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Phosphorus removal is vital in wastewater treatment to reduce reliance on limited resources. Deep reinforcement learning (DRL) is a machine learning technique that can optimize complex and nonlinear systems, including the processes in wastewater treatment plants, by learning control policies through trial and error. However, applying DRL to chemical and biological processes is challenging due to the need for accurate simulators. This study trained six models to identify the phosphorus removal process and used them to create a simulator for the DRL environment. Although the models achieved high accuracy (>97%), uncertainty and incorrect prediction behavior limited their performance as simulators over longer horizons. Compounding errors in the models' predictions were identified as one of the causes of this problem. This approach for improving process control involves creating simulation environments for DRL algorithms, using data from supervisory control and data acquisition (SCADA) systems with a sufficient historical horizon without complex system modeling or parameter estimation.",
        "comments": "Journal Paper",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12822"
    },
    {
        "doc_id": 65,
        "title": "DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer",
        "authors": [
            "Sonal Kumar",
            "Arijit Sur",
            "Rashmi Dutta Baruah"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Successive proposals of several self-supervised training schemes continue to emerge, taking one step closer to developing a universal foundation model. In this process, the unsupervised downstream tasks are recognized as one of the evaluation methods to validate the quality of visual features learned with a self-supervised training scheme. However, unsupervised dense semantic segmentation has not been explored as a downstream task, which can utilize and evaluate the quality of semantic information introduced in patch-level feature representations during self-supervised training of a vision transformer. Therefore, this paper proposes a novel data-driven approach for unsupervised semantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates semantically consistent and dense pseudo annotate segmentation masks for the unlabeled image dataset without using any visual-prior or synchronized data. We compare these pseudo-annotated segmentation masks with ground truth masks for evaluating recent self-supervised training schemes to learn shared semantic properties at the patch level and discriminative semantic properties at the segment level. Finally, we evaluate existing state-of-the-art self-supervised training schemes with our proposed downstream task, i.e., DatUS^2. Also, the best version of DatUS^2 outperforms the existing state-of-the-art method for the unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47% Pixel accuracy on the SUIM dataset. It also achieves a competitive level of accuracy for a large-scale and complex dataset, i.e., the COCO dataset.",
        "comments": "The manuscript contains 13 pages, 9 figures and 7 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12820"
    },
    {
        "doc_id": 66,
        "title": "Dynamic Layer Tying for Parameter-Efficient Transformers",
        "authors": [
            "Tamir David Hay",
            "Lior Wolf"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer $i$ independently or to copy the weights of a previous layer $j<i$. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12819"
    },
    {
        "doc_id": 67,
        "title": "Binomial Channel: On the Capacity-Achieving Distribution and Bounds on the Capacity",
        "authors": [
            "Ian Zieder",
            "Antonino Favano",
            "Luca Barletta",
            "Alex Dytso"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "This work considers a binomial noise channel. The paper can be roughly divided into two parts. The first part is concerned with the properties of the capacity-achieving distribution. In particular, for the binomial channel, it is not known if the capacity-achieving distribution is unique since the output space is finite (i.e., supported on integers $0, \\ldots, n)$ and the input space is infinite (i.e., supported on the interval $[0,1]$), and there are multiple distributions that induce the same output distribution. This paper shows that the capacity-achieving distribution is unique by appealing to the total positivity property of the binomial kernel. In addition, we provide upper and lower bounds on the cardinality of the support of the capacity-achieving distribution. Specifically, an upper bound of order $ \\frac{n}{2}$ is shown, which improves on the previous upper bound of order $n$ due to Witsenhausen. Moreover, a lower bound of order $\\sqrt{n}$ is shown. Finally, additional information about the locations and probability values of the support points is established.\n  The second part of the paper focuses on deriving upper and lower bounds on capacity. In particular, firm bounds are established for all $n$ that show that the capacity scales as $\\frac{1}{2} \\log(n)$.",
        "comments": "15 pages, 1 figure. Extended version of a paper submitted to IEEE ISIT 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12818"
    },
    {
        "doc_id": 68,
        "title": "COREC: Concurrent Non-Blocking Single-Queue Receive Driver for Low Latency Networking",
        "authors": [
            "Marco Faltelli",
            "Giacomo Belocchi",
            "Francesco Quaglia",
            "Giuseppe Bianchi"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Existing network stacks tackle performance and scalability aspects by relying on multiple receive queues. However, at software level, each queue is processed by a single thread, which prevents simultaneous work on the same queue and limits performance in terms of tail latency. To overcome this limitation, we introduce COREC, the first software implementation of a concurrent non-blocking single-queue receive driver. By sharing a single queue among multiple threads, workload distribution is improved, leading to a work-conserving policy for network stacks. On the technical side, instead of relying on traditional critical sections - which would sequentialize the operations by threads - COREC coordinates the threads that concurrently access the same receive queue in non-blocking manner via atomic machine instructions from the Read-Modify-Write (RMW) class. These instructions allow threads to access and update memory locations atomically, based on specific conditions, such as the matching of a target value selected by the thread. Also, they enable making any update globally visible in the memory hierarchy, bypassing interference on memory consistency caused by the CPU store buffers. Extensive evaluation results demonstrate that the possible additional reordering, which our approach may occasionally cause, is non-critical and has minimal impact on performance, even in the worst-case scenario of a single large TCP flow, with performance impairments accounting to at most 2-3 percent. Conversely, substantial latency gains are achieved when handling UDP traffic, real-world traffic mix, and multiple shorter TCP flows.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12815"
    },
    {
        "doc_id": 69,
        "title": "A Robot Expressing Emotions Through Gestures: Everyone Outside of Italy Would Understand this?",
        "authors": [
            "Ilaria Consoli",
            "Claudio Mattutino",
            "Cristina Gena"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "In the context of our research activities on affective computing and human-robot interaction we are working on both the recognition of human's emotions and the expression of emotions by robots. In our vision, robots will be increasingly present in schools, factories, and homes, and their empathetic behavior may foster their acceptance. In particular, in one of our research, we sought to replicate gestures associated with specific emotions on a social robot, NAO. Our focus was on Ekman's six primary emotions, along with five emotions selected from Plutchik's wheel of emotions. In our opinion the cultural component linked to the expression of emotions through gestures certainly influenced both us and the participants. Thus, we would like to investigate the influence of our culture in the gestural expression of emotion.",
        "comments": "MedCHI workshop 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12808"
    },
    {
        "doc_id": 70,
        "title": "Binary structured physics-informed neural networks for solving equations with rapidly changing solutions",
        "authors": [
            "Yanzhi Liu",
            "Ruifan Wu",
            "Ying Jiang"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Physics-informed neural networks (PINNs), rooted in deep learning, have emerged as a promising approach for solving partial differential equations (PDEs). By embedding the physical information described by PDEs into feedforward neural networks, PINNs are trained as surrogate models to approximate solutions without the need for label data. Nevertheless, even though PINNs have shown remarkable performance, they can face difficulties, especially when dealing with equations featuring rapidly changing solutions. These difficulties encompass slow convergence, susceptibility to becoming trapped in local minima, and reduced solution accuracy. To address these issues, we propose a binary structured physics-informed neural network (BsPINN) framework, which employs binary structured neural network (BsNN) as the neural network component. By leveraging a binary structure that reduces inter-neuron connections compared to fully connected neural networks, BsPINNs excel in capturing the local features of solutions more effectively and efficiently. These features are particularly crucial for learning the rapidly changing in the nature of solutions. In a series of numerical experiments solving Burgers equation, Euler equation, Helmholtz equation, and high-dimension Poisson equation, BsPINNs exhibit superior convergence speed and heightened accuracy compared to PINNs. From these experiments, we discover that BsPINNs resolve the issues caused by increased hidden layers in PINNs resulting in over-smoothing, and prevent the decline in accuracy due to non-smoothness of PDEs solutions.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12806"
    },
    {
        "doc_id": 71,
        "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach",
        "authors": [
            "Rohit Singh",
            "Anil Kumar Yerrapragada",
            "Jeeva Keshav S",
            "Radha Krishna Ganti"
        ],
        "subjects": [
            "Information Theory",
            "Artificial Intelligence",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Random Access is an important step in enabling the initial attachment of a User Equipment (UE) to a Base Station (gNB). The UE identifies itself by embedding a Preamble Index (RAPID) in the phase rotation of a known base sequence, which it transmits on the Physical Random Access Channel (PRACH). The signal on the PRACH also enables the estimation of propagation delay, often known as Timing Advance (TA), which is induced by virtue of the UE's position. Traditional receivers estimate the RAPID and TA using correlation-based techniques. This paper presents an alternative receiver approach that uses AI/ML models, wherein two neural networks are proposed, one for the RAPID and one for the TA. Different from other works, these two models can run in parallel as opposed to sequentially. Experiments with both simulated data and over-the-air hardware captures highlight the improved performance of the proposed AI/ML-based techniques compared to conventional correlation methods.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12803"
    },
    {
        "doc_id": 72,
        "title": "Deep Learning-based Target-To-User Association in Integrated Sensing and Communication Systems",
        "authors": [
            "Lorenzo Cazzella",
            "Marouan Mizmizi",
            "Dario Tagliaferri",
            "Damiano Badini",
            "Matteo Matteucci",
            "Umberto Spagnolini"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "In Integrated Sensing and Communication (ISAC) systems, matching the radar targets with communication user equipments (UEs) is functional to several communication tasks, such as proactive handover and beam prediction. In this paper, we consider a radar-assisted communication system where a base station (BS) is equipped with a multiple-input-multiple-output (MIMO) radar that has a double aim: (i) associate vehicular radar targets to vehicular equipments (VEs) in the communication beamspace and (ii) predict the beamforming vector for each VE from radar data. The proposed target-to-user (T2U) association consists of two stages. First, vehicular radar targets are detected from range-angle images, and, for each, a beamforming vector is estimated. Then, the inferred per-target beamforming vectors are matched with the ones utilized at the BS for communication to perform target-to-user (T2U) association. Joint multi-target detection and beam inference is obtained by modifying the you only look once (YOLO) model, which is trained over simulated range-angle radar images. Simulation results over different urban vehicular mobility scenarios show that the proposed T2U method provides a probability of correct association that increases with the size of the BS antenna array, highlighting the respective increase of the separability of the VEs in the beamspace. Moreover, we show that the modified YOLO architecture can effectively perform both beam prediction and radar target detection, with similar performance in mean average precision on the latter over different antenna array sizes.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12801"
    },
    {
        "doc_id": 73,
        "title": "Deep Learning in Physical Layer: Review on Data Driven End-to-End Communication Systems and their Enabling Semantic Applications",
        "authors": [
            "Nazmul Islam",
            "Seokjoo Shin"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Machine Learning"
        ],
        "abstract": "Deep Learning (DL) has enabled a paradigm shift in wireless communication system with data driven end-to-end (E2E) learning and optimization of the Physical Layer (PHY). By leveraging the representation learning of DL, E2E systems exhibit enhanced adaptability and performance in complex wireless environments, fulfilling the demands of 5G and beyond network systems and applications. The evolution of data-driven techniques in the PHY has enabled advanced semantic applications across various modalities including text, image, audio, video, and multi-modal transmissions. These applications transcend from traditional bit-level communication to semantic-level intelligent communication systems, which are capable of understanding and adapting to the context and intent of the data transmission. Although PHY as a DL architecture for data-driven E2E communication is a key factor in enabling semantic communication systems (SemCom), and various studies in recent years have surveyed them separately, their combination has not been thoroughly reviewed. Additionally, these are emerging fields that are still in their infancy, with several techniques having been developed and evolved in recent years. Therefore, this article provides a holistic review of data-driven PHY for E2E communication system, and their enabling semantic applications across different modalities. Furthermore, it identifies critical challenges and prospective research directions, providing a pivotal reference for future development of DL in PHY and SemCom.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12800"
    },
    {
        "doc_id": 74,
        "title": "Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding",
        "authors": [
            "Yuanyi Wang",
            "Haifeng Sun",
            "Jingyu Wang",
            "Qi Qi",
            "Shaoling Sun",
            "Jianxin Liao"
        ],
        "subjects": [
            "Information Retrieval",
            "Computation and Language"
        ],
        "abstract": "Entity alignment (EA), a pivotal process in integrating multi-source Knowledge Graphs (KGs), seeks to identify equivalent entity pairs across these graphs. Most existing approaches regard EA as a graph representation learning task, concentrating on enhancing graph encoders. However, the decoding process in EA - essential for effective operation and alignment accuracy - has received limited attention and remains tailored to specific datasets and model architectures, necessitating both entity and additional explicit relation embeddings. This specificity limits its applicability, particularly in GNN-based models. To address this gap, we introduce a novel, generalized, and efficient decoding approach for EA, relying solely on entity embeddings. Our method optimizes the decoding process by minimizing Dirichlet energy, leading to the gradient flow within the graph, to promote graph homophily. The discretization of the gradient flow produces a fast and scalable approach, termed Triple Feature Propagation (TFP). TFP innovatively channels gradient flow through three views: entity-to-entity, entity-to-relation, and relation-to-entity. This generalized gradient flow enables TFP to harness the multi-view structural information of KGs. Rigorous experimentation on diverse real-world datasets demonstrates that our approach significantly enhances various EA methods. Notably, the approach achieves these advancements with less than 6 seconds of additional computational time, establishing a new benchmark in efficiency and adaptability for future EA methods.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12798"
    },
    {
        "doc_id": 75,
        "title": "Benchmarking LLMs via Uncertainty Quantification",
        "authors": [
            "Fanghua Ye",
            "Mingming Yang",
            "Jianhui Pang",
            "Longyue Wang",
            "Derek F. Wong",
            "Emine Yilmaz",
            "Shuming Shi",
            "Zhaopeng Tu"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "The proliferation of open-source Large Language Models (LLMs) from various institutions has highlighted the urgent need for comprehensive evaluation methods. However, current evaluation platforms, such as the widely recognized HuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty, which is vital for thoroughly assessing LLMs. To bridge this gap, we introduce a new benchmarking approach for LLMs that integrates uncertainty quantification. Our examination involves eight LLMs (LLM series) spanning five representative natural language processing tasks. Additionally, we introduce an uncertainty-aware evaluation metric, UAcc, which takes into account both prediction accuracy and prediction uncertainty. Our findings reveal that: I) LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs may display greater uncertainty compared to their smaller counterparts; and III) Instruction-finetuning tends to increase the uncertainty of LLMs. By taking uncertainty into account, our new UAcc metric can either amplify or diminish the relative improvement of one LLM over another and may even change the relative ranking of two LLMs. These results underscore the significance of incorporating uncertainty in the evaluation of LLMs.",
        "comments": "24 pages, preprints",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12794"
    },
    {
        "doc_id": 76,
        "title": "Contractions in perfect graph",
        "authors": [
            "Alexandre Dupont-Bouillard",
            "Pierre Fouilhoux",
            "Roland Grappe",
            "Mathieu Lacroix"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper, we characterize the class of {\\em contraction perfect} graphs which are the graphs that remain perfect after the contraction of any edge set. We prove that a graph is contraction perfect if and only if it is perfect and the contraction of any single edge preserves its perfection. This yields a characterization of contraction perfect graphs in terms of forbidden induced subgraphs, and a polynomial algorithm to recognize them. We also define the utter graph $u(G)$ which is the graph whose stable sets are in bijection with the co-2-plexes of $G$, and prove that $u(G)$ is perfect if and only if $G$ is contraction perfect.",
        "comments": "11 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12793"
    },
    {
        "doc_id": 77,
        "title": "MORPH: Towards Automated Concept Drift Adaptation for Malware Detection",
        "authors": [
            "Md Tanvirul Alam",
            "Romy Fieblinger",
            "Ashim Mahara",
            "Nidhi Rastogi"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Concept drift is a significant challenge for malware detection, as the performance of trained machine learning models degrades over time, rendering them impractical. While prior research in malware concept drift adaptation has primarily focused on active learning, which involves selecting representative samples to update the model, self-training has emerged as a promising approach to mitigate concept drift. Self-training involves retraining the model using pseudo labels to adapt to shifting data distributions. In this research, we propose MORPH -- an effective pseudo-label-based concept drift adaptation method specifically designed for neural networks. Through extensive experimental analysis of Android and Windows malware datasets, we demonstrate the efficacy of our approach in mitigating the impact of concept drift. Our method offers the advantage of reducing annotation efforts when combined with active learning. Furthermore, our method significantly improves over existing works in automated concept drift adaptation for malware detection.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12790"
    },
    {
        "doc_id": 78,
        "title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study",
        "authors": [
            "W. Ronny Huang",
            "Cyril Allauzen",
            "Tongzhou Chen",
            "Kilol Gupta",
            "Ke Hu",
            "James Qin",
            "Yu Zhang",
            "Yongqiang Wang",
            "Shuo-Yiin Chang",
            "Tara N. Sainath"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "In the era of large models, the autoregressive nature of decoding often results in latency serving as a significant bottleneck. We propose a non-autoregressive LM-fused ASR system that effectively leverages the parallelization capabilities of accelerator hardware. Our approach combines the Universal Speech Model (USM) and the PaLM 2 language model in per-segment scoring mode, achieving an average relative WER improvement across all languages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our comprehensive ablation study analyzes key parameters such as LLM size, context length, vocabulary size, fusion methodology. For instance, we explore the impact of LLM size ranging from 128M to 340B parameters on ASR performance. This study provides valuable insights into the factors influencing the effectiveness of practical large-scale LM-fused speech recognition systems.",
        "comments": "ICASSP 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12789"
    },
    {
        "doc_id": 79,
        "title": "A Review of Deep Learning Methods for Photoplethysmography Data",
        "authors": [
            "Guangkun Nie",
            "Jiabao Zhu",
            "Gongzheng Tang",
            "Deyun Zhang",
            "Shijia Geng",
            "Qinghao Zhao",
            "Shenda Hong"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Photoplethysmography (PPG) is a highly promising device due to its advantages in portability, user-friendly operation, and non-invasive capabilities to measure a wide range of physiological information. Recent advancements in deep learning have demonstrated remarkable outcomes by leveraging PPG signals for tasks related to personal health management and other multifaceted applications. In this review, we systematically reviewed papers that applied deep learning models to process PPG data between January 1st of 2017 and July 31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed from three key perspectives: tasks, models, and data. We finally extracted 193 papers where different deep learning frameworks were used to process PPG signals. Based on the tasks addressed in these papers, we categorized them into two major groups: medical-related, and non-medical-related. The medical-related tasks were further divided into seven subgroups, including blood pressure analysis, cardiovascular monitoring and diagnosis, sleep health, mental health, respiratory monitoring and analysis, blood glucose analysis, as well as others. The non-medical-related tasks were divided into four subgroups, which encompass signal processing, biometric identification, electrocardiogram reconstruction, and human activity recognition. In conclusion, significant progress has been made in the field of using deep learning methods to process PPG data recently. This allows for a more thorough exploration and utilization of the information contained in PPG signals. However, challenges remain, such as limited quantity and quality of publicly available databases, a lack of effective validation in real-world scenarios, and concerns about the interpretability, scalability, and complexity of deep learning models. Moreover, there are still emerging research areas that require further investigation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12783"
    },
    {
        "doc_id": 80,
        "title": "DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for Alleviating Over-squashing",
        "authors": [
            "Li Sun",
            "Zhenhao Huang",
            "Hua Wu",
            "Junda Ye",
            "Hao Peng",
            "Zhengtao Yu",
            "Philip S. Yu"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown great power for learning and mining on graphs, and Graph Structure Learning (GSL) plays an important role in boosting GNNs with a refined graph. In the literature, most GSL solutions either primarily focus on structure refinement with task-specific supervision (i.e., node classification), or overlook the inherent weakness of GNNs themselves (e.g., over-squashing), resulting in suboptimal performance despite sophisticated designs. In light of these limitations, we propose to study self-supervised graph structure-feature co-refinement for effectively alleviating the issue of over-squashing in typical GNNs. In this paper, we take a fundamentally different perspective of the Ricci curvature in Riemannian geometry, in which we encounter the challenges of modeling, utilizing and computing Ricci curvature. To tackle these challenges, we present a self-supervised Riemannian model, DeepRicci. Specifically, we introduce a latent Riemannian space of heterogeneous curvatures to model various Ricci curvatures, and propose a gyrovector feature mapping to utilize Ricci curvature for typical GNNs. Thereafter, we refine node features by geometric contrastive learning among different geometric views, and simultaneously refine graph structure by backward Ricci flow based on a novel formulation of differentiable Ricci curvature. Finally, extensive experiments on public datasets show the superiority of DeepRicci, and the connection between backward Ricci flow and over-squashing. Codes of our work are given in https://github.com/RiemanGraph/.",
        "comments": "Accepted by IEEE ICDM 2023, Full paper, 10 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12780"
    },
    {
        "doc_id": 81,
        "title": "Deep Learning-based Intraoperative MRI Reconstruction",
        "authors": [
            "Jon Andr\u00e9 Ottesen",
            "Tryggve Storas",
            "Svein Are Sirirud Vatnehol",
            "Grethe L\u00f8vland",
            "Einar O. Vik-Mo",
            "Till Schellhorn",
            "Karoline Skogen",
            "Christopher Larsson",
            "Atle Bj\u00f8rnerud",
            "Inge Rasmus Groote-Eindbaas",
            "Matthan W. A. Caan"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Medical Physics"
        ],
        "abstract": "Purpose: To evaluate the quality of deep learning reconstruction for prospectively accelerated intraoperative magnetic resonance imaging (iMRI) during resective brain tumor surgery.\n  Materials and Methods: Accelerated iMRI was performed during brain surgery using dual surface coils positioned around the area of resection. A deep learning (DL) model was trained on the fastMRI neuro dataset to mimic the data from the iMRI protocol. Evaluation was performed on imaging material from 40 patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during tumor resection surgery. A comparative analysis was conducted between the conventional compressed sense (CS) method and the trained DL reconstruction method. Blinded evaluation of multiple image quality metrics was performed by two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the favored reconstruction variant.\n  Results: The DL reconstruction was strongly favored or favored over the CS reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3, respectively. Two of three readers consistently assigned higher ratings for the DL reconstructions, and the DL reconstructions had a higher score than their respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2, and 3, respectively. Still, the DL reconstructions exhibited shortcomings such as a striping artifact and reduced signal.\n  Conclusion: DL shows promise to allow for high-quality reconstructions of intraoperative MRI with equal to or improved perceived spatial resolution, signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and spatial resolution compared to compressed sense.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12771"
    },
    {
        "doc_id": 82,
        "title": "What Can Self-Admitted Technical Debt Tell Us About Security? A Mixed-Methods Study",
        "authors": [
            "Nicol\u00e1s E. D\u00edaz Ferreyra",
            "Mojtaba Shahin",
            "Mansorreh Zahedi",
            "Sodiq Quadri",
            "Ricardo Scandariato"
        ],
        "subjects": [
            "Software Engineering",
            "Human-Computer Interaction"
        ],
        "abstract": "Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimal design and implementation choices reported in software artefacts (e.g., code comments and commit messages) by developers themselves. Such reports have been central to the study of software maintenance and evolution over the last decades. However, they can also be deemed as dreadful sources of information on potentially exploitable vulnerabilities and security flaws. This work investigates the security implications of SATD from a technical and developer-centred perspective. On the one hand, it analyses whether security pointers disclosed inside SATD sources can be used to characterise vulnerabilities in Open-Source Software (OSS) projects and repositories. On the other hand, it delves into developers' perspectives regarding the motivations behind this practice, its prevalence, and its potential negative consequences. We followed a mixed-methods approach consisting of (i) the analysis of a preexisting dataset containing 94,455 SATD instances and (ii) an online survey with 222 OSS practitioners. We gathered 201 SATD instances through the dataset analysis and mapped them to different Common Weakness Enumeration (CWE) identifiers. Overall, 25 different types of CWEs were spotted across commit messages, pull requests, code comments, and issue sections, from which 8 appear among MITRE's Top-25 most dangerous ones. The survey shows that software practitioners often place security pointers across SATD artefacts to promote a security culture among their peers and help them spot flaky code sections, among other motives. However, they also consider such a practice risky as it may facilitate vulnerability exploits. Our findings suggest that preserving the contextual integrity of security pointers disseminated across SATD artefacts is critical to safeguard both commercial and OSS solutions against zero-day attacks.",
        "comments": "Accepted in the 21th International Conference on Mining Software Repositories (MSR '24)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12768"
    },
    {
        "doc_id": 83,
        "title": "Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\\mathcal{O}(1/k)$ Finite-Sample Complexity",
        "authors": [
            "Thinh T. Doan"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $\\mathcal{O}(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $\\mathcal{O}(1/k^{2/3})$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12764"
    },
    {
        "doc_id": 84,
        "title": "The State-Dependent Channel with a Rate-Limited Cribbing Helper",
        "authors": [
            "Amos Lapidoth",
            "Yossef Steinberg"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "The capacity of a memoryless state-dependent channel is derived for a setting in which the encoder is provided with rate-limited assistance from a cribbing helper that observes the state sequence causally and the past channel inputs strictly-causally. Said cribbing may increase capacity but not to the level achievable by a message-cognizant helper.",
        "comments": "8 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12763"
    },
    {
        "doc_id": 85,
        "title": "MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty",
        "authors": [
            "Tim Br\u00f6dermann",
            "David Bruggemann",
            "Christos Sakaridis",
            "Kevin Ta",
            "Odysseas Liagouris",
            "Jason Corkill",
            "Luc Van Gool"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Achieving level-5 driving automation in autonomous vehicles necessitates a robust semantic visual perception system capable of parsing data from different sensors across diverse conditions. However, existing semantic perception datasets often lack important non-camera modalities typically used in autonomous vehicles, or they do not exploit such modalities to aid and improve semantic annotations in challenging conditions. To address this, we introduce MUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverse conditions under increased uncertainty. MUSES includes synchronized multimodal recordings with 2D panoptic annotations for 2500 images captured under diverse weather and illumination. The dataset integrates a frame camera, a lidar, a radar, an event camera, and an IMU/GNSS sensor. Our new two-stage panoptic annotation protocol captures both class-level and instance-level uncertainty in the ground truth and enables the novel task of uncertainty-aware panoptic segmentation we introduce, along with standard semantic and panoptic segmentation. MUSES proves both effective for training and challenging for evaluating models under diverse visual conditions, and it opens new avenues for research in multimodal and uncertainty-aware dense semantic perception. Our dataset and benchmark will be made publicly available.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12761"
    },
    {
        "doc_id": 86,
        "title": "What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition",
        "authors": [
            "Carolin Holtermann",
            "Markus Frohmann",
            "Navid Rekabsaz",
            "Anne Lauscher"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge composition strategies. In particular, we test two module combination methods and five selection and weighting strategies for their effectiveness and efficiency in an extensive experimental setup. Our results highlight the efficacy of ensembling but also hint at the power of simple though often-ignored weighting methods. Further in-depth analyses allow us to understand the role of weighting vs. top-k selection, and show that, to a certain extent, the performance of adapter composition can even be predicted.",
        "comments": "Accepted to Findings of the ACL: EACL 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12756"
    },
    {
        "doc_id": 87,
        "title": "Towards Risk Analysis of the Impact of AI on the Deliberate Biological Threat Landscape",
        "authors": [
            "Matthew E. Walsh"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "The perception that the convergence of biological engineering and artificial intelligence (AI) could enable increased biorisk has recently drawn attention to the governance of biotechnology and artificial intelligence. The 2023 Executive Order, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, requires an assessment of how artificial intelligence can increase biorisk. Within this perspective, we present a simplistic framework for evaluating biorisk and demonstrate how this framework falls short in achieving actionable outcomes for a biorisk manager. We then suggest a potential path forward that builds upon existing risk characterization work and justify why characterization efforts of AI-enabled tools for engineering biology is needed.",
        "comments": "12 pages, 2 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12755"
    },
    {
        "doc_id": 88,
        "title": "PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction",
        "authors": [
            "Wanjuan Su",
            "Chen Zhang",
            "Qingshan Xu",
            "Wenbing Tao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Surface reconstruction has traditionally relied on the Multi-View Stereo (MVS)-based pipeline, which often suffers from noisy and incomplete geometry. This is due to that although MVS has been proven to be an effective way to recover the geometry of the scenes, especially for locally detailed areas with rich textures, it struggles to deal with areas with low texture and large variations of illumination where the photometric consistency is unreliable. Recently, Neural Implicit Surface Reconstruction (NISR) combines surface rendering and volume rendering techniques and bypasses the MVS as an intermediate step, which has emerged as a promising alternative to overcome the limitations of traditional pipelines. While NISR has shown impressive results on simple scenes, it remains challenging to recover delicate geometry from uncontrolled real-world scenes which is caused by its underconstrained optimization. To this end, the framework PSDF is proposed which resorts to external geometric priors from a pretrained MVS network and internal geometric priors inherent in the NISR model to facilitate high-quality neural implicit surface learning. Specifically, the visibility-aware feature consistency loss and depth prior-assisted sampling based on external geometric priors are introduced. These proposals provide powerfully geometric consistency constraints and aid in locating surface intersection points, thereby significantly improving the accuracy and delicate reconstruction of NISR. Meanwhile, the internal prior-guided importance rendering is presented to enhance the fidelity of the reconstructed surface mesh by mitigating the biased rendering issue in NISR. Extensive experiments on the Tanks and Temples dataset show that PSDF achieves state-of-the-art performance on complex uncontrolled scenes.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12751"
    },
    {
        "doc_id": 89,
        "title": "COOCK project Smart Port 2025 D3.1: \"To Twin Or Not To Twin\"",
        "authors": [
            "Randy Paredis",
            "Hans Vangheluwe",
            "Pamela Adelino Ramos Albertins"
        ],
        "subjects": [
            "Systems and Control",
            "Software Engineering"
        ],
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving and accelerating the operational efficiency of a harbour eco-system through the application of intelligent technologies\". It reports on the needs of companies for modelling and simulation and AI-based techniques, with twinning systems in particular. This document categorizes the purposes and Properties of Interest for the use of Digital Twins. It further illustrates some of the twinning usages, and touches on some of the potential architectural compositions for twins. This last topic will be further elaborated in a followup report.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12747"
    },
    {
        "doc_id": 90,
        "title": "On the Utility of Probing Trajectories for Algorithm-Selection",
        "authors": [
            "Quentin Renau",
            "Emma Hart"
        ],
        "subjects": [
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Machine-learning approaches to algorithm-selection typically take data describing an instance as input. Input data can take the form of features derived from the instance description or fitness landscape, or can be a direct representation of the instance itself, i.e. an image or textual description. Regardless of the choice of input, there is an implicit assumption that instances that are similar will elicit similar performance from algorithm, and that a model is capable of learning this relationship. We argue that viewing algorithm-selection purely from an instance perspective can be misleading as it fails to account for how an algorithm `views' similarity between instances. We propose a novel `algorithm-centric' method for describing instances that can be used to train models for algorithm-selection: specifically, we use short probing trajectories calculated by applying a solver to an instance for a very short period of time. The approach is demonstrated to be promising, providing comparable or better results to computationally expensive landscape-based feature-based approaches. Furthermore, projecting the trajectories into a 2-dimensional space illustrates that functions that are similar from an algorithm-perspective do not necessarily correspond to the accepted categorisation of these functions from a human perspective.",
        "comments": "To appear in the proceedings of the 27th International Conference, EvoApplications 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12745"
    },
    {
        "doc_id": 91,
        "title": "Monadic Intersection Types, Relationally (Extended Version)",
        "authors": [
            "Francesco Gavazzo",
            "Riccardo Treglia",
            "Gabriele Vanoni"
        ],
        "subjects": [
            "Programming Languages",
            "Logic in Computer Science"
        ],
        "abstract": "We extend intersection types to a computational $\u03bb$-calculus with algebraic operations \u00e0 la Plotkin and Power. We achieve this by considering monadic intersections, whereby computational effects appear not only in the operational semantics, but also in the type system. Since in the effectful setting termination is not anymore the only property of interest, we want to analyze the interactive behavior of typed programs with the environment. Indeed, our type system is able to characterize the natural notion of observation, both in the finite and in the infinitary setting, and for a wide class of effects, such as output, cost, pure and probabilistic nondeterminism, and combinations thereof. The main technical tool is a novel combination of syntactic techniques with abstract relational reasoning, which allows us to lift all the required notions, e.g. of typability and logical relation, to the monadic setting.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12744"
    },
    {
        "doc_id": 92,
        "title": "Correlation-Embedded Transformer Tracking: A Single-Branch Framework",
        "authors": [
            "Fei Xie",
            "Wankou Yang",
            "Chunyu Wang",
            "Lei Chu",
            "Yue Cao",
            "Chao Ma",
            "Wenjun Zeng"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Developing robust and discriminative appearance models has been a long-standing research challenge in visual object tracking. In the prevalent Siamese-based paradigm, the features extracted by the Siamese-like networks are often insufficient to model the tracked targets and distractor objects, thereby hindering them from being robust and discriminative simultaneously. While most Siamese trackers focus on designing robust correlation operations, we propose a novel single-branch tracking framework inspired by the transformer. Unlike the Siamese-like feature extraction, our tracker deeply embeds cross-image feature correlation in multiple layers of the feature network. By extensively matching the features of the two images through multiple layers, it can suppress non-target features, resulting in target-aware feature extraction. The output features can be directly used for predicting target locations without additional correlation steps. Thus, we reformulate the two-branch Siamese tracking as a conceptually simple, fully transformer-based Single-Branch Tracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBT baseline, we summarize many effective design principles and propose an improved tracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with a local modeling layer to enhance shallow-level features. A unified relation modeling is proposed to remove complex handcrafted layer pattern designs. SuperSBT is further improved by masked image modeling pre-training, integrating temporal modeling, and equipping with dedicated prediction heads. Thus, SuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores in LaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed of SBT from 37 FPS to 81 FPS. Extensive experiments show that our method achieves superior results on eight VOT benchmarks.",
        "comments": "14 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12743"
    },
    {
        "doc_id": 93,
        "title": "Decoding University Hierarchy and Prestige in China through Domestic Ph.D. Hiring Network",
        "authors": [
            "Chaolin Tian",
            "Xunyi Jiang",
            "Yurui Huang",
            "Langtian Ma",
            "Yifang Ma"
        ],
        "subjects": [
            "Digital Libraries"
        ],
        "abstract": "The academic job market for fresh Ph.D. students to pursue postdoctoral and junior faculty positions plays a crucial role in shaping the future orientations, developments, and status of the global academic system. In this work, we focus on the domestic Ph.D. hiring network among universities in China by exploring the doctoral education and academic employment of nearly 28,000 scientists across all Ph.D.-granting Chinese universities over three decades. We employ the minimum violation rankings algorithm to decode the rankings for universities based on the Ph.D. hiring network, which offers a deep understanding of the structure and dynamics within the network. Our results uncover a consistent, highly structured hierarchy within this hiring network, indicating the imbalances wherein a limited number of universities serve as the main sources of fresh Ph.D. across diverse disciplines. Furthermore, over time, it has become increasingly challenging for Chinese Ph.D. graduates to secure positions at institutions more prestigious than their alma maters. This study quantitatively captures the evolving structure of talent circulation in the domestic environment, providing valuable insights to enhance the organization, diversity, and talent distribution in China's academic enterprise.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12739"
    },
    {
        "doc_id": 94,
        "title": "Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects",
        "authors": [
            "Dachong Li",
            "Li Li",
            "Zhuangzhuang Chen",
            "Jianqiang Li"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Recent studies reveal that the remarkable performance of Vision transformers (ViTs) benefits from large receptive fields. For this reason, the large convolutional kernel design becomes an ideal solution to make Convolutional Neural Networks (CNNs) great again. However, the typical large convolutional kernels turn out to be hardware-unfriendly operators, resulting in discount compatibility of various hardware platforms. Thus, it is unwise to simply enlarge the convolutional kernel size. In this paper, we reveal that small convolutional kernels and convolution operations can achieve the closing effects of large kernel sizes. Then, we propose a shift-wise operator that ensures the CNNs capture long-range dependencies with the help of the sparse mechanism, while remaining hardware-friendly. Experimental results show that our shift-wise operator significantly improves the accuracy of a regular CNN while markedly reducing computational requirements. On the ImageNet-1k, our shift-wise enhanced CNN model outperforms the state-of-the-art models. Code & models at https://github.com/lidc54/shift-wiseConv.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12736"
    },
    {
        "doc_id": 95,
        "title": "TNANet: A Temporal-Noise-Aware Neural Network for Suicidal Ideation Prediction with Noisy Physiological Data",
        "authors": [
            "Niqi Liu",
            "Fang Liu",
            "Wenqi Ji",
            "Xinxin Du",
            "Xu Liu",
            "Guozhen Zhao",
            "Wenting Mu",
            "Yong-Jin Liu"
        ],
        "subjects": [
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "The robust generalization of deep learning models in the presence of inherent noise remains a significant challenge, especially when labels are subjective and noise is indiscernible in natural settings. This problem is particularly pronounced in many practical applications. In this paper, we address a special and important scenario of monitoring suicidal ideation, where time-series data, such as photoplethysmography (PPG), is susceptible to such noise. Current methods predominantly focus on image and text data or address artificially introduced noise, neglecting the complexities of natural noise in time-series analysis. To tackle this, we introduce a novel neural network model tailored for analyzing noisy physiological time-series data, named TNANet, which merges advanced encoding techniques with confidence learning, enhancing prediction accuracy. Another contribution of our work is the collection of a specialized dataset of PPG signals derived from real-world environments for suicidal ideation prediction. Employing this dataset, our TNANet achieves the prediction accuracy of 63.33% in a binary classification task, outperforming state-of-the-art models. Furthermore, comprehensive evaluations were conducted on three other well-known public datasets with artificially introduced noise to rigorously test the TNANet's capabilities. These tests consistently demonstrated TNANet's superior performance by achieving an accuracy improvement of more than 10% compared to baseline methods.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12733"
    },
    {
        "doc_id": 96,
        "title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process",
        "authors": [
            "Xiaodong Li",
            "Jiawei Sheng",
            "Jiangxia Cao",
            "Wenyuan Zhang",
            "Quangang Li",
            "Tingwen Liu"
        ],
        "subjects": [
            "Information Retrieval",
            "Social and Information Networks"
        ],
        "abstract": "Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios.",
        "comments": "This paper is accepted by WSDM'2024 Oral",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12732"
    },
    {
        "doc_id": 97,
        "title": "The Distributional Uncertainty of the SHAP score in Explainable Machine Learning",
        "authors": [
            "Santiago Cifuentes",
            "Leopoldo Bertossi",
            "Nina Pardal",
            "Sergio Abriola",
            "Maria Vanina Martinez",
            "Miguel Romero"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Logic in Computer Science"
        ],
        "abstract": "Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for the SHAP scores of all features. In particular, we pinpoint the complexity of these problems, and other related ones, showing them to be NP-complete. Finally, we present experiments on a real-world dataset, showing that our framework may contribute to a more robust feature scoring.",
        "comments": "MSC Class:          68T37; 68T27",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12731"
    },
    {
        "doc_id": 98,
        "title": "Enhancing Object Detection Performance for Small Objects through Synthetic Data Generation and Proportional Class-Balancing Technique: A Comparative Study in Industrial Scenarios",
        "authors": [
            "Jibinraj Antony",
            "Vinit Hegiste",
            "Ali Nazeri",
            "Hooman Tavakoli",
            "Snehal Walunj",
            "Christiane Plociennik",
            "Martin Ruskowski"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Object Detection (OD) has proven to be a significant computer vision method in extracting localized class information and has multiple applications in the industry. Although many of the state-of-the-art (SOTA) OD models perform well on medium and large sized objects, they seem to under perform on small objects. In most of the industrial use cases, it is difficult to collect and annotate data for small objects, as it is time-consuming and prone to human errors. Additionally, those datasets are likely to be unbalanced and often result in an inefficient model convergence. To tackle this challenge, this study presents a novel approach that injects additional data points to improve the performance of the OD models. Using synthetic data generation, the difficulties in data collection and annotations for small object data points can be minimized and to create a dataset with balanced distribution. This paper discusses the effects of a simple proportional class-balancing technique, to enable better anchor matching of the OD models. A comparison was carried out on the performances of the SOTA OD models: YOLOv5, YOLOv7 and SSD, for combinations of real and synthetic datasets within an industrial use case.",
        "comments": "Accepted and presented in conference ESAIM23 1st European Symposium on Artificial Intelligence in Manufacturing",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12729"
    },
    {
        "doc_id": 99,
        "title": "Two-View Topogram-Based Anatomy-Guided CT Reconstruction for Prospective Risk Minimization",
        "authors": [
            "Chang Liu",
            "Laura Klein",
            "Yixing Huang",
            "Edith Baader",
            "Michael Lell",
            "Marc Kachelrie\u00df",
            "Andreas Maier"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "To facilitate a prospective estimation of CT effective dose and risk minimization process, a prospective spatial dose estimation and the known anatomical structures are expected. To this end, a CT reconstruction method is required to reconstruct CT volumes from as few projections as possible, i.e. by using the topograms, with anatomical structures as correct as possible. In this work, an optimized CT reconstruction model based on a generative adversarial network (GAN) is proposed. The GAN is trained to reconstruct 3D volumes from an anterior-posterior and a lateral CT projection. To enhance anatomical structures, a pre-trained organ segmentation network and the 3D perceptual loss are applied during the training phase, so that the model can then generate both organ-enhanced CT volume and the organ segmentation mask. The proposed method can reconstruct CT volumes with PSNR of 26.49, RMSE of 196.17, and SSIM of 0.64, compared to 26.21, 201.55 and 0.63 using the baseline method. In terms of the anatomical structure, the proposed method effectively enhances the organ shape and boundary and allows for a straight-forward identification of the relevant anatomical structures. We note that conventional reconstruction metrics fail to indicate the enhancement of anatomical structures. In addition to such metrics, the evaluation is expanded with assessing the organ segmentation performance. The average organ dice of the proposed method is 0.71 compared with 0.63 in baseline model, indicating the enhancement of anatomical structures.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12725"
    },
    {
        "doc_id": 100,
        "title": "Reference-dependent asset pricing with a stochastic consumption-dividend ratio",
        "authors": [
            "Luca De Gennaro Aquino",
            "Xuedong He",
            "Moris Simon Strub",
            "Yuting Yang"
        ],
        "subjects": [
            "Mathematical Finance",
            "General Finance"
        ],
        "abstract": "We study a discrete-time consumption-based capital asset pricing model under expectations-based reference-dependent preferences. More precisely, we consider an endowment economy populated by a representative agent who derives utility from current consumption and from gains and losses in consumption with respect to a forward-looking, stochastic reference point. First, we consider a general model in which the agent's preferences include both contemporaneous gain-loss utility, that is, utility from the difference between current consumption and previously held expectations about current consumption, and prospective gain-loss utility, that is, utility from the difference between intertemporal beliefs about future consumption. A semi-closed form solution for equilibrium asset prices is derived for this case. We then specialize to a model in which the agent derives contemporaneous gain-loss utility only, obtaining equilibrium asset prices in closed form. Extensive numerical experiments show that, with plausible values of risk aversion and loss aversion, our models can generate equity premia that match empirical estimates. Interestingly, the models turn out to be consistent with some well-known empirical facts, namely procyclical variation in the price-dividend ratio and countercyclical variation in the conditional expected equity premium and in the conditional volatility of the equity premium. Furthermore, we find that prospective gain-loss utility is necessary for the model to predict reasonable values of the price-dividend ratio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12856"
    },
    {
        "doc_id": 101,
        "title": "New approximate stochastic dominance approaches for Enhanced Indexation models",
        "authors": [
            "Francesco Cesarone",
            "Justo Puerto"
        ],
        "subjects": [
            "Portfolio Management",
            "Computational Finance",
            "General Finance"
        ],
        "abstract": "In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczynski (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12669"
    },
    {
        "doc_id": 102,
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "authors": [
            "Henri Arno",
            "Klaas Mulier",
            "Joke Baeck",
            "Thomas Demeester"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Computational Finance"
        ],
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.",
        "comments": "Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12652"
    },
    {
        "doc_id": 103,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 104,
        "title": "General duality and dual attainment for adapted transport",
        "authors": [
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "We investigate duality and existence of dual optimizers for several adapted optimal transport problems under minimal assumptions. This includes the causal and bicausal transport, the barycenter problem, and a general multimarginal problem incorporating causality constraints. Moreover, we discuss applications of our results in robust finance. We consider a non-dominated model of several financial markets where stocks are traded dynamically, but the joint stock dynamics are unknown. We show that a no-arbitrage assumption in a quasi-sure sense naturally leads to sets of multicausal couplings. Consequently, computing the robust superhedging price is equivalent to solving an adapted transport problem, and finding a superhedging strategy means solving the corresponding dual.",
        "comments": "32 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11958"
    },
    {
        "doc_id": 105,
        "title": "Forecasting and Backtesting Gradient Allocations of Expected Shortfall",
        "authors": [
            "Takaaki Koike",
            "Cathy W. S. Chen",
            "Edward M. H. Lin"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Capital allocation is a procedure for quantifying the contribution of each source of risk to aggregated risk. The gradient allocation rule, also known as the Euler principle, is a prevalent rule of capital allocation under which the allocated capital captures the diversification benefit of the marginal risk as a component of overall risk. This research concentrates on Expected Shortfall (ES) as a regulatory standard and focuses on the gradient allocations of ES, also called ES contributions. We achieve the comprehensive treatment of backtesting the tuple of ES contributions in the framework of the traditional and comparative backtests based on the concepts of joint identifiability and multi-objective elicitability. For robust forecast evaluation against the choice of scoring function, we further develop Murphy diagrams for ES contributions as graphical tools to check whether one forecast dominates another under a class of scoring functions. Finally, leveraging the recent concept of multi-objective elicitability, we propose a novel semiparametric model for forecasting dynamic ES contributions based on a compositional regression model. In an empirical analysis of stock returns we evaluate and compare a variety of models for forecasting dynamic ES contributions and demonstrate the outstanding performance of the proposed model.",
        "comments": "MSC Class:          62F07; 62P05; 91B30",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11701"
    },
    {
        "doc_id": 106,
        "title": "A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting",
        "authors": [
            "Riaz Ud Din",
            "Salman Ahmed",
            "Saddam Hussain Khan"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.",
        "comments": "30 pages, 16 Figures, 4 Tables",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11621"
    },
    {
        "doc_id": 107,
        "title": "The geometry of multi-curve interest rate models",
        "authors": [
            "Claudio Fontana",
            "Giacomo Lanaro",
            "Agatha Murgoci"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We study the problems of consistency and of the existence of finite-dimensional realizations for multi-curve interest rate models of Heath-Jarrow-Morton type, generalizing the geometric approach developed by T. Bj\u00f6rk and co-authors in the classical single-curve setting. We characterize when a multi-curve interest rate model is consistent with a given parameterized family of forward curves and spreads and when a model can be realized by a finite-dimensional state process. We illustrate the general theory in a number of model classes and examples, providing explicit constructions of finite-dimensional realizations. Based on these theoretical results, we perform the calibration of a three-curve Hull-White model to market data and analyse the stability of the estimated parameters.",
        "comments": "28 pages, 2 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11619"
    },
    {
        "doc_id": 108,
        "title": "Functional Limit Theorems for Hawkes Processes",
        "authors": [
            "Ulrich Horst",
            "Wei Xu"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritical processes critical ones with heavily dispersed child events display long-range dependencies.",
        "comments": "59 pages; Keywords and phrases: Hawkes process, functional limit theorem, regular variation, convergence rate",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11495"
    },
    {
        "doc_id": 109,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 110,
        "title": "Data-driven Option Pricing",
        "authors": [
            "Min Dai",
            "Hanqing Jin",
            "Xi Yang"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "We propose an innovative data-driven option pricing methodology that relies exclusively on the dataset of historical underlying asset prices. While the dataset is rooted in the objective world, option prices are commonly expressed as discounted expectations of their terminal payoffs in a risk-neutral world. Bridging this gap motivates us to identify a pricing kernel process, transforming option pricing into evaluating expectations in the objective world. We recover the pricing kernel by solving a utility maximization problem, and evaluate the expectations in terms of a functional optimization problem. Leveraging the deep learning technique, we design data-driven algorithms to solve both optimization problems over the dataset. Numerical experiments are presented to demonstrate the efficiency of our methodology.",
        "comments": "15 pages, 3 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11158"
    },
    {
        "doc_id": 111,
        "title": "BioFinBERT: Finetuning Large Language Models (LLMs) to Analyze Sentiment of Press Releases and Financial Text Around Inflection Points of Biotech Stocks",
        "authors": [
            "Valentina Aparicio",
            "Daniel Gordon",
            "Sebastian G. Huayamares",
            "Yuhuai Luo"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "Large language models (LLMs) are deep learning algorithms being used to perform natural language processing tasks in various fields, from social sciences to finance and biomedical sciences. Developing and training a new LLM can be very computationally expensive, so it is becoming a common practice to take existing LLMs and finetune them with carefully curated datasets for desired applications in different fields. Here, we present BioFinBERT, a finetuned LLM to perform financial sentiment analysis of public text associated with stocks of companies in the biotechnology sector. The stocks of biotech companies developing highly innovative and risky therapeutic drugs tend to respond very positively or negatively upon a successful or failed clinical readout or regulatory approval of their drug, respectively. These clinical or regulatory results are disclosed by the biotech companies via press releases, which are followed by a significant stock response in many cases. In our attempt to design a LLM capable of analyzing the sentiment of these press releases,we first finetuned BioBERT, a biomedical language representation model designed for biomedical text mining, using financial textual databases. Our finetuned model, termed BioFinBERT, was then used to perform financial sentiment analysis of various biotech-related press releases and financial text around inflection points that significantly affected the price of biotech stocks.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11011"
    },
    {
        "doc_id": 112,
        "title": "Forecasting Cryptocurrency Staking Rewards",
        "authors": [
            "Sauren Gupta",
            "Apoorva Hathi Katharaki",
            "Yifan Xu",
            "Bhaskar Krishnamachari",
            "Rajarshi Gupta"
        ],
        "subjects": [
            "Statistical Finance",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This research explores a relatively unexplored area of predicting cryptocurrency staking rewards, offering potential insights to researchers and investors. We investigate two predictive methodologies: a) a straightforward sliding-window average, and b) linear regression models predicated on historical data. The findings reveal that ETH staking rewards can be forecasted with an RMSE within 0.7% and 1.1% of the mean value for 1-day and 7-day look-aheads respectively, using a 7-day sliding-window average approach. Additionally, we discern diverse prediction accuracies across various cryptocurrencies, including SOL, XTZ, ATOM, and MATIC. Linear regression is identified as superior to the moving-window average for perdicting in the short term for XTZ and ATOM. The results underscore the generally stable and predictable nature of staking rewards for most assets, with MATIC presenting a noteworthy exception.",
        "comments": "9 pages, 18 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10931"
    },
    {
        "doc_id": 113,
        "title": "Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock",
        "authors": [
            "Dengxin Huang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "This document presents a stock market analysis conducted on a dataset consisting of 750 instances and 16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section, feature engineering, data preparation, model selection, and insights from the analysis. The Fama French 3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear regression being the best-performing model.",
        "comments": "9 pages, 7 figures",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10903"
    },
    {
        "doc_id": 114,
        "title": "Stylized Facts and Market Microstructure: An In-Depth Exploration of German Bond Futures Market",
        "authors": [
            "Hamza Bodor",
            "Laurent Carlier"
        ],
        "subjects": [
            "Statistical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper presents an in-depth analysis of stylized facts in the context of futures on German bonds. The study examines four futures contracts on German bonds: Schatz, Bobl, Bund and Buxl, using tick-by-tick limit order book datasets. It uncovers a range of stylized facts and empirical observations, including the distribution of order sizes, patterns of order flow, and inter-arrival times of orders. The findings reveal both commonalities and unique characteristics across the different futures, thereby enriching our understanding of these markets. Furthermore, the paper introduces insightful realism metrics that can be used to benchmark market simulators. The study contributes to the literature on financial stylized facts by extending empirical observations to this class of assets, which has been relatively underexplored in existing research. This work provides valuable guidance for the development of more accurate and realistic market simulators.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10722"
    },
    {
        "doc_id": 115,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 116,
        "title": "Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review",
        "authors": [
            "Lars Ericson",
            "Xuejun Zhu",
            "Xusi Han",
            "Rao Fu",
            "Shuang Li",
            "Steve Guo",
            "Ping Hu"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "In the financial services industry, forecasting the risk factor distribution conditional on the history and the current market environment is the key to market risk modeling in general and value at risk (VaR) model in particular. As one of the most widely adopted VaR models in commercial banks, Historical simulation (HS) uses the empirical distribution of daily returns in a historical window as the forecast distribution of risk factor returns in the next day. The objectives for financial time series generation are to generate synthetic data paths with good variety, and similar distribution and dynamics to the original historical data. In this paper, we apply multiple existing deep generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for conditional time series generation, and propose and test two new methods for conditional multi-step time series generation, namely Encoder-Decoder CGAN and Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a set of KPIs to measure the quality of the generated time series for financial modeling. The KPIs cover distribution distance, autocorrelation and backtesting. All models (HS, parametric and neural networks) are tested on both historical USD yield curve data and additional data simulated from GARCH and CIR processes. The study shows that top performing models are HS, GARCH and CWGAN models. Future research directions in this area are also discussed.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10370"
    },
    {
        "doc_id": 117,
        "title": "Interplay between Cryptocurrency Transactions and Online Financial Forums",
        "authors": [
            "Ana Fern\u00e1ndez Vilas",
            "Rebeca P. D\u00edaz Redondo",
            "Daniel Couto Cancela",
            "Alejandro Torrado Pazos"
        ],
        "subjects": [
            "General Finance",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Cryptocurrencies are a type of digital money meant to provide security and anonymity while using cryptography techniques. Although cryptocurrencies represent a breakthrough and provide some important benefits, their usage poses some risks that are a result of the lack of supervising institutions and transparency. Because disinformation and volatility is discouraging for personal investors, cryptocurrencies emerged hand-in-hand with the proliferation of online users' communities and forums as places to share information that can alleviate users' mistrust. This research focuses on the study of the interplay between these cryptocurrency forums and fluctuations in cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin (BTC) and a related active discussion community, Bitcointalk, are analyzed. This study shows that the activity of Bitcointalk forum keeps a direct relationship with the trend in the values of BTC, therefore analysis of this interaction would be a perfect base to support personal investments in a non-regulated market and, to confirm whether cryptocurrency forums show evidences to detect abnormal behaviors in BTC values as well as to predict or estimate these values. The experiment highlights that forum data can explain specific events in the financial field. It also underlines the relevance of quotes (regular mechanism to response a post) at periods: (1) when there is a high concentration of posts around certain topics; (2) when peaks in the BTC price are observed; and, (3) when the BTC price gradually shifts downwards and users intend to sell.",
        "comments": "Journal ref:        Mathematics 2021, 9(4), 411;",
        "date": "27 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10238"
    },
    {
        "doc_id": 118,
        "title": "An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)",
        "authors": [
            "Garvit Arora",
            "Shubhangi Shubhangi",
            "Ying Wu",
            "Xuan Mei"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10162"
    },
    {
        "doc_id": 119,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 120,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 121,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 122,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 123,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 124,
        "title": "Mean-Field SDEs driven by $G$-Brownian Motion",
        "authors": [
            "Karl-Wilhelm Georg Bollweg",
            "Thilo Meyer-Brandis"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We extend the notion of mean-field SDEs to SDEs driven by $G$-Brownian motion. More precisely, we consider a $G$-SDE where the coefficients depend not only on time and the current state but also on the solution as random variable.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09113"
    },
    {
        "doc_id": 125,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 126,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 127,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 128,
        "title": "Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Xi Chen",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "subjects": [
            "General Finance",
            "Cryptography and Security"
        ],
        "abstract": "Lido, the leading Liquid Staking Derivative (LSD) provider on Ethereum, allows users to stake an arbitrary amount of ETH to receive stETH, which can be integrated with Decentralized Finance (DeFi) protocols such as Aave. The composability between Lido and Aave enables a novel strategy called \"leverage staking\", where users stake ETH on Lido to acquire stETH, utilize stETH as collateral on Aave to borrow ETH, and then restake the borrowed ETH on Lido. Users can iteratively execute this process to optimize potential returns based on their risk profile.\n  This paper systematically studies the opportunities and risks associated with leverage staking. We are the first to formalize the leverage staking strategy within the Lido-Aave ecosystem. Our empirical study identifies 262 leverage staking positions on Ethereum, with an aggregated staking amount of 295,243 ETH (482M USD). We discover that 90.13% of leverage staking positions have achieved higher returns than conventional staking. Furthermore, we perform stress tests to evaluate the risk introduced by leverage staking under extreme conditions. We find that leverage staking significantly amplifies the risk of cascading liquidations. We hope this paper can inform and encourage the development of robust risk management approaches to protect the Lido-Aave LSD ecosystem.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08610"
    },
    {
        "doc_id": 129,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 130,
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We consider two data driven approaches, Reinforcement Learning (RL) and Deep Trajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call option without and with transaction cost according to a quadratic hedging P&L objective at maturity (\"variance-optimal hedging\" or \"final quadratic hedging\"). We study the performance of the two approaches under various market environments (modeled via the Black-Scholes and/or the log-normal SABR model) to understand their advantages and limitations. Without transaction costs and in the Black-Scholes model, both approaches match the performance of the variance-optimal Delta hedge. In the log-normal SABR model without transaction costs, they match the performance of the variance-optimal Barlett's Delta hedge. Agents trained on Black-Scholes trajectories with matching initial volatility but used on SABR trajectories match the performance of Bartlett's Delta hedge in average cost, but show substantially wider variance. To apply RL approaches to these problems, P&L at maturity is written as sum of step-wise contributions and variants of RL algorithms are implemented and used that minimize expectation of second moments of such sums.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.07996",
        "date": "20 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08600"
    },
    {
        "doc_id": 131,
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Organizations use cash management models to control balances to both avoid overdrafts and obtain a profit from short-term investments. Most management models are based on control bounds which are derived from the assumption of a particular cash flow probability distribution. In this paper, we relax this strong assumption to fit cash management models to data by means of stochastic and linear programming. We also introduce ensembles of random cash management models which are built by randomly selecting a subsequence of the original cash flow data set. We illustrate our approach by means of a real case study showing that a small random sample of data is enough to fit sufficiently good bound-based models.",
        "comments": "19 pages,6 figures, 1 table",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08548"
    },
    {
        "doc_id": 132,
        "title": "Dynamic portfolio selection under generalized disappointment aversion",
        "authors": [
            "Zongxia Liang",
            "Sheng Wang",
            "Jianming Xia",
            "Fengyi Yuan"
        ],
        "subjects": [
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "This paper addresses the continuous-time portfolio selection problem under generalized disappointment aversion (GDA). The implicit definition of the certainty equivalent within GDA preferences introduces time inconsistency to this problem. We provide the sufficient and necessary conditions for a strategy to be an equilibrium by a fully nonlinear ordinary differential equation (ODE). Through an exploration of the existence and uniqueness of solution to the ODE, we establish the existence and uniqueness of the equilibrium. Our findings indicate that under disappointment aversion (DA) preferences, non-participation in the stock market is the unique equilibrium. The numerical analysis reveals that, under GDA preferences, the investment proportion in the stock market consistently remains smaller than the investment proportion under the classical Expected Utility (EU) theory.",
        "comments": "27 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08323"
    },
    {
        "doc_id": 133,
        "title": "Do backrun auctions protect traders?",
        "authors": [
            "Andrew W. Macpherson"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Distributed, Parallel, and Cluster Computing",
            "Computer Science and Game Theory"
        ],
        "abstract": "We study a new \"laminated\" queueing model for orders on batched trading venues such as decentralised exchanges. The model aims to capture and generalise transaction queueing infrastructure that has arisen to organise MEV activity on public blockchains such as Ethereum, providing convenient channels for sophisticated agents to extract value by acting on end-user order flow by performing arbitrage and related HFT activities. In our model, market orders are interspersed with orders created by arbitrageurs that under idealised conditions reset the marginal price to a global equilibrium between each trade, improving predictability of execution for liquidity traders.\n  If an arbitrageur has a chance to land multiple opportunities in a row, he may attempt to manipulate the execution price of the intervening market order by a probabilistic blind sandwiching strategy. To study how bad this manipulation can get, we introduce and bound a price manipulation coefficient that measures the deviation from global equilibrium of local pricing quoted by a rational arbitrageur. We exhibit cases in which this coefficient is well approximated by a \"zeta value' with interpretable and empirically measurable parameters.",
        "comments": "Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08302"
    },
    {
        "doc_id": 134,
        "title": "Optimal Insurance to Maximize Exponential Utility when Premium is Computed by a Convex Functional",
        "authors": [
            "Jingyi Cao",
            "Dongchen Li",
            "Virginia R. Young",
            "Bin Zou"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Risk Management"
        ],
        "abstract": "We find the optimal indemnity to maximize the expected utility of terminal wealth of a buyer of insurance whose preferences are modeled by an exponential utility. The insurance premium is computed by a convex functional. We obtain a necessary condition for the optimal indemnity; then, because the candidate optimal indemnity is given implicitly, we use that necessary condition to develop a numerical algorithm to compute it. We prove that the numerical algorithm converges to a unique indemnity that, indeed, equals the optimal policy. We also illustrate our results with numerical examples.",
        "comments": "12 pages, 3 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08094"
    },
    {
        "doc_id": 135,
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option Pricing",
        "authors": [
            "Ce Wang"
        ],
        "subjects": [
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two regression models fitted at each time step to price game options. Although the original LSMC can be used to price game options with an enlarged range of path in regression and a modified cashflow updating rule, we identified a drawback of such approach, which motivated us to propose our approach. We implemented numerical examples with benchmarks using binomial tree and numerical PDE, and it showed that our method produces more reliable results comparing to the original LSMC.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08093"
    },
    {
        "doc_id": 136,
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "authors": [
            "Shubham Singh",
            "Mayur Bhat"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Pricing of Securities"
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "comments": "12 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08077"
    },
    {
        "doc_id": 137,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 138,
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "authors": [
            "Samuel Vandak",
            "Geoffrey Goodell"
        ],
        "subjects": [
            "Computers and Society",
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "comments": "34 pages, 19 figures, 5 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07682"
    },
    {
        "doc_id": 139,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 140,
        "title": "Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Design/methodology/approach This research evaluated the databases of SQL, No-SQL and graph databases to compare and contrast efficiency and performance. To perform this experiment the data were collected from multiple sources including stock price and financial news. Python is used as an interface to connect and query databases (to create database structures according to the feed file structure, to load data into tables, objects, to read data , to connect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM (Large language model) including RAG (Retrieval Augmented Generation) with Machine Learning, deep learning, NLP (natural language processing) or Decision Analytics are computationally expensive. Finding a better option to consume less resources and time to get the result. Findings The Graph database of ESG (Environmental, Social and Governance) is comparatively better and can be considered for extended analytics to integrate ESG in business and investment. Practical implications A graph ML with a RAG architecture model can be introduced as a new framework with less computationally expensive LLM application in the equity filtering process for portfolio management. Originality/value Filtering out selective stocks out of two thousand or more listed companies in any stock exchange for active investment, consuming less resource consumption especially memory and energy to integrate artificial intelligence and ESG in business and investment.",
        "comments": "10 pages, 17 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07483"
    },
    {
        "doc_id": 141,
        "title": "Herd Behavior in Optimal Investment: A Dual-Agent Approach with Investment Opinion and Rational Decision Decomposition",
        "authors": [
            "Huisheng Wang",
            "H. Vicky Zhao"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control",
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "In this paper, we study the optimal investment problem involving two agents, where the decision of one agent is influenced by the other. To measure the distance between two agents' decisions, we introduce the average deviation. We formulate the stochastic optimal control problem considering herd behavior and derive the analytical solution through the variational method. We theoretically analyze the impact of users' herd behavior on the optimal decision by decomposing it into their rational decisions, which is called the rational decision decomposition. Furthermore, to quantify the preference for their rational decision over that of the other agent, we introduce the agent's investment opinion. Our study is validated through simulations on real stock data.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07183"
    },
    {
        "doc_id": 142,
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Chris Tanner"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Research in quantitative reasoning within the financial domain indeed necessitates the use of realistic tasks and data, primarily because of the significant impact of decisions made in business and finance. Financial professionals often interact with documents hundreds of pages long, but most research datasets drastically reduce this context length. To address this, we introduce a long-document financial QA task. We augment 7,621 questions from the existing FinQA dataset with full-document context, extending the average context length for each question from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and long-context language models on the augmented data. Our results show that DocFinQA provides challenges for even the strongest, state-of-the-art systems.",
        "comments": "13 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06915"
    },
    {
        "doc_id": 143,
        "title": "A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assessed in a series of numerical experiments involving the Merton jump-diffusion model.",
        "comments": "16 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06740"
    },
    {
        "doc_id": 144,
        "title": "Equity auction dynamics: latent liquidity models with activity acceleration",
        "authors": [
            "Mohammed Salek",
            "Damien Challet",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Finance"
        ],
        "abstract": "Equity auctions display several distinctive characteristics in contrast to continuous trading. As the auction time approaches, the rate of events accelerates causing a substantial liquidity buildup around the indicative price. This, in turn, results in a reduced price impact and decreased volatility of the indicative price. In this study, we adapt the latent/revealed order book framework to the specifics of equity auctions. We provide precise measurements of the model parameters, including order submissions, cancellations, and diffusion rates. Our setup allows us to describe the full dynamics of the average order book during closing auctions in Euronext Paris. These findings support the relevance of the latent liquidity framework in describing limit order book dynamics. Lastly, we analyze the factors contributing to a sub-diffusive indicative price and demonstrate the absence of indicative price predictability.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06724"
    },
    {
        "doc_id": 145,
        "title": "SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks",
        "authors": [
            "Alessio Brini",
            "Giacomo Toscano"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents financial assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with high-frequency prices of the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net shows improved accuracy, compared to alternative econometric and machine-learning-based models. Further, our results show that SpotV2Net maintains accuracy when performing intraday multi-step forecasts. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer, a model-agnostic interpretability tool and thereby uncover subgraphs that are critical to a node's predictions.",
        "comments": "34 pages, 9 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06249"
    },
    {
        "doc_id": 146,
        "title": "CNN-DRL for Scalable Actions in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Haseebullah Jumakhan",
            "Amir Mirzaeinia"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "The published MLP-based DRL in finance has difficulties in learning the dynamics of the environment when the action scale increases. If the buying and selling increase to one thousand shares, the MLP agent will not be able to effectively adapt to the environment. To address this, we designed a CNN agent that concatenates the data from the last ninety days of the daily feature vector to create the CNN input matrix. Our extensive experiments demonstrate that the MLP-based agent experiences a loss corresponding to the initial environment setup, while our designed CNN remains stable, effectively learns the environment, and leads to an increase in rewards.",
        "comments": "10th Annual Conf. on Computational Science & Computational Intelligence",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06179"
    },
    {
        "doc_id": 147,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 148,
        "title": "Multimodal Gen-AI for Fundamental Investment Research",
        "authors": [
            "Lezhi Li",
            "Ting-Yu Chang",
            "Hai Wang"
        ],
        "subjects": [
            "General Finance",
            "Machine Learning"
        ],
        "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.",
        "comments": " ",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06164"
    },
    {
        "doc_id": 149,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 150,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 151,
        "title": "StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks",
        "authors": [
            "Bohan Ma",
            "Yiheng Wang",
            "Yuchao Lu",
            "Tianzixuan Hu",
            "Jinling Xu",
            "Patrick Houlihan"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Machine Learning"
        ],
        "abstract": "Amidst ongoing market recalibration and increasing investor optimism, the U.S. stock market is experiencing a resurgence, prompting the need for sophisticated tools to protect and grow portfolios. Addressing this, we introduce \"Stockformer,\" a cutting-edge deep learning framework optimized for swing trading, featuring the TopKDropout method for enhanced stock selection. By integrating STL decomposition and self-attention networks, Stockformer utilizes the S&P 500's complex data to refine stock return predictions. Our methodology entailed segmenting data for training and validation (January 2021 to January 2023) and testing (February to June 2023). During testing, Stockformer's predictions outperformed ten industry models, achieving superior precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a remarkable accuracy rate of 62.39% in detecting market trends. In our backtests, Stockformer's swing trading strategy yielded a cumulative return of 13.19% and an annualized return of 30.80%, significantly surpassing current state-of-the-art models. Stockformer has emerged as a beacon of innovation in these volatile times, offering investors a potent tool for market forecasting. To advance the field and foster community collaboration, we have open-sourced Stockformer, available at https://github.com/Eric991005/Stockformer.",
        "comments": "Currently under consideration for publication in the International Journal of Forecasting",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06139"
    },
    {
        "doc_id": 152,
        "title": "Quantum Probability Theoretic Asset Return Modeling: A Novel Schr\u00f6dinger-Like Trading Equation and Multimodal Distribution",
        "authors": [
            "Li Lin"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "Quantum theory provides a comprehensive framework for quantifying uncertainty, often applied in quantum finance to explore the stochastic nature of asset returns. This perspective likens returns to microscopic particle motion, governed by quantum probabilities akin to physical laws. However, such approaches presuppose specific microscopic quantum effects in return changes, a premise criticized for lack of guarantee. This paper diverges by asserting that quantum probability is a mathematical extension of classical probability to complex numbers. It isn't exclusively tied to microscopic quantum phenomena, bypassing the need for quantum effects in returns.By directly linking quantum probability's mathematical structure to traders' decisions and market behaviors, it avoids assuming quantum effects for returns and invoking the wave function. The complex phase of quantum probability, capturing transitions between long and short decisions while considering information interaction among traders, offers an inherent advantage over classical probability in characterizing the multimodal distribution of asset returns.Utilizing Fourier decomposition, we derive a Schr\u00f6dinger-like trading equation, where each term explicitly corresponds to implications of market trading. The equation indicates discrete energy levels in financial trading, with returns following a normal distribution at the lowest level. As the market transitions to higher trading levels, a phase shift occurs in the return distribution, leading to multimodality and fat tails. Empirical research on the Chinese stock market supports the existence of energy levels and multimodal distributions derived from this quantum probability asset returns model.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05823"
    },
    {
        "doc_id": 153,
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "authors": [
            "Frank Xing"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Multiagent Systems",
            "General Finance"
        ],
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
        "comments": "15 pages",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05799"
    },
    {
        "doc_id": 154,
        "title": "Super-hedging-pricing formulas and Immediate-Profit arbitrage for market models under random horizon",
        "authors": [
            "Tahir Choulli",
            "Emmanuel Lepinette"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Probability",
            "Pricing of Securities"
        ],
        "abstract": "In this paper, we consider the discrete-time setting, and the market model described by (S,F,T)$. Herein F is the ``public\" flow of information which is available to all agents overtime, S is the discounted price process of d-tradable assets, and T is an arbitrary random time whose occurrence might not be observable via F. Thus, we consider the larger flow G which incorporates F and makes T an observable random time. This framework covers the credit risk theory setting, the life insurance setting and the setting of employee stock option valuation. For the stopped model (S^T,G) and for various vulnerable claims, based on this model, we address the super-hedging pricing valuation problem and its intrinsic Immediate-Profit arbitrage (IP hereafter for short). Our first main contribution lies in singling out the impact of change of prior and/or information on conditional essential supremum, which is a vital tool in super-hedging pricing. The second main contribution consists of describing as explicit as possible how the set of super-hedging prices expands under the stochasticity of T and its risks, and we address the IP arbitrage for (S^T,G) as well. The third main contribution resides in elaborating as explicit as possible pricing formulas for vulnerable claims, and singling out the various informational risks in the prices' dynamics.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05713"
    },
    {
        "doc_id": 155,
        "title": "Boundary conditions at infinity for Black-Scholes equations",
        "authors": [
            "Yukihiro Tsuzuki"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance"
        ],
        "abstract": "We propose numerical procedures for computing the prices of forward contracts where the underlying asset price is a Markovian local martingale. If the underlying process is a strict local martingale, multiple solutions exist for the corresponding Black-Scholes equations, and the derivative prices are characterized as the minimal solutions. Our prices are upper and lower bounds obtained using numerical methods on a finite grid under the respective boundary conditions. These bounds and the boundary values converge to the exact value as the underlying price approaches infinity. The proposed procedures are demonstrated through numerical tests.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05549"
    },
    {
        "doc_id": 156,
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "authors": [
            "Baptiste Lefort",
            "Eric Benhamou",
            "Jean-Jacques Ohana",
            "David Saltiel",
            "Beatrice Guez",
            "Damien Challet"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence"
        ],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05447"
    },
    {
        "doc_id": 157,
        "title": "An adaptive network-based approach for advanced forecasting of cryptocurrency values",
        "authors": [
            "Ali Mehrban",
            "Pegah Ahadian"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This paper describes an architecture for predicting the price of cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy Inference System (ANFIS). Historical data of cryptocurrencies and indexes that are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D), and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach the data are hybrid and backpropagation algorithms, as well as grid partition, subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which are used in data clustering. The architectural performance designed in this paper has been compared with different inputs and neural network models in terms of statistical evaluation criteria. Finally, the proposed method can predict the price of digital currencies in a short time.",
        "comments": "11 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05441"
    },
    {
        "doc_id": 158,
        "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification",
        "authors": [
            "Zinuo You",
            "Pengju Zhang",
            "Jin Zheng",
            "John Cartlidge"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).",
        "comments": "5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05430"
    },
    {
        "doc_id": 159,
        "title": "Introduction of L0 norm and application of L1 and C1 norm in the study of time-series",
        "authors": [
            "Victor Ujaldon Garcia"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Four markets are considered: Cryptocurrencies / South American exchange rate / Spanish Banking indices and European Indices and studied using TDA (Topological Data Analysis) tools. These tools are used to predict and showcase both strengths and weakness of the current TDA tools. In this paper a new tool $L0$ norm is defined and complemented with the already existing $C1$ norm.",
        "comments": "14 pages 8 figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05423"
    },
    {
        "doc_id": 160,
        "title": "Multiple-bubble testing in the cryptocurrency market: a case study of bitcoin",
        "authors": [
            "Sanaz Behzadi",
            "Mahmonir Bayanati",
            "Hamed Nozari"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Economic periods and financial crises have highlighted the importance of evaluating financial markets to investors and researchers in recent decades.",
        "comments": " ",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05417"
    },
    {
        "doc_id": 161,
        "title": "On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors",
        "authors": [
            "Xinshuai Dong",
            "Haoyue Dai",
            "Yewen Fan",
            "Songyao Jin",
            "Sathyamoorthy Rajendran",
            "Kun Zhang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Financial data is generally time series in essence and thus suffers from three fundamental issues: the mismatch in time resolution, the time-varying property of the distribution - nonstationarity, and causal factors that are important but unknown/unobserved. In this paper, we follow a causal perspective to systematically look into these three demons in finance. Specifically, we reexamine these issues in the context of causality, which gives rise to a novel and inspiring understanding of how the issues can be addressed. Following this perspective, we provide systematic solutions to these problems, which hopefully would serve as a foundation for future research in the area.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05414"
    },
    {
        "doc_id": 162,
        "title": "RIVCoin: an alternative, integrated, CeFi/DeFi-Vaulted Cryptocurrency",
        "authors": [
            "Roberto Rivera",
            "Guido Rocco",
            "Massimiliano Marzo",
            "Enrico Talin"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "This whitepaper introduces RIVCoin, a cryptocurrency built on Cosmos, fully stabilized by a diversified portfolio of both CeFi and DeFi assets, available in a digital, non-custodial wallet called RIV Wallet, that aims to provide Users an easy way to access the cryptocurrency markets, compliant to the strictest AML laws and regulations up to date. The token is a cryptocurrency at any time stabilized by a basket of assets: reserves are invested in a portfolio composed long term by 50% of CeFi assets, comprised of Fixed Income, Equity, Mutual and Hedge Funds and 50% of diversified strategies focused on digital assets, mainly staking and LP farming on the major, battle tested DeFi protocols. The cryptocurrency, as well as the dollar before Bretton Woods, is always fully stabilized by vaulted proof of assets: it is born and managed as a decentralized token, minted by a Decentralized Autonomous Organization, and entirely stabilized by assets evaluated by professional independent third parties. Users will trade, pool, and exchange the token without any intermediary, being able to merge them into a Liquidity Pool whose rewards will be composed by both the trading fees and the liquidity rewards derived from the reserve's seigniorage.\n  Users who wish and decide to pool RIVCoin in the Liquidity Pool will receive additional RIVCoin for themselves, and new RIVCoin are minted when the reserves increase in value or in case of purchase of new RIVCoin. The proposed model allows for alignment of incentives: decreasing the risk exposure by wealthier Users, but implicitly increasing that of smaller ones to a level perceived by them as still sustainable. Users indirectly benefit from the access to the rewards of sophisticated cryptocurrency portfolios hitherto precluded to them, without this turning into a disadvantage for the wealthy User.",
        "comments": " ",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05393"
    },
    {
        "doc_id": 163,
        "title": "Optimal Linear Signal: An Unsupervised Machine Learning Framework to Optimize PnL with Linear Signals",
        "authors": [
            "Pierre Renucci"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "This study presents an unsupervised machine learning approach for optimizing Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL generated from signals constructed linearly from exogenous variables. The methodology employs a linear relationship between exogenous variables and the trading signal, with the objective of maximizing the Sharpe Ratio through parameter optimization. Empirical application on an ETF representing U.S. Treasury bonds demonstrates the model's effectiveness, supported by regularization techniques to mitigate overfitting. The study concludes with potential avenues for further development, including generalized time steps and enhanced corrective terms.",
        "comments": "The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05337"
    },
    {
        "doc_id": 164,
        "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks",
        "authors": [
            "Zhang Chern Lee",
            "Wei Yun Tan",
            "Hoong Khen Koo",
            "Wilson Pang"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio",
        "comments": "19 pages, 5 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05264"
    },
    {
        "doc_id": 165,
        "title": "A Mean Field Game between Informed Traders and a Broker",
        "authors": [
            "Philippe Bergault",
            "Leandro S\u00e1nchez-Betancourt"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Optimization and Control"
        ],
        "abstract": "We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G\u00e2teaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05257"
    },
    {
        "doc_id": 166,
        "title": "On the Martingale Schr\u00f6dinger Bridge between Two Distributions",
        "authors": [
            "Marcel Nutz",
            "Johannes Wiesel"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We study a martingale Schr\u00f6dinger bridge problem: given two probability distributions, find their martingale coupling with minimal relative entropy. Our main result provides Schr\u00f6dinger potentials for this coupling. Namely, under certain conditions, the log-density of the optimal coupling is given by a triplet of real functions representing the marginal and martingale constraints. The potentials are also described as the solution of a dual problem.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05209"
    },
    {
        "doc_id": 167,
        "title": "Markowitz Portfolio Construction at Seventy",
        "authors": [
            "Stephen Boyd",
            "Kasper Johansson",
            "Ronald Kahn",
            "Philipp Schiele",
            "Thomas Schmelzer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "More than seventy years ago Harry Markowitz formulated portfolio construction as an optimization problem that trades off expected return and risk, defined as the standard deviation of the portfolio returns. Since then the method has been extended to include many practical constraints and objective terms, such as transaction cost or leverage limits. Despite several criticisms of Markowitz's method, for example its sensitivity to poor forecasts of the return statistics, it has become the dominant quantitative method for portfolio construction in practice. In this article we describe an extension of Markowitz's method that addresses many practical effects and gracefully handles the uncertainty inherent in return statistics forecasting. Like Markowitz's original formulation, the extension is also a convex optimization problem, which can be solved with high reliability and speed.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05080"
    },
    {
        "doc_id": 168,
        "title": "Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin",
        "authors": [
            "Didier Sornette",
            "Yu Zhang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least $200$ weeks with an exponent approximately equal to $0.9$, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between $0.3$ and $2.5$ depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to $-1.5$, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04702"
    },
    {
        "doc_id": 169,
        "title": "Proof of Efficient Liquidity: A Staking Mechanism for Capital Efficient Liquidity",
        "authors": [
            "Arman Abgaryan",
            "Utkarsh Sharma",
            "Joshua Tobkin"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "The Proof of Efficient Liquidity (PoEL) protocol, designed for specialised Proof of Stake (PoS) consensus-based blockchain infrastructures that incorporate intrinsic DeFi applications, aims to support sustainable liquidity bootstrapping and network security. This innovative mechanism efficiently utilises budgeted staking rewards to attract and sustain liquidity through a risk structuring engine and incentive allocation strategy, both of which are designed to maximise capital efficiency. The proposed protocol seeks to serve the dual objective of - (i) capital creation, by efficiently attracting risk capital, and maximising its operational utility for intrinsic DeFi applications, thereby asserting sustainability; and (ii) enhancing the adopting blockchain network's economic security, by augmenting their staking (PoS) mechanism with a harmonious layer seeking to attract a diversity of digital assets. Finally, in the appendix, we seek to generalise the financial incentivisation protocol to the notion of service fee credits, such that it utilises the network's auxiliary services as a means to propagate incentives to attract liquidity and facilitate the network to achieve the critical mass of usage necessary for sustained operations and growth.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04521"
    },
    {
        "doc_id": 170,
        "title": "Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks",
        "authors": [
            "Zan Yu",
            "Lianzeng Zhang"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Risk Management"
        ],
        "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.",
        "comments": "23 pages; 5 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04378"
    },
    {
        "doc_id": 171,
        "title": "Expiring Assets in Automated Market Makers",
        "authors": [
            "Kenan Wood",
            "Maurice Herlihy",
            "Hammurabi Mendes",
            "Jonad Pulaj"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Mathematical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "An automated market maker (AMM) is a state machine that manages pools of assets, allowing parties to buy and sell those assets according to a fixed mathematical formula. AMMs are typically implemented as smart contracts on blockchains, and its prices are kept in line with the overall market price by arbitrage: if the AMM undervalues an asset with respect to the market, an \"arbitrageur\" can make a risk-free profit by buying just enough of that asset to bring the AMM's price back in line with the market.\n  AMMs, however, are not designed for assets that expire: that is, assets that cannot be produced or resold after a specified date. As assets approach expiration, arbitrage may not be able to reconcile supply and demand, and the liquidity providers that funded the AMM may have excessive exposure to risk due to rapid price variations.\n  This paper formally describes the design of a decentralized exchange (DEX) for assets that expire, combining aspects of AMMs and limit-order books. We ensure liveness and market clearance, providing mechanisms for liquidity providers to control their exposure to risk and adjust prices dynamically in response to situations where arbitrage may fail.",
        "comments": "33 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04289"
    },
    {
        "doc_id": 172,
        "title": "Economic Forces in Stock Returns",
        "authors": [
            "Yue Chen",
            "Mohan Li"
        ],
        "subjects": [
            "General Economics",
            "Statistical Finance"
        ],
        "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.",
        "comments": "11 pages, 10 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04132"
    },
    {
        "doc_id": 173,
        "title": "Decomposing Smiles: A Time Change Approach",
        "authors": [
            "Liexin Cheng",
            "Xue Cheng"
        ],
        "subjects": [
            "Pricing of Securities",
            "Mathematical Finance"
        ],
        "abstract": "We develop a novel time-change approach to study the shape of implied volatility smiles. The method is applicable to common semimartingale models, including jump-diffusion, rough volatility and infinite activity models. We approximate the at-the-money skew and curvature with an improved moment-based formula. The moments are further explicitly computed under a time change framework. The limiting skew and curvature for several models are considered. We also test the accuracy of the short-term approximation results on models via numerical methods and on empirical data. Finally, we apply the method to the calibration problem.",
        "comments": " ",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03776"
    },
    {
        "doc_id": 174,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "subjects": [
            "Computational Finance",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation with S&P 100 stocks, MarketSenseAI outperformed the benchmark index by 13%, achieving returns up to 40%, while maintaining a risk profile comparable to the market. These results demonstrate the efficacy of Large Language Models in complex financial decision-making and mark a significant advancement in the integration of AI into financial analysis and investment strategies. This research contributes to the financial AI field, presenting an innovative approach and underscoring the transformative potential of AI in revolutionizing traditional financial analysis investment methodologies.",
        "comments": "15 pages, 12 figures, 12 tables",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03737"
    },
    {
        "doc_id": 175,
        "title": "Structured factor copulas for modeling the systemic risk of European and United States banks",
        "authors": [
            "Hoang Nguyen",
            "Audron\u0117 Virbickait\u0117",
            "M. Concepci\u00f3n Aus\u00edn",
            "Pedro Galeano"
        ],
        "subjects": [
            "Statistical Finance",
            "Applications"
        ],
        "abstract": "In this paper, we employ Credit Default Swaps (CDS) to model the joint and conditional distress probabilities of banks in Europe and the U.S. using factor copulas. We propose multi-factor, structured factor, and factor-vine models where the banks in the sample are clustered according to their geographic location. We find that within each region, the co-dependence between banks is best described using both, systematic and idiosyncratic, financial contagion channels. However, if we consider the banking system as a whole, then the systematic contagion channel prevails, meaning that the distress probabilities are driven by a latent global factor and region-specific factors. In all cases, the co-dependence structure of bank CDS spreads is highly correlated in the tail. The out-of-sample forecasts of several measures of systematic risk allow us to identify the periods of distress in the banking sector over the recent years including the COVID-19 pandemic, the interest rate hikes in 2022, and the banking crisis in 2023.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03443"
    },
    {
        "doc_id": 176,
        "title": "Modelling and Predicting the Conditional Variance of Bitcoin Daily Returns: Comparsion of Markov Switching GARCH and SV Models",
        "authors": [
            "Dennis Koch",
            "Vahidin Jeleskovic",
            "Zahid I. Younas"
        ],
        "subjects": [
            "Statistical Finance",
            "Risk Management"
        ],
        "abstract": "This paper introduces a unique and valuable research design aimed at analyzing Bitcoin price volatility. To achieve this, a range of models from the Markov Switching-GARCH and Stochastic Autoregressive Volatility (SARV) model classes are considered and their out-of-sample forecasting performance is thoroughly examined. The paper provides insights into the rationale behind the recommendation for a two-stage estimation approach, emphasizing the separate estimation of coefficients in the mean and variance equations. The results presented in this paper indicate that Stochastic Volatility models, particularly SARV models, outperform MS-GARCH models in forecasting Bitcoin price volatility. Moreover, the study suggests that in certain situations, persistent simple GARCH models may even outperform Markov-Switching GARCH models in predicting the variance of Bitcoin log returns. These findings offer valuable guidance for risk management experts, highlighting the potential advantages of SARV models in managing and forecasting Bitcoin price volatility.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03393"
    },
    {
        "doc_id": 177,
        "title": "Volatility models in practice: Rough, Path-dependent or Markovian?",
        "authors": [
            "Eduardo Abi Jaber",
            "Shaun",
            "Li"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "An extensive empirical study of the class of Volterra Bergomi models using SPX options data between 2011 and 2022 reveals the following fact-check on two fundamental claims echoed in the rough volatility literature:\n  Do rough volatility models with Hurst index $H \\in (0,1/2)$ really capture well SPX implied volatility surface with very few parameters? No, rough volatility models are inconsistent with the global shape of SPX smiles. They suffer from severe structural limitations imposed by the roughness component, with the Hurst parameter $H \\in (0,1/2)$ controlling the smile in a poor way. In particular, the SPX at-the-money skew is incompatible with the power-law shape generated by rough volatility models. The skew of rough volatility models increases too fast on the short end, and decays too slow on the longer end where \"negative\" $H$ is sometimes needed.\n  Do rough volatility models really outperform consistently their classical Markovian counterparts? No, for short maturities they underperform their one-factor Markovian counterpart with the same number of parameters. For longer maturities, they do not systematically outperform the one-factor model and significantly underperform when compared to an under-parametrized two-factor Markovian model with only one additional calibratable parameter.\n  On the positive side: our study identifies a (non-rough) path-dependent Bergomi model and an under-parametrized two-factor Markovian Bergomi model that consistently outperform their rough counterpart in capturing SPX smiles between one week and three years with only 3 to 4 calibratable parameters. \\end{abstract}",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03345"
    },
    {
        "doc_id": 178,
        "title": "Negatively dependent optimal risk sharing",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Risk Management"
        ],
        "abstract": "We analyze the problem of optimally sharing risk using allocations that exhibit counter-monotonicity, the most extreme form of negative dependence. Counter-monotonic allocations take the form of either \"winner-takes-all\" lotteries or \"loser-loses-all\" lotteries, and we respectively refer to these (normalized) cases as jackpot or scapegoat allocations. Our main theorem, the counter-monotonic improvement theorem, states that for a given set of random variables that are either all bounded from below or all bounded from above, one can always find a set of counter-monotonic random variables such that each component is greater or equal than its counterpart in the convex order. We show that Pareto optimal allocations, if they exist, must be jackpot allocations when all agents are risk seeking. We essentially obtain the opposite when all agents have discontinuous Bernoulli utility functions, as scapegoat allocations maximize the probability of being above the discontinuity threshold. We also consider the case of rank-dependent expected utility (RDU) agents and find conditions which guarantee that RDU agents prefer jackpot allocations. We provide an application for the mining of cryptocurrencies and show that in contrast to risk-averse miners, RDU miners with small computing power never join a mining pool. Finally, we characterize the competitive equilibria with risk-seeking agents, providing a first and second fundamental theorem of welfare economics where all equilibrium allocations are jackpot allocations.",
        "comments": "35 pages, 1 figure, Keywords: Pareto optimality, Risk sharing, Counter-monotonicity, Risk seeking, Rank-dependent expected utility, Cryptocurrency mining pools",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03328"
    },
    {
        "doc_id": 179,
        "title": "Optimal Order Execution subject to Reservation Strategies under Execution Risk",
        "authors": [
            "Xue Cheng",
            "Peng Guo",
            "Tai-ho Wang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under order fill uncertainty. A broker-dealer agency is authorized to execute an order of trading on client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reservation strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon. Optimal strategy in feedback form is obtained in closed form. In the absence of execution risk, the optimal strategies subject to reservation strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reservation strategies using implementation shortfall and target close orders as basis. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03305"
    },
    {
        "doc_id": 180,
        "title": "Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning",
        "authors": [
            "Hong-Gi Shin",
            "Sukhyun Jeong",
            "Eui-Yeon Kim",
            "Sungho Hong",
            "Young-Jin Cho",
            "Yong-Hoon Choi"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence"
        ],
        "abstract": "Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.",
        "comments": "Accepted by ICOIN 2024",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02710"
    },
    {
        "doc_id": 181,
        "title": "Displaying risk in mergers: a diagrammatic approach for exchange ratio determination",
        "authors": [
            "Alessandra Mainini",
            "Enrico Moretto",
            "Daniela Visetti"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This article extends, in a stochastic setting, previous results in the determination of feasible exchange ratios for merging companies. A first outcome is that shareholders of the companies involved in the merging process face both an upper and a lower bounds for acceptable exchange ratios. Secondly, in order for the improved `bargaining region' to be intelligibly displayed, the diagrammatic approach developed by Kulpa is exploited.",
        "comments": " ",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02681"
    },
    {
        "doc_id": 182,
        "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization Approach",
        "authors": [
            "Albert Dorador"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02601"
    },
    {
        "doc_id": 183,
        "title": "Opinion formation in the world trade network",
        "authors": [
            "C\u00e9lestin Coquid\u00e9",
            "Jos\u00e9 Lages",
            "Dima L. Shepelyansky"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Mechanics",
            "Social and Information Networks",
            "Physics and Society"
        ],
        "abstract": "We extend the opinion formation approach to probe the world influence of economical organizations. Our opinion formation model mimics a battle between currencies within the international trade network. Based on the United Nations Comtrade database, we construct the world trade network for the years of the last decade from 2010 to 2020. We consider different core groups constituted by countries preferring to trade in a specific currency. We will consider principally two core groups, namely, 5 Anglo-Saxon countries which prefer to trade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical currency, hereafter called BRI, pegged to their economies. We determine the trade currency preference of the other countries via a Monte Carlo process depending on the direct transactions between the countries. The results obtained in the frame of this mathematical model show that starting from year 2014 the majority of the world countries would have preferred to trade in BRI than USD. The Monte Carlo process reaches a steady state with 3 distinct groups: two groups of countries preferring, whatever is the initial distribution of the trade currency preferences, to trade, one in BRI and the other in USD, and a third group of countries swinging as a whole between USD and BRI depending on the initial distribution of the trade currency preferences. We also analyze the battle between USD, EUR and BRI, and present the reduced Google matrix description of the trade relations between the Anglo-Saxon countries and the BRICS+.",
        "comments": "16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02378"
    },
    {
        "doc_id": 184,
        "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
        "authors": [
            "Zeynep Hilal Kilimci",
            "Mustafa Yalcin"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02124"
    },
    {
        "doc_id": 185,
        "title": "Forecasting Bitcoin Volatility: A Comparative Analysis of Volatility Approaches",
        "authors": [
            "Cristina Chinazzo",
            "Vahidin Jeleskovic"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper conducts an extensive analysis of Bitcoin return series, with a primary focus on three volatility metrics: historical volatility (calculated as the sample standard deviation), forecasted volatility (derived from GARCH-type models), and implied volatility (computed from the emerging Bitcoin options market). These measures of volatility serve as indicators of market expectations for conditional volatility and are compared to elucidate their differences and similarities. The central finding of this study underscores a notably high expected level of volatility, both on a daily and annual basis, across all the methodologies employed. However, it's crucial to emphasize the potential challenges stemming from suboptimal liquidity in the Bitcoin options market. These liquidity constraints may lead to discrepancies in the computed values of implied volatility, particularly in scenarios involving extreme moneyness or maturity. This analysis provides valuable insights into Bitcoin's volatility landscape, shedding light on the unique characteristics and dynamics of this cryptocurrency within the context of financial markets.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02049"
    },
    {
        "doc_id": 186,
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "subjects": [
            "Computational Finance",
            "Numerical Analysis"
        ],
        "abstract": "This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01758"
    },
    {
        "doc_id": 187,
        "title": "Text mining arXiv: a look through quantitative finance papers",
        "authors": [
            "Michele Leonardo Bianchi"
        ],
        "subjects": [
            "Digital Libraries",
            "Information Retrieval",
            "General Finance"
        ],
        "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01751"
    },
    {
        "doc_id": 188,
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "authors": [
            "Lioba Heimbach",
            "Vabuk Pahari",
            "Eric Schertenleib"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.\n  In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum's biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 137 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum's total block value and outline possible mitigations.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01622"
    },
    {
        "doc_id": 189,
        "title": "An arbitrage driven price dynamics of Automated Market Makers in the presence of fees",
        "authors": [
            "Joseph Najnudel",
            "Shen-Ning Tung",
            "Kazutoshi Yamazaki",
            "Ju-Yi Yen"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",
        "comments": " ",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01526"
    },
    {
        "doc_id": 190,
        "title": "Nash Equilibria in Greenhouse Gas Offset Credit Markets",
        "authors": [
            "Liam Welsh",
            "Sebastian Jaimungal"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "In response to the global climate crisis, governments worldwide are introducing legislation to reduce greenhouse gas (GHG) emissions to help mitigate environmental catastrophes. One method to encourage emission reductions is to incentivize carbon capturing and carbon reducing projects while simultaneously penalising excess GHG output. Firms that invest in carbon capturing projects or reduce their emissions can receive offset credits (OCs) in return. These OCs can be used for regulatory purposes to offset their excess emissions in a compliance period. OCs may also be traded between firms. Thus, firms have the choice between investing in projects to generate OCs or to trade OCs. In this work, we present a novel market framework and characterise the optimal behaviour of GHG OC market participants in both single-player and two-player settings. We analyse both a single-period and multi-period setting. As the market model does not elicit a closed form solution, we develop a numerical methodology to estimate players' optimal behaviours in accordance to the Nash equilibria. Our findings indicate the actions players take are dependent on the scale of their project opportunities as well as their fellow market participants. We demonstrate the importance of behaving optimally via simulations in order to offset emission penalties and the importance of investing in GHG reducing or capturing projects from a financial perspective.",
        "comments": "MSC Class:          91G99; 35Q91; 91-08; 91A80; 91B74",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01427"
    },
    {
        "doc_id": 191,
        "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces",
        "authors": [
            "Farshud Sorourifar",
            "Thomas Banker",
            "Joel A. Paulson"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.",
        "comments": "9 pages, 2 figures consisting of 6 and 4 plots, accepted to NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01398"
    },
    {
        "doc_id": 192,
        "title": "Almost Perfect Shadow Prices",
        "authors": [
            "Eberhard Mayerhofer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a na\u00efve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",
        "comments": "15 pages",
        "date": "1 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00970"
    },
    {
        "doc_id": 193,
        "title": "A Portfolio's Common Causal Conditional Risk-neutral PDE",
        "authors": [
            "Alejandro Rodriguez Dominguez"
        ],
        "subjects": [
            "Portfolio Management",
            "Mathematical Finance"
        ],
        "abstract": "Portfolio's optimal drivers for diversification are common causes of the constituents' correlations. A closed-form formula for the conditional probability of the portfolio given its optimal common drivers is presented, with each pair constituent-common driver joint distribution modelled by Gaussian copulas. A conditional risk-neutral PDE is obtained for this conditional probability as a system of copulas' PDEs, allowing for dynamical risk management of a portfolio as shown in the experiments. Implied conditional portfolio volatilities and implied weights are new risk metrics that can be dynamically monitored from the PDEs or obtained from their solution.",
        "comments": "6 pages, 4 figures, Mathematical and Statistical Methods for Actuarial Sciences and Finance - MAF2024",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00949"
    },
    {
        "doc_id": 194,
        "title": "Intraday Trading Algorithm for Predicting Cryptocurrency Price Movements Using Twitter Big Data Analysis",
        "authors": [
            "Vahidin Jeleskovic",
            "Stephen Mackay"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Cryptocurrencies have emerged as a novel financial asset garnering significant attention in recent years. A defining characteristic of these digital currencies is their pronounced short-term market volatility, primarily influenced by widespread sentiment polarization, particularly on social media platforms such as Twitter. Recent research has underscored the correlation between sentiment expressed in various networks and the price dynamics of cryptocurrencies. This study delves into the 15-minute impact of informative tweets disseminated through foundation channels on trader behavior, with a focus on potential outcomes related to sentiment polarization. The primary objective is to identify factors that can predict positive price movements and potentially be leveraged through a trading algorithm. To accomplish this objective, we conduct a conditional examination of return and excess return rates within the 15 minutes following tweet publication. The empirical findings reveal statistically significant increases in return rates, particularly within the initial three minutes following tweet publication. Notably, adverse effects resulting from the messages were not observed. Surprisingly, sentiments were found to have no discerni-ble impact on cryptocurrency price movements. Our analysis further identifies that inves-tors are primarily influenced by the quality of tweet content, as reflected in the choice of words and tweet volume. While the basic trading algorithm presented in this study does yield some benefits within the 15-minute timeframe, these benefits are not statistically significant. Nevertheless, it serves as a foundational framework for potential enhance-ments and further investigations.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00603"
    },
    {
        "doc_id": 195,
        "title": "On the implied volatility of Inverse and Quanto Inverse options under stochastic volatility models",
        "authors": [
            "Elisa Al\u00f2s",
            "Eulalia Nualart",
            "Makar Pravosud"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "In this paper we study short-time behavior of the at-the-money implied volatility for Inverse and Quanto Inverse European options with fixed strike price. The asset price is assumed to follow a general stochastic volatility process. Using techniques of the Malliavin calculus such as the anticipating Ito's formula we first compute the level of the implied volatility of the option when the maturity converges to zero. Then, we find a short maturity asymptotic formula for the skew of the implied volatility that depends on the roughness of the volatility model. We apply our general results to the SABR and fractional Bergomi models, and provide some numerical simulations that confirm the accurateness of the asymptotic formula for the skew.",
        "comments": "arXiv admin note: text overlap with arXiv:2308.15341, arXiv:2208.01353",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00539"
    },
    {
        "doc_id": 196,
        "title": "Financial Time-Series Forecasting: Towards Synergizing Performance And Interpretability Within a Hybrid Machine Learning Approach",
        "authors": [
            "Shun Liu",
            "Kexin Wu",
            "Chufeng Jiang",
            "Bin Huang",
            "Danqing Ma"
        ],
        "subjects": [
            "Machine Learning",
            "Statistical Finance"
        ],
        "abstract": "In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered substantial attention due to its potential impact on financial markets and investment strategies. This paper propose a comparative study on hybrid machine learning algorithms and leverage on enhancing model interpretability. Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM), decision tree regressors are introduced. Through the grounded experiments, we observe linear regressor achieves the best performance among candidate models. For the interpretability, we carry out a systematic overview on the preprocessing techniques of time-series statistics, including decomposition, auto-correlational function, exponential triple forecasting, which aim to excavate latent relations and complex patterns appeared in the financial time-series forecasting. We believe this work may derive more attention and inspire more researches in the realm of time-series analysis and its realistic applications.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00534"
    },
    {
        "doc_id": 197,
        "title": "Optimization of portfolios with cryptocurrencies: Markowitz and GARCH-Copula model approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Claudio Latini",
            "Zahid I. Younas",
            "Mamdouh A. S. Al-Faryan"
        ],
        "subjects": [
            "Portfolio Management",
            "Applications"
        ],
        "abstract": "The growing interest in cryptocurrencies has drawn the attention of the financial world to this innovative medium of exchange. This study aims to explore the impact of cryptocurrencies on portfolio performance. We conduct our analysis retrospectively, assessing the performance achieved within a specific time frame by three distinct portfolios: one consisting solely of equities, bonds, and commodities; another composed exclusively of cryptocurrencies; and a third, which combines both 'traditional' assets and the best-performing cryptocurrency from the second portfolio.To achieve this, we employ the classic variance-covariance approach, utilizing the GARCH-Copula and GARCH-Vine Copula methods to calculate the risk structure. The optimal asset weights within the optimized portfolios are determined through the Markowitz optimization problem. Our analysis predominantly reveals that the portfolio comprising both cryptocurrency and traditional assets exhibits a higher Sharpe ratio from a retrospective viewpoint and demonstrates more stable performances from a prospective perspective. We also provide an explanation for our choice of portfolio optimization based on the Markowitz approach rather than CVaR and ES.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00507"
    },
    {
        "doc_id": 198,
        "title": "A framework for the valuation of insurance liabilities by production cost",
        "authors": [
            "Christoph Moehr"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "This paper sets out a framework for the valuation of insurance liabilities that is intended to be economically realistic, elementary, reasonably practically applicable, and as a special case to provide a basis for the valuation in regulatory solvency systems such as Solvency II and the SST. The valuation framework is based on the cost of producing the liabilities to an insurance company that is subject to solvency regulation (regulatory solvency capital requirements) and insolvency laws (consequences of failure) in finite discrete time. Starting from the replication approach of classical no-arbitrage theory, the framework additionally considers the nature and cost of capital (expressed by a ``financiability condition\"), that the liabilities may be required to be fulfilled only ``in sufficiently many cases\" (expressed by a ``fulfillment condition\"), production using ``fully illiquid\" assets in addition to tradables, and the asymmetry between assets and liabilities. We identify necessary and sufficient conditions on the capital investment under which the framework recovers the market prices of tradables, investigate extending production to take account of insolvency, implications of using illiquid assets in the production, and show how Solvency II and SST valuation can be derived with specific assumptions.",
        "comments": "35 pages, no figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00263"
    },
    {
        "doc_id": 199,
        "title": "Enhancing CVaR portfolio optimisation performance with GAM factor models",
        "authors": [
            "Davide Lauria",
            "W. Brent Lindquist",
            "Svetlozar T. Rachev"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "We propose a discrete-time econometric model that combines autoregressive filters with factor regressions to predict stock returns for portfolio optimisation purposes. In particular, we test both robust linear regressions and general additive models on two different investment universes composed of the Dow Jones Industrial Average and the Standard & Poor's 500 indexes, and we compare the out-of-sample performances of mean-CVaR optimal portfolios over a horizon of six years. The results show a substantial improvement in portfolio performances when the factor model is estimated with general additive models.",
        "comments": " ",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.00188"
    },
    {
        "doc_id": 200,
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "authors": [
            "Hanxue Gu",
            "Roy Colglazier",
            "Haoyu Dong",
            "Jikai Zhang",
            "Yaqian Chen",
            "Zafer Yildiz",
            "Yuwen Chen",
            "Lin Li",
            "Jichen Yang",
            "Jay Willhite",
            "Alex M. Meyer",
            "Brian Guo",
            "Yashvi Atul Shah",
            "Emily Luo",
            "Shipra Rajput",
            "Sally Kuehn",
            "Clark Bulleit",
            "Kevin A. Wu",
            "Jisoo Lee",
            "Brandon Ramirez",
            "Darui Lu",
            "Jay M. Levin",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "comments": "15 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12974"
    },
    {
        "doc_id": 201,
        "title": "On the Efficacy of Text-Based Input Modalities for Action Anticipation",
        "authors": [
            "Apoorva Beedu",
            "Karan Samel",
            "Irfan Essa"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "Although the task of anticipating future actions is highly uncertain, information from additional modalities help to narrow down plausible action choices. Each modality provides different environmental context for the model to learn from. While previous multi-modal methods leverage information from modalities such as video and audio, we primarily explore how text inputs for actions and objects can also enable more accurate action anticipation. Therefore, we propose a Multi-modal Anticipative Transformer (MAT), an attention-based video transformer architecture that jointly learns from multi-modal features and text captions. We train our model in two-stages, where the model first learns to predict actions in the video clip by aligning with captions, and during the second stage, we fine-tune the model to predict future actions. Compared to existing methods, MAT has the advantage of learning additional environmental context from two kinds of text inputs: action descriptions during the pre-training stage, and the text inputs for detected objects and actions during modality feature fusion. Through extensive experiments, we evaluate the effectiveness of the pre-training stage, and show that our model outperforms previous methods on all datasets. In addition, we examine the impact of object and action information obtained via text and perform extensive ablations. We evaluate the performance on on three datasets: EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that text descriptions do indeed aid in more effective action anticipation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12972"
    },
    {
        "doc_id": 202,
        "title": "Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via Cyclic Schedulers",
        "authors": [
            "Sahan Liyanaarachchi",
            "Sennur Ulukus",
            "Nail Akar"
        ],
        "subjects": [
            "Information Theory",
            "Networking and Internet Architecture",
            "Systems and Control"
        ],
        "abstract": "In a communication setting where multiple sources share a single channel to provide status updates to a remote monitor, source transmissions need to be scheduled appropriately to maintain timely communication between each of the sources and the monitor. We consider age-agnostic scheduling policies which are advantageous due to their simplicity of implementation. Further, we focus on a special class of age-agnostic policies, called cyclic schedulers, where each source is scheduled based on a fixed cyclic pattern. We use weighted average age of information (AoI) to quantify the timeliness of communication. We develop a Markov chain formulation to compute the exact mean AoI for the case of two-source cyclic schedulers. Based on the obtained age expression, we develop an algorithm that generates near-optimal cyclic schedulers to minimize the weighted average AoI for two heterogeneous sources, in the presence of channel errors.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12962"
    },
    {
        "doc_id": 203,
        "title": "On Simplified 3D Finite Element Simulations of Three-core Armored Power Cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Marius Hatlo",
            "Pedro Cruz-Romero"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper analyzes different ways to simulate electromagnetically three-core armored cables in 3D by means of the finite element method. Full periodic models, as lengthy as 36 m, are developed to evaluate the accuracy when simulating only a small portion of the cable, as commonly employed in the literature. The adequate length and boundary conditions for having the same accuracy of full periodic models are also studied. To this aim, five medium voltage and high voltage armored cables are analyzed, obtaining the minimum length of the cable that may be simulated for having accurate results in shorter time and with less computational burden. This also results in the proposal of a new method comprising the advantages of short geometries and the applicability of periodic boundary conditions. Its accuracy is compared with experimental measurements and the IEC standard for 145 kV and 245 kV cables. The results show a very good agreement between simulations and measurements (errors below 4 %), obtaining a reduction in the computation time of about 90 %. This new method brings a more effective tool for saving time and computational resources in cable design and the development of new analytical expressions for improving the IEC standard.",
        "comments": "Journal ref:        Energies 2018, 11, 3081",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12943"
    },
    {
        "doc_id": 204,
        "title": "Neural deformation fields for template-based reconstruction of cortical surfaces from MRI",
        "authors": [
            "Fabian Bongratz",
            "Anne-Marie Rickmann",
            "Christian Wachinger"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The reconstruction of cortical surfaces is a prerequisite for quantitative analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing segmentation-based methods separate the surface registration from the surface extraction, which is computationally inefficient and prone to distortions. We introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that learns a deformation field from a brain template to the cortical surfaces of an MRI scan. To this end, we present a geometric neural network that models the deformation-describing ordinary differential equation in a continuous manner. The network architecture comprises convolutional and graph-convolutional layers, which allows it to work with images and meshes at the same time. V2C-Flow is not only very fast, requiring less than two seconds to infer all four cortical surfaces, but also establishes vertex-wise correspondences to the template during reconstruction. In addition, V2C-Flow is the first approach for cortex reconstruction that models white matter and pial surfaces jointly, therefore avoiding intersections between them. Our comprehensive experiments on internal and external test data demonstrate that V2C-Flow results in cortical surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that the established correspondences are more consistent than in FreeSurfer and that they can directly be utilized for cortex parcellation and group analyses of cortical thickness.",
        "comments": "To appear in Medical Image Analysis",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12938"
    },
    {
        "doc_id": 205,
        "title": "Segmentation of tibiofemoral joint tissues from knee MRI using MtRA-Unet and incorporating shape information: Data from the Osteoarthritis Initiative",
        "authors": [
            "Akshay Daydar",
            "Alik Pramanick",
            "Arijit Sur",
            "Subramani Kanagaraj"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Knee Osteoarthritis (KOA) is the third most prevalent Musculoskeletal Disorder (MSD) after neck and back pain. To monitor such a severe MSD, a segmentation map of the femur, tibia and tibiofemoral cartilage is usually accessed using the automated segmentation algorithm from the Magnetic Resonance Imaging (MRI) of the knee. But, in recent works, such segmentation is conceivable only from the multistage framework thus creating data handling issues and needing continuous manual inference rendering it unable to make a quick and precise clinical diagnosis. In order to solve these issues, in this paper the Multi-Resolution Attentive-Unet (MtRA-Unet) is proposed to segment the femur, tibia and tibiofemoral cartilage automatically. The proposed work has included a novel Multi-Resolution Feature Fusion (MRFF) and Shape Reconstruction (SR) loss that focuses on multi-contextual information and structural anatomical details of the femur, tibia and tibiofemoral cartilage. Unlike previous approaches, the proposed work is a single-stage and end-to-end framework producing a Dice Similarity Coefficient (DSC) of 98.5% for the femur, 98.4% for the tibia, 89.1% for Femoral Cartilage (FC) and 86.1% for Tibial Cartilage (TC) for critical MRI slices that can be helpful to clinicians for KOA grading. The time to segment MRI volume (160 slices) per subject is 22 sec. which is one of the fastest among state-of-the-art. Moreover, comprehensive experimentation on the segmentation of FC and TC which is of utmost importance for morphology-based studies to check KOA progression reveals that the proposed method has produced an excellent result with binary segmentation",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12932"
    },
    {
        "doc_id": 206,
        "title": "Emotion-Aware Contrastive Adaptation Network for Source-Free Cross-Corpus Speech Emotion Recognition",
        "authors": [
            "Yan Zhao",
            "Jincen Wang",
            "Cheng Lu",
            "Sunan Li",
            "Bj\u00f6rn Schuller",
            "Yuan Zong",
            "Wenming Zheng"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Cross-corpus speech emotion recognition (SER) aims to transfer emotional knowledge from a labeled source corpus to an unlabeled corpus. However, prior methods require access to source data during adaptation, which is unattainable in real-life scenarios due to data privacy protection concerns. This paper tackles a more practical task, namely source-free cross-corpus SER, where a pre-trained source model is adapted to the target domain without access to source data. To address the problem, we propose a novel method called emotion-aware contrastive adaptation network (ECAN). The core idea is to capture local neighborhood information between samples while considering the global class-level adaptation. Specifically, we propose a nearest neighbor contrastive learning to promote local emotion consistency among features of highly similar samples. Furthermore, relying solely on nearest neighborhoods may lead to ambiguous boundaries between clusters. Thus, we incorporate supervised contrastive learning to encourage greater separation between clusters representing different emotions, thereby facilitating improved class-level adaptation. Extensive experiments indicate that our proposed ECAN significantly outperforms state-of-the-art methods under the source-free cross-corpus SER setting on several speech emotion corpora.",
        "comments": "Accepted by ICASSP 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12925"
    },
    {
        "doc_id": 207,
        "title": "Deep multitask neural networks for solving some stochastic optimal control problems",
        "authors": [
            "Christian Yeo"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.",
        "comments": "8 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12923"
    },
    {
        "doc_id": 208,
        "title": "Inertial Sensors for Human Motion Analysis: A Comprehensive Review",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Inertial motion analysis is having a growing interest during the last decades due to its advantages over classical optical systems. The technological solution based on inertial measurement units allows the measurement of movements in daily living environments, such as in everyday life, which is key for a realistic assessment and understanding of movements. This is why research in this field is still developing and different approaches are proposed. This presents a systematic review of the different proposals for inertial motion analysis found in the literature. The search strategy has been carried out on eight different platforms, including journal articles and conference proceedings, which are written in English and published until August 2022. The results are analyzed in terms of the publishers, the sensors used, the applications, the monitored units, the algorithms of use, the participants of the studies, and the validation systems employed. In addition, we delve deeply into the machine learning techniques proposed in recent years and in the approaches to reduce the estimation error. In this way, we show an overview of the research carried out in this field, going into more detail in recent years, and providing some research directions for future work",
        "comments": "ACM Class:          A.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12919"
    },
    {
        "doc_id": 209,
        "title": "Advancing Glitch Classification in Gravity Spy: Multi-view Fusion with Attention-based Machine Learning for Advanced LIGO's Fourth Observing Run",
        "authors": [
            "Yunan Wu",
            "Michael Zevin",
            "Christopher P. L. Berry",
            "Kevin Crowston",
            "Carsten \u00d8sterlund",
            "Zoheyr Doctor",
            "Sharan Banagiri",
            "Corey B. Jackson",
            "Vicky Kalogera",
            "Aggelos K. Katsaggelos"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "Instrumentation and Methods for Astrophysics",
            "Image and Video Processing"
        ],
        "abstract": "The first successful detection of gravitational waves by ground-based observatories, such as the Laser Interferometer Gravitational-Wave Observatory (LIGO), marked a revolutionary breakthrough in our comprehension of the Universe. However, due to the unprecedented sensitivity required to make such observations, gravitational-wave detectors also capture disruptive noise sources called glitches, potentially masking or appearing as gravitational-wave signals themselves. To address this problem, a community-science project, Gravity Spy, incorporates human insight and machine learning to classify glitches in LIGO data. The machine learning classifier, integrated into the project since 2017, has evolved over time to accommodate increasing numbers of glitch classes. Despite its success, limitations have arisen in the ongoing LIGO fourth observing run (O4) due to its architecture's simplicity, which led to poor generalization and inability to handle multi-time window inputs effectively. We propose an advanced classifier for O4 glitches. Our contributions include evaluating fusion strategies for multi-time window inputs, using label smoothing to counter noisy labels, and enhancing interpretability through attention module-generated weights. This development seeks to enhance glitch classification, aiding in the ongoing exploration of gravitational-wave phenomena.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12913"
    },
    {
        "doc_id": 210,
        "title": "Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network",
        "authors": [
            "Steven Rivetti",
            "Emil Bjornson",
            "Mikael Skoglund"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "In this paper, we study a cell-free multiple-input multiple-output network equipped with integrated sensing and communication (ISAC) access points (APs). The distributed APs are used to jointly serve the communication needs of user equipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve). To increase the system's robustness towards said Eve, we develop an ISAC waveform model that includes artificial noise (AN) aimed at degrading the Eve channel quality. The central processing unit receives the observations from each AP and calculates the optimal precoding and AN covariance matrices by solving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB) minimization problem. Simulation results highlight an underlying trade-off between sensing and communication performances: in particular, the UEs signal-to-noise and interference ratio and the maximum Eve's signal to noise ratio are directly proportional to the CRB. Furthermore, the optimal AN covariance matrix is rank-1 and has a peak in the eve's direction, leading to a surprising inverse-proportionality between the UEs-Eve distance and optimal-CRB magnitude.",
        "comments": "To appear at WCNC 2024. \\c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12901"
    },
    {
        "doc_id": 211,
        "title": "An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping with Applications to Multicomponent Diffusion and Relaxation MRI",
        "authors": [
            "Yunsong Liu",
            "Debdut Mandal",
            "Congyu Liao",
            "Kawin Setsompop",
            "Justin P. Haldar"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "It has been previously shown that high-quality partial volume tissue compartment maps can be obtained by combining multiparametric contrast-encoded MRI data acquisition methods with spatially-regularized spectroscopic image estimation techniques. However, the advantages of this combined approach generally come at the expense of substantial computational complexity. In this work, we propose a new algorithm to solve this kind of estimation problem more efficiently. Our algorithm is based on the linearized alternating directions method of multipliers (LADMM), and relies on the introduction of novel quadratic penalty terms to substantially simplify the subproblems that must be solved at each iteration. We evaluate this algorithm on a variety of different estimation problems (diffusion-relaxation, relaxation-relaxation, relaxometry, and magnetic resonance fingerprinting), where we consistently observe substantial (roughly 5$\\times$-80$\\times$) speed improvements. We expect that this new faster algorithm will lower practical barriers to using spatial regularization and multiparametric contrast-encoded MRI data acquisition methods for partial volume compartment mapping.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12890"
    },
    {
        "doc_id": 212,
        "title": "A database of physical therapy exercises with variability of execution collected by wearable sensors",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This document introduces the PHYTMO database, which contains data from physical therapies recorded with inertial sensors, including information from an optical reference system. PHYTMO includes the recording of 30 volunteers, aged between 20 and 70 years old. A total amount of 6 exercises and 3 gait variations were recorded. The volunteers performed two series with a minimum of 8 repetitions in each one. PHYTMO includes magneto-inertial data, together with a highly accurate location and orientation in the 3D space provided by the optical system. The files were stored in CSV format to ensure its usability. The aim of this dataset is the availability of data for two main purposes: the analysis of techniques for the identification and evaluation of exercises using inertial sensors and the validation of inertial sensor-based algorithms for human motion monitoring. Furthermore, the database stores enough data to apply Machine Learning-based algorithms. The participants' age range is large enough to establish age-based metrics for the exercises evaluation or the study of differences in motions between different groups.",
        "comments": "ACM Class:          E.5",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12868"
    },
    {
        "doc_id": 213,
        "title": "Simultaneous exercise recognition and evaluation in prescribed routines: Approach to virtual coaches",
        "authors": [
            "Sara Garc\u00eda-de-Villa",
            "David Casillas-P\u00e9rez",
            "Ana Jim\u00e9nez-Mart\u00edn",
            "Juan Jes\u00fas Garc\u00eda-Dom\u00ednguez"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Signal Processing"
        ],
        "abstract": "Home-based physical therapies are effective if the prescribed exercises are correctly executed and patients adhere to these routines. This is specially important for older adults who can easily forget the guidelines from therapists. Inertial Measurement Units (IMUs) are commonly used for tracking exercise execution giving information of patients' motion data. In this work, we propose the use of Machine Learning techniques to recognize which exercise is being carried out and to assess if the recognized exercise is properly executed by using data from four IMUs placed on the person limbs. To the best of our knowledge, both tasks have never been addressed together as a unique complex task before. However, their combination is needed for the complete characterization of the performance of physical therapies. We evaluate the performance of six machine learning classifiers in three contexts: recognition and evaluation in a single classifier, recognition of correct exercises, excluding the wrongly performed exercises, and a two-stage approach that first recognizes the exercise and then evaluates it. We apply our proposal to a set of 8 exercises of the upper-and lower-limbs designed for maintaining elderly people health status. To do so, the motion of volunteers were monitored with 4 IMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initial scenarios. In the third one, the recognition provides an accuracy of 96.2 \\%, whereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This work proves the feasibility of IMUs for a complete monitoring of physical therapies in which we can get information of which exercise is being performed and its quality, as a basis for designing virtual coaches.",
        "comments": "ACM Class:          I.2.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12857"
    },
    {
        "doc_id": 214,
        "title": "Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization",
        "authors": [
            "Prachi Singh",
            "Sriram Ganapathy"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Artificial Intelligence",
            "Sound"
        ],
        "abstract": "Speaker diarization, the task of segmenting an audio recording based on speaker identity, constitutes an important speech pre-processing step for several downstream applications. The conventional approach to diarization involves multiple steps of embedding extraction and clustering, which are often optimized in an isolated fashion. While end-to-end diarization systems attempt to learn a single model for the task, they are often cumbersome to train and require large supervised datasets. In this paper, we propose an end-to-end supervised hierarchical clustering algorithm based on graph neural networks (GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The E-SHARC approach uses front-end mel-filterbank features as input and jointly learns an embedding extractor and the GNN clustering module, performing representation learning, metric learning, and clustering with end-to-end optimization. Further, with additional inputs from an external overlap detector, the E-SHARC approach is capable of predicting the speakers in the overlapping speech regions. The experimental evaluation on several benchmark datasets like AMI, VoxConverse and DISPLACE, illustrates that the proposed E-SHARC framework improves significantly over the state-of-art diarization systems.",
        "comments": "10 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12850"
    },
    {
        "doc_id": 215,
        "title": "Learning safety critics via a non-contractive binary bellman operator",
        "authors": [
            "Agustin Castellano",
            "Hancheng Min",
            "Juan Andr\u00e9s Bazerque",
            "Enrique Mallada"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "The inability to naturally enforce safety in Reinforcement Learning (RL), with limited failures, is a core challenge impeding its use in real-world applications. One notion of safety of vast practical relevance is the ability to avoid (unsafe) regions of the state space. Though such a safety goal can be captured by an action-value-like function, a.k.a. safety critics, the associated operator lacks the desired contraction and uniqueness properties that the classical Bellman operator enjoys. In this work, we overcome the non-contractiveness of safety critic operators by leveraging that safety is a binary property. To that end, we study the properties of the binary safety critic associated with a deterministic dynamical system that seeks to avoid reaching an unsafe region. We formulate the corresponding binary Bellman equation (B2E) for safety and study its properties. While the resulting operator is still non-contractive, we fully characterize its fixed points representing--except for a spurious solution--maximal persistently safe regions of the state space that can always avoid failure. We provide an algorithm that, by design, leverages axiomatic knowledge of safe data to avoid spurious fixed points.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12849"
    },
    {
        "doc_id": 216,
        "title": "Optimal Evasion from a Sensing-Limited Pursuer",
        "authors": [
            "Dipankar Maity",
            "Alexander Von Moll",
            "Daigo Shishika",
            "Michael Dorothy"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Systems and Control"
        ],
        "abstract": "This paper investigates a partial-information pursuit evasion game in which the Pursuer has a limited-range sensor to detect the Evader. Given a fixed final time, we derive the optimal evasion strategy for the Evader to maximize its distance from the pursuer at the end. Our analysis reveals that in certain parametric regimes, the optimal Evasion strategy involves a 'risky' maneuver, where the Evader's trajectory comes extremely close to the pursuer's sensing boundary before moving behind the Pursuer. Additionally, we explore a special case in which the Pursuer can choose the final time. In this scenario, we determine a (Nash) equilibrium pair for both the final time and the evasion strategy.",
        "comments": "Accepted for presentation at, and publication in the proceedings of, the 2024 American Control Conference",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12848"
    },
    {
        "doc_id": 217,
        "title": "Digital Twin-Based Network Management for Better QoE in Multicast Short Video Streaming",
        "authors": [
            "Xinyu Huang",
            "Shisheng Hu",
            "Haojun Yang",
            "Xinghan Wang",
            "Yingying Pei",
            "Xuemin Shen"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Image and Video Processing"
        ],
        "abstract": "Multicast short video streaming can enhance bandwidth utilization by enabling simultaneous video transmission to multiple users over shared wireless channels. The existing network management schemes mainly rely on the sequential buffering principle and general quality of experience (QoE) model, which may deteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporal variation. In this paper, we propose a digital twin (DT)-based network management scheme to enhance QoE. Firstly, user status emulated by the DT is utilized to estimate the transmission capabilities and watching probability distributions of sub-multicast groups (SMGs) for an adaptive segment buffering. The SMGs' buffers are aligned to the unique virtual buffers managed by the DT for a fine-grained buffer update. Then, a multicast QoE model consisting of rebuffering time, video quality, and quality variation is developed, by considering the mutual influence of segment buffering among SMGs. Finally, a joint optimization problem of segment version selection and slot division is formulated to maximize QoE. To efficiently solve the problem, a data-model-driven algorithm is proposed by integrating a convex optimization method and a deep reinforcement learning algorithm. Simulation results based on the real-world dataset demonstrate that the proposed DT-based network management scheme outperforms benchmark schemes in terms of QoE improvement.",
        "comments": "13 pages, 12 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12826"
    },
    {
        "doc_id": 218,
        "title": "Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms",
        "authors": [
            "Esmaeel Mohammadi",
            "Mikkel Stokholm-Bjerregaard",
            "Aviaja Anna Hansen",
            "Per Halkj\u00e6r Nielsen",
            "Daniel Ortiz-Arroyo",
            "Petar Durdevic"
        ],
        "subjects": [
            "Systems and Control",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Phosphorus removal is vital in wastewater treatment to reduce reliance on limited resources. Deep reinforcement learning (DRL) is a machine learning technique that can optimize complex and nonlinear systems, including the processes in wastewater treatment plants, by learning control policies through trial and error. However, applying DRL to chemical and biological processes is challenging due to the need for accurate simulators. This study trained six models to identify the phosphorus removal process and used them to create a simulator for the DRL environment. Although the models achieved high accuracy (>97%), uncertainty and incorrect prediction behavior limited their performance as simulators over longer horizons. Compounding errors in the models' predictions were identified as one of the causes of this problem. This approach for improving process control involves creating simulation environments for DRL algorithms, using data from supervisory control and data acquisition (SCADA) systems with a sufficient historical horizon without complex system modeling or parameter estimation.",
        "comments": "Journal Paper",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12822"
    },
    {
        "doc_id": 219,
        "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach",
        "authors": [
            "Rohit Singh",
            "Anil Kumar Yerrapragada",
            "Jeeva Keshav S",
            "Radha Krishna Ganti"
        ],
        "subjects": [
            "Information Theory",
            "Artificial Intelligence",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Random Access is an important step in enabling the initial attachment of a User Equipment (UE) to a Base Station (gNB). The UE identifies itself by embedding a Preamble Index (RAPID) in the phase rotation of a known base sequence, which it transmits on the Physical Random Access Channel (PRACH). The signal on the PRACH also enables the estimation of propagation delay, often known as Timing Advance (TA), which is induced by virtue of the UE's position. Traditional receivers estimate the RAPID and TA using correlation-based techniques. This paper presents an alternative receiver approach that uses AI/ML models, wherein two neural networks are proposed, one for the RAPID and one for the TA. Different from other works, these two models can run in parallel as opposed to sequentially. Experiments with both simulated data and over-the-air hardware captures highlight the improved performance of the proposed AI/ML-based techniques compared to conventional correlation methods.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12803"
    },
    {
        "doc_id": 220,
        "title": "Deep Learning-based Target-To-User Association in Integrated Sensing and Communication Systems",
        "authors": [
            "Lorenzo Cazzella",
            "Marouan Mizmizi",
            "Dario Tagliaferri",
            "Damiano Badini",
            "Matteo Matteucci",
            "Umberto Spagnolini"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "In Integrated Sensing and Communication (ISAC) systems, matching the radar targets with communication user equipments (UEs) is functional to several communication tasks, such as proactive handover and beam prediction. In this paper, we consider a radar-assisted communication system where a base station (BS) is equipped with a multiple-input-multiple-output (MIMO) radar that has a double aim: (i) associate vehicular radar targets to vehicular equipments (VEs) in the communication beamspace and (ii) predict the beamforming vector for each VE from radar data. The proposed target-to-user (T2U) association consists of two stages. First, vehicular radar targets are detected from range-angle images, and, for each, a beamforming vector is estimated. Then, the inferred per-target beamforming vectors are matched with the ones utilized at the BS for communication to perform target-to-user (T2U) association. Joint multi-target detection and beam inference is obtained by modifying the you only look once (YOLO) model, which is trained over simulated range-angle radar images. Simulation results over different urban vehicular mobility scenarios show that the proposed T2U method provides a probability of correct association that increases with the size of the BS antenna array, highlighting the respective increase of the separability of the VEs in the beamspace. Moreover, we show that the modified YOLO architecture can effectively perform both beam prediction and radar target detection, with similar performance in mean average precision on the latter over different antenna array sizes.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12801"
    },
    {
        "doc_id": 221,
        "title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study",
        "authors": [
            "W. Ronny Huang",
            "Cyril Allauzen",
            "Tongzhou Chen",
            "Kilol Gupta",
            "Ke Hu",
            "James Qin",
            "Yu Zhang",
            "Yongqiang Wang",
            "Shuo-Yiin Chang",
            "Tara N. Sainath"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "In the era of large models, the autoregressive nature of decoding often results in latency serving as a significant bottleneck. We propose a non-autoregressive LM-fused ASR system that effectively leverages the parallelization capabilities of accelerator hardware. Our approach combines the Universal Speech Model (USM) and the PaLM 2 language model in per-segment scoring mode, achieving an average relative WER improvement across all languages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our comprehensive ablation study analyzes key parameters such as LLM size, context length, vocabulary size, fusion methodology. For instance, we explore the impact of LLM size ranging from 128M to 340B parameters on ASR performance. This study provides valuable insights into the factors influencing the effectiveness of practical large-scale LM-fused speech recognition systems.",
        "comments": "ICASSP 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12789"
    },
    {
        "doc_id": 222,
        "title": "A Review of Deep Learning Methods for Photoplethysmography Data",
        "authors": [
            "Guangkun Nie",
            "Jiabao Zhu",
            "Gongzheng Tang",
            "Deyun Zhang",
            "Shijia Geng",
            "Qinghao Zhao",
            "Shenda Hong"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Photoplethysmography (PPG) is a highly promising device due to its advantages in portability, user-friendly operation, and non-invasive capabilities to measure a wide range of physiological information. Recent advancements in deep learning have demonstrated remarkable outcomes by leveraging PPG signals for tasks related to personal health management and other multifaceted applications. In this review, we systematically reviewed papers that applied deep learning models to process PPG data between January 1st of 2017 and July 31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed from three key perspectives: tasks, models, and data. We finally extracted 193 papers where different deep learning frameworks were used to process PPG signals. Based on the tasks addressed in these papers, we categorized them into two major groups: medical-related, and non-medical-related. The medical-related tasks were further divided into seven subgroups, including blood pressure analysis, cardiovascular monitoring and diagnosis, sleep health, mental health, respiratory monitoring and analysis, blood glucose analysis, as well as others. The non-medical-related tasks were divided into four subgroups, which encompass signal processing, biometric identification, electrocardiogram reconstruction, and human activity recognition. In conclusion, significant progress has been made in the field of using deep learning methods to process PPG data recently. This allows for a more thorough exploration and utilization of the information contained in PPG signals. However, challenges remain, such as limited quantity and quality of publicly available databases, a lack of effective validation in real-world scenarios, and concerns about the interpretability, scalability, and complexity of deep learning models. Moreover, there are still emerging research areas that require further investigation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12783"
    },
    {
        "doc_id": 223,
        "title": "Deep Learning-based Intraoperative MRI Reconstruction",
        "authors": [
            "Jon Andr\u00e9 Ottesen",
            "Tryggve Storas",
            "Svein Are Sirirud Vatnehol",
            "Grethe L\u00f8vland",
            "Einar O. Vik-Mo",
            "Till Schellhorn",
            "Karoline Skogen",
            "Christopher Larsson",
            "Atle Bj\u00f8rnerud",
            "Inge Rasmus Groote-Eindbaas",
            "Matthan W. A. Caan"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Medical Physics"
        ],
        "abstract": "Purpose: To evaluate the quality of deep learning reconstruction for prospectively accelerated intraoperative magnetic resonance imaging (iMRI) during resective brain tumor surgery.\n  Materials and Methods: Accelerated iMRI was performed during brain surgery using dual surface coils positioned around the area of resection. A deep learning (DL) model was trained on the fastMRI neuro dataset to mimic the data from the iMRI protocol. Evaluation was performed on imaging material from 40 patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during tumor resection surgery. A comparative analysis was conducted between the conventional compressed sense (CS) method and the trained DL reconstruction method. Blinded evaluation of multiple image quality metrics was performed by two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the favored reconstruction variant.\n  Results: The DL reconstruction was strongly favored or favored over the CS reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3, respectively. Two of three readers consistently assigned higher ratings for the DL reconstructions, and the DL reconstructions had a higher score than their respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2, and 3, respectively. Still, the DL reconstructions exhibited shortcomings such as a striping artifact and reduced signal.\n  Conclusion: DL shows promise to allow for high-quality reconstructions of intraoperative MRI with equal to or improved perceived spatial resolution, signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and spatial resolution compared to compressed sense.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12771"
    },
    {
        "doc_id": 224,
        "title": "COOCK project Smart Port 2025 D3.1: \"To Twin Or Not To Twin\"",
        "authors": [
            "Randy Paredis",
            "Hans Vangheluwe",
            "Pamela Adelino Ramos Albertins"
        ],
        "subjects": [
            "Systems and Control",
            "Software Engineering"
        ],
        "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving and accelerating the operational efficiency of a harbour eco-system through the application of intelligent technologies\". It reports on the needs of companies for modelling and simulation and AI-based techniques, with twinning systems in particular. This document categorizes the purposes and Properties of Interest for the use of Digital Twins. It further illustrates some of the twinning usages, and touches on some of the potential architectural compositions for twins. This last topic will be further elaborated in a followup report.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12747"
    },
    {
        "doc_id": 225,
        "title": "Two-View Topogram-Based Anatomy-Guided CT Reconstruction for Prospective Risk Minimization",
        "authors": [
            "Chang Liu",
            "Laura Klein",
            "Yixing Huang",
            "Edith Baader",
            "Michael Lell",
            "Marc Kachelrie\u00df",
            "Andreas Maier"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "To facilitate a prospective estimation of CT effective dose and risk minimization process, a prospective spatial dose estimation and the known anatomical structures are expected. To this end, a CT reconstruction method is required to reconstruct CT volumes from as few projections as possible, i.e. by using the topograms, with anatomical structures as correct as possible. In this work, an optimized CT reconstruction model based on a generative adversarial network (GAN) is proposed. The GAN is trained to reconstruct 3D volumes from an anterior-posterior and a lateral CT projection. To enhance anatomical structures, a pre-trained organ segmentation network and the 3D perceptual loss are applied during the training phase, so that the model can then generate both organ-enhanced CT volume and the organ segmentation mask. The proposed method can reconstruct CT volumes with PSNR of 26.49, RMSE of 196.17, and SSIM of 0.64, compared to 26.21, 201.55 and 0.63 using the baseline method. In terms of the anatomical structure, the proposed method effectively enhances the organ shape and boundary and allows for a straight-forward identification of the relevant anatomical structures. We note that conventional reconstruction metrics fail to indicate the enhancement of anatomical structures. In addition to such metrics, the evaluation is expanded with assessing the organ segmentation performance. The average organ dice of the proposed method is 0.71 compared with 0.63 in baseline model, indicating the enhancement of anatomical structures.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12725"
    },
    {
        "doc_id": 226,
        "title": "Localized Data-driven Consensus Control",
        "authors": [
            "Zeze Chang",
            "Junjie Jiao",
            "Zhongkui Li"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper considers a localized data-driven consensus problem for leader-follower multi-agent systems with unknown discrete-time agent dynamics, where each follower computes its local control gain using only their locally collected state and input data. Both noiseless and noisy data-driven consensus protocols are presented, which can handle the challenge of the heterogeneity in control gains caused by the localized data sampling and achieve leader-follower consensus. The design of these data-driven consensus protocols involves low-dimensional linear matrix inequalities. In addition, the results are extended to the case where only the leader's data are collected and exploited. The effectiveness of the proposed methods is illustrated via simulation examples.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12707"
    },
    {
        "doc_id": 227,
        "title": "MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with Multi-Granular Features",
        "authors": [
            "Wenqian Cui",
            "Pedro Sarmento",
            "Mathieu Barthet"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Loopable music generation systems enable diverse applications, but they often lack controllability and customization capabilities. We argue that enhancing controllability can enrich these models, with emotional expression being a crucial aspect for both creators and listeners. Hence, building upon LooperGP, a loopable tablature generation model, this paper explores endowing systems with control over conveyed emotions. To enable such conditional generation, we propose integrating musical knowledge by utilizing multi-granular semantic and musical features during model training and inference. Specifically, we incorporate song-level features (Emotion Labels, Tempo, and Mode) and bar-level features (Tonal Tension) together to guide emotional expression. Through algorithmic and human evaluations, we demonstrate the approach's effectiveness in producing music conveying two contrasting target emotions, happiness and sadness. An ablation study is also conducted to clarify the contributing factors behind our approach's results.",
        "comments": "This preprint is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). The Version of Record of this contribution is published in Proceedings of EvoMUSART: International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar) 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12656"
    },
    {
        "doc_id": 228,
        "title": "On the Robustness of Deep Learning-aided Symbol Detectors to Varying Conditions and Imperfect Channel Knowledge",
        "authors": [
            "Chin-Hung Chen",
            "Boris Karanov",
            "Wim van Houtum",
            "Wu Yan",
            "Alex Young",
            "Alex Alvarado"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Recently, a data-driven Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm tailored to channels with intersymbol interference has been introduced. This so-called BCJRNet algorithm utilizes neural networks to calculate channel likelihoods. BCJRNet has demonstrated resilience against inaccurate channel tap estimations when applied to a time-invariant channel with ideal exponential decay profiles. However, its generalization capabilities for practically-relevant time-varying channels, where the receiver can only access incorrect channel parameters, remain largely unexplored. The primary contribution of this paper is to expand upon the results from existing literature to encompass a variety of imperfect channel knowledge cases that appear in real-world transmissions. Our findings demonstrate that BCJRNet significantly outperforms the conventional BCJR algorithm for stationary transmission scenarios when learning from noisy channel data and with imperfect channel decay profiles. However, this advantage is shown to diminish when the operating channel is also rapidly time-varying. Our results also show the importance of memory assumptions for conventional BCJR and BCJRNet. An underestimation of the memory largely degrades the performance of both BCJR and BCJRNet, especially in a slow-decaying channel. To mimic a situation closer to a practical scenario, we also combined channel tap uncertainty with imperfect channel memory knowledge. Somewhat surprisingly, our results revealed improved performance when employing the conventional BCJR with an underestimated memory assumption. BCJRNet, on the other hand, showed a consistent performance improvement as the level of accurate memory knowledge increased.",
        "comments": "Accepted paper at IEEE Wireless Communications and Networking Conference (WCNC) 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12645"
    },
    {
        "doc_id": 229,
        "title": "Blind Channel Estimation and Joint Symbol Detection with Data-Driven Factor Graphs",
        "authors": [
            "Luca Schmid",
            "Tomer Raviv",
            "Nir Shlezinger",
            "Laurent Schmalen"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "We investigate the application of the factor graph framework for blind joint channel estimation and symbol detection on time-variant linear inter-symbol interference channels. In particular, we consider the expectation maximization (EM) algorithm for maximum likelihood estimation, which typically suffers from high complexity as it requires the computation of the symbol-wise posterior distributions in every iteration. We address this issue by efficiently approximating the posteriors using the belief propagation (BP) algorithm on a suitable factor graph. By interweaving the iterations of BP and EM, the detection complexity can be further reduced to a single BP iteration per EM step. In addition, we propose a data-driven version of our algorithm that introduces momentum in the BP updates and learns a suitable EM parameter update schedule, thereby significantly improving the performance-complexity tradeoff with a few offline training samples. Our numerical experiments demonstrate the excellent performance of the proposed blind detector and show that it even outperforms coherent BP detection in high signal-to-noise scenarios.",
        "comments": "Submitted to IEEE for peer review",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12627"
    },
    {
        "doc_id": 230,
        "title": "Nonlinear Distortion Radiated from Large Arrays and Active Reconfigurable Intelligent Surfaces",
        "authors": [
            "Nikolaos Kolomvakis",
            "Alva Kosasih",
            "Emil Bj\u00f6rnson"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Extremely large aperture arrays (ELAAs) and reconfigurable intelligent surfaces (RISs) are candidate enablers to realize connectivity goals for the sixth-generation (6G) wireless networks. For instance, ELAAs can provide orders-of-magnitude higher area throughput compared to what massive multiple-input multiple-output (MIMO) can deliver through spatial multiplexing, while RISs can improve the propagation conditions over wireless channels but a passively reflecting RIS must be large to be effective. Active RIS with amplifiers can deal with this issue. In this paper, we study the distortion created by nonlinear amplifiers in both ELAAs and active RIS. We analytically obtain the angular directions and depth of the nonlinear distortion in both near- and far-field channels. The results are demonstrated numerically and we conclude that non-linearities can both create in-band and out-of-band distortion that is beamformed in entirely new directions and distances from the transmitter.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12622"
    },
    {
        "doc_id": 231,
        "title": "Fast Semi-supervised Unmixing using Non-convex Optimization",
        "authors": [
            "Behnood Rasti",
            "Alexandre Zouaoui",
            "Julien Mairal",
            "Jocelyn Chanussot"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "In this paper, we introduce a novel linear model tailored for semisupervised/library-based unmixing. Our model incorporates considerations for library mismatch while enabling the enforcement of the abundance sum-to-one constraint (ASC). Unlike conventional sparse unmixing methods, this model involves nonconvex optimization, presenting significant computational challenges. We demonstrate the efficacy of Alternating Methods of Multipliers (ADMM) in cyclically solving these intricate problems. We propose two semisupervised unmixing approaches, each relying on distinct priors applied to the new model in addition to the ASC: sparsity prior and convexity constraint. Our experimental results validate that enforcing the convexity constraint outperforms the sparsity prior for the endmember library. These results are corroborated across three simulated datasets (accounting for spectral variability and varying pixel purity levels) and the Cuprite dataset. Additionally, our comparison with conventional sparse unmixing methods showcases considerable advantages of our proposed model, which entails nonconvex optimization. Notably, our implementations of the proposed algorithms-fast semisupervised unmixing (FaSUn) and sparse unmixing using soft-shrinkage (SUnS)-prove considerably more efficient than traditional sparse unmixing methods. SUnS and FaSUn were implemented using PyTorch and provided in a dedicated Python package called Fast Semisupervised Unmixing (FUnmix), which is open-source and available at https://github.com/BehnoodRasti/FUnmix",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12609"
    },
    {
        "doc_id": 232,
        "title": "EEND-M2F: Masked-attention mask transformers for speaker diarization",
        "authors": [
            "Marc H\u00e4rk\u00f6nen",
            "Samuel J. Broughton",
            "Lahiru Samarakoon"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "In this paper, we make the explicit connection between image segmentation methods and end-to-end diarization methods. From these insights, we propose a novel, fully end-to-end diarization model, EEND-M2F, based on the Mask2Former architecture. Speaker representations are computed in parallel using a stack of transformer decoders, in which irrelevant frames are explicitly masked from the cross attention using predictions from previous layers. EEND-M2F is lightweight, efficient, and truly end-to-end, as it does not require any additional diarization, speaker verification, or segmentation models to run, nor does it require running any clustering algorithms. Our model achieves state-of-the-art performance on several public datasets, such as AMI, AliMeeting and RAMC. Most notably our DER of 16.07% on DIHARD-III is the first major improvement upon the challenge winning system.",
        "comments": "14 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12600"
    },
    {
        "doc_id": 233,
        "title": "Fast Implicit Neural Representation Image Codec in Resource-limited Devices",
        "authors": [
            "Xiang Liu",
            "Jiahong Chen",
            "Bin Chen",
            "Zimo Liu",
            "Baoyi An",
            "Shu-Tao Xia"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Displaying high-quality images on edge devices, such as augmented reality devices, is essential for enhancing the user experience. However, these devices often face power consumption and computing resource limitations, making it challenging to apply many deep learning-based image compression algorithms in this field. Implicit Neural Representation (INR) for image compression is an emerging technology that offers two key benefits compared to cutting-edge autoencoder models: low computational complexity and parameter-free decoding. It also outperforms many traditional and early neural compression methods in terms of quality. In this study, we introduce a new Mixed Autoregressive Model (MARM) to significantly reduce the decoding time for the current INR codec, along with a new synthesis network to enhance reconstruction quality. MARM includes our proposed Autoregressive Upsampler (ARU) blocks, which are highly computationally efficient, and ARM from previous work to balance decoding time and reconstruction quality. We also propose enhancing ARU's performance using a checkerboard two-stage decoding strategy. Moreover, the ratio of different modules can be adjusted to maintain a balance between quality and speed. Comprehensive experiments demonstrate that our method significantly improves computational efficiency while preserving image quality. With different parameter settings, our method can outperform popular AE-based codecs in constrained environments in terms of both quality and decoding time, or achieve state-of-the-art reconstruction quality compared to other INR codecs.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12587"
    },
    {
        "doc_id": 234,
        "title": "DiffMoog: a Differentiable Modular Synthesizer for Sound Matching",
        "authors": [
            "Noy Uzrad",
            "Oren Barkan",
            "Almog Elharar",
            "Shlomi Shvartzman",
            "Moshe Laufer",
            "Lior Wolf",
            "Noam Koenigstein"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Artificial Intelligence",
            "Sound"
        ],
        "abstract": "This paper presents DiffMoog - a differentiable modular synthesizer with a comprehensive set of modules typically found in commercial instruments. Being differentiable, it allows integration into neural networks, enabling automated sound matching, to replicate a given audio input. Notably, DiffMoog facilitates modulation capabilities (FM/AM), low-frequency oscillators (LFOs), filters, envelope shapers, and the ability for users to create custom signal chains. We introduce an open-source platform that comprises DiffMoog and an end-to-end sound matching framework. This framework utilizes a novel signal-chain loss and an encoder network that self-programs its outputs to predict DiffMoogs parameters based on the user-defined modular architecture. Moreover, we provide insights and lessons learned towards sound matching using differentiable synthesis. Combining robust sound capabilities with a holistic platform, DiffMoog stands as a premier asset for expediting research in audio synthesis and machine learning.",
        "comments": "5 pages, 7 figures, 1 table, Our code is released at https://github.com/aisynth/diffmoog",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12570"
    },
    {
        "doc_id": 235,
        "title": "Learning the cost-to-go for mixed-integer nonlinear model predictive control",
        "authors": [
            "Christopher A. Orrico",
            "W. P. M. H. Heemels",
            "Dinesh Krishnamoorthy"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Application of nonlinear model predictive control (NMPC) to problems with hybrid dynamical systems, disjoint constraints, or discrete controls often results in mixed-integer formulations with both continuous and discrete decision variables. However, solving mixed-integer nonlinear programming problems (MINLP) in real-time is challenging, which can be a limiting factor in many applications. To address the computational complexity of solving mixed integer nonlinear model predictive control problem in real-time, this paper proposes an approximate mixed integer NMPC formulation based on value function approximation. Leveraging Bellman's principle of optimality, the key idea here is to divide the prediction horizon into two parts, where the optimal value function of the latter part of the prediction horizon is approximated offline using expert demonstrations. Doing so allows us to solve the MINMPC problem with a considerably shorter prediction horizon online, thereby reducing the online computation cost. The paper uses an inverted pendulum example with discrete controls to illustrate this approach.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12562"
    },
    {
        "doc_id": 236,
        "title": "Approximate solution of stochastic infinite horizon optimal control problems for constrained linear uncertain systems",
        "authors": [
            "Eunhyek Joa",
            "Francesco Borrelli"
        ],
        "subjects": [
            "Optimization and Control",
            "Systems and Control"
        ],
        "abstract": "We propose a Model Predictive Control (MPC) with a single-step prediction horizon to solve infinite horizon optimal control problems with the expected sum of convex stage costs for constrained linear uncertain systems. The proposed method relies on two techniques. First, we estimate the expected values of the convex costs using a computationally tractable approximation, achieved by sampling across the space of disturbances. Second, we implement a data-driven approach to approximate the optimal value function and its corresponding domain, through systematic exploration of the system's state space. These estimates are subsequently used as the terminal cost and terminal set within the proposed MPC. We prove recursive feasibility, robust constraint satisfaction, and convergence in probability to the target set. Furthermore, we prove that the estimated value function converges to the optimal value function in a local region. The effectiveness of the proposed MPC is illustrated with detailed numerical simulations and comparisons with a value iteration method and a Learning MPC that minimizes a certainty equivalent cost.",
        "comments": "Submitted to the IEEE Transactions on Automatic Control",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12556"
    },
    {
        "doc_id": 237,
        "title": "On Building Myopic MPC Policies using Supervised Learning",
        "authors": [
            "Christopher A. Orrico",
            "Bokan Yang",
            "Dinesh Krishnamoorthy"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "The application of supervised learning techniques in combination with model predictive control (MPC) has recently generated significant interest, particularly in the area of approximate explicit MPC, where function approximators like deep neural networks are used to learn the MPC policy via optimal state-action pairs generated offline. While the aim of approximate explicit MPC is to closely replicate the MPC policy, substituting online optimization with a trained neural network, the performance guarantees that come with solving the online optimization problem are typically lost. This paper considers an alternative strategy, where supervised learning is used to learn the optimal value function offline instead of learning the optimal policy. This can then be used as the cost-to-go function in a myopic MPC with a very short prediction horizon, such that the online computation burden reduces significantly without affecting the controller performance. This approach differs from existing work on value function approximations in the sense that it learns the cost-to-go function by using offline-collected state-value pairs, rather than closed-loop performance data. The cost of generating the state-value pairs used for training is addressed using a sensitivity-based data augmentation scheme.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12546"
    },
    {
        "doc_id": 238,
        "title": "On the Fundamental Tradeoff of Joint Communication and Quickest Change Detection",
        "authors": [
            "Daewon Seo",
            "Sung Hoon Lim"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "In this work, we take the initiative in studying the fundamental tradeoff between communication and quickest change detection (QCD) under an integrated sensing and communication setting. We formally establish a joint communication and sensing problem for quickest change detection. Then, by utilizing constant subblock-composition codes and a modified QuSum detection rule, which we call subblock QuSum (SQS), we provide an inner bound on the fundamental tradeoff between communication rate and change point detection delay in the asymptotic regime of vanishing false alarm rate. We further provide a partial converse that matches our inner bound for a certain class of codes. This implies that the SQS detection strategy is asymptotically optimal for our codes as the false alarm rate constraint vanishes. We also present some canonical examples of the tradeoff region for a binary channel, a scalar Gaussian channel, and a MIMO Gaussian channel.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12499"
    },
    {
        "doc_id": 239,
        "title": "An Automated Real-Time Approach for Image Processing and Segmentation of Fluoroscopic Images and Videos Using a Single Deep Learning Network",
        "authors": [
            "Viet Dung Nguyen",
            "Michael T. LaCour",
            "Richard D. Komistek"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Image segmentation in total knee arthroplasty is crucial for precise preoperative planning and accurate implant positioning, leading to improved surgical outcomes and patient satisfaction. The biggest challenges of image segmentation in total knee arthroplasty include accurately delineating complex anatomical structures, dealing with image artifacts and noise, and developing robust algorithms that can handle anatomical variations and pathologies commonly encountered in patients. The potential of using machine learning for image segmentation in total knee arthroplasty lies in its ability to improve segmentation accuracy, automate the process, and provide real-time assistance to surgeons, leading to enhanced surgical planning, implant placement, and patient outcomes. This paper proposes a methodology to use deep learning for robust and real-time total knee arthroplasty image segmentation. The deep learning model, trained on a large dataset, demonstrates outstanding performance in accurately segmenting both the implanted femur and tibia, achieving an impressive mean-Average-Precision (mAP) of 88.83 when compared to the ground truth while also achieving a real-time segmented speed of 20 frames per second (fps). We have introduced a novel methodology for segmenting implanted knee fluoroscopic or x-ray images that showcases remarkable levels of accuracy and speed, paving the way for various potential extended applications.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12488"
    },
    {
        "doc_id": 240,
        "title": "Boosting Unknown-number Speaker Separation with Transformer Decoder-based Attractor",
        "authors": [
            "Younglo Lee",
            "Shukjae Choi",
            "Byeong-Yeol Kim",
            "Zhong-Qiu Wang",
            "Shinji Watanabe"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "We propose a novel speech separation model designed to separate mixtures with an unknown number of speakers. The proposed model stacks 1) a dual-path processing block that can model spectro-temporal patterns, 2) a transformer decoder-based attractor (TDA) calculation module that can deal with an unknown number of speakers, and 3) triple-path processing blocks that can model inter-speaker relations. Given a fixed, small set of learned speaker queries and the mixture embedding produced by the dual-path blocks, TDA infers the relations of these queries and generates an attractor vector for each speaker. The estimated attractors are then combined with the mixture embedding by feature-wise linear modulation conditioning, creating a speaker dimension. The mixture embedding, conditioned with speaker information produced by TDA, is fed to the final triple-path blocks, which augment the dual-path blocks with an additional pathway dedicated to inter-speaker processing. The proposed approach outperforms the previous best reported in the literature, achieving 24.0 and 23.7 dB SI-SDR improvement (SI-SDRi) on WSJ0-2 and 3mix respectively, with a single model trained to separate 2- and 3-speaker mixtures. The proposed model also exhibits strong performance and generalizability at counting sources and separating mixtures with up to 5 speakers.",
        "comments": "5 pages, 4 figures, accepted by ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12473"
    },
    {
        "doc_id": 241,
        "title": "Towards Adaptive Subspace Detection in Heterogeneous Environment",
        "authors": [
            "Aref Miri Rekavandi"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "In this paper, we aim to take one step forward to the scenario where an adaptive subspace detection framework is required to detect subspace signals in non-stationary environments. Despite the fact that this scenario is more realistic, the existing studies in detection theory mostly rely on homogeneous, or partially homogeneous assumptions in the environments for their design process meaning that the covariance matrices of primary and secondary datasets are exactly the same or different up to a scale factor. In this study, we allow some partial information of the train covariance matrix to be shared with the primary dataset, but the covariance matrix in the primary set can be entirely different in the structure. This is particularly true in radar systems where the secondary set is collected in distinct spatial and time zones. We design a Generalized Likelihood Ratio Test (GLRT) based detector where the noise is multivariate Gaussian and the subspace interference is assumed to be known. The simulation results reveal the superiority of the proposed approach in comparison with conventional detectors for such a realistic and general scenario.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12469"
    },
    {
        "doc_id": 242,
        "title": "Minimum observability of probabilistic Boolean networks",
        "authors": [
            "Jiayi Xu",
            "Shihua Fu",
            "Liyuan Xia",
            "Jianjun Wang"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper studies the minimum observability of probabilistic Boolean networks (PBNs), the main objective of which is to add the fewest measurements to make an unobservable PBN become observable. First of all, the algebraic form of a PBN is established with the help of semi-tensor product (STP) of matrices. By combining the algebraic forms of two identical PBNs into a parallel system, a method to search the states that need to be H-distinguishable is proposed based on the robust set reachability technique. Secondly, a necessary and sufficient condition is given to find the minimum measurements such that a given set can be H-distinguishable. Moreover, by comparing the numbers of measurements for all the feasible H-distinguishable state sets, the least measurements that make the system observable are gained. Finally, an example is given to verify the validity of the obtained results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12468"
    },
    {
        "doc_id": 243,
        "title": "Multi-agent deep reinforcement learning with centralized training and decentralized execution for transportation infrastructure management",
        "authors": [
            "M. Saifullah",
            "K. G. Papakonstantinou",
            "C. P. Andriotis",
            "S. M. Stoffels"
        ],
        "subjects": [
            "Multiagent Systems",
            "Artificial Intelligence",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "We present a multi-agent Deep Reinforcement Learning (DRL) framework for managing large transportation infrastructure systems over their life-cycle. Life-cycle management of such engineering systems is a computationally intensive task, requiring appropriate sequential inspection and maintenance decisions able to reduce long-term risks and costs, while dealing with different uncertainties and constraints that lie in high-dimensional spaces. To date, static age- or condition-based maintenance methods and risk-based or periodic inspection plans have mostly addressed this class of optimization problems. However, optimality, scalability, and uncertainty limitations are often manifested under such approaches. The optimization problem in this work is cast in the framework of constrained Partially Observable Markov Decision Processes (POMDPs), which provides a comprehensive mathematical basis for stochastic sequential decision settings with observation uncertainties, risk considerations, and limited resources. To address significantly large state and action spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL method with Centralized Training and Decentralized Execution (CTDE), termed as DDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method are demonstrated in a generally representative and realistic example application of an existing transportation network in Virginia, USA. The network includes several bridge and pavement components with nonstationary degradation, agency-imposed constraints, and traffic delay and risk considerations. Compared to traditional management policies for transportation networks, the proposed DDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposed algorithmic framework provides near optimal solutions for transportation infrastructure management under real-world constraints and complexities.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12455"
    },
    {
        "doc_id": 244,
        "title": "Post-Training Embedding Alignment for Decoupling Enrollment and Runtime Speaker Recognition Models",
        "authors": [
            "Chenyang Gao",
            "Brecht Desplanques",
            "Chelsea J. -T. Ju",
            "Aman Chadha",
            "Andreas Stolcke"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Machine Learning",
            "Sound"
        ],
        "abstract": "Automated speaker identification (SID) is a crucial step for the personalization of a wide range of speech-enabled services. Typical SID systems use a symmetric enrollment-verification framework with a single model to derive embeddings both offline for voice profiles extracted from enrollment utterances, and online from runtime utterances. Due to the distinct circumstances of enrollment and runtime, such as different computation and latency constraints, several applications would benefit from an asymmetric enrollment-verification framework that uses different models for enrollment and runtime embedding generation. To support this asymmetric SID where each of the two models can be updated independently, we propose using a lightweight neural network to map the embeddings from the two independent models to a shared speaker embedding space. Our results show that this approach significantly outperforms cosine scoring in a shared speaker logit space for models that were trained with a contrastive loss on large datasets with many speaker identities. This proposed Neural Embedding Speaker Space Alignment (NESSA) combined with an asymmetric update of only one of the models delivers at least 60% of the performance gain achieved by updating both models in the standard symmetric SID approach.",
        "comments": "Accepted to ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12440"
    },
    {
        "doc_id": 245,
        "title": "Secure Federated Learning Approaches to Diagnosing COVID-19",
        "authors": [
            "Rittika Adhikari",
            "Christopher Settles"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Distributed, Parallel, and Cluster Computing",
            "Machine Learning"
        ],
        "abstract": "The recent pandemic has underscored the importance of accurately diagnosing COVID-19 in hospital settings. A major challenge in this regard is differentiating COVID-19 from other respiratory illnesses based on chest X-rays, compounded by the restrictions of HIPAA compliance which limit the comparison of patient X-rays. This paper introduces a HIPAA-compliant model to aid in the diagnosis of COVID-19, utilizing federated learning. Federated learning is a distributed machine learning approach that allows for algorithm training across multiple decentralized devices using local data samples, without the need for data sharing. Our model advances previous efforts in chest X-ray diagnostic models. We examined leading models from established competitions in this domain and developed our own models tailored to be effective with specific hospital data. Considering the model's operation in a federated learning context, we explored the potential impact of biased data updates on the model's performance. To enhance hospital understanding of the model's decision-making process and to verify that the model is not focusing on irrelevant features, we employed a visualization technique that highlights key features in chest X-rays indicative of a positive COVID-19 diagnosis.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12438"
    },
    {
        "doc_id": 246,
        "title": "Performance Analysis of 6G Multiuser Massive MIMO-OFDM THz Wireless Systems with Hybrid Beamforming under Intercarrier Interference",
        "authors": [
            "Md Saheed Ullah",
            "Zulqarnain Bin Ashraf",
            "Sudipta Chandra Sarker"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "6G networks are expected to provide more diverse capabilities than their predecessors and are likely to support applications beyond current mobile applications, such as virtual and augmented reality (VR/AR), AI, and the Internet of Things (IoT). In contrast to typical multiple-input multiple-output (MIMO) systems, THz MIMO precoding cannot be conducted totally at baseband using digital precoders due to the restricted number of signal mixers and analog-to-digital converters that can be supported due to their cost and power consumption. In this thesis, we analyzed the performance of multiuser massive MIMO-OFDM THz wireless systems with hybrid beamforming. Carrier frequency offset (CFO) is one of the most well-known disturbances for OFDM. For practicality, we accounted for CFO, which results in Intercarrier Interference. Incorporating the combined impact of molecular absorption, high sparsity, and multi-path fading, we analyzed a three-dimensional wideband THz channel and the carrier frequency offset in multi-carrier systems. With this model, we first presented a two-stage wideband hybrid beamforming technique comprising Riemannian manifolds optimization for analog beamforming and then a zero-forcing (ZF) approach for digital beamforming. We adjusted the objective function to reduce complexity, and instead of maximizing the bit rate, we determined parameters by minimizing interference. Numerical results demonstrate the significance of considering ICI for practical implementation for the THz system. We demonstrated how our change in problem formulation minimizes latency without compromising results. We also evaluated spectral efficiency by varying the number of RF chains and antennas. The spectral efficiency grows as the number of RF chains and antennas increases, but the spectral efficiency of antennas declines when the number of users increases.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12351"
    },
    {
        "doc_id": 247,
        "title": "Distributionally Robust Beamforming and Estimation of Wireless Signals",
        "authors": [
            "Shixiong Wang",
            "Wei Dai",
            "Geoffrey Ye Li"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper investigates signal estimation in wireless transmission from the perspective of statistical machine learning, where the transmitted signals may be from an integrated sensing and communication system; that is, 1) signals may be not only discrete constellation points but also arbitrary complex values; 2) signals may be spatially correlated. Particular attention is paid to handling various uncertainties such as the uncertainty of the transmitting signal covariance, the uncertainty of the channel matrix, the uncertainty of the channel noise covariance, the existence of channel impulse noises (i.e., outliers), and the limited sample size of pilots. To proceed, a distributionally robust machine learning framework that is insensitive to the above uncertainties is proposed for beamforming (at the receiver) and estimation of wireless signals, which reveals that channel estimation is not a necessary operation. For optimal linear estimation, the proposed framework includes several existing beamformers as special cases such as diagonal loading and eigenvalue thresholding. For optimal nonlinear estimation, estimators are limited in reproducing kernel Hilbert spaces and neural network function spaces, and corresponding uncertainty-aware solutions (e.g., kernelized diagonal loading) are derived. In addition, we prove that the ridge and kernel ridge regression methods in machine learning are distributionally robust against diagonal perturbation in feature covariance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12345"
    },
    {
        "doc_id": 248,
        "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation",
        "authors": [
            "Shoaib Meraj Sami",
            "Md Mahedi Hasan",
            "Nasser M. Nasrabadi",
            "Raghuveer Rao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Image and Video Processing",
            "Machine Learning"
        ],
        "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task, primarily due to the unavailability of labeled data in the target domain. Hence, it is essential to construct an optimal target domain classifier by utilizing the labeled information of the source domain images. The transductive transfer learning (TTL) method that incorporates a CycleGAN-based unpaired domain translation network has been previously proposed in the literature for effective ATR annotation. Although this method demonstrates great potential for ATR, it severely suffers from lower annotation performance, higher Fr\u00e9chet Inception Distance (FID) score, and the presence of visual artifacts in the synthetic images. To address these issues, we propose a hybrid contrastive learning base unpaired domain translation (H-CUT) network that achieves a significantly lower FID score. It incorporates both attention and entropy to emphasize the domain-specific region, a noisy feature mixup module to generate high variational synthetic negative patches, and a modulated noise contrastive estimation (MoNCE) loss to reweight all negative patches using optimal transport for better performance. Our proposed contrastive learning and cycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks and two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and identity losses. In C3TTL, two H-CUT networks have been employed through a bijection mapping to feed the reconstructed source domain images into a pretrained classifier to guide the optimal target domain classifier. Extensive experimental analysis conducted on three ATR datasets demonstrates that the proposed C3TTL method is effective in annotating civilian and military vehicles, as well as ship targets.",
        "comments": "This Paper is Accepted in IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS. This Arxiv version is an older version than the reviewed version",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12340"
    },
    {
        "doc_id": 249,
        "title": "An Exploratory Study of Multimodal Physiological Data in Jazz Improvisation Using Basic Machine Learning Techniques",
        "authors": [
            "Yawen Zhang"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Our study delves into the \"Embodied Musicking Dataset,\" exploring the intertwined relationships and correlations between physiological and psychological dimensions during improvisational music performances. The primary objective is to ascertain the presence of a definitive causal or correlational relationship between these states and comprehend their manifestation in musical compositions. This rich dataset provides a perspective on how musicians coordinate their physicality with sonic events in real-time improvisational scenarios, emphasizing the concept of \"Embodied Musicking.\"",
        "comments": "Master's thesis",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12266"
    },
    {
        "doc_id": 250,
        "title": "Assessment of the maintenance cost and analysis of availability measures in a finite life cycle for a system subject to competing failures",
        "authors": [
            "Nuria Caball\u00e9",
            "Inma T. Castro"
        ],
        "subjects": [
            "Systems and Control",
            "Probability"
        ],
        "abstract": "This paper deals with the assessment of the performance of a system under a finite planning horizon. The system is subject to two dependent causes of failure: internal degradation and sudden shocks. We assume that internal degradation follows a gamma process. When the deterioration level of the degradation process exceeds a predetermined value, a degradation failure occurs. Sudden shocks arrive at the system following a doubly stochastic Poisson process (DSPP). A sudden shock provokes the total breakdown of the system. A condition-based maintenance (CBM) with periodic inspection times is developed. To evaluate the maintenance cost, recursive methods combining numerical integration and Monte Carlo simulation are developed to evalute the expected cost rate and its standard deviation. Also, recursive methods to calculate some transient measures of the system are given. Numerical examples are provided to illustrate the analytical results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12265"
    },
    {
        "doc_id": 251,
        "title": "CoAVT: A Cognition-Inspired Unified Audio-Visual-Text Pre-Training Model for Multimodal Processing",
        "authors": [
            "Xianghu Yue",
            "Xiaohai Tian",
            "Malu Zhang",
            "Zhizheng Wu",
            "Haizhou Li"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Multimedia",
            "Sound",
            "Image and Video Processing"
        ],
        "abstract": "There has been a long-standing quest for a unified audio-visual-text model to enable various multimodal understanding tasks, which mimics the listening, seeing and reading process of human beings. Humans tends to represent knowledge using two separate systems: one for representing verbal (textual) information and one for representing non-verbal (visual and auditory) information. These two systems can operate independently but can also interact with each other. Motivated by this understanding of human cognition, in this paper, we introduce CoAVT -- a novel cognition-inspired Correlated Audio-Visual-Text pre-training model to connect the three modalities. It contains a joint audio-visual encoder that learns to encode audio-visual synchronization information together with the audio and visual content for non-verbal information, and a text encoder to handle textual input for verbal information. To bridge the gap between modalities, CoAVT employs a query encoder, which contains a set of learnable query embeddings, and extracts the most informative audiovisual features of the corresponding text. Additionally, to leverage the correspondences between audio and vision with language respectively, we also establish the audio-text and visual-text bi-modal alignments upon the foundational audiovisual-text tri-modal alignment to enhance the multimodal representation learning. Finally, we jointly optimize CoAVT model with three multimodal objectives: contrastive loss, matching loss and language modeling loss. Extensive experiments show that CoAVT can learn strong multimodal correlations and be generalized to various downstream tasks. CoAVT establishes new state-of-the-art performance on text-video retrieval task on AudioCaps for both zero-shot and fine-tuning settings, audio-visual event classification and audio-visual retrieval tasks on AudioSet and VGGSound.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12264"
    },
    {
        "doc_id": 252,
        "title": "Maintenance policy for a system with a weighted linear combination of degradation processes",
        "authors": [
            "Shaomin Wu",
            "Inma T. Castro"
        ],
        "subjects": [
            "Systems and Control",
            "Probability"
        ],
        "abstract": "This paper develops maintenance policies for a system under condition monitoring. We assume that a number of defects may develop and the degradation process of each defect follows a gamma process, respectively. The system is inspected periodically and maintenance actions are performed on the defects present in the system. The effectiveness of the maintenance is assumed imperfect and it is modelled using a geometric process. By performing these maintenance actions, different costs are incurred depending on the type and the degradation levels of the defects. Furthermore, once a linear combination of the degradation processes exceeds a pre-specified threshold, the system needs a special maintenance and an extra cost is imposed. The system is renewed after several preventive maintenance activities have been performed. The main concern of this paper is to optimise the time between renewals and the number of renewals. Numerical examples are given to illustrate the results derived in the paper.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12263"
    },
    {
        "doc_id": 253,
        "title": "Diffusion Representation for Asymmetric Kernels",
        "authors": [
            "Alvaro Almeida Gomez",
            "Antonio Silva Neto",
            "Jorge zubelli"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "We extend the diffusion-map formalism to data sets that are induced by asymmetric kernels. Analytical convergence results of the resulting expansion are proved, and an algorithm is proposed to perform the dimensional reduction. In this work we study data sets in which its geometry structure is induced by an asymmetric kernel. We use a priori coordinate system to represent this geometry and, thus, be able to improve the computational complexity of reducing the dimensionality of data sets. A coordinate system connected to the tensor product of Fourier basis is used to represent the underlying geometric structure obtained by the diffusion-map, thus reducing the dimensionality of the data set and making use of the speedup provided by the two-dimensional Fast Fourier Transform algorithm (2-D FFT). We compare our results with those obtained by other eigenvalue expansions, and verify the efficiency of the algorithms with synthetic data, as well as with real data from applications including climate change studies.",
        "comments": "Journal ref:        Applied Numerical Mathematics, 2021",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12251"
    },
    {
        "doc_id": 254,
        "title": "Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming for Policy Optimization in Mixed Discrete-Continuous MDPs",
        "authors": [
            "Michael Gimelfarb",
            "Ayal Taitler",
            "Scott Sanner"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning",
            "Robotics",
            "Symbolic Computation",
            "Systems and Control"
        ],
        "abstract": "We propose Constraint-Generation Policy Optimization (CGPO) for optimizing policy parameters within compact and interpretable policy classes for mixed discrete-continuous Markov Decision Processes (DC-MDPs). CGPO is not only able to provide bounded policy error guarantees over an infinite range of initial states for many DC-MDPs with expressive nonlinear dynamics, but it can also provably derive optimal policies in cases where it terminates with zero error. Furthermore, CGPO can generate worst-case state trajectories to diagnose policy deficiencies and provide counterfactual explanations of optimal actions. To achieve such results, CGPO proposes a bi-level mixed-integer nonlinear optimization framework for optimizing policies within defined expressivity classes (i.e. piecewise (non)-linear) and reduces it to an optimal constraint generation methodology that adversarially generates worst-case state trajectories. Furthermore, leveraging modern nonlinear optimizers, CGPO can obtain solutions with bounded optimality gap guarantees. We handle stochastic transitions through explicit marginalization (where applicable) or chance-constraints, providing high-probability policy performance guarantees. We also present a road-map for understanding the computational complexities associated with different expressivity classes of policy, reward, and transition dynamics. We experimentally demonstrate the applicability of CGPO in diverse domains, including inventory control, management of a system of water reservoirs, and physics control. In summary, we provide a solution for deriving structured, compact, and explainable policies with bounded performance guarantees, enabling worst-case scenario generation and counterfactual policy diagnostics.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12243"
    },
    {
        "doc_id": 255,
        "title": "Power System Resource Expansion Planning",
        "authors": [
            "Sohom Datta"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Power System Resource Planning is the recurrent process of studying and determining what facilities and procedures should be provided to satisfy and promote appropriate future demands for electricity. The electric power system as planned should meet or balance societal goals. These include availability of electricity to all potential users at lowest possible cost, minimum environmental damage, high levels of safety and reliability, etc. Plans should be technically and financially feasible. Plans also should achieve the objectives the entity doing the planning, including minimizing risk. The emergence of meta-heuristics has given robustness to the non-analytical methods, because of the rationale behind them. Besides, evolutionary algorithms have provided a higher degree of confidence in a stochastic convergence to optimum and have supported this confidence with a mathematical background explaining not only how they achieve convergence but also how to improve the convergence rate. The present work of analyses and implementation can be divided into: i) Transmission Constrained Generation Expansion Planning (TC GEP), ii) Composite Generation Expansion and Transmission Network Expansion Planning (GEP TNEP), iii) Transmission Network Expansion (TNEP) Planning using AC model, iv) Composite Transmission Network Expansion Planning (TNEP) and Reactive Power Expansion Planning (RPP) and v) Transmission Network Planning using Interior-Point Method (IP TNEP).",
        "comments": "Master's thesis, Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India, May 2011",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12241"
    },
    {
        "doc_id": 256,
        "title": "Quantised Neural Network Accelerators for Low-Power IDS in Automotive Networks",
        "authors": [
            "Shashwat Khandelwal",
            "Anneliese Walsh",
            "Shanker Shreejith"
        ],
        "subjects": [
            "Cryptography and Security",
            "Hardware Architecture",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "In this paper, we explore low-power custom quantised Multi-Layer Perceptrons (MLPs) as an Intrusion Detection System (IDS) for automotive controller area network (CAN). We utilise the FINN framework from AMD/Xilinx to quantise, train and generate hardware IP of our MLP to detect denial of service (DoS) and fuzzying attacks on CAN network, using ZCU104 (XCZU7EV) FPGA as our target ECU architecture with integrated IDS capabilities. Our approach achieves significant improvements in latency (0.12 ms per-message processing latency) and inference energy consumption (0.25 mJ per inference) while achieving similar classification performance as state-of-the-art approaches in the literature.",
        "comments": "2 pages, 1 figure, 2 tables. arXiv admin note: text overlap with arXiv:2401.11030",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12240"
    },
    {
        "doc_id": 257,
        "title": "Spatial Scaper: A Library to Simulate and Augment Soundscapes for Sound Event Localization and Detection in Realistic Rooms",
        "authors": [
            "Iran R. Roman",
            "Christopher Ick",
            "Sivan Ding",
            "Adrian S. Roman",
            "Brian McFee",
            "Juan P. Bello"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Machine Learning",
            "Sound"
        ],
        "abstract": "Sound event localization and detection (SELD) is an important task in machine listening. Major advancements rely on simulated data with sound events in specific rooms and strong spatio-temporal labels. SELD data is simulated by convolving spatialy-localized room impulse responses (RIRs) with sound waveforms to place sound events in a soundscape. However, RIRs require manual collection in specific rooms. We present SpatialScaper, a library for SELD data simulation and augmentation. Compared to existing tools, SpatialScaper emulates virtual rooms via parameters such as size and wall absorption. This allows for parameterized placement (including movement) of foreground and background sound sources. SpatialScaper also includes data augmentation pipelines that can be applied to existing SELD data. As a case study, we use SpatialScaper to add rooms to the DCASE SELD data. Training a model with our data led to progressive performance improves as a direct function of acoustic diversity. These results show that SpatialScaper is valuable to train robust SELD models.",
        "comments": "5 pages, 4 figures, 1 table, to be presented at ICASSP 2024 in Seoul, South Korea",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12238"
    },
    {
        "doc_id": 258,
        "title": "Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot Adaption via Contextual Meta Graph Reinforcement Learning",
        "authors": [
            "Bairong Deng",
            "Tao Yu",
            "Zhenning Pan",
            "Xuehan Zhang",
            "Yufeng Wu",
            "Qiaoyi Ding"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Reinforcement learning is an emerging approaches to facilitate multi-stage sequential decision-making problems. This paper studies a real-time multi-stage stochastic power dispatch considering multivariate uncertainties. Current researches suffer from low generalization and practicality, that is, the learned dispatch policy can only handle a specific dispatch scenario, its performance degrades significantly if actual samples and training samples are inconsistent. To fill these gaps, a novel contextual meta graph reinforcement learning (Meta-GRL) for a highly generalized multi-stage optimal dispatch policy is proposed. Specifically, a more general contextual Markov decision process (MDP) and scalable graph representation are introduced to achieve a more generalized multi-stage stochastic power dispatch modeling. An upper meta-learner is proposed to encode context for different dispatch scenarios and learn how to achieve dispatch task identification while the lower policy learner learns context-specified dispatch policy. After sufficient offline learning, this approach can rapidly adapt to unseen and undefined scenarios with only a few updations of the hypothesis judgments generated by the meta-learner. Numerical comparisons with state-of-the-art policies and traditional reinforcement learning verify the optimality, efficiency, adaptability, and scalability of the proposed Meta-GRL.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12235"
    },
    {
        "doc_id": 259,
        "title": "A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN",
        "authors": [
            "Shashwat Khandelwal",
            "Shreejith Shanker"
        ],
        "subjects": [
            "Hardware Architecture",
            "Cryptography and Security",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Recent years have seen an exponential rise in complex software-driven functionality in vehicles, leading to a rising number of electronic control units (ECUs), network capabilities, and interfaces. These expanded capabilities also bring-in new planes of vulnerabilities making intrusion detection and management a critical capability; however, this can often result in more ECUs and network elements due to the high computational overheads. In this paper, we present a consolidated ECU architecture incorporating an Intrusion Detection System (IDS) for Automotive Controller Area Network (CAN) along with traditional ECU functionality on an off-the-shelf hybrid FPGA device, with near-zero overhead for the ECU functionality. We propose two quantised multi-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of attack vectors including Denial-of-Service, Fuzzing and Spoofing, which are accelerated using off-the-shelf deep-learning processing unit (DPU) IP block from Xilinx, operating fully transparently to the software on the ECU. The proposed models achieve the state-of-the-art classification accuracy for all the attacks, while we observed a 15x reduction in power consumption when compared against the GPU-based implementation of the same models quantised using Nvidia libraries. We also achieved a 2.3x speed up in per-message processing latency (at 0.24 ms from the arrival of a CAN message) to meet the strict end-to-end latency on critical CAN nodes and a 2.6x reduction in power consumption for inference when compared to the state-of-the-art IDS models on embedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the literature.",
        "comments": "9 pages, 3 figures, 11 tables",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12234"
    },
    {
        "doc_id": 260,
        "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies",
        "authors": [
            "Salma M. Elsherif",
            "Mohamad H. Kazma",
            "Ahmad F. Taha"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The operation of water distribution networks is a complex procedure aimed at efficiently delivering consumers with adequate water quantity while ensuring its safe quality. An added challenge is the dependency of the water quality dynamics on the system's hydraulics, which influences the performance of the water quality controller. Prior research has addressed either solving the optimum operational hydraulic setting problem or regulating the water quality dynamics as separate problems. Additionally, there have been efforts to couple these two problems and solve one compact problem resulting in trade-offs between the contradictory objectives. In contrast, this paper examines the dependency and influence from a control-theoretic standpoint. More specifically, we explore the influence of accountability for water quality controllability improvement when addressing the pump scheduling problem. We examine its effects on the cumulative cost of the interconnected systems as well as the subsequent performance of the water quality controller. To achieve this, we develop a framework that incorporates different controllability metrics within the operational hydraulic optimization problem; its aim is attaining an adequate level of water quality control across the system. We assess the aforementioned aspects' performance on various scaled networks with a wide range of numerical scenarios.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12214"
    },
    {
        "doc_id": 261,
        "title": "Programmable EM Sensor Array for Golden-Model Free Run-time Trojan Detection and Localization",
        "authors": [
            "Hanqiu Wang",
            "Max Panoff",
            "Zihao Zhan",
            "Shuo Wang",
            "Christophe Bobda",
            "Domenic Forte"
        ],
        "subjects": [
            "Cryptography and Security",
            "Signal Processing"
        ],
        "abstract": "Side-channel analysis has been proven effective at detecting hardware Trojans in integrated circuits (ICs). However, most detection techniques rely on large external probes and antennas for data collection and require a long measurement time to detect Trojans. Such limitations make these techniques impractical for run-time deployment and ineffective in detecting small Trojans with subtle side-channel signatures. To overcome these challenges, we propose a Programmable Sensor Array (PSA) for run-time hardware Trojan detection, localization, and identification. PSA is a tampering-resilient integrated on-chip magnetic field sensor array that can be re-programmed to change the sensors' shape, size, and location. Using PSA, EM side-channel measurement results collected from sensors at different locations on an IC can be analyzed to localize and identify the Trojan. The PSA has better performance than conventional external magnetic probes and state-of-the-art on-chip single-coil magnetic field sensors. We fabricated an AES-128 test chip with four AES Hardware Trojans. They were successfully detected, located, and identified with the proposed on-chip PSA within 10 milliseconds using our proposed cross-domain analysis.",
        "comments": "6 pages, 5 figures, Accepted at DATE2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12193"
    },
    {
        "doc_id": 262,
        "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
        "authors": [
            "Zachary Novack",
            "Julian McAuley",
            "Taylor Berg-Kirkpatrick",
            "Nicholas J. Bryan"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose frame-work for controlling pre-trained text-to-music diffusion models at inference-time via optimizing initial noise latents. Our method can be used to optimize through any differentiable feature matching loss to achieve a target (stylized) output and leverages gradient checkpointing for memory efficiency. We demonstrate a surprisingly wide-range of applications for music generation including inpainting, outpainting, and looping as well as intensity, melody, and musical structure control - all without ever fine-tuning the underlying model. When we compare our approach against related training, guidance, and optimization-based methods, we find DITTO achieves state-of-the-art performance on nearly all tasks, including outperforming comparable approaches on controllability, audio quality, and computational efficiency, thus opening the door for high-quality, flexible, training-free control of diffusion models. Sound examples can be found at https://DITTO-Music.github.io/web/.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12179"
    },
    {
        "doc_id": 263,
        "title": "Waveform-Domain Complementary Signal Sets for Interrupted Sampling Repeater Jamming Suppression",
        "authors": [
            "Hanning Su",
            "Qinglong Bao",
            "Jiameng Pan",
            "Fucheng Guo",
            "Weidong Hu"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The interrupted-sampling repeater jamming (ISRJ) is coherent and has the characteristic of suppression and deception to degrade the radar detection capabilities. The study focuses on anti-ISRJ techniques in the waveform domain, primarily capitalizing on waveform design and and anti-jamming signal processing methods in the waveform domain. By exploring the relationship between waveform-domain adaptive matched filtering (WD-AMF) output and waveform-domain signals, we demonstrate that ISRJ can be effectively suppressed when the transmitted waveform exhibits waveform-domain complementarity. We introduce a phase-coded (PC) waveform set with waveform-domain complementarity and propose a method for generating such waveform sets of arbitrary code lengths. The performance of WD-AMF are further developed due to the designed waveforms, and simulations affirm the superior adaptive anti-jamming capabilities of the designed waveforms compared to traditional ones. Remarkably, this improved performance is achieved without the need for prior knowledge of ISRJ interference parameters at either the transmitter or receiver stages.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12173"
    },
    {
        "doc_id": 264,
        "title": "Robust stability analysis of an energy-efficient control in a Networked Control System with application to Unmanned Ground Vehicles",
        "authors": [
            "Antonio Gonzalez",
            "Angel Cuenca",
            "Julian Salt",
            "Jelle Jacobs"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "In this paper, the robust stability and disturbance rejection performance analysis of an energy-efficient control is addressed in the framework of Networked Control System (NCS). The control scheme under study integrates periodic event-triggered control, packet-based control, time-varying Kalman filter, dual-rate control and prediction techniques, whose design is aimed at reducing energy consumption and bandwidth usage. The robust stability against time-varying model uncertainties is analyzed by means of a suficient condition based on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the proposed approach is experimentally validated in a tracking control for an Unmanned Ground Vehicle (UGV), which is a battery-constrained mobile device with limited computation capacities.",
        "comments": "38 pages, 12 figures, Information Sciences, 2021",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12172"
    },
    {
        "doc_id": 265,
        "title": "Dynamic Semantic Compression for CNN Inference in Multi-access Edge Computing: A Graph Reinforcement Learning-based Autoencoder",
        "authors": [
            "Nan Li",
            "Alexandros Iosifidis",
            "Qi Zhang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "This paper studies the computational offloading of CNN inference in dynamic multi-access edge computing (MEC) networks. To address the uncertainties in communication time and computation resource availability, we propose a novel semantic compression method, autoencoder-based CNN architecture (AECNN), for effective semantic extraction and compression in partial offloading. In the semantic encoder, we introduce a feature compression module based on the channel attention mechanism in CNNs, to compress intermediate data by selecting the most informative features. In the semantic decoder, we design a lightweight decoder to reconstruct the intermediate data through learning from the received compressed data to improve accuracy. To effectively trade-off communication, computation, and inference accuracy, we design a reward function and formulate the offloading problem of CNN inference as a maximization problem with the goal of maximizing the average inference accuracy and throughput over the long term. To address this maximization problem, we propose a graph reinforcement learning-based AECNN (GRL-AECNN) method, which outperforms existing works DROO-AECNN, GRL-BottleNet++ and GRL-DeepJSCC under different dynamic scenarios. This highlights the advantages of GRL-AECNN in offloading decision-making in dynamic MEC.",
        "comments": "arXiv admin note: text overlap with arXiv:2211.13745",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12167"
    },
    {
        "doc_id": 266,
        "title": "ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A Generalized Score-based Diffusion Post-filter",
        "authors": [
            "Yi-Chiao Wu",
            "Dejan Markovi\u0107",
            "Steven Krenn",
            "Israel D. Gebru",
            "Alexander Richard"
        ],
        "subjects": [
            "Audio and Speech Processing"
        ],
        "abstract": "Although recent mainstream waveform-domain end-to-end (E2E) neural audio codecs achieve impressive coded audio quality with a very low bitrate, the quality gap between the coded and natural audio is still significant. A generative adversarial network (GAN) training is usually required for these E2E neural codecs because of the difficulty of direct phase modeling. However, such adversarial learning hinders these codecs from preserving the original phase information. To achieve human-level naturalness with a reasonable bitrate, preserve the original phase, and get rid of the tricky and opaque GAN training, we develop a score-based diffusion post-filter (SPF) in the complex spectral domain and combine our previous AudioDec with the SPF to propose ScoreDec, which can be trained using only spectral and score-matching losses. Both the objective and subjective experimental results show that ScoreDec with a 24~kbps bitrate encodes and decodes full-band 48~kHz speech with human-level naturalness and well-preserved phase information.",
        "comments": "5 pages, 3 figures, 2 tables. Proc. ICASSP, 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12160"
    },
    {
        "doc_id": 267,
        "title": "Efficient Resource Allocation and User Association in NOMA-Enabled Vehicular-Aided HetNets with High Altitude Platforms",
        "authors": [
            "Ali Nauman",
            "Mashael Maashi",
            "Hend K. Alkahtani",
            "Fahd N. Al-Wesabi",
            "Nojood O Aljehane",
            "Mohammed Assiri",
            "Sara Saadeldeen Ibrahim",
            "Wali Ullah Khan"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The increasing demand for massive connectivity and high data rates has made the efficient use of existing spectrum resources an increasingly challenging problem. Non-orthogonal multiple access (NOMA) is a potential solution for future heterogeneous networks (HetNets) due to its high capacity and spectrum efficiency. In this study, we analyze an uplink NOMA-enabled vehicular-aided HetNet, where multiple vehicular user equipment (VUEs) share the access link spectrum, and a high-altitude platform (HAP) communicates with roadside units (RSUs) through a backhaul communication link. We propose an improved algorithm for user association that selects VUEs for HAPs based on channel coefficient ratios and terrestrial VUEs based on a caching-state backhaul communication link. The joint optimization problems aim to maximize a utility function that considers VUE transmission rates and cross-tier interference while meeting the constraints of backhaul transmission rates and QoS requirements of each VUE. The joint resource allocation optimization problem consists of three sub-problems: bandwidth allocation, user association, and transmission power allocation. We derive a closed-form solution for bandwidth allocation and solve the transmission power allocation sub-problem iteratively using Taylor expansion to transform a non-convex term into a convex one. Our proposed three-stage iterative algorithm for resource allocation integrates all three sub-problems and is shown to be effective through simulation results. Specifically, the results demonstrate that our solution achieves performance improvements over existing approaches.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12141"
    },
    {
        "doc_id": 268,
        "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
        "authors": [
            "John D. Mayfield",
            "Issam El Naqa"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Image and Video Processing"
        ],
        "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term Memory (LSTM) models were studied to provide sequential relationships for each timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot study, we compared three QCNN-LSTM models for binary classification of MS disability benchmarked against classical neural network architectures. Our hypothesis is that quantum models will provide competitive performance. Methods Matrix Product State (MPS), reverse Multistate Entanglement Renormalization Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM layer to process near-annual MRI data of patients diagnosed with MS. These were benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision Transformer (ViViT). Predicted logits were measured against ground truth labels of each patient's Extended Disability Severity Score (EDSS) using binary cross-entropy loss. Training/validation/holdout testing was partitioned using 5-fold cross validation with a total split of 60:20:20. Levene's test of variance was used to measure statistical difference and Student's t-test for paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively (p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73 and 0.77, respectively (p-value 0.631). Overall variance and mean were not statistically significant (p-value 0.713), however, time to train was significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218, respectively, p-value <0.001). Conclusion QCNN-LSTM models perform competitively to their classical counterparts with greater efficiency in train time. Clinically, these can add value in terms of efficiency to time-dependent deep learning prediction of disease progression based upon medical imaging.",
        "comments": "ACM Class:          I.2.0; I.2.6",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12132"
    },
    {
        "doc_id": 269,
        "title": "Energy-aware Trajectory Optimization for UAV-mounted RIS and Full-duplex Relay",
        "authors": [
            "Dimitrios Tyrovolas",
            "Nikos A. Mitsiou",
            "Thomas G. Boufikos",
            "Prodromos-Vasileios Mekikis",
            "Sotiris A. Tegos",
            "Panagiotis D. Diamantoulakis",
            "Sotiris Ioannidis",
            "Christos K. Liaskos",
            "George K. Karagiannidis"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "In the evolving landscape of sixth-generation (6G) wireless networks, unmanned aerial vehicles (UAVs) have emerged as transformative tools for dynamic and adaptive connectivity. However, dynamically adjusting their position to offer favorable communication channels introduces operational challenges in terms of energy consumption, especially when integrating advanced communication technologies like reconfigurable intelligent surfaces (RISs) and full-duplex relays (FDRs). To this end, by recognizing the pivotal role of UAV mobility, the paper introduces an energy-aware trajectory design for UAV-mounted RISs and UAV-mounted FDRs using the decode and forward (DF) protocol, aiming to maximize the network minimum rate and enhance user fairness, while taking into consideration the available on-board energy. Specifically, this work highlights their distinct energy consumption characteristics and their associated integration challenges by developing appropriate energy consumption models for both UAV-mounted RISs and FDRs that capture the intricate relationship between key factors such as weight, and their operational characteristics. Furthermore, a joint time-division multiple access (TDMA) user scheduling-UAV trajectory optimization problem is formulated, considering the power dynamics of both systems, while assuring that the UAV energy is not depleted mid-air. Finally, simulation results underscore the importance of energy considerations in determining the optimal trajectory and scheduling and provide insights into the performance comparison of UAV-mounted RISs and FDRs in UAV-assisted wireless networks.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12107"
    },
    {
        "doc_id": 270,
        "title": "Consistency Based Unsupervised Self-training For ASR Personalisation",
        "authors": [
            "Jisi Zhang",
            "Vandana Rajan",
            "Haaris Mehmood",
            "David Tuckey",
            "Pablo Peso Parada",
            "Md Asif Jalal",
            "Karthikeyan Saravanan",
            "Gil Ho Lee",
            "Jungin Lee",
            "Seokyeong Jung"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "On-device Automatic Speech Recognition (ASR) models trained on speech data of a large population might underperform for individuals unseen during training. This is due to a domain shift between user data and the original training data, differed by user's speaking characteristics and environmental acoustic conditions. ASR personalisation is a solution that aims to exploit user data to improve model robustness. The majority of ASR personalisation methods assume labelled user data for supervision. Personalisation without any labelled data is challenging due to limited data size and poor quality of recorded audio samples. This work addresses unsupervised personalisation by developing a novel consistency based training method via pseudo-labelling. Our method achieves a relative Word Error Rate Reduction (WERR) of 17.3% on unlabelled training data and 8.1% on held-out data compared to a pre-trained model, and outperforms the current state-of-the art methods.",
        "comments": "Accepted for IEEE ASRU 2023",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12085"
    },
    {
        "doc_id": 271,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Maria de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 272,
        "title": "Resource-constrained stereo singing voice cancellation",
        "authors": [
            "Clara Borrelli",
            "James Rae",
            "Dogac Basaran",
            "Matt McVicar",
            "Mehrez Souden",
            "Matthias Mauch"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "We study the problem of stereo singing voice cancellation, a subtask of music source separation, whose goal is to estimate an instrumental background from a stereo mix. We explore how to achieve performance similar to large state-of-the-art source separation networks starting from a small, efficient model for real-time speech separation. Such a model is useful when memory and compute are limited and singing voice processing has to run with limited look-ahead. In practice, this is realised by adapting an existing mono model to handle stereo input. Improvements in quality are obtained by tuning model parameters and expanding the training set. Moreover, we highlight the benefits a stereo model brings by introducing a new metric which detects attenuation inconsistencies between channels. Our approach is evaluated using objective offline metrics and a large-scale MUSHRA trial, confirming the effectiveness of our techniques in stringent listening tests.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12068"
    },
    {
        "doc_id": 273,
        "title": "NEUROSEC: FPGA-Based Neuromorphic Audio Security",
        "authors": [
            "Murat Isik",
            "Hiruna Vishwamith",
            "Yusuf Sur",
            "Kayode Inadagbo",
            "I. Can Dikmen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Emerging Technologies",
            "Machine Learning",
            "Neural and Evolutionary Computing",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Neuromorphic systems, inspired by the complexity and functionality of the human brain, have gained interest in academic and industrial attention due to their unparalleled potential across a wide range of applications. While their capabilities herald innovation, it is imperative to underscore that these computational paradigms, analogous to their traditional counterparts, are not impervious to security threats. Although the exploration of neuromorphic methodologies for image and video processing has been rigorously pursued, the realm of neuromorphic audio processing remains in its early stages. Our results highlight the robustness and precision of our FPGA-based neuromorphic system. Specifically, our system showcases a commendable balance between desired signal and background noise, efficient spike rate encoding, and unparalleled resilience against adversarial attacks such as FGSM and PGD. A standout feature of our framework is its detection rate of 94%, which, when compared to other methodologies, underscores its greater capability in identifying and mitigating threats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic computing and hardware security serve many sensor domains in mission-critical and privacy-preserving applications.",
        "comments": "Audio processing, FPGA, Hardware Security, Neuromorphic Computing",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12055"
    },
    {
        "doc_id": 274,
        "title": "Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling",
        "authors": [
            "Bruno Korbar",
            "Jaesung Huh",
            "Andrew Zisserman"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "The goal of this paper is automatic character-aware subtitle generation. Given a video and a minimal amount of metadata, we propose an audio-visual method that generates a full transcript of the dialogue, with precise speech timestamps, and the character speaking identified. The key idea is to first use audio-visual cues to select a set of high-precision audio exemplars for each character, and then use these exemplars to classify all speech segments by speaker identity. Notably, the method does not require face detection or tracking. We evaluate the method over a variety of TV sitcoms, including Seinfeld, Fraiser and Scrubs. We envision this system being useful for the automatic generation of subtitles to improve the accessibility of the vast amount of videos available on modern streaming services. Project page : \\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}",
        "comments": "Accepted for publication in ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12039"
    },
    {
        "doc_id": 275,
        "title": "A Survey of Advances in Optimization Methods for Wireless Communication System Design",
        "authors": [
            "Ya-Feng Liu",
            "Tsung-Hui Chang",
            "Mingyi Hong",
            "Zheyu Wu",
            "Anthony Man-Cho So",
            "Eduard A. Jorswieck",
            "Wei Yu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing",
            "Optimization and Control"
        ],
        "abstract": "Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recent advances in mathematical optimization theory and algorithms, from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing and/or developing suitable optimization algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.",
        "comments": "47 pages, 10 figures, submitted for possible publication",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12025"
    },
    {
        "doc_id": 276,
        "title": "NLCG-Net: A Model-Based Zero-Shot Learning Framework for Undersampled Quantitative MRI Reconstruction",
        "authors": [
            "Xinrui Jiang",
            "Yohan Jun",
            "Jaejin Cho",
            "Mengze Gao",
            "Xingwang Yong",
            "Berkin Bilgic"
        ],
        "subjects": [
            "Image and Video Processing",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Typical quantitative MRI (qMRI) methods estimate parameter maps after image reconstructing, which is prone to biases and error propagation. We propose a Nonlinear Conjugate Gradient (NLCG) optimizer for model-based T2/T1 estimation, which incorporates U-Net regularization trained in a scan-specific manner. This end-to-end method directly estimates qMRI maps from undersampled k-space data using mono-exponential signal modeling with zero-shot scan-specific neural network regularization to enable high fidelity T1 and T2 mapping. T2 and T1 mapping results demonstrate the ability of the proposed NLCG-Net to improve estimation quality compared to subspace reconstruction at high accelerations.",
        "comments": "8 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12004"
    },
    {
        "doc_id": 277,
        "title": "Lightweight Protection for Privacy in Offloaded Speech Understanding",
        "authors": [
            "Dongqi Cai",
            "Shangguang Wang",
            "Zeling Zhang",
            "Felix Xiaozhu Lin",
            "Mengwei Xu"
        ],
        "subjects": [
            "Sound",
            "Cryptography and Security",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech is a common input method for mobile embedded devices, but cloud-based speech recognition systems pose privacy risks. Disentanglement-based encoders, designed to safeguard user privacy by filtering sensitive information from speech signals, unfortunately require substantial memory and computational resources, which limits their use in less powerful devices. To overcome this, we introduce a novel system, XXX, optimized for such devices. XXX is built on the insight that speech understanding primarily relies on understanding the entire utterance's long-term dependencies, while privacy concerns are often linked to short-term details. Therefore, XXX focuses on selectively masking these short-term elements, preserving the quality of long-term speech understanding. The core of XXX is an innovative differential mask generator, grounded in interpretable learning, which fine-tunes the masking process. We tested XXX on the STM32H7 microcontroller, assessing its performance in various potential attack scenarios. The results show that XXX maintains speech understanding accuracy and privacy at levels comparable to existing encoders, but with a significant improvement in efficiency, achieving up to 53.3$\\times$ faster processing and a 134.1$\\times$ smaller memory footprint.",
        "comments": "under review",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11983"
    },
    {
        "doc_id": 278,
        "title": "Enhancing Safety in Nonlinear Systems: Design and Stability Analysis of Adaptive Cruise Control",
        "authors": [
            "Fan Yang",
            "Haoqi Li",
            "Maolong Lv",
            "Jiangping Hu",
            "Qingrui Zhou",
            "Bijoy K. Ghosh"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The safety of autonomous driving systems, particularly self-driving vehicles, remains of paramount concern. These systems exhibit affine nonlinear dynamics and face the challenge of executing predefined control tasks while adhering to state and input constraints to mitigate risks. However, achieving safety control within the framework of control input constraints, such as collision avoidance and maintaining system states within secure boundaries, presents challenges due to limited options. In this study, we introduce a novel approach to address safety concerns by transforming safety conditions into control constraints with a relative degree of 1. This transformation is facilitated through the design of control barrier functions, enabling the creation of a safety control system for affine nonlinear networks. Subsequently, we formulate a robust control strategy that incorporates safety protocols and conduct a comprehensive analysis of its stability and reliability. To illustrate the effectiveness of our approach, we apply it to a specific problem involving adaptive cruise control. Through simulations, we validate the efficiency of our model in ensuring safety without compromising control performance. Our approach signifies significant progress in the field, providing a practical solution to enhance safety for autonomous driving systems operating within the context of affine nonlinear dynamics.",
        "comments": "11pages,9figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11961"
    },
    {
        "doc_id": 279,
        "title": "Observation-Guided Meteorological Field Downscaling at Station Scale: A Benchmark and a New Method",
        "authors": [
            "Zili Liu",
            "Hao Chen",
            "Lei Bai",
            "Wenyuan Li",
            "Keyan Chen",
            "Zhengyi Wang",
            "Wanli Ouyang",
            "Zhengxia Zou",
            "Zhenwei Shi"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Image and Video Processing"
        ],
        "abstract": "Downscaling (DS) of meteorological variables involves obtaining high-resolution states from low-resolution meteorological fields and is an important task in weather forecasting. Previous methods based on deep learning treat downscaling as a super-resolution task in computer vision and utilize high-resolution gridded meteorological fields as supervision to improve resolution at specific grid scales. However, this approach has struggled to align with the continuous distribution characteristics of meteorological fields, leading to an inherent systematic bias between the downscaled results and the actual observations at meteorological stations. In this paper, we extend meteorological downscaling to arbitrary scattered station scales, establish a brand new benchmark and dataset, and retrieve meteorological states at any given station location from a coarse-resolution meteorological field. Inspired by data assimilation techniques, we integrate observational data into the downscaling process, providing multi-scale observational priors. Building on this foundation, we propose a new downscaling model based on hypernetwork architecture, namely HyperDS, which efficiently integrates different observational information into the model training, achieving continuous scale modeling of the meteorological field. Through extensive experiments, our proposed method outperforms other specially designed baseline models on multiple surface variables. Notably, the mean squared error (MSE) for wind speed and surface pressure improved by 67% and 19.5% compared to other methods. We will release the dataset and code subsequently.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11960"
    },
    {
        "doc_id": 280,
        "title": "Maximizing Spectral and Energy Efficiency in Multi-user MIMO OFDM Systems with RIS and Hardware Impairment",
        "authors": [
            "Mohammad Soleymani",
            "Ignacio Santamaria",
            "Aydin Sezgin",
            "Eduard Jorswieck"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "An emerging technology to enhance the spectral efficiency (SE) and energy efficiency (EE) of wireless communication systems is reconfigurable intelligent surface (RIS), which is shown to be very powerful in single-carrier systems. However, in multi-user orthogonal frequency division multiplexing (OFDM) systems, RIS may not be as promising as in single-carrier systems since an independent optimization of RIS elements at each sub-carrier is impossible in multi-carrier systems. Thus, this paper investigates the performance of various RIS technologies like regular (reflective and passive), simultaneously transmit and reflect (STAR), and multi-sector beyond diagonal (BD) RIS in multi-user multiple-input multiple-output (MIMO) OFDM broadcast channels (BC). This requires to formulate and solve a joint MIMO precoding and RIS optimization problem. The obtained solution reveals that RIS can significantly improve the system performance even when the number of RIS elements is relatively low. Moreover, we develop resource allocation schemes for STAR-RIS and multi-sector BD-RIS in MIMO OFDM BCs, and show that these RIS technologies can outperform a regular RIS, especially when the regular RIS cannot assist the communications for all the users.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11921"
    },
    {
        "doc_id": 281,
        "title": "A Training-Free Defense Framework for Robust Learned Image Compression",
        "authors": [
            "Myungseo Song",
            "Jinyoung Choi",
            "Bohyung Han"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We study the robustness of learned image compression models against adversarial attacks and present a training-free defense technique based on simple image transform functions. Recent learned image compression models are vulnerable to adversarial attacks that result in poor compression rate, low reconstruction quality, or weird artifacts. To address the limitations, we propose a simple but effective two-way compression algorithm with random input transforms, which is conveniently applicable to existing image compression models. Unlike the na\u00efve approaches, our approach preserves the original rate-distortion performance of the models on clean images. Moreover, the proposed algorithm requires no additional training or modification of existing models, making it more practical. We demonstrate the effectiveness of the proposed techniques through extensive experiments under multiple compression models, evaluation metrics, and attack scenarios.",
        "comments": "10 pages and 14 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11902"
    },
    {
        "doc_id": 282,
        "title": "Fully Differentiable Ray Tracing via Discontinuity Smoothing for Radio Network Optimization",
        "authors": [
            "Jerome Eertmans",
            "Laurent Jacques",
            "Claude Oestges"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Recently, Differentiable Ray Tracing has been successfully applied in the field of wireless communications for learning radio materials or optimizing the transmitter orientation. However, in the frame of gradient based optimization, obstruction of the rays by objects can cause sudden variations in the related objective functions or create entire regions where the gradient is zero. As these issues can dramatically impact convergence, this paper presents a novel Ray Tracing framework that is fully differentiable with respect to any scene parameter, but also provides a loss function continuous everywhere, thanks to specific local smoothing techniques. Previously non-continuous functions are replaced by a smoothing function, that can be exchanged with any function having similar properties. This function is also configurable via a parameter that determines how smooth the approximation should be. The present method is applied on a basic one-transmitter-multi-receiver scenario, and shows that it can successfully find the optimal solution. As a complementary resource, a 2D Python library, DiffeRT2d, is provided in Open Access, with examples and a comprehensive documentation.",
        "comments": "5 pages, 5 figures, accepted at EuCAP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11882"
    },
    {
        "doc_id": 283,
        "title": "A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection",
        "authors": [
            "Yuandi Wu",
            "Brett Sicard",
            "Stephen Andrew Gadsden"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control"
        ],
        "abstract": "This study presents a comprehensive overview of PIML techniques in the context of condition monitoring. The central concept driving PIML is the incorporation of known physical laws and constraints into machine learning algorithms, enabling them to learn from available data while remaining consistent with physical principles. Through fusing domain knowledge with data-driven learning, PIML methods offer enhanced accuracy and interpretability in comparison to purely data-driven approaches. In this comprehensive survey, detailed examinations are performed with regard to the methodology by which known physical principles are integrated within machine learning frameworks, as well as their suitability for specific tasks within condition monitoring. Incorporation of physical knowledge into the ML model may be realized in a variety of methods, with each having its unique advantages and drawbacks. The distinct advantages and limitations of each methodology for the integration of physics within data-driven models are detailed, considering factors such as computational efficiency, model interpretability, and generalizability to different systems in condition monitoring and fault detection. Several case studies and works of literature utilizing this emerging concept are presented to demonstrate the efficacy of PIML in condition monitoring applications. From the literature reviewed, the versatility and potential of PIML in condition monitoring may be demonstrated. Novel PIML methods offer an innovative solution for addressing the complexities of condition monitoring and associated challenges. This comprehensive survey helps form the foundation for future work in the field. As the technology continues to advance, PIML is expected to play a crucial role in enhancing maintenance strategies, system reliability, and overall operational efficiency in engineering systems.",
        "comments": "Paper has been submitted for review to the journal Expert Systems with Applications (December 31, 2023). 90 pages, 22 figures, 9 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11860"
    },
    {
        "doc_id": 284,
        "title": "LKFormer: Large Kernel Transformer for Infrared Image Super-Resolution",
        "authors": [
            "Feiwei Qin",
            "Kang Yan",
            "Changmiao Wang",
            "Ruiquan Ge",
            "Yong Peng",
            "Kai Zhang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Given the broad application of infrared technology across diverse fields, there is an increasing emphasis on investigating super-resolution techniques for infrared images within the realm of deep learning. Despite the impressive results of current Transformer-based methods in image super-resolution tasks, their reliance on the self-attentive mechanism intrinsic to the Transformer architecture results in images being treated as one-dimensional sequences, thereby neglecting their inherent two-dimensional structure. Moreover, infrared images exhibit a uniform pixel distribution and a limited gradient range, posing challenges for the model to capture effective feature information. Consequently, we suggest a potent Transformer model, termed Large Kernel Transformer (LKFormer), to address this issue. Specifically, we have designed a Large Kernel Residual Depth-wise Convolutional Attention (LKRDA) module with linear complexity. This mainly employs depth-wise convolution with large kernels to execute non-local feature modeling, thereby substituting the standard self-attentive layer. Additionally, we have devised a novel feed-forward network structure called Gated-Pixel Feed-Forward Network (GPFN) to augment the LKFormer's capacity to manage the information flow within the network. Comprehensive experimental results reveal that our method surpasses the most advanced techniques available, using fewer parameters and yielding considerably superior performance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11859"
    },
    {
        "doc_id": 285,
        "title": "Adversarial speech for voice privacy protection from Personalized Speech generation",
        "authors": [
            "Shihao Chen",
            "Liping Chen",
            "Jie Zhang",
            "KongAik Lee",
            "Zhenhua Ling",
            "Lirong Dai"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "The rapid progress in personalized speech generation technology, including personalized text-to-speech (TTS) and voice conversion (VC), poses a challenge in distinguishing between generated and real speech for human listeners, resulting in an urgent demand in protecting speakers' voices from malicious misuse. In this regard, we propose a speaker protection method based on adversarial attacks. The proposed method perturbs speech signals by minimally altering the original speech while rendering downstream speech generation models unable to accurately generate the voice of the target speaker. For validation, we employ the open-source pre-trained YourTTS model for speech generation and protect the target speaker's speech in the white-box scenario. Automatic speaker verification (ASV) evaluations were carried out on the generated speech as the assessment of the voice protection capability. Our experimental results show that we successfully perturbed the speaker encoder of the YourTTS model using the gradient-based I-FGSM adversarial perturbation method. Furthermore, the adversarial perturbation is effective in preventing the YourTTS model from generating the speech of the target speaker. Audio samples can be found in https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS.",
        "comments": "Accepted by icassp 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11857"
    },
    {
        "doc_id": 286,
        "title": "MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation",
        "authors": [
            "De-Xing Huang",
            "Xiao-Hu Zhou",
            "Xiao-Liang Xie",
            "Shi-Qi Liu",
            "Zhen-Qiu Feng",
            "Mei-Jiang Gui",
            "Hao Li",
            "Tian-Yu Xiang",
            "Xiu-Ling Liu",
            "Zeng-Guang Hou"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Medical image segmentation takes an important position in various clinical applications. Deep learning has emerged as the predominant solution for automated segmentation of volumetric medical images. 2.5D-based segmentation models bridge computational efficiency of 2D-based models and spatial perception capabilities of 3D-based models. However, prevailing 2.5D-based models often treat each slice equally, failing to effectively learn and exploit inter-slice information, resulting in suboptimal segmentation performances. In this paper, a novel Momentum encoder-based inter-slice fusion transformer (MOSformer) is proposed to overcome this issue by leveraging inter-slice information at multi-scale feature maps extracted by different encoders. Specifically, dual encoders are employed to enhance feature distinguishability among different slices. One of the encoders is moving-averaged to maintain the consistency of slice representations. Moreover, an IF-Swin transformer module is developed to fuse inter-slice multi-scale features. The MOSformer is evaluated on three benchmark datasets (Synapse, ACDC, and AMOS), establishing a new state-of-the-art with 85.63%, 92.19%, and 85.43% of DSC, respectively. These promising results indicate its competitiveness in medical image segmentation. Codes and models of MOSformer will be made publicly available upon acceptance.",
        "comments": "Under Review",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11856"
    },
    {
        "doc_id": 287,
        "title": "Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical Federated Learning Approach",
        "authors": [
            "Qiqing Wang",
            "Kaidi Yang"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Systems and Control"
        ],
        "abstract": "This paper proposes a privacy-preserving data fusion method for traffic state estimation (TSE). Unlike existing works that assume all data sources to be accessible by a single trusted party, we explicitly address data privacy concerns that arise in the collaboration and data sharing between multiple data owners, such as municipal authorities (MAs) and mobility providers (MPs). To this end, we propose a novel vertical federated learning (FL) approach, FedTSE, that enables multiple data owners to collaboratively train and apply a TSE model without having to exchange their private data. To enhance the applicability of the proposed FedTSE in common TSE scenarios with limited availability of ground-truth data, we further propose a privacy-preserving physics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models into FL. Real-world data validation shows that the proposed methods can protect privacy while yielding similar accuracy to the oracle method without privacy considerations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11836"
    },
    {
        "doc_id": 288,
        "title": "Intelligibility Enhancement of Acoustic Noisy Speech for Autism Spectrum Disorder Condition",
        "authors": [
            "M. Pillonetto",
            "A. Queiroz",
            "R. Coelho"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "This work introduces a time domain personalized method (pGTFF0) to achieve intelligibility improvement of noisy speech for Autism Spectrum Disorder (ASD) situation. For this proposal, harmonic features estimated from speech frames are considered as center frequencies of Gammatone auditory filterbanks. A gain factor is further applied to the output of the filtered samples. The key goal is the emulation of an external noise filtering tailored for individuals with ASD. A perceptual listening test demonstrates that ASD volunteers attained lower intelligibility rates than Neurotypical (NT). The proposed solution is compared to three competing approaches considering four acoustic noises at different signal-to-noise ratios. Two objective measures (ESTOI and PESQ) are also adopted for evaluation. The experimental results show that the personalized solution outperformed the competing approaches in terms of intelligibility and quality improvement.",
        "comments": "5 pages, 3 figues, 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11832"
    },
    {
        "doc_id": 289,
        "title": "Harmonic Detection from Noisy Speech with Auditory Frame Gain for Intelligibility Enhancement",
        "authors": [
            "A. Queiroz",
            "R. Coelho"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "This paper introduces a novel (HDAG - Harmonic Detection for Auditory Gain) method for speech intelligibility enhancement in noisy scenarios. In the proposed scheme, a series of selective Gammachirp filters are adopted to emphasize the harmonic components of speech reducing the masking effects of acoustic noises. The fundamental frequency are estimated by the HHT-Amp technique. Harmonic patterns estimated with low accuracy are detected and adjusted according the FSFFE low/high pitch separation. The central frequencies of the filterbank are defined considering the third octave subbands which are best suited to cover the regions most relevant to intelligibility. Before signal reconstruction, the gammachirp filtered components are amplified by gain factors regulated by FSFFE classification. The proposed HDAG solution and three baseline techniques are examined considering six background noises with four signal-to-noise ratios. Three objective measures are adopted for the evaluation of speech intelligibility and quality. Several experiments are conducted to demonstrate that the proposed scheme achieves better speech intelligibility improvement when compared to the competing approaches. A perceptual listening test is further considered and corroborates with the objective results.",
        "comments": "9 pages, 6 figures, 4 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11829"
    },
    {
        "doc_id": 290,
        "title": "Performance Analysis of Fluid Antenna-aided Backscatter Communications Systems",
        "authors": [
            "Farshad Rostami Ghadi",
            "Masoud Kaveh",
            "Kai-Kit Wong"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper studies the performance of backscatter communications (BC) over emerging fluid antenna (FA) technology. In particular, a single-antenna source sends information to a FA reader through the wireless forward (i.e., source-to-tag) and backscatter (tag-to-reader) channels. For the considered BC, we first derive the cumulative distribution function (CDF) of the equivalent channel at the FA receiver, and then we obtain closed-form expressions of the outage probability (OP) and delay outage rate (DOR) under a correlated Rayleigh distribution. Moreover, in order to gain more insights into the system performance, we present analytical expressions of the OP and DOR at the high SNR regime. Numerical results indicate that considering the FA at the reader can significantly improve the performance of BC in terms of the OP and DOR compared with a single-antenna reader.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11820"
    },
    {
        "doc_id": 291,
        "title": "Analyzing the coupling process of distributed mixed real-virtual prototypes",
        "authors": [
            "Peter Baumann",
            "Lars Mikelsons",
            "Oliver Kotte",
            "Dieter Schramm"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The ongoing connection and automation of vehicles leads to a closer interaction of the individual vehicle components, which demands for consideration throughout the entire development process. In the design phase, this is achieved through co-simulation of component models. However, complex co-simulation environments are rarely (re-)used in the verification and validation phases, in which mixed real-virtual prototypes (e.g. Hardware-in-the-Loop) are already available. One reason for this are coupling errors such as time-delays, which inevitably occur in co-simulation of virtual and real-time systems, and which influence system behavior in an unknown and generally detrimental way. This contribution introduces a novel, adaptive method to compensate for constant time-delays in potentially highly nonlinear, spatially distributed mixed real-virtual prototypes, using small feedforward neural networks. Their optimal initialization with respect to defined frequency domain features results from a-priori frequency domain analysis of the entire coupled system, including coupling faults and compensation methods. A linear and a nonlinear example demonstrate the method and emphasize its suitability for nonlinear systems due to online training and adaptation. As the compensation method requires knowledge only of the bandwidths, the proposed method is applicable to distributed mixed real-virtual prototypes in general.",
        "comments": "8 pages, 12 figures, published at 33rd Annual European Simulation and Modelling Conference, ESM 2019",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11779"
    },
    {
        "doc_id": 292,
        "title": "Advancing Accessibility: Voice Cloning and Speech Synthesis for Individuals with Speech Disorders",
        "authors": [
            "Vinotha R",
            "Hepsiba D",
            "L. D. Vijay Anand",
            "Deepak John Reji"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Neural Text-to-speech (TTS) synthesis is a powerful technology that can generate speech using neural networks. One of the most remarkable features of TTS synthesis is its capability to produce speech in the voice of different speakers. This paper introduces voice cloning and speech synthesis https://pypi.org/project/voice-cloning/ an open-source python package for helping speech disorders to communicate more effectively as well as for professionals seeking to integrate voice cloning or speech synthesis capabilities into their projects. This package aims to generate synthetic speech that sounds like the natural voice of an individual, but it does not replace the natural human voice. The architecture of the system comprises a speaker verification system, a synthesizer, a vocoder, and noise reduction. Speaker verification system trained on a varied set of speakers to achieve optimal generalization performance without relying on transcriptions. Synthesizer is trained using both audio and transcriptions that generate Mel spectrogram from a text and vocoder which converts the generated Mel Spectrogram into corresponding audio signal. Then the audio signal is processed by a noise reduction algorithm to eliminate unwanted noise and enhance speech clarity. The performance of synthesized speech from seen and unseen speakers are then evaluated using subjective and objective evaluation such as Mean Opinion Score (MOS), Gross Pitch Error (GPE), and Spectral distortion (SD). The model can create speech in distinct voices by including speaker characteristics that are chosen randomly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11771"
    },
    {
        "doc_id": 293,
        "title": "Massive Synchrony in Distributed Antenna Systems",
        "authors": [
            "Erik G. Larsson"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Distributed antennas must be phase-calibrated (phase-synchronized) for certain operations, such as reciprocity-based joint coherent downlink beamforming, to work. We use rigorous signal processing tools to analyze the accuracy of calibration protocols that are based on over-the-air measurements between antennas, with a focus on scalability aspects for large systems. We show that (i) for some who-measures-on-whom topologies, the errors in the calibration process are unbounded when the network grows; and (ii) despite that conclusion, it is optimal -- irrespective of the topology -- to solve a single calibration problem for the entire system and use the result everywhere to support the beamforming. The analyses are exemplified by investigating specific topologies, including lines, rings, and two-dimensional surfaces.",
        "comments": "Journal ref:        IEEE Transactions on Signal Processing, 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11730"
    },
    {
        "doc_id": 294,
        "title": "Beyond the Manual Touch: Situational-aware Force Control for Increased Safety in Robot-assisted Skullbase Surgery",
        "authors": [
            "Hisashi Ishida",
            "Deepa Galaiya",
            "Nimesh Nagururu",
            "Francis Creighton",
            "Peter Kazanzides",
            "Russell Taylor",
            "Manish Sahu"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Purpose - Skullbase surgery demands exceptional precision when removing bone in the lateral skull base. Robotic assistance can alleviate the effect of human sensory-motor limitations. However, the stiffness and inertia of the robot can significantly impact the surgeon's perception and control of the tool-to-tissue interaction forces. Methods - We present a situational-aware, force control technique aimed at regulating interaction forces during robot-assisted skullbase drilling. The contextual interaction information derived from the digital twin environment is used to enhance sensory perception and suppress undesired high forces. Results - To validate our approach, we conducted initial feasibility experiments involving a medical and two engineering students. The experiment focused on further drilling around critical structures following cortical mastoidectomy. The experiment results demonstrate that robotic assistance coupled with our proposed control scheme effectively limited undesired interaction forces when compared to robotic assistance without the proposed force control. Conclusions - The proposed force control techniques show promise in significantly reducing undesired interaction forces during robot-assisted skullbase surgery. These findings contribute to the ongoing efforts to enhance surgical precision and safety in complex procedures involving the lateral skull base.",
        "comments": "*These authors contributed equally to this work",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11721"
    },
    {
        "doc_id": 295,
        "title": "Integrating 3D Slicer with a Dynamic Simulator for Situational Aware Robotic Interventions",
        "authors": [
            "Manish Sahu",
            "Hisashi Ishida",
            "Laura Connolly",
            "Hongyi Fan",
            "Anton Deguet",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor",
            "Adnan Munawar"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Image-guided robotic interventions represent a transformative frontier in surgery, blending advanced imaging and robotics for improved precision and outcomes. This paper addresses the critical need for integrating open-source platforms to enhance situational awareness in image-guided robotic research. We present an open-source toolset that seamlessly combines a physics-based constraint formulation framework, AMBF, with a state-of-the-art imaging platform application, 3D Slicer. Our toolset facilitates the creation of highly customizable interactive digital twins, that incorporates processing and visualization of medical imaging, robot kinematics, and scene dynamics for real-time robot control. Through a feasibility study, we showcase real-time synchronization of a physical robotic interventional environment in both 3D Slicer and AMBF, highlighting low-latency updates and improved visualization.",
        "comments": "*These authors contributed equally",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11715"
    },
    {
        "doc_id": 296,
        "title": "Haptic-Assisted Collaborative Robot Framework for Improved Situational Awareness in Skull Base Surgery",
        "authors": [
            "Hisashi Ishida",
            "Manish Sahu",
            "Adnan Munawar",
            "Nimesh Nagururu",
            "Deepa Galaiya",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Skull base surgery is a demanding field in which surgeons operate in and around the skull while avoiding critical anatomical structures including nerves and vasculature. While image-guided surgical navigation is the prevailing standard, limitation still exists requiring personalized planning and recognizing the irreplaceable role of a skilled surgeon. This paper presents a collaboratively controlled robotic system tailored for assisted drilling in skull base surgery. Our central hypothesis posits that this collaborative system, enriched with haptic assistive modes to enforce virtual fixtures, holds the potential to significantly enhance surgical safety, streamline efficiency, and alleviate the physical demands on the surgeon. The paper describes the intricate system development work required to enable these virtual fixtures through haptic assistive modes. To validate our system's performance and effectiveness, we conducted initial feasibility experiments involving a medical student and two experienced surgeons. The experiment focused on drilling around critical structures following cortical mastoidectomy, utilizing dental stone phantom and cadaveric models. Our experimental results demonstrate that our proposed haptic feedback mechanism enhances the safety of drilling around critical structures compared to systems lacking haptic assistance. With the aid of our system, surgeons were able to safely skeletonize the critical structures without breaching any critical structure even under obstructed view of the surgical site.",
        "comments": "*These authors contributed equally",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11709"
    },
    {
        "doc_id": 297,
        "title": "Keep Decoding Parallel with Effective Knowledge Distillation from Language Models to End-to-end Speech Recognisers",
        "authors": [
            "Michael Hentschel",
            "Yuta Nishikawa",
            "Tatsuya Komatsu",
            "Yusuke Fujita"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "This study presents a novel approach for knowledge distillation (KD) from a BERT teacher model to an automatic speech recognition (ASR) model using intermediate layers. To distil the teacher's knowledge, we use an attention decoder that learns from BERT's token probabilities. Our method shows that language model (LM) information can be more effectively distilled into an ASR model using both the intermediate layers and the final layer. By using the intermediate layers as distillation target, we can more effectively distil LM knowledge into the lower network layers. Using our method, we achieve better recognition accuracy than with shallow fusion of an external LM, allowing us to maintain fast parallel decoding. Experiments on the LibriSpeech dataset demonstrate the effectiveness of our approach in enhancing greedy decoding with connectionist temporal classification (CTC).",
        "comments": "Accepted at ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11700"
    },
    {
        "doc_id": 298,
        "title": "Emulation-based Stabilization for Networked Control Systems with Stochastic Channels",
        "authors": [
            "Wei Ren",
            "Wei Wang",
            "Zhuo-Rui Pan",
            "Xi-Ming Sun",
            "Andrew R. Teel",
            "Dragan Nesic"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper studies the stabilization problem of networked control systems (NCSs) with random packet dropouts caused by stochastic channels. To describe the effects of stochastic channels on the information transmission, the transmission times are assumed to be deterministic, whereas the packet transmission is assumed to be random. We first propose a stochastic scheduling protocol to model random packet dropouts, and address the properties of the proposed stochastic scheduling protocol. The proposed scheduling protocol provides a unified modelling framework for a general class of random packet dropouts due to different stochastic channels. Next, the proposed scheduling protocol is embedded into the closed-loop system, which leads to a stochastic hybrid model for NCSs with random packet dropouts. Based on this stochastic hybrid model, we follow the emulation approach to establish sufficient conditions to guarantee uniform global asymptotical stability in probability. In particular, an upper bound on the maximally allowable transmission interval is derived explicitly for all stochastic protocols satisfying Lyapunov conditions that guarantee uniform global asymptotic stability in probability. Finally, two numerical examples are presented to demonstrate the derived results.",
        "comments": "12 pages, 4 figures, accepted",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11677"
    },
    {
        "doc_id": 299,
        "title": "Rethinking Cross-Attention for Infrared and Visible Image Fusion",
        "authors": [
            "Lihua Jian",
            "Songlei Xiong",
            "Han Yan",
            "Xiaoguang Niu",
            "Shaowu Wu",
            "Di Zhang"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "The salient information of an infrared image and the abundant texture of a visible image can be fused to obtain a comprehensive image. As can be known, the current fusion methods based on Transformer techniques for infrared and visible (IV) images have exhibited promising performance. However, the attention mechanism of the previous Transformer-based methods was prone to extract common information from source images without considering the discrepancy information, which limited fusion performance. In this paper, by reevaluating the cross-attention mechanism, we propose an alternate Transformer fusion network (ATFuse) to fuse IV images. Our ATFuse consists of one discrepancy information injection module (DIIM) and two alternate common information injection modules (ACIIM). The DIIM is designed by modifying the vanilla cross-attention mechanism, which can promote the extraction of the discrepancy information of the source images. Meanwhile, the ACIIM is devised by alternately using the vanilla cross-attention mechanism, which can fully mine common information and integrate long dependencies. Moreover, the successful training of ATFuse is facilitated by a proposed segmented pixel loss function, which provides a good trade-off for texture detail and salient structure preservation. The qualitative and quantitative results on public datasets indicate our ATFFuse is effective and superior compared to other state-of-the-art methods.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11675"
    },
    {
        "doc_id": 300,
        "title": "Mapping dust in the giant molecular cloud Orion A",
        "authors": [
            "Amery Gration",
            "John Magorrian"
        ],
        "subjects": [
            "Astrophysics of Galaxies"
        ],
        "abstract": "The Sun is located close to the Galactic mid-plane, meaning that we observe the Galaxy through significant quantities of dust. Moreover, the vast majority of the Galaxy's stars also lie in the disc, meaning that dust has an enormous impact on the massive astrometric, photometric and spectroscopic surveys of the Galaxy that are currently underway. To exploit the data from these surveys we require good three-dimensional maps of the Galaxy's dust. We present a new method for making such maps in which we form the best linear unbiased predictor of the extinction at an arbitrary point based on the extinctions for a set of observed stars. This method allows us to avoid the artificial inhomogeneities (so-called 'fingers of God') and resolution limits that are characteristic of many published dust maps. Moreover, it requires minimal assumptions about the statistical properties of the interstellar medium. In fact, we require only a model of the first and second moments of the dust density field. The method is suitable for use with directly measured extinctions, such as those provided by the Rayleigh-Jeans colour excess method, and inferred extinctions, such as those provided by hierarchical Bayesian models like StarHorse. We test our method by mapping dust in the region of the giant molecular cloud Orion A. Our results indicate a foreground dust cloud at a distance of 350 pc, which has been identified in work by another author.",
        "comments": "21 pages, 30 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12976"
    },
    {
        "doc_id": 301,
        "title": "Constraining gravity with a new precision $E_G$ estimator using Planck + SDSS BOSS",
        "authors": [
            "Lukas Wenzl",
            "Rachel Bean",
            "Shi-Fan Chen",
            "Gerrit S. Farren",
            "Mathew S. Madhavacheril",
            "Gabriela A. Marques",
            "Frank J. Qu",
            "Neelima Sehgal",
            "Blake D. Sherwin",
            "Alexander van Engelen"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "The $E_G$ statistic is a discriminating probe of gravity developed to test the prediction of general relativity (GR) for the relation between gravitational potential and clustering on the largest scales in the observable universe. We present a novel high-precision estimator for the $E_G$ statistic using CMB lensing and galaxy clustering correlations that carefully matches the effective redshifts across the different measurement components to minimize corrections. A suite of detailed tests is performed to characterize the estimator's accuracy, its sensitivity to assumptions and analysis choices and the non-Gaussianity of the estimator's uncertainty is characterized. After finalization of the estimator, it is applied to $\\textit{Planck}$ CMB lensing and SDSS CMASS and LOWZ galaxy data. We report the first harmonic space measurement of $E_G$ using the LOWZ sample and CMB lensing and also updated constraints using the final CMASS sample and the latest $\\textit{Planck}$ CMB lensing map. We find $E_G^{Planck+CMASS} = 0.36^{+0.06}_{-0.05}$ (68.27%) and $E_G^{\\rm \\textit{Planck}+LOWZ} = 0.40^{+0.11}_{-0.09} $ (68.27%), with additional subdominant systematic error budget estimates of 2% and 3% respectively. Using $\u03a9_{\\rm m,0}$ constraints from $\\textit{Planck}$ and SDSS BAO observations, $\u039b$CDM-GR predicts $E_G^{\\rm GR} (z = 0.555) = 0.401 \\pm 0.005$ and $E_G^{\\rm GR} (z = 0.316) = 0.452 \\pm 0.005$ at the effective redshifts of the CMASS and LOWZ based measurements. We report the measurement to be in good statistical agreement with the $\u039b$CDM-GR prediction, and report that the measurement is also consistent with the more general GR prediction of scale-independence for $E_G$. This work provides a carefully constructed and calibrated statistic with which $E_G$ measurements can be confidently and accurately obtained with upcoming survey data.",
        "comments": "36 pages, 20 figures, prepared for submission to PRD",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12971"
    },
    {
        "doc_id": 302,
        "title": "Measure transport with kernel mean embeddings",
        "authors": [
            "L. Wang",
            "N. N\u00fcsken"
        ],
        "subjects": [
            "Statistics Theory",
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "Kalman filters constitute a scalable and robust methodology for approximate Bayesian inference, matching first and second order moments of the target posterior. To improve the accuracy in nonlinear and non-Gaussian settings, we extend this principle to include more or different characteristics, based on kernel mean embeddings (KMEs) of probability measures into their corresponding Hilbert spaces. Focusing on the continuous-time setting, we develop a family of interacting particle systems (termed $\\textit{KME-dynamics}$) that bridge between the prior and the posterior, and that include the Kalman-Bucy filter as a special case. A variant of KME-dynamics has recently been derived from an optimal transport perspective by Maurais and Marzouk, and we expose further connections to (kernelised) diffusion maps, leading to a variational formulation of regression type. Finally, we conduct numerical experiments on toy examples and the Lorenz-63 model, the latter of which show particular promise for a hybrid modification (called Kalman-adjusted KME-dynamics).",
        "comments": "21 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12967"
    },
    {
        "doc_id": 303,
        "title": "Bayesian Semi-structured Subspace Inference",
        "authors": [
            "Daniel Dold",
            "David R\u00fcgamer",
            "Beate Sick",
            "Oliver D\u00fcrr"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach's efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets.",
        "comments": "Accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12950"
    },
    {
        "doc_id": 304,
        "title": "Are the Signs of Factor Loadings Arbitrary in Confirmatory Factor Analysis? Problems and Solutions",
        "authors": [
            "Dandan Tang",
            "Steven M. Boker",
            "Xin Tong"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The replication crisis in social and behavioral sciences has raised concerns about the reliability and validity of empirical studies. While research in the literature has explored contributing factors to this crisis, the issues related to analytical tools have received less attention. This study focuses on a widely used analytical tool - confirmatory factor analysis (CFA) - and investigates one issue that is typically overlooked in practice: accurately estimating factor-loading signs. Incorrect loading signs can distort the relationship between observed variables and latent factors, leading to unreliable or invalid results in subsequent analyses. Our study aims to investigate and address the estimation problem of factor-loading signs in CFA models. Based on an empirical demonstration and Monte Carlo simulation studies, we found current methods have drawbacks in estimating loading signs. To address this problem, three solutions are proposed and proven to work effectively. The applications of these solutions are discussed and elaborated.",
        "comments": "35 pages, 3 figures, 8 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12937"
    },
    {
        "doc_id": 305,
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "authors": [
            "Angela Zhou"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "comments": "conference version accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12934"
    },
    {
        "doc_id": 306,
        "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
        "authors": [
            "Logan Engstrom",
            "Axel Feldmann",
            "Aleksander Madry"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with \"high quality\" data sources may not increase (and can even hurt) performance compared to randomly selecting data.\n  To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2x compute multiplier over baseline methods.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12926"
    },
    {
        "doc_id": 307,
        "title": "Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection",
        "authors": [
            "Ankan Kar",
            "Nirjhar Nath",
            "Utpalraj Kemprai",
            "Aman"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "This article delves into the analysis of performance and utilization of Support Vector Machines (SVMs) for the critical task of forest fire detection using image datasets. With the increasing threat of forest fires to ecosystems and human settlements, the need for rapid and accurate detection systems is of utmost importance. SVMs, renowned for their strong classification capabilities, exhibit proficiency in recognizing patterns associated with fire within images. By training on labeled data, SVMs acquire the ability to identify distinctive attributes associated with fire, such as flames, smoke, or alterations in the visual characteristics of the forest area. The document thoroughly examines the use of SVMs, covering crucial elements like data preprocessing, feature extraction, and model training. It rigorously evaluates parameters such as accuracy, efficiency, and practical applicability. The knowledge gained from this study aids in the development of efficient forest fire detection systems, enabling prompt responses and improving disaster management. Moreover, the correlation between SVM accuracy and the difficulties presented by high-dimensional datasets is carefully investigated, demonstrated through a revealing case study. The relationship between accuracy scores and the different resolutions used for resizing the training datasets has also been discussed in this article. These comprehensive studies result in a definitive overview of the difficulties faced and the potential sectors requiring further improvement and focus.",
        "comments": "19 pages, 8 figures, accepted in IJCNS of SCIRP (not yet published)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12924"
    },
    {
        "doc_id": 308,
        "title": "Deep multitask neural networks for solving some stochastic optimal control problems",
        "authors": [
            "Christian Yeo"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.",
        "comments": "8 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12923"
    },
    {
        "doc_id": 309,
        "title": "Pretraining and the Lasso",
        "authors": [
            "Erin Craig",
            "Mert Pilanci",
            "Thomas Le Menestrel",
            "Balasubramanian Narasimhan",
            "Manuel Rivas",
            "Roozbeh Dehghannasiri",
            "Julia Salzman",
            "Jonathan Taylor",
            "Robert Tibshirani"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Pretraining is a popular and powerful paradigm in machine learning. As an example, suppose one has a modest-sized dataset of images of cats and dogs, and plans to fit a deep neural network to classify them from the pixel features. With pretraining, we start with a neural network trained on a large corpus of images, consisting of not just cats and dogs but hundreds of other image types. Then we fix all of the network weights except for the top layer (which makes the final classification) and train (or \"fine tune\") those weights on our dataset. This often results in dramatically better performance than the network trained solely on our smaller dataset.\n  In this paper, we ask the question \"Can pretraining help the lasso?\". We develop a framework for the lasso in which an overall model is fit to a large set of data, and then fine-tuned to a specific task on a smaller dataset. This latter dataset can be a subset of the original dataset, but does not need to be. We find that this framework has a wide variety of applications, including stratified models, multinomial targets, multi-response models, conditional average treatment estimation and even gradient boosting.\n  In the stratified model setting, the pretrained lasso pipeline estimates the coefficients common to all groups at the first stage, and then group specific coefficients at the second \"fine-tuning\" stage. We show that under appropriate assumptions, the support recovery rate of the common coefficients is superior to that of the usual lasso trained only on individual groups. This separate identification of common and individual coefficients can also be useful for scientific understanding.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12911"
    },
    {
        "doc_id": 310,
        "title": "Estimating the construct validity of Principal Components Analysis",
        "authors": [
            "Thomas M. H. Hope",
            "Cathy J. Price",
            "Ajay Halai",
            "Carola Salvi",
            "Jenny Crinion",
            "Merel Keijsers",
            "Christoph Sperber",
            "Howard Bowman"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "In many scientific disciplines, the features of interest cannot be observed directly, so must instead be inferred from observed behaviour. Latent variable analyses are increasingly employed to systematise these inferences, and Principal Components Analysis (PCA) is perhaps the simplest and most popular of these methods. Here, we examine how the assumptions that we are prepared to entertain, about the latent variable system, mediate the likelihood that PCA-derived components will capture the true sources of variance underlying data. As expected, we find that this likelihood is excellent in the best case, and robust to empirically reasonable levels of measurement noise, but best-case performance is also: (a) not robust to violations of the method's more prominent assumptions, of linearity and orthogonality; and also (b) requires that other subtler assumptions be made, such as that the latent variables should have varying importance, and that weights relating latent variables to observed data have zero mean. Neither variance explained, nor replication in independent samples, could reliably predict which (if any) PCA-derived components will capture true sources of variance in data. We conclude by describing a procedure to fit these inferences more directly to empirical data, and use it to find that components derived via PCA from two different empirical neuropsychological datasets, are less likely to have meaningful referents in the brain than we hoped.",
        "comments": "26 pages, 3 figures, 3 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12905"
    },
    {
        "doc_id": 311,
        "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic Conservation Laws",
        "authors": [
            "Jake J. Harmon",
            "Svetlana Tokareva",
            "Anatoly Zlotnik",
            "Pieter J. Swart"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolic partial differential equations (PDEs) under uncertainty. Constructed around the framework of stochastic finite volume (SFV) methods, our approach circumvents sampling schemes or simulation ensembles while also preserving fundamental properties, in particular hyperbolicity of the resulting systems and conservation of the discrete solutions. Furthermore, we augment the existing SFV theory with a priori convergence results for statistical quantities, in particular push-forward densities, which we demonstrate through numerical experiments. By linking refinement indicators to regions of the physical and stochastic spaces, we drive anisotropic refinements of the discretizations, introducing new degrees of freedom (DoFs) where deemed profitable. To illustrate our proposed method, we consider a series of numerical examples for non-linear hyperbolic PDEs based on Burgers' and Euler's equations.",
        "comments": "Report number:          LA-UR 23-32498                          MSC Class:          35L60; 35L67; 65C30; 65M50; 65M60",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12880"
    },
    {
        "doc_id": 312,
        "title": "Gridsemble: Selective Ensembling for False Discovery Rates",
        "authors": [
            "Jenna M. Landy",
            "Giovanni Parmigiani"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In this paper, we introduce Gridsemble, a data-driven selective ensembling algorithm for estimating local false discovery rates (fdr) in large-scale multiple hypothesis testing. Existing methods for estimating fdr often yield different conclusions, yet the unobservable nature of fdr values prevents the use of traditional model selection. There is limited guidance on choosing a method for a given dataset, making this an arbitrary decision in practice. Gridsemble circumvents this challenge by ensembling a subset of methods with weights based on their estimated performances, which are computed on synthetic datasets generated to mimic the observed data while including ground truth. We demonstrate through simulation studies and an experimental application that this method outperforms three popular R software packages with their default parameter values$\\unicode{x2014}$common choices given the current landscape. While our applications are in the context of high throughput transcriptomics, we emphasize that Gridsemble is applicable to any use of large-scale multiple hypothesis testing, an approach that is utilized in many fields. We believe that Gridsemble will be a useful tool for computing reliable estimates of fdr and for improving replicability in the presence of multiple hypotheses by eliminating the need for an arbitrary choice of method. Gridsemble is implemented in an open-source R software package available on GitHub at jennalandy/gridsemblefdr.",
        "comments": "12 pages, 3 figures (+ references and supplement). For open-source R software package, see https://github.com/jennalandy/gridsemblefdr. For all code used in the simulation studies and experimental application, see https://github.com/jennalandy/gridsemble_PAPER",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12865"
    },
    {
        "doc_id": 313,
        "title": "Empirical Likelihood Inference over Decentralized Networks",
        "authors": [
            "Jinye Du",
            "Qihua Wang"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "As a nonparametric statistical inference approach, empirical likelihood has been found very useful in numerous occasions. However, it encounters serious computational challenges when applied directly to the modern massive dataset. This article studies empirical likelihood inference over decentralized distributed networks, where the data are locally collected and stored by different nodes. To fully utilize the data, this article fuses Lagrange multipliers calculated in different nodes by employing a penalization technique. The proposed distributed empirical log-likelihood ratio statistic with Lagrange multipliers solved by the penalized function is asymptotically standard chi-squared under regular conditions even for a divergent machine number. Nevertheless, the optimization problem with the fused penalty is still hard to solve in the decentralized distributed network. To address the problem, two alternating direction method of multipliers (ADMM) based algorithms are proposed, which both have simple node-based implementation schemes. Theoretically, this article establishes convergence properties for proposed algorithms, and further proves the linear convergence of the second algorithm in some specific network structures. The proposed methods are evaluated by numerical simulations and illustrated with analyses of census income and Ford gobike datasets.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12836"
    },
    {
        "doc_id": 314,
        "title": "Distributed Empirical Likelihood Inference With or Without Byzantine Failures",
        "authors": [
            "Qihua Wang",
            "Jinye Du",
            "Ying Sheng"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Empirical likelihood is a very important nonparametric approach which is of wide application. However, it is hard and even infeasible to calculate the empirical log-likelihood ratio statistic with massive data. The main challenge is the calculation of the Lagrange multiplier. This motivates us to develop a distributed empirical likelihood method by calculating the Lagrange multiplier in a multi-round distributed manner. It is shown that the distributed empirical log-likelihood ratio statistic is asymptotically standard chi-squared under some mild conditions. The proposed algorithm is communication-efficient and achieves the desired accuracy in a few rounds. Further, the distributed empirical likelihood method is extended to the case of Byzantine failures. A machine selection algorithm is developed to identify the worker machines without Byzantine failures such that the distributed empirical likelihood method can be applied. The proposed methods are evaluated by numerical simulations and illustrated with an analysis of airline on-time performance study and a surface climate analysis of Yangtze River Economic Belt.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12827"
    },
    {
        "doc_id": 315,
        "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage",
        "authors": [
            "Ying Song",
            "Balaji Palanisamy"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Despite remarkable success in diverse web-based applications, Graph Neural Networks(GNNs) inherit and further exacerbate historical discrimination and social stereotypes, which critically hinder their deployments in high-stake domains such as online clinical diagnosis, financial crediting, etc. However, current fairness research that primarily craft on i.i.d data, cannot be trivially replicated to non-i.i.d. graph structures with topological dependence among samples. Existing fair graph learning typically favors pairwise constraints to achieve fairness but fails to cast off dimensional limitations and generalize them into multiple sensitive attributes; besides, most studies focus on in-processing techniques to enforce and calibrate fairness, constructing a model-agnostic debiasing GNN framework at the pre-processing stage to prevent downstream misuses and improve training reliability is still largely under-explored. Furthermore, previous work on GNNs tend to enhance either fairness or privacy individually but few probe into their interplays. In this paper, we propose a novel model-agnostic debiasing framework named MAPPING (\\underline{M}asking \\underline{A}nd \\underline{P}runing and Message-\\underline{P}assing train\\underline{ING}) for fair node classification, in which we adopt the distance covariance($dCov$)-based fairness constraints to simultaneously reduce feature and topology biases in arbitrary dimensions, and combine them with adversarial debiasing to confine the risks of attribute inference attacks. Experiments on real-world datasets with different GNN variants demonstrate the effectiveness and flexibility of MAPPING. Our results show that MAPPING can achieve better trade-offs between utility and fairness, and mitigate privacy risks of sensitive information leakage.",
        "comments": "Finished May last year. Remember to submit all papers to arXiv early without compromising the principles of conferences",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12824"
    },
    {
        "doc_id": 316,
        "title": "Interplay between an absorbing phase transition and synchronization in a driven granular system",
        "authors": [
            "R. Maire",
            "A. Plati",
            "M. Stockinger",
            "E. Trizac",
            "F. Smallenburg",
            "G. Foffi"
        ],
        "subjects": [
            "Statistical Mechanics"
        ],
        "abstract": "Absorbing phase transitions (APTs) are widespread in non-equilibrium systems, spanning condensed matter, epidemics, earthquakes, ecology, and chemical reactions. APTs feature an absorbing state in which the system becomes entrapped, along with a transition, either continuous or discontinuous, to an active state. Understanding which physical mechanisms determine the order of these transitions represents a challenging open problem in non-equilibrium statistical mechanics. Here, by numerical simulations and mean-field analysis, we show that a quasi-2d vibrofluidized granular system exhibits a novel form of APT. The absorbing phase is observed in the horizontal dynamics below a critical packing fraction, and can be continuous or discontinuous based on the emergent degree of synchronization in the vertical motion. Our results provide a direct representation of a feasible experimental scenario, showcasing a surprising interplay between dynamic phase transition and synchronization.",
        "comments": "4 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12817"
    },
    {
        "doc_id": 317,
        "title": "A New Precise Determination of the Primordial Abundance of Deuterium: Measurement in the metal-poor sub-DLA system at z=3.42 towards quasar J1332+0052",
        "authors": [
            "P. A. Kislitsyn",
            "S. A. Balashev",
            "M. T. Murphy",
            "C. Ledoux",
            "P. Noterdaeme",
            "A. V. Ivanchik"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "The theory of Big Bang nucleosynthesis, coupled with an estimate of the primordial deuterium abundance (D/H)_pr, offers insights into the baryon density of the Universe. Independently, the baryon density can be constrained during a different cosmological era through the analysis of cosmic microwave background (CMB) anisotropy. The comparison of these estimates serves as a rigorous test for the self-consistency of the Standard Cosmological Model and stands as a potent tool in the quest for new physics beyond the Standard Model of Particle Physics. For a meaningful comparison, a clear understanding of the various systematic errors affecting deuterium measurements is crucial. Given the limited number of D/H measurements, each new estimate carries significant weight. This study presents the detection of DI absorption lines in a metal-poor sub-Damped Lyman-alpha system ([O/H]=-1.71+-0.02, logN(HI)=19.304+-0.004) at z_abs=3.42 towards the quasar J1332+0052. Through simultaneous fitting of HI and DI Lyman-series lines, as well as low-ionization metal lines, observed at high spectral resolution and high signal-to-noise using VLT/UVES and Keck/HIRES, we derive log(DI/HI)=-4.622+-0.014, accounting for statistical and systematic uncertainties of 0.008dex and 0.012dex, respectively. Thanks to negligible ionization corrections and minimal deuterium astration at low metallicity, this D/H ratio provides a robust measurement of the primordial deuterium abundance, consistent and competitive with previous works. Incorporating all prior measurements, the best estimate of the primordial deuterium abundance is constrained as: (D/H)_pr=(2.533+-0.024)*10^-5. This represents a 5% improvement in precision over previous studies and reveals a moderate tension with the expectation from the Standard Model (~2.2sig). This discrepancy underscores the importance of further measurements in the pursuit of new physics.",
        "comments": "15 pages, 18 figures. Accepted for publication in MNRAS",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12797"
    },
    {
        "doc_id": 318,
        "title": "Extremal Tsirelson inequalities",
        "authors": [
            "Barizien Victor",
            "Bancal Jean-Daniel"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "It is well-known that the set of statistics that can be observed in a Bell-type experiment is limited by quantum theory. Unfortunately, tools are missing to identify the precise boundary of this set. Here, we propose to study the set of quantum statistics from a dual perspective. By considering all Bell expressions saturated by a given realization, we show that the CHSH expression can be decomposed in terms of extremal Tsirelson inequalities that we identify. This brings novel insight into the geometry of the quantum set in the (2,2,2) scenario. Furthermore, this allows us to identify all the Bell expressions that are able to self-test the Tsirelson realization.",
        "comments": "5+5 pages ; 2+1 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12791"
    },
    {
        "doc_id": 319,
        "title": "Understanding atom probe's analytical performance for iron oxides using correlation histograms and ab initio calculations",
        "authors": [
            "Se-Ho Kim",
            "Shalini Bhatt",
            "Daniel K. Schreiber",
            "J\u00f6rg Neugebauer",
            "Christoph Freysoldt",
            "Baptiste Gault",
            "Shyam Katnagallu"
        ],
        "subjects": [
            "Materials Science",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Field evaporation from ionic or covalently bonded materials often leads to the emission of molecular ions. The metastability of these molecular ions, particularly under the influence of the intense electrostatic field (1010 Vm-1), makes them prone to dissociation with or without an exchange of energy amongst them. These processes can affect the analytical performance of atom probe tomography (APT). For instance, neutral species formed through dissociation may not be detected at all or with a time of flight no longer related to their mass, causing their loss from the analysis. Here, we evaluated the changes in the measured composition of FeO, Fe2O3 and Fe3O4 across a wide range of analysis conditions. Possible dissociation reactions are predicted by density-functional theory (DFT) calculations considering the spin states of the molecules. The energetically favoured reactions are traced on to the multi-hit ion correlation histograms, to confirm their existence within experiments, using an automated Python-based routine. The detected reactions are carefully analysed to reflect upon the influence of these neutrals from dissociation reactions on the performance of APT for analysing iron oxides.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12784"
    },
    {
        "doc_id": 320,
        "title": "Sub-model aggregation for scalable eigenvector spatial filtering: Application to spatially varying coefficient modeling",
        "authors": [
            "Daisuke Murakami",
            "Shonosuke Murakami",
            "Hajime Seya",
            "Daniel A. Griffith"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "This study proposes a method for aggregating/synthesizing global and local sub-models for fast and flexible spatial regression modeling. Eigenvector spatial filtering (ESF) was used to model spatially varying coefficients and spatial dependence in the residuals by sub-model, while the generalized product-of-experts method was used to aggregate these sub-models. The major advantages of the proposed method are as follows: (i) it is highly scalable for large samples in terms of accuracy and computational efficiency; (ii) it is easily implemented by estimating sub-models independently first and aggregating/averaging them thereafter; and (iii) likelihood-based inference is available because the marginal likelihood is available in closed-form. The accuracy and computational efficiency of the proposed method are confirmed using Monte Carlo simulation experiments. This method was then applied to residential land price analysis in Japan. The results demonstrate the usefulness of this method for improving the interpretability of spatially varying coefficients. The proposed method is implemented in an R package spmoran (version 0.3.0 or later).",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12776"
    },
    {
        "doc_id": 321,
        "title": "Circulation in turbulent flow through a contraction",
        "authors": [
            "Vivek Mugundhan",
            "Sigurdur T. Thoroddsen"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "We study experimentally the statistical properties and evolution of circulation in a turbulent flow passing through a smooth 2-D contraction. The turbulence is generated with an active grids to reach $Re_\u03bb \\simeq 220$ at the inlet to the 2.5:1 contraction. We employ time-resolved 3-D Lagrangian Particle Tracking technique with the Shake-The-Box algorithm to obtain volumetric velocity fields which we use to calculate the simultaneous circulation in three perpendicular planes. Forming a circulation vector and studying the PDFs of the relative strength of its components, we can quantify how the mean strain enhances and orients coherent vortical structures with the streamwise direction. This is further studied with streamwise space and time correlations of the circulations over a range of loop sizes. The streamwise component of the circulation, over same-size square loops, shows increased integral length, while the other two components are less affected. The circulation around the compressive direction weakens and reaches prominent negative correlation values, suggesting buckling or sharp reorientation of transverse vortices. The PDFs of circulation transit from non-Gaussian to Gaussian behavior as the loop size is increased from dissipative to large scales.",
        "comments": "Journal ref:        V. Mugundhan and S. T. Thoroddsen, Circulation in turbulent flow through a contraction, Journal of Turbulence, 24, Issue 11-12, p. 577-612 (2023)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12757"
    },
    {
        "doc_id": 322,
        "title": "Optimal Confidence Bands for Shape-restricted Regression in Multidimensions",
        "authors": [
            "Ashley",
            "Datta",
            "Somabha Mukherjee",
            "Bodhisattva Sen"
        ],
        "subjects": [
            "Statistics Theory",
            "Methodology"
        ],
        "abstract": "In this paper, we propose and study construction of confidence bands for shape-constrained regression functions when the predictor is multivariate. In particular, we consider the continuous multidimensional white noise model given by $d Y(\\mathbf{t}) = n^{1/2} f(\\mathbf{t}) \\,d\\mathbf{t} + d W(\\mathbf{t})$, where $Y$ is the observed stochastic process on $[0,1]^d$ ($d\\ge 1$), $W$ is the standard Brownian sheet on $[0,1]^d$, and $f$ is the unknown function of interest assumed to belong to a (shape-constrained) function class, e.g., coordinate-wise monotone functions or convex functions. The constructed confidence bands are based on local kernel averaging with bandwidth chosen automatically via a multivariate multiscale statistic. The confidence bands have guaranteed coverage for every $n$ and for every member of the underlying function class. Under monotonicity/convexity constraints on $f$, the proposed confidence bands automatically adapt (in terms of width) to the global and local (H\u00f6lder) smoothness and intrinsic dimensionality of the unknown $f$; the bands are also shown to be optimal in a certain sense. These bands have (almost) parametric ($n^{-1/2}$) widths when the underlying function has ``low-complexity'' (e.g., piecewise constant/affine).",
        "comments": "43 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12753"
    },
    {
        "doc_id": 323,
        "title": "On the visualisation of the correlation matrix",
        "authors": [
            "Jan Graffelman"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "Extensions of earlier algorithms and enhanced visualization techniques for approximating a correlation matrix are presented. The visualization problems that result from using column or colum--and--row adjusted correlation matrices, which give numerically a better fit, are addressed. For visualization of a correlation matrix a weighted alternating least squares algorithm is used, with either a single scalar adjustment, or a column-only adjustment with symmetric factorization; these choices form a compromise between the numerical accuracy of the approximation and the comprehensibility of the obtained correlation biplots. Some illustrative examples are discussed.",
        "comments": "23 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12730"
    },
    {
        "doc_id": 324,
        "title": "Filamentary Network and Magnetic Field Structures Revealed with BISTRO in the High-Mass Star-Forming Region NGC2264 : Global Properties and Local Magnetogravitational Configurations",
        "authors": [
            "Jia-Wei Wang",
            "Patrick M. Koch",
            "Seamus D. Clarke",
            "Gary Fuller",
            "Nicolas Peretto",
            "Ya-Wen Tang",
            "Hsi-Wei Yen",
            "Shih-Ping Lai",
            "Nagayoshi Ohashi",
            "Doris Arzoumanian",
            "Doug Johnstone",
            "Ray Furuya",
            "Shu-ichiro Inutsuka",
            "Chang Won Lee",
            "Derek Ward-Thompson",
            "Valentin J. M. Le Gouellec",
            "Hong-Li Liu",
            "Lapo Fanciullo",
            "Jihye Hwang",
            "Kate Pattle",
            "Fr\u00e9d\u00e9rick Poidevin",
            "Mehrnoosh Tahani",
            "Takashi Onaka",
            "Mark G. Rawlings",
            "Eun Jung Chung",
            "et al. (132 additional authors not shown)"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "We report 850 $\u03bc$m continuum polarization observations toward the filamentary high-mass star-forming region NGC 2264, taken as part of the B-fields In STar forming Regions Observations (BISTRO) large program on the James Clerk Maxwell Telescope (JCMT). These data reveal a well-structured non-uniform magnetic field in the NGC 2264C and 2264D regions with a prevailing orientation around 30 deg from north to east. Field strengths estimates and a virial analysis for the major clumps indicate that NGC 2264C is globally dominated by gravity while in 2264D magnetic, gravitational, and kinetic energies are roughly balanced. We present an analysis scheme that utilizes the locally resolved magnetic field structures, together with the locally measured gravitational vector field and the extracted filamentary network. From this, we infer statistical trends showing that this network consists of two main groups of filaments oriented approximately perpendicular to one another. Additionally, gravity shows one dominating converging direction that is roughly perpendicular to one of the filament orientations, which is suggestive of mass accretion along this direction. Beyond these statistical trends, we identify two types of filaments. The type-I filament is perpendicular to the magnetic field with local gravity transitioning from parallel to perpendicular to the magnetic field from the outside to the filament ridge. The type-II filament is parallel to the magnetic field and local gravity. We interpret these two types of filaments as originating from the competition between radial collapsing, driven by filament self-gravity, and the longitudinal collapsing, driven by the region's global gravity.",
        "comments": "Accepted for publication in the Astrophysical Journal. 43 pages, 32 figures, and 4 tables (including Appendix)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12728"
    },
    {
        "doc_id": 325,
        "title": "New spectral-parameter dependent solutions of the Yang-Baxter equation",
        "authors": [
            "Alexander. S. Garkun",
            "Suvendu K. Barik",
            "Aleksey K. Fedorov",
            "Vladimir Gritsev"
        ],
        "subjects": [
            "Quantum Physics",
            "Exactly Solvable and Integrable Systems"
        ],
        "abstract": "The Yang-Baxter Equation (YBE) plays a crucial role for studying integrable many-body quantum systems. Many known YBE solutions provide various examples ranging from quantum spin chains to superconducting systems. Models of solvable statistical mechanics and their avatars are also based on YBE. Therefore, new solutions of the YBE could be used to construct new interesting 1D quantum or 2D classical systems with many other far-reaching applications. In this work, we attempt to find (almost) exhaustive set of solutions for the YBE in the lowest dimensions corresponding to a two-qubit case. We develop an algorithm, which can potentially be used for generating new higher-dimensional solutions of the YBE.",
        "comments": "28 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12710"
    },
    {
        "doc_id": 326,
        "title": "Deep Neural Network Benchmarks for Selective Classification",
        "authors": [
            "Andrea Pugnana",
            "Lorenzo Perini",
            "Jesse Davis",
            "Salvatore Ruggieri"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "With the increasing deployment of machine learning models in many socially-sensitive tasks, there is a growing demand for reliable and trustworthy predictions. One way to accomplish these requirements is to allow a model to abstain from making a prediction when there is a high risk of making an error. This requires adding a selection mechanism to the model, which selects those examples for which the model will provide a prediction. The selective classification framework aims to design a mechanism that balances the fraction of rejected predictions (i.e., the proportion of examples for which the model does not make a prediction) versus the improvement in predictive performance on the selected predictions. Multiple selective classification frameworks exist, most of which rely on deep neural network architectures. However, the empirical evaluation of the existing approaches is still limited to partial comparisons among methods and settings, providing practitioners with little insight into their relative merits. We fill this gap by benchmarking 18 baselines on a diverse set of 44 datasets that includes both image and tabular data. Moreover, there is a mix of binary and multiclass tasks. We evaluate these approaches using several criteria, including selective error rate, empirical coverage, distribution of rejected instance's classes, and performance on out-of-distribution instances. The results indicate that there is not a single clear winner among the surveyed baselines, and the best method depends on the users' objectives.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12708"
    },
    {
        "doc_id": 327,
        "title": "Heaps of pieces for lattice paths",
        "authors": [
            "Keiichi Shigechi"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We study heaps of pieces for lattice paths, which give a combinatorial visualization of lattice paths. We introduce two types of heaps: type $I$ and type $II$. A heap of type $I$ is characterized by peaks of a lattice path. We have a duality between a lattice path $\u03bc$ and its dual $\\overline\u03bc$ on heaps of type $I$. A heap of type $II$ for $\u03bc$ is characterized by the skew shape between the lowest path and $\u03bc$. We give a determinant expression for the generating function of heaps for general lattice paths, and an explicit formula for rational $(1,k)$-Dyck paths by using the inversion lemma. We introduce and study heaps in $k+1$-dimensions which are bijective to heaps of type $II$ for $(1,k)$-Dyck paths. Further, we show a bijective correspondence between type $I$ and type $II$ in the case of rational $(1,k)$-Dyck paths. As another application of heaps, we give two explicit formulae for the generating function of heaps for symmetric Dyck paths in terms of statistics on Dyck paths and on symmetric Dyck paths respectively.",
        "comments": "31 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12701"
    },
    {
        "doc_id": 328,
        "title": "A Computationally Efficient Approach to False Discovery Rate Control and Power Maximisation via Randomisation and Mirror Statistic",
        "authors": [
            "Marco Molinari",
            "Magne Thoresen"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "Simultaneously performing variable selection and inference in high-dimensional regression models is an open challenge in statistics and machine learning. The increasing availability of vast amounts of variables requires the adoption of specific statistical procedures to accurately select the most important predictors in a high-dimensional space, while controlling the False Discovery Rate (FDR) arising from the underlying multiple hypothesis testing. In this paper we propose the joint adoption of the Mirror Statistic approach to FDR control, coupled with outcome randomisation to maximise the statistical power of the variable selection procedure. Through extensive simulations we show how our proposed strategy allows to combine the benefits of the two techniques. The Mirror Statistic is a flexible method to control FDR, which only requires mild model assumptions, but requires two sets of independent regression coefficient estimates, usually obtained after splitting the original dataset. Outcome randomisation is an alternative to Data Splitting, that allows to generate two independent outcomes, which can then be used to estimate the coefficients that go into the construction of the Mirror Statistic. The combination of these two approaches provides increased testing power in a number of scenarios, such as highly correlated covariates and high percentages of active variables. Moreover, it is scalable to very high-dimensional problems, since the algorithm has a low memory footprint and only requires a single run on the full dataset, as opposed to iterative alternatives such as Multiple Data Splitting.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12697"
    },
    {
        "doc_id": 329,
        "title": "Energy-based Automated Model Evaluation",
        "authors": [
            "Ru Peng",
            "Heming Zou",
            "Haobo Wang",
            "Yawen Zeng",
            "Zenan Huang",
            "Junbo Zhao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive experiments across modalities, datasets and different architectural backbones to validate MDE's validity, together with its superiority compared with prior approaches. We also prove MDE's versatility by showing its seamless integration with large-scale models, and easy adaption to learning scenarios with noisy- or imbalanced- labels.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12689"
    },
    {
        "doc_id": 330,
        "title": "Feature Selection via Robust Weighted Score for High Dimensional Binary Class-Imbalanced Gene Expression Data",
        "authors": [
            "Zardad Khan",
            "Amjad Ali",
            "Saeed Aldahmani"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "In this paper, a robust weighted score for unbalanced data (ROWSU) is proposed for selecting the most discriminative feature for high dimensional gene expression binary classification with class-imbalance problem. The method addresses one of the most challenging problems of highly skewed class distributions in gene expression datasets that adversely affect the performance of classification algorithms. First, the training dataset is balanced by synthetically generating data points from minority class observations. Second, a minimum subset of genes is selected using a greedy search approach. Third, a novel weighted robust score, where the weights are computed by support vectors, is introduced to obtain a refined set of genes. The highest-scoring genes based on this approach are combined with the minimum subset of genes selected by the greedy search approach to form the final set of genes. The novel method ensures the selection of the most discriminative genes, even in the presence of skewed class distribution, thus improving the performance of the classifiers. The performance of the proposed ROWSU method is evaluated on $6$ gene expression datasets. Classification accuracy and sensitivity are used as performance metrics to compare the proposed ROWSU algorithm with several other state-of-the-art methods. Boxplots and stability plots are also constructed for a better understanding of the results. The results show that the proposed method outperforms the existing feature selection procedures based on classification performance from k nearest neighbours (kNN) and random forest (RF) classifiers.",
        "comments": "25 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12667"
    },
    {
        "doc_id": 331,
        "title": "A length scale for non-local multi-scale gradient interactions in isotropic turbulence",
        "authors": [
            "Miguel P. Encinar"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "Three-dimensional turbulent flows enhance velocity gradients via strong non-linear interactions of the rate-of-strain tensor with the vorticity vector, and with itself. For statistically homogeneous flows, their total contributions to gradient production are related to each other by conservation of mass, and so are the total enstrophy and total dissipation. However, locally they do not obey this relation and have different (often extreme) values, and for this reason both production mechanisms have been subject to numerous studies, often decomposed in multiscale interactions. In general lines, their dynamics and contributions to the cascade processes and turbulent kinetic dissipation are different, which posses a difficulty for turbulence modelling. In this paper, we explore the consequence of the 'Betchov' relations locally, and show that they implicitly define a length scale. This length scale is found to be about three times the size of the turbulent structures and their interactions. It is also found that while the non-locality of the dissipation and enstrophy at a given scale comes mostly from larger scales that do not cancel, the non-local production of strain and vorticity comes from multiscale interactions. An important consequence of this work is that isotropic cascade models need not distinguish between vortex stretching and strain self-amplification, but can instead consider both entities part of a more complex transfer mechanism, provided that their detailed point-value is not required and a local average of reasonable size is sufficient.",
        "comments": "11 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12658"
    },
    {
        "doc_id": 332,
        "title": "Cokernel statistics for walk matrices of directed and weighted random graphs",
        "authors": [
            "Alexander Van Werde"
        ],
        "subjects": [
            "Combinatorics",
            "Probability"
        ],
        "abstract": "The walk matrix associated to an $n\\times n$ integer matrix $X$ and an integer vector $b$ is defined by $W := (b,X b, . . . ,X^{n-1} b)$. We study limiting laws for the cokernel of $W$ in the scenario where $X$ is a random matrix with independent entries and $b$ is deterministic. Our first main result provides a formula for the distribution of the $p^{m}$-torsion part of the cokernel, as a group, when $X$ has independent entries from a specific distribution. The second main result relaxes the distributional assumption and concerns the $\\mathbb{Z}[x]$-module structure.\n  The motivation for this work arises from an open problem in spectral graph theory which asks to show that random graphs are often determined up to isomorphism by their (generalized) spectrum. Sufficient conditions for generalized spectral determinacy can namely be stated in terms of the cokernel of a walk matrix. Extensions of our results could potentially be used to determine how often those conditions are satisfied. Some remaining challenges for such extensions are outlined in the paper",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12655"
    },
    {
        "doc_id": 333,
        "title": "Multilevel network meta-regression for general likelihoods: synthesis of individual and aggregate data with applications to survival analysis",
        "authors": [
            "David M. Phillippo",
            "Sofia Dias",
            "Nicky J. Welton",
            "A. E. Ades"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Network meta-analysis combines aggregate data (AgD) from multiple randomised controlled trials, assuming that any effect modifiers are balanced across populations. Individual patient data (IPD) meta-regression is the ``gold standard'' method to relax this assumption, however IPD are frequently only available in a subset of studies. Multilevel network meta-regression (ML-NMR) extends IPD meta-regression to incorporate AgD studies whilst avoiding aggregation bias, but currently requires the aggregate-level likelihood to have a known closed form. Notably, this prevents application to time-to-event outcomes.\n  We extend ML-NMR to individual-level likelihoods of any form, by integrating the individual-level likelihood function over the AgD covariate distributions to obtain the respective marginal likelihood contributions. We illustrate with two examples of time-to-event outcomes, showing the performance of ML-NMR in a simulated comparison with little loss of precision from a full IPD analysis, and demonstrating flexible modelling of baseline hazards using cubic M-splines with synthetic data on newly diagnosed multiple myeloma.\n  ML-NMR is a general method for synthesising individual and aggregate level data in networks of all sizes. Extension to general likelihoods, including for survival outcomes, greatly increases the applicability of the method. R and Stan code is provided, and the methods are implemented in the multinma R package.",
        "comments": "43 pages, 8 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12640"
    },
    {
        "doc_id": 334,
        "title": "Classification non supervis{\u00e9}e des processus d'{\u00e9}v{\u00e9}nements r{\u00e9}currents",
        "authors": [
            "G\u00e9nia Babykina",
            "Vincent Vandewalle"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Event of the same type occurring several times for one individual (recurrent events) are present in various domains (industrial systems reliability, episodes of unemployment, political conflicts, chronic diseases episodes). Analysis of such kind of data should account for the whole recurrence process dynamics rather than only focusing on the number of observed events. Statistical models for recurrent events analysis are developed in the counting process probabilistic framework. One of the often-used models is the Andersen-Gill model, a generalization of the well-known Cox model for durations, which assumes that the baseline intensity of the recurrence process is time-dependent and is adjusted for covariates. For an individual i with covariates Xi, the intensity is as follows:  $\u03bb$_{ik}(t;$\u03b8$) = $\u03bb$_0(t) exp (X_i $\u03b2$). The baseline intensity can be specified parametrically, in a form of Weibull:  $\u03bb$_0 (t) = $\u03b3$_{1} $\u03b3$_{2} t^{$\u03b3$_2-1}, with $\u03b3$1 scale parameter et $\u03b3$2 shape parameter. However, the observed covariates are often insufficient to explain the observed heterogeneity in data. This is often the case of clinical trials data containing information on patients. In this article a mixture model for recurrent events analysis is proposed. This model allows to account for unobserved heterogeneity and to cluster individuals according to their recurrence process. The intensity of the process is parametrically specified within each class and depend on observed covariates. Thus, the intensity becomes specific to class k: $\u03bb$_{ik} (t; $\u03b8$_k) = $\u03b3$_{1k} $\u03b3$_{2k} t^{$\u03b3$_{2k}-1} exp (X_i $\u03b2$_k). The model parameters are estimated by the Maximum Likelihood method, using the EM algorithm. The BIC criterion is employed to choose the optimal number of classes. Model feasibility is verified by Monte Carlo simulations. An application to real data concerning hospital readmissions of elderly patients is proposed. The proposed model feasibility is empirically verified (the optimization algorithm converges, providing non-biased estimates). The real data application allows to identify two clinically relevant classes of patients.",
        "comments": "in French, 54es Journ{\u00e9}es de Statistique, Jul 2023, Bruxelles (BEL), France",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12621"
    },
    {
        "doc_id": 335,
        "title": "The Role of Sea-ice Processes on the Probability of AMOC Transitions",
        "authors": [
            "Ren\u00e9 M. van Westen",
            "Val\u00e9rian Jacques-Dumas",
            "Amber A. Boot",
            "Henk A. Dijkstra"
        ],
        "subjects": [
            "Geophysics"
        ],
        "abstract": "Recent simulations performed with the Community Earth System Model (CESM) have suggested a crucial role of sea-ice processes in AMOC hysteresis behaviour under varying surface freshwater forcing. Here, we further investigate this issue using additional CESM simulations and a novel conceptual ocean-sea-ice box model. The CESM simulations show that the presence of sea ice gives rise to the existence of statistical equilibrium states with a weak AMOC strength. This is confirmed in the conceptual model, which captures the same AMOC hysteresis behaviour as in the CESM simulation and where steady states are computed versus forcing parameters. In the conceptual model, transition probabilities between the different equilibrium states are determined using rare event techniques. The transition probabilities from a strong AMOC state to a weak AMOC state increase when considering sea-ice processes and indicate that sea ice promotes these transitions. On the other hand, sea ice strongly reduces the probabilities of the reverse transition from a weak AMOC state to a strong AMOC state and this implies that sea ice also limits AMOC recovery. The results here indicate that sea-ice processes play a dominant role in AMOC hysteresis width and influence transition probabilities between the different equilibrium states.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12615"
    },
    {
        "doc_id": 336,
        "title": "The twin peaks of learning neural networks",
        "authors": [
            "Elizaveta Demyanenko",
            "Christoph Feinauer",
            "Enrico M. Malatesta",
            "Luca Saglietti"
        ],
        "subjects": [
            "Machine Learning",
            "Disordered Systems and Neural Networks",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "Recent works demonstrated the existence of a double-descent phenomenon for the generalization error of neural networks, where highly overparameterized models escape overfitting and achieve good test performance, at odds with the standard bias-variance trade-off described by statistical learning theory. In the present work, we explore a link between this phenomenon and the increase of complexity and sensitivity of the function represented by neural networks. In particular, we study the Boolean mean dimension (BMD), a metric developed in the context of Boolean function analysis. Focusing on a simple teacher-student setting for the random feature model, we derive a theoretical analysis based on the replica method that yields an interpretable expression for the BMD, in the high dimensional regime where the number of data points, the number of features, and the input size grow to infinity. We find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak, and then slowly approaches a low asymptotic value. The same phenomenology is then traced in numerical experiments with different model classes and training setups. Moreover, we find empirically that adversarially initialized models tend to show higher BMD values, and that models that are more robust to adversarial attacks exhibit a lower BMD.",
        "comments": "36 pages, 30 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12610"
    },
    {
        "doc_id": 337,
        "title": "ASAP (Automatic Software for ASL Processing): A toolbox for processing Arterial Spin Labeling images",
        "authors": [
            "Virginia Mato Abad",
            "Pablo Garcia-Polo",
            "Owen ODaly",
            "Juan Antonio Hernandez-Tamames",
            "Fernando Zelaya"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "The method of Arterial Spin Labeling (ASL) has experienced a significant rise in its application to functional imaging, since it is the only technique capable of measuring blood perfusion in a truly non-invasive manner. Currently, there are no commercial packages for processing ASL data and there is no recognised standard for normalising ASL data to a common frame of reference. This work describes a new Automated Software for ASL Processing (ASAP) that can automatically process several ASL datasets. ASAP includes functions for all stages of image pre-processing: quantification, skull-stripping, co-registration, partial volume correction and normalization. To assess the applicability and validity of the toolbox, this work shows its application in the study of hypoperfusion in a sample of healthy subjects at risk of progressing to Alzheimer's Disease. ASAP requires limited user intervention, minimising the possibility of random and systematic errors, and produces cerebral blood flow maps that are ready for statistical group analysis. The software is easy to operate and results in excellent quality of spatial normalisation. The results found in this evaluation study are consistent with previous studies that find decreased perfusion",
        "comments": "10 pages, 8 figures, 3 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12603"
    },
    {
        "doc_id": 338,
        "title": "Asymptotic confidence interval for R2 in multiple linear regression",
        "authors": [
            "J Dedecker",
            "O Guedj",
            "M L Taupin"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Following White's approach of robust multiple linear regression, we give asymptotic confidence intervals for the multiple correlation coefficient R2 under minimal moment conditions. We also give the asymptotic joint distribution of the empirical estimators of the individual R2's. Through different sets of simulations, we show that the procedure is indeed robust (contrary to the procedure involving the near exact distribution of the empirical estimator of R2 is the multivariate Gaussian case) and can be also applied to count linear regression.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12598"
    },
    {
        "doc_id": 339,
        "title": "Interpreting Equivariant Representations",
        "authors": [
            "Andreas Abildtrup Hansen",
            "Anna Calissano",
            "Aasa Feragen"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Latent representations are used extensively for downstream tasks, such as visualization, interpolation or feature extraction of deep learning models. Invariant and equivariant neural networks are powerful and well-established models for enforcing inductive biases. In this paper, we demonstrate that the inductive bias imposed on the by an equivariant model must also be taken into account when using latent representations. We show how not accounting for the inductive biases leads to decreased performance on downstream tasks, and vice versa, how accounting for inductive biases can be done effectively by using an invariant projection of the latent representations. We propose principles for how to choose such a projection, and show the impact of using these principles in two common examples: First, we study a permutation equivariant variational auto-encoder trained for molecule graph generation; here we show that invariant projections can be designed that incur no loss of information in the resulting invariant representation. Next, we study a rotation-equivariant representation used for image classification. Here, we illustrate how random invariant projections can be used to obtain an invariant representation with a high degree of retained information. In both cases, the analysis of invariant latent representations proves superior to their equivariant counterparts. Finally, we illustrate that the phenomena documented here for equivariant neural networks have counterparts in standard neural networks where invariance is encouraged via augmentation. Thus, while these ambiguities may be known by experienced developers of equivariant models, we make both the knowledge as well as effective tools to handle the ambiguities available to the broader community.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12588"
    },
    {
        "doc_id": 340,
        "title": "Work statistics at first-passage times",
        "authors": [
            "Iago N Mamede",
            "Prashant Singh",
            "Arnab Pal",
            "Carlos E. Fiore",
            "Karel Proesmans"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Soft Condensed Matter"
        ],
        "abstract": "We investigate the work fluctuations in an overdamped non-equilibrium process that is stopped at a stochastic time. The latter is characterized by a first passage event that marks the completion of the non-equilibrium process. In particular, we consider a particle diffusing in one dimension in the presence of a time-dependent potential $U(x,t) = k |x-vt|^n/n$, where $k>0$ is the stiffness and $n>0$ is the order of the potential. Moreover, the particle is confined between two absorbing walls, located at $L_{\\pm}(t) $, that move with a constant velocity $v$ and are initially located at $L_{\\pm}(0) = \\pm L$. As soon as the particle reaches any of the boundaries, the process is said to be completed and here, we compute the work done $W$ by the particle in the modulated trap upto this random time. Employing the Feynman-Kac path integral approach, we find that the typical values of the work scale with $L$ with a crucial dependence on the order $n$. While for $n>1$, we show that $W \\sim L^{1-n}~\\exp \\left[ \\left( {k L^{n}}/{n}-v L \\right)/D \\right] $ for large $L$, we get an algebraic scaling of the form $W \\sim L^n$ for the $n<1$ case. The marginal case of $n=1$ is exactly solvable and our analysis unravels three distinct scaling behaviours: (i) $W \\sim L$ for $v>k$, (ii) $W \\sim L^2$ for $v=k$ and (iii) $W \\sim \\exp\\left[{-(v-k)L}\\right]$ for $v<k$. For all cases, we also obtain the probability distribution associated with the typical values of $W$. Finally, we observe an interesting set of relations between the relative fluctuations of the work done and the first-passage time for different $n$ -- which we argue physically. Our results are well supported by the numerical simulations.",
        "comments": "25 pages, 7 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12583"
    },
    {
        "doc_id": 341,
        "title": "DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations",
        "authors": [
            "Dogyun Park",
            "Sihyeon Kim",
            "Sojin Lee",
            "Hyunwoo J. Kim"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and the continuous signal functions in the shared latent space. Additionally, we introduce a novel conditioning mechanism for evaluating INRs with the hierarchically decomposed PEs to further enhance expressive power. Extensive experiments across four modalities, e.g., 2D images, 3D shapes, Neural Radiance Fields, and videos, with seven benchmark datasets, demonstrate the versatility of DDMI and its superior performance compared to the existing INR generative models.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12517"
    },
    {
        "doc_id": 342,
        "title": "Adiabatic Quantum Support Vector Machines",
        "authors": [
            "Prasanna Date",
            "Dong Jun Woun",
            "Kathleen Hamilton",
            "Eduardo A. Coello Perez",
            "Mayanka Chandra Shekhar",
            "Francisco Rios",
            "John Gounley",
            "In-Saeng Suh",
            "Travis Humble",
            "Georgia Tourassi"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Quantum Physics",
            "Machine Learning"
        ],
        "abstract": "Adiabatic quantum computers can solve difficult optimization problems (e.g., the quadratic unconstrained binary optimization problem), and they seem well suited to train machine learning models. In this paper, we describe an adiabatic quantum approach for training support vector machines. We show that the time complexity of our quantum approach is an order of magnitude better than the classical approach. Next, we compare the test accuracy of our quantum approach against a classical approach that uses the Scikit-learn library in Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC), Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies on par with the classical approach. Finally, we perform a scalability study in which we compute the total training times of the quantum approach and the classical approach with increasing number of features and number of data points in the training dataset. Our scalability results show that the quantum approach obtains a 3.5--4.5 times speedup over the classical approach on datasets with many (millions of) features.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12485"
    },
    {
        "doc_id": 343,
        "title": "Nonparametric logistic regression with deep learning",
        "authors": [
            "Atsutomo Yara",
            "Yoshikazu Terada"
        ],
        "subjects": [
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "Consider the nonparametric logistic regression problem. In the logistic regression, we usually consider the maximum likelihood estimator, and the excess risk is the expectation of the Kullback-Leibler (KL) divergence between the true and estimated conditional class probabilities. However, in the nonparametric logistic regression, the KL divergence could diverge easily, and thus, the convergence of the excess risk is difficult to prove or does not hold. Several existing studies show the convergence of the KL divergence under strong assumptions. In most cases, our goal is to estimate the true conditional class probabilities. Thus, instead of analyzing the excess risk itself, it suffices to show the consistency of the maximum likelihood estimator in some suitable metric. In this paper, using a simple unified approach for analyzing the nonparametric maximum likelihood estimator (NPMLE), we directly derive the convergence rates of the NPMLE in the Hellinger distance under mild assumptions. Although our results are similar to the results in some existing studies, we provide simple and more direct proofs for these results. As an important application, we derive the convergence rates of the NPMLE with deep neural networks and show that the derived rate nearly achieves the minimax optimal rate.",
        "comments": "23 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12482"
    },
    {
        "doc_id": 344,
        "title": "Bayesian identification of nonseparable Hamiltonians with multiplicative noise using deep learning and reduced-order modeling",
        "authors": [
            "Nicholas Galioto",
            "Harsh Sharma",
            "Boris Kramer",
            "Alex Arkady Gorodetsky"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Dynamical Systems",
            "Data Analysis, Statistics and Probability",
            "Computation"
        ],
        "abstract": "This paper presents a structure-preserving Bayesian approach for learning nonseparable Hamiltonian systems using stochastic dynamic models allowing for statistically-dependent, vector-valued additive and multiplicative measurement noise. The approach is comprised of three main facets. First, we derive a Gaussian filter for a statistically-dependent, vector-valued, additive and multiplicative noise model that is needed to evaluate the likelihood within the Bayesian posterior. Second, we develop a novel algorithm for cost-effective application of Bayesian system identification to high-dimensional systems. Third, we demonstrate how structure-preserving methods can be incorporated into the proposed framework, using nonseparable Hamiltonians as an illustrative system class. We compare the Bayesian method to a state-of-the-art machine learning method on a canonical nonseparable Hamiltonian model and a chaotic double pendulum model with small, noisy training datasets. The results show that using the Bayesian posterior as a training objective can yield upwards of 724 times improvement in Hamiltonian mean squared error using training data with up to 10% multiplicative noise compared to a standard training objective. Lastly, we demonstrate the utility of the novel algorithm for parameter estimation of a 64-dimensional model of the spatially-discretized nonlinear Schr\u00f6dinger equation with data corrupted by up to 20% multiplicative noise.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12476"
    },
    {
        "doc_id": 345,
        "title": "Entropy properties of mostly expanding partially hyperbolic diffeomorphisms",
        "authors": [
            "Jinhua Zhang"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "The statistical properties of mostly expanding partially hyperbolic diffeomorphisms have been substantially studied. In this paper, we would like to address the entropy properties of mostly expanding partially hyperbolic diffeomorphisms. We prove that for mostly expanding partially hyperbolic diffeomorphisms with minimal strong stable foliation and one-dimensional center bundle, there exists a $C^1$-open neighborhood of them, in which the topological entropy varies continuously and the intermediate entropy property holds. To prove that, we show that each non-hyperbolic ergodic measure is approached by horseshoes in entropy and in weak$*$-topology.",
        "comments": "34 pages. Comments are welcome",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12465"
    },
    {
        "doc_id": 346,
        "title": "NIV-SSD: Neighbor IoU-Voting Single-Stage Object Detector From Point Cloud",
        "authors": [
            "Shuai Liu",
            "Di Wang",
            "Quan Wang",
            "Kai Huang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Previous single-stage detectors typically suffer the misalignment between localization accuracy and classification confidence. To solve the misalignment problem, we introduce a novel rectification method named neighbor IoU-voting (NIV) strategy. Typically, classification and regression are treated as separate branches, making it challenging to establish a connection between them. Consequently, the classification confidence cannot accurately reflect the regression quality. NIV strategy can serve as a bridge between classification and regression branches by calculating two types of statistical data from the regression output to correct the classification confidence. Furthermore, to alleviate the imbalance of detection accuracy for complete objects with dense points (easy objects) and incomplete objects with sparse points (difficult objects), we propose a new data augmentation scheme named object resampling. It undersamples easy objects and oversamples difficult objects by randomly transforming part of easy objects into difficult objects. Finally, combining the NIV strategy and object resampling augmentation, we design an efficient single-stage detector termed NIV-SSD. Extensive experiments on several datasets indicate the effectiveness of the NIV strategy and the competitive performance of the NIV-SSD detector. The code will be available at https://github.com/Say2L/NIV-SSD.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12447"
    },
    {
        "doc_id": 347,
        "title": "Enumerating Seating Arrangements that Obey Social Distancing",
        "authors": [
            "George Spahn",
            "Doron Zeilberger"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We study maximal seating arrangements, either on a line, or in a rectangular auditorium with a fixed number of columns but an arbitrary number of rows, that obey any prescribed set of `social distancing' restrictions. In addition to enumeration, we study the statistical distribution of the density, and give efficient algorithms for generating these at random",
        "comments": "10 pages. Accompanied by a Maple package available from https://sites.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/social.html",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12430"
    },
    {
        "doc_id": 348,
        "title": "Rank-based estimators of global treatment effects for cluster randomized trials with multiple endpoints",
        "authors": [
            "E. Davies Smith",
            "V. Jairath",
            "G. Zou"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "Cluster randomization trials commonly employ multiple endpoints. When a single summary of treatment effects across endpoints is of primary interest, global hypothesis testing/effect estimation methods represent a common analysis strategy. However, specification of the joint distribution required by these methods is non-trivial, particularly when endpoint properties differ. We develop rank-based interval estimators for a global treatment effect referred to as the \"global win probability,\" or the probability that a treatment individual responds better than a control individual on average. Using endpoint-specific ranks among the combined sample and within each arm, each individual-level observation is converted to a \"win fraction\" which quantifies the proportion of wins experienced over every observation in the comparison arm. An individual's multiple observations are then replaced by a single \"global win fraction,\" constructed by averaging win fractions across endpoints. A linear mixed model is applied directly to the global win fractions to recover point, variance, and interval estimates of the global win probability adjusted for clustering. Simulation demonstrates our approach performs well concerning coverage and type I error, and methods are easily implemented using standard software. A case study using publicly available data is provided with corresponding R and SAS code.",
        "comments": "32 pages, 5 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12420"
    },
    {
        "doc_id": 349,
        "title": "Multi-modal News Understanding with Professionally Labelled Videos (ReutersViLNews)",
        "authors": [
            "Shih-Han Chou",
            "Matthew Kowal",
            "Yasmin Niknam",
            "Diana Moyano",
            "Shayaan Mehdi",
            "Richard Pito",
            "Cheng Zhang",
            "Ian Knopke",
            "Sedef Akinli Kocak",
            "Leonid Sigal",
            "Yalda Mohsenzadeh"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "While progress has been made in the domain of video-language understanding, current state-of-the-art algorithms are still limited in their ability to understand videos at high levels of abstraction, such as news-oriented videos. Alternatively, humans easily amalgamate information from video and language to infer information beyond what is visually observable in the pixels. An example of this is watching a news story, where the context of the event can play as big of a role in understanding the story as the event itself. Towards a solution for designing this ability in algorithms, we present a large-scale analysis on an in-house dataset collected by the Reuters News Agency, called Reuters Video-Language News (ReutersViLNews) dataset which focuses on high-level video-language understanding with an emphasis on long-form news. The ReutersViLNews Dataset consists of long-form news videos collected and labeled by news industry professionals over several years and contains prominent news reporting from around the world. Each video involves a single story and contains action shots of the actual event, interviews with people associated with the event, footage from nearby areas, and more. ReutersViLNews dataset contains videos from seven subject categories: disaster, finance, entertainment, health, politics, sports, and miscellaneous with annotations from high-level to low-level, title caption, visual video description, high-level story description, keywords, and location. We first present an analysis of the dataset statistics of ReutersViLNews compared to previous datasets. Then we benchmark state-of-the-art approaches for four different video-language tasks. The results suggest that news-oriented videos are a substantial challenge for current video-language understanding algorithms and we conclude by providing future directions in designing approaches to solve the ReutersViLNews dataset.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12419"
    },
    {
        "doc_id": 350,
        "title": "Towards Improved Variational Inference for Deep Bayesian Models",
        "authors": [
            "Sebastian W. Ober"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Deep learning has revolutionized the last decade, being at the forefront of extraordinary advances in a wide range of tasks including computer vision, natural language processing, and reinforcement learning, to name but a few. However, it is well-known that deep models trained via maximum likelihood estimation tend to be overconfident and give poorly-calibrated predictions. Bayesian deep learning attempts to address this by placing priors on the model parameters, which are then combined with a likelihood to perform posterior inference. Unfortunately, for deep models, the true posterior is intractable, forcing the user to resort to approximations. In this thesis, we explore the use of variational inference (VI) as an approximation, as it is unique in simultaneously approximating the posterior and providing a lower bound to the marginal likelihood. If tight enough, this lower bound can be used to optimize hyperparameters and to facilitate model selection. However, this capacity has rarely been used to its full extent for Bayesian neural networks, likely because the approximate posteriors typically used in practice can lack the flexibility to effectively bound the marginal likelihood. We therefore explore three aspects of Bayesian learning for deep models: 1) we ask whether it is necessary to perform inference over as many parameters as possible, or whether it is reasonable to treat many of them as optimizable hyperparameters; 2) we propose a variational posterior that provides a unified view of inference in Bayesian neural networks and deep Gaussian processes; 3) we demonstrate how VI can be improved in certain deep Gaussian process models by analytically removing symmetries from the posterior, and performing inference on Gram matrices instead of features. We hope that our contributions will provide a stepping stone to fully realize the promises of VI in the future.",
        "comments": "PhD Thesis; University of Cambridge",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12418"
    },
    {
        "doc_id": 351,
        "title": "On Efficient Sampling Schemes for the Eigenvalues of Complex Wishart Matrices",
        "authors": [
            "Peter J. Forrester"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "The paper \"An efficient sampling scheme for the eigenvalues of dual Wishart matrices\", by I.~Santamar\u00eda and V.~Elvira, [\\emph{IEEE Signal Processing Letters}, vol.~28, pp.~2177--2181, 2021] \\cite{SE21}, poses the question of efficient sampling from the eigenvalue probability density function of the $n \\times n$ central complex Wishart matrices with variance matrix equal to the identity. Underlying such complex Wishart matrices is a rectangular $R \\times n$ $(R \\ge n)$ standard complex Gaussian matrix, requiring then $2Rn$ real random variables for their generation. The main result of \\cite{SE21} gives a formula involving just two classical distributions specifying the two eigenvalues in the case $n=2$. The purpose of this Letter is to point out that existing results in the literature give two distinct ways to efficiently sample the eigenvalues in the general $n$ case. One is in terms of the eigenvalues of a tridiagonal matrix which factors as the product of a bidiagonal matrix and its transpose, with the $2n+1$ nonzero entries of the latter given by (the square root of) certain chi-squared random variables. The other is as the generalised eigenvalues for a pair of bidiagonal matrices, also containing a total of $2n+1$ chi-squared random variables. Moreover, these characterisation persist in the case of that the variance matrix consists of a single spike, and for the case of real Wishart matrices.",
        "comments": "4 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12409"
    },
    {
        "doc_id": 352,
        "title": "Approximation of Pufferfish Privacy for Gaussian Priors",
        "authors": [
            "Ni Ding"
        ],
        "subjects": [
            "Information Theory",
            "Cryptography and Security"
        ],
        "abstract": "This paper studies how to approximate pufferfish privacy when the adversary's prior belief of the published data is Gaussian distributed. Using Monge's optimal transport plan, we show that $(\u03b5, \u03b4)$-pufferfish privacy is attained if the additive Laplace noise is calibrated to the differences in mean and variance of the Gaussian distributions conditioned on every discriminative secret pair. A typical application is the private release of the summation (or average) query, for which sufficient conditions are derived for approximating $\u03b5$-statistical indistinguishability in individual's sensitive data. The result is then extended to arbitrary prior beliefs trained by Gaussian mixture models (GMMs): calibrating Laplace noise to a convex combination of differences in mean and variance between Gaussian components attains $(\u03b5,\u03b4)$-pufferfish privacy.",
        "comments": "11 pages, 5 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12391"
    },
    {
        "doc_id": 353,
        "title": "Fostering innovation, inclusion, and diversity in astronomy education: The Czech Astronomy Olympiad experience",
        "authors": [
            "V\u00e1clav Pavl\u00edk",
            "Jakub Vo\u0161mera",
            "Tom\u00e1\u0161 Gr\u00e1f",
            "Radka K\u0159\u00ed\u017eov\u00e1"
        ],
        "subjects": [
            "Physics Education",
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "Astronomy education and outreach are very important when it comes to the future generation's interest in science. The Czech Astronomy Olympiad shows how an educational competition for secondary and high schools can help us drive innovation and promote inclusion and diversity. In this work, we introduce the scope of this competition and show statistics on participation. We also discuss some of the steps taken to make astronomy accessible to a wider audience, such as organising international workshops. In addition, we explore some of the approaches which were adopted to broaden the Olympiad's reach and impact. These include, e.g., developing a dedicated website environment or publishing Open Access booklets with solved problems.",
        "comments": "4 pages, 2 figures, conference \"III Workshop on Astronomy Beyond the Common Senses for Accessibility and Inclusion\", to appear in \"Revista Mexicana de Astronom\u00eda y Astrof\u00edsica Serie Conferencias (edici\u00f3n RevMexAA Conference Series)\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12376"
    },
    {
        "doc_id": 354,
        "title": "SubgroupTE: Advancing Treatment Effect Estimation with Subgroup Identification",
        "authors": [
            "Seungyeon Lee",
            "Ruoqi Liu",
            "Wenyu Song",
            "Lang Li",
            "Ping Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Precise estimation of treatment effects is crucial for evaluating intervention effectiveness. While deep learning models have exhibited promising performance in learning counterfactual representations for treatment effect estimation (TEE), a major limitation in most of these models is that they treat the entire population as a homogeneous group, overlooking the diversity of treatment effects across potential subgroups that have varying treatment effects. This limitation restricts the ability to precisely estimate treatment effects and provide subgroup-specific treatment recommendations. In this paper, we propose a novel treatment effect estimation model, named SubgroupTE, which incorporates subgroup identification in TEE. SubgroupTE identifies heterogeneous subgroups with different treatment responses and more precisely estimates treatment effects by considering subgroup-specific causal effects. In addition, SubgroupTE iteratively optimizes subgrouping and treatment effect estimation networks to enhance both estimation and subgroup identification. Comprehensive experiments on the synthetic and semi-synthetic datasets exhibit the outstanding performance of SubgroupTE compared with the state-of-the-art models on treatment effect estimation. Additionally, a real-world study demonstrates the capabilities of SubgroupTE in enhancing personalized treatment recommendations for patients with opioid use disorder (OUD) by advancing treatment effect estimation with subgroup identification.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12369"
    },
    {
        "doc_id": 355,
        "title": "VC dimension of Graph Neural Networks with Pfaffian activation functions",
        "authors": [
            "Giuseppe Alessio D'Inverno",
            "Monica Bianchini",
            "Franco Scarselli"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool to learn tasks across a wide range of graph domains in a data-driven fashion; based on a message passing mechanism, GNNs have gained increasing popularity due to their intuitive formulation, closely linked with the Weisfeiler-Lehman (WL) test for graph isomorphism, to which they have proven equivalent. From a theoretical point of view, GNNs have been shown to be universal approximators, and their generalization capability (namely, bounds on the Vapnik Chervonekis (VC) dimension) has recently been investigated for GNNs with piecewise polynomial activation functions. The aim of our work is to extend this analysis on the VC dimension of GNNs to other commonly used activation functions, such as sigmoid and hyperbolic tangent, using the framework of Pfaffian function theory. Bounds are provided with respect to architecture parameters (depth, number of neurons, input size) as well as with respect to the number of colors resulting from the 1-WL test applied on the graph domain. The theoretical analysis is supported by a preliminary experimental study.",
        "comments": "37 pages, 9 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12362"
    },
    {
        "doc_id": 356,
        "title": "Distributionally Robust Beamforming and Estimation of Wireless Signals",
        "authors": [
            "Shixiong Wang",
            "Wei Dai",
            "Geoffrey Ye Li"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper investigates signal estimation in wireless transmission from the perspective of statistical machine learning, where the transmitted signals may be from an integrated sensing and communication system; that is, 1) signals may be not only discrete constellation points but also arbitrary complex values; 2) signals may be spatially correlated. Particular attention is paid to handling various uncertainties such as the uncertainty of the transmitting signal covariance, the uncertainty of the channel matrix, the uncertainty of the channel noise covariance, the existence of channel impulse noises (i.e., outliers), and the limited sample size of pilots. To proceed, a distributionally robust machine learning framework that is insensitive to the above uncertainties is proposed for beamforming (at the receiver) and estimation of wireless signals, which reveals that channel estimation is not a necessary operation. For optimal linear estimation, the proposed framework includes several existing beamformers as special cases such as diagonal loading and eigenvalue thresholding. For optimal nonlinear estimation, estimators are limited in reproducing kernel Hilbert spaces and neural network function spaces, and corresponding uncertainty-aware solutions (e.g., kernelized diagonal loading) are derived. In addition, we prove that the ridge and kernel ridge regression methods in machine learning are distributionally robust against diagonal perturbation in feature covariance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12345"
    },
    {
        "doc_id": 357,
        "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation",
        "authors": [
            "Shoaib Meraj Sami",
            "Md Mahedi Hasan",
            "Nasser M. Nasrabadi",
            "Raghuveer Rao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Image and Video Processing",
            "Machine Learning"
        ],
        "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task, primarily due to the unavailability of labeled data in the target domain. Hence, it is essential to construct an optimal target domain classifier by utilizing the labeled information of the source domain images. The transductive transfer learning (TTL) method that incorporates a CycleGAN-based unpaired domain translation network has been previously proposed in the literature for effective ATR annotation. Although this method demonstrates great potential for ATR, it severely suffers from lower annotation performance, higher Fr\u00e9chet Inception Distance (FID) score, and the presence of visual artifacts in the synthetic images. To address these issues, we propose a hybrid contrastive learning base unpaired domain translation (H-CUT) network that achieves a significantly lower FID score. It incorporates both attention and entropy to emphasize the domain-specific region, a noisy feature mixup module to generate high variational synthetic negative patches, and a modulated noise contrastive estimation (MoNCE) loss to reweight all negative patches using optimal transport for better performance. Our proposed contrastive learning and cycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks and two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and identity losses. In C3TTL, two H-CUT networks have been employed through a bijection mapping to feed the reconstructed source domain images into a pretrained classifier to guide the optimal target domain classifier. Extensive experimental analysis conducted on three ATR datasets demonstrates that the proposed C3TTL method is effective in annotating civilian and military vehicles, as well as ship targets.",
        "comments": "This Paper is Accepted in IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS. This Arxiv version is an older version than the reviewed version",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12340"
    },
    {
        "doc_id": 358,
        "title": "Asphericity of the base of the solar convection zone",
        "authors": [
            "Sarbani Basu",
            "Sylvain G. Korzennik"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "We have used solar oscillation frequencies and frequency splittings obtained over solar cycles 23 and 24 to investigate whether the base of the solar convection zone shows any departure from spherical symmetry. We used the even-order splitting coefficients, $a_2$-$a_8$, and estimated the contributions from each one separately. The average asphericity over the two solar cycles was determined using frequencies and splittings obtained with a 9216-day time-series. We find that evidence of asphericity is, {\\em at best}, marginal: the $a_2$ component is consistent with no asphericity, the $a_4$ and $a_6$ components yield results at a level a little greater than $1\\,\u03c3$, while the $a_8$ component shows a signature below $1\\,\u03c3$. The combined results indicate that the time average of the departure from the spherically symmetric position of the base of the convection zone is $\\lesssim 0.0001R_\\odot$. We have also used helioseismic data obtained from time-series of lengths 360 days, 576 days, 1152 days, and 2304 days in order to examine the consistency of the results and evaluate whether there is any time variation. We find that the evidence for time variation is statistically marginal in all cases, except for the $a_6$ component, for which tests consistently yield $p$ values of less than $0.05$.",
        "comments": "Accepted for publication in ApJ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12333"
    },
    {
        "doc_id": 359,
        "title": "Transfer Learning for Functional Mean Estimation: Phase Transition and Adaptive Algorithms",
        "authors": [
            "T. Tony Cai",
            "Dongwoo Kim",
            "Hongming Pu"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "This paper studies transfer learning for estimating the mean of random functions based on discretely sampled data, where, in addition to observations from the target distribution, auxiliary samples from similar but distinct source distributions are available. The paper considers both common and independent designs and establishes the minimax rates of convergence for both designs. The results reveal an interesting phase transition phenomenon under the two designs and demonstrate the benefits of utilizing the source samples in the low sampling frequency regime. For practical applications, this paper proposes novel data-driven adaptive algorithms that attain the optimal rates of convergence within a logarithmic factor simultaneously over a large collection of parameter spaces. The theoretical findings are complemented by a simulation study that further supports the effectiveness of the proposed algorithms",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12331"
    },
    {
        "doc_id": 360,
        "title": "Implementation of Allan Standard Deviation Technique in Stability Analysis of 4C31.61 Quasar Position",
        "authors": [
            "Jessica Syafaq Muthmaina",
            "Ibnu Nurul Huda",
            "Dwi Satya Palupi"
        ],
        "subjects": [
            "Astrophysics of Galaxies",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "The International Celestial Reference Frame (ICRF) plays an important role in astronomy and geodesy. The realization of ICRF is based on the position of thousands of quasars observed using the Very-Long Baseline Interferometry (VLBI) technique. Better quality of ICRF is achieved when the position of the quasars is stable. In this study, we aim to analyze the stability of one of the quasars in ICRF called 4C31.61 (2201+315). We performed VLBI data analysis by using Vienna VLBI and Satellite Software (VieVS) to get the position of the quasar. We also used the data of the quasar's position from the Paris Observatory Geodetic VLBI Center. We examined the stability of the quasar position by using the Allan standard deviation technique. We found that the quasar 4C31.61 (2201+315) has a stable position with the dominance of white noise across the majority of time scales.",
        "comments": "to be published in IOP Journal of Physics Conference Series (JPCS)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12325"
    },
    {
        "doc_id": 361,
        "title": "Interpreting Event-Studies from Recent Difference-in-Differences Methods",
        "authors": [
            "Jonathan Roth"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This note discusses the interpretation of event-study plots produced by recent difference-in-differences methods. I show that even when specialized to the case of non-staggered treatment timing, the default plots produced by software for three of the most popular recent methods (de Chaisemartin and D'Haultfoeuille, 2020; Callaway and SantAnna, 2021; Borusyak, Jaravel and Spiess, 2024) do not match those of traditional two-way fixed effects (TWFE) event-studies: the new methods may show a kink or jump at the time of treatment even when the TWFE event-study shows a straight line. This difference stems from the fact that the new methods construct the pre-treatment coefficients asymmetrically from the post-treatment coefficients. As a result, visual heuristics for analyzing TWFE event-study plots should not be immediately applied to those from these methods. I conclude with practical recommendations for constructing and interpreting event-study plots when using these methods.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12309"
    },
    {
        "doc_id": 362,
        "title": "Multiplicative and additive systematics in galaxy density fluctuations and clustering measurements",
        "authors": [
            "Federico Berlfein",
            "Rachel Mandelbaum",
            "Scott Dodelson",
            "Chad Schafer"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "Galaxy clustering measurements are a key probe of the matter density field in the Universe. With the era of precision cosmology upon us, surveys rely on precise measurements of the clustering signal for meaningful cosmological analysis. However, the presence of systematic contaminants can bias the observed galaxy number density, and thereby bias the galaxy two-point statistics. As the statistical uncertainties get smaller, correcting for these systematic contaminants becomes increasingly important for unbiased cosmological analysis. We present and validate a new method for understanding and mitigating these systematics in galaxy clustering measurements (two-point function) by identifying and characterizing contaminants in the galaxy overdensity field (one-point function) using a maximum-likelihood estimator (MLE). We test this methodology with KiDS-like mock galaxy catalogs and synthetic systematic template maps. We estimate the cosmological impact of such mitigation by quantifying uncertainties and possible biases in the inferred relationship between the observed and the true galaxy clustering signal. Our method robustly corrects the clustering signal to the sub-percent level and reduces numerous additive and multiplicative systematics from 1.5$\u03c3$ to less than 0.1$\u03c3$ for the scenarios we tested. In addition, we provide an empirical approach to identifying the functional form (additive, multiplicative, or other) by which specific systematics contaminate the galaxy number density. Even though this approach is tested and geared towards systematics contaminating the galaxy number density, the methods can be extended to systematics mitigation for other two-point correlation measurements.",
        "comments": "19 pages, 10 figures; submitted to MNRAS",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12293"
    },
    {
        "doc_id": 363,
        "title": "How informative are summaries of the cosmic 21-cm signal?",
        "authors": [
            "David Prelogovi\u0107",
            "Andrei Mesinger"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "The cosmic 21-cm signal will bring data-driven advances to studies of the Cosmic Dawn (CD) and Epoch of Reionization (EoR). Radio telescopes such as the SKA will eventually map the HI fluctuations over the first billion years - the majority of our observable Universe. With such large data volumes, it becomes increasingly important to develop \"optimal\" summary statistics, allowing us to learn as much as possible about the CD and EoR. In this work we compare the constraining power of several 21-cm summary statistics, using the determinant of the Fisher information matrix, $\\det F$. Since we do not have an established \"fiducial\" model for the astrophysics of the first galaxies, we compute the distribution of $\\det F$ across the prior volume. Using a large database of cosmic 21-cm lightcones that include realizations of telescope noise, we compare the following summaries: (i) the spherically-averaged power spectrum (1DPS), (ii) the cylindrically-averaged power spectrum (2DPS), (iii) the 2D Wavelet scattering transform (WST), (iv) a recurrent neural network (RNN), (v) an information-maximizing neural network (IMNN), and (vi) the combination of 2DPS and IMNN. Our best performing individual summary is the 2DPS, having relatively high Fisher information throughout parameter space. Although capable of achieving the highest Fisher information for some parameter choices, the IMNN does not generalize well, resulting in a broad distribution. Our best results are achieved with the concatenation of the 2DPS and IMNN. The combination of only these two complimentary summaries reduces the recovered parameter variances on average by factors of $\\sim$6.5 - 9.5, compared with using each summary independently. Finally, we point out that that the common assumption of a constant covariance matrix when doing Fisher forecasts using 21-cm summaries can significantly underestimate parameter constraints.",
        "comments": "11 pages, 8 figures, submitted to A&A",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12277"
    },
    {
        "doc_id": 364,
        "title": "Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax Analysis and Adaptive Procedure",
        "authors": [
            "T. Tony Cai",
            "Hongming Pu"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Transfer learning for nonparametric regression is considered. We first study the non-asymptotic minimax risk for this problem and develop a novel estimator called the confidence thresholding estimator, which is shown to achieve the minimax optimal risk up to a logarithmic factor. Our results demonstrate two unique phenomena in transfer learning: auto-smoothing and super-acceleration, which differentiate it from nonparametric regression in a traditional setting. We then propose a data-driven algorithm that adaptively achieves the minimax risk up to a logarithmic factor across a wide range of parameter spaces. Simulation studies are conducted to evaluate the numerical performance of the adaptive transfer learning algorithm, and a real-world example is provided to demonstrate the benefits of the proposed method.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12272"
    },
    {
        "doc_id": 365,
        "title": "Advances in the characterization of curvature of two-dimentional probability manifolds",
        "authors": [
            "Giuseppe Giacopelli",
            "Andrea De Gaetano"
        ],
        "subjects": [
            "Statistics Theory",
            "Probability"
        ],
        "abstract": "In this work some advances in the theory of curvature of two-dimensional probability manifolds corresponding to families of distributions are proposed. It is proved that location-scale distributions are hyperbolic in the Information Geometry sense even when the generatrix is non-even or non-smooth. A novel formula is obtained for the computation of curvature in the case of exponential families: this formula implies some new flatness criteria in dimension 2. Finally, it is observed that many two parameter distributions, widely used in applications, are locally hyperbolic, which highlights the role of hyperbolic geometry in the study of commonly employed probability manifolds. These results have benefited from the use of explainable computational tools, which can substantially boost scientific productivity.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12270"
    },
    {
        "doc_id": 366,
        "title": "A decomposition algorithm for streak camera data",
        "authors": [
            "Kaan Oguzhan",
            "Lucas Ranc",
            "Livio Verra",
            "Allen Caldwell"
        ],
        "subjects": [
            "Instrumentation and Detectors",
            "Accelerator Physics"
        ],
        "abstract": "We describe a novel reconstruction algorithm for time-resolved images obtained using a streak camera. This algorithm operates by decomposing a recorded image into a set of individual photoelectron-induced signals, thereby providing a powerful method for streak camera image reconstruction. This deconstruction allows for a standard statistical analysis of the resulting image. We demonstrate the effectiveness of this technique by analyzing the temporal spacing between the emitted fs-long laser pulse and its succeeding first, second, and third reflections within a thick glass captured by a streak image.",
        "comments": "18 pages, 12 Figures, 1 table, 1 algorithm block",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12269"
    },
    {
        "doc_id": 367,
        "title": "Generalized Ordinal Patterns Allowing for Ties and Their Applications in Hydrology",
        "authors": [
            "Alexander Schnurr",
            "Svenja Fischer"
        ],
        "subjects": [
            "Applications",
            "Probability"
        ],
        "abstract": "When using ordinal patterns, which describe the ordinal structure within a data vector, the problem of ties appeared permanently. So far, model classes were used which do not allow for ties; randomization has been another attempt to overcome this problem. Often, time periods with constant values even have been counted as times of monotone increase. To overcome this, a new approach is proposed: it explicitly allows for ties and, hence, considers more patterns than before. Ties are no longer seen as nuisance, but to carry valuable information. Limit theorems in the new framework are provided, both, for a single time series and for the dependence between two time series. The methods are used on hydrological data sets. It is common to distinguish five flood classes (plus 'absence of flood'). Considering data vectors of these classes at a certain gauge in a river basin, one will usually encounter several ties. Co-monotonic behavior between the data sets of two gauges (increasing, constant, decreasing) can be detected by the method as well as spatial patterns. Thus, it helps to analyze the strength of dependence between different gauges in an intuitive way. This knowledge can be used to asses risk and to plan future construction projects.",
        "comments": "Journal ref:        CSDA 171, 107472 (2022)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12268"
    },
    {
        "doc_id": 368,
        "title": "Accelerating Sinkhorn Algorithm with Sparse Newton Iterations",
        "authors": [
            "Xun Tang",
            "Michael Shavlovsky",
            "Holakou Rahmanian",
            "Elisa Tardini",
            "Kiran Koshy Thekumparampil",
            "Tesi Xiao",
            "Lexing Ying"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Computing the optimal transport distance between statistical distributions is a fundamental task in machine learning. One remarkable recent advancement is entropic regularization and the Sinkhorn algorithm, which utilizes only matrix scaling and guarantees an approximated solution with near-linear runtime. Despite the success of the Sinkhorn algorithm, its runtime may still be slow due to the potentially large number of iterations needed for convergence. To achieve possibly super-exponential convergence, we present Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by introducing early stopping for the matrix scaling steps and a second stage featuring a Newton-type subroutine. Adopting the variational viewpoint that the Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight that the Hessian matrix of the potential function is approximately sparse. Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration complexity, the same as the Sinkhorn algorithm. In terms of total iteration count, we observe that the SNS algorithm converges orders of magnitude faster across a wide range of practical cases, including optimal transportation between empirical distributions and calculating the Wasserstein $W_1, W_2$ distance of discretized densities. The empirical performance is corroborated by a rigorous bound on the approximate sparsity of the Hessian matrix.",
        "comments": "In ICLR 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12253"
    },
    {
        "doc_id": 369,
        "title": "Does True Randomness Exist? Efficacy Testing IBM Quantum Computers via Statistical Randomness",
        "authors": [
            "Owen Root",
            "Maria Becker"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "The fundamental principles of quantum mechanics, such as its probabilistic nature, allow for the theoretical ability of quantum computers to generate statistically random numbers, as opposed to classical computers which are only able to generate pseudo-random numbers. This ability of quantum computers has a variety of applications, one of which provides the basis for a method of efficacy testing Quantum Computers themselves. We introduce this testing method and utilize it to investigate the efficacy of nine IBM Quantum Computer systems. The testing method utilized four different quantum random number generator algorithms and a battery of eighteen statistical tests. Only a single quantum computer-algorithm combination was found to be statistically random, demonstrating the power of the testing method as well as indicating that further work is needed for these computers to reach their theoretical potential.",
        "comments": "12 pages, 6 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12250"
    },
    {
        "doc_id": 370,
        "title": "The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness",
        "authors": [
            "Yifan Hao",
            "Tong Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "Recent empirical and theoretical studies have established the generalization capabilities of large machine learning models that are trained to (approximately or exactly) fit noisy data. In this work, we prove a surprising result that even if the ground truth itself is robust to adversarial examples, and the benignly overfitted model is benign in terms of the ``standard'' out-of-sample risk objective, this benign overfitting process can be harmful when out-of-sample data are subject to adversarial manipulation. More specifically, our main results contain two parts: (i) the min-norm estimator in overparameterized linear model always leads to adversarial vulnerability in the ``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result between the standard risk and the ``adversarial'' risk of every ridge regression estimator, implying that under suitable conditions these two items cannot both be small at the same time by any single choice of the ridge regularization parameter. Furthermore, under the lazy training regime, we demonstrate parallel results on two-layer neural tangent kernel (NTK) model, which align with empirical observations in deep neural networks. Our finding provides theoretical insights into the puzzling phenomenon observed in practice, where the true target function (e.g., human) is robust against adverasrial attack, while beginly overfitted neural networks lead to models that are not robust.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12236"
    },
    {
        "doc_id": 371,
        "title": "Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning",
        "authors": [
            "Philip Amortila",
            "Tongyi Cao",
            "Akshay Krishnamurthy"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undesirable behavior, resulting in no misspecification amplification while still obtaining optimal statistical rates. As applications, we use this regression procedure to obtain new guarantees in offline and online reinforcement learning with misspecification and establish new separations between previously studied structural conditions and notions of coverage.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12216"
    },
    {
        "doc_id": 372,
        "title": "Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources",
        "authors": [
            "V\u00edctor Samuel P\u00e9rez-D\u00edaz",
            "Juan Rafael Mart\u00ednez-Galarza",
            "Alexander Caicedo",
            "Raffaele D'Abrusco"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics",
            "Artificial Intelligence"
        ],
        "abstract": "The automatic classification of X-ray detections is a necessary step in extracting astrophysical information from compiled catalogs of astrophysical sources. Classification is useful for the study of individual objects, statistics for population studies, as well as for anomaly detection, i.e., the identification of new unexplored phenomena, including transients and spectrally extreme sources. Despite the importance of this task, classification remains challenging in X-ray astronomy due to the lack of optical counterparts and representative training sets. We develop an alternative methodology that employs an unsupervised machine learning approach to provide probabilistic classes to Chandra Source Catalog sources with a limited number of labeled sources, and without ancillary information from optical and infrared catalogs. We provide a catalog of probabilistic classes for 8,756 sources, comprising a total of 14,507 detections, and demonstrate the success of the method at identifying emission from young stellar objects, as well as distinguishing between small-scale and large-scale compact accretors with a significant level of confidence. We investigate the consistency between the distribution of features among classified objects and well-established astrophysical hypotheses such as the unified AGN model. This provides interpretability to the probabilistic classifier. Code and tables are available publicly through GitHub. We provide a web playground for readers to explore our final classification at https://umlcaxs-playground.streamlit.app.",
        "comments": "21 pages, 11 figures. Accepted in MNRAS",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12203"
    },
    {
        "doc_id": 373,
        "title": "Using spatial extreme-value theory with machine learning to model and understand spatially compounding extremes",
        "authors": [
            "Jonathan Koh",
            "Daniel Steinfeld",
            "Olivia Martius"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "When extreme weather events affect large areas, their regional to sub-continental spatial scale is important for their impacts. We propose a novel methodology that combines spatial extreme-value theory with a machine learning (ML) algorithm to model weather extremes and quantify probabilities associated with the occurrence, intensity and spatial extent of these events. The model is here applied to Western European summertime heat extremes. Using new loss functions adapted to extreme values, we fit a theoretically-motivated spatial model to extreme positive temperature anomaly fields from 1959-2022, using the daily 500-hpa geopotential height fields across the Euro-Atlantic region and the local soil moisture as predictors. Our generative model reveals the importance of individual circulation features in determining different facets of heat extremes, thereby enriching our process understanding of them from a data-driven perspective. The occurrence, intensity, and spatial extent of heat extremes are sensitive to the relative position of individual ridges and troughs that are part of a large-scale wave pattern. Heat extremes in Europe are thus the result of a complex interplay between local and remote physical processes. Our approach is able to extrapolate beyond the range of the data to make risk-related probabilistic statements, and applies more generally to other weather extremes. It also offers an attractive alternative to physical model-based techniques, or to ML approaches that optimise scores focusing on predicting well the bulk instead of the tail of the data distribution.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12195"
    },
    {
        "doc_id": 374,
        "title": "Concentration inequalities for the sample correlation coefficient",
        "authors": [
            "Daniel Salnikov"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "The sample correlation coefficient $R$ plays an important role in many statistical analyses. We study the moments of $R$ under the bivariate Gaussian model assumption, provide a novel approximation for its finite sample mean and connect it with known results for the variance. We exploit these approximations to present non-asymptotic concentration inequalities for $R$. Finally, we illustrate our results in a simulation experiment that further validates the approximations presented in this work.",
        "comments": "10 pages, preprint",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12190"
    },
    {
        "doc_id": 375,
        "title": "Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE",
        "authors": [
            "Hong Wei",
            "James Xiao",
            "Yichao Zhang",
            "Xia Hong"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Image segmentation is a clustering task whereby each pixel is assigned a cluster label. Remote sensing data usually consists of multiple bands of spectral images in which there exist semantically meaningful land cover subregions, co-registered with other source data such as LIDAR (LIght Detection And Ranging) data, where available. This suggests that, in order to account for spatial correlation between pixels, a feature vector associated with each pixel may be a vectorized tensor representing the multiple bands and a local patch as appropriate. Similarly, multiple types of texture features based on a pixel's local patch would also be beneficial for encoding locally statistical information and spatial variations, without necessarily labelling pixel-wise a large amount of ground truth, then training a supervised model, which is sometimes impractical. In this work, by resorting to label only a small quantity of pixels, a new semi-supervised segmentation approach is proposed. Initially, over all pixels, an image data matrix is created in high dimensional feature space. Then, t-SNE projects the high dimensional data onto 3D embedding. By using radial basis functions as input features, which use the labelled data samples as centres, to pair with the output class labels, a modified canonical correlation analysis algorithm, referred to as RBF-CCA, is introduced which learns the associated projection matrix via the small labelled data set. The associated canonical variables, obtained for the full image, are applied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA algorithm has been implemented on several remotely sensed multispectral images, demonstrating excellent segmentation results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12164"
    },
    {
        "doc_id": 376,
        "title": "The accuracy of ALMA estimates of young disk radii and masses. Predicted observations from numerical simulations",
        "authors": [
            "Ngo-Duy Tung",
            "Leonardo Testi",
            "Ugo Lebreuilly",
            "Patrick Hennebelle",
            "Ana\u00eblle Maury",
            "Ralf S. Klessen",
            "Luca Cacciapuoti",
            "Matthias Gonz\u00e1lez",
            "Giovanni Rosotti",
            "Sergio Molinari"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics",
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "Protoplanetary disks, which are the natural consequence of the gravitational collapse of the dense molecular cloud cores, host the formation of the planetary systems known today in our universe. Numerous efforts have been dedicated to investigate the properties of these disks in the more mature Class II stage, either by using numerical simulations of disk evolution from a limited range of initial conditions or by observations of their dust continuum and line emission from specific molecular tracers, and to compare the results from the two standpoints. Yet few studies have investigated the main limitations at work when measuring the embedded Class 0/I disk properties from observations, especially in a statistical fashion. In this study, we provide a first attempt to compare the accuracy of some critical disk parameters in Class 0/I systems, as derived on real ALMA observational data, with the corresponding physical parameters that modellers can directly define in numerical simulations. The approach we follow is to provide full post-processing of the numerical simulations and apply on the synthetic observations the same techniques used by observers to derive the physical parameters. To that end, we performed 3D Monte Carlo radiative transfer and mock interferometric observations of the disk populations formed in an MHD simulation model of disk formation through the collapse of massive clumps with the tools RADMC-3D and CASA, respectively, to obtain their synthetic observations. With these observations, we re-employ the techniques commonly used in disk modelling from their continuum emissions to infer their properties that one would likely obtain if one observed them with real interferometers. We then demonstrate how their properties vary from the gas kinematics analyses to the dust continuum modelling.",
        "comments": "Accepted for publication in Astronomy & Astrophysics, 32 pages, 28 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12142"
    },
    {
        "doc_id": 377,
        "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
        "authors": [
            "John D. Mayfield",
            "Issam El Naqa"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Image and Video Processing"
        ],
        "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term Memory (LSTM) models were studied to provide sequential relationships for each timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot study, we compared three QCNN-LSTM models for binary classification of MS disability benchmarked against classical neural network architectures. Our hypothesis is that quantum models will provide competitive performance. Methods Matrix Product State (MPS), reverse Multistate Entanglement Renormalization Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM layer to process near-annual MRI data of patients diagnosed with MS. These were benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision Transformer (ViViT). Predicted logits were measured against ground truth labels of each patient's Extended Disability Severity Score (EDSS) using binary cross-entropy loss. Training/validation/holdout testing was partitioned using 5-fold cross validation with a total split of 60:20:20. Levene's test of variance was used to measure statistical difference and Student's t-test for paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively (p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73 and 0.77, respectively (p-value 0.631). Overall variance and mean were not statistically significant (p-value 0.713), however, time to train was significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218, respectively, p-value <0.001). Conclusion QCNN-LSTM models perform competitively to their classical counterparts with greater efficiency in train time. Clinically, these can add value in terms of efficiency to time-dependent deep learning prediction of disease progression based upon medical imaging.",
        "comments": "ACM Class:          I.2.0; I.2.6",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12132"
    },
    {
        "doc_id": 378,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 379,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 380,
        "title": "The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization",
        "authors": [
            "Matan Schliserman",
            "Uri Sherman",
            "Tomer Koren"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We study the generalization performance of gradient methods in the fundamental stochastic convex optimization setting, focusing on its dimension dependence. First, for full-batch gradient descent (GD) we give a construction of a learning problem in dimension $d=O(n^2)$, where the canonical version of GD (tuned for optimal performance of the empirical risk) trained with $n$ training examples converges, with constant probability, to an approximate empirical risk minimizer with $\u03a9(1)$ population excess risk. Our bound translates to a lower bound of $\u03a9(\\sqrt{d})$ on the number of training examples required for standard GD to reach a non-trivial test error, answering an open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b) and showing that a non-trivial dimension dependence is unavoidable. Furthermore, for standard one-pass stochastic gradient descent (SGD), we show that an application of the same construction technique provides a similar $\u03a9(\\sqrt{d})$ lower bound for the sample complexity of SGD to reach a non-trivial empirical error, despite achieving optimal test performance. This again provides an exponential improvement in the dimension dependence compared to previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an open question left therein.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12058"
    },
    {
        "doc_id": 381,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 382,
        "title": "Multi-objective optimisation using expected quantile improvement for decision making in disease outbreaks",
        "authors": [
            "Daria Semochkina",
            "Alexander I. J. Forrester",
            "David C Woods"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Optimization under uncertainty is important in many applications, particularly to inform policy and decision making in areas such as public health. A key source of uncertainty arises from the incorporation of environmental variables as inputs into computational models or simulators. Such variables represent uncontrollable features of the optimization problem and reliable decision making must account for the uncertainty they propagate to the simulator outputs. Often, multiple, competing objectives are defined from these outputs such that the final optimal decision is a compromise between different goals.\n  Here, we present emulation-based optimization methodology for such problems that extends expected quantile improvement (EQI) to address multi-objective optimization. Focusing on the practically important case of two objectives, we use a sequential design strategy to identify the Pareto front of optimal solutions. Uncertainty from the environmental variables is integrated out using Monte Carlo samples from the simulator. Interrogation of the expected output from the simulator is facilitated by use of (Gaussian process) emulators. The methodology is demonstrated on an optimization problem from public health involving the dispersion of anthrax spores across a spatial terrain. Environmental variables include meteorological features that impact the dispersion, and the methodology identifies the Pareto front even when there is considerable input uncertainty.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12031"
    },
    {
        "doc_id": 383,
        "title": "Four Gluon Vertex from Lattice QCD",
        "authors": [
            "Manuel Cola\u00e7o",
            "Orlando Oliveira",
            "Paulo J. Silva"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Theory"
        ],
        "abstract": "A lattice QCD calculation for the four gluon one-particle irreducible Green function in the Landau gauge is discussed. Results for some of the associated form factors are reported for kinematical configurations with a single momentum scale. Our results show that the computation of this Green function requires large statistical ensembles with 10K or larger number of gauge configurations. The simulations considered herein have a clear Monte Carlo signal for momenta up to $\\sim 1$ GeV. The form factors show an hierarchy, with the form factor associated with the tree level Feynman rule being dominant and essentially constant for the range of momenta accessed. The remaining form factors seem to increase as the momentum decreases, suggesting that a possible $\\log$ divergence may occur. The computed form factors are, at least, in qualitative agreement with the results obtained with continuum approaches to this vertex, when available.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12008"
    },
    {
        "doc_id": 384,
        "title": "Integrating Statistical Significance and Discriminative Power in Pattern Discovery",
        "authors": [
            "Leonardo Alexandre",
            "Rafael S. Costa",
            "Rui Henriques"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Pattern discovery plays a central role in both descriptive and predictive tasks across multiple domains. Actionable patterns must meet rigorous statistical significance criteria and, in the presence of target variables, further uphold discriminative power. Our work addresses the underexplored area of guiding pattern discovery by integrating statistical significance and discriminative power criteria into state-of-the-art algorithms while preserving pattern quality. We also address how pattern quality thresholds, imposed by some algorithms, can be rectified to accommodate these additional criteria. To test the proposed methodology, we select the triclustering task as the guiding pattern discovery case and extend well-known greedy and multi-objective optimization triclustering algorithms, $\u03b4$-Trimax and TriGen, that use various pattern quality criteria, such as Mean Squared Residual (MSR), Least Squared Lines (LSL), and Multi Slope Measure (MSL). Results from three case studies show the role of the proposed methodology in discovering patterns with pronounced improvements of discriminative power and statistical significance without quality deterioration, highlighting its importance in supervisedly guiding the search. Although the proposed methodology is motivated over multivariate time series data, it can be straightforwardly extended to pattern discovery tasks involving multivariate, N-way (N>3), transactional, and sequential data structures.\n  Availability: The code is freely available at https://github.com/JupitersMight/MOF_Triclustering under the MIT license.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12000"
    },
    {
        "doc_id": 385,
        "title": "Elasticity of self-organized frustrated disordered spring networks",
        "authors": [
            "Tommaso Pettinari",
            "Gustavo D\u00fcring",
            "Edan Lerner"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics"
        ],
        "abstract": "There have been some interesting recent advances in understanding the notion of mechanical disorder in structural glasses and the statistical mechanics of these systems' low-energy excitations. Here we contribute to these advances by studying a minimal model for structural glasses' elasticity in which the degree of mechanical disorder -- as characterized by recently introduced dimensionless quantifiers -- is readily tunable over a very large range. We comprehensively investigate a number of scaling laws observed for various macro-, meso- and microscopic elastic properties, and rationalize them using scaling arguments. Interestingly, we demonstrate that the model features the universal quartic glassy vibrational density of states as seen in many atomistic and molecular models of structural glasses formed by cooling a melt. The emergence of this universal glassy spectrum highlights the role of self-organization (towards mechanical equilibrium) in its formation, and elucidates why models featuring structural frustration alone do not feature the same universal glassy spectrum. Finally, we discuss relations to existing work in the context of strain-stiffening of elastic networks and of low-energy excitations in structural glasses, in addition to future research directions.",
        "comments": "9 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11996"
    },
    {
        "doc_id": 386,
        "title": "1/f noise in quantum nanoscience",
        "authors": [
            "Giuseppe Falci",
            "Pertti J. Hakonen",
            "Elisabetta Paladino"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Superconductivity"
        ],
        "abstract": "Fundamental issues of 1/f noise in quantum nanoscience are reviewed starting from basic statistical noise processes. Fundamental noise models based on two-level systems (TLS) are described. We emphasize the importance of TLSs in materials parameter fluctuations, such as dielectric constant. The present understanding of 1/f noise in superconducting quantum interferometers and in single electron devices is summarized. For coherent quantum nanoscience, we introduce superconducting qubits and the relation between decoherence and 1/f noise using the filter function formulation. We also clarify the qubit noise spectroscopy and emphasize the importance of materials with reduced 1/f noise for future quantum coherent nanodevices.",
        "comments": "15 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11989"
    },
    {
        "doc_id": 387,
        "title": "Cross-Validation Conformal Risk Control",
        "authors": [
            "Kfir M. Cohen",
            "Sangwoo Park",
            "Osvaldo Simeone",
            "Shlomo Shamai"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Conformal risk control (CRC) is a recently proposed technique that applies post-hoc to a conventional point predictor to provide calibration guarantees. Generalizing conformal prediction (CP), with CRC, calibration is ensured for a set predictor that is extracted from the point predictor to control a risk function such as the probability of miscoverage or the false negative rate. The original CRC requires the available data set to be split between training and validation data sets. This can be problematic when data availability is limited, resulting in inefficient set predictors. In this paper, a novel CRC method is introduced that is based on cross-validation, rather than on validation as the original CRC. The proposed cross-validation CRC (CV-CRC) extends a version of the jackknife-minmax from CP to CRC, allowing for the control of a broader range of risk functions. CV-CRC is proved to offer theoretical guarantees on the average risk of the set predictor. Furthermore, numerical experiments show that CV-CRC can reduce the average set size with respect to CRC when the available data are limited.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11974"
    },
    {
        "doc_id": 388,
        "title": "RUMBoost: Gradient Boosted Random Utility Models",
        "authors": [
            "Nicolas Salvad\u00e9",
            "Tim Hillel"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "This paper introduces the RUMBoost model, a novel discrete choice modelling approach that combines the interpretability and behavioural robustness of Random Utility Models (RUMs) with the generalisation and predictive ability of deep learning methods. We obtain the full functional form of non-linear utility specifications by replacing each linear parameter in the utility functions of a RUM with an ensemble of gradient boosted regression trees. This enables piece-wise constant utility values to be imputed for all alternatives directly from the data for any possible combination of input variables. We introduce additional constraints on the ensembles to ensure three crucial features of the utility specifications: (i) dependency of the utilities of each alternative on only the attributes of that alternative, (ii) monotonicity of marginal utilities, and (iii) an intrinsically interpretable functional form, where the exact response of the model is known throughout the entire input space. Furthermore, we introduce an optimisation-based smoothing technique that replaces the piece-wise constant utility values of alternative attributes with monotonic piece-wise cubic splines to identify non-linear parameters with defined gradient. We demonstrate the potential of the RUMBoost model compared to various ML and Random Utility benchmark models for revealed preference mode choice data from London. The results highlight the great predictive performance and the direct interpretability of our proposed approach. Furthermore, the smoothed attribute utility functions allow for the calculation of various behavioural indicators and marginal utilities. Finally, we demonstrate the flexibility of our methodology by showing how the RUMBoost model can be extended to complex model specifications, including attribute interactions, correlation within alternative error terms and heterogeneity within the population.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11954"
    },
    {
        "doc_id": 389,
        "title": "The Ensemble Kalman Filter for Dynamic Inverse Problems",
        "authors": [
            "Simon Weissmann",
            "Neil K. Chada",
            "Xin T. Tong"
        ],
        "subjects": [
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "In inverse problems, the goal is to estimate unknown model parameters from noisy observational data. Traditionally, inverse problems are solved under the assumption of a fixed forward operator describing the observation model. In this article, we consider the extension of this approach to situations where we have a dynamic forward model, motivated by applications in scientific computation and engineering. We specifically consider this extension for a derivative-free optimizer, the ensemble Kalman inversion (EKI). We introduce and justify a new methodology called dynamic-EKI, which is a particle-based method with a changing forward operator. We analyze our new method, presenting results related to the control of our particle system through its covariance structure. This analysis includes moment bounds and an ensemble collapse, which are essential for demonstrating a convergence result. We establish convergence in expectation and validate our theoretical findings through experiments with dynamic-EKI applied to a 2D Darcy flow partial differential equation.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11948"
    },
    {
        "doc_id": 390,
        "title": "Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent",
        "authors": [
            "Zhiyu Liu",
            "Zhi Han",
            "Yandong Tang",
            "Xi-Le Zhao",
            "Yao Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it is worth noting that our method does not require the precise estimation of the tensor tubal-rank. Even in cases where the tubal-rank is slightly overestimated, our approach continues to demonstrate robust performance. A series of experiments have been carried out to demonstrate that, as compared to other popular ones, our approach exhibits superior performance in multiple scenarios, in terms of the faster computational speed and the smaller convergence error.",
        "comments": "13 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11940"
    },
    {
        "doc_id": 391,
        "title": "Large deviation full counting statistics in adiabatic open quantum dynamics",
        "authors": [
            "Paulo J. Paulino",
            "Igor Lesanovsky",
            "Federico Carollo"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Quantum Physics"
        ],
        "abstract": "The state of an open quantum system undergoing an adiabatic process evolves by following the instantaneous stationary state of its time-dependent generator. This observation allows one to characterize, for a generic adiabatic evolution, the average dynamics of the open system. However, information about fluctuations of dynamical observables, such as the number of photons emitted or the time-integrated stochastic entropy production in single experimental runs, requires controlling the whole spectrum of the generator and not only the stationary state. Here, we show how such information can be obtained in adiabatic open quantum dynamics by exploiting tools from large deviation theory. We prove an adiabatic theorem for deformed generators, which allows us to encode, in a biased quantum state, the full counting statistics of generic time-integrated dynamical observables. We further compute the probability associated with an arbitrary \"rare\" time-history of the observable and derive a dynamics which realizes it in its typical behavior. Our results provide a way to characterize and engineer adiabatic open quantum dynamics and to control their fluctuations.",
        "comments": "7 + 8 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11933"
    },
    {
        "doc_id": 392,
        "title": "Combination of searches for pair-produced leptoquarks at $\\sqrt{s} = 13$ TeV with the ATLAS detector",
        "authors": [
            "ATLAS Collaboration"
        ],
        "subjects": [
            "High Energy Physics - Experiment"
        ],
        "abstract": "A statistical combination of various searches for pair-produced leptoquarks is presented, using the full LHC Run 2 (2015-2018) data set of $139$ fb$^{-1}$ collected with the ATLAS detector from proton-proton collisions at a centre-of-mass energy of $\\sqrt{s}=13$ TeV. All possible decays of the leptoquarks into quarks of the third generation and charged or neutral leptons of any generation are investigated. Since no significant deviations from the Standard Model expectation are observed in any of the individual analyses, combined exclusion limits are set on the production cross-sections for scalar and vector leptoquarks. The resulting lower bounds on leptoquark masses exceed those from the individual analyses by up to 100 GeV, depending on the signal hypothesis.",
        "comments": "36 pages in total, authorlist starting on p19, 7 figures, 2 tables submitted to Phys. Lett. B. All figures are available at http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/EXOT-2020-27",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11928"
    },
    {
        "doc_id": 393,
        "title": "Inertia drives concentration-wave turbulence in swimmer suspensions",
        "authors": [
            "Purnima Jain",
            "Navdeep Rana",
            "Sriram Ramaswamy",
            "Prasad Perlekar"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Fluid Dynamics"
        ],
        "abstract": "We discover an instability mechanism in suspensions of self-propelled particles that does not involve active stress. Instead, it is driven by a subtle interplay of inertia, swimmer motility, and concentration fluctuations, through a crucial time lag between the velocity and the concentration field. The resulting time-persistent state seen in our high-resolution numerical simulations consists of self-sustained waves of concentration and orientation, transiting from regular oscillations to wave turbulence. We analyze the statistical features of this active turbulence, including an intriguing connection to the Batchelor spectrum of passive scalars.",
        "comments": "11 pages and 9 figures including supplementary material",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11927"
    },
    {
        "doc_id": 394,
        "title": "Comparison of Model Output Statistics and Neural Networks to Postprocess Wind Gusts",
        "authors": [
            "Cristina Primo",
            "Benedikt Schulz",
            "Sebastian Lerch",
            "Reinhold Hess"
        ],
        "subjects": [
            "Applications",
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Wind gust prediction plays an important role in warning strategies of national meteorological services due to the high impact of its extreme values. However, forecasting wind gusts is challenging because they are influenced by small-scale processes and local characteristics. To account for the different sources of uncertainty, meteorological centers run ensembles of forecasts and derive probabilities of wind gusts exceeding a threshold. These probabilities often exhibit systematic errors and require postprocessing. Model Output Statistics (MOS) is a common operational postprocessing technique, although more modern methods such as neural network-bases approaches have shown promising results in research studies. The transition from research to operations requires an exhaustive comparison of both techniques. Taking a first step into this direction, our study presents a comparison of a postprocessing technique based on linear and logistic regression approaches with different neural network methods proposed in the literature to improve wind gust predictions, specifically distributional regression networks and Bernstein quantile networks. We further contribute to investigating optimal design choices for neural network-based postprocessing methods regarding changes of the numerical model in the training period, the use of persistence predictors, and the temporal composition of training datasets. The performance of the different techniques is compared in terms of calibration, accuracy, reliability and resolution based on case studies of wind gust forecasts from the operational weather model of the German weather service and observations from 170 weather stations.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11896"
    },
    {
        "doc_id": 395,
        "title": "Bootstrap prediction regions for daily curves of electricity demand and price using functional data",
        "authors": [
            "Rebeca Pel\u00e1ez",
            "Germ\u00e1n Aneiros",
            "Juan Vilar"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The aim of this paper is to compute one-day-ahead prediction regions for daily curves of electricity demand and price. Three model-based procedures to construct general prediction regions are proposed, all of them using bootstrap algorithms. The first proposed method considers any $L_p$ norm for functional data to measure the distance between curves, the second one is designed to take different variabilities along the curve into account, and the third one takes advantage of the notion of depth of a functional data. The regression model with functional response on which our proposed prediction regions are based is rather general: it allows to include both endogenous and exogenous functional variables, as well as exogenous scalar variables; in addition, the effect of such variables on the response one is modeled in a parametric, nonparametric or semi-parametric way. A comparative study is carried out to analyse the performance of these prediction regions for the electricity market of mainland Spain, in year 2012. This work extends and complements the methods and results in Aneiros et al. (2016) (focused on curve prediction) and Vilar et al. (2018) (focused on prediction intervals), which use the same database as here.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11885"
    },
    {
        "doc_id": 396,
        "title": "A theoretical framework for BL Her stars -- II. New period-luminosity relations in the Gaia passbands",
        "authors": [
            "Susmita Das",
            "L\u00e1szl\u00f3 Moln\u00e1r",
            "Shashi M. Kanbur",
            "Meridith Joyce",
            "Anupam Bhardwaj",
            "Harinder P. Singh",
            "Marcella Marconi",
            "Vincenzo Ripepi",
            "Radoslaw Smolec"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "We present new theoretical period-luminosity (PL) and period-Wesenheit (PW) relations for a fine grid of convective BL Her, the shortest period T2Cs, models computed using MESA-RSP and compare our results with the empirical relations from Gaia DR3. We use the state-of-the-art 1D non-linear radial stellar pulsation tool MESA-RSP to compute models of BL Her stars over a wide range of input parameters - metallicity (-2.0 dex $\\leq$ [Fe/H] $\\leq$ 0.0 dex), stellar mass (0.5M$_{\\odot}$-0.8M$_{\\odot}$), stellar luminosity (50L$_{\\odot}$-300L$_{\\odot}$) and effective temperature (full extent of the instability strip; in steps of 50K). The BL Her stars in the All Sky region exhibit statistically different PL slopes compared to the theoretical PL slopes computed using the four sets of convection parameters. We find the empirical PL and PW slopes from BL Her stars in the Magellanic Clouds to be statistically consistent with the theoretical relations computed using the different convection parameter sets in the Gaia passbands. There is negligible effect of metallicity on the PL relations in the individual Gaia passbands. However, there exists a small but significant negative coefficient of metallicity in the PWZ relations for the BL Her models using the four sets of convection parameters. This could be attributed to the increased sensitivity of bolometric corrections to metallicities at wavelengths shorter than the V band. Our BL Her models also suggest a dependence of the mass-luminosity relation on metallicity. We found the observed Fourier parameter space to be covered well by our models. Higher mass models (> 0.6M$_{\\odot}$) may be needed to reliably model the observed light curves of BL Her stars in the All Sky region. We also found the theoretical light curve structures (especially the Fourier amplitude parameters) to be affected by the choice of convection parameters.",
        "comments": "19 pages, 8 figures, accepted in Astronomy & Astrophysics",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11869"
    },
    {
        "doc_id": 397,
        "title": "Fast measurement of group index variation with ultimate precision using Hong-Ou-Mandel interferometry",
        "authors": [
            "Sandeep Singh",
            "Vimlesh Kumar",
            "G. K. Samanta"
        ],
        "subjects": [
            "Quantum Physics",
            "Optics"
        ],
        "abstract": "Hong-Ou-Mandel (HOM) interferometry has emerged as a valuable tool for quantum sensing applications, particularly in measuring physical parameters that influence the relative optical delay between pair photons. Unlike classical techniques, HOM-based quantum sensors offer higher resolution due to their intrinsic dispersion cancellation property. Despite this advantage, achieving precise measurements of optical delay crucial for practical applications often involves time-consuming integration and post-processing with traditional statistical methods. To address this challenge, our recent work focused on optimizing optical delay measurements in a time-efficient manner. By carefully selecting the length of a 1 mm periodically-poled KTP (PPKTP) crystal for pair photon generation, we achieved a remarkable group index measurement precision of $\\sim 6.75\\times 10^{-6}$ per centimeter of sample length, surpassing the previous maximum precision by over 400$\\%$. These current measurements maintain fast detection and high photon counts, which are essential for practical quantum sensing applications. The HOM-based method, while limiting the measurement range, can be extended by compensating for photon delay using an optical delay stage. As a proof-of-principle, we measured the group index variation of PPKTP over a temperature range up to 200$^{\\circ}$C with a precision in the range of one part per million ($\\sim$10$^{-6}$). This advancement not only contributes to quantum sensing but also holds promising implications for high-precision and long-range measurements in quantum optical coherence tomography.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11853"
    },
    {
        "doc_id": 398,
        "title": "Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials",
        "authors": [
            "Valentine Perrin",
            "Nathan Noiry",
            "Nicolas Loiseau",
            "Alex Nowak"
        ],
        "subjects": [
            "Methodology",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "Non-significant randomized control trials can hide subgroups of good responders to experimental drugs, thus hindering subsequent development. Identifying such heterogeneous treatment effects is key for precision medicine and many post-hoc analysis methods have been developed for that purpose. While several benchmarks have been carried out to identify the strengths and weaknesses of these methods, notably for binary and continuous endpoints, similar systematic empirical evaluation of subgroup analysis for time-to-event endpoints are lacking. This work aims to fill this gap by evaluating several subgroup analysis algorithms in the context of time-to-event outcomes, by means of three different research questions: Is there heterogeneity? What are the biomarkers responsible for such heterogeneity? Who are the good responders to treatment? In this context, we propose a new synthetic and semi-synthetic data generation process that allows one to explore a wide range of heterogeneity scenarios with precise control on the level of heterogeneity. We provide an open source Python package, available on Github, containing our generation process and our comprehensive benchmark framework. We hope this package will be useful to the research community for future investigations of heterogeneity of treatment effects and subgroup analysis methods benchmarking.",
        "comments": "9 pages, 8 figures, 2 tables. Code available at https://github.com/owkin/hte . Comments are welcome!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11842"
    },
    {
        "doc_id": 399,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 400,
        "title": "Monadic transductions and definable classes of matroids",
        "authors": [
            "Susan Jowett",
            "Dillon Mayhew",
            "Songbao Mo",
            "Christopher Tuffley"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "A transduction provides us with a way of using the monadic second-order language of a structure to make statements about a derived structure. Any transduction induces a relation on the set of these structures. This article presents a self-contained presentation of the theory of transductions for the monadic second-order language of matroids. This includes a proof of the matroid version of the Backwards Translation Theorem, which lifts any formula applied to the images of the transduction into a formula which we can apply to the pre-images. Applications include proofs that the class of lattice-path matroids and the class of spike-minors can be defined by sentences in monadic second-order logic.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12969"
    },
    {
        "doc_id": 401,
        "title": "Measure transport with kernel mean embeddings",
        "authors": [
            "L. Wang",
            "N. N\u00fcsken"
        ],
        "subjects": [
            "Statistics Theory",
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "Kalman filters constitute a scalable and robust methodology for approximate Bayesian inference, matching first and second order moments of the target posterior. To improve the accuracy in nonlinear and non-Gaussian settings, we extend this principle to include more or different characteristics, based on kernel mean embeddings (KMEs) of probability measures into their corresponding Hilbert spaces. Focusing on the continuous-time setting, we develop a family of interacting particle systems (termed $\\textit{KME-dynamics}$) that bridge between the prior and the posterior, and that include the Kalman-Bucy filter as a special case. A variant of KME-dynamics has recently been derived from an optimal transport perspective by Maurais and Marzouk, and we expose further connections to (kernelised) diffusion maps, leading to a variational formulation of regression type. Finally, we conduct numerical experiments on toy examples and the Lorenz-63 model, the latter of which show particular promise for a hybrid modification (called Kalman-adjusted KME-dynamics).",
        "comments": "21 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12967"
    },
    {
        "doc_id": 402,
        "title": "Exponential perturbative expansions and coordinate transformations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a unified approach for different exponential perturbation techniques used in the treatment of time-dependent quantum mechanical problems, namely the Magnus expansion, the Floquet--Magnus expansion for periodic systems, the quantum averaging technique and the Lie--Deprit perturbative algorithms. Even the standard perturbation theory fits in this framework. The approach is based on carrying out an appropriate change of coordinates (or picture) in each case, and can be formulated for any time-dependent linear system of ordinary differential equations. All the procedures (except the standard perturbation theory) lead to approximate solutions preserving by construction unitarity when applied to the time-dependent Schr\u00f6dinger equation.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12955"
    },
    {
        "doc_id": 403,
        "title": "A unifying framework for perturbative exponential factorizations",
        "authors": [
            "Ana Arnal",
            "Fernando Casas",
            "Cristina Chiralt"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a framework where Fer and Wilcox expansions for the solution of differential equations are derived from two particular choices for the initial transformation that seeds the product expansion. In this scheme intermediate expansions can also be envisaged. Recurrence formulas are developed. A new lower bound for the convergence of the Wilcox expansion is provided as well as some applications of the results. In particular, two examples are worked out up to high order of approximation to illustrate the behavior of the Wilcox expansion.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12952"
    },
    {
        "doc_id": 404,
        "title": "To answer a question of Professor Georges Rhin",
        "authors": [
            "V. Flammang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Professor Georges Rhin considers a nonzero algebraic integer $\\a$ with conjugates $\\a_1=\\a, \\ldots, \\a_d$ and asks what can be said about $\\d \\sum_{ | \\a_i | >1} | \\a_i |$, that we denote ${\\rm{R}}(\\a)$. If $\\a$ is supposed to be a totally positive algebraic integer, we can establish an analog to the famous Schur-Siegel-Smyth trace problem for this measure. After that, we compute the greatest lower bound $c(\u03b8)$ of the quantities ${\\rm{R(\\a)}}/d$, for $\\a$ belonging to nine subintervals of $]0, 90 [$. The third three subintervals are complete and consecutive. All our results are obtained by using the method of explicit auxiliary functions. The polynomials involved in these functions are found by our recursive algorithm.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12951"
    },
    {
        "doc_id": 405,
        "title": "On the spectral asymptotics in domains with long boundary",
        "authors": [
            "Leonid Friedlander"
        ],
        "subjects": [
            "Spectral Theory"
        ],
        "abstract": "I discuss a simple toy problem for the Dirichlet Laplacian in a sequence of domains where the contribution of the boundary to the spectral asymptotics is of the same order as the contribution from the interior",
        "comments": "MSC Class:          35P20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12948"
    },
    {
        "doc_id": 406,
        "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion",
        "authors": [
            "Dylan Zhang",
            "Curt Tigges",
            "Zory Zhang",
            "Stella Biderman",
            "Maxim Raginsky",
            "Talia Ringer"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Formal Languages and Automata Theory",
            "Logic in Computer Science",
            "Programming Languages"
        ],
        "abstract": "This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models' behavior. The framework includes a representation that captures the general \\textit{syntax} of structural recursion, coupled with two different frameworks for understanding their \\textit{semantics} -- one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture.\n  With our framework as a powerful conceptual tool, we identify different issues under various set-ups. The models trained to emulate recursive computations cannot fully capture the recursion yet instead fit short-cut algorithms and thus cannot solve certain edge cases that are under-represented in the training distribution. In addition, it is difficult for state-of-the-art large language models (LLMs) to mine recursive rules from in-context demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating reduction (step-wise computation) of the recursive function.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.14699",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12947"
    },
    {
        "doc_id": 407,
        "title": "The local limit of rooted directed animals on the square lattice",
        "authors": [
            "Olivier H\u00e9nard",
            "\u00c9douard Maurel-Segala",
            "Arvind Singh"
        ],
        "subjects": [
            "Probability",
            "Combinatorics"
        ],
        "abstract": "We consider the local limit of finite uniformly distributed directed animals on the square lattice viewed from the root. Two constructions of the resulting uniform infinite directed animal are given: one as a heap of dominoes, constructed by letting gravity act on a right-continuous random walk and one as a Markov process, obtained by slicing the animal horizontally. We look at geometric properties of this local limit and prove, in particular, that it consists of a single vertex at infinitely many (random) levels. Several martingales are found in connection with the confinement of the infinite directed animal on the non-negative coordinates.",
        "comments": "59 pages, 16 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12935"
    },
    {
        "doc_id": 408,
        "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
        "authors": [
            "Angela Zhou"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "This paper studies offline reinforcement learning with linear function approximation in a setting with decision-theoretic, but not estimation sparsity. The structural restrictions of the data-generating process presume that the transitions factor into a sparse component that affects the reward and could affect additional exogenous dynamics that do not affect the reward. Although the minimally sufficient adjustment set for estimation of full-state transition properties depends on the whole state, the optimal policy and therefore state-action value function depends only on the sparse component: we call this causal/decision-theoretic sparsity. We develop a method for reward-filtering the estimation of the state-action value function to the sparse component by a modification of thresholded lasso in least-squares policy evaluation. We provide theoretical guarantees for our reward-filtered linear fitted-Q-iteration, with sample complexity depending only on the size of the sparse component.",
        "comments": "conference version accepted at AISTATS 2024",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12934"
    },
    {
        "doc_id": 409,
        "title": "The fiber bundle structure of General Relativity in Ashtekar variables",
        "authors": [
            "Matteo Bruno"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "In this review, we aim to analyze the mathematical interpretation of the Ashtekar-Barbero-Immirzi formulation of General Relativity. Along with a brief introduction to the necessary mathematical structures and tools, we illustrate some relevant physical theory quantities as geometrical objects within the framework of principal bundle theory.",
        "comments": "27 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12927"
    },
    {
        "doc_id": 410,
        "title": "A hypocoercivity-exploiting stabilised finite element method for Kolmogorov equation",
        "authors": [
            "Zhaonan Dong",
            "Emmanuil H. Georgoulis",
            "Philip J. Herbert"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a new stabilised finite element method for the classical Kolmogorov equation. The latter serves as a basic model problem for large classes of kinetic-type equations and, crucially, is characterised by degenerate diffusion. The stabilisation is constructed so that the resulting method admits a \\emph{numerical hypocoercivity} property, analogous to the corresponding property of the PDE problem. More specifically, the stabilisation is constructed so that spectral gap is possible in the resulting ``stronger-than-energy'' stabilisation norm, despite the degenerate nature of the diffusion in Kolmogorov, thereby the method has a provably robust behaviour as the ``time'' variable goes to infinity. We consider both a spatially discrete version of the stabilised finite element method and a fully discrete version, with the time discretisation realised by discontinuous Galerkin timestepping. Both stability and a priori error bounds are proven in all cases. Numerical experiments verify the theoretical findings.",
        "comments": "20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12921"
    },
    {
        "doc_id": 411,
        "title": "Decompositions of linear operators on pre-euclidean spaces by means of graphs",
        "authors": [
            "Hani Abdelwahab",
            "Elisabete Barreiro",
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Representation Theory",
            "Functional Analysis"
        ],
        "abstract": "In this work we study a linear operator $f$ on a pre-euclidean space $\\mathcal{V}$ by using properties of a corresponding graph. Given a basis $\\B$ of $\\mathcal{V}$, we present a decomposition of $\\mathcal{V}$ as an orthogonal direct sum of certain linear subspaces $\\{U_i\\}_{i \\in I}$, each one admitting a basis inherited from $\\B$, in such way that $f = \\sum_{i \\in I}f_i$, being each $f_i$ a linear operator satisfying certain conditions respect with $U_i$. Considering new hypothesis, we assure the existence of an isomorphism between the graphs associated to $f$ relative to two different bases. We also study the minimality of $\\mathcal{V}$ by using the graph associated to $f$ relative to $\\B$.",
        "comments": "Journal ref:Mathematics 11 (2023) special Issue \"Functional Analysis, Topology and Quantum Mechanics II\", no. 3, 725",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12916"
    },
    {
        "doc_id": 412,
        "title": "Viability and control of a delayed SIR epidemic with an ICU state constraint",
        "authors": [
            "Dimitri Breda",
            "Matteo Della Rossa",
            "Lorenzo Freddi"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This paper studies viability and control synthesis for a delayed SIR epidemic. The model integrates a constant delay representing an incubation/latency time. The control inputs model non-pharmaceutical interventions, while an intensive care unit (ICU) state-constraint is introduced to reflect the healthcare system's capacity. The arising delayed control system is analyzed via functional viability tools, providing insights into fulfilling the ICU constraint through feedback control maps. In particular, we consider two scenarios: first, we consider the case of general continuous initial conditions. Then, as a further refinement of our analysis, we assume that the initial conditions satisfy a Lipschitz continuity property, consistent with the considered model. The study compares the (in general, sub-optimal) obtained control policies with the optimal ones for the delay-free case, emphasizing the impact of the delay parameter. The obtained results are supported and illustrated, in a concluding section, by numerical examples.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12907"
    },
    {
        "doc_id": 413,
        "title": "Weight modules over split Lie algebras",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Representation Theory"
        ],
        "abstract": "We study the structure of weight modules $V$ with restrictions neither on the dimension nor on the base field, over split Lie algebras $L$. We show that if $L$ is perfect and $V$ satisfies $LV=V$ and ${\\mathcal Z}(V)=0$, then $$\\hbox{$L =\\bigoplus\\limits_{i\\in I} I_{i}$ and $V = \\bigoplus\\limits_{j \\in J} V_{j}$}$$ with any $I_{i}$ an ideal of $L$ satisfying $[I_{i},I_{k}]=0$ if $i \\neq k$, and any $V_{j}$ a (weight) submodule of $V$ in such a way that for any $j \\in J$ there exists a unique $i \\in I$ such that $I_iV_j \\neq 0,$ being $V_j$ a weight module over $I_i$. Under certain conditions, it is shown that the above decomposition of $V$ is by means of the family of its minimal submodules, each one being a simple (weight) submodule.",
        "comments": "Journal ref:        Modern Phys. Lett. A 28 (2013), no. 5, 1350008, 9 pp",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12906"
    },
    {
        "doc_id": 414,
        "title": "New simple solutions of the Yang--Baxter equation and their permutation groups",
        "authors": [
            "Ferran Cedo",
            "Jan Okninski"
        ],
        "subjects": [
            "Quantum Algebra",
            "Group Theory"
        ],
        "abstract": "A new class of indecomposable, irretractable, involutive, non-degenerate set-theoretic solutions of the Yang--Baxter equation is constructed. This class complements the class of such solutions constructed in \\cite{CO22} and together they generalize the class of solutions described in \\cite[Theorem 4.7{CO21}. Necessary and sufficient conditions are found in order that these new solutions are simple. For a rich subclass of these solutions the structure of their permutation groups, considered as left braces, is determined. In particular, these results answer a question stated in \\cite{CO21}. In the finite case, all these solutions have square cardinality. A new class of finite simple solutions of non-square cardinality such that their permutation groups are simple left braces is also constructed.",
        "comments": "arXiv admin note: text overlap with arXiv:2112.07271",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12904"
    },
    {
        "doc_id": 415,
        "title": "Propagation reversal on trees in the large diffusion regime",
        "authors": [
            "Hermen Jan Hupkes",
            "Mia Jukic"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "In this work we study travelling wave solutions to bistable reaction diffusion equations on bi-infinite $k$-ary trees in the continuum regime where the diffusion parameter is large. Adapting the spectral convergence method developed by Bates and his coworkers, we find an asymptotic prediction for the speed of travelling front solutions. In addition, we prove that the associated profiles converge to the solutions of a suitable limiting reaction-diffusion PDE. Finally, for the standard cubic nonlinearity we provide explicit formula's to bound the thin region in parameter space where the propagation direction undergoes a reversal.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12899"
    },
    {
        "doc_id": 416,
        "title": "Graded pseudo-H-rings",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Antonio D\u00edaz",
            "Marina Haralampidou",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Consider a pseudo-$H$-space $E$ endowed with a separately continuous biadditive associative multiplication which induces a grading on $E$ with respect to an abelian group $G$. We call such a space a graded pseudo-$H$-ring and we show that it has the form $E = cl(U + \\sum_j I_j)$ with $U$ a closed subspace of $E_1$ (the summand associated to the unit element in $G$), and any $I_j$ runs over a well described closed graded ideal of $E$, satisfying $I_jI_k = 0$ if $j \\neq k$. We also give a context in which graded simplicity of $E$ is characterized. Moreover, the second Wedderburn-type theorem is given for certain graded pseudo-$H$-rings.",
        "comments": "Journal ref:        Banach Journal of Mathematical Analysis 9 (2015), no. 2, 311-321",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12897"
    },
    {
        "doc_id": 417,
        "title": "Determination of a pair of newforms from the product of their twisted central values",
        "authors": [
            "Pramath Anamby",
            "Ritwik Pal"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We show that a pair of newforms $(f,g)$ can be uniquely determined by the product of the central $L$-values of their twists. To achieve our goal, we prove an asymptotic formula for the average of the product of the central values of two twisted $L$-functions- $L(1/2, f \\times \u03c7)L(1/2, g \\times \u03c7\u03c8)$, where $(f,g)$ is a pair of newforms. The average is taken over the primitive Dirichlet characters $\u03c7$ and $\u03c8$ of distinct prime moduli.",
        "comments": "Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12891"
    },
    {
        "doc_id": 418,
        "title": "Finitely many implies infinitely many",
        "authors": [
            "Melvyn B. Nathanson"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Many mathematical statements have the following form. If something is true for all finite subsets of an infinite set $I$, then it is true for all of $I$. This paper describes some old and new results on infinite sets of linear and polynomial equations with the property that solutions for all finite subsets of the set of equations implies the existence of a solution for the infinite set of equations.",
        "comments": "12 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12887"
    },
    {
        "doc_id": 419,
        "title": "On split Leibniz superalgebras",
        "authors": [
            "Antonio J. Calder\u00f3n",
            "Jos\u00e9 M. S\u00e1nchez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "We study the structure of arbitrary split Leibniz superalgebras. We show that any of such superalgebras ${\\frak L}$ is of the form ${\\frak L} = {\\mathcal U} + \\sum_jI_j$ with ${\\mathcal U}$ a subspace of an abelian (graded) subalgebra $H$ and any $I_j$ a well described (graded) ideal of ${\\frak L}$ satisfying $[I_j,I_k] = 0$ if $j \\neq k$. In the case of ${\\frak L}$ being of maximal length, the simplicity of ${\\frak L}$ is also characterized in terms of connections of roots.",
        "comments": "arXiv admin note: text overlap with arXiv:2003.12607",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12886"
    },
    {
        "doc_id": 420,
        "title": "Pirashvili--Richter-type theorems for the reflexive and dihedral homology theories",
        "authors": [
            "Daniel Graves"
        ],
        "subjects": [
            "Algebraic Topology"
        ],
        "abstract": "Reflexive homology and dihedral homology are the homology theories associated to the reflexive and dihedral crossed simplicial groups respectively. The former has recently been shown to capture interesting information about $C_2$-equivariant homotopy theory and its structure is related to the study of \"real\" objects in algebraic topology. The latter has long been of interest for its applications in $O(2)$-equivariant homotopy theory and connections to Hermitian algebraic $K$-theory. In this paper, we show that the reflexive and dihedral homology theories can be interpreted as functor homology over categories of non-commutative sets, after the fashion of Pirashvili and Richter's result for the Hochschild and cyclic homology theories.",
        "comments": "13 pages. Comments welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12884"
    },
    {
        "doc_id": 421,
        "title": "Counting subgraphs of coloring graphs",
        "authors": [
            "Shamil Asgarli",
            "Sara Krehbiel",
            "Howard W. Levinson",
            "Heather M. Russell"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "The chromatic polynomial $\u03c0_{G}(k)$ of a graph $G$ can be viewed as counting the number of vertices in a family of coloring graphs $\\mathcal C_k(G)$ associated with (proper) $k$-colorings of $G$ as a function of the number of colors $k$. These coloring graphs can be understood as a reconfiguration system. We generalize the chromatic polynomial to $\u03c0_G^{(H)}(k)$, counting occurrences of arbitrary induced subgraphs $H$ in these coloring graphs, and we prove that these functions are polynomial in $k$. In particular, we study the chromatic pairs polynomial $\u03c0_{G}^{(P_2)}(k)$, which counts the number of edges in coloring graphs, corresponding to the number of pairs of colorings that differ on a single vertex. We show two trees share a chromatic pairs polynomial if and only if they have the same degree sequence, and we conjecture that the chromatic pairs polynomial refines the chromatic polynomial in general. We also instantiate our polynomials with other choices of $H$ to generate new graph invariants.",
        "comments": "25 pages, 14 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12883"
    },
    {
        "doc_id": 422,
        "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic Conservation Laws",
        "authors": [
            "Jake J. Harmon",
            "Svetlana Tokareva",
            "Anatoly Zlotnik",
            "Pieter J. Swart"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolic partial differential equations (PDEs) under uncertainty. Constructed around the framework of stochastic finite volume (SFV) methods, our approach circumvents sampling schemes or simulation ensembles while also preserving fundamental properties, in particular hyperbolicity of the resulting systems and conservation of the discrete solutions. Furthermore, we augment the existing SFV theory with a priori convergence results for statistical quantities, in particular push-forward densities, which we demonstrate through numerical experiments. By linking refinement indicators to regions of the physical and stochastic spaces, we drive anisotropic refinements of the discretizations, introducing new degrees of freedom (DoFs) where deemed profitable. To illustrate our proposed method, we consider a series of numerical examples for non-linear hyperbolic PDEs based on Burgers' and Euler's equations.",
        "comments": "Report number:          LA-UR 23-32498                          MSC Class:          35L60; 35L67; 65C30; 65M50; 65M60",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12880"
    },
    {
        "doc_id": 423,
        "title": "An extension of the Liouville theorem for Fourier multipliers to sub-exponentially growing solutions",
        "authors": [
            "David Berger",
            "Ren\u00e9 L. Schilling",
            "Eugene Shargorodsky",
            "Teo Sharia"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We study the equation $m(D)f = 0$ in a large class of sub-exponentially growing functions. Under appropriate restrictions on $m \\in C(\\mathbb{R}^n)$, we show that every such solution can be analytically continued to a sub-exponentially growing entire function on $\\mathbb{C}^n$ if and only if $m(\u03be) \\not= 0$ for $\u03be\\not= 0$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12876"
    },
    {
        "doc_id": 424,
        "title": "Some Aspects of Higher Continued Fractions",
        "authors": [
            "Etan Basser",
            "Nicholas Ovenhouse",
            "Anuj Sakarda"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We investigate some properties of the higher continued fractions defined recently by Musiker, Ovenhouse, Schiffler, and Zhang. We prove that the maps defining the higher continued fractions are increasing continuous functions on the positive real numbers. We also investigate some asymptotics of these maps.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12859"
    },
    {
        "doc_id": 425,
        "title": "Implicative-orthomodular lattices",
        "authors": [
            "Lavinia Corina Ciungu"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Based on implicative involutive BE algebras, we redefine the orthomodular lattices, by introducing the notion of implicative-orthomodular lattices, and we study their properties. We characterize these algebras, proving that the implicative-orthomodular lattices are quantum-Wajsberg algebras. We also define and characterize the implicative-modular algebras as a subclass of implicative-orthomodular lattices. The orthomodular softlattices and orthomodular widelattices are also redefined, by introducing the notions of implicative-orthomodular softlattices and implicative-orthomodular widelattices. Finally, we prove that the implicative-orthomodular softlattices are equivalent to implicative-orthomodular lattices and that the implicative-orthomodular widelattices are special cases of quantum-Wajsberg algebras.",
        "comments": "arXiv admin note: text overlap with arXiv:2401.04140",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12845"
    },
    {
        "doc_id": 426,
        "title": "Gelation and localization in multicomponent coagulation with multiplicative kernel through branching processes",
        "authors": [
            "Jochem Hoogendijk",
            "Ivan Kryven",
            "Camillo Schenone"
        ],
        "subjects": [
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "The multicomponent coagulation equation is a generalisation of the Smoluchowski coagulation equation in which size of a particle is described by a vector. As with the original Smoluchowski equation, the multicomponent coagulation equation features gelation when supplied with a multiplicative kernel. Additionally, a new type of behaviour called localization is observed due to the multivariate nature of the particle size distribution. Here we extend and apply the branching process representation technique, which we introduced to study differential equations in our previous work, to find a concise probabilistic solution of the multicomponent coagulation equation supplied with monodisperse initial conditions and provide short proofs for the gelation time and localization.",
        "comments": "12 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12844"
    },
    {
        "doc_id": 427,
        "title": "Moving null curves and integrability",
        "authors": [
            "Metin G\u00fcrses",
            "Asli Pekcan"
        ],
        "subjects": [
            "Exactly Solvable and Integrable Systems",
            "Differential Geometry"
        ],
        "abstract": "We study the null curves and their motion in a $3$-dimensional flat space-time $M_{3}$. We show that when the motion of null curves forms two surfaces in $M_{3}$ the integrability conditions lead to the well-known AKNS hierarchy. In this case we obtain all the geometrical quantities of the surfaces arising from the whole hierarchy but we particulary focus on the surfaces of the MKdV and KdV equations. We obtain one- and two-soliton surfaces associated to the MKdV equation and show that the Gauss and mean curvatures of these surfaces develop singularities in finite time. We show that the tetrad vectors on the curves satisfy the spin vector equation in the ferromagnetism model of Heisenberg.",
        "comments": "16 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12841"
    },
    {
        "doc_id": 428,
        "title": "Hamilton cycles for involutions of classical types",
        "authors": [
            "Gon\u00e7alo Gutierres",
            "Ricardo Mamede",
            "Jos\u00e9 Luis Santos"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Let ${\\mathcal W}_n$ denote any of the three families of classical Weyl groups: the symmetric groups ${\\mathcal S}_n$, the hyperoctahedral groups (signed permutation groups) ${\\mathcal S}^B_n$, or the even-signed permutation groups ${\\mathcal S}^D_n$. In this paper we give an uniform construction of a Hamilton cycle for the restriction to involutions on these three families of groups with respect to a inverse-closed connecting set of involutions. This Hamilton cycle is optimal with respect to the Hamming distance only for the symmetric group ${\\mathcal S}_n$.\n  We also recall an optimal algorithm for a Gray code for type $B$ involutions. A modification of this algorithm would provide a Gray Code for type $D$ involutions with Hamming distance two, which would be optimal. We give such a construction for ${\\mathcal S}^D_4$ and ${\\mathcal S}^D_5$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12839"
    },
    {
        "doc_id": 429,
        "title": "Bifurcation of periodic solutions to nonlinear measure differential equations",
        "authors": [
            "Maria Carolina Mesquita Macena Stefani",
            "Milan Tvrd\u00fd"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "This paper is devoted to bifurcations of periodic solutions of nonlinear measure differential equations with a parameter. Main tools are nonlinear generalized differential equations (in the sense of Kurzweil) and the Kurzweil gauge type generalized integral. We continue the research started by the first author under the supervision of the second one.",
        "comments": "MSC Class:          26A39; 34C23; 34C25; 47H11",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12837"
    },
    {
        "doc_id": 430,
        "title": "Equivariant $K$-theory of even-dimensional complex quadrics",
        "authors": [
            "Bidhan Paul"
        ],
        "subjects": [
            "Algebraic Topology",
            "K-Theory and Homology"
        ],
        "abstract": "The aim of this paper is to describe the torus equivariant $K$-ring of even-dimensional complex quadrics by studying the graph equivariant $K$-theory of their corresponding GKM graphs. This involves providing a presentation for its graph equivariant $K$- ring in terms of generators and relations. This parallels the description of the equivariant cohomology ring of even-dimensional complex quadrics due to Kuroki.",
        "comments": "17 pages, comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12833"
    },
    {
        "doc_id": 431,
        "title": "Numerical approximation of the stochastic Cahn-Hilliard equation with space-time white noise near the sharp interface limit",
        "authors": [
            "\u013dubom\u00edr Ba\u0148as",
            "Jean Daniel Mukam"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We consider the stochastic Cahn-Hilliard equation with additive space-time white noise $\u03b5^\u03b3\\dot{W}$ in dimension $d=2,3$, where $\u03b5>0$ is an interfacial width parameter. We study numerical approximation of the equation which combines a structure preserving implicit time-discretization scheme with a discrete approximation of the space-time white noise. We derive a strong error estimate for the considered numerical approximation which is robust with respect to the inverse of the interfacial width parameter $\u03b5$. Furthermore, by a splitting approach, we show that for sufficiently large scaling parameter $\u03b3$, the numerical approximation of the stochastic Cahn-Hilliard equation converges uniformly to the deterministic Hele-Shaw/Mullins-Sekerka problem in the sharp interface limit $\u03b5\\rightarrow 0$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12832"
    },
    {
        "doc_id": 432,
        "title": "Compactness and existence theory for a general class of stationary radiative transfer equations",
        "authors": [
            "Elena Dematt\u00e8",
            "Jin Woo Jang",
            "Juan J. L. Vel\u00e1zquez"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we study the steady-states of a large class of stationary radiative transfer equations in a $C^1$ convex bounded domain. Namely, we consider the case in which both absorption-emission and scattering coefficients depend on the local temperature $T$ and the radiation frequency $\u03bd.$ The radiative transfer equation determines the temperature of the material at each point. The main difficulty in proving existence of solutions is to obtain compactness of the sequence of integrals along lines that appear in several exponential terms. We prove a new compactness result suitable to deal with such a non-local operator containing integrals on a line segment. On the other hand, to obtain the existence theory of the full equation with both absorption and scattering terms we combine the compactness result with the construction of suitable Green functions for a class of non-local equations.",
        "comments": "MSC Class:          35Q31 (Primary) 85A25; 76N10; 35R25; 35A02 (Secondary)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12828"
    },
    {
        "doc_id": 433,
        "title": "Exodromy beyond conicality",
        "authors": [
            "Peter J. Haine",
            "Mauro Porta",
            "Jean-Baptiste Teyssier"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "Category Theory"
        ],
        "abstract": "We show that compact subanalytic stratified spaces and algebraic stratifications of real varieties have finite exit-path $\\infty$-categories, refining classical theorems of Lefschetz-Whitehead, Lojasiewicz, and Hironaka on the finiteness of the underlying homotopy types of these spaces. These stratifications are typically not conical; hence we cannot rely on the currently available exodromy equivalence between constructible sheaves on a stratified space, which requires conicality as a fundamental hypothesis. Building on ideas of Clausen and Orsnes Jansen, we study the class of exodromic stratified spaces, for which the conclusion of the exodromy theorem holds. We prove two new fundamental properties of this class of stratified spaces: coarsenings of exodromic stratifications are exodromic, and every morphism between exodromic stratified spaces induces a functor between the associated exit path $\\infty$-categories. As a consequence, we produce many new examples of exodromic stratified spaces, including: coarsenings of conical stratifications, locally finite subanalytic stratifications of real analytic spaces, and algebraic stratifications of real varieties. Our proofs are at the generality of stratified $\\infty$-topoi, hence apply to even more general situations such as stratified topological stacks. Finally, we use the previously mentioned finiteness results to construct derived moduli stacks of constructible and perverse sheaves.",
        "comments": "Comments very welcome. 73 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12825"
    },
    {
        "doc_id": 434,
        "title": "Ray-Singer Torsion, Topological Strings and Black Holes",
        "authors": [
            "Cumrun Vafa"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "Genus one amplitude for topological strings on Calabi-Yau 3-folds can be computed using mirror symmetry: The partition function at genus one gets mapped to a holomorphic version of Ray-Singer torsion on the mirror Calabi-Yau. On the other hand it can be shown by a physical argument that this gives a curvature squared correction term to the gravitational action. This in paticular leads to an effective quantum gravity cutoff known as the species scale, which varies over moduli space of Calabi-Yau manifolds. This resolves some of the puzzles associated to the entropy of small black holes when there are a large number of light species of particles. Thus Ray-Singer torsion, via its connection to topological strings at genus one, provides a measure of light degrees of freedom of four dimensional N=2 supergravity theories. Based on a talk given on May 12th, 2023 at the Singer Memorial Conference, MIT.",
        "comments": "11 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12816"
    },
    {
        "doc_id": 435,
        "title": "$b$-Hurwitz numbers from Whittaker vectors for $\\mathcal{W}$-algebras",
        "authors": [
            "Nitin K. Chidambaram",
            "Maciej Do\u0142\u0119ga",
            "Kento Osuga"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Mathematical Physics",
            "Combinatorics",
            "Representation Theory"
        ],
        "abstract": "We show that $b$-Hurwitz numbers with a rational weight are obtained by taking an explicit limit of a Whittaker vector for the $\\mathcal{W}$-algebra of type $A$. Our result is a vast generalization of several previous results that treated the monotone case, and the cases of quadratic and cubic polynomial weights. It also provides an interpretation of the associated Whittaker vector in terms of generalized branched coverings that might be of independent interest. Our result is new even in the special case $b=0$ that corresponds to classical hypergeometric Hurwitz numbers, and implies that they are governed by the topological recursion of Eynard-Orantin. This gives an independent proof of the recent result of Bychkov-Dunin-Barkowski-Kazarian-Shadrin.",
        "comments": "40 pages, comments welcome!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12814"
    },
    {
        "doc_id": 436,
        "title": "Optimal Stopping of Branching Diffusion Processes",
        "authors": [
            "Idris Kharroubi",
            "Antonio Ocello"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "This article explores an optimal stopping problem for branching diffusion processes. It consists in looking for optimal stopping lines, a type of stopping time that maintains the branching structure of the processes under analysis. By using a dynamic programming approach, we characterize the value function for a multiplicative cost that depends on the particle's label. We reduce the problem's dimensionality by setting a branching property and defining the problem in a finite-dimensional context. Within this framework, we focus on the value function, establishing polynomial growth and local Lipschitz properties, together with an innovative dynamic programming principle. This outcome leads to an analytical characterization with the help of a nonlinear elliptic PDE. We conclude by showing that the value function serves as the unique viscosity solution for this PDE, generalizing the comparison principle to this setting.",
        "comments": "MSC Class:          60G40; 60J80; 35J60; 49L20; 49L25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12811"
    },
    {
        "doc_id": 437,
        "title": "A sequence of $\u03c0/3$-equiangular hyperbolic polyhedra",
        "authors": [
            "Jun Nonaka"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "Atkinson [2] found a sequence of three-dimensional hyperbolic polyhedra whose dihedral angles are $\u03c0/3$. In this paper, we show the other sequence of such polyhedra. We also find the volumes of some of such polyhedra.",
        "comments": "12 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12809"
    },
    {
        "doc_id": 438,
        "title": "New lower bounds for three-term progression free sets in $\\mathbb{F}_p^n$",
        "authors": [
            "Christian Elsholtz",
            "Laura Proske",
            "Lisa Sauermann"
        ],
        "subjects": [
            "Combinatorics",
            "Number Theory"
        ],
        "abstract": "We prove new lower bounds on the maximum size of sets $A\\subseteq \\mathbb{F}_p^n$ or $A\\subseteq \\mathbb{Z}_m^n$ not containing three-term arithmetic progressions (consisting of three distinct points). More specifically, we prove that for any fixed integer $m\\ge 2$ and sufficiently large $n$ (in terms of $m$), there exists a three-term progression free subset $A\\subseteq \\mathbb{Z}_m^n$ of size $|A|\\ge (cm)^n$ for some absolute constant $c>1/2$. Such a bound for $c=1/2$ can be obtained with a classical construction of Salem and Spencer from 1942, and improving upon this value of $1/2$ has been a well-known open problem (our proof gives $c= 0.54$).\n  Our construction relies on finding a subset $S\\subset \\mathbb{Z}_m^2$ of size at least $(7/24)m^2$ with a certain type of reducibility property. This property allows us to ``lift'' $S$ to a three-term progression free subset of $\\mathbb{Z}_m^n$ for large $n$ (even though the original set $S\\subset \\mathbb{Z}_m^2$ does contain three-term arithmetic progressions).",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12802"
    },
    {
        "doc_id": 439,
        "title": "Some convergence analysis for multicontinuum homogenization",
        "authors": [
            "Wing Tat Leung"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this paper, we provide an analysis of a recently proposed multicontinuum homogenization technique. The analysis differs from those used in classical homogenization methods for several reasons. First, the cell problems in multicontinuum homogenization use constraint problems and can not be directly substituted into the differential operator. Secondly, the problem contains high contrast that remains in the homogenized problem. The homogenized problem averages the microstructure while containing the small parameter. In this analysis, we first based on our previous techniques, CEM-GMsFEM, to define a CEM-downscaling operator that maps the multicontinuum quantities to an approximated microscopic solution. Following the regularity assumption of the multicontinuum quantities, we construct a downscaling operator and the homogenized multicontinuum equations using the information of linear approximation of the multicontinuum quantities. The error analysis is given by the residual estimate of the homogenized equations and the well-posedness assumption of the homogenized equations.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12799"
    },
    {
        "doc_id": 440,
        "title": "Well-posedness of low regularity solutions for the 3D relativistic Euler equations",
        "authors": [
            "Huali Zhang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We study the well-posedness of low regularity solutions for the Cauchy problem of 3D relativistic Euler equations. By introducing a new decomposition for the relativistic velocity, deriving a new transport equation for modified vorticity, and establishing Strichartz estimates of linear wave equations endowed with the acoustic metric, we first prove a complete local well-posedness result for the Cauchy problem of 3D relativistic Euler equations if the initial velocity $\\bu_0=(u^0_0,\\mathring{\\bu}_0)^{\\mathrm{T}}$, logarithmic enthalpy $h_0$, and modified vorticity $\\bw_0$ satisfy $(h_0,\\mathring{\\bu}_0,\\bw_0)\\in H^s \\times H^s \\times H^{s_0} (2<s_0<s)$, where $\\mathring{\\bu}_0$ is a three-vector and $u^0_0=\\sqrt{1+|\\mathring{\\bu}_0|^2}$. Secondly, combining the above Strichartz estimates, semi-classical analysis, and induction method, we prove the corresponding problem is well-posed if $(h_0,\\mathring{\\bu}_0,\\bw_0) \\in H^s \\times H^s \\times H^2 (s>2)$. Our approach relies on Andersson-Zhang's work \\cite{AZ} on corresponding non-relativistic problems. All our results are valid for a general equation of state $p(\\varrho)=\\varrho^\\vartheta, \\vartheta>1$.",
        "comments": "Welcome all comments!",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12796"
    },
    {
        "doc_id": 441,
        "title": "Contractions in perfect graph",
        "authors": [
            "Alexandre Dupont-Bouillard",
            "Pierre Fouilhoux",
            "Roland Grappe",
            "Mathieu Lacroix"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper, we characterize the class of {\\em contraction perfect} graphs which are the graphs that remain perfect after the contraction of any edge set. We prove that a graph is contraction perfect if and only if it is perfect and the contraction of any single edge preserves its perfection. This yields a characterization of contraction perfect graphs in terms of forbidden induced subgraphs, and a polynomial algorithm to recognize them. We also define the utter graph $u(G)$ which is the graph whose stable sets are in bijection with the co-2-plexes of $G$, and prove that $u(G)$ is perfect if and only if $G$ is contraction perfect.",
        "comments": "11 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12793"
    },
    {
        "doc_id": 442,
        "title": "The Alekseev-Meinrenken diffeomorphism arising from the Stokes phenomenon",
        "authors": [
            "Xiaomeng Xu"
        ],
        "subjects": [
            "Differential Geometry",
            "Classical Analysis and ODEs"
        ],
        "abstract": "The Alekseev-Meinrenken diffeomorphism is a distinguished diffeomorphism from the space of $n\\times n$ Hermitian matrices to the space of $n\\times n$ positive definite Hermitian matrices. This paper derives the explicit expression of the diffeomorphism, via the Stokes phenomenon of meromorphic linear systems of ordinary differential equations with Poncar\u00e9 rank $1$.",
        "comments": "18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12792"
    },
    {
        "doc_id": 443,
        "title": "On indices and monogenity of quartic number fields defined by quadrinomials",
        "authors": [
            "Hamid Ben Yakkou"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Consider a quartic number field $K$ generated by a root of an irreducible quadrinomial of the form $ F(x)= x^4+ax^3+bx+c \\in \\Z[x]$. Let $i(K)$ denote the index of $K$. Engstrom \\cite{Engstrom} established that $i(K)=2^u \\cdot 3^v$ with $u \\le 2$ and $v \\le 1$. In this paper, we provide sufficient conditions on $a$, $b$ and $c$ for $i(K)$ to be divisible by $2$ or $3$, determining the exact corresponding values of $u$ and $v$ in each case.\n  In particular, when $i(K) \\neq 1$, $K$ cannot be monogenic. We also identify new infinite parametric families of monogenic quartic number generated by roots of non-monogenic quadrinomials. We illustrate our results by some computational examples. Our method based on a theorem of Ore on the decomposition of primes in number fields \\cite{Nar,O}.",
        "comments": "MSC Class:          11R04; 11R16; 11R21; 11Y40                          ACM Class:          F.2.2",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12782"
    },
    {
        "doc_id": 444,
        "title": "On the average stopping time of the Collatz map in $\\mathbb{F}_2[x]$",
        "authors": [
            "Manuel Inselmann"
        ],
        "subjects": [
            "Dynamical Systems",
            "Combinatorics",
            "Probability"
        ],
        "abstract": "Define the map $T_1$ on $\\mathbb{F}_2[x]$ by $T_1(f)=\\frac{f}{x}$ if $f(0)=0$ and $T_1(f)=\\frac{(x+1)f+1}{x}$ if $f(0)=1$. For a non-zero polynomial $f$ let $\u03c4_1(f)$ denote the least natural $k$ number for which $T_1^{k}(f)=1$. Define the average stopping time to be $\u03c1_1(n)=\\frac{\\sum_{f\\in \\mathbb{F}_2[x], \\text{deg}(f)=n }\u03c4_1(f)}{2^n}$. We show that $\\frac{\u03c1_1(n)}{n}$ converges to $2$ as $n\\rightarrow\\infty$ confirming a conjecture of Alon, Behajaina and Paran. Furthermore, we give a new proof that $\u03c4_1(f)\\in O(\\text{deg}(f)^{1.5})$ for all $f\\in\\mathbb{F}_2[x]\\setminus\\{0\\}$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12781"
    },
    {
        "doc_id": 445,
        "title": "On $p$-adic Hurwitz-type spectral zeta functions",
        "authors": [
            "Su Hu",
            "Min-Soo Kim"
        ],
        "subjects": [
            "Number Theory",
            "Mathematical Physics",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Let $\\left\\{E_n\\right\\}_{n=1}^{\\infty}$ be the set of energy levels corresponding to a Hamiltonian $H$.\n  Denote by $$\u03bb_{0}=0~~\\textrm{and}~~\u03bb_{n}=E_{n}$$\n  for $n\\in\\mathbb N.$ In this paper, we shall construct and investigate the $p$-adic counterparts of the Hurwitz-type spectral zeta function \\begin{equation} \u03b6^{H}(s,\u03bb)=\\sum_{n=0}^{\\infty}\\frac{1}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} and its alternating form \\begin{equation} \u03b6_{E}^{H}(s,\u03bb)=2\\sum_{n=0}^{\\infty}\\frac{(-1)^{n}}{(\u03bb_{n}+\u03bb)^{s}} \\end{equation} in a parallel way.",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12775"
    },
    {
        "doc_id": 446,
        "title": "Y-function and L'Hospital-type Monotonicity Rules with Nabla and Diamond-Alpha Derivatives on Time Scales",
        "authors": [
            "Xiao-Yue Du",
            "Zhong-Xuan Mao",
            "Jing-Feng Tian"
        ],
        "subjects": [
            "Classical Analysis and ODEs"
        ],
        "abstract": "The main objective of this paper is to establish the $Y$-function and L'Hospital-type monotonicity rules with nabla and diamond-alpha derivatives on time scales.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12774"
    },
    {
        "doc_id": 447,
        "title": "Multitype branching processes in random environments with not strictly positive expectation matrices",
        "authors": [
            "Vilma Orgov\u00e1nyi",
            "K\u00e1roly Simon"
        ],
        "subjects": [
            "Probability",
            "Dynamical Systems"
        ],
        "abstract": "It is well known that under some conditions the almost sure survival probability of a multitype branching processes in random environment is positive if the Lyapunov exponent corresponding to the expectation matrices is positive, and zero if the Lyapunov exponent is negative. The goal of this note is to establish similar results when certain positivity conditions on the expectation matrices are not met. One application of such a result is to classify the positivity of Lebesgue measure of certain overlapping random self-similar sets in the line.",
        "comments": "22 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12767"
    },
    {
        "doc_id": 448,
        "title": "Absorbing ideals: a survey on $\u03c9$-stable groups",
        "authors": [
            "Bruno Moreira Fernandes"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We introduce a new concept in the Absorbing Ideal Theory in commutative rings, that is, the $\u03c9$-stable groups. We will provide examples and non-examples of these groups, and establish their relationship with H-congruence. Ultimately, we will study the action of these groups considering the transitivity condition",
        "comments": "9 pages",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12766"
    },
    {
        "doc_id": 449,
        "title": "Spectral analysis of a semiclassical random walk associated to a general confining potential",
        "authors": [
            "Thomas Normand"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Spectral Theory"
        ],
        "abstract": "We consider a semiclassical random walk with respect to a probability measure associated to a potential with a finite number of critical points. We recover the spectral results from [1] on the corresponding operator in a more general setting and with improved accuracy. In particular we do not make any assumption on the distribution of the critical points of the potential, in the spirit of [15]. Our approach consists in adapting the ideas from [15] to the recent gaussian quasimodes framework which appears to be more robust than the usual methods, especially when dealing with non local operators.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12765"
    },
    {
        "doc_id": 450,
        "title": "Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\\mathcal{O}(1/k)$ Finite-Sample Complexity",
        "authors": [
            "Thinh T. Doan"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $\\mathcal{O}(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $\\mathcal{O}(1/k^{2/3})$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12764"
    },
    {
        "doc_id": 451,
        "title": "Optimal design of a local renewable electricity supply system for power-intensive production processes with demand response",
        "authors": [
            "Sonja H. M. Germscheid",
            "Benedikt Nilges",
            "Niklas von der Assen",
            "Alexander Mitsos",
            "Manuel Dahmen"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This work studies synergies arising from combining industrial demand response and local renewable electricity supply. To this end, we optimize the design of a local electricity generation and storage system with an integrated demand response scheduling of a continuous power-intensive production process in a multi-stage problem. We optimize both total annualized cost and global warming impact and consider local photovoltaic and wind electricity generation, an electric battery, and electricity trading on day-ahead and intraday market. We find that installing a battery can reduce emissions and enable large trading volumes on the electricity markets, but significantly increases cost. Economic and ecologic process and battery operation are driven primarily by the electricity price and grid emission factor, respectively, rather than locally generated electricity. A parameter study reveals that economic savings from the local system and flexibilizing the process behave almost additive.",
        "comments": "manuscript (32 pages, 9 figures, 6 tables), supporting materials (11 pages, 9 figures, 2 tables)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12759"
    },
    {
        "doc_id": 452,
        "title": "Optimal Confidence Bands for Shape-restricted Regression in Multidimensions",
        "authors": [
            "Ashley",
            "Datta",
            "Somabha Mukherjee",
            "Bodhisattva Sen"
        ],
        "subjects": [
            "Statistics Theory",
            "Methodology"
        ],
        "abstract": "In this paper, we propose and study construction of confidence bands for shape-constrained regression functions when the predictor is multivariate. In particular, we consider the continuous multidimensional white noise model given by $d Y(\\mathbf{t}) = n^{1/2} f(\\mathbf{t}) \\,d\\mathbf{t} + d W(\\mathbf{t})$, where $Y$ is the observed stochastic process on $[0,1]^d$ ($d\\ge 1$), $W$ is the standard Brownian sheet on $[0,1]^d$, and $f$ is the unknown function of interest assumed to belong to a (shape-constrained) function class, e.g., coordinate-wise monotone functions or convex functions. The constructed confidence bands are based on local kernel averaging with bandwidth chosen automatically via a multivariate multiscale statistic. The confidence bands have guaranteed coverage for every $n$ and for every member of the underlying function class. Under monotonicity/convexity constraints on $f$, the proposed confidence bands automatically adapt (in terms of width) to the global and local (H\u00f6lder) smoothness and intrinsic dimensionality of the unknown $f$; the bands are also shown to be optimal in a certain sense. These bands have (almost) parametric ($n^{-1/2}$) widths when the underlying function has ``low-complexity'' (e.g., piecewise constant/affine).",
        "comments": "43 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12753"
    },
    {
        "doc_id": 453,
        "title": "N-free posets and orthomodularity",
        "authors": [
            "Gejza Jen\u010da"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We prove that the incomparability orthoset of a finite poset is Dacey if and only if the poset is N-free. We give a characterization of finite posets with compatible incomparability orthosets.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12749"
    },
    {
        "doc_id": 454,
        "title": "Multicausal transport: barycenters and dynamic matching",
        "authors": [
            "Beatrice Acciaio",
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "We introduce a multivariate version of adapted transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agents' types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.",
        "comments": "26 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12748"
    },
    {
        "doc_id": 455,
        "title": "Approximation of sea surface velocity field by fitting surrogate two-dimensional flow to scattered measurements",
        "authors": [
            "Karlo Jakac",
            "Luka Lan\u010da",
            "Ante Sikirica",
            "Stefan Ivi\u0107"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Optimization and Control"
        ],
        "abstract": "In this paper, a rapid approximation method is introduced to estimate the sea surface velocity field based on scattered measurements. The method uses a simplified two-dimensional flow model as a surrogate model, which mimics the real submesoscale flow. The proposed approach treats the interpolation of the flow velocities as an optimization problem, aiming to fit the flow model to the scattered measurements. To ensure consistency between the simulated velocity field and the measured values, the boundary conditions in the numerical simulations are adjusted during the optimization process. Additionally, the relevance of quantity and quality of the scattered measurements is assessed, emphasizing the importance of the measurement locations within the domain as well as explaining how these measurements contribute to the accuracy and reliability of the sea surface velocity field approximation. The proposed methodology has been successfully tested in both synthetic and real-world scenarios, leveraging measurements obtained from GPS drifters and HF-radar systems. The adaptability of this approach for different domains, measurement types and conditions implies that it is suitable for real-world submesoscale scenarios where only an approximation of the sea surface velocity field is sufficient.",
        "comments": "22 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12746"
    },
    {
        "doc_id": 456,
        "title": "Anderson stochastic quantization equation",
        "authors": [
            "Hugo Eulry",
            "Antoine Mouzard",
            "Tristan Robert"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Probability"
        ],
        "abstract": "We study the parabolic defocusing stochastic quantization equation with both mutliplicative spatial white noise and an independant space-time white noise forcing, on compact surfaces, with polynomial nonlinearity. After renormalizing the nonlinearity, we construct the random Gibbs measure as an absolutely continuous measure with respect to the law of the Anderson Gaussian Free Field for fixed realization of the spatial white noise. Then, when the initial data is distributed according to the Gibbs measure, we prove almost sure global well-posedness for the dynamics and invariance of the Gibbs measure.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12742"
    },
    {
        "doc_id": 457,
        "title": "Polynomial representation of TU-games",
        "authors": [
            "Ulrich Faigle",
            "Michel Grabisch"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We propose in this paper a polynomial representation of TU-games, fuzzy measures, capacities, and more generally set functions. Our representation needs a countably infinite set of players and the natural ordering of finite sets of $\\mathbb{N}$, defined recursively. For a given basis of the vector space of games, we associate to each game $v$ a formal polynomial of degree at most $2^n-1$ whose coefficients are the coordinates of $v$ in the given basis. By the fundamental theorem of algebra, $v$ can be represented by the roots of the polynomial. We present some new families of games stemming from this polynomial context, like the irreducible games, the multiplicative games and the cyclotomic games.",
        "comments": "MSC Class:          12D99; 91A12",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12741"
    },
    {
        "doc_id": 458,
        "title": "Controlling the C3 super class linearization algorithm",
        "authors": [
            "Florent Hivert",
            "Nicolas M. Thi\u00e9ry"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "C3 is an algorithm used by several widely used programming languages such as Python to support multiple inheritance in object oriented programming (OOP): for each class, C3 computes recursively a linear extension of the poset of all its super classes (the Method Resolution Order, MRO) from user-provided local information (an ordering of the direct super classes). This algorithm can fail if the local information is not consistent.\n  For large hierarchies of classes, as encountered when modeling hierarchies of concepts from abstract algebra in the SageMath computational system, maintaining consistent local information by hand does not scale and leads to unpredictable C3 failures.\n  This paper reports on the authors' work to analyze and circumvent this maintenance nightmare. First, we discovered through extensive computer exploration that there exists posets admitting no consistent local information; we exhibit the smallest one which has 10 elements. Then, we provide and analyze an algorithm that, given a poset and a linear extension, automatically builds local information for C3 in such a way that guarantees that it will never fail, at the price of a slight relaxation of the hypotheses. This algorithm has been used in production in SageMath since 2013.",
        "comments": "15 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12740"
    },
    {
        "doc_id": 459,
        "title": "Invariants cohomologiques mod 2 et invariants de Witt des groupes altern\u00e9s",
        "authors": [
            "Jean-Pierre Serre"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "We determine the cohomological invariants and the Witt invariants of the alternating group $A_n$.",
        "comments": "in French",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12738"
    },
    {
        "doc_id": 460,
        "title": "The algebraic degree of the Wasserstein distance",
        "authors": [
            "Chiara Meroni",
            "Bernhard Reinke",
            "Kexin Wang"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Group Theory"
        ],
        "abstract": "Given two rational univariate polynomials, the Wasserstein distance of their associated measures is an algebraic number. We determine the algebraic degree of the squared Wasserstein distance, serving as a measure of algebraic complexity of the corresponding optimization problem. The computation relies on the structure of a subpolytope of the Birkhoff polytope, invariant under a transformation induced by complex conjugation.",
        "comments": "17 pages, 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12735"
    },
    {
        "doc_id": 461,
        "title": "On the improved convergence of lifted distributional Gauss curvature from Regge elements",
        "authors": [
            "Jay Gopalakrishnan",
            "Michael Neunteufel",
            "Joachim Sch\u00f6berl",
            "Max Wardetzky"
        ],
        "subjects": [
            "Numerical Analysis",
            "Differential Geometry"
        ],
        "abstract": "Although Regge finite element functions are not continuous, useful generalizations of nonlinear derivatives like the curvature, can be defined using them. This paper is devoted to studying the convergence of the finite element lifting of a generalized (distributional) Gauss curvature defined using a metric tensor in the Regge finite element space. Specifically, we investigate the interplay between the polynomial degree of the curvature lifting by Lagrange elements and the degree of the metric tensor in the Regge finite element space. Previously, a superconvergence result, where convergence rate of one order higher than expected, was obtained when the metric is the canonical Regge interpolant of the exact metric. In this work, we show that an even higher order can be obtained if the degree of the curvature lifting is reduced by one polynomial degre and if at least linear Regge elements are used. These improved convergence rates are confirmed by numerical examples.",
        "comments": "MSC Class:          65N30 (Primary) 53A70; 83C27 (Secondary)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12734"
    },
    {
        "doc_id": 462,
        "title": "On A Proof of the ADKMV Conjecture",
        "authors": [
            "Zhiyuan Wang",
            "Chenglang Yang",
            "Jian Zhou"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Algebraic Geometry",
            "Exactly Solvable and Integrable Systems"
        ],
        "abstract": "We present a mathematical proof of a conjectural formula due to Aganagic, Dijkgraaf, Klemm, Mari\u00f1o and Vafa, expressing the topological vertex as a Bogoliubov transform of the fermionic vacuum. In our proof we introduce a boson-fermionic field assignment which generalizes the well-known boson-fermion correspondence. The proof also works for the generalization to the framed topological vertex made by Deng and Zhou. As a consequence, partition functions of toric Calabi-Yau threefolds are related to tau-functions of multi-component KP hierarchy.",
        "comments": "36 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12726"
    },
    {
        "doc_id": 463,
        "title": "Wasserstein Diffusion on Multidimensional Spaces",
        "authors": [
            "Karl-Theodor Sturm"
        ],
        "subjects": [
            "Probability",
            "Functional Analysis",
            "Metric Geometry"
        ],
        "abstract": "Given any closed Riemannian manifold $M$, we construct a reversible diffusion process on the space ${\\mathcal P}(M)$ of probability measures on $M$ that is\n  (i) reversible w.r.t.~the entropic measure ${\\mathbb P}^\u03b2$ on ${\\mathcal P}(M)$, heuristically given as $$d\\mathbb{P}^\u03b2(\u03bc)=\\frac{1}{Z} e^{-\u03b2\\, \\text{Ent}(\u03bc| m)}\\ d\\mathbb{P}^*(\u03bc);$$ (ii) associated with a regular Dirichlet form with carr\u00e9 du champ derived from the Wasserstein gradient in the sense of Otto calculus $${\\mathcal E}_W(f)=\\liminf_{g\\to f}\\ \\frac12\\int_{{\\mathcal P}(M)} \\big\\|\\nabla_W g\\big\\|^2(\u03bc)\\ d{\\mathbb P}^\u03b2(\u03bc);$$ (iii) non-degenerate, at least in the case of the $n$-sphere and the $n$-torus.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12721"
    },
    {
        "doc_id": 464,
        "title": "$n$-valued Coset Groups and Dynamics",
        "authors": [
            "Mikhail Kornev"
        ],
        "subjects": [
            "Group Theory",
            "Combinatorics",
            "Dynamical Systems"
        ],
        "abstract": "We obtain asymptotic and exact formulae of growth functions for some families of $n$-valued coset groups. We also describe connections between the theory of $n$-valued groups and Symbolic Dynamics.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12718"
    },
    {
        "doc_id": 465,
        "title": "On positively divisible non-Markovian processes",
        "authors": [
            "Bilal Canturk",
            "Heinz-Peter Breuer"
        ],
        "subjects": [
            "Probability",
            "Mathematical Physics"
        ],
        "abstract": "There are some positively divisible non-Markovian processes whose transition matrices satisfy the Chapman-Kolmogorov equation. These processes should also satisfy the Kolmogorov consistency conditions, an essential requirement for a process to be classified as a stochastic process. Combining the Kolmogorov consistency conditions with the Chapman-Kolmogorov equation, we derive a necessary condition for positively divisible stochastic processes on a finite sample space. This necessary condition enables a systematic approach to the manipulation of certain Markov processes in order to obtain a positively divisible non-Markovian process. We illustrate this idea by an example and, in addition, analyze a classic example given by Feller in the light of our approach.",
        "comments": "14 pages, 1 figure",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12715"
    },
    {
        "doc_id": 466,
        "title": "Moutard hyperquadrics and generalized Darboux directions",
        "authors": [
            "Fernanda Py Silva Cordeiro",
            "Marcos Craizer"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "For a fixed point of a non-degenerate surface in 3-space, there are three directions in its tangent plane such that the third order contact of a quadric in the Moutard pencil in these directions with the surface is a perfect cube. These directions are called Darboux directions and they coincide with the zeros of the cubic form at the point. In this paper, we extend this result to non-degenerate hypersurfaces.",
        "comments": "9 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12712"
    },
    {
        "doc_id": 467,
        "title": "Quandles as pre-Lie skew braces, set-theoretic Hopf algebras & universal R-matrices",
        "authors": [
            "Anastasia Doikou",
            "Bernard Rybolowicz",
            "Paola Stefanelli"
        ],
        "subjects": [
            "Quantum Algebra",
            "Mathematical Physics",
            "Rings and Algebras"
        ],
        "abstract": "We present connections between left non-degenerate solutions of set-theoretic Yang-Baxter equation and left shelves using certain maps called Drinfel'd homomorphisms. We further generalise the notion of affine quandle, by using heap endomorphisms and metahomomorphisms, and identify the Yang-Baxter algebra for solutions of the braid equation associated to a given quandle. We introduce the notion of the pre-Lie skew brace and identify certain affine quandles that give rise to pre-Lie skew braces. Generalisations of the braiding of a group, associated to set-theoretic solutions of the braid equation is also presented. These generalized structures encode part of the underlying Hopf algebra. Indeed, we also introduce the quasi-triangular Hopf algebras and the universal R-matrices for quandle algebras and for set-theoretic Yang-Baxter algebras. In fact, we obtain the universal R-matrix for the set-theoretic Yang-Baxter algebras after identifying the associated admissible Drinfel'd twist. Generic set-theoretic solutions coming from heap endomorphisms are also identified.",
        "comments": "36 pages LaTex",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12704"
    },
    {
        "doc_id": 468,
        "title": "Heaps of pieces for lattice paths",
        "authors": [
            "Keiichi Shigechi"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We study heaps of pieces for lattice paths, which give a combinatorial visualization of lattice paths. We introduce two types of heaps: type $I$ and type $II$. A heap of type $I$ is characterized by peaks of a lattice path. We have a duality between a lattice path $\u03bc$ and its dual $\\overline\u03bc$ on heaps of type $I$. A heap of type $II$ for $\u03bc$ is characterized by the skew shape between the lowest path and $\u03bc$. We give a determinant expression for the generating function of heaps for general lattice paths, and an explicit formula for rational $(1,k)$-Dyck paths by using the inversion lemma. We introduce and study heaps in $k+1$-dimensions which are bijective to heaps of type $II$ for $(1,k)$-Dyck paths. Further, we show a bijective correspondence between type $I$ and type $II$ in the case of rational $(1,k)$-Dyck paths. As another application of heaps, we give two explicit formulae for the generating function of heaps for symmetric Dyck paths in terms of statistics on Dyck paths and on symmetric Dyck paths respectively.",
        "comments": "31 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12701"
    },
    {
        "doc_id": 469,
        "title": "Pragmatic Communication in Multi-Agent Collaborative Perception",
        "authors": [
            "Yue Hu",
            "Xianghe Pang",
            "Xiaoqi Qin",
            "Yonina C. Eldar",
            "Siheng Chen",
            "Ping Zhang",
            "Wenjun Zhang"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Collaborative perception allows each agent to enhance its perceptual abilities by exchanging messages with others. It inherently results in a trade-off between perception ability and communication costs. Previous works transmit complete full-frame high-dimensional feature maps among agents, resulting in substantial communication costs. To promote communication efficiency, we propose only transmitting the information needed for the collaborator's downstream task. This pragmatic communication strategy focuses on three key aspects: i) pragmatic message selection, which selects task-critical parts from the complete data, resulting in spatially and temporally sparse feature vectors; ii) pragmatic message representation, which achieves pragmatic approximation of high-dimensional feature vectors with a task-adaptive dictionary, enabling communicating with integer indices; iii) pragmatic collaborator selection, which identifies beneficial collaborators, pruning unnecessary communication links. Following this strategy, we first formulate a mathematical optimization framework for the perception-communication trade-off and then propose PragComm, a multi-agent collaborative perception system with two key components: i) single-agent detection and tracking and ii) pragmatic collaboration. The proposed PragComm promotes pragmatic communication and adapts to a wide range of communication conditions. We evaluate PragComm for both collaborative 3D object detection and tracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V and V2X-SIM2.0. PragComm consistently outperforms previous methods with more than 32.7K times lower communication volume on OPV2V. Code is available at github.com/PhyllisH/PragComm.",
        "comments": "18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12694"
    },
    {
        "doc_id": 470,
        "title": "Random Riemannian Geometry in 4 Dimensions",
        "authors": [
            "Karl-Theodor Sturm"
        ],
        "subjects": [
            "Probability",
            "Differential Geometry",
            "Metric Geometry"
        ],
        "abstract": "We construct and analyze conformally invariant random fields on 4-dimensional Riemannian manifolds $(M,g)$. These centered Gaussian fields $h$, called \\emph{co-biharmonic Gaussian fields}, are characterized by their covariance kernels $k$ defined as the integral kernel for the inverse of the \\emph{Paneitz operator} \\begin{equation*}\\mathsf p=\\frac1{8\u03c0^2}\\bigg[\u0394^2+\n  \\mathsf{div}\\left(2\\mathsf{Ric}-\\frac23\\mathsf{scal}\\right)\\nabla \\bigg]. \\end{equation*} The kernel $k$ is invariant (modulo additive corrections) under conformal transformations, and it exhibits a precise logarithmic divergence $$\\Big|k(x,y)-\\log\\frac1{d(x,y)}\\Big|\\le C.$$ In terms of the co-biharmonic Gaussian field $h$, we define the \\emph{quantum Liouville measure}, a random measure on $M$, heuristically given as \\begin{equation*}\n  d\u03bc(x):= e^{\u03b3h(x)-\\frac{\u03b3^2}2k(x,x)}\\,d \\text{vol}_g(x)\\,, \\end{equation*} and rigorously obtained a.s.~for $|\u03b3|<\\sqrt8$ as weak limit of the RHS with $h$ replaced by suitable regular approximations $(h_\\ell)_{\\ell\\in\\mathbb N}$.\n  For the flat torus $M=\\mathbb T^4$, we provide discrete approximations of the Gaussian field and of the Liouville measures in terms of semi-discrete random objects, based on Gaussian random variables on the discrete torus and piecewise constant functions in the isotropic Haar system.",
        "comments": "MSC Class:          60G15; 58J65; 31C25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12676"
    },
    {
        "doc_id": 471,
        "title": "Analysis of a combined Filtered/phase-field approach to topology optimization in elasticit",
        "authors": [
            "Ferdinando Auricchio",
            "Michele Marino",
            "Idriss Mazari",
            "Ulisse Stefanelli"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "We advance a combined filtered/phase-field approach to topology optimization in the setting of linearized elasticity. Existence of minimizers is proved and rigorous parameter asymptotics are discussed by means of variational convergence techniques. Moreover, we investigate an abstract space discretization in the spirit of conformal finite elements. Eventually, stationarity is equivalently reformulated in terms of a Lagrangian.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12675"
    },
    {
        "doc_id": 472,
        "title": "\u03bb-Cent-Dians and Generalized-Center for Network Design",
        "authors": [
            "V\u00edctor Bucarey",
            "Natividad Gonz\u00e1lez-Blanco",
            "Martine Labb\u00e9",
            "Juan A. Mesa"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "In this paper, we extend the notions of $\u03bb$-cent-dian and generalized-center from Facility Location Theory to the more intricate domain of Network Design. Our focus is on the task of designing a sub-network within a given underlying network while adhering to a budget constraint. This sub-network is intended to efficiently serve a collection of origin/destination pairs of demand. % rather than individual points.\n  The $\u03bb$-cent-dian problem studies the balance between efficiency and equity. We investigate the properties of the $\u03bb$-cent-dian and generalized-center solution networks under the lens of equity, efficiency, and Pareto-optimality. We provide a mathematical formulation for $\u03bb\\geq 0$ and discuss the bilevel structure of this problem for $\u03bb>1$. Furthermore, we describe a procedure to obtain a complete parametrization of the Pareto-optimality set based on solving two mixed integer linear formulations by introducing the concept of maximum $\u03bb$-cent-dian. We evaluate the quality of the different solution concepts using some inequality measures. Finally, for $\u03bb\\in[0,1]$, we study the implementation of a Benders decomposition method to solve it at scale.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12673"
    },
    {
        "doc_id": 473,
        "title": "Highly connected orientations from edge-disjoint rigid subgraphs",
        "authors": [
            "D\u00e1niel Garamv\u00f6lgyi",
            "Tibor Jord\u00e1n",
            "Csaba Kir\u00e1ly",
            "Soma Vill\u00e1nyi"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We give an affirmative answer to a long-standing conjecture of Thomassen, stating that every sufficiently highly connected graph has a $k$-vertex-connected orientation. We prove that a connectivity of order $O(k^5)$ suffices. As a key tool, we show that for every pair of positive integers $d$ and $t$, every $(t \\cdot h(d))$-connected graph contains $t$ edge-disjoint $d$-rigid (in particular, $d$-connected) spanning subgraphs, where $h(d) = 10d(d+1)$. This also implies a positive answer to the conjecture of Kriesell that every sufficiently highly connected graph $G$ contains a spanning tree $T$ such that $G-E(T)$ is $k$-connected.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12670"
    },
    {
        "doc_id": 474,
        "title": "EL-VIT: Probing Vision Transformer with Interactive Visualization",
        "authors": [
            "Hong Zhou",
            "Rui Zhang",
            "Peifeng Lai",
            "Chaoran Guo",
            "Yong Wang",
            "Zhida Sun",
            "Junjie Li"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Nowadays, Vision Transformer (ViT) is widely utilized in various computer vision tasks, owing to its unique self-attention mechanism. However, the model architecture of ViT is complex and often challenging to comprehend, leading to a steep learning curve. ViT developers and users frequently encounter difficulties in interpreting its inner workings. Therefore, a visualization system is needed to assist ViT users in understanding its functionality. This paper introduces EL-VIT, an interactive visual analytics system designed to probe the Vision Transformer and facilitate a better understanding of its operations. The system consists of four layers of visualization views. The first three layers include model overview, knowledge background graph, and model detail view. These three layers elucidate the operation process of ViT from three perspectives: the overall model architecture, detailed explanation, and mathematical operations, enabling users to understand the underlying principles and the transition process between layers. The fourth interpretation view helps ViT users and experts gain a deeper understanding by calculating the cosine similarity between patches. Our two usage scenarios demonstrate the effectiveness and usability of EL-VIT in helping ViT users understand the working mechanism of ViT.",
        "comments": "10 pages, 7 figures, conference",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12666"
    },
    {
        "doc_id": 475,
        "title": "Polynomial and rational interpolation: potential, barycentric weights, and Lebesgue constants",
        "authors": [
            "Kelong Zhao",
            "Shuhuang Xiang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this paper, we focus on barycentric weights and Lebesgue constants for Lagrange interpolation of arbitrary node distributions on \\([-1,1]\\). The following three main works are included: estimates of upper and lower bounds on the barycentric weights are given in terms of the logarithmic potential function; for interpolation of non-equilibrium potentials, lower bounds with exponentially growing parts of Lebesgue constants are given; and for interpolation consistent with equilibrium potentials, non-exponentially growing upper bounds on their Lebesgue constants are given. Based on the work in this paper, we can discuss the behavior of the Lebesgue constant and the existence of exponential convergence in a unified manner in the framework of potential theory.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12664"
    },
    {
        "doc_id": 476,
        "title": "Global existence for long wave Hopf unstable spatially extended systems with a conservation law",
        "authors": [
            "Nicole Gauss",
            "Anna Logioti",
            "Guido Schneider",
            "Dominik Zimmermann"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "We are interested in reaction-diffusion systems, with a conservation law, exhibiting a Hopf bifurcation at the spatial wave number $k = 0$. With the help of a multiple scaling perturbation ansatz a Ginzburg-Landau equation coupled to a scalar conservation law can be derived as an amplitude system for the approximate description of the dynamics of the original reaction-diffusion system near the first instability. We use the amplitude system to show the global existence of all solutions starting in a small neighborhood of the weakly unstable ground state for original systems posed on a large spatial interval with periodic boundary conditions.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12660"
    },
    {
        "doc_id": 477,
        "title": "Cokernel statistics for walk matrices of directed and weighted random graphs",
        "authors": [
            "Alexander Van Werde"
        ],
        "subjects": [
            "Combinatorics",
            "Probability"
        ],
        "abstract": "The walk matrix associated to an $n\\times n$ integer matrix $X$ and an integer vector $b$ is defined by $W := (b,X b, . . . ,X^{n-1} b)$. We study limiting laws for the cokernel of $W$ in the scenario where $X$ is a random matrix with independent entries and $b$ is deterministic. Our first main result provides a formula for the distribution of the $p^{m}$-torsion part of the cokernel, as a group, when $X$ has independent entries from a specific distribution. The second main result relaxes the distributional assumption and concerns the $\\mathbb{Z}[x]$-module structure.\n  The motivation for this work arises from an open problem in spectral graph theory which asks to show that random graphs are often determined up to isomorphism by their (generalized) spectrum. Sufficient conditions for generalized spectral determinacy can namely be stated in terms of the cokernel of a walk matrix. Extensions of our results could potentially be used to determine how often those conditions are satisfied. Some remaining challenges for such extensions are outlined in the paper",
        "comments": "19 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12655"
    },
    {
        "doc_id": 478,
        "title": "Mock Alexander Polynomials",
        "authors": [
            "Neslihan G\u00fcg\u00fcmc\u00fc",
            "Louis H. Kauffman"
        ],
        "subjects": [
            "Geometric Topology",
            "Combinatorics"
        ],
        "abstract": "In this paper, we construct mock Alexander polynomials for starred links and linkoids in surfaces. These polynomials are defined as specific sums over states of link or linkoid diagrams that satisfy $f=n$, where $f$ denotes the number of regions and $n$ denotes the number of crossings of diagrams.",
        "comments": "MSC Class:          57M25; 57M20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12654"
    },
    {
        "doc_id": 479,
        "title": "Geometry of Mechanics",
        "authors": [
            "Miguel C. Mu\u00f1oz-Lecanda",
            "Narciso Rom\u00e1n-Roy"
        ],
        "subjects": [
            "Mathematical Physics",
            "High Energy Physics - Theory",
            "Differential Geometry"
        ],
        "abstract": "We study the geometry underlying mechanics and its application to describe autonomous and nonautonomous conservative dynamical systems of different types; as well as dissipative dynamical systems. We use different geometric descriptions to study the main properties and characteristics of these systems; such as their Lagrangian, Hamiltonian and unified formalisms, their symmetries, the variational principles, and others. The study is done mainly for the regular case, although some comments and explanations about singular systems are also included.",
        "comments": "237 pages. This is a draft version of a future book. Comments are welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12650"
    },
    {
        "doc_id": 480,
        "title": "Space-time unfitted finite elements on moving explicit geometry representations",
        "authors": [
            "Santiago Badia",
            "Pere A. Martorell",
            "Francesc Verdugo"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Numerical Analysis"
        ],
        "abstract": "This work proposes a novel variational approximation of partial differential equations on moving geometries determined by explicit boundary representations. The benefits of the proposed formulation are the ability to handle large displacements of explicitly represented domain boundaries without generating body-fitted meshes and remeshing techniques. For the space discretization, we use a background mesh and an unfitted method that relies on integration on cut cells only. We perform this intersection by using clipping algorithms. To deal with the mesh movement, we pullback the equations to a reference configuration (the spatial mesh at the initial time slab times the time interval) that is constant in time. This way, the geometrical intersection algorithm is only required in 3D, another key property of the proposed scheme. At the end of the time slab, we compute the deformed mesh, intersect the deformed boundary with the background mesh, and consider an exact transfer operator between meshes to compute jump terms in the time discontinuous Galerkin integration. The transfer is also computed using geometrical intersection algorithms. We demonstrate the applicability of the method to fluid problems around rotating (2D and 3D) geometries described by oriented boundary meshes. We also provide a set of numerical experiments that show the optimal convergence of the method.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12649"
    },
    {
        "doc_id": 481,
        "title": "Sequential discontinuity and first-order problems",
        "authors": [
            "Arno Pauly",
            "Giovanni Sold\u00e0"
        ],
        "subjects": [
            "Logic",
            "Logic in Computer Science",
            "General Topology"
        ],
        "abstract": "We explore the low levels of the structure of the continuous Weihrauch degrees of first-order problems. In particular, we show that there exists a minimal discontinuous first-order degree, namely that of $\\accn$, without any determinacy assumptions. The same degree is also revealed as the least sequentially discontinuous one, i.e. the least degree with a representative whose restriction to some sequence converging to a limit point is still discontinuous.\n  The study of games related to continuous Weihrauch reducibility constitutes an important ingredient in the proof of the main theorem. We present some initial additional results about the degrees of first-order problems that can be obtained using this approach.",
        "comments": "MSC Class:          03D78; 03D30; 54H05",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12641"
    },
    {
        "doc_id": 482,
        "title": "On The Axioms Of $\\mathcal{M},\\mathcal{N}$-Adhesive Categories",
        "authors": [
            "Davide Castelnovo",
            "Marino Miculan"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Category Theory"
        ],
        "abstract": "Adhesive and quasiadhesive categories provide a general framework for the study of algebraic graph rewriting systems. In a quasiadhesive category any two regular subobjects have a join which is again a regular subobject. Vice versa, if regular monos are adhesive, then the existence of a regular join for any pair of regular subobjects entails quasiadhesivity. It is also known (quasi)adhesive categories can be embedded in a Grothendieck topos via a functor preserving pullbacks and pushouts along (regular) monomorphisms. In this paper we extend these results to $\\mathcal{M}, \\mathcal{N}$-adhesive categories, a concept recently introduced to generalize the notion of (quasi)adhesivity. We introduce the notion of $\\mathcal{N}$-adhesive morphism, which allows us to express $\\mathcal{M}, \\mathcal{N}$-adhesivity as a condition on the subobjects's posets. Moreover, $\\mathcal{N}$-adhesive morphisms allows us to show how an $\\mathcal{M},\\mathcal{N}$-adhesive category can be embedded into a Grothendieck topos, preserving pullbacks and $\\mathcal{M}, \\mathcal{N}$-pushouts.",
        "comments": "ACM Class:          F.4.1",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12638"
    },
    {
        "doc_id": 483,
        "title": "Spectra and pseudo-spectra of tridiagonal $k$-Toeplitz matrices and the topological origin of the non-Hermitian skin effect",
        "authors": [
            "Habib Ammari",
            "Silvio Barandun",
            "Yannick De Bruijn",
            "Ping Liu",
            "Clemens Thalhammer"
        ],
        "subjects": [
            "Mathematical Physics",
            "Materials Science",
            "Rings and Algebras",
            "Optics"
        ],
        "abstract": "We establish new results on the spectra and pseudo-spectra of tridiagonal $k$-Toeplitz operators and matrices. In particular, we prove the connection between the winding number of the eigenvalues of the symbol function and the exponential decay of the associated eigenvectors (or pseudo-eigenvectors). Our results elucidate the topological origin of the non-Hermitian skin effect in general one-dimensional polymer systems of subwavelength resonators with imaginary gauge potentials, proving the observation and conjecture in arXiv:2307.13551. We also numerically verify our theory for these systems.",
        "comments": "18 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12626"
    },
    {
        "doc_id": 484,
        "title": "Benders decomposition for congested partial set covering location with uncertain demand",
        "authors": [
            "Alice Calamita",
            "Ivana Ljubi\u0107",
            "Laura Palagi"
        ],
        "subjects": [
            "Optimization and Control",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper, we introduce a mixed integer quadratic formulation for the congested variant of the partial set covering location problem, which involves determining a subset of facility locations to open and efficiently allocating customers to these facilities to minimize the combined costs of facility opening and congestion while ensuring target coverage. To enhance the resilience of the solution against demand fluctuations, we address the case under uncertain customer demand using $\u0393$-robustness. We formulate the deterministic problem and its robust counterpart as mixed-integer quadratic problems. We investigate the effect of the protection level in adapted instances from the literature to provide critical insights into how sensitive the planning is to the protection level. Moreover, since the size of the robust counterpart grows with the number of customers, which could be significant in real-world contexts, we propose the use of Benders decomposition to effectively reduce the number of variables by projecting out of the master problem all the variables dependent on the number of customers. We illustrate how to incorporate our Benders approach within a mixed-integer second-order cone programming (MISOCP) solver, addressing explicitly all the ingredients that are instrumental for its success. We discuss single-tree and multi-tree approaches and introduce a perturbation technique to deal with the degeneracy of the Benders subproblem efficiently. Our tailored Benders approaches outperform the perspective reformulation solved using the state-of-the-art MISOCP solver Gurobi on adapted instances from the literature.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12625"
    },
    {
        "doc_id": 485,
        "title": "A Unifying System Theory Framework for Distributed Optimization and Games",
        "authors": [
            "Guido Carnevale",
            "Nicola Mimmo",
            "Giuseppe Notarstefano"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This paper introduces a systematic methodological framework to design and analyze distributed algorithms for optimization and games over networks. Starting from a centralized method, we identify an aggregation function involving all the decision variables (e.g., a global cost gradient or constraint) and design a distributed consensus-oriented dynamics to asymptotically approximate the unavailable information at each agent. Then, we delineate the proper methodology for intertwining the identified building blocks, i.e., the optimization-oriented method and the consensus-oriented one. The key intuition is to interpret the obtained interconnection as a singularly perturbed system. We rely on this interpretation to provide sufficient conditions for the building blocks to be successfully connected into a distributed scheme exhibiting the convergence guarantees of the centralized algorithm. Finally, we show the potential of our approach by developing a new distributed scheme with linear rate for constraint-coupled problems.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12623"
    },
    {
        "doc_id": 486,
        "title": "Characteristic polynomials of isometries of even unimodular lattices",
        "authors": [
            "Yuta Takada"
        ],
        "subjects": [
            "Number Theory",
            "Algebraic Geometry"
        ],
        "abstract": "E. Bayer-Fluckiger gave a necessary and sufficient condition for a polynomial to be realized as the characteristic polynomial of a semisimple isometry of an even unimodular lattice, by describing the local-global obstruction, and the author extended the result. This article presents a systematic way to compute the obstruction. As an application, we give a necessary and sufficient condition for a Salem number of degree $10$ or $18$ to be realized as the dynamical degree of an automorphism of nonprojective K3 surface, in terms of its minimal polynomial.",
        "comments": "MSC Class:          11H56; 14J28",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12620"
    },
    {
        "doc_id": 487,
        "title": "Sum of two squares in biquadratic fields",
        "authors": [
            "Wenhuan Huang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "This paper gives an algorithm to determine whether a number in a biquadratic field is a sum of two squares, based on local-global principle of isotropy of quadratic forms.",
        "comments": "4 pages. Suggestions for improvement are welcomed",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12619"
    },
    {
        "doc_id": 488,
        "title": "Computation of classical and $v$-adic $L$-series of $t$-motives",
        "authors": [
            "Xavier Caruso",
            "Quentin Gazda"
        ],
        "subjects": [
            "Symbolic Computation",
            "Number Theory"
        ],
        "abstract": "We design an algorithm for computing the $L$-series associated to an Anderson $t$-motives, exhibiting quasilinear complexity with respect to the target precision. Based on experiments, we conjecture that the order of vanishing at $T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good reduction does not depend on the finite place $v$.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12618"
    },
    {
        "doc_id": 489,
        "title": "On the hardness of deciding the finite convergence of Lasserre hierarchies",
        "authors": [
            "Luis Felipe Vargas"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "A polynomial optimization problem (POP) asks for minimizing a polynomial function given a finite set of polynomial constraints (equations and inequalities). This problem is well-known to be hard in general, as it encodes many hard combinatorial problems. The Lasserre hierarchy is a sequence of semidefinite relaxations for solving (POP). Under the standard archimedean condition, this hierarchy is guaranteed to converge asymptotically to the optimal value of (POP) (Lasserre, 2001) and, moreover, finite convergence holds generically (Nie, 2012). In this paper, we aim to investigate whether there is an efficient algorithmic procedure to decide whether the Lasserre hierarchy of (POP) has finite convergence. We show that unless P=NP there cannot exist such an algorithmic procedure that runs in polynomial time. We show this already for the standard quadratic programs. Our approach relies on characterizing when finite convergence holds for the so-called Motzkin-Straus formulation (and some variations of it) for the stability number of a graph.",
        "comments": "MSC Class:          90C23; 90c20; 68Q17; 11E25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12613"
    },
    {
        "doc_id": 490,
        "title": "The twin peaks of learning neural networks",
        "authors": [
            "Elizaveta Demyanenko",
            "Christoph Feinauer",
            "Enrico M. Malatesta",
            "Luca Saglietti"
        ],
        "subjects": [
            "Machine Learning",
            "Disordered Systems and Neural Networks",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "Recent works demonstrated the existence of a double-descent phenomenon for the generalization error of neural networks, where highly overparameterized models escape overfitting and achieve good test performance, at odds with the standard bias-variance trade-off described by statistical learning theory. In the present work, we explore a link between this phenomenon and the increase of complexity and sensitivity of the function represented by neural networks. In particular, we study the Boolean mean dimension (BMD), a metric developed in the context of Boolean function analysis. Focusing on a simple teacher-student setting for the random feature model, we derive a theoretical analysis based on the replica method that yields an interpretable expression for the BMD, in the high dimensional regime where the number of data points, the number of features, and the input size grow to infinity. We find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak, and then slowly approaches a low asymptotic value. The same phenomenology is then traced in numerical experiments with different model classes and training setups. Moreover, we find empirically that adversarially initialized models tend to show higher BMD values, and that models that are more robust to adversarial attacks exhibit a lower BMD.",
        "comments": "36 pages, 30 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12610"
    },
    {
        "doc_id": 491,
        "title": "Dispersive estimates for wave and Schr\u00f6dinger equations with a potential in non-trapping exterior domains",
        "authors": [
            "Thomas Duyckaerts",
            "Jianwei Urban Yang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We prove resolvent estimates for a Schr\u00f6dinger operator with a short-range potential outside an obstacle with Dirichlet boundary conditions. As a consequence, we deduce integrability of the local energy for the wave equation, and smoothing effect for the Schr\u00f6dinger equation. Finally, for both equations, we prove that local Strichartz estimates for the free equation outside an obstacle imply global Strichartz estimates with a short-range potential outside the same obstacle. The estimates are all global in time, after projection on the continuous spectrum of the operator.",
        "comments": "MSC Class:          35L05; 35Q41; 35B65; 35P25",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12608"
    },
    {
        "doc_id": 492,
        "title": "The asymptotic behavior of fraudulent algorithms",
        "authors": [
            "Michel Bena\u00efm",
            "Laurent Miclo"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "Let $U$ be a Morse function on a  compact connected $m$-dimensional Riemannian manifold, $m \\geq 2,$ satisfying $\\min U=0$ and let $\\mathcal{U} = \\{x \\in M \\: : U(x) = 0\\}$ be the set of global minimizers. Consider the stochastic algorithm $X^{(\u03b2)}:=(X^{(\u03b2)}(t))_{t\\geq 0}$ defined on $N = M \\setminus \\mathcal{U},$  whose generator is$U \u0394\\cdot-\u03b2\\langle \\nabla U,\\nabla \\cdot\\rangle$, where $\u03b2\\in\\RR$ is a real parameter.We show that for $\u03b2>\\frac{m}{2}-1,$ $X^{(\u03b2)}(t)$ converges a.s.\\ as $t \\rightarrow   \\infty$, toward a point $p \\in \\mathcal{U}$ and that each  $p \\in \\mathcal{U}$  has a positive probability to be selected. On the other hand, for $\u03b2<  \\frac{m}{2}-1,$ the law of $(X^{(\u03b2)}(t))$ converges in total variation (at an exponential rate) toward the probability measure  $\u03c0_\u03b2$ having density proportional to  $U(x)^{-1-\u03b2}$ with respect to the Riemannian measure.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12605"
    },
    {
        "doc_id": 493,
        "title": "A coupling concept for Stokes-Darcy systems: the ICDD method",
        "authors": [
            "Marco Discacciati",
            "Paola Gervasio"
        ],
        "subjects": [
            "Numerical Analysis",
            "Fluid Dynamics"
        ],
        "abstract": "We present a coupling framework for Stokes-Darcy systems valid for arbitrary flow direction at low Reynolds numbers and for isotropic porous media. The proposed method is based on an overlapping domain decomposition concept to represent the transition region between the free-fluid and the porous-medium regimes. Matching conditions at the interfaces of the decomposition impose the continuity of velocity (on one interface) and pressure (on the other one) and the resulting algorithm can be easily implemented in a non-intrusive way. The numerical approximations of the fluid velocity and pressure obtained by the studied method converge to the corresponding counterparts computed by direct numerical simulation at the microscale, with convergence rates equal to suitable powers of the scale separation parameter $\\varepsilon$ in agreement with classical results in homogenization.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12602"
    },
    {
        "doc_id": 494,
        "title": "Asymptotic confidence interval for R2 in multiple linear regression",
        "authors": [
            "J Dedecker",
            "O Guedj",
            "M L Taupin"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Following White's approach of robust multiple linear regression, we give asymptotic confidence intervals for the multiple correlation coefficient R2 under minimal moment conditions. We also give the asymptotic joint distribution of the empirical estimators of the individual R2's. Through different sets of simulations, we show that the procedure is indeed robust (contrary to the procedure involving the near exact distribution of the empirical estimator of R2 is the multivariate Gaussian case) and can be also applied to count linear regression.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12598"
    },
    {
        "doc_id": 495,
        "title": "Superconvergent postprocessing of $C^0$ interior penalty method",
        "authors": [
            "Ying Cai",
            "Hailong Guo",
            "Zhimin Zhang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "This paper focuses on the superconvergence analysis of the Hessian recovery technique for the $C^0$ Interior Penalty Method (C0IP) in solving the biharmonic equation. We establish interior error estimates for C0IP method that serve as the superconvergent analysis tool. Using the argument of superconvergence by difference quotient, we prove superconvergent results of the recovered Hessian matrix on translation-invariant meshes. The Hessian recovery technique enables us to construct an asymptotically exact ${\\it a\\, posteriori}$ error estimator for the C0IP method. Numerical experiments are provided to support our theoretical results.",
        "comments": "MSC Class:          65N30; 65N25; 65N15; 65N50",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12589"
    },
    {
        "doc_id": 496,
        "title": "Center stable manifolds for the radial semi-linear wave equation outside a ball",
        "authors": [
            "Thomas Duyckaerts",
            "Jianwei Urban Yang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider the nonlinear wave equation, with a large exponent, power-like non-linearity, outside a ball of the Euclidean 3-dimensional space. In a previous article, we have proved that any global solution converges, up to a radiation term, to a stationary solution of the equation. In this work, we construct the center-stable manifold associated to each of the stationary solution, giving a complete description of the dynamics of global solutions. We also study the behavior of solutions close to each of the center-stable manifold.",
        "comments": "MSC Class:          35L05; 35A01; 35B40; 35B44; 37K40",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12581"
    },
    {
        "doc_id": 497,
        "title": "Chow ring of moduli spaces of quasi-polarised K3 surfaces in lower genus",
        "authors": [
            "Fei Si"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "In the paper, we show the Chow ring of moduli spaces of quasi-polarised K3 surfaces in lower genus ($\\le 5$) is tautological.",
        "comments": "16 pages. Comments are very welcome",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12580"
    },
    {
        "doc_id": 498,
        "title": "On polynomial images of a closed ball",
        "authors": [
            "Jos\u00e9 F. Fernando",
            "Carlos Ueno"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "In this work we approach the problem of determining which (compact) semialgebraic subsets of ${\\mathbb R}^n$ are images under polynomial maps $f:{\\mathbb R}^m\\to{\\mathbb R}^n$ of the closed unit ball $\\overline{\\mathcal B}_m$ centered at the origin of some Euclidean space ${\\mathbb R}^m$ and that of estimating (when possible) which is the smallest $m$ with this property. Contrary to what happens with the images of ${\\mathbb R}^m$ under polynomial maps, it is quite straightforward to provide basic examples of semialgebraic sets that are polynomial images of the closed unit ball. For instance, simplices, cylinders, hypercubes, elliptic, parabolic or hyperbolic segments (of dimension $n$) are polynomial images of the closed unit ball in ${\\mathbb R}^n$.\n  The previous examples (and other basic ones proposed in the article) provide a large family of `$n$-bricks' and we find necessary and sufficient conditions to guarantee that a finite union of `$n$-bricks' is again a polynomial image of the closed unit ball either of dimension $n$ or $n+1$. In this direction, we prove: {\\em A finite union ${\\mathcal S}$ of $n$-dimensional convex polyhedra is the image of the $n$-dimensional closed unit ball $\\overline{\\mathcal B}_n$ if and only if ${\\mathcal S}$ is connected by analytic paths}.\n  The previous result can be generalized using the `$n$-bricks' mentioned before and we show: {\\em If ${\\mathcal S}_1,\\ldots,{\\mathcal S}_\\ell\\subset{\\mathbb R}^n$ are `$n$-bricks', the union ${\\mathcal S}:=\\bigcup_{i=1}^\\ell{\\mathcal S}_i$ is the image of the closed unit ball $\\overline{\\mathcal B}_{n+1}$ of ${\\mathbb R}^{n+1}$ under a polynomial map $f:{\\mathbb R}^{n+1}\\to{\\mathbb R}^n$ if and only if ${\\mathcal S}$ is connected by analytic paths}.",
        "comments": "41 pages, 18 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12579"
    },
    {
        "doc_id": 499,
        "title": "Representation of positive semidefinite elements as sum of squares in 2-dimensional local rings",
        "authors": [
            "Jos\u00e9 F. Fernando"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "A classical problem in real geometry concerns the representation of positive semidefinite elements of a ring $A$ as sums of squares of elements of $A$. If $A$ is an excellent ring of dimension $\\geq3$, it is already known that it contains positive semidefinite elements that cannot be represented as sums of squares in $A$. The one dimensional local case has been afforded by Scheiderer (mainly when its residue field is real closed). In this work we focus on the $2$-dimensional case and determine (under some mild conditions) which local excellent henselian rings $A$ of embedding dimension $3$ have the property that every positive semidefinite element of $A$ is a sum of squares of elements of $A$.",
        "comments": "55 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12572"
    },
    {
        "doc_id": 500,
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "authors": [
            "Hanxue Gu",
            "Roy Colglazier",
            "Haoyu Dong",
            "Jikai Zhang",
            "Yaqian Chen",
            "Zafer Yildiz",
            "Yuwen Chen",
            "Lin Li",
            "Jichen Yang",
            "Jay Willhite",
            "Alex M. Meyer",
            "Brian Guo",
            "Yashvi Atul Shah",
            "Emily Luo",
            "Shipra Rajput",
            "Sally Kuehn",
            "Clark Bulleit",
            "Kevin A. Wu",
            "Jisoo Lee",
            "Brandon Ramirez",
            "Darui Lu",
            "Jay M. Levin",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "comments": "15 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12974"
    },
    {
        "doc_id": 501,
        "title": "Analysis of a detailed multi-stage model of stochastic gene expression using queueing theory and model reduction",
        "authors": [
            "Muhan Ma",
            "Juraj Szavits-Nossan",
            "Abhyudai Singh",
            "Ramon Grima"
        ],
        "subjects": [
            "Molecular Networks",
            "Quantitative Methods",
            "Subcellular Processes"
        ],
        "abstract": "We introduce a biologically detailed, stochastic model of gene expression describing the multiple rate-limiting steps of transcription, nuclear pre-mRNA processing, nuclear mRNA export, cytoplasmic mRNA degradation and translation of mRNA into protein. The processes in sub-cellular compartments are described by an arbitrary number of processing stages, thus accounting for a significantly finer molecular description of gene expression than conventional models such as the telegraph, two-stage and three-stage models of gene expression. We use two distinct tools, queueing theory and model reduction using the slow-scale linear-noise approximation, to derive exact or approximate analytic expressions for the moments or distributions of nuclear mRNA, cytoplasmic mRNA and protein fluctuations, as well as lower bounds for their Fano factors in steady-state conditions. We use these to study the phase diagram of the stochastic model; in particular we derive parametric conditions determining three types of transitions in the properties of mRNA fluctuations: from sub-Poissonian to super-Poissonian noise, from high noise in the nucleus to high noise in the cytoplasm, and from a monotonic increase to a monotonic decrease of the Fano factor with the number of processing stages. In contrast, protein fluctuations are always super-Poissonian and show weak dependence on the number of mRNA processing stages. Our results delineate the region of parameter space where conventional models give qualitatively incorrect results and provide insight into how the number of processing stages, e.g. the number of rate-limiting steps in initiation, splicing and mRNA degradation, shape stochastic gene expression by modulation of molecular memory.",
        "comments": "49 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12661"
    },
    {
        "doc_id": 502,
        "title": "The stability and instability of the language control network: a longitudinal resting-state functional magnetic resonance imaging study",
        "authors": [
            "Zilong Li",
            "Cong Liu",
            "Xin Pan",
            "Guosheng Ding",
            "Ruiming Wanga"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The language control network is vital among language-related networks responsible for solving the problem of multiple language switching. Researchers have expressed concerns about the instability of the language control network when exposed to external influences (e.g., Long-term second language learning). However, some studies have suggested that the language control network is stable. Therefore, whether the language control network is stable or not remains unclear. In the present study, we directly evaluated the stability and instability of the language control network using resting-state functional magnetic resonance imaging (rs-fMRI). We employed cohorts of Chinese first-year college students majoring in English who underwent second language (L2) acquisition courses at a university and those who did not. Two resting-state fMRI scans were acquired approximately 1 year apart. We found that the language control network was both moderately stable and unstable. We further investigated the morphological coexistence patterns of stability and instability within the language control network. First, we extracted connections representing stability and plasticity from the entire network. We then evaluated whether the coexistence patterns were modular (stability and instability involve different brain regions) or non-modular (stability and plasticity involve the same brain regions but have unique connectivity patterns). We found that both stability and instability coexisted in a non-modular pattern. Compared with the non-English major group, the English major group has a more non-modular coexistence pattern.. These findings provide preliminary evidence of the coexistence of stability and instability in the language control network.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12616"
    },
    {
        "doc_id": 503,
        "title": "Experiencing an elongated limb in virtual reality modifies the tactile distance perception of the corresponding real limb",
        "authors": [
            "Fran\u00e7ois Le Jeune",
            "Marco D'Alonzo",
            "Valeria Piombino",
            "Alessia Noccaro",
            "Domenico Formica",
            "Giovanni Di Pino"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In measurement, a reference frame is needed to compare the measured object to something already known. This raises the neuroscientific question of which reference frame is used by humans when exploring the environment. Previous studies suggested that, in touch, the body employed as measuring tool also serves as reference frame. Indeed, an artificial modification of the perceived dimensions of the body changes the tactile perception of external object dimensions. However, it is unknown if such a change in tactile perception would occur when the body schema is modified through the illusion of owning an limb altered in size. Therefore, employing a virtual hand illusion paradigm with an elongated forearm of different lengths, we systematically tested the subjective perception of distance between two points (tactile distance perception task, TDP task) on the corresponding real forearm following the illusion. Thus, TDP task is used as a proxy to gauge changes in the body schema. Embodiment of the virtual arm was found significantly greater after the synchronous visuo-tactile stimulation condition compared to the asynchronous one, and the forearm elongation significantly increased the TDP. However, we did not find any link between the visuo-tactile induced ownership over the elongated arm and TDP variation, suggesting that vision plays the main role in the modification of the body schema. Additionally, significant effect of elongation found on TDP but not on proprioception suggests that these are affected differently by body schema modifications. These findings confirm the body schema malleability and its role as reference frame in touch.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12601"
    },
    {
        "doc_id": 504,
        "title": "A robust balancing mechanism for spiking neural networks",
        "authors": [
            "Antonio Politi",
            "Alessandro Torcini"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Neurons and Cognition"
        ],
        "abstract": "Dynamical balance of excitation and inhibition is usually invoked to explain the irregular low firing activity observed in the cortex. We propose a robust nonlinear balancing mechanism for a random network of spiking neurons, which works also in absence of strong external currents. Biologically, the mechanism exploits the plasticity of excitatory-excitatory synapses induced by short-term depression. Mathematically, the nonlinear response of the synaptic activity is the key ingredient responsible for the emergence of a stable balanced regime. Our claim is supported by a simple self-consistent analysis accompanied by extensive simulations performed for increasing network sizes. The observed regime is essentially fluctuation driven and characterized by highly irregular spiking dynamics of all neurons.",
        "comments": "9 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12559"
    },
    {
        "doc_id": 505,
        "title": "Understanding Cellular Noise with Optical Perturbation and Deep Learning",
        "authors": [
            "Chuanbo Liu",
            "Yu Fu",
            "Lu Lin",
            "Elliot L. Elson",
            "Jin Wang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Noise plays a crucial role in the regulation of cellular and organismal function and behavior.\n  Exploring noise's impact is key to understanding fundamental biological processes, such as gene expression, signal transduction, and the mechanisms of development and evolution.\n  Currently, a comprehensive method to quantify dynamical behavior of cellular noise within these biochemical systems is lacking.\n  In this study, we introduce an optically-controlled perturbation system utilizing the light-sensitive Phytochrome B (PhyB) from \\textit{Arabidopsis thaliana}, which enables precise noise modulation with high spatial-temporal resolution.\n  Our system exhibits exceptional sensitivity to light, reacting consistently to pulsed light signals, distinguishing it from other photoreceptor-based promoter systems that respond to a single light wavelength.\n  To characterize our system, we developed a stochastic model for phytochromes that accounts for photoactivation/deactivation, thermal reversion, and the dynamics of the light-activated gene promoter system.\n  To precisely control our system, we determined the rate constants for this model using an omniscient deep neural network that can directly map rate constant combinations to time-dependent state joint distributions.\n  By adjusting the activation rates through light intensity and degradation rates via N-terminal mutagenesis, we illustrate that out optical-controlled perturbation can effectively modulate molecular expression level as well as noise.\n  Our results highlight the potential of employing an optically-controlled gene perturbation system as a noise-controlled stimulus source.\n  This approach, when combined with the analytical capabilities of a sophisticated deep neural network, enables the accurate estimation of rate constants from observational data in a broad range of biochemical reaction networks.",
        "comments": "33 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12498"
    },
    {
        "doc_id": 506,
        "title": "Modular Control of Biological Networks",
        "authors": [
            "David Murrugarra",
            "Alan Veliz-Cuba",
            "Elena Dimitrova",
            "Claus Kadelka",
            "Matthew Wheeler",
            "Reinhard Laubenbacher"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "The concept of control is central to understanding and applications of biological network models. Some of their key structural features relate to control functions, through gene regulation, signaling, or metabolic mechanisms, and computational models need to encode these. Applications of models often focus on model-based control, such as in biomedicine or metabolic engineering. This paper presents an approach to model-based control that exploits two common features of biological networks, namely their modular structure and canalizing features of their regulatory mechanisms. The paper focuses on intracellular regulatory networks, represented by Boolean network models. A main result of this paper is that control strategies can be identified by focusing on one module at a time. This paper also presents a criterion based on canalizing features of the regulatory rules to identify modules that do not contribute to network control and can be excluded. For even moderately sized networks, finding global control inputs is computationally very challenging. The modular approach presented here leads to a highly efficient approach to solving this problem. This approach is applied to a published Boolean network model of blood cancer large granular lymphocyte (T-LGL) leukemia to identify a minimal control set that achieves a desired control objective.",
        "comments": "15 pages, 5 figures. arXiv admin note: text overlap with arXiv:2206.04217",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12477"
    },
    {
        "doc_id": 507,
        "title": "A dynamic model to study the potential TB infections and assessment of control strategies in China",
        "authors": [
            "Chuanqing Xu",
            "Kedeng Cheng",
            "Songbai Guo",
            "Dehui Yuan",
            "Xiaoyu Zhao"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "China is one of the countries with a high burden of tuberculosis, and although the number of new cases of tuberculosis has been decreasing year by year, the number of new infections per year has remained high and the diagnosis rate of tuberculosis-infected patients has remained low. Based on the analysis of TB infection data, we develop a model of TB transmission dynamics that include potentially infected individuals and BCG vaccination, fit the model parameters to the data on new TB cases, calculate the basic reproduction number \\mathcal{R}_v= 0.4442. A parametric sensitivity analysis of \\mathcal{R}_v is performed, and we obtained the correlation coefficients of BCG vaccination rate and effectiveness rate with \\mathcal{R}_v as -0.810, -0.825. According to the model, we estimate that there are 614,186 (95% CI [562,631,665,741]) potentially infected TB cases in China, accounting for about 39.5% of the total number of TB cases. We assess the feasibility of achieving the goals of the WHO strategy to end tuberculosis in China and find that reducing the number of new cases by 90 per cent by 2035 is very difficult with the current tuberculosis control measures. However, with an effective combination of control measures such as increased detection of potentially infected persons, improved drug treatment, and reduction of overall exposure to tuberculosis patients, it is feasible to reach the WHO strategic goal of ending tuberculosis by 2035.",
        "comments": "20 pages, 10 figures, 33 conference",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12462"
    },
    {
        "doc_id": 508,
        "title": "Hypochaos prevents tragedy of the commons in discrete-time eco-evolutionary game dynamics",
        "authors": [
            "Samrat Sohel Mondal",
            "Avishuman Ray",
            "Sagar Chakraborty"
        ],
        "subjects": [
            "Populations and Evolution",
            "Adaptation and Self-Organizing Systems"
        ],
        "abstract": "While quite a few recent papers have explored game-resource feedback using the framework of evolutionary game theory, almost all the studies are confined to using time-continuous dynamical equations. Moreover, in such literature, the effect of ubiquitous chaos in the resulting eco-evolutionary dynamics is rather missing. Here, we present a deterministic eco-evolutionary discrete-time dynamics in generation-wise non-overlapping population of two types of harvesters, one harvesting at a faster rate than the other, consuming a self-renewing resource capable of showing chaotic dynamics. In the light of our finding that sometimes chaos is confined exclusively to either the dynamics of the resource or that of the consumer fractions, an interesting scenario is realized: The resource state can keep oscillating chaotically, and hence, it does not vanish to result in the tragedy of the commons, extinction of the resource due to selfish indiscriminate exploitation, and yet the consumer population, whose dynamics depends directly on the state of the resource, may end up being composed exclusively of defectors, i.e., high harvesters. This appears non-intuitive because it is well known that prevention of tragedy of the commons usually requires substantial cooperation to be present.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12245"
    },
    {
        "doc_id": 509,
        "title": "A distribution-guided Mapper algorithm",
        "authors": [
            "Yuyang Tao",
            "Shufei Ge"
        ],
        "subjects": [
            "Algebraic Topology",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Motivation: The Mapper algorithm is an essential tool to explore shape of data in topology data analysis. With a dataset as an input, the Mapper algorithm outputs a graph representing the topological features of the whole dataset. This graph is often regarded as an approximation of a reeb graph of data. The classic Mapper algorithm uses fixed interval lengths and overlapping ratios, which might fail to reveal subtle features of data, especially when the underlying structure is complex.\n  Results: In this work, we introduce a distribution guided Mapper algorithm named D-Mapper, that utilizes the property of the probability model and data intrinsic characteristics to generate density guided covers and provides enhanced topological features. Our proposed algorithm is a probabilistic model-based approach, which could serve as an alternative to non-prababilistic ones. Moreover, we introduce a metric accounting for both the quality of overlap clustering and extended persistence homology to measure the performance of Mapper type algorithm. Our numerical experiments indicate that the D-Mapper outperforms the classical Mapper algorithm in various scenarios. We also apply the D-Mapper to a SARS-COV-2 coronavirus RNA sequences dataset to explore the topological structure of different virus variants. The results indicate that the D-Mapper algorithm can reveal both vertical and horizontal evolution processes of the viruses.\n  Availability: Our package is available at https://github.com/ShufeiGe/D-Mapper.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12237"
    },
    {
        "doc_id": 510,
        "title": "Machine Learning Modeling Of SiRNA Structure-Potency Relationship With Applications Against Sars-Cov-2 Spike Gene",
        "authors": [
            "Damilola Oshunyinka"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "The pharmaceutical Research and development (R&D) process is lengthy and costly, taking nearly a decade to bring a new drug to the market. However, advancements in biotechnology, computational methods, and machine learning algorithms have the potential to revolutionize drug discovery, speeding up the process and improving patient outcomes. The COVID-19 pandemic has further accelerated and deepened the recognition of the potential of these techniques, especially in the areas of drug repurposing and efficacy predictions. Meanwhile, non-small molecule therapeutic modalities such as cell therapies, monoclonal antibodies, and RNA interference (RNAi) technology have gained importance due to their ability to target specific disease pathways and/or patient populations. In the field of RNAi, many experiments have been carried out to design and select highly efficient siRNAs. However, the established patterns for efficient siRNAs are sometimes contradictory and unable to consistently determine the most potent siRNA molecules against a target mRNA. Thus, this paper focuses on developing machine learning models based on the cheminformatics representation of the nucleotide composition (i.e. AUTGC) of siRNA to predict their potency and aid the selection of the most efficient siRNAs for further development. The PLS (Partial Least Square) and SVR (Support Vector Regression) machine learning models built in this work outperformed previously published models. These models can help in predicting siRNA potency and aid in selecting the best siRNA molecules for experimental validation and further clinical development. The study has demonstrated the potential of AI/machine learning models to help expedite siRNA-based drug discovery including the discovery of potent siRNAs against SARS-CoV-2.",
        "comments": "Master's thesis",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12232"
    },
    {
        "doc_id": 511,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 512,
        "title": "Matching biomolecular structures by registration of point clouds",
        "authors": [
            "Michael Habeck",
            "Andreas Kr\u00f6pelin",
            "Nima Vakili"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Motivation: Assessing the match between two biomolecular structures is at the heart of structural analyses such as superposition, alignment and docking. These tasks are typically solved with specialized structure-matching techniques implemented in software for protein structural alignment, rigid-body docking, or rigid fitting into cryo-EM maps. Results: We present a unifying framework to compare biomolecular structures by applying ideas from computer vision. The structures are represented as three-dimensional point clouds and compared by quantifying their overlap. We use the kernel correlation to measure point cloud overlap, and discuss local and global optimization strategies for maximizing the kernel correlation over the space of rigid transformations. We derive a majorization-minimization procedure that can be used to register two point clouds without establishing a point-to-point correspondence. We demonstrate that the majorization-minimization algorithms outperform the commonly used Iterative Closest Point registration algorithm. Furthermore, we discuss and benchmark a randomization strategy for globally optimizing the kernel correlation. We illustrate the approach on various 3D fitting problems such as the comparison of circularly permuted structures and rigid fitting of cryo-EM maps or bead models from small-angle scattering.",
        "comments": "18 pages (main text), 7 figures (main text)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12082"
    },
    {
        "doc_id": 513,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Maria de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 514,
        "title": "Approximating a linear dynamical system from non-sequential data",
        "authors": [
            "Cliff Stein",
            "Pratik Worah"
        ],
        "subjects": [
            "Genomics"
        ],
        "abstract": "Given non-sequential snapshots from instances of a dynamical system, we design a compressed sensing based algorithm that reconstructs the dynamical system. We formally prove that successful reconstruction is possible under the assumption that we can construct an approximate clock from a subset of the coordinates of the underlying system.\n  As an application, we argue that our assumption is likely true for genomic datasets, and we recover the underlying nuclear receptor networks and predict pathways, as opposed to genes, that may differentiate phenotypes in some publicly available datasets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11858"
    },
    {
        "doc_id": 515,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 516,
        "title": "Full-dimensional characterisation of time-warped spike-time stimulus-response distribution geometries",
        "authors": [
            "James B Isbister"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Characterising the representation of sensory stimuli in the brain is a fundamental scientific endeavor, which can illuminate principles of information coding. Most characterizations reduce the dimensionality of neural data by converting spike trains to firing rates or binned spike counts, applying explicitly named methods of ``dimensionality reduction'', or collapsing trial-to-trial variability. Characterisation of the full-dimensional geometry of timing-based representations may provide unexpected insights into how complex high-dimensional information is encoded. Recent research shows that the distribution of representations elicited over trials of a single stimulus can be geometrically characterized without the application of dimensionality reduction, maintaining the temporal spiking information of individual neurons in a cell assembly and illuminating rich geometric structure. We extend these results, showing that precise spike time patterns for larger cell assemblies are time-warped (i.e. stretched or compressed) on each trial. Moreover, by geometrically characterizing distributions of large spike time patterns, our analysis supports the hypothesis that the degree to which a spike time pattern is time-warped depends on the cortical area's background activity level on a single trial. Finally, we suggest that the proliferation of large electrophysiology datasets and the increasing concentration of ``neural geometrists'', creates ideal conditions for characterization of full-dimensional spike time representations, in complement to dimensionality reduction approaches.",
        "comments": "Accepted as an extended abstract at the NeurReps workshop at NeurIPS 2023. The workshop doesn't publish extended abstracts so submitting here",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11784"
    },
    {
        "doc_id": 517,
        "title": "Impact of temporal interaction on the evolution of cooperation",
        "authors": [
            "Yujie He",
            "Tianyu Ren",
            "Junjun Zheng",
            "Huawen Liang"
        ],
        "subjects": [
            "Physics and Society",
            "Social and Information Networks",
            "Populations and Evolution"
        ],
        "abstract": "This research investigates the impact of dynamic interactions with time-varying topologies on the evolution of cooperative behaviours in social dilemmas. Traditional research has focused on deterministic rules governing pairwise interactions, yet the impact of interaction frequency and synchronicity on cooperation remains underexplored. Addressing this gap, our work introduces two temporal interaction mechanisms to model the stochastic or periodic participation of individuals in these games, acknowledging real-life variances due to exogenous temporal factors and geographical time differences. We consider that the interaction state significantly influences both game payoff calculations and the strategy updating process, offering new insights into the emergence and sustainability of cooperation. Our results indicate that maximum game participation frequency is suboptimal under a stochastic interaction mechanism. Instead, an intermediate region of activation probability yields the highest cooperation level, especially under strong dilemma conditions. This suggests that a balance between inactivity security and interaction frequency is crucial. Furthermore, local synchronization of interactions within specific areas is shown to be beneficial, as time differences hinder the spread of cross-structures but promote the formation of dense cooperative clusters with smoother boundaries. Our findings provide an intuitive understanding of node-based temporality and probabilistic interactions, contributing to the broader discourse on resolving social dilemmas.",
        "comments": "7 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11782"
    },
    {
        "doc_id": 518,
        "title": "Combining oligo pools and Golden Gate cloning to create protein variant libraries or guide RNA libraries for CRISPR applications",
        "authors": [
            "Alicia Maci\u00e1 Valero",
            "Rianne C. Prins",
            "Thijs de Vroet",
            "Sonja Billerbeck"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biomolecules"
        ],
        "abstract": "Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 350 bases), a higher error rate compared to alternative synthesis methods, and the presence of truncated molecules in the pool due to incomplete synthesis. Here, we provide users with a comprehensive protocol that details how oligo pools can be used in combination with Golden Gate cloning to create user-defined protein mutant libraries, as well as single guide RNA libraries for CRISPR applications. Our methods are optimized to work within the Yeast Toolkit Golden Gate scheme, but are in principle compatible with any other Golden Gate-based modular cloning toolkit and extendable to other restriction enzyme-based cloning methods beyond Golden Gate. Our methods yield high-quality, affordable, in-house variant libraries.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11746"
    },
    {
        "doc_id": 519,
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "authors": [
            "Chaoqian Wang",
            "Matja\u017e Perc",
            "Attila Szolnoki"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Statistical Mechanics",
            "Computational Complexity",
            "Cellular Automata and Lattice Gases",
            "Populations and Evolution"
        ],
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Ball-and-Box problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11686"
    },
    {
        "doc_id": 520,
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "authors": [
            "Courtney Golden",
            "Dan Ilan",
            "Nicholas Cebry",
            "Christopher Batten"
        ],
        "subjects": [
            "Hardware Architecture",
            "Genomics"
        ],
        "abstract": "DNA sequence alignment is an important workload in computational genomics. Reference-guided DNA assembly involves aligning many read sequences against candidate locations in a long reference genome. To reduce the computational load of this alignment, candidate locations can be pre-filtered using simpler alignment algorithms like edit distance. Prior work has explored accelerating filtering on simulated compute-in-DRAM, due to the massive parallelism of compute-in-memory architectures. In this paper, we present work-in-progress on accelerating filtering using a commercial compute-in-SRAM accelerator. We leverage the recently released Gemini accelerator platform from GSI Technology, which is the first, to our knowledge, commercial-scale compute-in-SRAM system. We accelerate the Myers' bit-parallel edit distance algorithm, producing average speedups of 14.1x over single-core CPU performance. Individual query/candidate alignments produce speedups of up to 24.1x. These early results suggest this novel architecture is well-suited to accelerating the filtering step of sequence-to-sequence DNA alignment.",
        "comments": "Journal ref:        5th Workshop on Accelerator Architecture in Computational Biology and Bioinformatics (AACBB), June 2023",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11685"
    },
    {
        "doc_id": 521,
        "title": "Modern approaches to improving phase contrast electron microscopy",
        "authors": [
            "Jeremy J. Axelrod",
            "Jessie T. Zhang",
            "Petar N. Petrov",
            "Robert M. Glaeser",
            "Holger Mueller"
        ],
        "subjects": [
            "Quantitative Methods",
            "Optics",
            "Biomolecules"
        ],
        "abstract": "Although defocus can be used to generate partial phase contrast in transmission electron microscope images, cryo-electron microscopy (cryo-EM) can be further improved by the development of phase plates which increase contrast by applying a phase shift to the unscattered part of the electron beam. Many approaches have been investigated, including the ponderomotive interaction between light and electrons. We review the recent successes achieved with this method in high-resolution, single-particle cryo-EM. We also review the status of using pulsed or near-field enhanced laser light as alternatives, along with approaches that use scanning transmission electron microscopy (STEM) with a segmented detector rather than a phase plate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11678"
    },
    {
        "doc_id": 522,
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "authors": [
            "Pratik Worah"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.\n  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11562"
    },
    {
        "doc_id": 523,
        "title": "Understanding Hepatitis B Virus Infection through Hepatocyte Proliferation and Capsid Recycling",
        "authors": [
            "Rupchand Sutradhar",
            "D C Dalal"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "Proliferation of uninfected as well as infected hepatocytes and recycling of DNA-containing\n  capsids are two major mechanisms playing significant roles in the clearance of hepatitis B\n  virus (HBV) infection. In this study, the temporal dynamics of this infection are investigated\n  through two in silico bio-mathematical models considering both proliferation of hepatocytes\n  and the recycling of capsids. Both models are formulated on the basis of a key finding in the existing literature: mitosis of infected yields in two uninfected progenies. In the first model,\n  we examine regular proliferation (occurs continuously), while the second model deals with the\n  irregular proliferation (happens when the total number of liver cells decreases to less than 70%\n  of its initial volume). The models are calibrated with the experimental data obtained from\n  an adult chimpanzee. Results of this study suggest that when both hepatocytes proliferate\n  with equal rate, proliferation aids the individual in a rapid recovery from the acute infection\n  whereas in the case of chronic infection, the severity of the infection increases if the proliferation\n  occurs frequently. On the other hand, if the infected cells proliferate at a slower rate than uninfected cells, the proliferation of uninfected hepatocytes contributes to increase the infection,\n  but the proliferation of infected hepatocytes acts to reduce the infection from the long-term\n  perspective. Furthermore, it is also observed that the differences between the outcomes of\n  regular and irregular proliferations are substantial and noteworthy.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11481"
    },
    {
        "doc_id": 524,
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "authors": [
            "Yin Li",
            "Yu Xiong",
            "Wenxin Fan",
            "Kai Wang",
            "Qingqing Yu",
            "Liping Si",
            "Patrick van der Smagt",
            "Jun Tang",
            "Nutan Chen"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.\n  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM models, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these RMSEs are significantly lower than the random prediction error of $4.55$.\n  Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11447"
    },
    {
        "doc_id": 525,
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "authors": [
            "Haoqiang Guo",
            "Sendong Zhao",
            "Haochun Wang",
            "Yanrui Du",
            "Bing Qin"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Biomolecules"
        ],
        "abstract": "Deep learning is now widely used in drug discovery, providing significant acceleration and cost reduction. As the most fundamental building block, molecular representation is essential for predicting molecular properties to enable various downstream applications. Most existing methods attempt to incorporate more information to learn better representations. However, not all features are equally important for a specific task. Ignoring this would potentially compromise the training efficiency and predictive accuracy. To address this issue, we propose a novel approach, which treats language models as an agent and molecular pretraining models as a knowledge base. The agent accentuates task-relevant features in the molecular representation by understanding the natural language description of the task, just as a tailor customizes clothes for clients. Thus, we call this approach MolTailor. Evaluations demonstrate MolTailor's superior performance over baselines, validating the efficacy of enhancing relevance for molecular representation learning. This illustrates the potential of language model guided optimization to better exploit and unleash the capabilities of existing powerful molecular representation methods. Our codes and appendix are available at https://github.com/SCIR-HI/MolTailor.",
        "comments": "Accepted by AAAI 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11403"
    },
    {
        "doc_id": 526,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 527,
        "title": "Sensory adaptation in a continuum model of bacterial chemotaxis -- working range, cost-accuracy relation, and coupled systems",
        "authors": [
            "Vansh Kharbanda",
            "Benedikt Sabass"
        ],
        "subjects": [
            "Cell Behavior",
            "Soft Condensed Matter"
        ],
        "abstract": "Sensory adaptation enables organisms to adjust their perception in a changing environment. A paradigm is bacterial chemotaxis, where the output activity of chemoreceptors is adapted to different baseline concentrations via receptor methylation. The range of internal receptor states limits the stimulus magnitude to which these systems can adapt. Here, we employ a highly idealized, Langevin-equation based model to study how the finite range of state variables affects the adaptation accuracy and the energy dissipation in individual and coupled systems. Maintaining an adaptive state requires constant energy dissipation. We show that the steady-state dissipation rate increases approximately linearly with the adaptation accuracy for varying stimulus magnitudes in the so-called perfect adaptation limit. This result complements the well-known logarithmic cost-accuracy relationship for varying chemical driving. Next, we study linearly coupled pairs of sensory units. We find that the interaction reduces the dissipation rate per unit and affects the overall cost-accuracy relationship. A coupling of the slow methylation variables results in a better accuracy than a coupling of activities. Overall, the findings highlight the significance of both the working range and collective operation mode as crucial design factors that impact the accuracy and energy expenditure of molecular adaptation networks.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11341"
    },
    {
        "doc_id": 528,
        "title": "Uncertainty quantification of receptor ligand binding sites prediction",
        "authors": [
            "Nanjie Chen",
            "Dongliang Yu",
            "Dmitri Beglov",
            "Mark Kon",
            "Julio Enrique Castrillon Candas"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Recent advancements in protein docking site prediction have highlighted the limitations of traditional rigid docking algorithms, like PIPER, which often neglect critical stochastic elements such as solvent-induced fluctuations. These oversights can lead to inaccuracies in identifying viable docking sites due to the complexity of high-dimensional, stochastic energy manifolds with low regularity. To address this issue, our research introduces a novel model where the molecular shapes of ligands and receptors are represented using multi-variate Karhunen-Lo `eve (KL) expansions. This method effectively captures the stochastic nature of energy manifolds, allowing for a more accurate representation of molecular interactions.Developed as a plugin for PIPER, our scientific computing software enhances the platform, delivering robust uncertainty measures for the energy manifolds of ranked binding sites. Our results demonstrate that top-ranked binding sites, characterized by lower uncertainty in the stochastic energy manifold, align closely with actual docking sites. Conversely, sites with higher uncertainty correlate with less optimal docking positions. This distinction not only validates our approach but also sets a new standard in protein docking predictions, offering substantial implications for future molecular interaction research and drug development.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11312"
    },
    {
        "doc_id": 529,
        "title": "Seasonality of primary productivity affects coastal species more than its magnitude",
        "authors": [
            "Carlota Muniz",
            "Christopher McQuaid",
            "Nicolas Weidberg"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "While the importance of extreme conditions is recognised, patterns in species abundances are often interpreted through average environmental conditions within their distributional range. For marine species with pelagic larvae, temperature and phytoplankton concentration are key variables. Along the south coast of South Africa, conspicuous spatial patterns in recruitment rates and the abundances of different mussel species exist, with focal areas characterized by large populations. We studied 15 years of sea surface temperature (SST) and chlorophyll-a (chl-a) satellite data, using spectral analyses to partition their temporal variability over ecologically relevant time periods, including seasonal (101 to 365 days) and intra-seasonal cycles (20 to 100 days). Adult cover and mussel recruitment were measured at 10 sites along the south coast and regression models showed that about 70 percent of the variability in recruitment and adult cover was explained by seasonal variability in chl-a, while mean annual chl-a and SST only explained 30 percent of the recruitment, with no significant effect for adult cover. SST and chl-a at two upwelling centres showed less predictable seasonal cycles during the second half of the study period with a significant cooling trend during austral autumn, coinciding with one of the mussel reproductive peaks. This likely reflects recent changes in the Agulhas Current, the world largest western boundary current, which affects coastal ecosystems by driving upwelling.",
        "comments": "Journal ref:        Science of the Total Environment, 757:143740, 2021",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11289"
    },
    {
        "doc_id": 530,
        "title": "Smart Drug-Delivery Systems for Cancer Nanotherapy",
        "authors": [
            "Paola Sanchez-Moreno",
            "Juan Luis Ortega-Vinuesa",
            "Jose Manuel Peula-Garcia",
            "Juan Antonio Marchal",
            "Houria Boulaiz"
        ],
        "subjects": [
            "Tissues and Organs",
            "Mesoscale and Nanoscale Physics",
            "Biological Physics"
        ],
        "abstract": "Despite all the advances achieved in the field of tumor-biology research, in most cases conventional therapies including chemotherapy are still the leading choices. The main disadvantage of these treatments, in addition to the low solubility of many antitumor drugs, is their lack of specificity, which explains the frequent occurrence of serious side effects due to nonspecific drug uptake by healthy cells. Progress in nanotechnology and its application in medicine have provided new opportunities and different smart systems. Such systems can improve the intracellular delivery of the drugs due to their multifunctionality and targeting potential. The purpose of this manuscript is to review and analyze the recent progress made in nanotherapy applied to cancer treatment. First, we provide a global overview of cancer and different smart nanoparticles currently used in oncology. Then, we analyze in detail the development of drug-delivery strategies in cancer therapy, focusing mainly on the intravenously administered smart nanoparticles with protein corona to avoid immune-system clearance. Finally, we discuss the challenges, clinical trials, and future directions of the nanoparticle-based therapy in cancer.",
        "comments": "Preprint version, 25 pages, 7 figures, 3 tables. Authors thank to Bentham Science the posibility of deposit the ACCEPTED VERSION of the peer-reviewed article after 12 months of publication on journal web site on arXiv repository. The published manuscript is available at EurekaSelect via https://www.eurekaselect.com/openurl/content.php?genre=article&doi=10.2174/1389450117666160527142544",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11192"
    },
    {
        "doc_id": 531,
        "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge",
        "authors": [
            "Chih-Hsuan Wei",
            "Alexis Allot",
            "Po-Ting Lai",
            "Robert Leaman",
            "Shubo Tian",
            "Ling Luo",
            "Qiao Jin",
            "Zhizheng Wang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "subjects": [
            "Computation and Language",
            "Quantitative Methods"
        ],
        "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves the factuality and verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive set of features and tools that allow researchers to navigate the ever-expanding wealth of biomedical literature, expediting research and unlocking valuable insights for scientific discovery.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11048"
    },
    {
        "doc_id": 532,
        "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
        "authors": [
            "Minkai Xu",
            "Jiaqi Han",
            "Aaron Lou",
            "Jean Kossaifi",
            "Arvind Ramanathan",
            "Kamyar Azizzadenesheli",
            "Jure Leskovec",
            "Stefano Ermon",
            "Anima Anandkumar"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis",
            "Quantitative Methods"
        ],
        "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11037"
    },
    {
        "doc_id": 533,
        "title": "Clustering Molecular Energy Landscapes by Adaptive Network Embedding",
        "authors": [
            "Paula Mercurio",
            "Di Liu"
        ],
        "subjects": [
            "Biomolecules",
            "Statistical Mechanics",
            "Machine Learning"
        ],
        "abstract": "In order to efficiently explore the chemical space of all possible small molecules, a common approach is to compress the dimension of the system to facilitate downstream machine learning tasks. Towards this end, we present a data driven approach for clustering potential energy landscapes of molecular structures by applying recently developed Network Embedding techniques, to obtain latent variables defined through the embedding function. To scale up the method, we also incorporate an entropy sensitive adaptive scheme for hierarchical sampling of the energy landscape, based on Metadynamics and Transition Path Theory. By taking into account the kinetic information implied by a system's energy landscape, we are able to interpret dynamical node-node relationships in reduced dimensions. We demonstrate the framework through Lennard-Jones (LJ) clusters and a human DNA sequence.",
        "comments": "19 pages, 10 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10972"
    },
    {
        "doc_id": 534,
        "title": "Homogenisation of nonlinear blood flow in periodic networks: the limit of small haematocrit heterogeneity",
        "authors": [
            "Y. Ben-Ami",
            "B. D. Wood",
            "J. M. Pitt-Francis",
            "P. K. Maini",
            "H. M. Byrne"
        ],
        "subjects": [
            "Tissues and Organs",
            "Soft Condensed Matter",
            "Biological Physics"
        ],
        "abstract": "In this work we develop a homogenisation methodology to upscale mathematical descriptions of microcirculatory blood flow from the microscale (where individual vessels are resolved) to the macroscopic (or tissue) scale. Due to the assumed two-phase nature of blood and specific features of red blood cells (RBCs), mathematical models for blood flow in the microcirculation are highly nonlinear, coupling the flow and RBC concentrations (haematocrit). In contrast to previous works which accomplished blood-flow homogenisation by assuming that the haematocrit level remains constant, here we allow for spatial heterogeneity in the haematocrit concentration and thus begin with a nonlinear microscale model. We simplify the analysis by considering the limit of small haematocrit heterogeneity which prevails when variations in haematocrit concentration between neighbouring vessels are small. Homogenisation results in a system of coupled, nonlinear partial differential equations describing the flow and haematocrit transport at the macroscale, in which a nonlinear Darcy-type model relates the flow and pressure gradient via a haematocrit-dependent permeability tensor. During the analysis we obtain further that haematocrit transport at the macroscale is governed by a purely advective equation. Applying the theory to particular examples of two- and three-dimensional geometries of periodic networks, we calculate the effective permeability tensor associated with blood flow in these vascular networks. We demonstrate how the statistical distribution of vessel lengths and diameters, together with the average haematocrit level, affect the statistical properties of the macroscopic permeability tensor. These data can be used to simulate blood flow and haematocrit transport at the macroscale.",
        "comments": "34 pages, 8 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10932"
    },
    {
        "doc_id": 535,
        "title": "A Chaotic Associative Memory",
        "authors": [
            "Nurani Rajagopal Rohan",
            "Sayan Gupta",
            "V. Srinivasa Chakravarthy"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Chaotic Dynamics"
        ],
        "abstract": "We propose a novel Chaotic Associative Memory model using a network of chaotic Rossler systems and investigate the storage capacity and retrieval capabilities of this model as a function of increasing periodicity and chaos. In early models of associate memory networks, memories were modeled as fixed points, which may be mathematically convenient but has poor neurobiological plausibility. Since brain dynamics is inherently oscillatory, attempts have been made to construct associative memories using nonlinear oscillatory networks. However, oscillatory associative memories are plagued by the problem of poor storage capacity, though efforts have been made to improve capacity by adding higher order oscillatory modes. The chaotic associative memory proposed here exploits the continuous spectrum of chaotic elements and has higher storage capacity than previously described oscillatory associate memories.",
        "comments": "10 pages, 8 Figures, Submitted to \"Chaos: An Interdisciplinary Journal of Nonlinear Science\"",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10922"
    },
    {
        "doc_id": 536,
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "authors": [
            "Jason Toy",
            "Josh MacAdam",
            "Phil Tabor"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
        "comments": "9 pages, 4 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10910"
    },
    {
        "doc_id": 537,
        "title": "Novel community data in ecology -- properties and prospects",
        "authors": [
            "Florian Hartig",
            "Nerea Abrego",
            "Alex Bush",
            "Jonathan M. Chase",
            "Gurutzeta Guillera-Arroita",
            "Mathew A. Leibold",
            "Otso Ovaskainen",
            "Lo\u00efc Pellissier",
            "Maximilian Pichler",
            "Giovanni Poggiato",
            "Laura Pollock",
            "Sara Si-Moussi",
            "Wilfried Thuiller",
            "Duarte S. Viana",
            "David I. Warton",
            "Damaris Zurell",
            "Douglas W. Yu"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "New technologies for acquiring biological information such as eDNA, acoustic or optical sensors, make it possible to generate spatial community observations at unprecedented scales. The potential of these novel community data to standardize community observations at high spatial, temporal, and taxonomic resolution and at large spatial scale ('many rows and many columns') has been widely discussed, but so far, there has been little integration of these data with ecological models and theory. Here, we review these developments and highlight emerging solutions, focusing on statistical methods for analyzing novel community data, in particular joint species distribution models; the new ecological questions that can be answered with these data; and the potential implications of these developments for policy and conservation.",
        "comments": "Journal ref:        Trends in Ecology & Evolution, 2024",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10860"
    },
    {
        "doc_id": 538,
        "title": "Exploring the role of structure in a time constrained decision task",
        "authors": [
            "Naomi Chaix-Eichel",
            "Gautham Venugopal",
            "Thomas Boraud",
            "Nicolas P. Rougier"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "The structure of the basal ganglia is remarkably similar across a number of species (often described in terms of direct, indirect and hyperdirect pathways) and is deeply involved in decision making and action selection. In this article, we are interested in exploring the role of structure when solving a decision task while avoiding to make any strong assumption regarding the actual structure. To do so, we exploit the echo state network paradigm that allows to solve complex task based on a random architecture. Considering a temporal decision task, the question is whether a specific structure allows for better performance and if so, whether this structure shares some similarity with the basal ganglia. Our results highlight the advantage of having a slow (direct) and a fast (hyperdirect) pathway that allows to deal with late information during a decision making task.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10849"
    },
    {
        "doc_id": 539,
        "title": "Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer Subtype Diagnosis",
        "authors": [
            "Charles Theodore Kent",
            "Leila Bagheriye",
            "Johan Kwisthout"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Machine Learning",
            "Genomics",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Recent strides in the field of neural computation has seen the adoption of Winner Take All (WTA) circuits to facilitate the unification of hierarchical Bayesian inference and spiking neural networks as a neurobiologically plausible model of information processing. Current research commonly validates the performance of these networks via classification tasks, particularly of the MNIST dataset. However, researchers have not yet reached consensus about how best to translate the stochastic responses from these networks into discrete decisions, a process known as population decoding. Despite being an often underexamined part of SNNs, in this work we show that population decoding has a significanct impact on the classification performance of WTA networks. For this purpose, we apply a WTA network to the problem of cancer subtype diagnosis from multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing so we utilise a novel implementation of gene similarity networks, a feature encoding technique based on Kohoens self organising map algorithm. We further show that the impact of selecting certain population decoding methods is amplified when facing imbalanced datasets.",
        "comments": "This paper has been accepted in BIOINFORMATICS 2024 (BIOSTEC 2024)",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10844"
    },
    {
        "doc_id": 540,
        "title": "DeepRLI: A Multi-objective Framework for Universal Protein--Ligand Interaction Prediction",
        "authors": [
            "Haoyu Lin",
            "Shiwei Wang",
            "Jintao Zhu",
            "Yibo Li",
            "Jianfeng Pei",
            "Luhua Lai"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Protein (receptor)--ligand interaction prediction is a critical component in computer-aided drug design, significantly influencing molecular docking and virtual screening processes. Despite the development of numerous scoring functions in recent years, particularly those employing machine learning, accurately and efficiently predicting binding affinities for protein--ligand complexes remains a formidable challenge. Most contemporary methods are tailored for specific tasks, such as binding affinity prediction, binding pose prediction, or virtual screening, often failing to encompass all aspects. In this study, we put forward DeepRLI, a novel protein--ligand interaction prediction architecture. It encodes each protein--ligand complex into a fully connected graph, retaining the integrity of the topological and spatial structure, and leverages the improved graph transformer layers with cosine envelope as the central module of the neural network, thus exhibiting superior scoring power. In order to equip the model to generalize to conformations beyond the confines of crystal structures and to adapt to molecular docking and virtual screening tasks, we propose a multi-objective strategy, that is, the model outputs three scores for scoring and ranking, docking, and screening, and the training process optimizes these three objectives simultaneously. For the latter two objectives, we augment the dataset through a docking procedure, incorporate suitable physics-informed blocks and employ an effective contrastive learning approach. Eventually, our model manifests a balanced performance across scoring, ranking, docking, and screening, thereby demonstrating its ability to handle a range of tasks. Overall, this research contributes a multi-objective framework for universal protein--ligand interaction prediction, augmenting the landscape of structure-based drug design.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10806"
    },
    {
        "doc_id": 541,
        "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks",
        "authors": [
            "Heorhii Skovorodnikov",
            "Hoda Alkhzaimi"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Genomics"
        ],
        "abstract": "With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples via spectral analysis yielding conclusions for countermeasures against such attacks.",
        "comments": "15 pages, core code available at: https://github.com/HeorhiiS/fimba-attack",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10657"
    },
    {
        "doc_id": 542,
        "title": "Exact analytical algorithm for solvent accessible surface area and derivatives in implicit solvent molecular simulations on GPUs",
        "authors": [
            "Xin Cao",
            "Michelle H. Hummel",
            "Yuzhang Wang",
            "Carlos Simmerling",
            "Evangelos A. Coutsias"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "In this paper, we present dSASA (differentiable SASA), an exact geometric method to calculate solvent accessible surface area (SASA) analytically along with atomic derivatives on GPUs. The atoms in a molecule are first assigned to tetrahedra in groups of four atoms by Delaunay tetrahedrization adapted for efficient GPU implementation and the SASA values for atoms and molecules are calculated based on the tetrahedrization information and inclusion-exclusion method. The SASA values from the numerical icosahedral-based method can be reproduced with more than 98% accuracy for both proteins and RNAs. Having been implemented on GPUs and incorporated into the software Amber, we can apply dSASA to implicit solvent molecular dynamics simulations with inclusion of this nonpolar term. The current GPU version of GB/SA simulations has been accelerated up to nearly 20-fold compared to the CPU version and it outperforms LCPO as the system size increases. The performance and importance of the nonpolar part in implicit solvent modeling are demonstrated in GB/SA simulations of proteins and accurate SASA calculation of nucleic acids.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10462"
    },
    {
        "doc_id": 543,
        "title": "Ecosystem models cannot predict the consequences of conservation decisions",
        "authors": [
            "Larissa Lubiana Botelho",
            "Cailan Jeynes-Smith",
            "Sarah Vollert",
            "Michael Bode"
        ],
        "subjects": [
            "Populations and Evolution",
            "Quantitative Methods"
        ],
        "abstract": "Ecosystem models are often used to predict the consequences of management decisions in applied ecology, including fisheries management and threatened species conservation. These models are high-dimensional, parameter-rich, and nonlinear, yet limited data is available to calibrate them, and they are rarely tested or validated. Consequently, the accuracy of their forecasts, and their utility as decision-support tools is a matter of debate. In this paper, we calibrate ecosystem models to time-series data from 110 different experimental microcosm ecosystems, each containing between three and five interacting species. We then assess how often these calibrated models offer accurate and useful predictions about how the ecosystem will respond to a set of standard management interventions. Our results show that for each timeseries dataset, a large number of very different parameter sets offer equivalent, good fits. However, these calibrated ecosystem models have poor predictive accuracy when forecasting future dynamics and offer ambiguous predictions about how species in the ecosystem will respond to management interventions. Closer inspection reveals that the ecosystem models fail because calibration cannot determine the types of interactions that occur within the ecosystem. Our findings call into question claims that ecosystem modelling can support applied ecological decision-making when they are calibrated against real-world datasets.",
        "comments": "23 pages (main text + supplementary material) 9 figures (main text + supplementary material)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10439"
    },
    {
        "doc_id": 544,
        "title": "Diffusion of intrinsically disordered proteins within viscoelastic membraneless droplets",
        "authors": [
            "Fuga Watanabe",
            "Takuma Akimoto",
            "Robert B. Best",
            "Kresten Lindorff-Larsen",
            "Ralf Metzler",
            "Eiji Yamamoto"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Biological Physics",
            "Computational Physics",
            "Biomolecules"
        ],
        "abstract": "In living cells, intrinsically disordered proteins (IDPs), such as FUS and DDX4, undergo phase separation, forming biomolecular condensates. Using molecular dynamics simulations, we investigate their behavior in their respective homogenous droplets. We find that the proteins exhibit transient subdiffusion due to the viscoelastic nature and confinement effects in the droplets. The conformation and the instantaneous diffusivity of the proteins significantly vary between the interior and the interface of the droplet, resulting in non-Gaussianity in the displacement distributions. This study highlights key aspects of IDP behavior in biomolecular condensates.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10438"
    },
    {
        "doc_id": 545,
        "title": "Exploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies",
        "authors": [
            "Gang Qu",
            "Anton Orlichenko",
            "Junqi Wang",
            "Gemeng Zhang",
            "Li Xiao",
            "Aiying Zhang",
            "Zhengming Ding",
            "Yu-Ping Wang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined graph structure to depict associations between brain regions, a detail not solely provided by FCs. To bridge this gap, we introduce the Gated Graph Transformer (GGT) framework, designed to predict cognitive metrics based on FCs. Empirical validation on the Philadelphia Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of our model, further accentuating its potential in identifying pivotal neural connectivities that correlate with human cognitive processes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10348"
    },
    {
        "doc_id": 546,
        "title": "DrugAssist: A Large Language Model for Molecule Optimization",
        "authors": [
            "Geyan Ye",
            "Xibao Cai",
            "Houtim Lai",
            "Xing Wang",
            "Junhong Huang",
            "Longyue Wang",
            "Wei Liu",
            "Xiangxiang Zeng"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called MolOpt-Instructions for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.",
        "comments": "Geyan Ye and Xibao Cai are equal contributors; Longyue Wang is corresponding author",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10334"
    },
    {
        "doc_id": 547,
        "title": "Fine scale depth regulation of invertebrate larvae around coastal fronts",
        "authors": [
            "Nicolas Weidberg",
            "Wayne Goschen",
            "Jennifer M. Jackson",
            "Paula Pattrick",
            "Christopher D. McQuaid",
            "Francesca Porri"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Vertical migrations of zooplankters have been widely described, but their active movements through shallow, highly dynamic water columns within the inner shelf may be more complex and difficult to characterize. In this study, invertebrate larvae, currents, and hydrographic variables were sampled at different depths during and after the presence of fronts on three different cruises off the southern coast of South Africa. Internal wave dynamics were observed in the hydrographic data set but also through satellite imagery, although strong surface convergent currents were absent and thermal stratification was weak. During the first two cruises, fronts were more conspicuous and they preceded strong onshore currents at depth which developed with the rising tide. Vertical distributions of larvae changed accordingly, with higher abundances at these deep layers once the front disappeared. The third cruise was carried out during slack tides, the front was not conspicuous, deep strong onshore currents did not occur afterward and larval distributions did not change consistently through time. Overall, the vertical distributions of many larval taxa matched the vertical profiles of shoreward currents and multivariate analyses revealed that these flows structured the larval community, which was neither influenced by temperature nor chlorophyll. Thus, the ability to regulate active vertical positioning may enhance shoreward advection and determine nearshore larval distributions.",
        "comments": "Journal ref:        Limnology and Oceanography. 64 - 2, pp. 785 - 802, 2019",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10303"
    },
    {
        "doc_id": 548,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 549,
        "title": "Mechanisms of nearshore retention and offshore export of mussel larvae over the Agulhas Bank",
        "authors": [
            "Nicolas Weidberg",
            "Francesca Porri",
            "Charles von der Meden",
            "Jennifer M. Jackson",
            "Wayne Goschen",
            "Christopher McQuaid"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Ecological connectivity is critical for population dynamics but in many benthic species it is complicated by a planktonic larval phase, whose dispersal remains poorly understood. Using a plankton pump, we examine the distribution of intertidal mussel larvae along three axes: alongshore, cross-shelf and by depth during a large scale (600 km) cruise over the Agulhas Bank off southern Africa in August/September 2010. As a general pattern, higher veliger abundances were found close to the coast. Our analyses of the nearshore flow, estimated from ADCP data and the vertical distribution of larvae, show that onshore larval retention may be mediated by active vertical swimming through the water column guided by light and wind-induced turbulence. A massive offshore export of larvae off St Francis Bay was, however, observed during an Agulhas Current meander which influenced inner shelf waters. We hypothesize that, by increasing and homogenizing flow, the Agulhas Current may erase the effects of larval vertical positioning on onshore retention and transport larvae offshore. Our study highlights the need to integrate the effects of complex, region-specific physical dynamics with the swimming behaviour of larvae in order to explain their spatial distribution, population connectivity and the consequences for population dynamics.",
        "comments": "Journal ref:        Journal of Plankton Research. 37 - 6, pp. 1166 - 1180. Oxford Journals, 11/2015",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10292"
    },
    {
        "doc_id": 550,
        "title": "Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning",
        "authors": [
            "Ryan Cho",
            "Mobasshira Zaman",
            "Kyu Taek Cho",
            "Jaejin Hwang"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Neurons and Cognition"
        ],
        "abstract": "This study aimed to analyze brain activity during various STEM activities, exploring the feasibility of classifying between different tasks. EEG brain data from twenty subjects engaged in five cognitive tasks were collected and segmented into 4-second clips. Power spectral densities of brain frequency waves were then analyzed. Testing different k-intervals with XGBoost, Random Forest, and Bagging Classifier revealed that Random Forest performed best, achieving a testing accuracy of 91.07% at an interval size of two. When utilizing all four EEG channels, cognitive flexibility was most recognizable. Task-specific classification accuracy showed the right frontal lobe excelled in mathematical processing and planning, the left frontal lobe in cognitive flexibility and mental flexibility, and the left temporoparietal lobe in connections. Notably, numerous connections between frontal and temporoparietal lobes were observed during STEM activities. This study contributes to a deeper understanding of implementing machine learning in analyzing brain activity and sheds light on the brain's mechanisms.",
        "comments": "20 pages, 7 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10285"
    },
    {
        "doc_id": 551,
        "title": "EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model",
        "authors": [
            "Yuqi Chen",
            "Kan Ren",
            "Kaitao Song",
            "Yansen Wang",
            "Yifan Wang",
            "Dongsheng Li",
            "Lili Qiu"
        ],
        "subjects": [
            "Signal Processing",
            "Artificial Intelligence",
            "Machine Learning",
            "Multimedia",
            "Neurons and Cognition"
        ],
        "abstract": "Self-supervised learning has emerged as a highly effective approach in the fields of natural language processing and computer vision. It is also applicable to brain signals such as electroencephalography (EEG) data, given the abundance of available unlabeled data that exist in a wide spectrum of real-world medical applications ranging from seizure detection to wave analysis. The existing works leveraging self-supervised learning on EEG modeling mainly focus on pretraining upon each individual dataset corresponding to a single downstream task, which cannot leverage the power of abundant data, and they may derive sub-optimal solutions with a lack of generalization. Moreover, these methods rely on end-to-end model learning which is not easy for humans to understand. In this paper, we present a novel EEG foundation model, namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained model cannot only learn universal representations on EEG signals with adaptable performance on various downstream tasks but also provide interpretable outcomes of the useful patterns within the data. To validate the effectiveness of our model, we extensively evaluate it on various downstream tasks and assess the performance under different transfer settings. Furthermore, we demonstrate how the learned model exhibits transferable anomaly detection performance and provides valuable interpretability of the acquired patterns via self-supervised learning.",
        "comments": "A preprint version of an ongoing work",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10278"
    },
    {
        "doc_id": 552,
        "title": "Evolving Diploid Boolean and Multi-Valued Gene Networks",
        "authors": [
            "Larry Bull"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Boolean networks have been widely used to explore aspects of gene regulation, traditionally with a single network. A modified form of the model to explore the effects of increasing the number of gene states has also recently been introduced. In this paper, these discrete dynamical networks are evolved as diploids within rugged fitness landscapes to explore their behaviour. Results suggest the general properties of haploid networks in similar circumstances remain for diploids. The previously proposed inherent fitness landscape smoothing properties of eukaryotic sex are shown to be exhibited in these dynamical systems, as is their propensity to change in size based upon the characteristics of the network and fitness landscape.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.01694",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10237"
    },
    {
        "doc_id": 553,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 554,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 555,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 556,
        "title": "Correlating fluorescence microscopy, optical and magnetic tweezers to study single chiral biopolymers, tested on DNA plectoneme formation dynamics",
        "authors": [
            "Jack W Shepherd",
            "Sebastien Guilbaud",
            "Zhaokun Zhou",
            "Jamieson Howard",
            "Matthew Burman",
            "Charley Schaefer",
            "Adam Kerrigan",
            "Clare Steele-King",
            "Agnes Noy",
            "Mark C Leake"
        ],
        "subjects": [
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Biopolymer topology is critical for determining interactions inside cell environments, exemplified by DNA where its response to mechanical perturbation is as important as biochemical properties to its cellular roles. The dynamic structures of chiral biopolymers exhibit complex dependence with extension and torsion, however the physical mechanisms underpinning the emergence of structural motifs upon physiological twisting and stretching are poorly understood due to technological limitations in correlating force, torque and spatial localization information. We present COMBI-Tweez (Combined Optical and Magnetic BIomolecule TWEEZers), a transformative tool that overcomes these challenges by integrating optical trapping, time-resolved electromagnetic tweezers, and fluorescence microscopy, demonstrated on single DNA molecules, that can controllably form and visualise higher order structural motifs including plectonemes. This technology combined with cutting-edge MD simulations provides quantitative insight into complex dynamic structures relevant to DNA cellular processes and can be adapted to study a range of filamentous biopolymers.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10087"
    },
    {
        "doc_id": 557,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 558,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 559,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 560,
        "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
        "authors": [
            "Zofia Rudnicka",
            "Janusz Szczepanski",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in the medical image scan segmentation, and intelligent visual-content generation, i.e. computer-generated three-dimensional (3D) images in the context of Extended Reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes also with possible developments and open challenges in AI application in Extended Reality-based solutions. Finally, the future lines of research and development directions of Artificial Intelligence applications both in medical image segmentation and Extended Reality-based medical solutions are discussed",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09857"
    },
    {
        "doc_id": 561,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 562,
        "title": "The impact of Covid-19 vaccination in Aotearoa New Zealand: a modelling study",
        "authors": [
            "Samik Datta",
            "Giorgia Vattiato",
            "Oliver J Maclaren",
            "Ning Hua",
            "Andrew Sporle",
            "Michael J Plank"
        ],
        "subjects": [
            "Populations and Evolution",
            "Physics and Society"
        ],
        "abstract": "Aotearoa New Zealand implemented a Covid-19 elimination strategy in 2020 and 2021, which enabled a large majority of the population to be vaccinated before being exposed to the virus. This strategy delivered one of the lowest pandemic mortality rates in the world. However, quantitative estimates of the population-level health benefits of vaccination are lacking. Here, we use a validated mathematical model to investigate counterfactual scenarios with differing levels of vaccine coverage in different age and ethnicity groups. The model builds on earlier research by adding age- and time-dependent case ascertainment, the effect of antiviral medications, improved hospitalisation rate estimates, and the impact of relaxing control measures. The model was used for scenario analysis and policy advice for the New Zealand Government in 2022 and 2023. We compare the number of Covid-19 hospitalisations, deaths, and years of life lost in each counterfactual scenario to a baseline scenario that is fitted to epidemiological data between January 2022 and June 2023. Our results estimate that vaccines saved 6650 (95% credible interval [4424, 10180]) lives, and prevented 74500 [51000, 115400] years of life lost and 45100 [34400, 55600] hospitalisations during this 18-month period. Making the same comparison before the benefit of antiviral medications is accounted for, the estimated number of lives saved by vaccines increases to 7604 [5080, 11942]. Due to inequities in the vaccine rollout, vaccination rates among M\u0101ori were lower than in people of European ethnicity. Our results show that, if vaccination rates had been equitable, an estimated 11-26% of the 292 M\u0101ori Covid-19 deaths that were recorded in this time period could have been prevented. We conclude that Covid-19 vaccination greatly reduced health burden in New Zealand and that equity needs to be a key focus of future vaccination programmes.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09679"
    },
    {
        "doc_id": 563,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 564,
        "title": "Molecular causality in the advent of foundation models",
        "authors": [
            "Sebastian Lobentanzer",
            "Pablo Rodriguez-Mier",
            "Stefan Bauer",
            "Julio Saez-Rodriguez"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Correlation is not causation. As simple as this widely agreed-upon statement may seem, scientifically defining causality and using it to drive our modern biomedical research is immensely challenging. In this perspective, we attempt to synergise the partly disparate fields of systems biology, causal reasoning, and machine learning, to inform future approaches in the field of systems biology and molecular networks.",
        "comments": "22 pages, 0 figures, 87 references; submitted to MSB",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09558"
    },
    {
        "doc_id": 565,
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "Junhao Wen",
            "Mathilde Antoniades",
            "Zhijian Yang",
            "Gyujoon Hwang",
            "Ioanna Skampardoni",
            "Rongguang Wang",
            "Christos Davatzikos"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing",
            "Quantitative Methods"
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09517"
    },
    {
        "doc_id": 566,
        "title": "Is the Emergence of Life an Expected Phase Transition in the Evolving Universe?",
        "authors": [
            "Stuart Kauffman",
            "Andrea Roli"
        ],
        "subjects": [
            "Populations and Evolution",
            "Biological Physics"
        ],
        "abstract": "We propose a novel definition of life in terms of which its emergence in the universe is expected, and its ever-creative open-ended evolution is entailed by no law. Living organisms are Kantian Wholes that achieve Catalytic Closure, Constraint Closure, and Spatial Closure. We here unite for the first time two established mathematical theories, namely Collectively Autocatalytic Sets and the Theory of the Adjacent Possible. The former establishes that a first-order phase transition to molecular reproduction is expected in the chemical evolution of the universe where the diversity and complexity of molecules increases; the latter posits that, under loose hypotheses, if the system starts with a small number of beginning molecules, each of which can combine with copies of itself or other molecules to make new molecules, over time the number of kinds of molecules increases slowly but then explodes upward hyperbolically. Together these theories imply that life is expected as a phase transition in the evolving universe. The familiar distinction between software and hardware loses its meaning in living cells. We propose new ways to study the phylogeny of metabolisms, new astronomical ways to search for life on exoplanets, new experiments to seek the emergence of the most rudimentary life, and the hint of a coherent testable pathway to prokaryotes with template replication and coding.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09514"
    },
    {
        "doc_id": 567,
        "title": "Role of Upwelling on Larval Dispersal and Productivity of Gooseneck Barnacle Populations in the Cantabrian Sea: Management Implications",
        "authors": [
            "Antonella Rivera",
            "Nicolas Weidberg",
            "Antonio F. Pardi\u00f1as",
            "Ricardo Gonzalez-Gil",
            "Luc\u0131a Garc\u0131a- Florez",
            "Jose Luis Acu\u00f1a"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "The effect of coastal upwelling on the recruitment and connectivity of coastal marine populations has rarely been characterized to a level of detail to be included into sound fishery management strategies. The gooseneck barnacle (Pollicipes pollicipes) fishery at the Cantabrian Coast (Northern Spain) is located at the fringes of the NW Spanish Upwelling system. This fishery is being co-managed through a fine-scale, interspersed set of protected rocks where each rock receives a distinct level of protection. Such interspersion is potentially beneficial, but the extent to which such spacing is consistent with mean larval dispersal distances is as yet unknown. We have simulated the spread of gooseneck barnacle larvae in the Central Cantabrian Coast using a high-resolution time-series of current profiles measured at a nearshore location. During a year of high upwelling activity (2009), theoretical recruitment success was 94% with peak recruitment predicted 56 km west of the emission point. However, for a year of low upwelling activity (2011) theoretical recruitment success dropped to 15.4% and peak recruitment was expected 13 km east of the emission point. This is consistent with a positive correlation between catch rates and the Integrated Upwelling Index, using a 4-year lag to allow recruits to reach commercial size. Furthermore, a net long-term westward larval transport was estimated by means of mitochondrial cytochrome c oxidase subunit I (COI) sequences for five populations in the Cantabrian Sea. Our results call into question the role of long distance dispersal, driven by the mesoscale processes in the area, in gooseneck barnacle populations and point to the prevalent role of small-scale, asymmetric connectivity more consistent with the typical scale of the co-management process in this fishery.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09513"
    },
    {
        "doc_id": 568,
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Haotian Lu",
            "Yexin Wu",
            "Zexin Yuan",
            "Shengdian Jiang",
            "Jiaxiang Wu",
            "Yimin Wang",
            "Junchi Yan"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09500"
    },
    {
        "doc_id": 569,
        "title": "Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "Jiayu Chang",
            "Shiyu Wang",
            "Chen Ling",
            "Zhaohui Qin",
            "Liang Zhao"
        ],
        "subjects": [
            "Quantitative Methods",
            "Information Retrieval"
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations.",
        "comments": "This is the official paper accepted by AAAI 2024 Workshop on Large Language Models for Biological Discoveries",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09490"
    },
    {
        "doc_id": 570,
        "title": "The Interplay Between Logical Phenomena and the Cognitive System of the Mind",
        "authors": [
            "Kazem Haghnejad Azar"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In this article, we employ mathematical concepts as a tool to examine the phenomenon of consciousness experience and logical phenomena. Through our investigation, we aim to demonstrate that our experiences, while not confined to limitations, cannot be neatly encapsulated within a singular collection. Our conscious experience emerges as a result of the developmental and augmentative trajectory of our cognitive system. As our cognitive abilities undergo refinement and advancement, our capacity for logical thinking likewise evolves, thereby manifesting a heightened level of conscious experience. The primary objective of this article is to embark upon a profound exploration of the concept of logical experience, delving into the intricate process by which these experiences are derived from our mind.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09465"
    },
    {
        "doc_id": 571,
        "title": "Diffusion-Driven Generative Framework for Molecular Conformation Prediction",
        "authors": [
            "Bobin Yang",
            "Jie Deng",
            "Zhenghan Chen",
            "Ruoxue Wu"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "The task of deducing three-dimensional molecular configurations from their two-dimensional graph representations holds paramount importance in the fields of computational chemistry and pharmaceutical development. The rapid advancement of machine learning, particularly within the domain of deep generative networks, has revolutionized the precision of predictive modeling in this context. Traditional approaches often adopt a two-step strategy: initially estimating interatomic distances and subsequently refining the spatial molecular structure by solving a distance geometry problem. However, this sequential approach occasionally falls short in accurately capturing the intricacies of local atomic arrangements, thereby compromising the fidelity of the resulting structural models. Addressing these limitations, this research introduces a cutting-edge generative framework named \\method{}. This framework is grounded in the principles of diffusion observed in classical non-equilibrium thermodynamics. \\method{} views atoms as discrete entities and excels in guiding the reversal of diffusion, transforming a distribution of stochastic noise back into coherent molecular structures through a process akin to a Markov chain. This transformation commences with the initial representation of a molecular graph in an abstract latent space, culminating in the realization of three-dimensional structures via a sophisticated bilevel optimization scheme meticulously tailored to meet the specific requirements of the task. One of the formidable challenges in this modeling endeavor involves preserving roto-translational invariance to ensure that the generated molecular conformations adhere to the laws of physics. Extensive experimental evaluations confirm the efficacy of the proposed \\method{} in comparison to state-of-the-art methods.",
        "comments": "arXiv admin note: text overlap with arXiv:2105.07246 by other authors",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09451"
    },
    {
        "doc_id": 572,
        "title": "Regenerative Medicine for Tendon/Ligament Injuries: De Novo Equine Tendon/Ligament Neotissue Generation and Application",
        "authors": [
            "Takashi Taguchi"
        ],
        "subjects": [
            "Tissues and Organs"
        ],
        "abstract": "Tendon and ligament injuries are debilitating conditions across species. Poor regenerative capacities of these tissues limit restoration of original functions. The first study of this dissertation evaluated the effect of cellular administration on tendon/ligament injuries in horses using meta-analysis. The findings led to the second study that engineered implantable de novo tendon neotissue using equine adipose-derived multipotent stromal cells and collagen type I. The neotendon was evaluated for its biocompatibility and therapeutic potential in the third study using immunocompetent and immunocompromised rat bilateral calcaneal tendon elongation model. The fourth study investigated the therapeutic effects of neotendon in surgically-induced non-terminal equine accessory ligament of deep digital flexor tendon injury model.",
        "comments": " ",
        "date": "24 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09423"
    },
    {
        "doc_id": 573,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 574,
        "title": "Graph-based vulnerability assessment of resting-state functional brain networks in full-term neonates",
        "authors": [
            "Mahshid Fouladivanda",
            "Kamran Kazemi",
            "Habibollah Danyali",
            "Ardalan Aarabi"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Quantitative Methods"
        ],
        "abstract": "Network disruption during early brain development can result in long-term cognitive impairments. In this study, we investigated rich-club organization in resting-state functional brain networks in full-term neonates using a multiscale connectivity analysis. We further identified the most influential nodes, also called spreaders, having higher impacts on the flow of information throughout the network. The network vulnerability to damage to rich-club (RC) connectivity within and between resting-state networks was also assessed using a graph-based vulnerability analysis. Our results revealed a rich club organization and small-world topology for resting-state functional brain networks in full term neonates, regardless of the network size. Interconnected mostly through short-range connections, functional rich-club hubs were confined to sensory-motor, cognitive-attention-salience (CAS), default mode, and language-auditory networks with an average cross-scale overlap of 36%, 20%, 15% and 12%, respectively. The majority of the functional hubs also showed high spreading potential, except for several non-RC spreaders within CAS and temporal networks. The functional networks exhibited high vulnerability to loss of RC nodes within sensorimotor cortices, resulting in a significant increase and decrease in network segregation and integration, respectively. The network vulnerability to damage to RC nodes within the language-auditory, cognitive-attention-salience, and default mode networks was also significant but relatively less prominent. Our findings suggest that the network integration in neonates can be highly compromised by damage to RC connectivity due to brain immaturity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09255"
    },
    {
        "doc_id": 575,
        "title": "Reproducibility via neural fields of visual illusions induced by localized stimuli",
        "authors": [
            "Cyprien Tamekue",
            "Dario Prandi",
            "Yacine Chitour"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Pattern Formation and Solitons"
        ],
        "abstract": "This paper investigates the replication of experiments by Billock and Tsou [PNAS, 2007] using the controllability of neural fields of Amari-type modelling the cortical activity in the primary visual cortex (V1), focusing on a regular funnel pattern localised in the fovea or the peripheral visual field. The aim is to understand and model the visual phenomena observed in these experiments, emphasising their nonlinear nature. The study involves designing sensory inputs simulating the visual stimuli from Billock and Tsou's experiments. The after-images induced by these inputs are then theoretically and numerically studied to determine their capacity to replicate the experimentally observed visual effects. A key aspect of this research is investigating the effects induced by the nonlinear nature of neural responses. In particular, by highlighting the importance of both excitatory and inhibitory neurons in the emergence of certain visual phenomena, this study suggests that an interplay of both types of neuronal activities plays an essential role in visual processes, challenging the assumption that the latter is mainly driven by excitatory activities alone.",
        "comments": "MSC Class:          92C20; 35B36; 45A05; 45G15; 45K05; 65R20",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09108"
    },
    {
        "doc_id": 576,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 577,
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "authors": [
            "Ziyang Yu",
            "Wenbing Huang",
            "Yang Liu"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08986"
    },
    {
        "doc_id": 578,
        "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
        "authors": [
            "Zahra Sheikhbahaee",
            "Adam Safron",
            "Casper Hesp",
            "Guillaume Dumas"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08873"
    },
    {
        "doc_id": 579,
        "title": "Using i-vectors for subject-independent cross-session EEG transfer learning",
        "authors": [
            "Jonathan Lasko",
            "Jeff Ma",
            "Mike Nicoletti",
            "Jonathan Sussman-Fort",
            "Sooyoung Jeong",
            "William Hartmann"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Cognitive load classification is the task of automatically determining an individual's utilization of working memory resources during performance of a task based on physiologic measures such as electroencephalography (EEG). In this paper, we follow a cross-disciplinary approach, where tools and methodologies from speech processing are used to tackle this problem. The corpus we use was released publicly in 2021 as part of the first passive brain-computer interface competition on cross-session workload estimation. We present our approach which used i-vector-based neural network classifiers to accomplish inter-subject cross-session EEG transfer learning, achieving 18% relative improvement over equivalent subject-dependent models. We also report experiments showing how our subject-independent models perform competitively on held-out subjects and improve with additional subject data, suggesting that subject-dependent training is not required for effective cognitive load determination.",
        "comments": "11 pages",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08851"
    },
    {
        "doc_id": 580,
        "title": "On the maximum value of the stairs2 index",
        "authors": [
            "Bryan Currie",
            "Kristina Wicke"
        ],
        "subjects": [
            "Combinatorics",
            "Populations and Evolution"
        ],
        "abstract": "Measures of tree balance play an important role in different research areas such as mathematical phylogenetics or theoretical computer science. The balance of a tree is usually quantified in a single number, called a balance or imbalance index, and several such indices exist in the literature. Here, we focus on the stairs2 balance index for rooted binary trees, which was first introduced in the context of viral phylogenetics but has not been fully analyzed from a mathematical viewpoint yet. While it is known that the caterpillar tree uniquely minimizes the stairs2 index for all leaf numbers and the fully balanced tree uniquely maximizes the stairs2 index for leaf numbers that are powers of two, understanding the maximum value and maximal trees for arbitrary leaf numbers is an open problem in the literature. In this note, we fill this gap by showing that for all leaf numbers, there is a unique rooted binary tree maximizing the stairs2 index. Additionally, we obtain recursive and closed expressions for the maximum value of the stairs2 index of a rooted binary tree with $n$ leaves.",
        "comments": "12 pages, 1 figure",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08838"
    },
    {
        "doc_id": 581,
        "title": "Mechanical constraints and cell cycle regulation in models of collective cell migration",
        "authors": [
            "Carles Falc\u00f3",
            "Daniel J. Cohen",
            "Jos\u00e9 A. Carrillo",
            "Ruth E. Baker"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biological Physics"
        ],
        "abstract": "The spatiotemporal coordination and regulation of cell proliferation is fundamental in many aspects of development and tissue maintenance. Cells have the ability to adapt their division rates in response to mechanical checkpoints, yet we do not fully understand how cell proliferation regulation impacts cell migration phenomena. Here, we present a minimal continuum model of cell migration with cell cycle dynamics, which includes mechanical constraints and hence can account for cell proliferation regulation. By combining minimal mathematical modelling, Bayesian inference, and recent experimental data, we quantify the impact of mechanical constraints across different cell cycle stages in epithelial tissue expansion experiments. Our model suggests that cells sense local density and adapt cell cycle progression in response, during G1 and the combined S/G2/M phases, providing an explicit relationship between each cell cycle stage duration and local tissue density, which is consistent with several experimental observations. Finally, we compare our mathematical model predictions to different experiments studying cell cycle regulation and present a quantitative analysis on the impact of mechanical constraints on cell migration patterns. Our work presents a systematic approach for investigating and analysing cell cycle data, providing mechanistic insights into how individual cells regulate proliferation, based on population-based experimental measurements.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08805"
    },
    {
        "doc_id": 582,
        "title": "Machine Learning-Based Analysis of Ebola Virus' Impact on Gene Expression in Nonhuman Primates",
        "authors": [
            "Mostafa Rezapour",
            "Muhammad Khalid Khan Niazi",
            "Hao Lu",
            "Aarthi Narayanan",
            "Metin Nafi Gurcan"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "This study introduces the Supervised Magnitude-Altitude Scoring (SMAS) methodology, a machine learning-based approach, for analyzing gene expression data obtained from nonhuman primates (NHPs) infected with Ebola virus (EBOV). We utilize a comprehensive dataset of NanoString gene expression profiles from Ebola-infected NHPs, deploying the SMAS system for nuanced host-pathogen interaction analysis. SMAS effectively combines gene selection based on statistical significance and expression changes, employing linear classifiers such as logistic regression to accurately differentiate between RT-qPCR positive and negative NHP samples. A key finding of our research is the identification of IFI6 and IFI27 as critical biomarkers, demonstrating exceptional predictive performance with 100% accuracy and Area Under the Curve (AUC) metrics in classifying various stages of Ebola infection. Alongside IFI6 and IFI27, genes, including MX1, OAS1, and ISG15, were significantly upregulated, highlighting their essential roles in the immune response to EBOV. Our results underscore the efficacy of the SMAS method in revealing complex genetic interactions and response mechanisms during EBOV infection. This research provides valuable insights into EBOV pathogenesis and aids in developing more precise diagnostic tools and therapeutic strategies to address EBOV infection in particular and viral infection in general.",
        "comments": "28 pages, 8 figures, 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08738"
    },
    {
        "doc_id": 583,
        "title": "Survival Analysis of Young Triple-Negative Breast Cancer Patients",
        "authors": [
            "M. Mehdi Owrang O",
            "Fariba Jafari Horestani",
            "Ginger Schwarz"
        ],
        "subjects": [
            "Quantitative Methods",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "Breast cancer prognosis is crucial for effective treatment, with the disease more common in women over 40 years old but rare under 40 years old, where less than 5 percent of cases occur in the U.S. Studies indicate a worse prognosis in younger women, which varies by ethnicity. Breast cancers are classified based on receptors like estrogen, progesterone, and HER2. Triple-negative breast cancer (TNBC), lacking these receptors, accounts for about 15 percent of cases and is more prevalent in younger patients, often resulting in poorer outcomes. Nevertheless, the impact of age on TNBC prognosis remains unclear. Factors like age, race, tumor grade, size, and lymph node status are studied for their role in TNBC's clinical outcomes, but current research is inconclusive about age-related differences. This study uses SEER data set to examine the influence of younger age on survivability in TNBC patients, aiming to determine if age is a significant prognostic factor. Our experimental results on SEER dataset confirm the existing research reports that TNBC patients have worse prognosis compared to non-TNBC based on age. Our main goal was to investigate whether younger age has any significance on the survivability of TNBC patients. Experimental results do not show that younger age has any significance on the prognosis and survival rate of the TNBC patients",
        "comments": "31 Pages, 11 Figures, 7 Tables, Peer-reviewed article",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08712"
    },
    {
        "doc_id": 584,
        "title": "On Image Search in Histopathology",
        "authors": [
            "H. R. Tizhoosh",
            "Liron Pantanowitz"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Quantitative Methods"
        ],
        "abstract": "Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for nuanced quantification of cellular structures across diverse tissue types, facilitating comparisons and enabling inferences about diagnosis, prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08699"
    },
    {
        "doc_id": 585,
        "title": "Concept Alignment",
        "authors": [
            "Sunayana Rane",
            "Polyphony J. Bruna",
            "Ilia Sucholutsky",
            "Christopher Kello",
            "Thomas L. Griffiths"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Neurons and Cognition"
        ],
        "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has focused on value alignment, broadly referring to creating AI systems that share human values. We argue that before we can even attempt to align values, it is imperative that AI systems and humans align the concepts they use to understand the world. We integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. We summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. Finally, we explain how we can leverage the tools already being developed in cognitive science and AI research to accelerate progress towards concept alignment.",
        "comments": "NeurIPS MP2 Workshop 2023",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08672"
    },
    {
        "doc_id": 586,
        "title": "Validation and Comparison of Non-Stationary Cognitive Models: A Diffusion Model Application",
        "authors": [
            "Lukas Schumacher",
            "Martin Schnuerch",
            "Andreas Voss",
            "Stefan T. Radev"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "Cognitive processes undergo various fluctuations and transient states across different temporal scales. Superstatistics are emerging as a flexible framework for incorporating such non-stationary dynamics into existing cognitive model classes. In this work, we provide the first experimental validation of superstatistics and formal comparison of four non-stationary diffusion decision models in a specifically designed perceptual decision-making task. Task difficulty and speed-accuracy trade-off were systematically manipulated to induce expected changes in model parameters. To validate our models, we assess whether the inferred parameter trajectories align with the patterns and sequences of the experimental manipulations. To address computational challenges, we present novel deep learning techniques for amortized Bayesian estimation and comparison of models with time-varying parameters. Our findings indicate that transition models incorporating both gradual and abrupt parameter shifts provide the best fit to the empirical data. Moreover, we find that the inferred parameter trajectories closely mirror the sequence of experimental manipulations. Posterior re-simulations further underscore the ability of the models to faithfully reproduce critical data patterns. Accordingly, our results suggest that the inferred non-stationary dynamics may reflect actual changes in the targeted psychological constructs. We argue that our initial experimental validation paves the way for the widespread application of superstatistics in cognitive modeling and beyond.",
        "comments": " ",
        "date": "7 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08626"
    },
    {
        "doc_id": 587,
        "title": "Dynamic Brain Behaviours in Stroke: A Longitudinal Investigation Based on fMRI Analysis",
        "authors": [
            "Kaichao Wu",
            "Beth Jelfs",
            "Katrina Neville",
            "Qiang Fang"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Background: The brain's functional network constantly adapts to external changes. However, the mechanisms underlying this dynamic adaptive behavior in stroke patients with motor injuries and its role in post-stroke motor recovery remain poorly understood.\n  Method: This study conducted a long-term investigation involving 15 first-stroke patients. Each participant underwent five fMRI scans distributed equally over a six-month period. Using functional neuroimaging data, time-varying functional modularity in post-stroke patients was detected, and subsequently, the dynamic brain behaviors, including recruitment, integration, and flexibility, along with their longitudinal changes, were assessed.\n  Results: Our findings reveal that stroke lesions lead to significant and enduring alterations in all three dynamic behaviors within functional brain networks. Furthermore, during the six-month recovery period, patients who exhibited good and poor recovery showed notable differences in recruitment and flexibility, indicating distinct recovery trajectories for these groups. Notably, when predicting post-stroke recovery status, whole-brain recruitment emerged as a robust and reliable feature, achieving an AUC of 85.93\n  Significance: Our study offers a comprehensive depiction of dynamic brain behavior in the post-ischemic-stroke brain, with a focus on longitudinal changes concurrent with functional recovery. These dynamic patterns hold promise as valuable tools for evaluating and predicting motor recovery following stroke.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08607"
    },
    {
        "doc_id": 588,
        "title": "Long cycles in linear thresholding systems",
        "authors": [
            "Anna Laddach",
            "Michael Shapiro"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Linear thresholding systems have been used as a model of neural activation and more recently proposed as a model of gene regulation. Here we exhibit linear thresholding systems whose dynamics produce surprisingly long cycles.",
        "comments": "3 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08605"
    },
    {
        "doc_id": 589,
        "title": "From Conceptual Spaces to Quantum Concepts: Formalising and Learning Structured Conceptual Models",
        "authors": [
            "Sean Tull",
            "Razin A. Shaikh",
            "Sara Sabrina Zemljic",
            "Stephen Clark"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence",
            "Quantum Physics"
        ],
        "abstract": "In this article we present a new modelling framework for structured concepts using a category-theoretic generalisation of conceptual spaces, and show how the conceptual representations can be learned automatically from data, using two very different instantiations: one classical and one quantum. A contribution of the work is a thorough category-theoretic formalisation of our framework. We claim that the use of category theory, and in particular the use of string diagrams to describe quantum processes, helps elucidate some of the most important features of our approach. We build upon Gardenfors' classical framework of conceptual spaces, in which cognition is modelled geometrically through the use of convex spaces, which in turn factorise in terms of simpler spaces called domains. We show how concepts from the domains of shape, colour, size and position can be learned from images of simple shapes, where concepts are represented as Gaussians in the classical implementation, and quantum effects in the quantum one. In the classical case we develop a new model which is inspired by the Beta-VAE model of concepts, but is designed to be more closely connected with language, so that the names of concepts form part of the graphical model. In the quantum case, concepts are learned by a hybrid classical-quantum network trained to perform concept classification, where the classical image processing is carried out by a convolutional neural network and the quantum representations are produced by a parameterised quantum circuit. Finally, we consider the question of whether our quantum models of concepts can be considered conceptual spaces in the Gardenfors sense.",
        "comments": "This article consolidates our previous reports on concept formalisation and learning: arXiv:2302.14822 and arXiv:2203.11216",
        "date": "6 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08585"
    },
    {
        "doc_id": 590,
        "title": "How cytoskeletal crosstalk makes cells move: bridging cell-free and cell studies",
        "authors": [
            "James P. Conboy",
            "Irene Ist\u00fariz Petitjean",
            "Anouk van der Net",
            "Gijsje H. Koenderink"
        ],
        "subjects": [
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "Cell migration is a fundamental process for life and is highly dependent on the dynamical and mechanical properties of the cytoskeleton. Intensive physical and biochemical crosstalk between actin, microtubules, and intermediate filaments ensures their coordination to facilitate and enable migration. In this review we discuss the different mechanical aspects that govern cell migration and provide, for each mechanical aspect, a novel perspective by juxtaposing two complementary approaches to the biophysical study of cytoskeletal crosstalk: live-cell studies (often referred to as top-down studies) and cell-free studies (often referred to as bottom-up studies). We summarize the main findings from both experimental approaches, and we provide our perspective on bridging the two perspectives to address the open questions of how cytoskeletal crosstalk governs cell migration and makes cells move.",
        "comments": "4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08368"
    },
    {
        "doc_id": 591,
        "title": "dabih -- encrypted data storage and sharing platform",
        "authors": [
            "Michael Huttner",
            "Jakob Simeth",
            "Renato Liguori",
            "Fulvia Ferrazzi",
            "Rainer Spang"
        ],
        "subjects": [
            "Cryptography and Security",
            "Software Engineering",
            "Genomics"
        ],
        "abstract": "Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research. Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges.\n  Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management. dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format. Its approach to data security involves a two-stage envelope encryption process. We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism. The private key necessary for decrypting the data remains exclusively on the owner's device. Thus, accessing data is impossible without explicit permission from the keyholder.\n  Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries. Documentation is available as part of the web application.\n  Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions. All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files.",
        "comments": "16 pages including 4 figures and 5 appendices",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08333"
    },
    {
        "doc_id": 592,
        "title": "Multifractal organization of EEG signals in Multiple Sclerosis",
        "authors": [
            "Marcin W\u0105torek",
            "Wojciech Tomczyk",
            "Magda Gaw\u0142owska",
            "Natalia Golonka-Afek",
            "Aleksandra \u017byrkowska",
            "Monika Marona",
            "Marcin Wnuk",
            "Agnieszka S\u0142owik",
            "Jeremi K. Ochab",
            "Magdalena Fafrowicz",
            "Tadeusz Marek",
            "Pawe\u0142 O\u015bwi\u0119cimka"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Disordered Systems and Neural Networks",
            "Adaptation and Self-Organizing Systems",
            "Quantitative Methods"
        ],
        "abstract": "Quantifying the complex/multifractal organization of the brain signals is crucial to fully understanding the brain processes and structure. In this contribution, we performed the multifractal analysis of the electroencephalographic (EEG) data obtained from a controlled multiple sclerosis (MS) study, focusing on the correlation between the degree of multifractality, disease duration, and disability level. Our results reveal a significant correspondence between the complexity of the time series and multiple sclerosis development, quantified respectively by scaling exponents and the Expanded Disability Status Scale (EDSS). Namely, for some brain regions, a well-developed multifractality and little persistence of the time series were identified in patients with a high level of disability, whereas the control group and patients with low EDSS were characterised by persistence and monofractality of the signals. The analysis of the cross-correlations between EEG signals supported these results, with the most significant differences identified for patients with EDSS $> 1$ and the combined group of patients with EDSS $\\leq 1$ and controls. No association between the multifractality and disease duration was observed, indicating that the multifractal organisation of the data is a hallmark of developing the disease. The observed complexity/multifractality of EEG signals is hypothetically a result of neuronal compensation -- i.e., of optimizing neural processes in the presence of structural brain degeneration. The presented study is highly relevant due to the multifractal formalism used to quantify complexity and due to scarce resting-state EEG evidence for cortical reorganization associated with compensation.",
        "comments": "39 pages, including supplementary materials (11 figures, 4 tables)",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08321"
    },
    {
        "doc_id": 593,
        "title": "Sources of HIV infections among MSM with a migration background: a viral phylogenetic case study in Amsterdam, the Netherlands",
        "authors": [
            "Alexandra Blenkinsop",
            "Nikos Pantazis",
            "Evangelia Georgia Kostaki",
            "Lysandros Sofocleous",
            "Ard van Sighem",
            "Daniela Bezemer",
            "Thijs van de Laar",
            "Marc van der Valk",
            "Peter Reiss",
            "Godelieve de Bree",
            "Oliver Ratmann"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Background: Men and women with a migration background comprise an increasing proportion of incident HIV cases across Western Europe. Several studies indicate a substantial proportion acquire HIV post-migration.\n  Methods: We used partial HIV consensus sequences with linked demographic and clinical data from the opt-out ATHENA cohort of people with HIV in the Netherlands to quantify population-level sources of transmission to Dutch-born and foreign-born Amsterdam men who have sex with men (MSM) between 2010-2021. We identified phylogenetically and epidemiologically possible transmission pairs in local transmission chains and interpreted these in the context of estimated infection dates, quantifying transmission dynamics between sub-populations by world region of birth.\n  Results: We estimate the majority of Amsterdam MSM who acquired their infection locally had a Dutch-born Amsterdam MSM source (56% [53-58%]). Dutch-born MSM were the predominant source population of infections among almost all foreign-born Amsterdam MSM sub-populations. Stratifying by two-year intervals indicated shifts in transmission dynamics, with a majority of infections originating from foreign-born MSM since 2018, although uncertainty ranges remained wide.\n  Conclusions: In the context of declining HIV incidence among Amsterdam MSM, our data suggest whilst native-born MSM have predominantly driven transmissions in 2010-2021, the contribution from foreign-born MSM living in Amsterdam is increasing.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08308"
    },
    {
        "doc_id": 594,
        "title": "Attention-Based CNN-BiLSTM for Sleep State Classification of Spatiotemporal Wide-Field Calcium Imaging Data",
        "authors": [
            "Xiaohui Zhang",
            "Eric C. Landsness",
            "Hanyang Miao",
            "Wei Chen",
            "Michelle Tang",
            "Lindsey M. Brier",
            "Joseph P. Culver",
            "Jin-Moo Lee",
            "Mark A. Anastasio"
        ],
        "subjects": [
            "Image and Video Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Background: Wide-field calcium imaging (WFCI) with genetically encoded calcium indicators allows for spatiotemporal recordings of neuronal activity in mice. When applied to the study of sleep, WFCI data are manually scored into the sleep states of wakefulness, non-REM (NREM) and REM by use of adjunct EEG and EMG recordings. However, this process is time-consuming, invasive and often suffers from low inter- and intra-rater reliability. Therefore, an automated sleep state classification method that operates on spatiotemporal WFCI data is desired. New Method: A hybrid network architecture consisting of a convolutional neural network (CNN) to extract spatial features of image frames and a bidirectional long short-term memory network (BiLSTM) with attention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Results: Sleep states were classified with an accuracy of 84% and Cohen's kappa of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while posterior area contributes most to the identification of wakefulness. The attention scores indicated that the proposed network focuses on short- and long-range temporal dependency in a state-specific manner. Comparison with Existing Method: On a 3-hour WFCI recording, the CNN-BiLSTM achieved a kappa of 0.67, comparable to a kappa of 0.65 corresponding to the human EEG/EMG-based scoring. Conclusions: The CNN-BiLSTM effectively classifies sleep states from spatiotemporal WFCI data and will enable broader application of WFCI in sleep.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08098"
    },
    {
        "doc_id": 595,
        "title": "A new model of trust based on neural information processing",
        "authors": [
            "Scott E. Allen",
            "Ren\u00e9 F. Kizilcec",
            "A. David Redish"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction",
            "Neurons and Cognition"
        ],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08064"
    },
    {
        "doc_id": 596,
        "title": "Understanding YTHDF2-mediated mRNA Degradation By m6A-BERT-Deg",
        "authors": [
            "Ting-He Zhang",
            "Sumin Jo",
            "Michelle Zhang",
            "Kai Wang",
            "Shou-Jiang Gao",
            "Yufei Huang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "N6-methyladenosine (m6A) is the most abundant mRNA modification within mammalian cells, holding pivotal significance in the regulation of mRNA stability, translation, and splicing. Furthermore, it plays a critical role in the regulation of RNA degradation by primarily recruiting the YTHDF2 reader protein. However, the selective regulation of mRNA decay of the m6A-methylated mRNA through YTHDF2 binding is poorly understood. To improve our understanding, we developed m6A-BERT-Deg, a BERT model adapted for predicting YTHDF2-mediated degradation of m6A-methylated mRNAs. We meticulously assembled a high-quality training dataset by integrating multiple data sources for the HeLa cell line. To overcome the limitation of small training samples, we employed a pre-training-fine-tuning strategy by first performing a self-supervised pre-training of the model on 427,760 unlabeled m6A site sequences. The test results demonstrated the importance of this pre-training strategy in enabling m6A-BERT-Deg to outperform other benchmark models. We further conducted a comprehensive model interpretation and revealed a surprising finding that the presence of co-factors in proximity to m6A sites may disrupt YTHDF2-mediated mRNA degradation, subsequently enhancing mRNA stability. We also extended our analyses to the HEK293 cell line, shedding light on the context-dependent YTHDF2-mediated mRNA degradation.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08004"
    },
    {
        "doc_id": 597,
        "title": "Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series Clustering",
        "authors": [
            "Hamid Ghaderi",
            "Brandon Foreman",
            "Chandan K. Reddy",
            "Vignesh Subbian"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses. While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap. Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates. Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets. Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets. Our analysis revealed three generalizable TBI phenotypes (\u03b1, \\b{eta}, and \u03b3), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays. Specifically, phenotype \u03b1 represents mild TBI with a remarkably consistent clinical presentation. In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype \u03b3 represents a moderate TBI profile in terms of severity and clinical diversity. Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates. Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations.",
        "comments": "25 pages, 10 figures, 4 tables, submitted to Computers in Biology and Medicine",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08002"
    },
    {
        "doc_id": 598,
        "title": "Integrate Any Omics: Towards genome-wide data integration for patient stratification",
        "authors": [
            "Shihao Ma",
            "Andy G. X. Zeng",
            "Benjamin Haibe-Kains",
            "Anna Goldenberg",
            "John E Dick",
            "Bo Wang"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "High-throughput omics profiling advancements have greatly enhanced cancer patient stratification. However, incomplete data in multi-omics integration presents a significant challenge, as traditional methods like sample exclusion or imputation often compromise biological diversity and dependencies. Furthermore, the critical task of accurately classifying new patients with partial omics data into existing subtypes is commonly overlooked. To address these issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised framework for integrating incomplete multi-omics data and classifying new samples. IntegrAO first combines partially overlapping patient graphs from diverse omics sources and utilizes graph neural networks to produce unified patient embeddings. Our systematic evaluation across five cancer cohorts involving six omics modalities demonstrates IntegrAO's robustness to missing data and its accuracy in classifying new samples with partial profiles. An acute myeloid leukemia case study further validates its capability to uncover biological and clinical heterogeneity in incomplete datasets. IntegrAO's ability to handle heterogeneous and incomplete data makes it an essential tool for precision oncology, offering a holistic approach to patient characterization.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07937"
    },
    {
        "doc_id": 599,
        "title": "Predicting heteropolymer interactions: demixing and hypermixing of disordered protein sequences",
        "authors": [
            "Kyosuke Adachi",
            "Kyogo Kawaguchi"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Cells contain multiple condensates which spontaneously form due to the heterotypic interactions between their components. Although the proteins and disordered region sequences that are responsible for condensate formation have been extensively studied, the rule of interactions between the components that allow demixing, i.e., the coexistence of multiple condensates, is yet to be elucidated. Here we construct an effective theory of the interaction between heteropolymers by fitting it to the molecular dynamics simulation results obtained for more than 200 sequences sampled from the disordered regions of human proteins. We find that the sum of amino acid pair interactions across two heteropolymers predicts the Boyle temperature qualitatively well, which can be quantitatively improved by the dimer pair approximation, where we incorporate the effect of neighboring amino acids in the sequences. The improved theory, combined with the finding of a metric that captures the effective interaction strength between distinct sequences, allowed the selection of up to three disordered region sequences that demix with each other in multicomponent simulations, as well as the generation of artificial sequences that demix with a given sequence. The theory points to a generic sequence design strategy to demix or hypermix thanks to the low dimensional nature of the space of the interactions that we identify. As a consequence of the geometric arguments in the space of interactions, we find that the number of distinct sequences that can demix with each other is strongly constrained, irrespective of the choice of the coarse-grained model. Altogether, we construct a theoretical basis for methods to estimate the effective interaction between heteropolymers, which can be utilized in predicting phase separation properties as well as rules of assignment in the localization and functions of disordered proteins.",
        "comments": "20 pages, 21 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07826"
    }
]