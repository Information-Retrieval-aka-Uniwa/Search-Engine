[
    {
        "doc_id": 0,
        "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies",
        "authors": [
            "Salma M. Elsherif",
            "Mohamad H. Kazma",
            "Ahmad F. Taha"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The operation of water distribution networks is a complex procedure aimed at efficiently delivering consumers with adequate water quantity while ensuring its safe quality. An added challenge is the dependency of the water quality dynamics on the system's hydraulics, which influences the performance of the water quality controller. Prior research has addressed either solving the optimum operational hydraulic setting problem or regulating the water quality dynamics as separate problems. Additionally, there have been efforts to couple these two problems and solve one compact problem resulting in trade-offs between the contradictory objectives. In contrast, this paper examines the dependency and influence from a control-theoretic standpoint. More specifically, we explore the influence of accountability for water quality controllability improvement when addressing the pump scheduling problem. We examine its effects on the cumulative cost of the interconnected systems as well as the subsequent performance of the water quality controller. To achieve this, we develop a framework that incorporates different controllability metrics within the operational hydraulic optimization problem; its aim is attaining an adequate level of water quality control across the system. We assess the aforementioned aspects' performance on various scaled networks with a wide range of numerical scenarios.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12214"
    },
    {
        "doc_id": 1,
        "title": "Programmable EM Sensor Array for Golden-Model Free Run-time Trojan Detection and Localization",
        "authors": [
            "Hanqiu Wang",
            "Max Panoff",
            "Zihao Zhan",
            "Shuo Wang",
            "Christophe Bobda",
            "Domenic Forte"
        ],
        "subjects": [
            "Cryptography and Security",
            "Signal Processing"
        ],
        "abstract": "Side-channel analysis has been proven effective at detecting hardware Trojans in integrated circuits (ICs). However, most detection techniques rely on large external probes and antennas for data collection and require a long measurement time to detect Trojans. Such limitations make these techniques impractical for run-time deployment and ineffective in detecting small Trojans with subtle side-channel signatures. To overcome these challenges, we propose a Programmable Sensor Array (PSA) for run-time hardware Trojan detection, localization, and identification. PSA is a tampering-resilient integrated on-chip magnetic field sensor array that can be re-programmed to change the sensors' shape, size, and location. Using PSA, EM side-channel measurement results collected from sensors at different locations on an IC can be analyzed to localize and identify the Trojan. The PSA has better performance than conventional external magnetic probes and state-of-the-art on-chip single-coil magnetic field sensors. We fabricated an AES-128 test chip with four AES Hardware Trojans. They were successfully detected, located, and identified with the proposed on-chip PSA within 10 milliseconds using our proposed cross-domain analysis.",
        "comments": "6 pages, 5 figures, Accepted at DATE2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12193"
    },
    {
        "doc_id": 2,
        "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
        "authors": [
            "Zachary Novack",
            "Julian McAuley",
            "Taylor Berg-Kirkpatrick",
            "Nicholas J. Bryan"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose frame-work for controlling pre-trained text-to-music diffusion models at inference-time via optimizing initial noise latents. Our method can be used to optimize through any differentiable feature matching loss to achieve a target (stylized) output and leverages gradient checkpointing for memory efficiency. We demonstrate a surprisingly wide-range of applications for music generation including inpainting, outpainting, and looping as well as intensity, melody, and musical structure control - all without ever fine-tuning the underlying model. When we compare our approach against related training, guidance, and optimization-based methods, we find DITTO achieves state-of-the-art performance on nearly all tasks, including outperforming comparable approaches on controllability, audio quality, and computational efficiency, thus opening the door for high-quality, flexible, training-free control of diffusion models. Sound examples can be found at https://DITTO-Music.github.io/web/.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12179"
    },
    {
        "doc_id": 3,
        "title": "Waveform-Domain Complementary Signal Sets for Interrupted Sampling Repeater Jamming Suppression",
        "authors": [
            "Hanning Su",
            "Qinglong Bao",
            "Jiameng Pan",
            "Fucheng Guo",
            "Weidong Hu"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The interrupted-sampling repeater jamming (ISRJ) is coherent and has the characteristic of suppression and deception to degrade the radar detection capabilities. The study focuses on anti-ISRJ techniques in the waveform domain, primarily capitalizing on waveform design and and anti-jamming signal processing methods in the waveform domain. By exploring the relationship between waveform-domain adaptive matched filtering (WD-AMF) output and waveform-domain signals, we demonstrate that ISRJ can be effectively suppressed when the transmitted waveform exhibits waveform-domain complementarity. We introduce a phase-coded (PC) waveform set with waveform-domain complementarity and propose a method for generating such waveform sets of arbitrary code lengths. The performance of WD-AMF are further developed due to the designed waveforms, and simulations affirm the superior adaptive anti-jamming capabilities of the designed waveforms compared to traditional ones. Remarkably, this improved performance is achieved without the need for prior knowledge of ISRJ interference parameters at either the transmitter or receiver stages.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12173"
    },
    {
        "doc_id": 4,
        "title": "Robust stability analysis of an energy-efficient control in a Networked Control System with application to Unmanned Ground Vehicles",
        "authors": [
            "Antonio Gonzalez",
            "Angel Cuenca",
            "Julian Salt",
            "Jelle Jacobs"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "In this paper, the robust stability and disturbance rejection performance analysis of an energy-efficient control is addressed in the framework of Networked Control System (NCS). The control scheme under study integrates periodic event-triggered control, packet-based control, time-varying Kalman filter, dual-rate control and prediction techniques, whose design is aimed at reducing energy consumption and bandwidth usage. The robust stability against time-varying model uncertainties is analyzed by means of a suficient condition based on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the proposed approach is experimentally validated in a tracking control for an Unmanned Ground Vehicle (UGV), which is a battery-constrained mobile device with limited computation capacities.",
        "comments": "38 pages, 12 figures, Information Sciences, 2021",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12172"
    },
    {
        "doc_id": 5,
        "title": "Dynamic Semantic Compression for CNN Inference in Multi-access Edge Computing: A Graph Reinforcement Learning-based Autoencoder",
        "authors": [
            "Nan Li",
            "Alexandros Iosifidis",
            "Qi Zhang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "This paper studies the computational offloading of CNN inference in dynamic multi-access edge computing (MEC) networks. To address the uncertainties in communication time and computation resource availability, we propose a novel semantic compression method, autoencoder-based CNN architecture (AECNN), for effective semantic extraction and compression in partial offloading. In the semantic encoder, we introduce a feature compression module based on the channel attention mechanism in CNNs, to compress intermediate data by selecting the most informative features. In the semantic decoder, we design a lightweight decoder to reconstruct the intermediate data through learning from the received compressed data to improve accuracy. To effectively trade-off communication, computation, and inference accuracy, we design a reward function and formulate the offloading problem of CNN inference as a maximization problem with the goal of maximizing the average inference accuracy and throughput over the long term. To address this maximization problem, we propose a graph reinforcement learning-based AECNN (GRL-AECNN) method, which outperforms existing works DROO-AECNN, GRL-BottleNet++ and GRL-DeepJSCC under different dynamic scenarios. This highlights the advantages of GRL-AECNN in offloading decision-making in dynamic MEC.",
        "comments": "arXiv admin note: text overlap with arXiv:2211.13745",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12167"
    },
    {
        "doc_id": 6,
        "title": "ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A Generalized Score-based Diffusion Post-filter",
        "authors": [
            "Yi-Chiao Wu",
            "Dejan Markovi\u0107",
            "Steven Krenn",
            "Israel D. Gebru",
            "Alexander Richard"
        ],
        "subjects": [
            "Audio and Speech Processing"
        ],
        "abstract": "Although recent mainstream waveform-domain end-to-end (E2E) neural audio codecs achieve impressive coded audio quality with a very low bitrate, the quality gap between the coded and natural audio is still significant. A generative adversarial network (GAN) training is usually required for these E2E neural codecs because of the difficulty of direct phase modeling. However, such adversarial learning hinders these codecs from preserving the original phase information. To achieve human-level naturalness with a reasonable bitrate, preserve the original phase, and get rid of the tricky and opaque GAN training, we develop a score-based diffusion post-filter (SPF) in the complex spectral domain and combine our previous AudioDec with the SPF to propose ScoreDec, which can be trained using only spectral and score-matching losses. Both the objective and subjective experimental results show that ScoreDec with a 24~kbps bitrate encodes and decodes full-band 48~kHz speech with human-level naturalness and well-preserved phase information.",
        "comments": "5 pages, 3 figures, 2 tables. Proc. ICASSP, 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12160"
    },
    {
        "doc_id": 7,
        "title": "Efficient Resource Allocation and User Association in NOMA-Enabled Vehicular-Aided HetNets with High Altitude Platforms",
        "authors": [
            "Ali Nauman",
            "Mashael Maashi",
            "Hend K. Alkahtani",
            "Fahd N. Al-Wesabi",
            "Nojood O Aljehane",
            "Mohammed Assiri",
            "Sara Saadeldeen Ibrahim",
            "Wali Ullah Khan"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The increasing demand for massive connectivity and high data rates has made the efficient use of existing spectrum resources an increasingly challenging problem. Non-orthogonal multiple access (NOMA) is a potential solution for future heterogeneous networks (HetNets) due to its high capacity and spectrum efficiency. In this study, we analyze an uplink NOMA-enabled vehicular-aided HetNet, where multiple vehicular user equipment (VUEs) share the access link spectrum, and a high-altitude platform (HAP) communicates with roadside units (RSUs) through a backhaul communication link. We propose an improved algorithm for user association that selects VUEs for HAPs based on channel coefficient ratios and terrestrial VUEs based on a caching-state backhaul communication link. The joint optimization problems aim to maximize a utility function that considers VUE transmission rates and cross-tier interference while meeting the constraints of backhaul transmission rates and QoS requirements of each VUE. The joint resource allocation optimization problem consists of three sub-problems: bandwidth allocation, user association, and transmission power allocation. We derive a closed-form solution for bandwidth allocation and solve the transmission power allocation sub-problem iteratively using Taylor expansion to transform a non-convex term into a convex one. Our proposed three-stage iterative algorithm for resource allocation integrates all three sub-problems and is shown to be effective through simulation results. Specifically, the results demonstrate that our solution achieves performance improvements over existing approaches.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12141"
    },
    {
        "doc_id": 8,
        "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
        "authors": [
            "John D. Mayfield",
            "Issam El Naqa"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Image and Video Processing"
        ],
        "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term Memory (LSTM) models were studied to provide sequential relationships for each timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot study, we compared three QCNN-LSTM models for binary classification of MS disability benchmarked against classical neural network architectures. Our hypothesis is that quantum models will provide competitive performance. Methods Matrix Product State (MPS), reverse Multistate Entanglement Renormalization Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM layer to process near-annual MRI data of patients diagnosed with MS. These were benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision Transformer (ViViT). Predicted logits were measured against ground truth labels of each patient's Extended Disability Severity Score (EDSS) using binary cross-entropy loss. Training/validation/holdout testing was partitioned using 5-fold cross validation with a total split of 60:20:20. Levene's test of variance was used to measure statistical difference and Student's t-test for paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively (p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73 and 0.77, respectively (p-value 0.631). Overall variance and mean were not statistically significant (p-value 0.713), however, time to train was significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218, respectively, p-value <0.001). Conclusion QCNN-LSTM models perform competitively to their classical counterparts with greater efficiency in train time. Clinically, these can add value in terms of efficiency to time-dependent deep learning prediction of disease progression based upon medical imaging.",
        "comments": "ACM Class:          I.2.0; I.2.6",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12132"
    },
    {
        "doc_id": 9,
        "title": "Energy-aware Trajectory Optimization for UAV-mounted RIS and Full-duplex Relay",
        "authors": [
            "Dimitrios Tyrovolas",
            "Nikos A. Mitsiou",
            "Thomas G. Boufikos",
            "Prodromos-Vasileios Mekikis",
            "Sotiris A. Tegos",
            "Panagiotis D. Diamantoulakis",
            "Sotiris Ioannidis",
            "Christos K. Liaskos",
            "George K. Karagiannidis"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "In the evolving landscape of sixth-generation (6G) wireless networks, unmanned aerial vehicles (UAVs) have emerged as transformative tools for dynamic and adaptive connectivity. However, dynamically adjusting their position to offer favorable communication channels introduces operational challenges in terms of energy consumption, especially when integrating advanced communication technologies like reconfigurable intelligent surfaces (RISs) and full-duplex relays (FDRs). To this end, by recognizing the pivotal role of UAV mobility, the paper introduces an energy-aware trajectory design for UAV-mounted RISs and UAV-mounted FDRs using the decode and forward (DF) protocol, aiming to maximize the network minimum rate and enhance user fairness, while taking into consideration the available on-board energy. Specifically, this work highlights their distinct energy consumption characteristics and their associated integration challenges by developing appropriate energy consumption models for both UAV-mounted RISs and FDRs that capture the intricate relationship between key factors such as weight, and their operational characteristics. Furthermore, a joint time-division multiple access (TDMA) user scheduling-UAV trajectory optimization problem is formulated, considering the power dynamics of both systems, while assuring that the UAV energy is not depleted mid-air. Finally, simulation results underscore the importance of energy considerations in determining the optimal trajectory and scheduling and provide insights into the performance comparison of UAV-mounted RISs and FDRs in UAV-assisted wireless networks.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12107"
    },
    {
        "doc_id": 10,
        "title": "Consistency Based Unsupervised Self-training For ASR Personalisation",
        "authors": [
            "Jisi Zhang",
            "Vandana Rajan",
            "Haaris Mehmood",
            "David Tuckey",
            "Pablo Peso Parada",
            "Md Asif Jalal",
            "Karthikeyan Saravanan",
            "Gil Ho Lee",
            "Jungin Lee",
            "Seokyeong Jung"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "On-device Automatic Speech Recognition (ASR) models trained on speech data of a large population might underperform for individuals unseen during training. This is due to a domain shift between user data and the original training data, differed by user's speaking characteristics and environmental acoustic conditions. ASR personalisation is a solution that aims to exploit user data to improve model robustness. The majority of ASR personalisation methods assume labelled user data for supervision. Personalisation without any labelled data is challenging due to limited data size and poor quality of recorded audio samples. This work addresses unsupervised personalisation by developing a novel consistency based training method via pseudo-labelling. Our method achieves a relative Word Error Rate Reduction (WERR) of 17.3% on unlabelled training data and 8.1% on held-out data compared to a pre-trained model, and outperforms the current state-of-the art methods.",
        "comments": "Accepted for IEEE ASRU 2023",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12085"
    },
    {
        "doc_id": 11,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Mariam de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 12,
        "title": "Resource-constrained stereo singing voice cancellation",
        "authors": [
            "Clara Borrelli",
            "James Rae",
            "Dogac Basaran",
            "Matt McVicar",
            "Mehrez Souden",
            "Matthias Mauch"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "We study the problem of stereo singing voice cancellation, a subtask of music source separation, whose goal is to estimate an instrumental background from a stereo mix. We explore how to achieve performance similar to large state-of-the-art source separation networks starting from a small, efficient model for real-time speech separation. Such a model is useful when memory and compute are limited and singing voice processing has to run with limited look-ahead. In practice, this is realised by adapting an existing mono model to handle stereo input. Improvements in quality are obtained by tuning model parameters and expanding the training set. Moreover, we highlight the benefits a stereo model brings by introducing a new metric which detects attenuation inconsistencies between channels. Our approach is evaluated using objective offline metrics and a large-scale MUSHRA trial, confirming the effectiveness of our techniques in stringent listening tests.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12068"
    },
    {
        "doc_id": 13,
        "title": "NEUROSEC: FPGA-Based Neuromorphic Audio Security",
        "authors": [
            "Murat Isik",
            "Hiruna Vishwamith",
            "Yusuf Sur",
            "Kayode Inadagbo",
            "I. Can Dikmen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Emerging Technologies",
            "Machine Learning",
            "Neural and Evolutionary Computing",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Neuromorphic systems, inspired by the complexity and functionality of the human brain, have gained interest in academic and industrial attention due to their unparalleled potential across a wide range of applications. While their capabilities herald innovation, it is imperative to underscore that these computational paradigms, analogous to their traditional counterparts, are not impervious to security threats. Although the exploration of neuromorphic methodologies for image and video processing has been rigorously pursued, the realm of neuromorphic audio processing remains in its early stages. Our results highlight the robustness and precision of our FPGA-based neuromorphic system. Specifically, our system showcases a commendable balance between desired signal and background noise, efficient spike rate encoding, and unparalleled resilience against adversarial attacks such as FGSM and PGD. A standout feature of our framework is its detection rate of 94%, which, when compared to other methodologies, underscores its greater capability in identifying and mitigating threats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic computing and hardware security serve many sensor domains in mission-critical and privacy-preserving applications.",
        "comments": "Audio processing, FPGA, Hardware Security, Neuromorphic Computing",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12055"
    },
    {
        "doc_id": 14,
        "title": "Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling",
        "authors": [
            "Bruno Korbar",
            "Jaesung Huh",
            "Andrew Zisserman"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "The goal of this paper is automatic character-aware subtitle generation. Given a video and a minimal amount of metadata, we propose an audio-visual method that generates a full transcript of the dialogue, with precise speech timestamps, and the character speaking identified. The key idea is to first use audio-visual cues to select a set of high-precision audio exemplars for each character, and then use these exemplars to classify all speech segments by speaker identity. Notably, the method does not require face detection or tracking. We evaluate the method over a variety of TV sitcoms, including Seinfeld, Fraiser and Scrubs. We envision this system being useful for the automatic generation of subtitles to improve the accessibility of the vast amount of videos available on modern streaming services. Project page : \\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}",
        "comments": "Accepted for publication in ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12039"
    },
    {
        "doc_id": 15,
        "title": "A Survey of Advances in Optimization Methods for Wireless Communication System Design",
        "authors": [
            "Ya-Feng Liu",
            "Tsung-Hui Chang",
            "Mingyi Hong",
            "Zheyu Wu",
            "Anthony Man-Cho So",
            "Eduard A. Jorswieck",
            "Wei Yu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing",
            "Optimization and Control"
        ],
        "abstract": "Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recent advances in mathematical optimization theory and algorithms, from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing and/or developing suitable optimization algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.",
        "comments": "47 pages, 10 figures, submitted for possible publication",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12025"
    },
    {
        "doc_id": 16,
        "title": "NLCG-Net: A Model-Based Zero-Shot Learning Framework for Undersampled Quantitative MRI Reconstruction",
        "authors": [
            "Xinrui Jiang",
            "Yohan Jun",
            "Jaejin Cho",
            "Mengze Gao",
            "Xingwang Yong",
            "Berkin Bilgic"
        ],
        "subjects": [
            "Image and Video Processing",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Typical quantitative MRI (qMRI) methods estimate parameter maps after image reconstructing, which is prone to biases and error propagation. We propose a Nonlinear Conjugate Gradient (NLCG) optimizer for model-based T2/T1 estimation, which incorporates U-Net regularization trained in a scan-specific manner. This end-to-end method directly estimates qMRI maps from undersampled k-space data using mono-exponential signal modeling with zero-shot scan-specific neural network regularization to enable high fidelity T1 and T2 mapping. T2 and T1 mapping results demonstrate the ability of the proposed NLCG-Net to improve estimation quality compared to subspace reconstruction at high accelerations.",
        "comments": "8 pages, 5 figures, submitted to International Society for Magnetic Resonance in Medicine 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12004"
    },
    {
        "doc_id": 17,
        "title": "Lightweight Protection for Privacy in Offloaded Speech Understanding",
        "authors": [
            "Dongqi Cai",
            "Shangguang Wang",
            "Zeling Zhang",
            "Felix Xiaozhu Lin",
            "Mengwei Xu"
        ],
        "subjects": [
            "Sound",
            "Cryptography and Security",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech is a common input method for mobile embedded devices, but cloud-based speech recognition systems pose privacy risks. Disentanglement-based encoders, designed to safeguard user privacy by filtering sensitive information from speech signals, unfortunately require substantial memory and computational resources, which limits their use in less powerful devices. To overcome this, we introduce a novel system, XXX, optimized for such devices. XXX is built on the insight that speech understanding primarily relies on understanding the entire utterance's long-term dependencies, while privacy concerns are often linked to short-term details. Therefore, XXX focuses on selectively masking these short-term elements, preserving the quality of long-term speech understanding. The core of XXX is an innovative differential mask generator, grounded in interpretable learning, which fine-tunes the masking process. We tested XXX on the STM32H7 microcontroller, assessing its performance in various potential attack scenarios. The results show that XXX maintains speech understanding accuracy and privacy at levels comparable to existing encoders, but with a significant improvement in efficiency, achieving up to 53.3$\\times$ faster processing and a 134.1$\\times$ smaller memory footprint.",
        "comments": "under review",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11983"
    },
    {
        "doc_id": 18,
        "title": "Enhancing Safety in Nonlinear Systems: Design and Stability Analysis of Adaptive Cruise Control",
        "authors": [
            "Fan Yang",
            "Haoqi Li",
            "Maolong Lv",
            "Jiangping Hu",
            "Qingrui Zhou",
            "Bijoy K. Ghosh"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The safety of autonomous driving systems, particularly self-driving vehicles, remains of paramount concern. These systems exhibit affine nonlinear dynamics and face the challenge of executing predefined control tasks while adhering to state and input constraints to mitigate risks. However, achieving safety control within the framework of control input constraints, such as collision avoidance and maintaining system states within secure boundaries, presents challenges due to limited options. In this study, we introduce a novel approach to address safety concerns by transforming safety conditions into control constraints with a relative degree of 1. This transformation is facilitated through the design of control barrier functions, enabling the creation of a safety control system for affine nonlinear networks. Subsequently, we formulate a robust control strategy that incorporates safety protocols and conduct a comprehensive analysis of its stability and reliability. To illustrate the effectiveness of our approach, we apply it to a specific problem involving adaptive cruise control. Through simulations, we validate the efficiency of our model in ensuring safety without compromising control performance. Our approach signifies significant progress in the field, providing a practical solution to enhance safety for autonomous driving systems operating within the context of affine nonlinear dynamics.",
        "comments": "11pages,9figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11961"
    },
    {
        "doc_id": 19,
        "title": "Observation-Guided Meteorological Field Downscaling at Station Scale: A Benchmark and a New Method",
        "authors": [
            "Zili Liu",
            "Hao Chen",
            "Lei Bai",
            "Wenyuan Li",
            "Keyan Chen",
            "Zhengyi Wang",
            "Wanli Ouyang",
            "Zhengxia Zou",
            "Zhenwei Shi"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Image and Video Processing"
        ],
        "abstract": "Downscaling (DS) of meteorological variables involves obtaining high-resolution states from low-resolution meteorological fields and is an important task in weather forecasting. Previous methods based on deep learning treat downscaling as a super-resolution task in computer vision and utilize high-resolution gridded meteorological fields as supervision to improve resolution at specific grid scales. However, this approach has struggled to align with the continuous distribution characteristics of meteorological fields, leading to an inherent systematic bias between the downscaled results and the actual observations at meteorological stations. In this paper, we extend meteorological downscaling to arbitrary scattered station scales, establish a brand new benchmark and dataset, and retrieve meteorological states at any given station location from a coarse-resolution meteorological field. Inspired by data assimilation techniques, we integrate observational data into the downscaling process, providing multi-scale observational priors. Building on this foundation, we propose a new downscaling model based on hypernetwork architecture, namely HyperDS, which efficiently integrates different observational information into the model training, achieving continuous scale modeling of the meteorological field. Through extensive experiments, our proposed method outperforms other specially designed baseline models on multiple surface variables. Notably, the mean squared error (MSE) for wind speed and surface pressure improved by 67% and 19.5% compared to other methods. We will release the dataset and code subsequently.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11960"
    },
    {
        "doc_id": 20,
        "title": "Maximizing Spectral and Energy Efficiency in Multi-user MIMO OFDM Systems with RIS and Hardware Impairment",
        "authors": [
            "Mohammad Soleymani",
            "Ignacio Santamaria",
            "Aydin Sezgin",
            "Eduard Jorswieck"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "An emerging technology to enhance the spectral efficiency (SE) and energy efficiency (EE) of wireless communication systems is reconfigurable intelligent surface (RIS), which is shown to be very powerful in single-carrier systems. However, in multi-user orthogonal frequency division multiplexing (OFDM) systems, RIS may not be as promising as in single-carrier systems since an independent optimization of RIS elements at each sub-carrier is impossible in multi-carrier systems. Thus, this paper investigates the performance of various RIS technologies like regular (reflective and passive), simultaneously transmit and reflect (STAR), and multi-sector beyond diagonal (BD) RIS in multi-user multiple-input multiple-output (MIMO) OFDM broadcast channels (BC). This requires to formulate and solve a joint MIMO precoding and RIS optimization problem. The obtained solution reveals that RIS can significantly improve the system performance even when the number of RIS elements is relatively low. Moreover, we develop resource allocation schemes for STAR-RIS and multi-sector BD-RIS in MIMO OFDM BCs, and show that these RIS technologies can outperform a regular RIS, especially when the regular RIS cannot assist the communications for all the users.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11921"
    },
    {
        "doc_id": 21,
        "title": "A Training-Free Defense Framework for Robust Learned Image Compression",
        "authors": [
            "Myungseo Song",
            "Jinyoung Choi",
            "Bohyung Han"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We study the robustness of learned image compression models against adversarial attacks and present a training-free defense technique based on simple image transform functions. Recent learned image compression models are vulnerable to adversarial attacks that result in poor compression rate, low reconstruction quality, or weird artifacts. To address the limitations, we propose a simple but effective two-way compression algorithm with random input transforms, which is conveniently applicable to existing image compression models. Unlike the na\u00efve approaches, our approach preserves the original rate-distortion performance of the models on clean images. Moreover, the proposed algorithm requires no additional training or modification of existing models, making it more practical. We demonstrate the effectiveness of the proposed techniques through extensive experiments under multiple compression models, evaluation metrics, and attack scenarios.",
        "comments": "10 pages and 14 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11902"
    },
    {
        "doc_id": 22,
        "title": "Fully Differentiable Ray Tracing via Discontinuity Smoothing for Radio Network Optimization",
        "authors": [
            "Jerome Eertmans",
            "Laurent Jacques",
            "Claude Oestges"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Recently, Differentiable Ray Tracing has been successfully applied in the field of wireless communications for learning radio materials or optimizing the transmitter orientation. However, in the frame of gradient based optimization, obstruction of the rays by objects can cause sudden variations in the related objective functions or create entire regions where the gradient is zero. As these issues can dramatically impact convergence, this paper presents a novel Ray Tracing framework that is fully differentiable with respect to any scene parameter, but also provides a loss function continuous everywhere, thanks to specific local smoothing techniques. Previously non-continuous functions are replaced by a smoothing function, that can be exchanged with any function having similar properties. This function is also configurable via a parameter that determines how smooth the approximation should be. The present method is applied on a basic one-transmitter-multi-receiver scenario, and shows that it can successfully find the optimal solution. As a complementary resource, a 2D Python library, DiffeRT2d, is provided in Open Access, with examples and a comprehensive documentation.",
        "comments": "5 pages, 5 figures, accepted at EuCAP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11882"
    },
    {
        "doc_id": 23,
        "title": "A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection",
        "authors": [
            "Yuandi Wu",
            "Brett Sicard",
            "Stephen Andrew Gadsden"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Systems and Control"
        ],
        "abstract": "This study presents a comprehensive overview of PIML techniques in the context of condition monitoring. The central concept driving PIML is the incorporation of known physical laws and constraints into machine learning algorithms, enabling them to learn from available data while remaining consistent with physical principles. Through fusing domain knowledge with data-driven learning, PIML methods offer enhanced accuracy and interpretability in comparison to purely data-driven approaches. In this comprehensive survey, detailed examinations are performed with regard to the methodology by which known physical principles are integrated within machine learning frameworks, as well as their suitability for specific tasks within condition monitoring. Incorporation of physical knowledge into the ML model may be realized in a variety of methods, with each having its unique advantages and drawbacks. The distinct advantages and limitations of each methodology for the integration of physics within data-driven models are detailed, considering factors such as computational efficiency, model interpretability, and generalizability to different systems in condition monitoring and fault detection. Several case studies and works of literature utilizing this emerging concept are presented to demonstrate the efficacy of PIML in condition monitoring applications. From the literature reviewed, the versatility and potential of PIML in condition monitoring may be demonstrated. Novel PIML methods offer an innovative solution for addressing the complexities of condition monitoring and associated challenges. This comprehensive survey helps form the foundation for future work in the field. As the technology continues to advance, PIML is expected to play a crucial role in enhancing maintenance strategies, system reliability, and overall operational efficiency in engineering systems.",
        "comments": "Paper has been submitted for review to the journal Expert Systems with Applications (December 31, 2023). 90 pages, 22 figures, 9 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11860"
    },
    {
        "doc_id": 24,
        "title": "LKFormer: Large Kernel Transformer for Infrared Image Super-Resolution",
        "authors": [
            "Feiwei Qin",
            "Kang Yan",
            "Changmiao Wang",
            "Ruiquan Ge",
            "Yong Peng",
            "Kai Zhang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Given the broad application of infrared technology across diverse fields, there is an increasing emphasis on investigating super-resolution techniques for infrared images within the realm of deep learning. Despite the impressive results of current Transformer-based methods in image super-resolution tasks, their reliance on the self-attentive mechanism intrinsic to the Transformer architecture results in images being treated as one-dimensional sequences, thereby neglecting their inherent two-dimensional structure. Moreover, infrared images exhibit a uniform pixel distribution and a limited gradient range, posing challenges for the model to capture effective feature information. Consequently, we suggest a potent Transformer model, termed Large Kernel Transformer (LKFormer), to address this issue. Specifically, we have designed a Large Kernel Residual Depth-wise Convolutional Attention (LKRDA) module with linear complexity. This mainly employs depth-wise convolution with large kernels to execute non-local feature modeling, thereby substituting the standard self-attentive layer. Additionally, we have devised a novel feed-forward network structure called Gated-Pixel Feed-Forward Network (GPFN) to augment the LKFormer's capacity to manage the information flow within the network. Comprehensive experimental results reveal that our method surpasses the most advanced techniques available, using fewer parameters and yielding considerably superior performance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11859"
    },
    {
        "doc_id": 25,
        "title": "Adversarial speech for voice privacy protection from Personalized Speech generation",
        "authors": [
            "Shihao Chen",
            "Liping Chen",
            "Jie Zhang",
            "KongAik Lee",
            "Zhenhua Ling",
            "Lirong Dai"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "The rapid progress in personalized speech generation technology, including personalized text-to-speech (TTS) and voice conversion (VC), poses a challenge in distinguishing between generated and real speech for human listeners, resulting in an urgent demand in protecting speakers' voices from malicious misuse. In this regard, we propose a speaker protection method based on adversarial attacks. The proposed method perturbs speech signals by minimally altering the original speech while rendering downstream speech generation models unable to accurately generate the voice of the target speaker. For validation, we employ the open-source pre-trained YourTTS model for speech generation and protect the target speaker's speech in the white-box scenario. Automatic speaker verification (ASV) evaluations were carried out on the generated speech as the assessment of the voice protection capability. Our experimental results show that we successfully perturbed the speaker encoder of the YourTTS model using the gradient-based I-FGSM adversarial perturbation method. Furthermore, the adversarial perturbation is effective in preventing the YourTTS model from generating the speech of the target speaker. Audio samples can be found in https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS.",
        "comments": "Accepted by icassp 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11857"
    },
    {
        "doc_id": 26,
        "title": "MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation",
        "authors": [
            "De-Xing Huang",
            "Xiao-Hu Zhou",
            "Xiao-Liang Xie",
            "Shi-Qi Liu",
            "Zhen-Qiu Feng",
            "Mei-Jiang Gui",
            "Hao Li",
            "Tian-Yu Xiang",
            "Xiu-Ling Liu",
            "Zeng-Guang Hou"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Medical image segmentation takes an important position in various clinical applications. Deep learning has emerged as the predominant solution for automated segmentation of volumetric medical images. 2.5D-based segmentation models bridge computational efficiency of 2D-based models and spatial perception capabilities of 3D-based models. However, prevailing 2.5D-based models often treat each slice equally, failing to effectively learn and exploit inter-slice information, resulting in suboptimal segmentation performances. In this paper, a novel Momentum encoder-based inter-slice fusion transformer (MOSformer) is proposed to overcome this issue by leveraging inter-slice information at multi-scale feature maps extracted by different encoders. Specifically, dual encoders are employed to enhance feature distinguishability among different slices. One of the encoders is moving-averaged to maintain the consistency of slice representations. Moreover, an IF-Swin transformer module is developed to fuse inter-slice multi-scale features. The MOSformer is evaluated on three benchmark datasets (Synapse, ACDC, and AMOS), establishing a new state-of-the-art with 85.63%, 92.19%, and 85.43% of DSC, respectively. These promising results indicate its competitiveness in medical image segmentation. Codes and models of MOSformer will be made publicly available upon acceptance.",
        "comments": "Under Review",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11856"
    },
    {
        "doc_id": 27,
        "title": "Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical Federated Learning Approach",
        "authors": [
            "Qiqing Wang",
            "Kaidi Yang"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Systems and Control"
        ],
        "abstract": "This paper proposes a privacy-preserving data fusion method for traffic state estimation (TSE). Unlike existing works that assume all data sources to be accessible by a single trusted party, we explicitly address data privacy concerns that arise in the collaboration and data sharing between multiple data owners, such as municipal authorities (MAs) and mobility providers (MPs). To this end, we propose a novel vertical federated learning (FL) approach, FedTSE, that enables multiple data owners to collaboratively train and apply a TSE model without having to exchange their private data. To enhance the applicability of the proposed FedTSE in common TSE scenarios with limited availability of ground-truth data, we further propose a privacy-preserving physics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models into FL. Real-world data validation shows that the proposed methods can protect privacy while yielding similar accuracy to the oracle method without privacy considerations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11836"
    },
    {
        "doc_id": 28,
        "title": "Intelligibility Enhancement of Acoustic Noisy Speech for Autism Spectrum Disorder Condition",
        "authors": [
            "M. Pillonetto",
            "A. Queiroz",
            "R. Coelho"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "This work introduces a time domain personalized method (pGTFF0) to achieve intelligibility improvement of noisy speech for Autism Spectrum Disorder (ASD) situation. For this proposal, harmonic features estimated from speech frames are considered as center frequencies of Gammatone auditory filterbanks. A gain factor is further applied to the output of the filtered samples. The key goal is the emulation of an external noise filtering tailored for individuals with ASD. A perceptual listening test demonstrates that ASD volunteers attained lower intelligibility rates than Neurotypical (NT). The proposed solution is compared to three competing approaches considering four acoustic noises at different signal-to-noise ratios. Two objective measures (ESTOI and PESQ) are also adopted for evaluation. The experimental results show that the personalized solution outperformed the competing approaches in terms of intelligibility and quality improvement.",
        "comments": "5 pages, 3 figues, 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11832"
    },
    {
        "doc_id": 29,
        "title": "Harmonic Detection from Noisy Speech with Auditory Frame Gain for Intelligibility Enhancement",
        "authors": [
            "A. Queiroz",
            "R. Coelho"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "This paper introduces a novel (HDAG - Harmonic Detection for Auditory Gain) method for speech intelligibility enhancement in noisy scenarios. In the proposed scheme, a series of selective Gammachirp filters are adopted to emphasize the harmonic components of speech reducing the masking effects of acoustic noises. The fundamental frequency are estimated by the HHT-Amp technique. Harmonic patterns estimated with low accuracy are detected and adjusted according the FSFFE low/high pitch separation. The central frequencies of the filterbank are defined considering the third octave subbands which are best suited to cover the regions most relevant to intelligibility. Before signal reconstruction, the gammachirp filtered components are amplified by gain factors regulated by FSFFE classification. The proposed HDAG solution and three baseline techniques are examined considering six background noises with four signal-to-noise ratios. Three objective measures are adopted for the evaluation of speech intelligibility and quality. Several experiments are conducted to demonstrate that the proposed scheme achieves better speech intelligibility improvement when compared to the competing approaches. A perceptual listening test is further considered and corroborates with the objective results.",
        "comments": "9 pages, 6 figures, 4 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11829"
    },
    {
        "doc_id": 30,
        "title": "Performance Analysis of Fluid Antenna-aided Backscatter Communications Systems",
        "authors": [
            "Farshad Rostami Ghadi",
            "Masoud Kaveh",
            "Kai-Kit Wong"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper studies the performance of backscatter communications (BC) over emerging fluid antenna (FA) technology. In particular, a single-antenna source sends information to a FA reader through the wireless forward (i.e., source-to-tag) and backscatter (tag-to-reader) channels. For the considered BC, we first derive the cumulative distribution function (CDF) of the equivalent channel at the FA receiver, and then we obtain closed-form expressions of the outage probability (OP) and delay outage rate (DOR) under a correlated Rayleigh distribution. Moreover, in order to gain more insights into the system performance, we present analytical expressions of the OP and DOR at the high SNR regime. Numerical results indicate that considering the FA at the reader can significantly improve the performance of BC in terms of the OP and DOR compared with a single-antenna reader.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11820"
    },
    {
        "doc_id": 31,
        "title": "Analyzing the coupling process of distributed mixed real-virtual prototypes",
        "authors": [
            "Peter Baumann",
            "Lars Mikelsons",
            "Oliver Kotte",
            "Dieter Schramm"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The ongoing connection and automation of vehicles leads to a closer interaction of the individual vehicle components, which demands for consideration throughout the entire development process. In the design phase, this is achieved through co-simulation of component models. However, complex co-simulation environments are rarely (re-)used in the verification and validation phases, in which mixed real-virtual prototypes (e.g. Hardware-in-the-Loop) are already available. One reason for this are coupling errors such as time-delays, which inevitably occur in co-simulation of virtual and real-time systems, and which influence system behavior in an unknown and generally detrimental way. This contribution introduces a novel, adaptive method to compensate for constant time-delays in potentially highly nonlinear, spatially distributed mixed real-virtual prototypes, using small feedforward neural networks. Their optimal initialization with respect to defined frequency domain features results from a-priori frequency domain analysis of the entire coupled system, including coupling faults and compensation methods. A linear and a nonlinear example demonstrate the method and emphasize its suitability for nonlinear systems due to online training and adaptation. As the compensation method requires knowledge only of the bandwidths, the proposed method is applicable to distributed mixed real-virtual prototypes in general.",
        "comments": "8 pages, 12 figures, published at 33rd Annual European Simulation and Modelling Conference, ESM 2019",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11779"
    },
    {
        "doc_id": 32,
        "title": "Advancing Accessibility: Voice Cloning and Speech Synthesis for Individuals with Speech Disorders",
        "authors": [
            "Vinotha R",
            "Hepsiba D",
            "L. D. Vijay Anand",
            "Deepak John Reji"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Neural Text-to-speech (TTS) synthesis is a powerful technology that can generate speech using neural networks. One of the most remarkable features of TTS synthesis is its capability to produce speech in the voice of different speakers. This paper introduces voice cloning and speech synthesis https://pypi.org/project/voice-cloning/ an open-source python package for helping speech disorders to communicate more effectively as well as for professionals seeking to integrate voice cloning or speech synthesis capabilities into their projects. This package aims to generate synthetic speech that sounds like the natural voice of an individual, but it does not replace the natural human voice. The architecture of the system comprises a speaker verification system, a synthesizer, a vocoder, and noise reduction. Speaker verification system trained on a varied set of speakers to achieve optimal generalization performance without relying on transcriptions. Synthesizer is trained using both audio and transcriptions that generate Mel spectrogram from a text and vocoder which converts the generated Mel Spectrogram into corresponding audio signal. Then the audio signal is processed by a noise reduction algorithm to eliminate unwanted noise and enhance speech clarity. The performance of synthesized speech from seen and unseen speakers are then evaluated using subjective and objective evaluation such as Mean Opinion Score (MOS), Gross Pitch Error (GPE), and Spectral distortion (SD). The model can create speech in distinct voices by including speaker characteristics that are chosen randomly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11771"
    },
    {
        "doc_id": 33,
        "title": "Massive Synchrony in Distributed Antenna Systems",
        "authors": [
            "Erik G. Larsson"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Distributed antennas must be phase-calibrated (phase-synchronized) for certain operations, such as reciprocity-based joint coherent downlink beamforming, to work. We use rigorous signal processing tools to analyze the accuracy of calibration protocols that are based on over-the-air measurements between antennas, with a focus on scalability aspects for large systems. We show that (i) for some who-measures-on-whom topologies, the errors in the calibration process are unbounded when the network grows; and (ii) despite that conclusion, it is optimal -- irrespective of the topology -- to solve a single calibration problem for the entire system and use the result everywhere to support the beamforming. The analyses are exemplified by investigating specific topologies, including lines, rings, and two-dimensional surfaces.",
        "comments": "Journal ref:        IEEE Transactions on Signal Processing, 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11730"
    },
    {
        "doc_id": 34,
        "title": "Beyond the Manual Touch: Situational-aware Force Control for Increased Safety in Robot-assisted Skullbase Surgery",
        "authors": [
            "Hisashi Ishida",
            "Deepa Galaiya",
            "Nimesh Nagururu",
            "Francis Creighton",
            "Peter Kazanzides",
            "Russell Taylor",
            "Manish Sahu"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Purpose - Skullbase surgery demands exceptional precision when removing bone in the lateral skull base. Robotic assistance can alleviate the effect of human sensory-motor limitations. However, the stiffness and inertia of the robot can significantly impact the surgeon's perception and control of the tool-to-tissue interaction forces. Methods - We present a situational-aware, force control technique aimed at regulating interaction forces during robot-assisted skullbase drilling. The contextual interaction information derived from the digital twin environment is used to enhance sensory perception and suppress undesired high forces. Results - To validate our approach, we conducted initial feasibility experiments involving a medical and two engineering students. The experiment focused on further drilling around critical structures following cortical mastoidectomy. The experiment results demonstrate that robotic assistance coupled with our proposed control scheme effectively limited undesired interaction forces when compared to robotic assistance without the proposed force control. Conclusions - The proposed force control techniques show promise in significantly reducing undesired interaction forces during robot-assisted skullbase surgery. These findings contribute to the ongoing efforts to enhance surgical precision and safety in complex procedures involving the lateral skull base.",
        "comments": "*These authors contributed equally to this work",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11721"
    },
    {
        "doc_id": 35,
        "title": "Integrating 3D Slicer with a Dynamic Simulator for Situational Aware Robotic Interventions",
        "authors": [
            "Manish Sahu",
            "Hisashi Ishida",
            "Laura Connolly",
            "Hongyi Fan",
            "Anton Deguet",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor",
            "Adnan Munawar"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Image-guided robotic interventions represent a transformative frontier in surgery, blending advanced imaging and robotics for improved precision and outcomes. This paper addresses the critical need for integrating open-source platforms to enhance situational awareness in image-guided robotic research. We present an open-source toolset that seamlessly combines a physics-based constraint formulation framework, AMBF, with a state-of-the-art imaging platform application, 3D Slicer. Our toolset facilitates the creation of highly customizable interactive digital twins, that incorporates processing and visualization of medical imaging, robot kinematics, and scene dynamics for real-time robot control. Through a feasibility study, we showcase real-time synchronization of a physical robotic interventional environment in both 3D Slicer and AMBF, highlighting low-latency updates and improved visualization.",
        "comments": "*These authors contributed equally",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11715"
    },
    {
        "doc_id": 36,
        "title": "Haptic-Assisted Collaborative Robot Framework for Improved Situational Awareness in Skull Base Surgery",
        "authors": [
            "Hisashi Ishida",
            "Manish Sahu",
            "Adnan Munawar",
            "Nimesh Nagururu",
            "Deepa Galaiya",
            "Peter Kazanzides",
            "Francis X. Creighton",
            "Russell H. Taylor"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Skull base surgery is a demanding field in which surgeons operate in and around the skull while avoiding critical anatomical structures including nerves and vasculature. While image-guided surgical navigation is the prevailing standard, limitation still exists requiring personalized planning and recognizing the irreplaceable role of a skilled surgeon. This paper presents a collaboratively controlled robotic system tailored for assisted drilling in skull base surgery. Our central hypothesis posits that this collaborative system, enriched with haptic assistive modes to enforce virtual fixtures, holds the potential to significantly enhance surgical safety, streamline efficiency, and alleviate the physical demands on the surgeon. The paper describes the intricate system development work required to enable these virtual fixtures through haptic assistive modes. To validate our system's performance and effectiveness, we conducted initial feasibility experiments involving a medical student and two experienced surgeons. The experiment focused on drilling around critical structures following cortical mastoidectomy, utilizing dental stone phantom and cadaveric models. Our experimental results demonstrate that our proposed haptic feedback mechanism enhances the safety of drilling around critical structures compared to systems lacking haptic assistance. With the aid of our system, surgeons were able to safely skeletonize the critical structures without breaching any critical structure even under obstructed view of the surgical site.",
        "comments": "*These authors contributed equally",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11709"
    },
    {
        "doc_id": 37,
        "title": "Keep Decoding Parallel with Effective Knowledge Distillation from Language Models to End-to-end Speech Recognisers",
        "authors": [
            "Michael Hentschel",
            "Yuta Nishikawa",
            "Tatsuya Komatsu",
            "Yusuke Fujita"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "This study presents a novel approach for knowledge distillation (KD) from a BERT teacher model to an automatic speech recognition (ASR) model using intermediate layers. To distil the teacher's knowledge, we use an attention decoder that learns from BERT's token probabilities. Our method shows that language model (LM) information can be more effectively distilled into an ASR model using both the intermediate layers and the final layer. By using the intermediate layers as distillation target, we can more effectively distil LM knowledge into the lower network layers. Using our method, we achieve better recognition accuracy than with shallow fusion of an external LM, allowing us to maintain fast parallel decoding. Experiments on the LibriSpeech dataset demonstrate the effectiveness of our approach in enhancing greedy decoding with connectionist temporal classification (CTC).",
        "comments": "Accepted at ICASSP 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11700"
    },
    {
        "doc_id": 38,
        "title": "Emulation-based Stabilization for Networked Control Systems with Stochastic Channels",
        "authors": [
            "Wei Ren",
            "Wei Wang",
            "Zhuo-Rui Pan",
            "Xi-Ming Sun",
            "Andrew R. Teel",
            "Dragan Nesic"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper studies the stabilization problem of networked control systems (NCSs) with random packet dropouts caused by stochastic channels. To describe the effects of stochastic channels on the information transmission, the transmission times are assumed to be deterministic, whereas the packet transmission is assumed to be random. We first propose a stochastic scheduling protocol to model random packet dropouts, and address the properties of the proposed stochastic scheduling protocol. The proposed scheduling protocol provides a unified modelling framework for a general class of random packet dropouts due to different stochastic channels. Next, the proposed scheduling protocol is embedded into the closed-loop system, which leads to a stochastic hybrid model for NCSs with random packet dropouts. Based on this stochastic hybrid model, we follow the emulation approach to establish sufficient conditions to guarantee uniform global asymptotical stability in probability. In particular, an upper bound on the maximally allowable transmission interval is derived explicitly for all stochastic protocols satisfying Lyapunov conditions that guarantee uniform global asymptotic stability in probability. Finally, two numerical examples are presented to demonstrate the derived results.",
        "comments": "12 pages, 4 figures, accepted",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11677"
    },
    {
        "doc_id": 39,
        "title": "Rethinking Cross-Attention for Infrared and Visible Image Fusion",
        "authors": [
            "Lihua Jian",
            "Songlei Xiong",
            "Han Yan",
            "Xiaoguang Niu",
            "Shaowu Wu",
            "Di Zhang"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "The salient information of an infrared image and the abundant texture of a visible image can be fused to obtain a comprehensive image. As can be known, the current fusion methods based on Transformer techniques for infrared and visible (IV) images have exhibited promising performance. However, the attention mechanism of the previous Transformer-based methods was prone to extract common information from source images without considering the discrepancy information, which limited fusion performance. In this paper, by reevaluating the cross-attention mechanism, we propose an alternate Transformer fusion network (ATFuse) to fuse IV images. Our ATFuse consists of one discrepancy information injection module (DIIM) and two alternate common information injection modules (ACIIM). The DIIM is designed by modifying the vanilla cross-attention mechanism, which can promote the extraction of the discrepancy information of the source images. Meanwhile, the ACIIM is devised by alternately using the vanilla cross-attention mechanism, which can fully mine common information and integrate long dependencies. Moreover, the successful training of ATFuse is facilitated by a proposed segmented pixel loss function, which provides a good trade-off for texture detail and salient structure preservation. The qualitative and quantitative results on public datasets indicate our ATFFuse is effective and superior compared to other state-of-the-art methods.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11675"
    },
    {
        "doc_id": 40,
        "title": "RTA-Former: Reverse Transformer Attention for Polyp Segmentation",
        "authors": [
            "Zhikai Li",
            "Murong Yi",
            "Ali Uneri",
            "Sihan Niu",
            "Craig Jones"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Polyp segmentation is a key aspect of colorectal cancer prevention, enabling early detection and guiding subsequent treatments. Intelligent diagnostic tools, including deep learning solutions, are widely explored to streamline and potentially automate this process. However, even with many powerful network architectures, there still comes the problem of producing accurate edge segmentation. In this paper, we introduce a novel network, namely RTA-Former, that employs a transformer model as the encoder backbone and innovatively adapts Reverse Attention (RA) with a transformer stage in the decoder for enhanced edge segmentation. The results of the experiments illustrate that RTA-Former achieves state-of-the-art (SOTA) performance in five polyp segmentation datasets. The strong capability of RTA-Former holds promise in improving the accuracy of Transformer-based polyp segmentation, potentially leading to better clinical decisions and patient outcomes. Our code will be publicly available on GitHub.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11671"
    },
    {
        "doc_id": 41,
        "title": "Streaming Bilingual End-to-End ASR model using Attention over Multiple Softmax",
        "authors": [
            "Aditya Patil",
            "Vikas Joshi",
            "Purvi Agrawal",
            "Rupesh Mehta"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Computation and Language",
            "Sound"
        ],
        "abstract": "Even with several advancements in multilingual modeling, it is challenging to recognize multiple languages using a single neural model, without knowing the input language and most multilingual models assume the availability of the input language. In this work, we propose a novel bilingual end-to-end (E2E) modeling approach, where a single neural model can recognize both languages and also support switching between the languages, without any language input from the user. The proposed model has shared encoder and prediction networks, with language-specific joint networks that are combined via a self-attention mechanism. As the language-specific posteriors are combined, it produces a single posterior probability over all the output symbols, enabling a single beam search decoding and also allowing dynamic switching between the languages. The proposed approach outperforms the conventional bilingual baseline with 13.3%, 8.23% and 1.3% word error rate relative reduction on Hindi, English and code-mixed test sets, respectively.",
        "comments": "Published in IEEE's Spoken Language Technology (SLT) 2022, 8 pages (6 + 2 for references), 5 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11645"
    },
    {
        "doc_id": 42,
        "title": "Optimizing performance in elastic optical networks using advanced reconfigurable optical add-drop multiplexers: A novel design approach and comprehensive analysis",
        "authors": [
            "Faranak Khosravi",
            "Mehdi Shadaram"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Network operators diversify service offerings and enhance network efficiency by leveraging bandwidth-variable transceivers and colorless flexible-grid reconfigurable optical add-drop multiplexers (ROADMs). Nonetheless, the paradigm shift from rigid to elastic optical networks (EONs) has affected several key parameters, including bit rate, center frequency spacing, modulation format, and optical reach. This study investigated the transformative impact of emerging technologies on the design and structure of optical network architectures, including spectrally efficient multicarrier systems and bandwidth-variable wavelength-selective switches. A cost-effective ROADM architecture applying an order-based connecting approach was introduced, which presented a high connectivity level and a blockage probability of less than 10-4. When this architecture was implemented in the EON, the data transportation rate was 1 Tb/s. This outcome successfully accommodated a 20 % surge in traffic demand, while the optimized network architecture significantly improved fiber utilization by 3.4 %. Consequently, this study contributed a practical and efficient solution for implementing flexible optical networks, effectively addressing current concerns and propelling the optical communication system sector forward.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11640"
    },
    {
        "doc_id": 43,
        "title": "Reframing Offline Reinforcement Learning as a Regression Problem",
        "authors": [
            "Prajwal Koirala",
            "Cody Fleming"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "The study proposes the reformulation of offline reinforcement learning as a regression problem that can be solved with decision trees. Aiming to predict actions based on input states, return-to-go (RTG), and timestep information, we observe that with gradient-boosted trees, the agent training and inference are very fast, the former taking less than a minute. Despite the simplification inherent in this reformulated problem, our agent demonstrates performance that is at least on par with established methods. This assertion is validated by testing it across standard datasets associated with D4RL Gym-MuJoCo tasks. We further discuss the agent's ability to generalize by testing it on two extreme cases, how it learns to model the return distributions effectively even with highly skewed expert datasets, and how it exhibits robust performance in scenarios with sparse/delayed rewards.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11630"
    },
    {
        "doc_id": 44,
        "title": "Real-Time Systems Optimization with Black-box Constraints and Hybrid Variables",
        "authors": [
            "Sen Wang",
            "Dong Li",
            "Shao-Yu Huang",
            "Xuanliang Deng",
            "Ashrarul H. Sifat",
            "Changhee Jung",
            "Ryan Williams",
            "Haibo Zeng"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "When optimizing real-time systems, designers often face a challenging problem where the schedulability constraints are non-convex, non-continuous, or lack an analytical form to understand their properties. Although the optimization framework NORTH proposed in previous work is general (it works with arbitrary schedulability analysis) and scalable, it can only handle problems with continuous variables, which limits its application. In this paper, we extend the applications of the framework NORTH to problems with a hybrid of continuous and discrete variables. This is achieved in a coordinate-descent method, where the continuous and discrete variables are optimized separately during iterations. The new framework, NORTH+, improves around 20% solution quality than NORTH in experiments.",
        "comments": "Workshop on OPtimization for Embedded and ReAl-time systems (OPERA 2023) co-located with the 44th IEEE Real-Time Systems Symposium (RTSS)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11620"
    },
    {
        "doc_id": 45,
        "title": "Another Way to the Top: Exploit Contextual Clustering in Learned Image Coding",
        "authors": [
            "Yichi Zhang",
            "Zhihao Duan",
            "Ming Lu",
            "Dandan Ding",
            "Fengqing Zhu",
            "Zhan Ma"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "While convolution and self-attention are extensively used in learned image compression (LIC) for transform coding, this paper proposes an alternative called Contextual Clustering based LIC (CLIC) which primarily relies on clustering operations and local attention for correlation characterization and compact representation of an image. As seen, CLIC expands the receptive field into the entire image for intra-cluster feature aggregation. Afterward, features are reordered to their original spatial positions to pass through the local attention units for inter-cluster embedding. Additionally, we introduce the Guided Post-Quantization Filtering (GuidedPQF) into CLIC, effectively mitigating the propagation and accumulation of quantization errors at the initial decoding stage. Extensive experiments demonstrate the superior performance of CLIC over state-of-the-art works: when optimized using MSE, it outperforms VVC by about 10% BD-Rate in three widely-used benchmark datasets; when optimized using MS-SSIM, it saves more than 50% BD-Rate over VVC. Our CLIC offers a new way to generate compact representations for image compression, which also provides a novel direction along the line of LIC development.",
        "comments": "The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11615"
    },
    {
        "doc_id": 46,
        "title": "$\\texttt{immrax}$: A Parallelizable and Differentiable Toolbox for Interval Analysis and Mixed Monotone Reachability in JAX",
        "authors": [
            "Akash Harapanahalli",
            "Saber Jafarpour",
            "Samuel Coogan"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "We present an implementation of interval analysis and mixed monotone interval reachability analysis as function transforms in Python, fully composable with the computational framework JAX. The resulting toolbox inherits several key features from JAX, including computational efficiency through Just-In-Time Compilation, GPU acceleration for quick parallelized computations, and Automatic Differentiability. We demonstrate the toolbox's performance on several case studies, including a reachability problem on a vehicle model controlled by a neural network, and a robust closed-loop optimal control problem for a swinging pendulum.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11608"
    },
    {
        "doc_id": 47,
        "title": "Thermal Image Calibration and Correction using Unpaired Cycle-Consistent Adversarial Networks",
        "authors": [
            "Hossein Rajoli",
            "Pouya Afshin",
            "Fatemeh Afghah"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) offer a flexible and cost-effective solution for wildfire monitoring. However, their widespread deployment during wildfires has been hindered by a lack of operational guidelines and concerns about potential interference with aircraft systems. Consequently, the progress in developing deep-learning models for wildfire detection and characterization using aerial images is constrained by the limited availability, size, and quality of existing datasets. This paper introduces a solution aimed at enhancing the quality of current aerial wildfire datasets to align with advancements in camera technology. The proposed approach offers a solution to create a comprehensive, standardized large-scale image dataset. This paper presents a pipeline based on CycleGAN to enhance wildfire datasets and a novel fusion method that integrates paired RGB images as attribute conditioning in the generators of both directions, improving the accuracy of the generated images.",
        "comments": "This paper has been accepted at the Asilomar 2023 Conference and will be published",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11582"
    },
    {
        "doc_id": 48,
        "title": "Deterministic Multi-stage Constellation Reconfiguration Using Integer Linear Programing and Sequential Decision-Making Methods",
        "authors": [
            "Hang Woon Lee",
            "David O. Williams Rogers",
            "Brycen D. Pearl",
            "Hao Chen",
            "Koki Ho"
        ],
        "subjects": [
            "Optimization and Control",
            "Systems and Control"
        ],
        "abstract": "In this paper, we address the problem of reconfiguring Earth observation satellite constellation systems through multiple stages. The Multi-stage Constellation Reconfiguration Problem (MCRP) aims to maximize the total observation rewards obtained by covering a set of targets of interest through the active manipulation of the orbits and relative phasing of constituent satellites. In this paper, we consider deterministic problem settings in which the targets of interest are known a priori. We propose a novel integer linear programming formulation for MCRP, capable of obtaining provably optimal solutions. To overcome computational intractability due to the combinatorial explosion in solving large-scale instances, we introduce two computationally efficient sequential decision-making methods based on the principles of a myopic policy and a rolling horizon procedure. The computational experiments demonstrate that the devised sequential decision-making approaches yield high-quality solutions with improved computational efficiency over the baseline MCRP. Finally, a case study using Hurricane Harvey data showcases the advantages of multi-stage constellation reconfiguration over single-stage and no-reconfiguration scenarios.",
        "comments": "37 pages, 13 figures, submitted to the Journal of Spacecraft and Rockets",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11567"
    },
    {
        "doc_id": 49,
        "title": "Nigel -- Mechatronic Design and Robust Sim2Real Control of an Over-Actuated Autonomous Vehicle",
        "authors": [
            "Chinmay Vilas Samak",
            "Tanmay Vilas Samak",
            "Javad Mohammadpour Velni",
            "Venkat Narayan Krovi"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Simulation to reality (sim2real) transfer from a dynamics and controls perspective usually involves re-tuning or adapting the designed algorithms to suit real-world operating conditions, which often violates the performance guarantees established originally. This work presents a generalizable framework for achieving reliable sim2real transfer of autonomy-oriented control systems using multi-model multi-objective robust optimal control synthesis, which lends well to uncertainty handling and disturbance rejection with theoretical guarantees. Particularly, this work is centered around an actuation-redundant scaled autonomous vehicle called Nigel, with independent all-wheel drive and independent all-wheel steering architecture, whose enhanced configuration space bodes well for robust control applications. To this end, we present a systematic study on the complete mechatronic design, dynamics modeling, parameter identification, and robust stabilizing as well as steady-state tracking control of Nigel using the proposed framework, with experimental validation.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11542"
    },
    {
        "doc_id": 50,
        "title": "Model Predictive Approach for Detumbling an Underactuated Satellite",
        "authors": [
            "Kota Kondo",
            "Yasuhiro Yoshimura",
            "Mai Bando",
            "Shuji Nagasaki",
            "Toshiya Hanada"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This research proposes an innovative approach to detumble satellites' triple-axis angular velocities with only one single-axis magnetic torquer. Since magnetic torque is generated perpendicularly to magnetorquers, no intended control torque along the magnetorquer can be produced, which makes systems underactuated. Our paper introduces a control method using Model Predictive Control (MPC) and compares it with B-dot control algorithm. By applying these control laws to Kyushu University Light Curve Inversion (Q-Li) Demonstration Satellite in numerical simulations, we describe the applicability of these control laws to underactuated systems.",
        "comments": "15 pages, 4 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11539"
    },
    {
        "doc_id": 51,
        "title": "Maintenance cost assessment for heterogeneous multi-component systems incorporating perfect inspections and waiting time to maintenance",
        "authors": [
            "Luc\u00eda Bautista",
            "Inma T. Castro",
            "Luis Landesa"
        ],
        "subjects": [
            "Systems and Control",
            "Probability"
        ],
        "abstract": "Most existing research about complex systems maintenance assumes they consist of the same type of components. However, systems can be assembled with heterogeneous components (for example degrading and non-degrading components) that require different maintenance actions. Since industrial systems become more and more complex, more research about the maintenance of systems with heterogeneous components is needed. For this reason, in this paper, a system consisting of two groups of components: degrading and non-degrading components is analyzed. The main novelty of this paper is the evaluation of a maintenance policy at system-level coordinating condition-based maintenance for the degrading components, delay time to the maintenance and an inspection strategy for this heterogeneous system. To that end, an analytic cost model is built using the semi-regenerative processes theory. Furthermore, a safety constraint related to the reliability of the degrading components is imposed. To find the optimal maintenance strategy, meta-heuristic algorithms are used.",
        "comments": "27 pages, 4 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11538"
    },
    {
        "doc_id": 52,
        "title": "Nonlinear Model Predictive Detumbling of Small Satellites with a Single-axis Magnetorquer",
        "authors": [
            "Kota Kondo",
            "Ilya Kolmanovsky",
            "Yasuhiro Yoshimura",
            "Mai Bando",
            "Shuji Nagasaki",
            "Toshiya Hanada"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Various actuators are used in spacecraft to achieve attitude stabilization, including thrusters, momentum wheels, and control moment gyros. Small satellites, however, have stringent size, weight, and cost constraints, which makes many actuator choices prohibitive. Consequently, magnetic torquers have commonly been applied to spacecraft to attenuate angular rates. Approaches for dealing with under-actuation due to magnetic control torque's dependency on the magnetic field and required high magnetic flux densities have been previously considered. Generally speaking, control of a satellite that becomes under-actuated as a result of on-board failures has been a recurrent theme in the literature. Methods for controlling spacecraft with fewer actuators than degrees of freedom are increasingly in demand due to the increased number of small satellite launches. Magnetic torquers have been extensively investigated for momentum management of spacecraft with momentum wheels and for nutation damping of spin satellites, momentum-biased, and dual-spin satellites. Nonetheless, severely under-actuated small spacecraft that carry only a single-axis magnetic torquer have not been previously treated. This note considers the detumbling of a small spacecraft using only a single-axis magnetic torquer. Even with a three-axis magnetic torquer, the spacecraft is under-actuated, while, in the case of only a single axis magnetic torquer, the problem is considerably more demanding. Our note examines the feasibility of spacecraft attitude control with a single-axis magnetic torquer and possible control methods that can be used.",
        "comments": "20 pages, 6 figures. Journal of Guidance, Control, and Dynamics (2021)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11536"
    },
    {
        "doc_id": 53,
        "title": "Pulse Width Modulation Method Applied to Nonlinear Model Predictive Control on an Under-actuated Small Satellite",
        "authors": [
            "Kota Kondo",
            "Yasuhiro Yoshimura",
            "Shiji Nagasaki",
            "Toshiya Hanada"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Among various satellite actuators, magnetic torquers have been widely equipped for stabilization and attitude control of small satellites. Although magnetorquers are generally used with other actuators, such as momentum wheels, this paper explores a control method where only a magnetic actuation is available. We applied a nonlinear optimal control method, Nonlinear Model Predictive Control (NMPC), to small satellites, employing the generalized minimal residual (GMRES) method, which generates continuous control inputs. Onboard magnetic actuation systems often find it challenging to produce smooth magnetic moments as a control input; hence, we employ the Pulse Width Modulation (PWM) method, which discretizes a control input and reduces the burden on actuators. In our case, the PWM approach discretizes control torques generated by the NMPC scheme. This study's main contributions are investigating the NMPC and the GMRES method applied to small spacecraft and presenting the PWM control system's feasibility.",
        "comments": "19 pages, 10 figures. In AIAA Scitech 2021 Forum",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11533"
    },
    {
        "doc_id": 54,
        "title": "CaBuAr: California Burned Areas dataset for delineation",
        "authors": [
            "Daniele Rege Cambrin",
            "Luca Colomba",
            "Paolo Garza"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "Forest wildfires represent one of the catastrophic events that, over the last decades, caused huge environmental and humanitarian damages. In addition to a significant amount of carbon dioxide emission, they are a source of risk to society in both short-term (e.g., temporary city evacuation due to fire) and long-term (e.g., higher risks of landslides) cases. Consequently, the availability of tools to support local authorities in automatically identifying burned areas plays an important role in the continuous monitoring requirement to alleviate the aftereffects of such catastrophic events. The great availability of satellite acquisitions coupled with computer vision techniques represents an important step in developing such tools. This paper introduces a novel open dataset that tackles the burned area delineation problem, a binary segmentation problem applied to satellite imagery. The presented resource consists of pre- and post-fire Sentinel-2 L2A acquisitions of California forest fires that took place starting in 2015. Raster annotations were generated from the data released by California's Department of Forestry and Fire Protection. Moreover, in conjunction with the dataset, we release three different baselines based on spectral indexes analyses, SegFormer, and U-Net models.",
        "comments": "Accepted at the IEEE Geoscience and Remote Sensing Magazine",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11519"
    },
    {
        "doc_id": 55,
        "title": "Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis",
        "authors": [
            "Yanhong Peng",
            "Ceng Zhang",
            "Chenlong Hu",
            "Zebing Mao"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Systems and Control"
        ],
        "abstract": "This paper presents an innovative approach to integrating Large Language Models (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for precise color synthesis in automation systems. We propose a novel framework that employs fine-tuned LLMs to interpret natural language commands and convert them into specific operational instructions for EHD pump control. This approach aims to enhance user interaction with complex hardware systems, making it more intuitive and efficient. The methodology involves four key steps: fine-tuning the language model with a dataset of color specifications and corresponding Arduino code, developing a natural language processing interface, translating user inputs into executable Arduino code, and controlling EHD pumps for accurate color mixing. Conceptual experiment results, based on theoretical assumptions, indicate a high potential for accurate color synthesis, efficient language model interpretation, and reliable EHD pump operation. This research extends the application of LLMs beyond text-based tasks, demonstrating their potential in industrial automation and control systems. While highlighting the limitations and the need for real-world testing, this study opens new avenues for AI applications in physical system control and sets a foundation for future advancements in AI-driven automation technologies.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11500"
    },
    {
        "doc_id": 56,
        "title": "HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores",
        "authors": [
            "Nikolas F\u00f6rster",
            "Wilhelm Kirchg\u00e4ssner",
            "Till Piepenbrock",
            "Oliver Schweins",
            "Oliver Wallscheid"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning",
            "Applied Physics"
        ],
        "abstract": "The MagNet Challenge 2023 calls upon competitors to develop data-driven models for the material-specific, waveform-agnostic estimation of steady-state power losses in toroidal ferrite cores. The following HARDCORE (H-field and power loss estimation for Arbitrary waveforms with Residual, Dilated convolutional neural networks in ferrite COREs) approach shows that a residual convolutional neural network with physics-informed extensions can serve this task efficiently when trained on observational data beforehand. One key solution element is an intermediate model layer which first reconstructs the bh curve and then estimates the power losses based on the curve's area rendering the proposed topology physically interpretable. In addition, emphasis was placed on expert-based feature engineering and information-rich inputs in order to enable a lean model architecture. A model is trained from scratch for each material, while the topology remains the same. A Pareto-style trade-off between model size and estimation accuracy is demonstrated, which yields an optimum at as low as 1755 parameters and down to below 8\\,\\% for the 95-th percentile of the relative error for the worst-case material with sufficient samples.",
        "comments": "Competition submission version",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11488"
    },
    {
        "doc_id": 57,
        "title": "ColorVideoVDP: A visual difference predictor for image, video and display distortions",
        "authors": [
            "Rafal K. Mantiuk",
            "Param Hanji",
            "Maliha Ashraf",
            "Yuta Asano",
            "Alexandre Chapiro"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Graphics",
            "Image and Video Processing"
        ],
        "abstract": "ColorVideoVDP is a video and image quality metric that models spatial and temporal aspects of vision, for both luminance and color. The metric is built on novel psychophysical models of chromatic spatiotemporal contrast sensitivity and cross-channel contrast masking. It accounts for the viewing conditions, geometric, and photometric characteristics of the display. It was trained to predict common video streaming distortions (e.g. video compression, rescaling, and transmission errors), and also 8 new distortion types related to AR/VR displays (e.g. light source and waveguide non-uniformities). To address the latter application, we collected our novel XR-Display-Artifact-Video quality dataset (XR-DAVID), comprised of 336 distorted videos. Extensive testing on XR-DAVID, as well as several datasets from the literature, indicate a significant gain in prediction performance compared to existing metrics. ColorVideoVDP opens the doors to many novel applications which require the joint automated spatiotemporal assessment of luminance and color distortions, including video streaming, display specification and design, visual comparison of results, and perceptually-guided quality optimization.",
        "comments": "28 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11485"
    },
    {
        "doc_id": 58,
        "title": "Distributed Traffic Signal Control of Interconnected Intersections: A Two-Lane Traffic Network Model",
        "authors": [
            "Xinfeng Ru",
            "Weiguo Xia",
            "Ting Bai"
        ],
        "subjects": [
            "Systems and Control",
            "Adaptation and Self-Organizing Systems"
        ],
        "abstract": "Practical and accurate traffic models play an important role in capturing real traffic dynamics and then in achieving effective control performance. This paper studies traffic signal control in a traffic network with multiple interconnected intersections, where the target is to balance the vehicle density on each lane by controlling the green times of each phase at every intersection. Different from traditional road-based modeling schemes, a two-lane intersection model is first proposed to model the flow propagation in a more accurate way. A distributed model predictive control (MPC) method is then presented to assign the green times. To enable the real-time feasibility of the proposed approach, the alternating direction method of multipliers (ADMM) is incorporated with the distributed MPC scheme for solving the problem. Finally, the simulation studies performed in VISSIM for a six-intersection traffic network in Dalian, China, show the effectiveness and characteristics of the proposed method.",
        "comments": "journal paper",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11483"
    },
    {
        "doc_id": 59,
        "title": "Battery-Free Sensor Array for Wireless Multi-Depth In-Situ Sensing",
        "authors": [
            "Hongzhi Guo",
            "Adam Kamrath"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Underground in-situ sensing plays a vital role in precision agriculture and infrastructure monitoring. While existing sensing systems utilize wires to connect an array of sensors at various depths for spatial-temporal data collection, wireless underground sensor networks offer a cable-free alternative. However, these wireless sensors are typically battery-powered, necessitating periodic recharging or replacement. This paper proposes a battery-free sensor array which can be used for wireless multi-depth in-situ sensing. Utilizing Near Field Communication (NFC)-which can penetrate soil with negligible signal power loss-this sensor array can form a virtual magnetic waveguide, achieving long communication ranges. An analytical model has been developed to offer insights and determine optimal design parameters. Moreover, a prototype, constructed using off-the-shelf NFC sensors, was tested to validate the proposed concept. While this system is primarily designed for underground applications, it holds potential for other multi-depth in-situ sensing scenarios, including underwater environments.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11479"
    },
    {
        "doc_id": 60,
        "title": "Task-specific regularization loss towards model calibration for reliable lung cancer detection",
        "authors": [
            "Mehar Prateek Kalra",
            "Mansi Singhal",
            "Rohan Raju Dhanakashirur"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Lung cancer is one of the significant causes of cancer-related deaths globally. Early detection and treatment improve the chances of survival. Traditionally CT scans have been used to extract the most significant lung infection information and diagnose cancer. This process is carried out manually by an expert radiologist. The imbalance in the radiologists-to-population ratio in a country like India implies significant work pressure on them and thus raises the need to automate a few of their responsibilities. The tendency of modern-day Deep Neural networks to make overconfident mistakes limit their usage to detect cancer. In this paper, we propose a new task-specific loss function to calibrate the neural network to reduce the risk of overconfident mistakes. We use the state-of-the-art Multi-class Difference in Confidence and Accuracy (MDCA) loss in conjunction with the proposed task-specific loss function to achieve the same. We also integrate post-hoc calibration by performing temperature scaling on top of the train-time calibrated model. We demonstrate 5.98% improvement in the Expected Calibration Error (ECE) and a 17.9% improvement in Maximum Calibration Error (MCE) as compared to the best-performing SOTA algorithm.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11464"
    },
    {
        "doc_id": 61,
        "title": "Energy Consumption Analysis for Continuous Phase Modulation in Smart-Grid Internet of Things of beyond 5G",
        "authors": [
            "Hongjian Gao",
            "Yang Lu",
            "Shaoshi Yang",
            "Jingsheng Tan",
            "Longlong Nie",
            "Xinyi Qu"
        ],
        "subjects": [
            "Signal Processing",
            "Networking and Internet Architecture"
        ],
        "abstract": "Wireless sensor network (WSN) underpinning the smart-grid Internet of Things (SG-IoT) has been a popular research topic in recent years due to its great potential for enabling a wide range of important applications. However, the energy consumption (EC) characteristic of sensor nodes is a key factor that affects the operational performance (e.g., lifetime of sensors) and the total cost of ownership of WSNs. In this paper, to find the modulation techniques suitable for WSNs, we investigate the EC characteristic of continuous phase modulation (CPM), which is an attractive modulation scheme candidate for WSNs because of its constant envelope property. We first develop an EC model for the sensor nodes of WSNs by considering the circuits and a typical communication protocol that relies on automatic repeat request (ARQ)-based retransmissions to ensure successful data delivery. Then, we use this model to analyze the EC characteristic of CPM under various configurations of modulation parameters. Furthermore, we compare the EC characteristic of CPM with that of other representative modulation schemes, such as offset quadrature phase-shift keying (OQPSK) and quadrature amplitude modulation (QAM), which are commonly used in communication protocols of WSNs. Our analysis and simulation results provide insights into the EC characteristics of multiple modulation schemes in the context of WSNs; thus, they are beneficial for designing energy-efficient SG-IoT in the beyond-5G (B5G) and the 6G era.",
        "comments": "7 figures, 2 tables",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11449"
    },
    {
        "doc_id": 62,
        "title": "Towards Non-Robocentric Dynamic Landing of Quadrotor UAVs",
        "authors": [
            "Li-Yu Lo",
            "Boyang Li",
            "Chih-Yung Wen",
            "Ching-Wei Chang"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "In this work, we propose a dynamic landing solution without the need for onboard exteroceptive sensors and an expensive computation unit, where all localization and control modules are carried out on the ground in a non-inertial frame. Our system starts with a relative state estimator of the aerial robot from the perspective of the landing platform, where the state tracking of the UAV is done through a set of onboard LED markers and an on-ground camera; the state is expressed geometrically on manifold, and is returned by Iterated Extended Kalman filter (IEKF) algorithm. Subsequently, a motion planning module is developed to guide the landing process, formulating it as a minimum jerk trajectory by applying the differential flatness property. Considering visibility and dynamic constraints, the problem is solved using quadratic programming, and the final motion primitive is expressed through piecewise polynomials. Through a series of experiments, the applicability of this approach is validated by successfully landing 18 cm x 18 cm quadrotor on a 43 cm x 43 cm platform, exhibiting performance comparable to conventional methods. Finally, we provide comprehensive hardware and software details to the research community for future reference.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11445"
    },
    {
        "doc_id": 63,
        "title": "IoT Cloud RAN Testbed for Ultra-Precise TDoA-based Localization in LPWANs",
        "authors": [
            "Thomas Maul",
            "Joerg Robert",
            "Sebastian Klob"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "There have been many research efforts in the area of localization in recent years. Especially within the Internet of Things (IoT), the knowledge of position information for individual components is of great interest, for example, in asset tracking, to name just one. However, many of these use cases require a high energy efficiency, making a GNSS-based approach infeasible. One promising candidate can be found in Low Power Wide Area Networks (LPWAN), which enable battery lifetimes of up to 20 years. However, no gold standard for localization exists for these types of networks. Our work proposes a testbed architecture that allows the investigation and development of localization algorithms within LPWA Networks. The concept is built on a Cloud Radio Access Network (CRAN) architecture that allows the streaming of IQ from remote base stations to a central processing unit. Furthermore, the architecture is expanded by a synchronization concept based on Signals of Opportunity (SoO) to enable the testbed for runtime-based positioning. Therefore, we propose a hardware concept consisting of antennas and a low-cost off-the-shelf software-defined radio (SDR)-based frontend architecture and a software framework using a hypertext transfer protocol (HTTP)-based server and client architecture. The proposed system is installed in an urban environment. Initial measurements are conducted, where it can be shown that the proposed architecture can be used for highly precise Time Difference of Arrival (TDoA) measurements, offering the possibility of time synchronization down to approximately 200 ps and frequency synchronization of 3 mHz.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11435"
    },
    {
        "doc_id": 64,
        "title": "Joint Downlink and Uplink Optimization for RIS-Aided FDD MIMO Communication Systems",
        "authors": [
            "Gyoseung Lee",
            "Hyeongtaek Lee",
            "Donghwan Kim",
            "Jaehoon Chung",
            "A. Lee. Swindlehurst",
            "Junil Choi"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-aided frequency division duplexing (FDD) communication systems. Since the downlink and uplink signals are simultaneously transmitted in FDD, the phase shifts at the RIS should be designed to support both transmissions. Considering a single-user multiple-input multiple-output system, we formulate a weighted sum-rate maximization problem to jointly maximize the downlink and uplink system performance. To tackle the non-convex optimization problem, we adopt an alternating optimization (AO) algorithm, in which two phase shift optimization techniques are developed to handle the unit-modulus constraints induced by the reflection coefficients at the RIS. The first technique exploits the manifold optimization-based algorithm, while the second uses a lower-complexity AO approach. Numerical results verify that the proposed techniques rapidly converge to local optima and significantly improve the overall system performance compared to existing benchmark schemes.",
        "comments": "Accepted to IEEE Transactions on Wireless Communications",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11429"
    },
    {
        "doc_id": 65,
        "title": "Joint UAV Deployment and Resource Allocation in THz-Assisted MEC-Enabled Integrated Space-Air-Ground Networks",
        "authors": [
            "Yan Kyaw Tun",
            "Gy\u00f6rgy D\u00e1n",
            "Yu Min Park",
            "Choong Seon Hong"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Signal Processing"
        ],
        "abstract": "Multi-access edge computing (MEC)-enabled integrated space-air-ground (SAG) networks have drawn much attention recently, as they can provide communication and computing services to wireless devices in areas that lack terrestrial base stations (TBSs). Leveraging the ample bandwidth in the terahertz (THz) spectrum, in this paper, we propose MEC-enabled integrated SAG networks with collaboration among unmanned aerial vehicles (UAVs). We then formulate the problem of minimizing the energy consumption of devices and UAVs in the proposed MEC-enabled integrated SAG networks by optimizing tasks offloading decisions, THz sub-bands assignment, transmit power control, and UAVs deployment. The formulated problem is a mixed-integer nonlinear programming (MILP) problem with a non-convex structure, which is challenging to solve. We thus propose a block coordinate descent (BCD) approach to decompose the problem into four sub-problems: 1) device task offloading decision problem, 2) THz sub-band assignment and power control problem, 3) UAV deployment problem, and 4) UAV task offloading decision problem. We then propose to use a matching game, concave-convex procedure (CCP) method, successive convex approximation (SCA), and block successive upper-bound minimization (BSUM) approaches for solving the individual subproblems. Finally, extensive simulations are performed to demonstrate the effectiveness of our proposed algorithm.",
        "comments": "36 pages, 8 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11419"
    },
    {
        "doc_id": 66,
        "title": "Optimal detection of non-overlapping images via combinatorial auction",
        "authors": [
            "Simon Anuk",
            "Tamir Bendory",
            "Amichai Painsky"
        ],
        "subjects": [
            "Image and Video Processing",
            "Signal Processing",
            "Optimization and Control"
        ],
        "abstract": "This paper studies the classical problem of detecting the location of multiple image occurrences in a two-dimensional, noisy measurement. Assuming the image occurrences do not overlap, we formulate this task as a constrained maximum likelihood optimization problem. We show that the maximum likelihood estimator is equivalent to an instance of the winner determination problem from the field of combinatorial auction, and that the solution can be obtained by searching over a binary tree. We then design a pruning mechanism that significantly accelerates the runtime of the search. We demonstrate on simulations and electron microscopy data sets that the proposed algorithm provides accurate detection in challenging regimes of high noise levels and densely packed image occurrences.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11413"
    },
    {
        "doc_id": 67,
        "title": "Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel Optimization Perspective",
        "authors": [
            "Xingdi Chen",
            "Yu Xiong",
            "Kai Yang"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Utilization of inter-base station cooperation for information processing has shown great potential in enhancing the overall quality of communication services (QoS) in wireless communication networks. Nevertheless, such cooperations require the knowledge of channel state information (CSI) at base stations (BSs), which is assumed to be perfectly known. However, CSI errors are inevitable in practice which necessitates beamforming techniques that can achieve robust performance in the presence of channel estimation errors. Existing approaches relax the robust beamforming design problems into semidefinite programming (SDP), which can only achieve a solution that is far from being optimal. To this end, this paper views robust beamforming design problems from a bilevel optimization perspective. In particular, we focus on maximizing the worst-case weighted sum-rate (WSR) in the downlink multi-cell multi-user multiple-input single-output (MISO) system considering bounded CSI errors. We first reformulate this problem into a bilevel optimization problem and then develop an efficient algorithm based on the cutting plane method. A distributed optimization algorithm has also been developed to facilitate the parallel processing in practical settings. Numerical results are provided to confirm the effectiveness of the proposed algorithm in terms of performance and complexity, particularly in the presence of CSI uncertainties.",
        "comments": "accepted at AAAI2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11409"
    },
    {
        "doc_id": 68,
        "title": "Application of a Novel Model Reduction Technique to the Assessment of Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems",
        "authors": [
            "Mark A. Pinsky"
        ],
        "subjects": [
            "Systems and Control",
            "Differential Geometry"
        ],
        "abstract": "This paper develops a new approach to the assessment of the boundedness/stability of some vector nonlinear systems with delays and variable coefficients. The approach rests on the development of scalar counterparts to the original vector systems. We show that the solutions to these scalar auxiliary nonlinear equations with delay and variable coefficients bound from the above the norms of solutions to the original equations with the matched history functions. This prompts the assessment of the boundedness/stability traits of the vector systems through the abridged evaluation of the dynamics of their scalar counterparts. The latter task is achieved in effortless simulations or through the application of simplified analytical inferences. Consequently, we convey some novel boundedness/ stability criteria and estimate the radiuses of the balls imbedded in the boundedness/stability regions. Lastly, we authenticate our inferences in representative simulations that also measure their accuracy.",
        "comments": "17 pages",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11398"
    },
    {
        "doc_id": 69,
        "title": "Joint User Scheduling and Computing Resource Allocation Optimization in Asynchronous Mobile Edge Computing Networks",
        "authors": [
            "Yihan Cang",
            "Ming Chen",
            "Yijin Pan",
            "Zhaohui Yang",
            "Ye Hu",
            "Haijian Sun",
            "Mingzhe Chen"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "In this paper, the problem of joint user scheduling and computing resource allocation in asynchronous mobile edge computing (MEC) networks is studied. In such networks, edge devices will offload their computational tasks to an MEC server, using the energy they harvest from this server. To get their tasks processed on time using the harvested energy, edge devices will strategically schedule their task offloading, and compete for the computational resource at the MEC server. Then, the MEC server will execute these tasks asynchronously based on the arrival of the tasks. This joint user scheduling, time and computation resource allocation problem is posed as an optimization framework whose goal is to find the optimal scheduling and allocation strategy that minimizes the energy consumption of these mobile computing tasks. To solve this mixed-integer non-linear programming problem, the general benders decomposition method is adopted which decomposes the original problem into a primal problem and a master problem. Specifically, the primal problem is related to computation resource and time slot allocation, of which the optimal closed-form solution is obtained. The master problem regarding discrete user scheduling variables is constructed by adding optimality cuts or feasibility cuts according to whether the primal problem is feasible, which is a standard mixed-integer linear programming problem and can be efficiently solved. By iteratively solving the primal problem and master problem, the optimal scheduling and resource allocation scheme is obtained. Simulation results demonstrate that the proposed asynchronous computing framework reduces 87.17% energy consumption compared with conventional synchronous computing counterpart.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11377"
    },
    {
        "doc_id": 70,
        "title": "Self-supervised Contrastive Learning for 6G UM-MIMO THz Communications: Improving Robustness Under Imperfect CSI",
        "authors": [
            "Rafid Umayer Murshed",
            "Md Saheed Ullah",
            "Mohammad Saquib",
            "Moe Z. Win"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper investigates the potential of contrastive learning in 6G ultra-massive multiple-input multiple-output (UM-MIMO) communication systems, specifically focusing on hybrid beamforming under imperfect channel state information (CSI) conditions at THz. UM-MIMO systems are promising for future 6G wireless communication networks due to their high spectral efficiency and capacity. The accuracy of CSI significantly influences the performance of UM-MIMO systems. However, acquiring perfect CSI is challenging due to various practical constraints such as channel estimation errors, feedback delays, and hardware imperfections. To address this issue, we propose a novel self-supervised contrastive learning-based approach for hybrid beamforming, which is robust against imperfect CSI. We demonstrate the power of contrastive learning to tackle the challenges posed by imperfect CSI and show that our proposed method results in improved system performance in terms of achievable rate compared to traditional methods.",
        "comments": "6 pages, 7 figures, Submitted to IEEE International Conference on Communications, 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11376"
    },
    {
        "doc_id": 71,
        "title": "Modeling Considerations for Developing Deep Space Autonomous Spacecraft and Simulators",
        "authors": [
            "Christopher Agia",
            "Guillem Casadesus Vila",
            "Saptarshi Bandyopadhyay",
            "David S. Bayard",
            "Kar-Ming Cheung",
            "Charles H. Lee",
            "Eric Wood",
            "Ian Aenishanslin",
            "Steven Ardito",
            "Lorraine Fesq",
            "Marco Pavone",
            "Issa A. D. Nesnas"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "To extend the limited scope of autonomy used in prior missions for operation in distant and complex environments, there is a need to further develop and mature autonomy that jointly reasons over multiple subsystems, which we term system-level autonomy. System-level autonomy establishes situational awareness that resolves conflicting information across subsystems, which may necessitate the refinement and interconnection of the underlying spacecraft and environment onboard models. However, with a limited understanding of the assumptions and tradeoffs of modeling to arbitrary extents, designing onboard models to support system-level capabilities presents a significant challenge.\n  In this paper, we provide a detailed analysis of the increasing levels of model fidelity for several key spacecraft subsystems, with the goal of informing future spacecraft functional- and system-level autonomy algorithms and the physics-based simulators on which they are validated. We do not argue for the adoption of a particular fidelity class of models but, instead, highlight the potential tradeoffs and opportunities associated with the use of models for onboard autonomy and in physics-based simulators at various fidelity levels. We ground our analysis in the context of deep space exploration of small bodies, an emerging frontier for autonomous spacecraft operation in space, where the choice of models employed onboard the spacecraft may determine mission success. We conduct our experiments in the Multi-Spacecraft Concept and Autonomy Tool (MuSCAT), a software suite for developing spacecraft autonomy algorithms.",
        "comments": "Project page: https://sites.google.com/stanford.edu/spacecraft-models. 20 pages, 8 figures. Accepted to the IEEE Conference on Aerospace (AeroConf) 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11371"
    },
    {
        "doc_id": 72,
        "title": "Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation",
        "authors": [
            "Christian Cabrera",
            "Andrei Paleyes",
            "Neil D. Lawrence"
        ],
        "subjects": [
            "Software Engineering",
            "Artificial Intelligence",
            "Systems and Control"
        ],
        "abstract": "Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems' complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems' responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems' performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems' interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.",
        "comments": "Accepted at The 1st International Workshop New Trends in Software Architecture (SATrends) 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11370"
    },
    {
        "doc_id": 73,
        "title": "A Fast Effective Greedy Approach for MU-MIMO Beam Selection in mm-Wave and THz Communications",
        "authors": [
            "Rafid Umayer Murshed",
            "Md Saheed Ullah",
            "Mohammad Saquib"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper addresses the beam-selection challenges in Multi-User Multiple Input Multiple Output (MU-MIMO) beamforming for mm-wave and THz channels, focusing on the pivotal aspect of spectral efficiency (SE) and computational efficiency. We introduce a novel approach, the Greedy Interference-Optimized Singular Vector Beam-selection (G-IOSVB) algorithm, which offers a strategic balance between high SE and low computational complexity. Our study embarks on a comparative analysis of G-IOSVB against the traditional IOSVB and the exhaustive Singular-Vector Beamspace Search (SVBS) algorithms. The findings reveal that while SVBS achieves the highest SE, it incurs significant computational costs, approximately 162 seconds per channel realization. In contrast, G-IOSVB aligns closely with IOSVB in SE performance yet is markedly more computationally efficient. Heatmaps vividly demonstrate this efficiency, highlighting G-IOSVB's reduced computation time without sacrificing SE. We also delve into the mathematical intricacies of G-IOSVB, demonstrating its theoretical and practical superiority through rigorous expressions and detailed algorithmic analysis. The numerical results illustrate that G-IOSVB stands out as an efficient, practical solution for MU-MIMO systems, making it a promising candidate for high-speed, high-efficiency wireless communication networks.",
        "comments": "Accepted for Lecture presentation at the 58th Annual Conference on Information Sciences and Systems, to be held at Princeton University from March 13-15, 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11369"
    },
    {
        "doc_id": 74,
        "title": "Asynchronous Parallel Reinforcement Learning for Optimizing Propulsive Performance in Fin Ray Control",
        "authors": [
            "Xin-Yang Liu",
            "Dariush Bodaghi",
            "Qian Xue",
            "Xudong Zheng",
            "Jian-Xun Wang"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Fish fin rays constitute a sophisticated control system for ray-finned fish, facilitating versatile locomotion within complex fluid environments. Despite extensive research on the kinematics and hydrodynamics of fish locomotion, the intricate control strategies in fin-ray actuation remain largely unexplored. While deep reinforcement learning (DRL) has demonstrated potential in managing complex nonlinear dynamics; its trial-and-error nature limits its application to problems involving computationally demanding environmental interactions. This study introduces a cutting-edge off-policy DRL algorithm, interacting with a fluid-structure interaction (FSI) environment to acquire intricate fin-ray control strategies tailored for various propulsive performance objectives. To enhance training efficiency and enable scalable parallelism, an innovative asynchronous parallel training (APT) strategy is proposed, which fully decouples FSI environment interactions and policy/value network optimization. The results demonstrated the success of the proposed method in discovering optimal complex policies for fin-ray actuation control, resulting in a superior propulsive performance compared to the optimal sinusoidal actuation function identified through a parametric grid search. The merit and effectiveness of the APT approach are also showcased through comprehensive comparison with conventional DRL training strategies in numerical experiments of controlling nonlinear dynamics.",
        "comments": "37 pages, 12 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11349"
    },
    {
        "doc_id": 75,
        "title": "Decentralized Optimization in Networks with Arbitrary Delays",
        "authors": [
            "Tomas Ortega",
            "Hamid Jafarkhani"
        ],
        "subjects": [
            "Optimization and Control",
            "Multiagent Systems",
            "Signal Processing",
            "Systems and Control"
        ],
        "abstract": "We consider the problem of decentralized optimization in networks with communication delays. To accommodate delays, we need decentralized optimization algorithms that work on directed graphs. Existing approaches require nodes to know their out-degree to achieve convergence. We propose a novel gossip-based algorithm that circumvents this requirement, allowing decentralized optimization in networks with communication delays. We prove that our algorithm converges on non-convex objectives, with the same main complexity order term as centralized Stochastic Gradient Descent (SGD), and show that the graph topology and the delays only affect the higher order terms. We provide numerical simulations that illustrate our theoretical results.",
        "comments": "Accepted to IEEE ICC 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11344"
    },
    {
        "doc_id": 76,
        "title": "Error bounds of constant gain least-mean-squares algorithms",
        "authors": [
            "Chang Liu",
            "Antwan D. Clark"
        ],
        "subjects": [
            "Signal Processing",
            "Systems and Control"
        ],
        "abstract": "Constant gain least-mean-squares (LMS) algorithms have a wide range of applications in trajectory tracking problems, but the formal convergence of LMS in mean square is not yet fully established. This work provides an upper bound on the constant gain that guarantees a bounded mean-squared error of LMS for a general design vector. These results highlight the role of the fourth-order moment of the design vector. Numerical examples demonstrate the applicability of this upper bound in setting a constant gain in LMS, while existing criteria may fail. We also provide the associated error bound, which can be applied to design vectors with linearly dependent elements.",
        "comments": "6 pages",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11333"
    },
    {
        "doc_id": 77,
        "title": "A Hierarchical Decision-Based Maintenance for a Complex Modular System Driven by the { MoMA} Algorithm",
        "authors": [
            "M. L. Gamiz",
            "D. Montoro-Cazorla",
            "M. C. Segovia-Garcia"
        ],
        "subjects": [
            "Systems and Control",
            "Methodology"
        ],
        "abstract": "This paper presents a maintenance policy for a modular system formed by K independent modules (n-subsystems) subjected to environmental conditions (shocks). For the modeling of this complex system, the use of the Matrix-Analytical Method (MAM) is proposed under a layered approach according to its hierarchical structure. Thus, the operational state of the system (top layer) depends on the states of the modules (middle layer), which in turn depend on the states of their components (bottom layer). This allows a detailed description of the system operation to plan maintenance actions appropriately and optimally. We propose a hierarchical decision-based maintenance strategy with periodic inspections as follows: at the time of the inspection, the condition of the system is first evaluated. If intervention is necessary, the modules are then checked to make individual decisions based on their states, and so on. Replacement or repair will be carried out as appropriate. An optimization problem is formulated as a function of the length of the inspection period and the intervention cost incurred over the useful life of the system. Our method shows the advantages, providing compact and implementable expressions. The model is illustrated on a submarine Electrical Control Unit (ECU).",
        "comments": "43 pages, 6 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11328"
    },
    {
        "doc_id": 78,
        "title": "Weakly-Supervised Semantic Segmentation of Circular-Scan, Synthetic-Aperture-Sonar Imagery",
        "authors": [
            "Isaac J. Sledge",
            "Dominic M. Byrne",
            "Jonathan L. King",
            "Steven H. Ostertag",
            "Denton L. Woods",
            "James L. Prater",
            "Jermaine L. Kennedy",
            "Timothy M. Marston",
            "Jose C. Principe"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "We propose a weakly-supervised framework for the semantic segmentation of circular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our framework is trained in a supervised manner, on image-level labels, to uncover a set of semi-sparse, spatially-discriminative regions in each image. The classification uncertainty of each region is then evaluated. Those areas with the lowest uncertainties are then chosen to be weakly labeled segmentation seeds, at the pixel level, for the second part of the framework. Each of the seed extents are progressively resized according to an unsupervised, information-theoretic loss with structured-prediction regularizers. This reshaping process uses multi-scale, adaptively-weighted features to delineate class-specific transitions in local image content. Content-addressable memories are inserted at various parts of our framework so that it can leverage features from previously seen images to improve segmentation performance for related images.\n  We evaluate our weakly-supervised framework using real-world CSAS imagery that contains over ten seafloor classes and ten target classes. We show that our framework performs comparably to nine fully-supervised deep networks. Our framework also outperforms eleven of the best weakly-supervised deep networks. We achieve state-of-the-art performance when pre-training on natural imagery. The average absolute performance gap to the next-best weakly-supervised network is well over ten percent for both natural imagery and sonar imagery. This gap is found to be statistically significant.",
        "comments": "Submitted to the IEEE Journal of Oceanic Engineering",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11313"
    },
    {
        "doc_id": 79,
        "title": "RoTIR: Rotation-Equivariant Network and Transformers for Fish Scale Image Registration",
        "authors": [
            "Ruixiong Wang",
            "Alin Achim",
            "Renata Raele-Rolfe",
            "Qiao Tong",
            "Dylan Bergen",
            "Chrissy Hammond",
            "Stephen Cross"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "Image registration is an essential process for aligning features of interest from multiple images. With the recent development of deep learning techniques, image registration approaches have advanced to a new level. In this work, we present 'Rotation-Equivariant network and Transformers for Image Registration' (RoTIR), a deep-learning-based method for the alignment of fish scale images captured by light microscopy. This approach overcomes the challenge of arbitrary rotation and translation detection, as well as the absence of ground truth data. We employ feature-matching approaches based on Transformers and general E(2)-equivariant steerable CNNs for model creation. Besides, an artificial training dataset is employed for semi-supervised learning. Results show RoTIR successfully achieves the goal of fish scale image registration.",
        "comments": "7 pages, 4 figures, 2 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11270"
    },
    {
        "doc_id": 80,
        "title": "Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric",
        "authors": [
            "Golara Javadi",
            "Kamer Ali Yuksel",
            "Yunsu Kim",
            "Thiago Castro Ferreira",
            "Mohamed Al-Badrashiny"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "In the realm of automatic speech recognition (ASR), the quest for models that not only perform with high accuracy but also offer transparency in their decision-making processes is crucial. The potential of quality estimation (QE) metrics is introduced and evaluated as a novel tool to enhance explainable artificial intelligence (XAI) in ASR systems. Through experiments and analyses, the capabilities of the NoRefER (No Reference Error Rate) metric are explored in identifying word-level errors to aid post-editors in refining ASR hypotheses. The investigation also extends to the utility of NoRefER in the corpus-building process, demonstrating its effectiveness in augmenting datasets with insightful annotations. The diagnostic aspects of NoRefER are examined, revealing its ability to provide valuable insights into model behaviors and decision patterns. This has proven beneficial for prioritizing hypotheses in post-editing workflows and fine-tuning ASR models. The findings suggest that NoRefER is not merely a tool for error detection but also a comprehensive framework for enhancing ASR systems' transparency, efficiency, and effectiveness. To ensure the reproducibility of the results, all source codes of this study are made publicly available.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11268"
    },
    {
        "doc_id": 81,
        "title": "AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking",
        "authors": [
            "Mehmet Y. Turali",
            "Mehmet E. Lorasdagi",
            "Ali T. Koc",
            "Suleyman S. Kozat"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Machine Learning"
        ],
        "abstract": "We study the problem of feature selection in general machine learning (ML) context, which is one of the most critical subjects in the field. Although, there exist many feature selection methods, however, these methods face challenges such as scalability, managing high-dimensional data, dealing with correlated features, adapting to variable feature importance, and integrating domain knowledge. To this end, we introduce the ``Adaptive Feature Selection with Binary Masking\" (AFS-BM) which remedies these problems. AFS-BM achieves this by joint optimization for simultaneous feature selection and model training. In particular, we do the joint optimization and binary masking to continuously adapt the set of features and model parameters during the training process. This approach leads to significant improvements in model accuracy and a reduction in computational requirements. We provide an extensive set of experiments where we compare AFS-BM with the established feature selection methods using well-known datasets from real-life competitions. Our results show that AFS-BM makes significant improvement in terms of accuracy and requires significantly less computational complexity. This is due to AFS-BM's ability to dynamically adjust to the changing importance of features during the training process, which an important contribution to the field. We openly share our code for the replicability of our results and to facilitate further research.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11250"
    },
    {
        "doc_id": 82,
        "title": "Hierarchical Cell-Free Massive MIMO for High Capacity with Simple Implementation",
        "authors": [
            "Wei Jiang",
            "Hans D. Schotten"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Cell-free massive multi-input multi-output (MIMO) has recently gained much attention for its potential in shaping the landscape of sixth-generation (6G) wireless systems. This paper proposes a hierarchical network architecture tailored for cell-free massive MIMO, seamlessly integrating co-located and distributed antennas. A central base station (CBS), equipped with an antenna array, positions itself near the center of the coverage area, complemented by distributed access points spanning the periphery. The proposed architecture remarkably outperforms conventional cell-free networks, demonstrating superior sum throughput while maintaining a comparable worst-case per-user spectral efficiency. Meanwhile, the implementation cost associated with the fronthaul network is substantially diminished.",
        "comments": "2024 IEEE International Conference on Communications (ICC-2024)",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11236"
    },
    {
        "doc_id": 83,
        "title": "Susceptibility of Adversarial Attack on Medical Image Segmentation Models",
        "authors": [
            "Zhongxuan Wang",
            "Leo Xu"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The nature of deep neural networks has given rise to a variety of attacks, but little work has been done to address the effect of adversarial attacks on segmentation models trained on MRI datasets. In light of the grave consequences that such attacks could cause, we explore four models from the U-Net family and examine their responses to the Fast Gradient Sign Method (FGSM) attack. We conduct FGSM attacks on each of them and experiment with various schemes to conduct the attacks. In this paper, we find that medical imaging segmentation models are indeed vulnerable to adversarial attacks and that there is a negligible correlation between parameter size and adversarial attack success. Furthermore, we show that using a different loss function than the one used for training yields higher adversarial attack success, contrary to what the FGSM authors suggested. In future efforts, we will conduct the experiments detailed in this paper with more segmentation models and different attacks. We will also attempt to find ways to counteract the attacks by using model ensembles or special data augmentations. Our code is available at https://github.com/ZhongxuanWang/adv_attk",
        "comments": "6 pages, 8 figures, presented at 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI) conference",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11224"
    },
    {
        "doc_id": 84,
        "title": "3D Receiver for Molecular Communications in Internet of Organoids",
        "authors": [
            "Shaojie Zhang",
            "Ozgur B. Akan"
        ],
        "subjects": [
            "Emerging Technologies",
            "Systems and Control"
        ],
        "abstract": "Organoids have garnered attention due to their effectiveness in modeling the 3D structure of organ interactions. However, the communication engineering perspective has received relatively little attention. One way to achieve organoids communication is molecular communication (MC). Molecular communication is a bio-inspired communication paradigm that uses molecules as information carriers. It is considered one of the most promising methods for enabling the Internet of Nano-Things (IoNT) and nanonetworks. BioFETs are commonly used to implement practical MC receivers. However, most previous analyses have focused on a planar device, neglecting considerations like the threshold voltage and its potential 3D structure. This paper introduces the first FinFET-based MC receiver that covers both the top and side gates with receptors. Both binding noise and flicker noise are considered in the analysis. The performance, in terms of signal-to-noise ratio (SNR) and symbol error probability (SEP), is compared with that of the 2D receiver.",
        "comments": "10 pages, 11 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11214"
    },
    {
        "doc_id": 85,
        "title": "Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO Systems",
        "authors": [
            "Jintao Wang",
            "Chengzhi Ma",
            "Shiqi Gong",
            "Xi Yang",
            "Shaodan Ma"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Considering the appealing distribution gains of distributed antenna systems (DAS) and passive gains of reconfigurable intelligent surface (RIS), a flexible reconfigurable architecture called reconfigurable distributed antenna and reflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as two special cases and maintains the advantages of distributed antennas while reducing the hardware cost by replacing some active antennas with low-cost passive reflecting surfaces. In this paper, we present a RDARS-aided uplink multi-user communication system and investigate the system transmission reliability with the newly proposed architecture. Specifically, in addition to the distribution gain and the reflection gain provided by the connection and reflection modes, respectively, we also consider the dynamic mode switching of each element which introduces an additional degree of freedom (DoF) and thus results in a selection gain. As such, we aim to minimize the total sum mean-square-error (MSE) of all data streams by jointly optimizing the receive beamforming matrix, the reflection phase shifts and the channel-aware placement of elements in the connection mode. To tackle this nonconvex problem with intractable binary and cardinality constraints, we propose an inexact block coordinate descent (BCD) based penalty dual decomposition (PDD) algorithm with the guaranteed convergence. Since the PDD algorithm usually suffers from high computational complexity, a low-complexity greedy-search-based alternating optimization (AO) algorithm is developed to yield a semi-closed-form solution with acceptable performance. Numerical results demonstrate the superiority of the proposed architecture compared to the conventional fully passive RIS or DAS. Furthermore, some insights about the practical implementation of RDARS are provided.",
        "comments": "13 pages, 9 figures. This paper has been submitted to IEEE journal for possible publication",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11205"
    },
    {
        "doc_id": 86,
        "title": "Transversally exponentially stable Euclidean space extension technique for discrete time systems",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "We propose a modification technique for discrete time systems for exponentially fast convergence to compact sets. The extension technique allows us to use tools defined on Euclidean spaces to systems evolving on manifolds by modifying the dynamics of the system such that the manifold is an attractor set. We show the stability properties of this technique using the simulation of the rigid body rotation system on the unit sphere $S^3$. We also show the improvement afforded due to this technique on a Luenberger like observer designed for the rigid body rotation system on $S^3$.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11200"
    },
    {
        "doc_id": 87,
        "title": "Projected Belief Networks With Discriminative Alignment for Acoustic Event Classification: Rivaling State of the Art CNNs",
        "authors": [
            "Paul M. Baggenstoss",
            "Kevin Wilkinghoff",
            "Felix Govaers",
            "Frank Kurth"
        ],
        "subjects": [
            "Machine Learning",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "The projected belief network (PBN) is a generative stochastic network with tractable likelihood function based on a feed-forward neural network (FFNN). The generative function operates by \"backing up\" through the FFNN. The PBN is two networks in one, a FFNN that operates in the forward direction, and a generative network that operates in the backward direction. Both networks co-exist based on the same parameter set, have their own cost functions, and can be separately or jointly trained. The PBN therefore has the potential to possess the best qualities of both discriminative and generative classifiers. To realize this potential, a separate PBN is trained on each class, maximizing the generative likelihood function for the given class, while minimizing the discriminative cost for the FFNN against \"all other classes\". This technique, called discriminative alignment (PBN-DA), aligns the contours of the likelihood function to the decision boundaries and attains vastly improved classification performance, rivaling that of state of the art discriminative networks. The method may be further improved using a hidden Markov model (HMM) as a component of the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of PBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification experiments are provided. The first experiment uses air-acoustic events, and the second uses underwater acoustic data consisting of marine mammal calls. In both experiments, PBN-DA-HMM attains comparable or better performance as a state of the art CNN, and attain a factor of two error reduction when combined with the CNN.",
        "comments": "15 Pages. Submitted to IEEE-TNNLS",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11199"
    },
    {
        "doc_id": 88,
        "title": "Machine learning based state observer for discrete time systems evolving on Lie groups",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning"
        ],
        "abstract": "In this paper, a machine learning based observer for systems evolving on manifolds is designed such that the state of the observer is restricted to the Lie group on which the system evolves. Conventional techniques involving machine learning based observers on systems evolving on Lie groups involve designing charts for the Lie group, training a machine learning based observer for each chart, and switching between the trained models based on the state of the system. We propose a novel deep learning based technique whose predictions are restricted to a measure 0 subset of Euclidean space without using charts. Using this network, we design an observer ensuring that the state of the observer is restricted to the Lie group, and predicting the state using only one trained algorithm. The deep learning network predicts an ``error term'' on the Lie algebra of the Lie group, uses the map from the Lie algebra to the group, and uses the group action and the present state to estimate the state at the next epoch. This model being purely data driven does not require the model of the system. The proposed algorithm provides a novel framework for constraining the output of machine learning networks to a measure 0 subset of a Euclidean space without chart specific training and without requiring switching. We show the validity of this method using Monte Carlo simulations performed of the rigid body rotation and translation system.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11196"
    },
    {
        "doc_id": 89,
        "title": "Triple-Refined Hybrid-Field Beam Training for mmWave Extremely Large-Scale MIMO",
        "authors": [
            "Kangjian Chen",
            "Chenhao Qi",
            "Octavia A. Dobre",
            "Geoffrey Ye Li"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper investigates beam training for extremely large-scale multiple-input multiple-output systems. By considering both the near field and far field, a triple-refined hybrid-field beam training scheme is proposed, where high-accuracy estimates of channel parameters are obtained through three steps of progressive beam refinement. First, the hybrid-field beam gain (HFBG)-based first refinement method is developed. Based on the analysis of the HFBG, the first-refinement codebook is designed and the beam training is performed accordingly to narrow down the potential region of the channel path. Then, the maximum likelihood (ML)-based and principle of stationary phase (PSP)-based second refinement methods are developed. By exploiting the measurements of the beam training, the ML is used to estimate the channel parameters. To avoid the high computational complexity of ML, closed-form estimates of the channel parameters are derived according to the PSP. Moreover, the Gaussian approximation (GA)-based third refinement method is developed. The hybrid-field neighboring search is first performed to identify the potential region of the main lobe of the channel steering vector. Afterwards, by applying the GA, a least-squares estimator is developed to obtain the high-accuracy channel parameter estimation. Simulation results verify the effectiveness of the proposed scheme.",
        "comments": "Journal ref:        IEEE Transactions on Wireless Communications, 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11195"
    },
    {
        "doc_id": 90,
        "title": "Angular velocity and linear acceleration measurement bias estimators for the rigid body system with global exponential convergence",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Rigid body systems usually consider measurements of the pose of the body using onboard cameras/LiDAR systems, that of linear acceleration using an accelerometer and of angular velocity using an IMU. However, the measurements of the linear acceleration and angular velocity are usually biased with an unknown constant or slowly varying bias. We propose a measurement bias estimator for such systems under assumption of boundedness of angular velocity. We also provide continuous estimates to the state of the system, i.e. the pose, linear velocity, and position of the body. These estimates are globally exponentially convergent to the state of the rigid body system. We propose two bias estimators designed with the estimate of the pose in the ambient Euclidean space of the Special Euclidean group and show global exponential convergence of the proposed observers to the state of the system. The first observer assumes knowledge of bounds of the angular velocity, while the second observer uses a Riccati observer to overcome this limitation. We show the convergence with an example of a rigid body rotation and translation system on the special Euclidean group. We show that the observer is able to estimate the bias using data collected from an Intel Realsense camera.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11191"
    },
    {
        "doc_id": 91,
        "title": "Globally exponentially convergent observer for systems evolving on matrix Lie groups",
        "authors": [
            "Soham Shanbhag",
            "Dong Eui Chang"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "We propose a globally exponentially convergent observer for the dynamical system evolving on matrix Lie groups with bounded velocity with unknown bound. We design the observer in the ambient Euclidean space and show exponential convergence of the observer to the state of the system. We show the convergence with an example of a rigid body rotation and translation system on the special Euclidean group. We compare the proposed observer with an observer present in the literature.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11189"
    },
    {
        "doc_id": 92,
        "title": "Predictive stability filters for nonlinear dynamical systems affected by disturbances",
        "authors": [
            "Alexandre Didier",
            "Andrea Zanelli",
            "Kim P. Wabersich",
            "Melanie N. Zeilinger"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Predictive safety filters provide a way of projecting potentially unsafe inputs onto the set of inputs that guarantee recursive state and input constraint satisfaction. Unsafe inputs, proposed, e.g. by a human or learning-based controller, can thereby be filtered by leveraging model predictive control techniques. In this paper, we extend this framework such that in addition, robust asymptotic stability of the closed-loop system can be guaranteed by enforcing a decrease of an implicit Lyapunov function which is constructed using a predicted system trajectory. Differently from previous results, we show robust asymptotic stability on an extended state consisting of the system state and a warmstart input sequence and establish robust asymptotic stability for the augmented dynamics with respect to a predefined disturbance. The proposed strategy is applied to an automotive lane keeping example in simulation.",
        "comments": "Submitted to NMPC'24",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11183"
    },
    {
        "doc_id": 93,
        "title": "Data-Driven Target Localization: Benchmarking Gradient Descent Using the Cram\u00e9r-Rao Bound",
        "authors": [
            "Shyam Venkatasubramanian",
            "Sandeep Gogineni",
            "Bosung Kang",
            "Ali Pezeshki",
            "Muralidhar Rangaswamy",
            "Vahid Tarokh"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning"
        ],
        "abstract": "In modern radar systems, precise target localization using azimuth and velocity estimation is paramount. Traditional unbiased estimation methods have leveraged gradient descent algorithms to reach the theoretical limits of the Cram\u00e9r Rao Bound (CRB) for the error of the parameter estimates. In this study, we present a data-driven neural network approach that outperforms these traditional techniques, demonstrating improved accuracies in target azimuth and velocity estimation. Using a representative simulated scenario, we show that our proposed neural network model consistently achieves improved parameter estimates due to its inherently biased nature, yielding a diminished mean squared error (MSE). Our findings underscore the potential of employing deep learning methods in radar systems, paving the way for more accurate localization in cluttered and dynamic environments.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11176"
    },
    {
        "doc_id": 94,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 95,
        "title": "Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe Reinforcement Learning",
        "authors": [
            "Jingyuan Zhou",
            "Longhao Yan",
            "Kaidi Yang"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Connected and automated vehicles (CAVs) have recently gained prominence in traffic research, thanks to the advancements in communication technology and autonomous driving. A variety of longitudinal control strategies for CAVs have been developed to enhance traffic efficiency, stability, and safety in mixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promising strategy for mixed-autonomy platoon control since it can tackle complex scenarios in real-time. However, there are three research gaps for DRL-based mixed-autonomy platoon control. First, incorporating safety considerations into DRL typically relies on designing collision avoidance-based reward functions, which lack collision-free guarantees. Second, current DRL-based-control approaches for mixed traffic only consider the safety of CAVs, with little attention paid to the surrounding HDVs. To address the research gaps, we introduce a differentiable safety layer that converts DRL actions into safe actions with collision-free guarantees. This process relies on solving a differentiable quadratic programming problem that incorporates control barrier function-based (CBF) safety constraints for both CAV and its following HDVs to achieve system-level safety. Moreover, constructing CBF constraints needs system dynamics for the following HDVs, and thus we employ an online system identification module to estimate the car-following dynamics of the surrounding HDVs. The proposed safe reinforcement learning approach explicitly integrates system-level safety constraints into the training process and enables our method to adapt to varying safety-critical scenarios. Simulation results demonstrate that our proposed method effectively ensures CAV safety and improves HDV safety in mixed platoon environments while simultaneously enhancing traffic capacity and string stability.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11148"
    },
    {
        "doc_id": 96,
        "title": "Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities",
        "authors": [
            "Georgios Ioannides",
            "Aman Chadha",
            "Aaron Elkins"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computation and Language",
            "Computer Vision and Pattern Recognition",
            "Sound",
            "Audio and Speech Processing",
            "Signal Processing"
        ],
        "abstract": "We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy across a diverse range of tasks, including emotion recognition in speech, image classification, and text classification, thereby establishing its robustness and versatility in handling multi-modal data. Furthermore, we introduce the Importance Factor (IF), a new learning-based metric that enhances the explainability of models trained with GAAM-based methods. Overall, GAAM represents an advancement towards development of better performing and more explainable attention models across multiple modalities.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11143"
    },
    {
        "doc_id": 97,
        "title": "Wideband Beamforming for RIS Assisted Near-Field Communications",
        "authors": [
            "Ji Wang",
            "Jian Xiao",
            "Yixuan Zou",
            "Wenwu Xie",
            "Yuanwei Liu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "A near-field wideband beamforming scheme is investigated for reconfigurable intelligent surface (RIS) assisted multiple-input multiple-output (MIMO) systems, in which a deep learning-based end-to-end (E2E) optimization framework is proposed to maximize the system spectral efficiency. To deal with the near-field double beam split effect, the base station is equipped with frequency-dependent hybrid precoding architecture by introducing sub-connected true time delay (TTD) units, while two specific RIS architectures, namely true time delay-based RIS (TTD-RIS) and virtual subarray-based RIS (SA-RIS), are exploited to realize the frequency-dependent passive beamforming at the RIS. Furthermore, the efficient E2E beamforming models without explicit channel state information are proposed, which jointly exploits the uplink channel training module and the downlink wideband beamforming module. In the proposed network architecture of the E2E models, the classical communication signal processing methods, i.e., polarized filtering and sparsity transform, are leveraged to develop a signal-guided beamforming network. Numerical results show that the proposed E2E models have superior beamforming performance and robustness to conventional beamforming benchmarks. Furthermore, the tradeoff between the beamforming gain and the hardware complexity is investigated for different frequency-dependent RIS architectures, in which the TTD-RIS can achieve better spectral efficiency than the SA-RIS while requiring additional energy consumption and hardware cost.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11141"
    },
    {
        "doc_id": 98,
        "title": "Reconfigurable Intelligent Surface-Enabled Array Radar for Interference Mitigation",
        "authors": [
            "Shengyao Chen",
            "Qi Feng",
            "Longyao Ran",
            "Feng Xi",
            "Zhong Liu"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Conventional active array radars often jointly design the transmit and receive beamforming for effectively suppressing interferences. To further promote the interference suppression performance, this paper introduces a reconfigurable intelligent surface (RIS) to assist the radar receiver because the RIS has the ability to bring plentiful additional degrees-of-freedom. To maximize the output signal-to-interference-plus-noise ratio (SINR) of receive array, we formulate the codesign of transmit beamforming and RIS-aided receive beamforming into a nonconvex constrained fractional programming problem, and then propose an alternating minimization-based algorithm to jointly optimize the transmit beamformer, receive beamformer and RIS reflection coefficients. Specifically, we offer the closed-form optimal solutions of transmit and receive beamformers according to the minimum variance distortionless response principle, and translate the RIS reflection coefficients design into a series of unimodular quadratic programming (UQP) subproblems by employing the Dinkelbach transform. To tackle the UQP subproblems efficiently, we propose a second-order Riemannian Newton method (RNM) with improved Riemannian Newton direction, which avoids the line search and has better convergence speed than typical first-order Riemannian manifold optimization methods. Moreover, we derive the convergence of the proposed codesign algorithm by deducing the explicit convergence condition of RNM. We also analyze the computational complexity. Numerical results demonstrate that the proposed RIS-aided array radar has superior performance of interference suppression to the RIS-free one, and the SINR improvement is proportional to the number of RIS elements.",
        "comments": "28 pages, 9 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11137"
    },
    {
        "doc_id": 99,
        "title": "A Finger on the Pulse of Cardiovascular Health: Smartphone Photoplethysmography-Based Pulse Waveform Analysis for Blood Pressure Measurement",
        "authors": [
            "Ivan Liu",
            "Fangyuan Liu",
            "Qi Zhong",
            "Shiguang Ni"
        ],
        "subjects": [
            "Signal Processing",
            "Computers and Society"
        ],
        "abstract": "Routine blood pressure (BP) monitoring, crucial for health assessment, faces challenges such as limited access to medical-grade equipment and expertise. Portable cuff BP devices, on the other hand, are cumbersome to carry all day and often cost-prohibitive in less developed countries. Besides, these sphygmomanometer-based devices can cause discomfort and disrupt blood flow during measurement. This study explores the use of smartphones for continuous BP monitoring, focusing on overcoming the trust barriers associated with the opacity of machine learning models in predicting BP from low-quality PPG signals. Our approach included developing models based on cardiovascular literature, using simple statistical methods to estimate BP from smartphone PPG signals with comprehensive data pre-processing, applying SHAP for enhanced interpretability and feature identification, and comparing our methods against standard references using Bland-Altman analysis. Validated with data from 125 participants, the study demonstrated significant correlations in waveform features between smartphone and reference BP monitoring devices. The cross-validation of linear regression [MAE=9.86 and 8.01 mmHg for systolic blood pressure (SBP) and diastolic blood pressure (DBP), respectively] and random forest model (MAE=8.91 and 6.68 mmHg for SBP and DBP) using waveform-only variables demonstrated the feasibility of using a smartphone to estimate BP. Although SHAP analysis identified key feature sets, Bland-Altman results did not fully meet established thresholds (84.64% and 94.69% of MAE<15 mmHg for SBP and DBP, respectively). The study suggests the potential of smartphone cameras to enhance the accuracy and interpretability of machine learning models for daily BP estimation, but also indicates that smartphone PPG-based BP prediction is not yet a replacement for traditional medical devices.",
        "comments": "33 pages, 9 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11117"
    },
    {
        "doc_id": 100,
        "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
        "authors": [
            "Tahereh Zarrat Ehsan",
            "Seyed Mehdi Mohtavipour"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal chicken health conditions, minimizing economic losses and bolstering profitability. This paper presents a novel real-time framework for analyzing chicken behavior in cage-free poultry houses to detect abnormal behaviors. Specifically, two significant abnormalities, namely inactive broiler and huddling behavior, are investigated in this study. The proposed framework comprises three key steps: (1) chicken detection utilizing a state-of-the-art deep learning model, (2) tracking individual chickens across consecutive frames with a fast tracker module, and (3) detecting abnormal behaviors within the video stream. Experimental studies are conducted to evaluate the efficacy of the proposed algorithm in accurately assessing chicken behavior. The results illustrate that our framework provides a precise and efficient solution for real-time anomaly detection, facilitating timely interventions to maintain chicken health and enhance overall productivity on poultry farms. Github: https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
        "comments": "11 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12176"
    },
    {
        "doc_id": 101,
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Theoretical Economics"
        ],
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about centralization in block-building (due to, e.g., MEV and private order flow) and the outsourcing of block-building by validators to specialists (i.e., proposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers inevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve decentralization among proposers?\n  This paper develops mathematical models and results that offer answers to these questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block producer rewards, and staking costs, we quantify the extent to which heterogeneous rewards lead to concentration in the equilibrium staking distribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly reinvest rewards into staking, we quantify, as a function of the block producer heterogeneity, the rate at which stake concentrates on the most sophisticated block producers.\n  3. In a model with heterogeneous proposers and specialized builders, we quantify, as a function of the competitiveness of the builder ecosystem, the extent to which proposer-builder separation reduces the heterogeneity in rewards across different proposers.\n  Our models and results take advantage of connections to contest design, P\u00f3lya urn processes, and auction theory.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12120"
    },
    {
        "doc_id": 102,
        "title": "Measures of the Capital Network of the U.S. Economy",
        "authors": [
            "Ben Klemens"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "About two million U.S. corporations and partnerships are linked to each other and human investors by about 15 million owner-subsidiary links. Comparable social networks such as corporate board memberships and socially-built systems such as the network of Internet links are \"small worlds,\" meaning a network with a small diameter and link densities with a power-law distribution, but these properties had not yet been measured for the business entity network. This article shows that both inbound links and outbound links display a power-law distribution with a coefficient of concentration estimable to within a generally narrow confidence interval, overall, for subnetworks including only business entities, only for the great connected component of the network, and in subnetworks with edges associated with certain industries, for all years 2009-2021. In contrast to other networks with power-law distributed link densities, the network is mostly a tree, and has a diameter an order of magnitude larger than a small-world network with the same link distribution. The regularity of the power-law distribution indicates that its coefficient can be used as a new, well-defined macroeconomic metric for the concentration of capital flows in an economy. Economists might use it as a new measure of market concentration which is more comprehensive than measures based only on the few biggest firms. Comparing capital link concentrations across countries would facilitate modeling the relationship between business network characteristics and other macroeconomic indicators.",
        "comments": "18 pages. JEL classifications: L14; C81; M42; G34",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12118"
    },
    {
        "doc_id": 103,
        "title": "Metrics matter, a Formal comment on Ward et al Plos-One 2016 paper : Is decoupling GDP growth from environmental impact possible?",
        "authors": [
            "Herv\u00e9 Bercegol",
            "Paul E. Brockway"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The Ward et al. (2016) Plos-One paper is an important, heavily-cited paper in the decoupling literature. The authors present evidence of 1990-2015 growth in material and energy consumption and GDP at a world level, and for selected countries. They find only relative decoupling has occurred, leading to their central claim that future absolute decoupling is implausible. However, the authors have made two key errors in their collected data: GDP data is in current prices which includes inflation, and their global material use data is the total mass of fossil energy materials. Strictly, GDP data should be in constant prices to allow for its comparison over time, and material inputs to an economy should be the sum of mineral raw materials. Amending for these errors, we find much smaller levels of energy-GDP relative decoupling, and no materials-GDP decoupling at all at a global level. We check these new results by adding data for 1900-1990 to provide a longer time series, and find consistently low (and even no) levels of global relative decoupling of material use. The central claim for materials over the implausibility of future absolute decoupling therefore not only remains valid but is reinforced by the corrected datasets.",
        "comments": "6 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12100"
    },
    {
        "doc_id": 104,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 105,
        "title": "Market Responses to Genuine Versus Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers",
        "authors": [
            "Chen Liang",
            "Murat Tunc",
            "Gordon Burtch"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction"
        ],
        "abstract": "Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about the motivations of donors in these charity fundraisers, resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity, based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of strategic generosity), and based on an individual's degree of social exposure within the NFT marketplace. We show that charity-NFT \"relisters\" experience significant penalties in the market, in terms of the prices they are able to command on other NFT listings, particularly among those who relist quickly and those who are more socially exposed. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12064"
    },
    {
        "doc_id": 106,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 107,
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "Several of the classical results in social choice theory demonstrate that in order for many voting systems to be well-behaved the set domain of individual preferences must satisfy some kind of restriction, such as being single-peaked on a political axis. As a consequence it becomes interesting to measure how diverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference diversity, focusing on the abundance of distinct suborders one subsets of the alternative. We provide a common generalisation of the frequently used concepts of ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our theorems imply a ceiling for the local diversity in domains on large sets of alternatives, which show that in this measure Black's single-peaked domain is in fact optimal. We also demonstrate that for some numbers of alternatives, there are Condorcet domains which have largest local diversity without having maximum order.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11912"
    },
    {
        "doc_id": 108,
        "title": "Efficiency in random allocation with ordinal rules",
        "authors": [
            "Samson Alva",
            "Eun Jeong Heo",
            "Vikram Manjunath"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study ordinal rules for allocating indivisible goods via lottery. Ordinality requires a rule to consider only how agents rank degenerate lotteries and may be necessitated by cognitive, informational, or as we show, incentive constraints. The limited responsiveness of ordinal rules to agents' preferences means that they can only satisfy welfare properties based on first order stochastic dominance, which is incomplete.\n  We define a new efficiency concept for ordinal rules. While ordinality and efficiency together are incompatible with the usual notions of fairness and somewhat limit randomization, they does leave room for a rich class of rules. We demonstrate this through a characterization of all ordinal, efficient, strategy-proof, non-bossy, boundedly invariant, and neutral rules.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11899"
    },
    {
        "doc_id": 109,
        "title": "Finite horizon optimal control of reaction-diffusion SIV epidemic system with stochastic environment",
        "authors": [
            "Zong Wang"
        ],
        "subjects": [
            "Optimization and Control",
            "Dynamical Systems"
        ],
        "abstract": "This contribution mainly focuses on the finite horizon optimal control problems of a susceptible-infected-vaccinated(SIV) epidemic system governed by reaction-diffusion equations and Markov switching. Stochastic dynamic programming is employed to find the optimal vaccination effort and economic return for a stochastic reaction diffusion SIV epidemic model. To achieve this, a key step is to show the existence and uniqueness of invariant measure for the model. Then, we obtained the necessary and sufficient conditions for the near-optimal control. Furthermore, we give an algorithm to approximate the Hamilton-Jacobi Bellman (HJB) equation. Finally, some numerical simulations are presented to confirm our analytic results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11744"
    },
    {
        "doc_id": 110,
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "authors": [
            "Yu Zhu",
            "Kang Li",
            "Lequan Yu",
            "Pheng-Ann Heng"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.",
        "comments": "Accepted by AAAI 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11674"
    },
    {
        "doc_id": 111,
        "title": "Analyzing the Impact of Financial Inclusion on Economic Growth in Bangladesh",
        "authors": [
            "Ganapati Kumar Biswas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial inclusion is touted one of the principal drivers for economic growth for an economy. The study aims to explore the impact of financial inclusion on economic growth in Bangladesh. In my study, I used the number of loan accounts as the proxy for financial inclusion. Using time series data from spans from 2004-2021, the study revealed that there exists a long-run relationship between GDP, financial inclusion, and other macroeconomic variables in Bangladesh. The study also found that financial inclusion had a positive impact on economic growth of Bangladesh during the study period. Therefore, the policymakers and the central bank of Bangladesh as the apex authority of financial system should promote financial inclusion activities to achieve sustainable economic growth.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11585"
    },
    {
        "doc_id": 112,
        "title": "A note on the stability of Monotone Markov Chains",
        "authors": [
            "Bar Light"
        ],
        "subjects": [
            "Probability",
            "Theoretical Economics"
        ],
        "abstract": "This note studies monotone Markov chains a subclass of Markov chains with extensive applications in operations research and economics. While the properties that ensure the global stability of these chains are well studied, their establishment often relies on the fulfillment of a certain splitting condition. We address the challenges of verifying the splitting condition, by introducing simple, applicable conditions that ensure global stability. The simplicity of these conditions is demonstrated through various examples including autoregressive processes and portfolio allocation problems.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11568"
    },
    {
        "doc_id": 113,
        "title": "Taxi dispatching strategies with compensations",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski",
            "Javier Palanca",
            "Javier Bajo"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi vehicles are key elements in daily traffic activity. The advance of ICT and geo-positioning systems has given rise to new opportunities for improving the efficiency of taxi fleets in terms of waiting times of passengers, cost and time for drivers, traffic density, CO2 emissions, etc., by using more informed, intelligent dispatching. Still, the explicit spatial and temporal components, as well as the scale and, in particular, the dynamicity of the problem of pairing passengers and taxis in big towns, render traditional approaches for solving standard assignment problem useless for this purpose, and call for intelligent approximation strategies based on domain-specific heuristics. Furthermore, taxi drivers are often autonomous actors and may not agree to participate in assignments that, though globally efficient, may not be sufficently beneficial for them individually. This paper presents a new heuristic algorithm for taxi assignment to customers that considers taxi reassignments if this may lead to globally better solutions. In addition, as such new assignments may reduce the expected revenues of individual drivers, we propose an economic compensation scheme to make individually rational drivers agree to proposed modifications in their assigned clients. We carried out a set of experiments, where several commonly used assignment strategies are compared to three different instantiations of our heuristic algorithm. The results indicate that our proposal has the potential to reduce customer waiting times in fleets of autonomous taxis, while being also beneficial from an economic point of view.",
        "comments": "ACM Class:          I.2.1",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11553"
    },
    {
        "doc_id": 114,
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "authors": [
            "Zhigang Wang",
            "Xu Zhang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Transformer-based models are becoming deeper and larger recently. For better scalability, an underlying training solution in industry is to split billions of parameters (tensors) into many tasks and then run them across homogeneous accelerators (e.g., GPUs). However, such dedicated compute cluster is prohibitively expensive in academia and moderate companies. An economic replacement is to aggregate existing heterogeneous devices and share resources among multi-tenants. Nevertheless, static hardware configurations and dynamic resource contention definitely cause straggling tasks, which heavily slows down the overall training efficiency. Existing works feature contributions mainly tailored for traditional data parallelism. They cannot work well for the new tensor parallelism due to strict communication and correctness constraints.\n  In this paper we first present ZERO-resizing, a novel dynamic workload balancing technique without any data migration. We tune workloads in real-time by temporarily resizing matrices involved in core tensor-related computations. We particularly design data imputation and priority selection policies to respectively satisfy consistency constraint required by normal training and reduce the accuracy loss. We also give a lightweight data migration technique without loss of accuracy, to cope with heavy heterogeneity. Our final SEMI-migration solution is built on top of these two techniques and can adaptively distinguish their respective balancing missions, to achieve an overall success in efficiency and accuracy. Extensive experiments on the representative Colossal-AI platform validate the effectiveness of our proposals.",
        "comments": "13 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11469"
    },
    {
        "doc_id": 115,
        "title": "Local Identification in the Instrumental Variable Multivariate Quantile Regression Model",
        "authors": [
            "Haruki Kono"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The instrumental variable (IV) quantile regression model introduced by Chernozhukov and Hansen (2005) is a useful tool for analyzing quantile treatment effects in the presence of endogeneity, but when outcome variables are multidimensional, it is silent on the joint distribution of different dimensions of each variable. To overcome this limitation, we propose an IV model built on the optimal-transport-based multivariate quantile that takes into account the correlation between the entries of the outcome variable. We then provide a local identification result for the model. Surprisingly, we find that the support size of the IV required for the identification is independent of the dimension of the outcome vector, as long as the IV is sufficiently informative. Our result follows from a general identification theorem that we establish, which has independent theoretical significance.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11422"
    },
    {
        "doc_id": 116,
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "authors": [
            "Md Zubair",
            "Md. Shahidul Salim",
            "Mehrab Mustafy Rahman",
            "Mohammad Jahid Ibna Basher",
            "Shahin Imran",
            "Iqbal H. Sarker"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with higher accuracy. These predictions guide our system to assist the farmers in making feasible decisions about planting, irrigation, harvesting, and so on. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.",
        "comments": "16 pages, 14 figures and 12 tables. Submitted to Engineering Application of Artificial Intelligence (Elsevier)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11410"
    },
    {
        "doc_id": 117,
        "title": "Fake Google restaurant reviews and the implications for consumers and restaurants",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The use of online reviews to aid with purchase decisions is popular among consumers as it is a simple heuristic tool based on the reported experiences of other consumers. However, not all online reviews are written by real consumers or reflect actual experiences, and present implications for consumers and businesses. This study examines the effects of fake online reviews written by artificial intelligence (AI) on consumer decision making. Respondents were surveyed about their attitudes and habits concerning online reviews using an online questionnaire (n=351), and participated in a restaurant choice experiment using varying proportions of fake and real reviews. While the findings confirm prior studies, new insights are gained about the confusion for consumers and consequences for businesses when reviews written by AI are believed rather than real reviews. The study presents a fake review detection model using logistic regression modeling to score and flag reviews as a solution.",
        "comments": "pp.1-158, 41 tables, 11 figures. Doctor of Business Administration Dissertation",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11345"
    },
    {
        "doc_id": 118,
        "title": "An income-based approach to modeling commuting distance in the Toronto area",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The purpose of this article is to propose a novel model of the effects of changes in shelter and driving costs on car commuting distances in the overheated Toronto housing market from 2011 to 2016. The model borrows from theoretical concepts of microeconomics and urban geography to examine the Toronto housing market. Using 2011 and 2016 Census data for census metropolitan areas (CMAs) and census agglomerations (CAs) in Southern Ontario and computed driving costs, the model of car commuting distance is based on variables of allocation of monthly household income to monthly shelter costs and driving costs as a function of the car driving distance to Toronto. Using this model, we can predict the effect on car commuting distance due to changes in any of the variables. The model also offers an explanation for communities of Toronto car commuters beyond a driving radius that we might expect for daily commuting. The model confirms that increases in shelter costs in the Toronto housing market from 2011 to 2016 have forced the boundaries of feasible housing locations outward, and forced households to move farther away, thus increasing car commuting distance.",
        "comments": "pp.1-40, 8 tables, 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11343"
    },
    {
        "doc_id": 119,
        "title": "Coevolution of Resource and Strategies in Common-Pool Resource Dilemmas: A Coupled Human-Environmental System Model",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Yongliang Yang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "Common-pool resource governance requires users to cooperate and avoid overexploitation, but defection and free-riding often undermine cooperation. We model a human-environmental system that integrates dynamics of resource and users' strategies. The resource follows a logistic function that depends on natural growth rate, carrying capacity, and extraction rates of cooperators and defectors. The users' strategies evolve according to different processes that capture effects of payoff, resource, and noise. We analyze the feedback between resource availability and strategic adaptation, and explores the conditions for the emergence and maintenance of cooperation. We find different processes lead to different regimes of equilibrium solutions and resource levels depending on the parameter configuration and initial conditions. We also show that some processes can enhance the sustainability of the resource by making the users more responsive to the resource scarcity. The paper advances the understanding of human-environmental system and offers insights for resource governance policies and interventions.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11269"
    },
    {
        "doc_id": 120,
        "title": "Estimation with Pairwise Observations",
        "authors": [
            "Felix Chan",
            "Laszlo Matyas"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The paper introduces a new estimation method for the standard linear regression model. The procedure is not driven by the optimisation of any objective function rather, it is a simple weighted average of slopes from observation pairs. The paper shows that such estimator is consistent for carefully selected weights. Other properties, such as asymptotic distributions, have also been derived to facilitate valid statistical inference. Unlike traditional methods, such as Least Squares and Maximum Likelihood, among others, the estimated residual of this estimator is not by construction orthogonal to the explanatory variables of the model. This property allows a wide range of practical applications, such as the testing of endogeneity, i.e.,the correlation between the explanatory variables and the disturbance terms, and potentially several others.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11229"
    },
    {
        "doc_id": 121,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 122,
        "title": "Long-term Effects of India's Childhood Immunization Program on Earnings and Consumption Expenditure: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Summan, Nandi, and Bloom (2023; SNB) finds that exposure of babies to India's Universal Immunization Programme (UIP) in the late 1980s increased their weekly wages in early adulthood by 0.138 log points and per-capita household consumption 0.028 points. But the results are attained by regressing on age, in years, while controlling for year of birth--two variables that, as constructed, are nearly collinear. The results are therefore attributable to trends during the one-year survey period, such as inflation. A randomization exercise shows that when the true impacts are zero, the SNB estimator averages 0.088 points for wages and 0.039 points for consumption.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11100"
    },
    {
        "doc_id": 123,
        "title": "Information Based Inference in Models with Set-Valued Predictions and Misspecification",
        "authors": [
            "Hiroaki Kaido",
            "Francesca Molinari"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This paper proposes an information-based inference method for partially identified parameters in incomplete models that is valid both when the model is correctly specified and when it is misspecified. Key features of the method are: (i) it is based on minimizing a suitably defined Kullback-Leibler information criterion that accounts for incompleteness of the model and delivers a non-empty pseudo-true set; (ii) it is computationally tractable; (iii) its implementation is the same for both correctly and incorrectly specified models; (iv) it exploits all information provided by variation in discrete and continuous covariates; (v) it relies on Rao's score statistic, which is shown to be asymptotically pivotal.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11046"
    },
    {
        "doc_id": 124,
        "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models",
        "authors": [
            "Ben Aoki-Sherwood",
            "Catherine Bregou",
            "David Liben-Nowell",
            "Kiran Tomlinson",
            "Thomas Zeng"
        ],
        "subjects": [
            "Machine Learning",
            "Multiagent Systems",
            "Econometrics"
        ],
        "abstract": "A common theory of choice posits that individuals make choices in a two-step process, first selecting some subset of the alternatives to consider before making a selection from the resulting consideration set. However, inferring unobserved consideration sets (or item consideration probabilities) in this \"consider then choose\" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We consider a natural extension of consider-then-choose models to a top-$k$ ranking setting, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that knowledge of item utilities allows us to infer bounds on the relative sizes of consideration probabilities. Additionally, given a condition on the expected consideration set size, we derive absolute upper and lower bounds on item consideration probabilities. We also provide algorithms to tighten those bounds on consideration probabilities by propagating inferred constraints. Thus, we show that we can learn useful information about consideration probabilities despite not being able to identify them precisely. We demonstrate our methods on a ranking dataset from a psychology experiment with two different ranking tasks (one with fixed consideration sets and one with unknown consideration sets). This combination of data allows us to estimate utilities and then learn about unknown consideration probabilities using our bounds.",
        "comments": "11 pages; accepted as an extended abstract to AAMAS '24",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11016"
    },
    {
        "doc_id": 125,
        "title": "Subjective Causality",
        "authors": [
            "Joseph Y. Halpern",
            "Evan Piermont"
        ],
        "subjects": [
            "Theoretical Economics",
            "Artificial Intelligence",
            "Logic in Computer Science"
        ],
        "abstract": "We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are consistent with some causal model and to identify causal judgements from observed behavior.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10937"
    },
    {
        "doc_id": 126,
        "title": "An Experimental Study of Decentralized Matching",
        "authors": [
            "Federico Echenique",
            "Alejandro Robinson-Cort\u00e9s",
            "Leeat Yariv"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "We present an experimental study of decentralized two-sided matching markets with no transfers. Experimental participants are informed of everyone's preferences and can make arbitrary non-binding match offers that get finalized when a period of market inactivity has elapsed. Several insights emerge. First, stable outcomes are prevalent. Second, while centralized clearinghouses commonly aim at implementing extremal stable matchings, our decentralized markets most frequently culminate in the median stable matching. Third, preferences' cardinal representations impact the stable partners participants match with. Last, the dynamics underlying our results exhibit strategic sophistication, with agents successfully avoiding cycles of blocking pairs.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10872"
    },
    {
        "doc_id": 127,
        "title": "Aberration compensation for the anamorphic triplet",
        "authors": [
            "Dmitry Zhuridov"
        ],
        "subjects": [
            "Optics",
            "Applied Physics",
            "Instrumentation and Detectors"
        ],
        "abstract": "Compensation of the generalized spherical aberrations is discussed for the plane-symmetric and anamorphic optical systems. The compensation rules are derived for an economical three-component double-plane symmetric telescopic system containing two cylindrical mirrors and one toroidal lens. Anamorphic systems, which provide large magnifications in the two orthogonal directions, are presented.",
        "comments": "4 pages, 4 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10762"
    },
    {
        "doc_id": 128,
        "title": "Methodology to assess prosumer participation in European electricity markets",
        "authors": [
            "Rub\u00e9n Rodr\u00edguez-Vilches",
            "Francisco Mart\u00edn-Mart\u00ednez",
            "\u00c1lvaro S\u00e1nchez-Miralles",
            "Javier Rodrigo Guti\u00e9rrez de la C\u00e1mara",
            "Sergio Mu\u00f1oz Delgado"
        ],
        "subjects": [
            "Physics and Society",
            "Systems and Control"
        ],
        "abstract": "The emergence of distributed generation and the electrification of demand have opened the possibility for prosumers to participate in electricity markets, receiving economic benefits on their bills and contributing to the reduction of carbon emissions, aligning with United Nations Sustainable Development Goal 7. Consumers and prosumers can participate through implicit and explicit demand flexibility and (collective) self-consumption. This study analyses the potential markets in which prosumers can participate and indicates whether these are currently open. The markets studied include day-ahead, intraday, ancillary services, adequacy services, constraint management, and local flexibility markets. Additionally, collective self-consumption is analysed as a service through which prosumers can participate in the electricity market. Previous studies are usually focused on a single market or in a single country, making impossible a complete comparison. This analysis has been done in Spain, Italy, Croatia, and the United Kingdom as representative countries to obtain a methodology to assess countries' openness to prosumer participation in electricity markets, comparing regulatory frameworks and assigning scores based on their prosumer inclusion across various markets. This work updates current literature reviews with the changes and a new description of local market designs in Spain. This methodology can be used to compare other countries' grade of openness. The results of this study show that the analysed countries can be categorised into three groups: almost open, partially open, and closed markets. Analysing the differences, recommendations on the following steps to foster user participation are suggested for each group.",
        "comments": "Journal ref:        Renewable and Sustainable Energy Reviews Volume 191, March 2024, 114179",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10696"
    },
    {
        "doc_id": 129,
        "title": "Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing",
        "authors": [
            "Wolfgang Maass",
            "Ankit Agrawal",
            "Alessandro Ciani",
            "Sven Danz",
            "Alejandro Delgadillo",
            "Philipp Ganser",
            "Pascal Kienast",
            "Marco Kulig",
            "Valentina K\u00f6nig",
            "Nil Rodellas-Gr\u00e0cia",
            "Rivan Rughubar",
            "Stefan Schr\u00f6der",
            "Marc Stautner",
            "Hannah Stein",
            "Tobias Stollenwerk",
            "Daniel Zeuch",
            "Frank K. Wilhelm"
        ],
        "subjects": [
            "Quantum Physics",
            "Systems and Control"
        ],
        "abstract": "Quantum computing (QC) and machine learning (ML), taken individually or combined into quantum-assisted ML (QML), are ascending computing paradigms whose calculations come with huge potential for speedup, increase in precision, and resource reductions. Likely improvements for numerical simulations in engineering imply the possibility of a strong economic impact on the manufacturing industry. In this project report, we propose a framework for a quantum computing-enhanced service ecosystem for simulation in manufacturing, consisting of various layers ranging from hardware to algorithms to service and organizational layers. In addition, we give insight into the current state of the art of applications research based on QC and QML, both from a scientific and an industrial point of view. We further analyse two high-value use cases with the aim of a quantitative evaluation of these new computing paradigms for industrially-relevant settings.",
        "comments": "10 pages, 3 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10623"
    },
    {
        "doc_id": 130,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 131,
        "title": "Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest Machine Learning",
        "authors": [
            "Zaina Abu Hweij",
            "Florence Liang",
            "Sophie Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Medical Physics"
        ],
        "abstract": "Acute compartment syndrome (ACS) is an orthopedic emergency, caused by elevated pressure within a muscle compartment, that leads to permanent tissue damage and eventually death. Diagnosis of ACS relies heavily on patient-reported symptoms, a method that is clinically unreliable and often supplemented with invasive intracompartmental pressure measurements. This study proposes a continuous, objective, noninvasive diagnostic for ACS. The device detects ACS through a random forest machine learning model that uses pressure readings from force-sensitive resistors (FSRs) placed on the skin. The final diagnosis is exported real-time to a web application via Bluetooth. To validate the diagnostic, a data set containing FSR measurements and the corresponding simulated intracompartmental pressure was created. The diagnostic achieved an accuracy, on par to the invasive gold standard, of 97%. The device excelled in key performance metrics including precision, sensitivity, and F1 score. Manufactured for 73 USD, our device may be an economic alternative to needle-based diagnostics. These results demonstrate the potential of noninvasive ACS diagnostics to meet clinical standards and enhance patient care.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10386"
    },
    {
        "doc_id": 132,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 133,
        "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms",
        "authors": [
            "Iris Yan"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere. GS can cause severe damages to satellites, power grids, and communication infrastructures. Estimate of direct economic impacts of a large scale GS exceeds $40 billion a day in the US. Early prediction is critical in preventing and minimizing the hazards. However, current methods either predict several hours ahead but fail to identify all types of GS, or make predictions within short time, e.g., one hour ahead of the occurrence. This work aims to predict all types of geomagnetic storms reliably and as early as possible using big data and machine learning algorithms. By fusing big data collected from multiple ground stations in the world on different aspects of solar measurements and using Random Forests regression with feature selection and downsampling on minor geomagnetic storm instances (which carry majority of the data), we are able to achieve an accuracy of 82.55% on data collected in 2021 when making early predictions three hours in advance. Given that important predictive features such as historic Kp indices are measured every 3 hours and their importance decay quickly with the amount of time in advance, an early prediction of 3 hours ahead of time is believed to be close to the practical limit.",
        "comments": "14 pages, 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10290"
    },
    {
        "doc_id": 134,
        "title": "How industrial clusters influence the growth of the regional GDP: A spatial-approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Steffen Loeber"
        ],
        "subjects": [
            "General Economics",
            "Econometrics"
        ],
        "abstract": "In this paper, we employ spatial econometric methods to analyze panel data from German NUTS 3 regions. Our goal is to gain a deeper understanding of the significance and interdependence of industry clusters in shaping the dynamics of GDP. To achieve a more nuanced spatial differentiation, we introduce indicator matrices for each industry sector which allows for extending the spatial Durbin model to a new version of it. This approach is essential due to both the economic importance of these sectors and the potential issue of omitted variables. Failing to account for industry sectors can lead to omitted variable bias and estimation problems. To assess the effects of the major industry sectors, we incorporate eight distinct branches of industry into our analysis. According to prevailing economic theory, these clusters should have a positive impact on the regions they are associated with. Our findings indeed reveal highly significant impacts, which can be either positive or negative, of specific sectors on local GDP growth. Spatially, we observe that direct and indirect effects can exhibit opposite signs, indicative of heightened competitiveness within and between industry sectors. Therefore, we recommend that industry sectors should be taken into consideration when conducting spatial analysis of GDP. Doing so allows for a more comprehensive understanding of the economic dynamics at play.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10261"
    },
    {
        "doc_id": 135,
        "title": "Nowcasting Madagascar's real GDP using machine learning algorithms",
        "authors": [
            "Franck Ramaharo",
            "Gerzhino Rasolofomanana"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "We investigate the predictive power of different machine learning algorithms to nowcast Madagascar's gross domestic product (GDP). We trained popular regression models, including linear regularized regression (Ridge, Lasso, Elastic-net), dimensionality reduction model (principal component regression), k-nearest neighbors algorithm (k-NN regression), support vector regression (linear SVR), and tree-based ensemble models (Random forest and XGBoost regressions), on 10 Malagasy quarterly macroeconomic leading indicators over the period 2007Q1--2022Q4, and we used simple econometric models as a benchmark. We measured the nowcast accuracy of each model by calculating the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by aggregating individual predictions, consistently outperforms traditional econometric models. We conclude that machine learning models can deliver more accurate and timely nowcasts of Malagasy economic performance and provide policymakers with additional guidance for data-driven decision making.",
        "comments": "13 pages, 6 figures, 5 tables",
        "date": "24 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10255"
    },
    {
        "doc_id": 136,
        "title": "Equilibrium Multiplicity: A Systematic Approach using Homotopies, with an Application to Chicago",
        "authors": [
            "Amine C-L. Ouazad"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Discrete choice models with social interactions or spillovers may exhibit multiple equilibria. This paper provides a systematic approach to enumerating them for a quantitative spatial model with discrete locations, social interactions, and elastic housing supply. The approach relies on two homotopies. A homotopy is a smooth function that transforms the solutions of a simpler city where solutions are known, to a city with heterogeneous locations and finite supply elasticity. The first homotopy is that, in the set of cities with perfectly elastic floor surface supply, an economy with heterogeneous locations is homotopic to an economy with homogeneous locations, whose solutions can be comprehensively enumerated. Such an economy is epsilon close to an economy whose equilibria are the zeros of a system of polynomials. This is a well-studied area of mathematics where the enumeration of equilibria can be guaranteed. The second homotopy is that a city with perfectly elastic housing supply is homotopic to a city with an arbitrary supply elasticity. In a small number of cases, the path may bifurcate and a single path yields two or more equilibria. By running the method on thousands of cities, we obtain a large number of equilibria. Each equilibrium has different population distributions. We provide a method that is computationally feasible for economies with a large number of locations choices, with an empirical application to the City of Chicago. There exist multiple ``counterfactual Chicagos'' consistent with the estimated parameters. Population distribution, prices, and welfare are not uniquely pinned down by amenities. The paper's method can be applied to models in trade and IO. Further applications of algebraic geometry are suggested.",
        "comments": "MSC Class:          91; 90; 65                          ACM Class:          G.3; J.4; I.6",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10181"
    },
    {
        "doc_id": 137,
        "title": "Nowcasting economic activity in European regions using a mixed-frequency dynamic factor model",
        "authors": [
            "Luca Barbaglia",
            "Lorenzo Frattarolo",
            "Niko Hauzenberger",
            "Dominik Hirschbuehl",
            "Florian Huber",
            "Luca Onorante",
            "Michael Pfarrhofer",
            "Luca Tiozzo Pezzoli"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Timely information about the state of regional economies can be essential for planning, implementing and evaluating locally targeted economic policies. However, European regional accounts for output are published at an annual frequency and with a two-year delay. To obtain robust and more timely measures in a computationally efficient manner, we propose a mixed-frequency dynamic factor model that accounts for national information to produce high-frequency estimates of the regional gross value added (GVA). We show that our model produces reliable nowcasts of GVA in 162 regions across 12 European countries.",
        "comments": "JEL: C22, C53, R11; keywords: factor models, mixed-frequency, nowcasting, regional data",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10054"
    },
    {
        "doc_id": 138,
        "title": "A Quantile Nelson-Siegel model",
        "authors": [
            "Matteo Iacopini",
            "Aubrey Poon",
            "Luca Rossini",
            "Dan Zhu"
        ],
        "subjects": [
            "Applications",
            "Econometrics"
        ],
        "abstract": "A widespread approach to modelling the interaction between macroeconomic variables and the yield curve relies on three latent factors usually interpreted as the level, slope, and curvature (Diebold et al., 2006). This approach is inherently focused on the conditional mean of the yields and postulates a dynamic linear model where the latent factors smoothly change over time. However, periods of deep crisis, such as the Great Recession and the recent pandemic, have highlighted the importance of statistical models that account for asymmetric shocks and are able to forecast the tails of a variable's distribution. A new version of the dynamic three-factor model is proposed to address this issue based on quantile regressions. The novel approach leverages the potential of quantile regression to model the entire (conditional) distribution of the yields instead of restricting to its mean. An application to US data from the 1970s shows the significant heterogeneity of the interactions between financial and macroeconomic variables across different quantiles. Moreover, an out-of-sample forecasting exercise showcases the proposed method's advantages in predicting the yield distribution tails compared to the standard conditional mean model. Finally, by inspecting the posterior distribution of the three factors during the recent major crises, new evidence is found that supports the greater and longer-lasting negative impact of the great recession on the yields compared to the COVID-19 pandemic.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09874"
    },
    {
        "doc_id": 139,
        "title": "Wealth dynamics in a multi-aggregate closed monetary system",
        "authors": [
            "Andrea Monaco",
            "Matteo Ghio",
            "Adamaria Perrotta"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We examine the statistical properties of a closed monetary economy with multi-aggregates interactions. Building upon Yakovenko's single-agent monetary model (Dragulescu and Yakovenko, 2000), we investigate the joint equilibrium distribution of aggregate size and wealth. By comparing theoretical and simulated data, we validate our findings and investigate the influence of both micro dynamics and macro characteristics of the system on the distribution. Additionally, we analyze the system's convergence towards equilibrium under various conditions. Our laboratory model may offer valuable insights into macroeconomic phenomena allowing to reproduce typical wealth distribution features observed in real economy.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09871"
    },
    {
        "doc_id": 140,
        "title": "Game-theoretic Model Predictive Control for Modelling Competitive Supply Chains",
        "authors": [
            "Sophie Hall",
            "Laura Guerrini",
            "Florian D\u00f6rfler",
            "Dominic Liao-McPherson"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Supply chains transform raw materials into finished goods and distribute them to end consumers. The vast majority of products we use daily are supplied to us through complex global supply chains. This paper proposes a modelling methodology for dynamic competitive supply chains based on game theory and model predictive control. We model each manufacturer in the supply chain as a rational utility maximizing agent that selects their actions by finding an open-loop generalized Nash equilibrium of a multi-stage game. To react to competitors and the state of the market, every agent re-plans their actions in a receding horizon manner based on estimates of market and supplier parameters thereby creating an approximate closed-loop equilibrium policy. We demonstrate through numerical simulations that this modelling approach is computationally tractable and generates economically interpretable behaviors in a variety of settings such as demand spikes, supply shocks, and information asymmetry.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09853"
    },
    {
        "doc_id": 141,
        "title": "Game Representations and Extensions of the Shapley Value",
        "authors": [
            "Pradeep Dubey"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We show that any cooperative game can be represented by an assignment of costly facilities to players, in which it is intuitively obvious how to allocate the total cost in an equitable manner. This equitable solution turns out to be the Shapley value of the game, and thus provides as an alternative justification of the value. Game representations also open the door for extending the Shapley value to situations where not all coalitions can form, provided those that can constitute a \"semi-algebra\"; or, more generally, a \"hierarchy\"; or, still more generally, have \"full span\".",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09845"
    },
    {
        "doc_id": 142,
        "title": "A Framework for Digital Currencies for Financial Inclusion in Latin America and the Caribbean",
        "authors": [
            "Gabriel Bizama",
            "Alexander Wu",
            "Bernardo Paniagua",
            "Max Mitre"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This research aims to provide a framework to assess the contribution of digital currencies to promote financial inclusion, based on a diagnosis of the landscape of financial inclusion and domestic and cross-border payments in Latin America and the Caribbean. It also provides insights from central banks in the region on key aspects regarding a possible implementation of central bank digital currencies. Findings show that although digital currencies development is at an early stage, a well-designed system could reduce the cost of domestic and cross-border payments, improve the settlement of transactions to achieve real-time payments, expand the accessibility of central bank money, incorporate programmable payments and achieve system performance demands.",
        "comments": "32 pages, 7 figures, 3 tables and 3 boxes",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09811"
    },
    {
        "doc_id": 143,
        "title": "AI and the Opportunity for Shared Prosperity: Lessons from the History of Technology and the Economy",
        "authors": [
            "Guy Ben-Ishai",
            "Jeff Dean",
            "James Manyika",
            "Ruth Porat",
            "Hal Varian",
            "Kent Walker"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Recent progress in artificial intelligence (AI) marks a pivotal moment in human history. It presents the opportunity for machines to learn, adapt, and perform tasks that have the potential to assist people, from everyday activities to their most creative and ambitious projects. It could also help businesses and organizations harness knowledge, increase productivity, innovate, transform, and power shared prosperity. This tremendous potential raises two fundamental questions: (1) Will AI actually advance national and global economic transformation to benefit society at large? and (2) What issues must we get right to fully realize AI's economic value, expand prosperity and improve lives everywhere? We explore these questions by considering the recent history of technology and innovation as a guide for the likely impact of AI and what we must do to realize its economic potential to benefit society. While we do not presume the future will be entirely like that past, for reasons we will discuss, we do believe prior experience with technological change offers many useful lessons. We conclude that while progress in AI presents a historic opportunity to advance our economic prosperity and future wellbeing, its economic benefits will not come automatically and that AI risks exacerbating existing economic challenges unless we collectively and purposefully act to enable its potential and address its challenges. We suggest a collective policy agenda - involving developers, deployers and users of AI, infrastructure providers, policymakers, and those involved in workforce training - that may help both realize and harness AI's economic potential and address its risks to our shared prosperity.",
        "comments": "Draft withdrawn to obtain feedback",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09811"
    },
    {
        "doc_id": 144,
        "title": "Empowering Africa: An In-depth Exploration of the Adoption of Artificial Intelligence Across the Continent",
        "authors": [
            "Kinyua Gikunda"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "This paper explores the dynamic landscape of Artificial Intelligence (AI) adoption in Africa, analysing its varied applications in addressing socio-economic challenges and fostering development. Examining the African AI ecosystem, the study considers regional nuances, cultural factors, and infrastructural constraints shaping the deployment of AI solutions. Case studies in healthcare, agriculture, finance, and education highlight AI's transformative potential for efficiency, accessibility, and inclusivity. The paper emphasizes indigenous AI innovations and international collaborations contributing to a distinct African AI ecosystem. Ethical considerations, including data privacy and algorithmic bias, are addressed alongside policy frameworks supporting responsible AI implementation. The role of governmental bodies, regulations, and private sector partnerships is explored in creating a conducive AI development environment. Challenges such as digital literacy gaps and job displacement are discussed, with proposed strategies for mitigation. In conclusion, the paper provides a nuanced understanding of AI in Africa, contributing to sustainable development discussions and advocating for an inclusive and ethical AI ecosystem on the continent.",
        "comments": " ",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09457"
    },
    {
        "doc_id": 145,
        "title": "Equity Premium in Efficient Markets",
        "authors": [
            "B. N. Kausik"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Equity premium, the surplus returns of stocks over bonds, has been an enduring puzzle. While numerous prior works approach the problem assuming the utility of money is invariant across contexts, our approach implies that in efficient markets the utility of money is polymorphic, with risk aversion dependent on the information available in each context, i.e. the discount on each future cash flow depends on all information available on that cash flow. Specifically, we prove that in efficient markets, informed investors maximize return on volatility by being risk-neutral with riskless bonds, and risk-averse with equities, thereby resolving the puzzle. We validate our results on historical data with surprising consistency.\n  JEL Classification: C58, G00, G12, G17",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09265"
    },
    {
        "doc_id": 146,
        "title": "Airline delays, congestion internalization and non-price spillover effects of low cost carrier entry",
        "authors": [
            "William E. Bendinelli",
            "Humberto F. A. J. Bettini",
            "Alessandro V. M. Oliveira"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper develops an econometric model of flight delays to investigate the influence of competition and dominance on the incentives of carriers to maintain on-time performance. We consider both the route and the airport levels to inspect the local and global effects of competition, with a unifying framework to test the hypotheses of 1. airport congestion internalization and 2. the market competition-quality relationship in a single econometric model. In particular, we examine the impacts of the entry of low cost carriers (LCC) on the flight delays of incumbent full service carriers in the Brazilian airline industry. The main results indicate a highly significant effect of airport congestion self-internalization in parallel with route-level quality competition. Additionally, the potential competition caused by LCC presence provokes a global effect that suggests the existence of non-price spillovers of the LCC entry to non-entered routes.",
        "comments": "Journal ref:        Transportation Research Part A: Policy and Practice, 85, 39-52 (2016)",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09174"
    },
    {
        "doc_id": 147,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 148,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 149,
        "title": "Strategic formation of production networks",
        "authors": [
            "Antoine Mandel",
            "Van-Quy Nguyen",
            "Bach Dong-Xuan"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We provide a strategic model of the formation of production networks that subsumes the standard general equilibrium approach. The objective of firms in our setting is to choose their supply relationships so as to maximize their profit at the general equilibrium that unfolds. We show that this objective is equivalent to the maximization by the firms of their eigenvector centrality in the production network. As is common in network formation games based on centrality, there are multiple Nash equilibria in our setting. We have investigated the characteristics and the social efficiency of these equilibria in a stylized version of our model representing international trade networks. We show that the impact of network structure on social welfare is firstly determined by a trade-off between costs of increasing process complexity and positive spillovers on productivity induced by the diversification of the input mix. We further analyze a variant of our model that accounts for the risks of disruption of supply relationships. In this setting, we characterize how social welfare depends on the structure of the production network, the spatial distribution of risks, and the process of shock aggregation in supply chains. We finally show that simple trade policies characterized by sets of links that are either prevented or catalyzed can be a powerful equilibrium selection device.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08929"
    },
    {
        "doc_id": 150,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 151,
        "title": "MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data",
        "authors": [
            "Zhengke Sun",
            "Yuliang Ma"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "The problem of traffic congestion not only causes a large amount of economic losses, but also seriously endangers the urban environment. Predicting traffic congestion has important practical significance. So far, most studies have been based on historical data from sensors placed on different roads to predict future traffic flow and speed, to analyze the traffic congestion conditions of a certain road segment. However, due to the fixed position of sensors, it is difficult to mine new information. On the other hand, vehicle trajectory data is more flexible and can extract traffic information as needed. Therefore, we proposed a new traffic congestion prediction model - Multi Adjacency relationship Attention Graph Convolutional Networks(MA2GCN). This model transformed vehicle trajectory data into graph structured data in grid form, and proposed a vehicle entry and exit matrix based on the mobility between different grids. At the same time, in order to improve the performance of the model, this paper also built a new adaptive adjacency matrix generation method and adjacency matrix attention module. This model mainly used gated temporal convolution and graph convolution to extract temporal and spatial information, respectively. Compared with multiple baselines, our model achieved the best performance on Shanghai taxi GPS trajectory dataset. The code is available at https://github.com/zachysun/Taxi_Traffic_Benchmark.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08727"
    },
    {
        "doc_id": 152,
        "title": "Automated Design Appraisal: Estimating Real Estate Price Growth and Value at Risk due to Local Development",
        "authors": [
            "Adam R. Swietek"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial criteria in architectural design evaluation are limited to cost performance. Here, I introduce a method, Automated Design Appraisal (ADA), to predict the market price of a generated building design concept within a local urban context. Integrating ADA with 3D building performance simulations enables financial impact assessment that exceeds the spatial resolution of previous work. Within an integrated impact assessment, ADA measures the direct and localized effect of urban development. To demonstrate its practical utility, I study local devaluation risk due to nearby development associated with changes to visual landscape quality. The results shed light on the relationship between amenities and property value, identifying clusters of properties physically exposed or financially sensitive to local land-use change. Beyond its application as a financial sensitivity tool, ADA serves as a blueprint for architectural design optimization procedures, in which economic performance is evaluated based on learned preferences derived from financial market data.",
        "comments": "18 pages, 7 figures",
        "date": "17 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08645"
    },
    {
        "doc_id": 153,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 154,
        "title": "Non-Banking Sector development effect on Economic Growth. A Nighttime light data approach",
        "authors": [
            "Leonard Mushunje",
            "Maxwell Mashasha"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper uses nighttime light(NTL) data to measure the nexus of the non-banking sector, particularly insurance, and economic growth in South Africa. We hypothesize that insurance sector growth positively propels economic growth due to its economic growth-supportive traits like investment protection and optimal risk mitigation. We also claim that Nighttime light data is a good economic measure than Gross domestic product (GDP). We used weighted regressions to measure the relationships between nighttime light data, GDP, and insurance sector development. We used time series South African GDP data collected from the World Bank for the period running from 2000 to 2018, and the nighttime lights data from the National Geophysical Data Centre (NGDC) in partnership with the National Oceanic and Atmospheric Administration (NOAA). From the models fitted and the reported BIC, AIC, and likelihood ratios, the insurance sector proved to have more predictive power on economic development in South Africa, and radiance light explained economic growth better than GDP and GDP/Capita. We concluded that nighttime data is a good proxy for economic growth than GDP/Capita in emerging economies like South Africa, where secondary data needs to be more robust and sometimes inflated. The findings will guide researchers and policymakers on what drives economic development and what policies to put in place. It would be interesting to extend the current study to other sectors such as micro-finances, mutual and hedge funds.",
        "comments": "28 pages",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08596"
    },
    {
        "doc_id": 155,
        "title": "How do we measure trade elasticity for services?",
        "authors": [
            "Satoshi Nakano",
            "Kazuhiko Nishimura"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper is about our attempt of identifying trade elasticities through the variations in the exchange rate, for possible applications to the case of services whose physical transactions are veiled in the trade statistics. The regression analysis to estimate the elasticity entails a situation where the explanatory variable is leaked into the error term through the latent supply equation, causing an endogeneity problem for which an instrumental variable cannot be found. Our identification strategy is to utilize the normalizing condition, which enables the supply parameter to be identified, along with the reduced-form equation of the system of demand and supply equations. We evaluate the performances of the method proposed by applying to several different tangible goods, whose benchmark trade elasticities are estimable by utilizing the information on their physical transactions.",
        "comments": " ",
        "date": "18 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08594"
    },
    {
        "doc_id": 156,
        "title": "Incremento del precio de los combustibles y su incidencia en los productos de la canasta basica del canton el triunfo, provincia del guayas",
        "authors": [
            "Alvear Guzman Katherine",
            "Campozano Buele Jenner",
            "Duran Canarte Paulette",
            "Holguin Cedeno Roger",
            "Mejia Crespin Fernando"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The objective of this research was to analyze the impact of the increase in the price of fuels and its incidence on the products of the basic basket of the El Triunfo, the province of Guayas. In the present study, the non-experimental quantitative method was used. The study population was limited to the families of the town, seeking to determine how their level of consumption was impacted after the increase in fuels. Just 95 people were randomly taken. The study instrument that was used was surveys, with a focus on the purchasing power of families with respect to the basic basket after the increase in fuel prices. The results were processed through Cronbach's Alpha and reflected in pie charts. The independent and dependent variable that make up our study, were related through a simple linear regression, to determine if they correlate with each other.\n  Keywords: Fuels, Basic basket, Linear regression, Subsidies, Inflation",
        "comments": "in Spanish language",
        "date": "13 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08590"
    },
    {
        "doc_id": 157,
        "title": "Incentivizing Secure Software Development: The Role of Liability (Waiver) and Audit",
        "authors": [
            "Ziyuan Huang",
            "Gergely Bicz\u00f3k",
            "Mingyan Liu"
        ],
        "subjects": [
            "Cryptography and Security",
            "Systems and Control"
        ],
        "abstract": "Misaligned incentives in secure software development have long been the focus of research in the economics of security. Product liability, a powerful legal framework in other industries, has been largely ineffective for software products until recent times. However, the rapid regulatory responses to recent global cyberattacks by both the United States and the European Union, together with the (relative) success of the General Data Protection Regulation in defining both duty and standard of care for software vendors, may just enable regulators to use liability to re-align incentives for the benefit of the digital society. Specifically, the recently proposed United States National Cybersecurity Strategy shifts responsibility for cyber incidents back to software vendors. In doing so, the strategy also puts forward the concept of the liability waiver: if a software company voluntarily undergoes and passes an IT security audit, its liability is waived.\n  In this paper, we analyze this audit scenario from the aspect of the software vendor. We propose a mechanism where a software vendor should first undergo a repeated auditing process in each stage of which the vendor decides whether to quit early or stay with additional security investment. We show that the optimal strategy for an opt-in vendor is to never quit; and exert cumulative investments in either \"one-and-done\" or \"incremental\" manner. We relate the audit mechanism to a liability waiver insurance policy and revealed its effect on reshaping the vendor's risk perception. We also discuss influence of audit quality on the vendor's incentives and pinpoint that a desirable audit rule should be highly accurate and less strict.",
        "comments": "21 pages, 6 figures, submitted to the 23rd Workshop on the Economics of Information Security",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08476"
    },
    {
        "doc_id": 158,
        "title": "Assessing the impact of forced and voluntary behavioral changes on economic-epidemiological co-dynamics: A comparative case study between Belgium and Sweden during the 2020 COVID-19 pandemic",
        "authors": [
            "Tijs W. Alleman",
            "Jan M. Baetens"
        ],
        "subjects": [
            "Econometrics",
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "During the COVID-19 pandemic, governments faced the challenge of managing population behavior to prevent their healthcare systems from collapsing. Sweden adopted a strategy centered on voluntary sanitary recommendations while Belgium resorted to mandatory measures. Their consequences on pandemic progression and associated economic impacts remain insufficiently understood. This study leverages the divergent policies of Belgium and Sweden during the COVID-19 pandemic to relax the unrealistic -- but persistently used -- assumption that social contacts are not influenced by an epidemic's dynamics. We develop an epidemiological-economic co-simulation model where pandemic-induced behavioral changes are a superposition of voluntary actions driven by fear, prosocial behavior or social pressure, and compulsory compliance with government directives. Our findings emphasize the importance of early responses, which reduce the stringency of measures necessary to safeguard healthcare systems and minimize ensuing economic damage. Voluntary behavioral changes lead to a pattern of recurring epidemics, which should be regarded as the natural long-term course of pandemics. Governments should carefully consider prolonging lockdown longer than necessary because this leads to higher economic damage and a potentially higher second surge when measures are released. Our model can aid policymakers in the selection of an appropriate long-term strategy that minimizes economic damage.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08442"
    },
    {
        "doc_id": 159,
        "title": "Causal Machine Learning for Moderation Effects",
        "authors": [
            "Nora Bearth",
            "Michael Lechner"
        ],
        "subjects": [
            "Econometrics",
            "Machine Learning"
        ],
        "abstract": "It is valuable for any decision maker to know the impact of decisions (treatments) on average and for subgroups. The causal machine learning literature has recently provided tools for estimating group average treatment effects (GATE) to understand treatment heterogeneity better. This paper addresses the challenge of interpreting such differences in treatment effects between groups while accounting for variations in other covariates. We propose a new parameter, the balanced group average treatment effect (BGATE), which measures a GATE with a specific distribution of a priori-determined covariates. By taking the difference of two BGATEs, we can analyse heterogeneity more meaningfully than by comparing two GATEs. The estimation strategy for this parameter is based on double/debiased machine learning for discrete treatments in an unconfoundedness setting, and the estimator is shown to be $\\sqrt{N}$-consistent and asymptotically normal under standard conditions. Adding additional identifying assumptions allows specific balanced differences in treatment effects between groups to be interpreted causally, leading to the causal balanced group average treatment effect. We explore the finite sample properties in a small-scale simulation study and demonstrate the usefulness of these parameters in an empirical example.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08290"
    },
    {
        "doc_id": 160,
        "title": "A techno-economic model for avoiding conflicts of interest between owners of offshore wind farms and maintenance suppliers",
        "authors": [
            "Alberto Pliego Marug\u00e1n",
            "Fausto Pedro Garc\u00eda M\u00e1rquez",
            "Jes\u00fas Mar\u00eda Pinar P\u00e9rez"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "General Economics",
            "Systems and Control"
        ],
        "abstract": "Currently, wind energy is one of the most important sources of renewable energy. Offshore locations for wind turbines are increasingly exploited because of their numerous advantages. However, offshore wind farms require high investment in maintenance service. Due to its complexity and special requirements, maintenance service is usually outsourced by wind farm owners. In this paper, we propose a novel approach to determine, quantify, and reduce the possible conflicts of interest between owners and maintenance suppliers. We created a complete techno-economic model to address this problem from an impartial point of view. An iterative process was developed to obtain statistical results that can help stakeholders negotiate the terms of the contract, in which the availability of the wind farm is the reference parameter by which to determine penalisations and incentives. Moreover, a multi-objective programming problem was addressed that maximises the profits of both parties without losing the alignment of their interests. The main scientific contribution of this paper is the maintenance analysis of offshore wind farms from two perspectives: that of the owner and the maintenance supplier. This analysis evaluates the conflicts of interest of both parties. In addition, we demonstrate that proper adjustment of some parameters, such as penalisation, incentives, and resources, and adequate control of availability can help reduce this conflict of interests.",
        "comments": "Published in Renewable and Sustainable Energy Reviews (ELSEVIER) 10 July 2022. DOI: https://doi.org/10.1016/j.rser.2022.112753 Cite as: Marug\u00e1n, A. P., M\u00e1rquez, F. P. G., & P\u00e9rez, J. M. P. (2022). A techno-economic model for avoiding conflicts of interest between owners of offshore wind farms and maintenance suppliers. Renewable and Sustainable Energy Reviews, 168, 112753",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08251"
    },
    {
        "doc_id": 161,
        "title": "A Large-Scale Epidemic Simulation Framework for Realistic Social Contact Networks",
        "authors": [
            "Joy Kitson",
            "Ian Costello",
            "Jiangzhuo Chen",
            "Diego Jim\u00e9nez",
            "Stefan Hoops",
            "Henning Mortveit",
            "Esteban Meneses",
            "Jae-Seung Yeom",
            "Madhav V. Marathe",
            "Abhinav Bhatele"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Global pandemics can wreak havoc and lead to significant social, economic, and personal losses. Preventing the spread of infectious diseases requires implementing interventions at different levels of government, and evaluating the potential impact and efficacy of those preemptive measures. Agent-based modeling can be used for detailed studies of epidemic diffusion and possible interventions. We present Loimos, a highly parallel simulation of epidemic diffusion written on top of Charm++, an asynchronous task-based parallel runtime. Loimos uses a hybrid of time-stepping and discrete-event simulation to model disease spread. We demonstrate that our implementation of Loimos is able to scale to large core counts on an HPC system. In particular, Loimos is able to simulate a US-scale synthetic interaction network in an average of 1.497 seconds per simulation day when executed on 16 nodes on Rivanna at the University of Virginia, processing around 428 billion interactions (person-person edges) in under five minutes for an average of 1.4 billion traversed edges per second (TEPS).",
        "comments": "13 pages (including references), 9 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08124"
    },
    {
        "doc_id": 162,
        "title": "Automated lag-selection for multi-step univariate time series forecast using Bayesian Optimization: Forecast station-wise monthly rainfall of nine divisional cities of Bangladesh",
        "authors": [
            "Rezoanoor Rahman",
            "Fariha Taskin"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Rainfall is an essential hydrological component, and most of the economic activities of an agrarian country like Bangladesh depend on rainfall. An accurate rainfall forecast can help make necessary decisions and reduce the damages caused by heavy or low to no rainfall. The monthly average rainfall is a time series data, and recently, long short-term memory (LSTM) neural networks are being used heavily for time series forecasting problems. One major challenge of forecasting using LSTMs is to select the appropriate number of lag values. In this research, we considered the number of lag values selected as a hyperparameter of LSTM; it, with the other hyperparameters determining LSTMs structure, has been optimized using Bayesian optimization. We used our proposed method to forecast rainfall for nine different weather stations of Bangladesh. Finally, the performance of the proposed model has been compared with some other LSTM with different lag-selection methods and some several popular machine learning and statistical forecasting models.",
        "comments": "19 pages in total",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08070"
    },
    {
        "doc_id": 163,
        "title": "A new model of trust based on neural information processing",
        "authors": [
            "Scott E. Allen",
            "Ren\u00e9 F. Kizilcec",
            "A. David Redish"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction",
            "Neurons and Cognition"
        ],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08064"
    },
    {
        "doc_id": 164,
        "title": "A Day-to-Day Dynamical Approach to the Most Likely User Equilibrium Problem",
        "authors": [
            "Jiayang Li",
            "Qianni Wang",
            "Liyang Feng",
            "Jun Xie",
            "Yu Marco Nie"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Multiagent Systems",
            "General Economics"
        ],
        "abstract": "The lack of a unique user equilibrium (UE) route flow in traffic assignment has posed a significant challenge to many transportation applications. The maximum-entropy principle, which advocates for the consistent selection of the most likely solution as a representative, is often used to address the challenge. Built on a recently proposed day-to-day (DTD) discrete-time dynamical model called cumulative logit (CULO), this study provides a new behavioral underpinning for the maximum-entropy UE (MEUE) route flow. It has been proven that CULO can reach a UE state without presuming travelers are perfectly rational. Here, we further establish that CULO always converges to the MEUE route flow if (i) travelers have zero prior information about routes and thus are forced to give all routes an equal choice probability, or (ii) all travelers gather information from the same source such that the so-called general proportionality condition is satisfied. Thus, CULO may be used as a practical solution algorithm for the MEUE problem. To put this idea into practice, we propose to eliminate the route enumeration requirement of the original CULO model through an iterative route discovery scheme. We also examine the discrete-time versions of four popular continuous-time dynamical models and compare them to CULO. The analysis shows that the replicator dynamic is the only one that has the potential to reach the MEUE solution with some regularity. The analytical results are confirmed through numerical experiments.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08013"
    },
    {
        "doc_id": 165,
        "title": "Inequality leads to the evolution of intolerance in reputation-based populations",
        "authors": [
            "Luis A. Martinez-Vaquero"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "This work studies the impact of economic inequality on the evolution of intolerance through a reputation-based model of indirect reciprocity. Results show that economic inequality is a powerful enhancer of intolerance, inducing the escalation of out-group discrimination even without the presence of new intolerant mutants. It also generates behavior modifications within tolerant disfavored minorities: their members either relax punishments against the uncooperative or prioritize helping the wealthy, even suffering discrimination in return. On the other hand, the redistribution of wealth is proved as a viable solution to avoid the spread of intolerance as long as it increases equality and is implemented before intolerance permeates part of the population.",
        "comments": "Journal ref:        Chaos 33 (3), 033119 (2023)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07873"
    },
    {
        "doc_id": 166,
        "title": "Evolutionary dynamics of organised crime and terrorist networks",
        "authors": [
            "Luis A. Martinez-Vaquero",
            "Valerio Dolci",
            "Vito Trianni"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "Crime is pervasive into modern societies, although with different levels of diffusion across regions. Its dynamics are dependent on various socio-economic factors that make the overall picture particularly complex. While several theories have been proposed to account for the establishment of criminal behaviour, from a modelling perspective organised crime and terrorist networks received much less attention. In particular, the dynamics of recruitment into such organisations deserve specific considerations, as recruitment is the mechanism that makes crime and terror proliferate. We propose a framework able to model such processes in both organised crime and terrorist networks from an evolutionary game theoretical perspective. By means of a stylised model, we are able to study a variety of different circumstances and factors influencing the growth or decline of criminal organisations and terrorist networks, and observe the convoluted interplay between agents that decide to get associated to illicit groups, criminals that prefer to act on their own, and the rest of the civil society.",
        "comments": "Journal ref:        Sci Rep 9, 9727 (2019)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07869"
    },
    {
        "doc_id": 167,
        "title": "A General Approach for Computing a Consensus in Group Decision Making That Integrates Multiple Ethical Principles",
        "authors": [
            "Francisco Salas-Molina",
            "Filippo Bistaffa",
            "Juan A. Rodriguez-Aguilar"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We tackle the problem of computing a consensus according to multiple ethical principles -- which can include, for example, the principle of maximum freedom associated with the Benthamite doctrine and the principle of maximum fairness associated with the Rawlsian principles -- among the preferences of different individuals in the context of Group-Decision-Making. More formally, we put forward a novel formalisation of the above-mentioned problem based on a multinorm approximation problem that aims at minimising multiple p-metric distance functions, where each parameter p represents a given ethical principle. Our contribution incurs obvious benefits from a social-choice perspective. Firstly, our approach significantly generalises state-of-the-art approaches that were limited to only two ethical principles (p set to one, for maximum freedom, and p set to infinity, for maximum fairness). Secondly, our experimental results considering an established test case demonstrate that our approach is capable, thanks to a novel re-weighting scheme, to compute a multi-norm consensus that takes into account each ethical principle in a balanced way, in contrast with state-of-the-art approaches that were heavily biased towards the p=1 ethical principle",
        "comments": "20 pages, 1 table, 1 figure",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07818"
    },
    {
        "doc_id": 168,
        "title": "Improving OCR Quality in 19th Century Historical Documents Using a Combined Machine Learning Based Approach",
        "authors": [
            "David Fleischhacker",
            "Wolfgang Goederle",
            "Roman Kern"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "This paper addresses a major challenge to historical research on the 19th century. Large quantities of sources have become digitally available for the first time, while extraction techniques are lagging behind. Therefore, we researched machine learning (ML) models to recognise and extract complex data structures in a high-value historical primary source, the Schematismus. It records every single person in the Habsburg civil service above a certain hierarchical level between 1702 and 1918 and documents the genesis of the central administration over two centuries. Its complex and intricate structure as well as its enormous size have so far made any more comprehensive analysis of the administrative and social structure of the later Habsburg Empire on the basis of this source impossible. We pursued two central objectives: Primarily, the improvement of the OCR quality, for which we considered an improved structure recognition to be essential; in the further course, it turned out that this also made the extraction of the data structure possible. We chose Faster R-CNN as base for the ML architecture for structure recognition. In order to obtain the required amount of training data quickly and economically, we synthesised Hof- und Staatsschematismus-style data, which we used to train our model. The model was then fine-tuned with a smaller set of manually annotated historical source data. We then used Tesseract-OCR, which was further optimised for the style of our documents, to complete the combined structure extraction and OCR process. Results show a significant decrease in the two standard parameters of OCR-performance, WER and CER (where lower values are better). Combined structure detection and fine-tuned OCR improved CER and WER values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).",
        "comments": "29 pages, 23 figures, 7 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07787"
    },
    {
        "doc_id": 169,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 170,
        "title": "Impermanent Loss Conditions: An Analysis of Decentralized Exchange Platforms",
        "authors": [
            "Matthias Hafner",
            "Helmut Dietl"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Decentralized exchanges are widely used platforms for trading crypto assets. The most common types work with automated market makers (AMM), allowing traders to exchange assets without needing to find matching counterparties. Thereby, traders exchange against asset reserves managed by smart contracts. These assets are provided by liquidity providers in exchange for a fee. Static analysis shows that small price changes in one of the assets can result in losses for liquidity providers. Despite the success of AMMs, it is claimed that liquidity providers often suffer losses. However, the literature does not adequately consider the dynamic effects of fees over time. Therefore, we investigate the impermanent loss problem in a dynamic setting using Monte Carlo simulations. Our findings indicate that price changes do not necessarily lead to losses. Fees paid by traders and arbitrageurs are equally important. In this respect, we can show that an arbitrage-friendly environment benefits the liquidity provider. Thus, we suggest that AMM developers should promote an arbitrage-friendly environment rather than trying to prevent arbitrage.",
        "comments": "This paper was presented at the CfC 2024 Academic Track Conference",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07689"
    },
    {
        "doc_id": 171,
        "title": "Spatial clusters for demand and supply of childcare services in Italy",
        "authors": [
            "Andreella Angela",
            "Aliverti Emanuele",
            "Caldura Federico",
            "Campostrini Stefano"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "The availability of affordable and high-quality childcare services has become a significant concern in recent years. Such services can facilitate the balance between work and family life, increasing participation in the workforce and promoting gender equality. Furthermore, childcare can also help address the issue of decreasing fertility rates by making it more affordable for parents to have children while maintaining their careers. This is critical, especially for countries that are facing ultralow fertility rates like Italy. The Italian government has included within the recovery and resilience plan financed with Next Generations EU funds an unprecedented investment in order to increase the supply of children's education services and make it more equitably distributed across the country. In this article, we estimate groups of spatial areas with similar structures in terms of coverage (availability of childcare services at the municipality level), public expenditure rates in childcare, as well as other socio-demographic and economic factors, such as female employment, education, and grandparent rates. Our empirical findings confirm how Italy is characterized by a large number of \"sub-regional models\" and how some of these clusters are shared across multiple regions. We provide a preliminary attempt to explain how such patterns are driven by socio-demographic factors and argue that these very different conditions necessitate specific policy decisions. The work highlights the need for regional governance of the children's educational system.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07600"
    },
    {
        "doc_id": 172,
        "title": "Existence of MMS Allocations with Mixed Manna",
        "authors": [
            "Kevin Hsu"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "Maximin share (MMS) allocations are a popular relaxation of envy-free allocations that have received wide attention in the context of the fair division of indivisible items. Although MMS allocations can fail to exist [1], previous work has found conditions under which they exist. Specifically, MMS allocations exist whenever $m \\leq n+5$ in the context of goods allocation, and this bound is tight in the sense that MMS allocations can fail to exist when $m = n+6$ [2]. Unfortunately, the technique used to establish this result does not generalize readily to the chores and mixed manna settings. This paper generalizes this result to the chores setting and provides a partial solution for the mixed manna setting. Our results depend on the presence of certain types of agents. Specifically, an agent $i$ is a goods agent (resp. chores agent) if every item is a good (resp. chore) to $i$, and a non-negative mixed agent if $i$ is neither a goods nor a chores agent and the MMS guarantee of $i$ is non-negative. In this paper, we prove that an MMS allocation exists if $m \\leq n+5$ and there exists a goods agent, a non-negative mixed agent, or only chores agents.\n  [1] David Kurokawa, Ariel D Procaccia, and Junxing Wang. When can the maximin share guarantee be guaranteed? In Thirtieth AAAI Conference on Artificial Intelligence, 2016.\n  [2] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for mms fair allocations. In International Conference on Web and Internet Economics, pages 355-372. Springer, 2021.",
        "comments": "11 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07490"
    },
    {
        "doc_id": 173,
        "title": "Unemployment Volatility: When Workers Pay Costs upon Accepting Jobs",
        "authors": [
            "Rich Ryan"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "When a firm hires a worker, adding the new hire to payroll is costly. These costs reduce the amount of resources that can go to recruiting workers and amplify how unemployment responds to changes in productivity. Workers also incur up-front costs upon accepting jobs. Examples include moving expenses and regulatory fees. I establish that workers' costs lessen the response of unemployment to productivity changes and do not subtract from resources available for recruitment. The influence of workers' costs is bounded by properties of a matching function, which describes how job openings and unemployment produce hires. Using data on job finding that are adjusted for workers' transitions between employment and unemployment and for how the Job Openings and Labor Turnover Survey records hires, I estimate a bound that ascribes limited influence to workers' costs. The results demonstrate that costs paid by workers upon accepting jobs affect outcomes in the labor market (firms threaten workers with paying the up-front costs again if wage negotiations fail), but their influence on volatility is less important than firms' costs.",
        "comments": "31 pages, 3 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07423"
    },
    {
        "doc_id": 174,
        "title": "A Comparative Examination of Network and Contract-Based Blockchain Storage Solutions for Decentralized Applications",
        "authors": [
            "Lipeng He"
        ],
        "subjects": [
            "Networking and Internet Architecture"
        ],
        "abstract": "Decentralized applications (DApps), which are innovative blockchain-powered software systems designed to serve as the fundamental building blocks for the next generation of Internet services, have witnessed exponential growth in recent years. This paper thoroughly compares and analyzes two blockchain-based decentralized storage networks (DSNs), which are crucial foundations for DApp and blockchain ecosystems. The study examines their respective mechanisms for data persistence, strategies for enforcing data retention, and token economics. In addition to delving into technical details, the suitability of each storage solution for decentralized application development is assessed, taking into consideration network performance, storage costs, and existing use cases. By evaluating these factors, the paper aims to provide insights into the effectiveness of these technologies in supporting the desirable properties of truly decentralized blockchain applications. In conclusion, the findings of this research are discussed and synthesized, offering valuable perspectives on the capabilities of these technologies. It sheds light on their potential to facilitate the development of DApps and provides an understanding of the ongoing trends in blockchain development.",
        "comments": "13 pages, 1 figure, published in Proceedings of the 3rd International Conference on Digital Economy and Computer Application (DECA 2023)",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07417"
    },
    {
        "doc_id": 175,
        "title": "Learning to be Homo Economicus: Can an LLM Learn Preferences from Choice",
        "authors": [
            "Jeongbin Kim",
            "Matthew Kovach",
            "Kyu-Min Lee",
            "Euncheol Shin",
            "Hector Tzavellas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper explores the use of Large Language Models (LLMs) as decision aids, with a focus on their ability to learn preferences and provide personalized recommendations. To establish a baseline, we replicate standard economic experiments on choice under risk (Choi et al., 2007) with GPT, one of the most prominent LLMs, prompted to respond as (i) a human decision maker or (ii) a recommendation system for customers. With these baselines established, GPT is provided with a sample set of choices and prompted to make recommendations based on the provided data. From the data generated by GPT, we identify its (revealed) preferences and explore its ability to learn from data. Our analysis yields three results. First, GPT's choices are consistent with (expected) utility maximization theory. Second, GPT can align its recommendations with people's risk aversion, by recommending less risky portfolios to more risk-averse decision makers, highlighting GPT's potential as a personalized decision aid. Third, however, GPT demonstrates limited alignment when it comes to disappointment aversion.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07345"
    },
    {
        "doc_id": 176,
        "title": "Individual and Collective Welfare in Risk Sharing with Many States",
        "authors": [
            "Federico Echenique",
            "Farzad Pourbabaee"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory"
        ],
        "abstract": "We provide a quantitative assessment of welfare in the classical model of risk-sharing and exchange under uncertainty. We prove three kinds of results. First, that in an equilibrium allocation, the scope for improving individual welfare by a given margin (an $\\ve$-improvement) vanishes as the number of states increases. Second, that the scope for a change in aggregate resources that may be distributed to enhance individual welfare by a given margin also vanishes. Equivalently: in an inefficient allocation, for a given level of resource sub-optimality (as measured by the coefficient of resource under-utilization), the possibilities for enhancing welfare by perturbing aggregate resources decrease exponentially to zero with the number of states. Finally, we consider efficient risk-sharing in standard models of uncertainty aversion with multiple priors, and show that, in an inefficient allocation, certain sets of priors shrink with the size of the state space.",
        "comments": "MSC Class:          91B50                          ACM Class:          J.4",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07337"
    },
    {
        "doc_id": 177,
        "title": "Utilitarian Beliefs in Social Networks: Explaining the Emergence of Hatred",
        "authors": [
            "Houda Nait El Barj",
            "Theophile Sautory"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study the dynamics of opinions in a setting where a leader has a payoff that depends on agents' beliefs and where agents derive psychological utility from their beliefs. Agents sample a signal that maximises their utility and then communicate with each other through a network formed by disjoint social groups. The leader has a choice to target a finite set of social groups with a specific signal to influence their beliefs and maximise his returns. Heterogeneity in agents' preferences allows us to analyse the evolution of opinions as a dynamical system with asymmetric forces. We apply our model to explain the emergence of hatred and the spread of racism in a society. We show that when information is restricted, the equilibrium level of hatred is determined solely by the belief of the most extremist agent in the group regardless of the inherent structure of the network. On the contrary, when information is dense, the space is completely polarised in equilibrium with the presence of multiple \"local truths\" which oscillate in periodic cycles. We find that when preferences are uniformly distributed, the equilibrium level of hatred depends solely on the value of the practical punishment associated with holding a hate belief. Our finding suggests that an optimal policy to reduce hatred should focus on increasing the cost associated with holding a racist belief.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07178"
    },
    {
        "doc_id": 178,
        "title": "A Note on Uncertainty Quantification for Maximum Likelihood Parameters Estimated with Heuristic Based Optimization Algorithms",
        "authors": [
            "Zachary Porreca"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Gradient-based solvers risk convergence to local optima, leading to incorrect researcher inference. Heuristic-based algorithms are able to ``break free\" of these local optima to eventually converge to the true global optimum. However, given that they do not provide the gradient/Hessian needed to approximate the covariance matrix and that the significantly longer computational time they require for convergence likely precludes resampling procedures for inference, researchers often are unable to quantify uncertainty in the estimates they derive with these methods. This note presents a simple and relatively fast two-step procedure to estimate the covariance matrix for parameters estimated with these algorithms. This procedure relies on automatic differentiation, a computational means of calculating derivatives that is popular in machine learning applications. A brief empirical example demonstrates the advantages of this procedure relative to bootstrapping and shows the similarity in standard error estimates between this procedure and that which would normally accompany maximum likelihood estimation with a gradient-based algorithm.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07176"
    },
    {
        "doc_id": 179,
        "title": "Inference for Synthetic Controls via Refined Placebo Tests",
        "authors": [
            "Lihua Lei",
            "Timothy Sudijono"
        ],
        "subjects": [
            "Methodology",
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The synthetic control method is often applied to problems with one treated unit and a small number of control units. A common inferential task in this setting is to test null hypotheses regarding the average treatment effect on the treated. Inference procedures that are justified asymptotically are often unsatisfactory due to (1) small sample sizes that render large-sample approximation fragile and (2) simplification of the estimation procedure that is implemented in practice. An alternative is permutation inference, which is related to a common diagnostic called the placebo test. It has provable Type-I error guarantees in finite samples without simplification of the method, when the treatment is uniformly assigned. Despite this robustness, the placebo test suffers from low resolution since the null distribution is constructed from only $N$ reference estimates, where $N$ is the sample size. This creates a barrier for statistical inference at a common level like $\u03b1= 0.05$, especially when $N$ is small. We propose a novel leave-two-out procedure that bypasses this issue, while still maintaining the same finite-sample Type-I error guarantee under uniform assignment for a wide range of $N$. Unlike the placebo test whose Type-I error always equals the theoretical upper bound, our procedure often achieves a lower unconditional Type-I error than theory suggests; this enables useful inference in the challenging regime when $\u03b1< 1/N$. Empirically, our procedure achieves a higher power when the effect size is reasonably large and a comparable power otherwise. We generalize our procedure to non-uniform assignments and show how to conduct sensitivity analysis. From a methodological perspective, our procedure can be viewed as a new type of randomization inference different from permutation or rank-based inference, which is particularly effective in small samples.",
        "comments": "36 pages. Comments welcome",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07152"
    },
    {
        "doc_id": 180,
        "title": "Causal machine learning in public policy evaluation -- an application to the conditioning of cash transfers in Morocco",
        "authors": [
            "Patrick Rehill",
            "Nicholas Biddle"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Causal machine learning methods can be used to search for treatment effect heterogeneity in high-dimensional datasets even where we lack a strong enough theoretical framework to select variables or make parametric assumptions about data. This paper uses causal machine learning methods to estimate heterogeneous treatment effects in the case of an experimental study carried out in Morocco which evaluated the effect of conditionalizing a cash transfer program on school attendance compared to a labelled cash transfer. We show that there is little heterogeneity in effects with the average treatment effect across three different conditioning policies all being negative. We then explore if there are any variables in the dataset of 1936 pre-treatment variables that are particularly strong predictors of heterogeneity to try to understand this effect. While there are some variables we expected to be important here based on our theoretical framework, most are atheoretical variables whose effects are difficult to interpret. Household spending variables and child time-use variables are particularly important, however no variables have particularly large effects. The second purpose of this paper is to demonstrate and reflect upon a causal machine learning approach to policy evaluation. In this vein we suggest that findings that are difficult to interpret in this way are not surprising given the atheoretical methodology. We reflect that causal machine learning methods should not replace existing evaluation methodologies, but rather could be a useful tool for working with high-dimensional data and generating hypotheses.",
        "comments": "20 pages, 10 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07075"
    },
    {
        "doc_id": 181,
        "title": "A Dynamic Agent Based Model of the Real Economy with Monopolistic Competition, Perfect Product Differentiation, Heterogeneous Agents, Increasing Returns to Scale and Trade in Disequilibrium",
        "authors": [
            "Subhamon Supantha",
            "Naresh Kumar Sharma"
        ],
        "subjects": [
            "Theoretical Economics",
            "Multiagent Systems"
        ],
        "abstract": "We have used agent-based modeling as our numerical method to artificially simulate a dynamic real economy where agents are rational maximizers of an objective function of Cobb-Douglas type. The economy is characterised by heterogeneous agents, acting out of local or imperfect information, monopolistic competition, perfect product differentiation, allowance for increasing returns to scale technology and trade in disequilibrium. An algorithm for economic activity in each period is devised and a general purpose open source agent-based model is developed which allows for counterfactual inquiries, testing out treatments, analysing causality of various economic processes, outcomes and studying emergent properties. 10,000 simulations, with 10 firms and 80 consumers are run with varying parameters and the results show that from only a few initial conditions the economy reaches equilibrium while in most of the other cases it remains in perpetual disequilibrium. It also shows that from a few initial conditions the economy reaches a disaster where all the consumer wealth falls to zero or only a single producer remains. Furthermore, from some initial conditions, an ideal economy with high wage rate, high consumer utility and no unemployment is also reached. It was also observed that starting from an equal endowment of wealth in consumers and in producers, inequality emerged in the economy. In majority of the cases most of the firms(6-7) shut down because they were not profitable enough and only a few firms remained. Our results highlight that all these varying outcomes are possible for a decentralized market economy with rational optimizing agents.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07070"
    },
    {
        "doc_id": 182,
        "title": "A simple stochastic nonlinear AR model with application to bubble",
        "authors": [
            "Xuanling Yang",
            "Dong Li",
            "Ting Zhang"
        ],
        "subjects": [
            "Statistics Theory",
            "Econometrics"
        ],
        "abstract": "Economic and financial time series can feature locally explosive behavior when a bubble is formed. The economic or financial bubble, especially its dynamics, is an intriguing topic that has been attracting longstanding attention. To illustrate the dynamics of the local explosion itself, the paper presents a novel, simple, yet useful time series model, called the stochastic nonlinear autoregressive model, which is always strictly stationary and geometrically ergodic and can create long swings or persistence observed in many macroeconomic variables. When a nonlinear autoregressive coefficient is outside of a certain range, the model has periodically explosive behaviors and can then be used to portray the bubble dynamics. Further, the quasi-maximum likelihood estimation (QMLE) of our model is considered, and its strong consistency and asymptotic normality are established under minimal assumptions on innovation. A new model diagnostic checking statistic is developed for model fitting adequacy. In addition two methods for bubble tagging are proposed, one from the residual perspective and the other from the null-state perspective. Monte Carlo simulation studies are conducted to assess the performances of the QMLE and the two bubble tagging methods in finite samples. Finally, the usefulness of the model is illustrated by an empirical application to the monthly Hang Seng Index.",
        "comments": "41 pages, 6 figures",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07038"
    },
    {
        "doc_id": 183,
        "title": "Causative Insights into Open Source Software Security using Large Language Code Embeddings and Semantic Vulnerability Graph",
        "authors": [
            "Nafis Tanveer Islam",
            "Gonzalo De La Torre Parra",
            "Dylan Manual",
            "Murtuza Jadliwala",
            "Peyman Najafirad"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Open Source Software (OSS) security and resilience are worldwide phenomena hampering economic and technological innovation. OSS vulnerabilities can cause unauthorized access, data breaches, network disruptions, and privacy violations, rendering any benefits worthless. While recent deep-learning techniques have shown great promise in identifying and localizing vulnerabilities in source code, it is unclear how effective these research techniques are from a usability perspective due to a lack of proper methodological analysis. Usually, these methods offload a developer's task of classifying and localizing vulnerable code; still, a reasonable study to measure the actual effectiveness of these systems to the end user has yet to be conducted. To address the challenge of proper developer training from the prior methods, we propose a system to link vulnerabilities to their root cause, thereby intuitively educating the developers to code more securely. Furthermore, we provide a comprehensive usability study to test the effectiveness of our system in fixing vulnerabilities and its capability to assist developers in writing more secure code. We demonstrate the effectiveness of our system by showing its efficacy in helping developers fix source code with vulnerabilities. Our study shows a 24% improvement in code repair capabilities compared to previous methods. We also show that, when trained by our system, on average, approximately 9% of the developers naturally tend to write more secure code with fewer vulnerabilities.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07035"
    },
    {
        "doc_id": 184,
        "title": "FedDriveScore: Federated Scoring Driving Behavior with a Mixture of Metric Distributions",
        "authors": [
            "Lin Lu"
        ],
        "subjects": [
            "Machine Learning",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Scoring the driving performance of various drivers on a unified scale, based on how safe or economical they drive on their daily trips, is essential for the driver profile task. Connected vehicles provide the opportunity to collect real-world driving data, which is advantageous for constructing scoring models. However, the lack of pre-labeled scores impede the use of supervised regression models and the data privacy issues hinder the way of traditionally data-centralized learning on the cloud side for model training. To address them, an unsupervised scoring method is presented without the need for labels while still preserving fairness and objectiveness compared to subjective scoring strategies. Subsequently, a federated learning framework based on vehicle-cloud collaboration is proposed as a privacy-friendly alternative to centralized learning. This framework includes a consistently federated version of the scoring method to reduce the performance degradation of the global scoring model caused by the statistical heterogeneous challenge of local data. Theoretical and experimental analysis demonstrate that our federated scoring model is consistent with the utility of the centrally learned counterpart and is effective in evaluating driving performance.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06953"
    },
    {
        "doc_id": 185,
        "title": "An empirical model of fleet modernization: on the relationship between market concentration and innovation adoption in the Brazilian airline industry",
        "authors": [
            "Alessandro V. M. Oliveira",
            "Thiago Caliari",
            "Rodolfo R. Narcizo"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The modernization of an airline's fleet can reduce its operating costs, improve the perceived quality of service offered to passengers, and mitigate emissions. The present paper investigates the market incentives that airlines have to adopt technological innovation from manufacturers by acquiring new generation aircraft. We develop an econometric model of fleet modernization in the Brazilian commercial aviation over two decades. We examine the hypothesis of an inverted-U relationship between market concentration and fleet modernization and find evidence that both the extremes of competition and concentration may inhibit innovation adoption by carriers. We find limited evidence associating either hubbing activity or low-cost carriers with the more intense introduction of new types of aircraft models and variants in the industry. Finally, our results suggest that energy cost rises may provoke boosts in fleet modernization in the long term, with carriers possibly targeting more eco-efficient operations up to two years after an upsurge in fuel price.",
        "comments": "Journal ref:        Research in Transportation Business & Management, 43, 100704 (2022)",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06876"
    },
    {
        "doc_id": 186,
        "title": "Deep Learning With DAGs",
        "authors": [
            "Sourabh Balgi",
            "Adel Daoud",
            "Jose M. Pe\u00f1a",
            "Geoffrey T. Wodtke",
            "Jesse Zhou"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Econometrics",
            "Methodology"
        ],
        "abstract": "Social science theories often postulate causal relationships among a set of variables or events. Although directed acyclic graphs (DAGs) are increasingly used to represent these theories, their full potential has not yet been realized in practice. As non-parametric causal models, DAGs require no assumptions about the functional form of the hypothesized relationships. Nevertheless, to simplify the task of empirical evaluation, researchers tend to invoke such assumptions anyway, even though they are typically arbitrary and do not reflect any theoretical content or prior knowledge. Moreover, functional form assumptions can engender bias, whenever they fail to accurately capture the complexity of the causal system under investigation. In this article, we introduce causal-graphical normalizing flows (cGNFs), a novel approach to causal inference that leverages deep neural networks to empirically evaluate theories represented as DAGs. Unlike conventional approaches, cGNFs model the full joint distribution of the data according to a DAG supplied by the analyst, without relying on stringent assumptions about functional form. In this way, the method allows for flexible, semi-parametric estimation of any causal estimand that can be identified from the DAG, including total effects, conditional effects, direct and indirect effects, and path-specific effects. We illustrate the method with a reanalysis of Blau and Duncan's (1967) model of status attainment and Zhou's (2019) model of conditional versus controlled mobility. To facilitate adoption, we provide open-source software together with a series of online tutorials for implementing cGNFs. The article concludes with a discussion of current limitations and directions for future development.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06864"
    },
    {
        "doc_id": 187,
        "title": "Austria's KlimaTicket: Assessing the short-term impact of a cheap nationwide travel pass on demand",
        "authors": [
            "Hannes Wallimann"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Measures to reduce transport-related greenhouse gas emissions are of great importance to policy-makers. A recent example is the nationwide KlimaTicket in Austria, a country with a relatively high share of transport-related emissions. The cheap yearly season ticket introduced in October 2021 allows unlimited access to Austria's public transport network. Using the synthetic control and synthetic difference-in-differences methods, I assess the causal effect of this policy on public transport demand by constructing a data-driven counterfactual out of European railway companies to mimic the number of passengers of the Austrian Federal Railways without the KlimaTicket. The results indicate public transport demand grew slightly faster in Austria, i.e., 3.3 or 6.8 percentage points, depending on the method, than it would have in the absence of the KlimaTicket. However, the growth effect after the COVID-19 pandemic appears only statistically significant when applying the synthetic control method, and the positive effect on public transport demand growth disappears in 2022.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06835"
    },
    {
        "doc_id": 188,
        "title": "QCQP-Net: Reliably Learning Feasible Alternating Current Optimal Power Flow Solutions Under Constraints",
        "authors": [
            "Sihan Zeng",
            "Youngdae Kim",
            "Yuxuan Ren",
            "Kibaek Kim"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "At the heart of power system operations, alternating current optimal power flow (ACOPF) studies the generation of electric power in the most economical way under network-wide load requirement, and can be formulated as a highly structured non-convex quadratically constrained quadratic program (QCQP). Optimization-based solutions to ACOPF (such as ADMM or interior-point method), as the classic approach, require large amount of computation and cannot meet the need to repeatedly solve the problem as load requirement frequently changes. On the other hand, learning-based methods that directly predict the ACOPF solution given the load input incur little computational cost but often generates infeasible solutions (i.e. violate the constraints of ACOPF). In this work, we combine the best of both worlds -- we propose an innovated framework for learning ACOPF, where the input load is mapped to the ACOPF solution through a neural network in a computationally efficient and reliable manner. Key to our innovation is a specific-purpose \"activation function\" defined implicitly by a QCQP and a novel loss, which enforce constraint satisfaction. We show through numerical simulations that our proposed method achieves superior feasibility rate and generation cost in situations where the existing learning-based approaches fail.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06820"
    },
    {
        "doc_id": 189,
        "title": "Robust Analysis of Short Panels",
        "authors": [
            "Andrew Chesher",
            "Adam M. Rosen",
            "Yuanqi Zhang"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Many structural econometric models include latent variables on whose probability distributions one may wish to place minimal restrictions. Leading examples in panel data models are individual-specific variables sometimes treated as \"fixed effects\" and, in dynamic models, initial conditions. This paper presents a generally applicable method for characterizing sharp identified sets when models place no restrictions on the probability distribution of certain latent variables and no restrictions on their covariation with other variables. In our analysis latent variables on which restrictions are undesirable are removed, leading to econometric analysis robust to misspecification of restrictions on their distributions which are commonplace in the applied panel data literature. Endogenous explanatory variables are easily accommodated. Examples of application to some static and dynamic binary, ordered and multiple discrete choice and censored panel data models are presented.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06611"
    },
    {
        "doc_id": 190,
        "title": "Multimodal Learning for detecting urban functional zones using remote sensing image and multi-semantic information",
        "authors": [
            "Chuanji Shi",
            "Yingying Zhang",
            "Jiaotuan Wang",
            "Qiqi Zhu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Urban area-of-interest (AOI) refers to an integrated urban functional zone with defined boundaries. The rapid development of urban commerce has resulted in an increased demand for more precise requirements in defining AOIs. However, existing research primarily concentrates on broad AOI mining for urban planning or regional economic analysis, failing to cater to the precise requirements of mobile Internet online-to-offline businesses. These businesses necessitate accuracy down to a specific community, school, or hospital. In this paper, we propose an end-to-end multimodal deep learning algorithm for detecting AOI fence polygon using remote sensing images and multi-semantics reference information. We then evaluate its timeliness through a cascaded module that incorporates dynamic human mobility and logistics address information. Specifically, we begin by selecting a point-of-interest (POI) of specific category, and use it to recall corresponding remote sensing images, nearby POIs, road nodes, human mobility, and logistics addresses to build a multimodal detection model based on transformer encoder-decoder architecture, titled AOITR. In the model, in addition to the remote sensing images, multi-semantic information including core POI and road nodes is embedded and reorganized as the query content part for the transformer decoder to generate the AOI polygon. Meanwhile, relatively dynamic distribution features of human mobility, nearby POIs, and logistics addresses are used for AOI reliability evaluation through a cascaded feedforward network. The experimental results demonstrate that our algorithm significantly outperforms two existing methods.",
        "comments": "22 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06550"
    },
    {
        "doc_id": 191,
        "title": "Analysis of the Impact of Central bank Digital Currency on the Demand for Transactional Currency",
        "authors": [
            "Ruimin Song",
            "Tiantian Zhao",
            "Chunhui Zhou"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper takes the development of Central bank digital currencies as a perspective, introduces it into the Baumol-Tobin money demand theoretical framework, establishes the transactional money demand model under Central bank Digital Currency, and qualitatively analyzes the influence mechanism of Central bank digital currencies on transactional money demand; meanwhile, quarterly data from 2010-2022 are selected to test the relationship between Central bank digital currencies and transactional money demand through the ARDL model. The long-run equilibrium and short-run dynamics between the demand for Central bank digital currencies and transactional currency are examined by ARDL model. The empirical results show that the issuance and circulation of Central bank digital currencies will reduce the demand for transactional money. Based on the theoretical analysis and empirical test, this paper proposes that China should explore a more effective Currency policy in the context of Central bank digital currencies while promoting the development of Central bank digital currencies in a prudent manner in the future.",
        "comments": "Central bank digital currencies; transactional money demand; ARDL model. arXiv admin note: text overlap with arXiv:2310.07326",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06457"
    },
    {
        "doc_id": 192,
        "title": "Causally Aware Generative Adversarial Networks for Light Pollution Control",
        "authors": [
            "Yuyao Zhang",
            "Ke Guo",
            "Xiao Zhou"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "Artificial light plays an integral role in modern cities, significantly enhancing human productivity and the efficiency of civilization. However, excessive illumination can lead to light pollution, posing non-negligible threats to economic burdens, ecosystems, and human health. Despite its critical importance, the exploration of its causes remains relatively limited within the field of artificial intelligence, leaving an incomplete understanding of the factors contributing to light pollution and sustainable illumination planning distant. To address this gap, we introduce a novel framework named Causally Aware Generative Adversarial Networks (CAGAN). This innovative approach aims to uncover the fundamental drivers of light pollution within cities and offer intelligent solutions for optimal illumination resource allocation in the context of sustainable urban development. We commence by examining light pollution across 33,593 residential areas in seven global metropolises. Our findings reveal substantial influences on light pollution levels from various building types, notably grasslands, commercial centers and residential buildings as significant contributors. These discovered causal relationships are seamlessly integrated into the generative modeling framework, guiding the process of generating light pollution maps for diverse residential areas. Extensive experiments showcase CAGAN's potential to inform and guide the implementation of effective strategies to mitigate light pollution. Our code and data are publicly available at https://github.com/zhangyuuao/Light_Pollution_CAGAN.",
        "comments": "9pages, 9figures, accepted by AAAI2024, AI for Social Impact (Special Track)",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06453"
    },
    {
        "doc_id": 193,
        "title": "Secure Targeted Message Dissemination in IoT Using Blockchain Enabled Edge Computing",
        "authors": [
            "Muhammad Baqer Mollah",
            "Md Abul Kalam Azad",
            "Yinghui Zhang"
        ],
        "subjects": [
            "Cryptography and Security",
            "Networking and Internet Architecture"
        ],
        "abstract": "Smart devices are considered as an integral part of Internet of Things (IoT), have an aim to make a dynamic network to exchange information, collect data, analysis, and make optimal decisions in an autonomous way to achieve more efficient, automatic, and economical services. Message dissemination among these smart devices allows adding new features, sending updated instructions, alerts or safety messages, informing the pricing information or billing amount, incentives, and installing security patches. On one hand, such message disseminations are directly beneficial to the all parties involved in the IoT system. On the other hand, due to remote procedure, smart devices, vendors, and other involved authorities might have to meet a number of security, privacy, and performance related concerns while disseminating messages among targeted devices. To this end, in this paper, we design STarEdgeChain, a security and privacy aware targeted message dissemination in IoT to show how blockchain along with advanced cryptographic techniques are devoted to address such concerns. In fact, the STarEdgeChain employs a permissioned blockchain assisted edge computing in order to expedite a single signcrypted message dissemination among targeted groups of devices, at the same time avoiding the dependency of utilizing multiple unicasting approaches. Finally, we develop a software prototype of STarEdgeChain and show it's practicability for smart devices. The codes are publicly available at https://github.com/mbaqer/Blockchain-IoT",
        "comments": "12 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06384"
    },
    {
        "doc_id": 194,
        "title": "Exposure effects are not automatically useful for policymaking",
        "authors": [
            "Eric Auerbach",
            "Jonathan Auerbach",
            "Max Tabord-Meehan"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "We thank Savje (2023) for a thought-provoking article and appreciate the opportunity to share our perspective as social scientists. In his article, Savje recommends misspecified exposure effects as a way to avoid strong assumptions about interference when analyzing the results of an experiment. In this invited discussion, we highlight a limiation of Savje's recommendation: exposure effects are not generally useful for evaluating social policies without the strong assumptions that Savje seeks to avoid.",
        "comments": "Invited Discussion Paper",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06264"
    },
    {
        "doc_id": 195,
        "title": "Temporary exclusion in repeated contests",
        "authors": [
            "Yaron Azrieli"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "Consider a large population of agents who repeatedly compete for awards, as in the case of researchers who can annually apply for grants from a science foundation. A key objective for the principal is to efficiently allocate resources to the highest quality applications, but the review process is often inherently noisy. Imperfect selection of winners may encourage low quality applications, which in turn forces the designer to commit more resources to the reviewing process and can further increase the misallocation. We study \\emph{temporary exclusion} as a potential solution to these problems. With exclusion, an agent is ineligible to apply in the current period if they were rejected (or if they applied) in the previous period. Such policy introduces intertemporal incentives to the participation decision and encourages self-selection. We characterize the steady-state equilibria of this dynamic game and compare the outcomes to the benchmark case without exclusion. In particular, we show that whenever the benefit from winning is large, exclusion leads to fewer low quality applications and higher welfare for agents.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06257"
    },
    {
        "doc_id": 196,
        "title": "The Shapley Value in Database Management",
        "authors": [
            "Leopoldo Bertossi",
            "Benny Kimelfeld",
            "Ester Livshits",
            "Mika\u00ebl Monet"
        ],
        "subjects": [
            "Databases"
        ],
        "abstract": "Attribution scores can be applied in data management to quantify the contribution of individual items to conclusions from the data, as part of the explanation of what led to these conclusions. In Artificial Intelligence, Machine Learning, and Data Management, some of the common scores are deployments of the Shapley value, a formula for profit sharing in cooperative game theory. Since its invention in the 1950s, the Shapley value has been used for contribution measurement in many fields, from economics to law, with its latest researched applications in modern machine learning. Recent studies investigated the application of the Shapley value to database management. This article gives an overview of recent results on the computational complexity of the Shapley value for measuring the contribution of tuples to query answers and to the extent of inconsistency with respect to integrity constraints. More specifically, the article highlights lower and upper bounds on the complexity of calculating the Shapley value, either exactly or approximately, as well as solutions for realizing the calculation in practice.",
        "comments": "12 pages, including references. This is the authors version of the corresponding SIGMOD Record article",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06234"
    },
    {
        "doc_id": 197,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 198,
        "title": "Grassroots Innovation Actors: Their Role and Positioning in Economic Ecosystems -- A Comparative Study Through Complex Network Analysis",
        "authors": [
            "Marcelo S. Tedesco",
            "Francisco Javier Ramos Soria"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This study offers an examination of grassroots innovation actors and their integration within larger economic ecosystems. Through a comparative analysis in Oaxaca, Mexico; La Plata, Argentina; and Araucania, Chile, this research sheds light on the vital role that grassroots innovation plays in broader economic ecosystems. Using Complex Network Analysis and the TE-SER model, the study unveils how these actors interact, collaborate, and influence major economic ecosystems in the context of complex social challenges. The findings highlight that actors from the grassroots innovation ecosystem make up a significant portion of the larger innovation-driven entrepreneurial economic ecosystem, accounting for between 20% and 30% in all three cases and are strategically positioned within the ecosystem's structural network. Additionally, this study emphasizes the potential for greater integration of grassroots innovation actors to leverage resources and foster socio-economic development. The research concludes by advocating for further studies in similar socio-economic contexts to enhance our understanding of integration dynamics and mutual benefits between grassroots innovation ecosystems and other larger economic systems.",
        "comments": "21 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06163"
    },
    {
        "doc_id": 199,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 200,
        "title": "General relativity in a nutshell II",
        "authors": [
            "Jorge Pinochet"
        ],
        "subjects": [
            "Popular Physics",
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "The aim of this work is to use the notions of Riemann's geometry introduced in Part I, to analyze the foundations of Einstein's theory of general relativity.",
        "comments": "14 pages, 11 figures",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.12219"
    },
    {
        "doc_id": 201,
        "title": "Off-stoichiometric effect on magnetic and electron transport properties of Fe$_2$VAl$_{1.35}$ in respect to Ni$_2$VAl; Comparative study",
        "authors": [
            "Andrzej \u015alebarski",
            "Marcin Fija\u0142kowski",
            "J\u00f3zef Deniszczyk",
            "Maciej M. Ma\u015bka",
            "Dariusz Kaczorowski"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Disordered Systems and Neural Networks"
        ],
        "abstract": "Density functional theory (DFT) calculations confirm that the structurally ordered Fe$_2$VAl Heusler alloy is nonmagnetic narrow-gap semiconductor. This compound is apt to form various disordered modifications with high concentration of antisite defects. We study the effect of structural disorder on the electronic structure, magnetic, and electronic transport properties of the full Heusler alloy Fe$_2$VAl and its off-stoichiometric equivalent Fe$_2$VAl$_{1.35}$. Data analysis in relation to {\\it ab initio} calculations indicates an appearance of antisite disorder mainly due to Fe--V and Fe--Al stoichiometric variations. The data for weakly magnetic Fe$_2$VAl$_{1.35}$ are discussed in respect to Ni$_2$VAl. Fe$_2$VAl$_{1.35}$ can be classified as a nearly ferromagnetic metal with a pronounced spin glassy contribution, which, however, does not give a predominant effect on its thermoelectric properties. The figure of merit $ZT$ is at 300 K about 0.05 for the Fe sample and 0.02 for Ni one, respectively. However, it is documented that the narrow $d$ band resulting from Fe/V site exchange can be responsible for the unusual temperature dependencies of the physical properties of the Fe2TiAl$_{1.35}$ alloy, characteristic of strongly correlated electron systems. As an example, the magnetic susceptibility of Fe$_2$VAl$_{1.35}$ exhibits singularity characteristic of a Griffiths phase, appearing as an inhomogeneous electronic state below $T_G\\sim 200$ K. We also performed numerical analysis which supports the Griffiths phase scenario.",
        "comments": "19 pages, 22 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12218"
    },
    {
        "doc_id": 202,
        "title": "Identifying gap-closings in open non-Hermitian systems by Biorthogonal Polarization",
        "authors": [
            "Ipsita Mandal"
        ],
        "subjects": [
            "Quantum Physics",
            "Mesoscale and Nanoscale Physics",
            "High Energy Physics - Theory",
            "Optics"
        ],
        "abstract": "We investigate gap-closings in one- and two-dimensional tight-binding models with two bands, containing non-Hermitian hopping terms, and open boundary conditions (OBCs) imposed along one direction. We compare the bulk OBC spectra with the periodic boundary condition (PBC) spectra, pointing out that they do not coincide, which is an intrinsic characteristic of non-Hermitian systems. The non-Hermiticity thus results in the failure of the familiar notions of bulk-boundary correspondence found for Hermitian systems. This necessitates the search for topological invariants which can characterize gap-closings in open non-Hermitian systems correctly and unambiguously. We elucidate the behaviour of two possible candidates applicable for one-dimensional slices -- (1) the sum of winding numbers for the two bands defined on a generalized Brillouin zone and (2) the biorthogonal polarization (BP). While the former shows jumps/discontinuities for some of the non-Hermitian systems studied here, at points when an edge mode enters the bulk states and becomes delocalized, it does not maintain quantized values in a given topological phase. On the contrary, BP shows jumps and at phase transitions takes the quantized value of one or zero, which corresponds to whether an actual edge mode exists or whether that mode is delocalized and absorbed within the bulk (not being an edge mode anymore).",
        "comments": "13 pages, 5 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12213"
    },
    {
        "doc_id": 203,
        "title": "Active Inference Demonstrated with Artificial Spin Ice",
        "authors": [
            "R. L. Stamps"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Disordered Systems and Neural Networks",
            "Biological Physics"
        ],
        "abstract": "A variational Bayesian method is implemented in a numerical model of interacting nanomagnetic elements to demonstrate active inference in an Artificial Spin Ice geometry. It is shown that thermal fluctuations can drive this magnetic spin system to evolve along a trajectory of spin configuration states in response to an external environment according to a neurological free energy principle with active inference. The proposed bilayer is an extension of a two-dimensional system studied in an Artificial Spin Ice that has been extensively investigated experimentally and theoretically. The two layers function effectively as a sensory layer providing input to a hidden layer. The spin dynamics displayed by the bilayer are shown to be well described using a continuous form of the free energy principle that has been proposed as a high level description of certain biological neural processes. Numerical simulations demonstrate that this proposed bilayer geometry is able to reproduce theoretical results derived previously for examples of neurological action and perception.",
        "comments": "26 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12211"
    },
    {
        "doc_id": 204,
        "title": "A Single Photon Source based on a Long-Range Interacting Room Temperature Vapor",
        "authors": [
            "Felix Moumtsilis",
            "Max M\u00e4usezahl",
            "Haim Nakav",
            "Annika Belz",
            "Robert L\u00f6w",
            "Tilman Pfau"
        ],
        "subjects": [
            "Atomic Physics",
            "Quantum Physics"
        ],
        "abstract": "We report on the current development of a single photon source based on a long-range interacting room temperature rubidium vapor. We discuss the history of the project, the production of vapor cells, and the observation of Rabi-oscillations in the four-wave-mixing excitation scheme.",
        "comments": "8 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12209"
    },
    {
        "doc_id": 205,
        "title": "LONEStar: The Lunar Flashlight Optical Navigation Experiment",
        "authors": [
            "Michael Krause",
            "Ava Thrasher",
            "Priyal Soni",
            "Liam Smego",
            "Reuben Isaac",
            "Jennifer Nolan",
            "Micah Pledger",
            "E. Glenn Lightsey",
            "W. Jud Ready",
            "John Christian"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Instrumentation and Methods for Astrophysics",
            "Space Physics"
        ],
        "abstract": "This paper documents the results from the highly successful Lunar flashlight Optical Navigation Experiment with a Star tracker (LONEStar). Launched in December 2022, Lunar Flashlight (LF) was a NASA-funded technology demonstration mission. After a propulsion system anomaly prevented capture in lunar orbit, LF was ejected from the Earth-Moon system and into heliocentric space. NASA subsequently transferred ownership of LF to Georgia Tech to conduct an unfunded extended mission to demonstrate further advanced technology objectives, including LONEStar. From August-December 2023, the LONEStar team performed on-orbit calibration of the optical instrument and a number of different OPNAV experiments. This campaign included the processing of nearly 400 images of star fields, Earth and Moon, and four other planets (Mercury, Mars, Jupiter, and Saturn). LONEStar provided the first on-orbit demonstrations of heliocentric navigation using only optical observations of planets. Of special note is the successful in-flight demonstration of (1) instantaneous triangulation with simultaneous sightings of two planets with the LOST algorithm and (2) dynamic triangulation with sequential sightings of multiple planets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12198"
    },
    {
        "doc_id": 206,
        "title": "Learning Dynamics from Multicellular Graphs with Deep Neural Networks",
        "authors": [
            "Haiqian Yang",
            "Florian Meyer",
            "Shaoxun Huang",
            "Liu Yang",
            "Cristiana Lungu",
            "Monilola A. Olayioye",
            "Markus J. Buehler",
            "Ming Guo"
        ],
        "subjects": [
            "Biological Physics",
            "Soft Condensed Matter"
        ],
        "abstract": "The inference of multicellular self-assembly is the central quest of understanding morphogenesis, including embryos, organoids, tumors, and many others. However, it has been tremendously difficult to identify structural features that can indicate multicellular dynamics. Here we propose to harness the predictive power of graph-based deep neural networks (GNN) to discover important graph features that can predict dynamics. To demonstrate, we apply a physically informed GNN (piGNN) to predict the motility of multicellular collectives from a snapshot of their positions both in experiments and simulations. We demonstrate that piGNN is capable of navigating through complex graph features of multicellular living systems, which otherwise can not be achieved by classical mechanistic models. With increasing amounts of multicellular data, we propose that collaborative efforts can be made to create a multicellular data bank (MDB) from which it is possible to construct a large multicellular graph model (LMGM) for general-purposed predictions of multicellular organization.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12196"
    },
    {
        "doc_id": 207,
        "title": "Using spatial extreme-value theory with machine learning to model and understand spatially compounding extremes",
        "authors": [
            "Jonathan Koh",
            "Daniel Steinfeld",
            "Olivia Martius"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "When extreme weather events affect large areas, their regional to sub-continental spatial scale is important for their impacts. We propose a novel methodology that combines spatial extreme-value theory with a machine learning (ML) algorithm to model weather extremes and quantify probabilities associated with the occurrence, intensity and spatial extent of these events. The model is here applied to Western European summertime heat extremes. Using new loss functions adapted to extreme values, we fit a theoretically-motivated spatial model to extreme positive temperature anomaly fields from 1959-2022, using the daily 500-hpa geopotential height fields across the Euro-Atlantic region and the local soil moisture as predictors. Our generative model reveals the importance of individual circulation features in determining different facets of heat extremes, thereby enriching our process understanding of them from a data-driven perspective. The occurrence, intensity, and spatial extent of heat extremes are sensitive to the relative position of individual ridges and troughs that are part of a large-scale wave pattern. Heat extremes in Europe are thus the result of a complex interplay between local and remote physical processes. Our approach is able to extrapolate beyond the range of the data to make risk-related probabilistic statements, and applies more generally to other weather extremes. It also offers an attractive alternative to physical model-based techniques, or to ML approaches that optimise scores focusing on predicting well the bulk instead of the tail of the data distribution.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12195"
    },
    {
        "doc_id": 208,
        "title": "Information Problem in Black Holes and Cosmology and Ghosts in Quadratic Gravity",
        "authors": [
            "Igor Volovich"
        ],
        "subjects": [
            "High Energy Physics - Theory"
        ],
        "abstract": "Black hole information problem is the question about unitarity of the evolution operator during the collapse and evaporation of the black hole. One can ask the same question about unitarity of quantum and inflationary cosmology. In this paper we argue that in both cases, for black holes and for cosmology, the answer is negative and we face non-unitarity.\n  Such a question can not be addressed by using the fixed classical gravitational background since one has to take into account the backreaction. To his end one uses the semi-classical gravity, which includes the expectation value of the energy - momentum tensor operator of the matter fields. One has to renormalize the energy-momentum tensor and one gets an effective action which contains quadratic terms in scalar curvature and Ricci tensor. Such quadratic gravity contains ghosts which in fact lead to violation of unitarity in black holes and cosmology. We discuss the question whether black holes will emit ghosts.\n  One can try to restrict ourselves to the $f(R)$ gravity that seems is a good approximation to the semi-classical gravity and widely used in cosmology. The black hole entropy in $f(R)$ gravity is different from the Bekenstein-Hawking entropy and from entanglement island entropy. The black hole entropy in $R+R^2$ gravity goes to a constant during the evaporation process. This can be interpreted as another indication to the possible non-unitarity in black holes and cosmology",
        "comments": "10 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12191"
    },
    {
        "doc_id": 209,
        "title": "Towards a more complete description of hybrid leptogenesis",
        "authors": [
            "Rohan Pramanick",
            "Tirtha Sankar Ray",
            "Arunansu Sil"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Hybrid leptogenesis framework combining type I and type II seesaw mechanism for neutrino mass necessarily include scattering topologies involving both the scalar triplet and the right handed neutrino. We demonstrate that a systematic inclusion of these mixed scatterings can significantly alter the evolution of the number densities leading to an order of magnitude change in the predicted value of present-day asymmetry. We provide quantitative limit on the degeneracy of the seesaw scales where the complete analysis becomes numerically significant, limiting the validity of leptogenesis being dominated by the lightest seesaw species.",
        "comments": "27 pages, 2 tables and 14 captioned figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12189"
    },
    {
        "doc_id": 210,
        "title": "A Moving Surface Drag Model for LES of Wind over Waves",
        "authors": [
            "Manuel Ayala",
            "Zein Sadek",
            "Ond\u0159ej Fer\u010d\u00e1k",
            "Ra\u00fal Bayo\u00e1n Cal",
            "Dennice Gayme",
            "Charles Meneveau"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "Numerical prediction of the interactions between wind and ocean waves is essential for climate modeling and a wide range of offshore operations. Large Eddy Simulation (LES) of the marine atmospheric boundary layer is a practical numerical predictive tool but requires parameterization of surface fluxes at the air-water interface. Current momentum flux parameterizations primarily use wave-phase adapting computational grids, incurring high computational costs, or use an equilibrium model based on Monin-Obukhov similarity theory for rough surfaces that cannot resolve wave phase information. To include wave phase-resolving physics at a cost similar to the equilibrium model, the Moving Surface Drag (MOSD) model is introduced. It assumes ideal airflow over locally piece-wise planar representations of moving water wave surfaces. Horizontally unresolved interactions are still modeled using the equilibrium model. Validation against experimental and numerical datasets with known monochromatic waves demonstrates the robustness and accuracy of the model in representing wave-induced impacts on mean velocity and Reynolds stress profiles. The model is formulated to be applicable to a broad range of wave fields and its ability to represent cross-swell and multiple wavelength cases is illustrated. Additionally, the model is applied to LES of a laboratory-scale fixed-bottom offshore wind turbine model, and the results are compared with wind tunnel experimental data. The LES with the MOSD model shows good agreement in wind-wave-wake interactions and phase-dependent physics at a low computational cost. The model's simplicity and minimal computational needs make it valuable for studying turbulent atmospheric-scale flows over the sea, particularly in offshore wind energy research.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12188"
    },
    {
        "doc_id": 211,
        "title": "Ionic conductivity of a lithium-doped deep eutectic solvent: Glass formation and rotation-translation coupling",
        "authors": [
            "A. Schulz",
            "P. Lunkenheimer",
            "A. Loidl"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Disordered Systems and Neural Networks",
            "Materials Science",
            "Chemical Physics"
        ],
        "abstract": "Deep eutectic solvents with admixed lithium salts are considered as electrolytes in electrochemical devices like batteries or supercapacitors. Here we apply dielectric spectroscopy to the widely studied deep eutectic solvent glyceline, to which 1 and 5 mol% LiCl were added. We investigate the glassy freezing and rotation-translation coupling of these mixtures in a wide temperature range, including the deeply supercooled state. The temperature dependences of the detected dipolar reorientation dynamics and of the ionic dc conductivity reveal the signatures of glassy freezing. In comparison to pure glyceline, lithium admixture leads to a reduction of ionic conductivity, which is accompanied by a slowing down of the rotational dipolar motions. In contrast to pure glyceline, the ionic and dipolar dynamics become increasingly decoupled at low temperatures and obey a fractional Debye-Stokes-Einstein relation as previously found in other glass-forming liquids. The obtained results demonstrate the relevance of decoupling effects and of the glass transition for the technically relevant ionic conductivity of these solvents.",
        "comments": "9 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12186"
    },
    {
        "doc_id": 212,
        "title": "Observation of discrete charge states of a coherent two-level system in a superconducting qubit",
        "authors": [
            "Bao-Jie Liu",
            "Ying-Ying Wang",
            "Tal Sheffer",
            "Chen Wang"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "We report observations of discrete charge states of a coherent dielectric two-level system (TLS) that is strongly coupled to an offset-charge-sensitive superconducting transmon qubit. We measure an offset charge of 0.072$e$ associated with the two TLS eigenstates, which have a transition frequency of 2.9 GHz and a relaxation time exceeding 3 ms. Combining measurements in the strong dispersive and resonant regime, we quantify both transverse and longitudinal couplings of the TLS-qubit interaction. We further perform joint tracking of TLS transitions and quasiparticle tunneling dynamics but find no intrinsic correlations. This study demonstrates microwave-frequency TLS as a source of low-frequency charge noise.",
        "comments": "5 pages, 5 figures + 10 pages, 8 figures, 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12183"
    },
    {
        "doc_id": 213,
        "title": "Theoretical studies of envelope oscillations and instabilities of mismatched intense charged-particle beams in periodic focusing channels",
        "authors": [
            "J\u00fcrgen Struckmeier",
            "Martin Reiser"
        ],
        "subjects": [
            "Accelerator Physics"
        ],
        "abstract": "The behavior of mismatched intense charged-particle beams in periodic transport channels of the solenoid and quadrupole type is studied theoretically. The envelope-oscillation frequencies of the mismatched beam are obtained by the smooth-approximation method and by numerical evaluation of the linearly perturbed K-V envelope equations. Phase shifts of the envelope oscillations and growth rates in the case of instability are calculated for a solenoid and a magnetic quadrupole (FODO) channel using the parameters of the Maryland and GSI beam transport experiments. For comparison and the purpose of illustration, the K-V equations are integrated numerically, and envelope curves as well as single-particle trajectories for for mismatched beams are shown in graphical form. In addition, computer simulation studies with the PARMILA code were performed, and results are presented both for K-V and a Gaussian distribution in transverse phase space.",
        "comments": "27 pages, 24 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12171"
    },
    {
        "doc_id": 214,
        "title": "My Understanding for Static and Dynamic Light Scattering",
        "authors": [
            "Yong Sun"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Static Light Scattering (SLS) and Dynamic Light Scattering (DLS) are very important techniques to study the characteristics of nano-particles in dispersion. The data of SLS is determined by the optical characteristic and the measured values of DLS are determined by optical and hydrodynamic characteristics of different size nano-particles in dispersion. Then considering the optical characteristic of nano-particles and using the SLS technique further, the size distribution can be measured accurately and is also consistent with the results measured using the TEM technique. Based on the size distribution obtained using the SLS or TEM technique and the relation between the static and hydrodynamic radii, all the expected and measured values of $g^{\\left( 2\\right) }\\left( \u03c4\\right) $ investigated are very well consistent. Since the data measured using the DLS technique contains the information of the optical and hydrodynamic properties of nano-particles together, therefore the accurate size distribution cannot be obtained from the experimental data of\n  $g^{\\left( 2\\right) }\\left( \u03c4\\right) $ for an unknown sample. The traditional particle information: apparent hydrodynamic radius and polydispersity index measured using the DLS technique are determined by the optical and hydrodynamic characteristics and size distribution together. They cannot represent a number distribution of nano-particles in dispersion. Using the light scattering technique not only can measure the size distribution accurately but also can provide a method to understand the optical and hydrodynamic characteristics of nano-particles.",
        "comments": "12 pages, 7 figures, 5 tables. arXiv admin note: text overlap with arXiv:1110.1703",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12169"
    },
    {
        "doc_id": 215,
        "title": "SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities",
        "authors": [
            "Boyuan Chen",
            "Zhuo Xu",
            "Sean Kirmani",
            "Brian Ichter",
            "Danny Driess",
            "Pete Florence",
            "Dorsa Sadigh",
            "Leonidas Guibas",
            "Fei Xia"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computation and Language",
            "Machine Learning",
            "Robotics"
        ],
        "abstract": "Understanding and reasoning about spatial relationships is a fundamental capability for Visual Question Answering (VQA) and robotics. While Vision Language Models (VLM) have demonstrated remarkable performance in certain VQA benchmarks, they still lack capabilities in 3D spatial reasoning, such as recognizing quantitative relationships of physical objects like distances or size differences. We hypothesize that VLMs' limited spatial reasoning capability is due to the lack of 3D spatial knowledge in training data and aim to solve this problem by training VLMs with Internet-scale spatial reasoning data. To this end, we present a system to facilitate this approach. We first develop an automatic 3D spatial VQA data generation framework that scales up to 2 billion VQA examples on 10 million real-world images. We then investigate various factors in the training recipe, including data quality, training pipeline, and VLM architecture. Our work features the first internet-scale 3D spatial reasoning dataset in metric space. By training a VLM on such data, we significantly enhance its ability on both qualitative and quantitative spatial VQA. Finally, we demonstrate that this VLM unlocks novel downstream applications in chain-of-thought spatial reasoning and robotics due to its quantitative estimation capability. Project website: https://spatial-vlm.github.io/",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12168"
    },
    {
        "doc_id": 216,
        "title": "Study of Jupiter's Interior: Comparison of 2, 3, 4, 5, and 6 Layer Models",
        "authors": [
            "Burkhard Militzer",
            "William B. Hubbard"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics"
        ],
        "abstract": "With the goal of matching spacecraft measurements from Juno and Galileo missions, we construct ensembles of 2, 3, 4, 5, and 6 layer models for Jupiter's interior. All except our two layer models can match the planet's gravity field as measured by the Juno spacecraft. We find, however, that some model types are more plausible than others. In the best three layer models, for example, the transition from molecular to metallic hydrogen needs to be at ~500 GPa while theory and experiments place this transition at ~100 GPa. Four layer models with a single sharp boundary between core and mantle would be short-lived due to rapid convective core erosion. For this reason, we favor our five layer models that include a dilute core surrounded by a stably stratified core transition layer. Six layer models with a small compact core are also possible but with an upper limit of 3 Earth masses for such a compact core. All models assume a 1 bar temperature of 166.1 K, employ physical equations of state, and are constructed with the nonperturbative Concentric Maclaurin Spheroid (CMS) method. We analyze the convergence of this method and describe technical steps that are needed to make this technique so efficient that ensembles of models can be generated.",
        "comments": "11 figures, 1 table, one numerical method to find roots of N dimensional problems",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12166"
    },
    {
        "doc_id": 217,
        "title": "Bayesian analysis of nontrivial features in the speed of sound inside neutron stars in light of astrophysical and pQCD constraints",
        "authors": [
            "Debora Mroczek"
        ],
        "subjects": [
            "Nuclear Theory",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Functional forms of the neutron star Equation of State (EoS) are required to extract the viable EoS band from neutron star observations. Realistic nuclear EoS, containing deconfined quarks or hyperons, present nontrivial features in the speed of sound such as bumps, kinks, and plateaus. Using modified Gaussian processes to model EoS with nontrivial features, we show in a fully Bayesian analysis incorporating measurements from X-ray sources, gravitational wave observations, and perturbative QCD results that these features are compatible with current constraints. We find nontrivial behavior in the EoS plays a role in understanding the possible phase structure of neutron stars at densities around 2 $n_{\\rm sat}$.",
        "comments": "4 pages, 2 figures. Contribution to Quark Matter 2023",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12165"
    },
    {
        "doc_id": 218,
        "title": "On the Evolution During Growth of Regular Boundaries of Bodies into Fractals",
        "authors": [
            "Vladimir Goldshtein",
            "Reuven Segev"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "Generalizing smooth volumetric growth to the singular case, using de Rham currents and flat chains, we demonstrate how regular boundaries of bodies may evolve to fractals.",
        "comments": "MSC Class:          70A05",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12163"
    },
    {
        "doc_id": 219,
        "title": "Threshold production of $\u03b7_{c,b}$ using holographic QCD",
        "authors": [
            "Florian Hechenberger",
            "Kiminad A. Mamo",
            "Ismail Zahed"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We discuss the possibility that threshold photoproduction of $\u03b7_{c,b}$ may be sensitive to the pseudovector $1^{+-}$ glueball exchange. We use the holographic construction to identify the pseudovector glueball with the Kalb-Ramond field, minimally coupled to bulk Dirac fermions. We derive the holographic C-odd form factor and its respective charge radius. Using the pertinent Witten diagrams, we derive and analyze the differential photoproduction cross section for $\u03b7_{c,b}$ in the threshold regime, including the interference from the dual bulk photon exchange with manifest vector dominance. The possibility of measuring this process at current and future electron facilities is discussed.",
        "comments": "19 pages, 10 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12162"
    },
    {
        "doc_id": 220,
        "title": "Toward new scaling laws for wrinkling in biologically relevant fiber-reinforced bilayers",
        "authors": [
            "A. Mirandola",
            "A. Cutolo",
            "A. R. Carotenuto",
            "N. Nguyen",
            "L. Pocivavsek",
            "M. Fraldi",
            "L. Deseri"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Materials Science"
        ],
        "abstract": "Wrinkling, creasing and folding are frequent phenomena encountered in biological and man-made bilayers made by thin films bonded to thicker and softer substrates often containing fibers. Paradigmatic examples of the latter are the skin, the brain, and arterial walls, for which wiggly cross-sections are detected. Although experimental investigations on corrugation of these and analog bilayers would greatly benefit from scaling laws for prompt comparison of the wrinkling features, neither are they available nor have systematic approaches yielding to such laws ever been provided before. This gap is filled in this paper, where a uniaxially compressed bilayer formed by a thin elastic film bonded on a hyperelastic fiber-reinforced substrate is considered. The force balance at the film-substrate interface is here analytically and numerically investigated for highly mismatched film-substrates. The onset of wrinkling is then characterized in terms of both the critical strain and its corresponding wavenumber. Inspired by the asymptotic laws available for neo-Hookean bilayers, the paper then provides a systematic way to achieve novel scaling laws for the wrinkling features for fiber-reinforced highly mismatched hyperelastic bilayers. Such novel scaling laws shed light on the key contributions defining the response of the bilayer, as it is characterized by a fiber-induced complex anisotropy. Results are compared with Finite Element Analyses and also with outcomes of both existing linear models and available adhoc scalings. Furthermore, the amplitude, the global maximum and minimum of ruga occurring under increasing compression spanning the wrinkling, period doubling and folding regimes are also obtained.",
        "comments": "Journal ref:        Journal of Applied Physics 134.15 (2023)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12157"
    },
    {
        "doc_id": 221,
        "title": "Dirac zeros in an orbital selective Mott phase: Green's function Berry curvature and flux quantization",
        "authors": [
            "Lei Chen",
            "Haoyu Hu",
            "Maia G. Vergniory",
            "Jennifer Cano",
            "Qimiao Si"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "How electronic topology develops in strongly correlated systems represents a fundamental challenge in the field of quantum materials. Recent studies have advanced the characterization and diagnosis of topology in Mott insulators whose underlying electronic structure is topologically nontrivial, through ``Green's function zeros\". However, their counterparts in metallic systems have yet to be explored. Here, we address this problem in an orbital-selective Mott phase (OSMP), which is of extensive interest to a variety of strongly correlated systems with a short-range Coulomb repulsion. We demonstrate symmetry protected crossing of the zeros in an OSMP. Utilizing the concept of Green's function Berry curvature, we show that the zero crossing has a quantized Berry flux. The resulting notion of Dirac zeros provides a window into the largely hidden landscape of topological zeros in strongly correlated metallic systems and, moreover, opens up a means to diagnose strongly correlated topology in new materials classes.",
        "comments": "10 pages, 5 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12156"
    },
    {
        "doc_id": 222,
        "title": "Superfluidity of indirect momentum space dark dipolar excitons in a double layer with massive anisotropic tilted semi-Dirac bands",
        "authors": [
            "A. Nafis Arafat",
            "Oleg L. Berman",
            "Godfrey Gumbs"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "We have theoretically investigated the spin- and valley-dependent superfluidity properties of indirect momentum space dark dipolar excitons in double layers with massive anisotropic tilted semi-Dirac bands in the presence of circularly polarized irradiation. An external vertical electric field is also applied to the structure and is responsible for tilting and gap opening for the band structure. For our calculations we used the parameters of a double layer of 1T$^\\prime$-MoS$_2$. Closed form analytical expressions are presented for the energy spectrum for excitons, their associated wave functions and binding energies. Additionally, we examine the effects which the intensity and frequency of circularly polarized irradiation has for 1T$^\\prime$-MoS$_2$ on the effective mass of the excitons since it has been demonstrated that the application of an external high-frequency dressing field tailors the crucial electronic including the exciton binding energy, as well as the critical temperature for superfluidity. We also calculate the sound velocity in the anisotropic weakly-interacting Bose gas of two-component indirect momentum space dark excitons for a double layer of 1T$^\\prime$-MoS$_2$. We show that the critical velocity of superfluidity, the spectrum of collective excitations, concentrations of the superfluid and normal component, and mean field critical temperature for superfluidity are anisotropic and formed by a two-component system. The critical temperature for superfluidity is increased when the exciton concentration and interlayer separation are increased. We propose the use of phonon-assisted photoluminescence to experimentally confirm directional superfluidity of indirect momentum space dark excitons in a double layer with massive anisotropic tilted semi-Dirac bands.",
        "comments": "24 pages, 12 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12154"
    },
    {
        "doc_id": 223,
        "title": "Review on the Role of GNSS Meteorology in Monitoring Water Vapor for Atmospheric Physics",
        "authors": [
            "Javier Vaquero-Martinez",
            "Manuel Anton"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "After 30 years since the beginning of the Global Positioning System (GPS), or, more generally, Global Navigation Satellite System (GNSS) meteorology, this technique has proven to be a reliable method for retrieving atmospheric water vapor; it is low-cost, weather independent, with high temporal resolution and is highly accurate and precise. GNSS ground-based networks are becoming denser, and the first stations installed have now quite long time-series that allow the study of the temporal features of water vapor and its relevant role inside the climate system. In this review, the different GNSS methodologies to retrieve atmospheric water vapor content re-examined, such as tomography, conversion of GNSS tropospheric delay to water vapor estimates, analyses of errors, and combinations of GNSS with other sources to enhance water vapor information. Moreover, the use of these data in different kinds of studies is discussed. For instance, the GNSS technique is commonly used as a reference tool for validating other water vapor products (e.g., radiosounding, radiometers onboard satellite platforms or ground-based instruments). Additionally, GNSS retrievals are largely used in order to determine the high spatio-temporal variability and long-term trends of atmospheric water vapor or in models with the goal of determining its notable influence on the climate system (e.g., assimilation in numerical prediction, as input to radiative transfer models, study of circulation patterns, etc.",
        "comments": "29 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12148"
    },
    {
        "doc_id": 224,
        "title": "An Efficient Finite Difference-based Implicit Solver for Phase-Field Equations with Spatially and Temporally Varying Parameters",
        "authors": [
            "Zirui Mao",
            "G. R. Liu",
            "Michael J. Demkowicz"
        ],
        "subjects": [
            "Numerical Analysis",
            "Mathematical Physics"
        ],
        "abstract": "The phase field method is an effective tool for modeling microstructure evolution in materials. Many efficient implicit numerical solvers have been proposed for phase field simulations under uniform and time-invariant model parameters. We use Eyre's theorem to develop an unconditionally stable implicit solver for spatially non-uniform and time-varying model parameters. The accuracy, unconditional stability, and efficiency of the solver is validated against benchmarking examples. In its current form, the solver requires a uniform mesh and may only be applied to problems with periodic, Neumann, or mixed periodic and Neumann boundary conditions.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12147"
    },
    {
        "doc_id": 225,
        "title": "On the Effectiveness of Observations in the Mid-Infrared Wavelength Range on the 2.5-Meter Telescope of the Caucasus Mountain Observatory of Moscow State University with Commercial IR Cameras",
        "authors": [
            "S. G. Zheltoukhov",
            "A. M. Tatarnikov"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "The main factors that influence the success of observations in the infrared range (central wavelengths of the photometric bands at 3.75 and 4.8~$\u03bc$m) on the multipurpose optical telescope are considered. Estimates of the sky background brightness are obtained for the Caucasus Mountain Observatory (CMO) of Moscow State University: $1.3\\cdot10^6$~photons/(s pixel) in the 3.75~$\u03bc$m band and $3.4\\cdot10^6$~photons/(s pixel) in the 4.8~$\u03bc$m; and the instrumental background for the 2.5-m CMO telescope at $0^\\circ$C: $3.2\\cdot10^6$~photons/(s pixel) in the 3.75~$\u03bc$m band and $4.3\\cdot10^6$~photons/(s pixel) in the 4.8~$\u03bc$m band. It is shown that at this background signal level with the currently available commercial cameras in the $3-5$~$\u03bc$m spectral range, the telescope-camera coupling capabilities for observing faint objects will still be limited by the thermal background. For different observational conditions, estimates of the limiting magnitudes of objects available for observations in the 3.75 and 4.8~$\u03bc$m ranges are obtained. For average observation conditions (instrument temperature of $0^\\circ$C and stellar image size of 1 arcsec), the limit is $\\sim10.6^m$ and $\\sim8.4^m$, respectively.",
        "comments": "16 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12146"
    },
    {
        "doc_id": 226,
        "title": "Laser cooling of a fermionic molecule",
        "authors": [
            "Jinyu Dai",
            "Qi Sun",
            "Benjamin C. Riley",
            "Debayan Mitra",
            "Tanya Zelevinsky"
        ],
        "subjects": [
            "Atomic Physics",
            "Quantum Gases"
        ],
        "abstract": "Only bosonic molecular species have been directly laser cooled to date, primarily due to an abundance of bosonic isotopes in nature and to their simpler hyperfine structure. Fermionic molecules provide new opportunities for ultracold chemistry, quantum simulation, and precision measurements. Here we report direct laser cooling of a fermionic molecular isotopologue, calcium monodeuteride (CaD). With a nuclear spin I = 1, only 5 hyperfine states need to be addressed for rotational closure in optical cycling. These hyperfine states are unresolved for typical experimental linewidths. We present a method for efficiently producing alkaline-earth metal hydrides and deuterides. We demonstrate rotational closure and show magnetically assisted Sisyphus cooling in one dimension for a beam of CaD molecules. Our results indicate that the experimental complexity for laser cooling CaD is similar to that of calcium monohydride (CaH). Laser cooling of CaD is a promising first step for production of ultracold and trapped atomic deuterium.",
        "comments": "8 pages, 5 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12145"
    },
    {
        "doc_id": 227,
        "title": "The accuracy of ALMA estimates of young disk radii and masses. Predicted observations from numerical simulations",
        "authors": [
            "Ngo-Duy Tung",
            "Leonardo Testi",
            "Ugo Lebreuilly",
            "Patrick Hennebelle",
            "Ana\u00eblle Maury",
            "Ralf S. Klessen",
            "Luca Cacciapuoti",
            "Matthias Gonz\u00e1lez",
            "Giovanni Rosotti",
            "Sergio Molinari"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics",
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "Protoplanetary disks, which are the natural consequence of the gravitational collapse of the dense molecular cloud cores, host the formation of the planetary systems known today in our universe. Numerous efforts have been dedicated to investigate the properties of these disks in the more mature Class II stage, either by using numerical simulations of disk evolution from a limited range of initial conditions or by observations of their dust continuum and line emission from specific molecular tracers, and to compare the results from the two standpoints. Yet few studies have investigated the main limitations at work when measuring the embedded Class 0/I disk properties from observations, especially in a statistical fashion. In this study, we provide a first attempt to compare the accuracy of some critical disk parameters in Class 0/I systems, as derived on real ALMA observational data, with the corresponding physical parameters that modellers can directly define in numerical simulations. The approach we follow is to provide full post-processing of the numerical simulations and apply on the synthetic observations the same techniques used by observers to derive the physical parameters. To that end, we performed 3D Monte Carlo radiative transfer and mock interferometric observations of the disk populations formed in an MHD simulation model of disk formation through the collapse of massive clumps with the tools RADMC-3D and CASA, respectively, to obtain their synthetic observations. With these observations, we re-employ the techniques commonly used in disk modelling from their continuum emissions to infer their properties that one would likely obtain if one observed them with real interferometers. We then demonstrate how their properties vary from the gas kinematics analyses to the dust continuum modelling.",
        "comments": "Accepted for publication in Astronomy & Astrophysics, 32 pages, 28 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12142"
    },
    {
        "doc_id": 228,
        "title": "Construction of a next-to-next-to-next-to-leading order approximation for heavy flavour production in deep inelastic scattering with quark masses",
        "authors": [
            "Niccol\u00f2 Laurenti"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The subject of this thesis is the construction of an approximation for the next-to-next-to-next-to leading order (N^3LO) deep inelastic scattering (DIS) massive coefficient function of the gluon for F2 in heavy quark pair production. Indeed, this object is one of the ingredients needed for the construction of any variable flavour number (factorization) scheme at O(alphas^3). The construction of such scheme is crucial for the improvement of the accuracy of the extraction of the parton distribution functions from the experimental data, that in turn will provide an improvement of the accuracy of all the theoretical predictions in high energy physics.\n  Despite the function we are interested in is not known exactly, its expansion in some kinematic limits is available. In particular the high-scale limit (Q^2 >> m^2), high-energy limit (z->0, where z is the argument of the coefficient function) and threshold limit (z->zmax=1/(1+4m^2/Q^2)) of the exact coefficient function are all known, with the exception of some terms that we will provide in approximate form. Therefore, combining these limits in a proper way, we will construct an approximation for the unknown term of the N^3LO gluon coefficient function, that describes the exact curve in the whole range of z.\n  Since other approximations for the N^3LO gluon coefficient functions are present in the literature, we will conclude by comparing our final approximate coefficient functions with such approximations. We will show a comparison both for the NNLO, whose exact function is known, and for the N^3LO. With our approach, we expect our results to be more accurate than previous approximations, thus providing a sufficient precision for a complete description of DIS at N^3LO and the consequent determination of N^3LO PDFs.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12139"
    },
    {
        "doc_id": 229,
        "title": "Gradient Preserving Operator Inference: Data-Driven Reduced-Order Models for Equations with Gradient Structure",
        "authors": [
            "Yuwei Geng",
            "Jasdeep Singh",
            "Lili Ju",
            "Boris Kramer",
            "Zhu Wang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Hamiltonian Operator Inference has been introduced in [Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn structure-preserving reduced-order models (ROMs) for Hamiltonian systems. This approach constructs a low-dimensional model using only data and knowledge of the Hamiltonian function. Such ROMs can keep the intrinsic structure of the system, allowing them to capture the physics described by the governing equations. In this work, we extend this approach to more general systems that are either conservative or dissipative in energy, and which possess a gradient structure. We derive the optimization problems for inferring structure-preserving ROMs that preserve the gradient structure. We further derive an {\\em a priori} error estimate for the reduced-order approximation. To test the algorithms, we consider semi-discretized partial differential equations with gradient structure, such as the parameterized wave and Korteweg-de-Vries equations in the conservative case and the one- and two-dimensional Allen-Cahn equations in the dissipative case. The numerical results illustrate the accuracy, structure-preservation properties, and predictive capabilities of the gradient-preserving Operator Inference ROMs.",
        "comments": "30 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12138"
    },
    {
        "doc_id": 230,
        "title": "Spin Wave Threshold Gate",
        "authors": [
            "Arne Van Zegbroeck",
            "Pantazis Anagnostou",
            "Said Hamdioui",
            "Christop Adelmann",
            "Florin Ciubotaru",
            "Sorin Cotofana"
        ],
        "subjects": [
            "Emerging Technologies"
        ],
        "abstract": "While Spin Waves (SW) interaction provides natural support for low power Majority (MAJ) gate implementations many hurdles still exists on the road towards the realization of practically relevant SW circuits. In this paper we leave the SW interaction avenue and propose Threshold Logic (TL) inspired SW computing, which relies on successive phase rotations applied to one single SW instead of on the interference of an odd number of SWs. After providing a short TL inside we introduce the SW TL gate concept and discuss the way to mirror TL gate weight and threshold values into physical phase-shifter parameters. Subsequently, we design and demonstrate proper operation of a SW TL based Full Adder (FA) by means of micro-magnetic simulations. We conclude the paper by providing inside on the potential advantages of our proposal by means of a conceptual comparison of MAJ and TL based FA implementations.",
        "comments": "This work has received funding from the Horizon Europe research and innovation program within the project \"Spider\" (grant agreement no. 101070417)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12136"
    },
    {
        "doc_id": 231,
        "title": "Accelerating Continuous Variable Coherent Ising Machines via Momentum",
        "authors": [
            "Robin Brown",
            "Davide Venturelli",
            "Marco Pavone",
            "David E. Bernal Neira"
        ],
        "subjects": [
            "Optimization and Control",
            "Emerging Technologies",
            "Quantum Physics"
        ],
        "abstract": "The Coherent Ising Machine (CIM) is a non-conventional architecture that takes inspiration from physical annealing processes to solve Ising problems heuristically. Its dynamics are naturally continuous and described by a set of ordinary differential equations that have been proven to be useful for the optimization of continuous variables non-convex quadratic optimization problems. The dynamics of such Continuous Variable CIMs (CV-CIM) encourage optimization via optical pulses whose amplitudes are determined by the negative gradient of the objective; however, standard gradient descent is known to be trapped by local minima and hampered by poor problem conditioning. In this work, we propose to modify the CV-CIM dynamics using more sophisticated pulse injections based on tried-and-true optimization techniques such as momentum and Adam. Through numerical experiments, we show that the momentum and Adam updates can significantly speed up the CV-CIM's convergence and improve sample diversity over the original CV-CIM dynamics. We also find that the Adam-CV-CIM's performance is more stable as a function of feedback strength, especially on poorly conditioned instances, resulting in an algorithm that is more robust, reliable, and easily tunable. More broadly, we identify the CIM dynamical framework as a fertile opportunity for exploring the intersection of classical optimization and modern analog computing.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12135"
    },
    {
        "doc_id": 232,
        "title": "The Early Universe as an Open Quantum System: Complexity and Decoherence",
        "authors": [
            "Arpan Bhattacharyya",
            "Suddhasattwa Brahma",
            "S. Shajidul Haque",
            "Jacob S. Lund",
            "Arpon Paul"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "General Relativity and Quantum Cosmology",
            "Quantum Physics"
        ],
        "abstract": "In this work, we extend previous results, demonstrating how complexity in an open quantum system can identify decoherence between two fields, even in the presence of an accelerating background. Using the curved-space Caldeira-Leggett two-field model in de Sitter as our toy model, we discover a distinctive feature in the growth of complexity of purification, providing an alternative diagnostic for studying decoherence when the adiabatic perturbation is coupled to a heavy field. This paper initiates a new pathway to explore the features of quantum complexity in an accelerating background, thereby expanding our understanding of the evolution of primordial cosmological perturbations in the early universe.",
        "comments": "24 pages, 8 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12134"
    },
    {
        "doc_id": 233,
        "title": "Time-Resolved Imaging Reveals Transiently Chaotic Spin-Orbit-Torque-Driven Dynamics Under Controlled Conditions",
        "authors": [
            "Lisa-Marie Kern",
            "Kai Litzius",
            "Victor Deinhart",
            "Michael Schneider",
            "Christopher Klose",
            "Kathinka Gerlinger",
            "Riccardo Battistelli",
            "Dieter Engel",
            "Christian M. G\u00fcnther",
            "Meng-Jie Huang",
            "Katja H\u00f6flich",
            "Felix B\u00fcttner",
            "Stefan Eisebitt",
            "Bastian Pfau"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Materials Science"
        ],
        "abstract": "Spin-orbit torques (SOTs) act as efficient drivers for nanoscale magnetic systems, such as in magnetic tunnel junctions, nano-oscillators and racetrack geometries. In particular, in combination with materials exhibiting high Dzyaloshinskii--Moriya interaction, SOTs are considered to result in well-controlled deterministic magnetisation dynamics and are, therefore, used as robust drives to move and create magnetic skyrmions. In contrast to these expectations, we here find unpredictable, transiently chaotic dynamics induced by SOT at an artificial anisotropy-engineered defect in a magnetic racetrack. Based on these controlled conditions, we directly observe the nanoscale dynamics with holography-based, time-resolved x-ray imaging. In concert with micromagnetic simulations, we disclose a regime of violent picosecond fluctuations, including topological instabilities that, remarkably, result in deterministic final configurations. In addition, our images expose previously unseen skyrmion shedding and highlight the potential of transiently chaotic pathways for topological switching. Our approach offers new perspectives for the investigation and application of highly non-linear SOT dynamics in spintronics materials.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12130"
    },
    {
        "doc_id": 234,
        "title": "Machine-learning structural reconstructions for accelerated point defect calculations",
        "authors": [
            "Irea Mosquera-Lois",
            "Se\u00e1n R. Kavanagh",
            "Alex M. Ganose",
            "Aron Walsh"
        ],
        "subjects": [
            "Materials Science",
            "Chemical Physics"
        ],
        "abstract": "Defects dictate the properties of many functional materials. To understand the behaviour of defects and their impact on physical properties, it is necessary to identify the most stable defect geometries. However, global structure searching is computationally challenging for high-throughput defect studies or materials with complex defect landscapes, like alloys or disordered solids. Here, we tackle this limitation by harnessing a machine-learning surrogate model to qualitatively explore the defect structural landscape. By learning defect motifs in a family of related metal chalcogenide and mixed anion crystals, the model successfully predicts favourable reconstructions for unseen defects in unseen compositions for 90% of cases, thereby reducing the number of first-principles calculations by 73%. Using CdSe$_x$Te$_{1-x}$ alloys as an exemplar, we train a model on the end member compositions and apply it to find the stable geometries of all inequivalent vacancies for a range of mixing concentrations, thus enabling more accurate and faster defect studies for configurational complex systems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12127"
    },
    {
        "doc_id": 235,
        "title": "Hybrid resonant metasurfaces with configurable structural colors",
        "authors": [
            "Jelena Wohlwend",
            "Anna Hilti",
            "Claudiadele Polinari",
            "Ralph Spolenak",
            "Henning Galinski"
        ],
        "subjects": [
            "Optics",
            "Applied Physics"
        ],
        "abstract": "Metasurfaces play a key role in functionalizing light at the nanoscale. Existing dielectric metasurfaces, however, are often limited to geometric primitives and their usage in emergent hybrid metasurfaces is hampered as confinement of light occurs only in their interior. Taking inspiration from biophotonic systems in nature, we introduce a new class of hybrid metasurfaces, which combine ordered and disordered elements. While the ordered phase relies on non-reciprocal meta-atoms - whose breaking of the out-of-plane symmetry enables the confinement of visible light in air, the disordered phase exploits global plasmonic network modes and their ability to localize energy at nanometric scales. By generating configurable structural colors with extra-ordinary resolution, we demonstrate that coupling of these elements provides a new dimension in the design space. We showcase that control of the local light-matter interaction enables the creation of intricate, customizable optical patterns, which open new avenues for information encoding and high-security features.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12123"
    },
    {
        "doc_id": 236,
        "title": "Temperature as Joules per Bit",
        "authors": [
            "Charles Alexandre B\u00e9dard",
            "Sophie Berthelette",
            "Xavier Coiteux-Roy",
            "Stefan Wolf"
        ],
        "subjects": [
            "Quantum Physics",
            "Statistical Mechanics",
            "Classical Physics"
        ],
        "abstract": "Boltzmann's constant reflects a historical misunderstanding of the concept of entropy, whose informational nature is obfuscated when expressed in J/K. We suggest that the development of temperature and energy, historically prior to that of entropy, does not amount to their logical priority: Temperature should be defined in terms of entropy, not vice versa. Following the precepts of information theory, entropy is measured in bits, and coincides with information capacity at thermodynamic equilibrium. Consequently, not only is the temperature of an equilibrated system expressed in J/bit, but it acquires an operational meaning: It is the cost in energy to increase its information capacity by 1 bit. Our proposal also supports the notion of available capacity, analogous to free energy. Finally, it simplifies Landauer's cost and clarifies that it is a cost of displacement, not of erasure.",
        "comments": "12 pages, 2 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12119"
    },
    {
        "doc_id": 237,
        "title": "Dynamic control of active droplets using light-responsive chiral liquid crystal environment",
        "authors": [
            "Vanessa Jir\u00f3n",
            "Mojtaba Rajabi",
            "Hao Wang",
            "Oleg D. Lavrentovich"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics"
        ],
        "abstract": "Microscopic active droplets are of interest since they can be used to transport matter from one point to another. The challenge is to control the trajectory. In this work, we demonstrate an approach to control the direction of active droplet propulsion by a photoresponsive cholesteric liquid crystal environment. The active droplet represents a water dispersion of bacterial B. subtilis microswimmers. When placed in a cholesteric, a surfactant-stabilized active droplet distorts the local director field, producing a point defect-hedgehog, which breaks the fore-aft symmetry. The chaotic motion of the bacteria inside the droplet is rectified into directional motion by the asymmetric director field outside the droplet. When the pitch of the cholesteric is altered by visible light irradiation, the asymmetry axis and thus the droplet trajectory realign along a new direction. Droplets realign counterclockwise on exposure to light of 535 nm, and clockwise on exposure to light of 450 nm, as dictated by the photoinduced change in the handedness of the cholesteric. The strategy allows for a non-contact dynamic control of active droplets trajectories and demonstrates the advantage of orientationally ordered media in control of active matter over their isotropic counterparts.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12116"
    },
    {
        "doc_id": 238,
        "title": "Weak second-order quantum state diffusion unraveling of the Lindblad master equation",
        "authors": [
            "Sayak Adhikari",
            "Roi Baer"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Abstract Simulating mixed-state evolution in open quantum systems is crucial for various chemical physics, quantum optics, and computer science applications. These simulations typically follow the Lindblad master equation dynamics. An alternative approach known as quantum state diffusion unraveling is based on the trajectories of pure states generated by random wave functions, which evolve according to a nonlinear It\u00f4-Schr\u00f6dinger equation (ISE). This study introduces weak first- and second-order solvers for the ISE based on directly applying the It\u00f4-Taylor expansion with exact derivatives in the interaction picture. We tested the method on free and driven Morse oscillators coupled to a thermal environment and found that both orders allowed practical estimation with a few dozen iterations. The variance was relatively small compared to the linear unraveling and did not grow with time. The second-order solver delivers much higher accuracy and stability with bigger time steps than the first-order scheme, with a small additional workload. However, the second-order algorithm has quadratic complexity with the number of Lindblad operators as opposed to the linear complexity of the first-order algorithm.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12109"
    },
    {
        "doc_id": 239,
        "title": "Geometric Phase of a Transmon in a Dissipative Quantum Circuit",
        "authors": [
            "Ludmila Viotti",
            "Fernando C. Lombardo",
            "Paula I. Villar"
        ],
        "subjects": [
            "Quantum Physics",
            "Superconductivity"
        ],
        "abstract": "Superconducting circuits reveal themselves as promising physical devices with multiple uses. Within those uses, the fundamental concept of the geometric phase accumulated by the state of a system shows up recurrently, as, for example, in the construction of geometric gates. Given this framework, we study the geometric phases acquired by a paradigmatic setup: a transmon coupled to a superconductor resonating cavity. We do so both for the case in which the evolution is unitary and when it is subjected to dissipative effects. These models offer a comprehensive quantum description of an anharmonic system interacting with a single mode of the electromagnetic field within a perfect or dissipative cavity, respectively. In the dissipative model, the non-unitary effects arise from dephasing, relaxation, and decay of the transmon coupled to its environment. Our approach enables a comparison of the geometric phases obtained in these models, leading to a thorough understanding of the corrections introduced by the presence of the environment.",
        "comments": "12 pages, 11 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12106"
    },
    {
        "doc_id": 240,
        "title": "Magic Can Enhance the Quantum Capacity of Channels",
        "authors": [
            "Kaifeng Bu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics"
        ],
        "abstract": "We investigate the role of magic in the quantum capacity of channels. We consider the quantum channel of the recently proposed discrete beam splitter with the fixed environment state. We find that if the fixed environment state is a stabilizer state, then the quantum capacity is zero. Moreover, we find that the quantum capacity is nonzero for some magic states, and the quantum capacity increases linearly with respect to the number of single-qudit magic states in the environment. These results suggest that magic can increase the quantum capacity of channels, which sheds new insight into the role of stabilizer and magic states in quantum communication.",
        "comments": "5+6 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12105"
    },
    {
        "doc_id": 241,
        "title": "Ground and Excited States from Ensemble Variational Principles",
        "authors": [
            "Lexin Ding",
            "Cheng-Lin Hong",
            "Christian Schilling"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics",
            "Chemical Physics"
        ],
        "abstract": "The extension of the Rayleigh-Ritz variational principle to ensemble states $\u03c1_{\\mathbf{w}}\\equiv\\sum_k w_k |\u03a8_k\\rangle \\langle\u03a8_k|$ with fixed weights $w_k$ lies ultimately at the heart of several recent methodological developments for targeting excitation energies by variational means. Prominent examples are density and density matrix functional theory, Monte Carlo sampling, state-average complete active space self-consistent field methods and variational quantum eigensolvers. In order to provide a sound basis for all these methods and to improve their current implementations, we prove the validity of the underlying critical hypothesis: Whenever the ensemble energy is well-converged, the same holds true for the ensemble state $\u03c1_{\\mathbf{w}}$ as well as the individual eigenstates $|\u03a8_k\\rangle$ and eigenenergies $E_k$. To be more specific, we derive linear bounds $d_-\u0394{E}_{\\mathbf{w}} \\leq \u0394Q \\leq d_+ \u0394\u0394{E}_{\\mathbf{w}}$ on the errors $\u0394Q $ of these sought-after quantities. A subsequent analytical analysis and numerical illustration proves the tightness of our universal inequalities. Our results and particularly the explicit form of $d_{\\pm}\\equiv d_{\\pm}^{(Q)}(\\mathbf{w},\\mathbf{E})$ provide valuable insights into the optimal choice of the auxiliary weights $w_k$ in practical applications.",
        "comments": "22 pages, 9 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12104"
    },
    {
        "doc_id": 242,
        "title": "Shear Layers and Plugs in the Capillary Flow of Wormlike Micellar Gels",
        "authors": [
            "Ronak Gupta",
            "Masoud Daneshi",
            "Ian Frigaard",
            "Gwynn Elfring"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Fluid Dynamics"
        ],
        "abstract": "Wormlike micellar solutions formed by long-chained zwitterionic surfactants show gel-like rheology at room temperature and have recently been found to exhibit other complex and interesting rheological features. We study the dynamics of these wormlike micellar gels in a pipe-flow scenario using optical coherence tomography-based velocimetry and report the existence of plug flows with strong wall slip and non-parabolic velocity profiles for different surfactant concentrations and imposed flow rates. We rationalize these results as features of a developing transient flow of a viscoelastic solution in space and time and show that these shear layers indicate a flow induced heterogeneity. Our experiments shed light on the transient fluid dynamics of wormlike micelles in simple geometries and highlight the complexity of flows involving wormlike micellar gels and similar soft matter systems in canonical flows.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12102"
    },
    {
        "doc_id": 243,
        "title": "Effective Abelian Lattice Gauge Field Theories for scalar-matter-monopole interactions",
        "authors": [
            "K. Farakos",
            "G. Koutsoumbas",
            "Nick E. Mavromatos"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We present a gauge and Lorentz invariant effective field theory model for the interaction of a charged scalar matter field with a magnetic monopole source, described by an external magnetic current. The quantum fluctuations of the monopole field are described effectively by a strongly-coupled ``dual'' $U_{\\rm d}(1)$ gauge field, which is independent of the electromagnetic $U_{\\rm em}(1)$ gauge field. The effective interactions of the charged matter with the monopole source are described by a gauge invariant mixed Chern-Simons-like (Pontryagin-density) term between the two $U(1)$ gauge fields. The latter interaction coupling is left free, and a Lattice study of the system is performed with the aim of determining the phase structure of this effective theory. Our study shows that, in the spontaneously-broken-symmetry phase, the monopole source triggers, via the mixed Chern-Simons term, which is non-trivial in its presence, the generation of a dynamical singular configuration (magnetic-monopole-like) for the respective gauge fields. The scalar field also behaves in the broken phase in a way similar to that of the scalar sector of the `t Hooft-Polyakov monopole.",
        "comments": "23 pages revtex, several pdf figures incorporated",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12101"
    },
    {
        "doc_id": 244,
        "title": "The inverse problem for a class of implicit differential equations and the coisotropic embedding theorem",
        "authors": [
            "Luca Schiavone"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics",
            "Differential Geometry"
        ],
        "abstract": "We carry on the approach used in [Sch] to provide a solution for the inverse problem of the calculus of variations for Maxwell equations in vacuum and we provide an abstract theory including all implicit differential equations that can be formulated in terms of vector fields over pre-symplectic manifolds.",
        "comments": "MSC Class:          53Dxx; 53Zxx; 49Sxx",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12096"
    },
    {
        "doc_id": 245,
        "title": "Discrete symmetries tested at 10$^{-4}$ precision using linear polarization of photons from positronium annihilations",
        "authors": [
            "Pawe\u0142 Moskal",
            "Eryk Czerwi\u0144ski",
            "Juhi Raj",
            "Steven D. Bass",
            "Ermias Y. Beyene",
            "Neha Chug",
            "Aur\u00e9lien Coussat",
            "Catalina Curceanu",
            "Meysam Dadgar",
            "Manish Das",
            "Kamil Dulski",
            "Aleksander Gajos",
            "Marek Gorgol",
            "Beatrix C. Hiesmayr",
            "Bo\u017cena Jasi\u0144ska",
            "Krzysztof Kacprzak",
            "Tevfik Kaplanoglu",
            "\u0141ukasz Kap\u0142on",
            "Konrad Klimaszewski",
            "Pawe\u0142 Konieczka",
            "Grzegorz Korcyl",
            "Tomasz Kozik",
            "Wojciech Krzemie\u0144",
            "Deepak Kumar",
            "Simbarashe Moyo",
            "et al. (16 additional authors not shown)"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Experiment"
        ],
        "abstract": "Discrete symmetries play an important role in particle physics with violation of CP connected to the matter-antimatter imbalance in the Universe. We report the most precise test of P, T and CP invariance in decays of ortho-positronium, performed with methodology involving polarization of photons from these decays. Positronium, the simplest bound state of an electron and positron, is of recent interest with discrepancies reported between measured hyperfine energy structure and theory at the level of $10^{-4}$ signaling a need for better understanding of the positronium system at this level. We test discrete symmetries using photon polarizations determined via Compton scattering in the dedicated J-PET tomograph on an event-by-event basis and without the need to control the spin of the positronium with an external magnetic field, in contrast to previous experiments. Our result is consistent with QED expectations at the level of 0.0007 and one standard deviation.",
        "comments": "17 pages, 10 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12092"
    },
    {
        "doc_id": 246,
        "title": "Quantum Eigensolver for General Matrices",
        "authors": [
            "Xiao-Ming Zhang",
            "Yukun Zhang",
            "Wenhao He",
            "Xiao Yuan"
        ],
        "subjects": [
            "Quantum Physics",
            "Mesoscale and Nanoscale Physics",
            "Data Structures and Algorithms",
            "Numerical Analysis",
            "Computational Physics"
        ],
        "abstract": "The eigenvalue problem, a cornerstone in linear algebra, provides profound insights into studying matrix properties. Quantum algorithms addressing this problem have hitherto been constrained to special normal matrices assuming spectral decomposition, leaving the extension to general matrices an open challenge. In this work, we present a novel family of quantum algorithms tailored for solving the eigenvalue problem for general matrices, encompassing scenarios with complex eigenvalues or even defective matrices. Our approach begins by tackling the task of searching for an eigenvalue without additional constraints. For diagonalizable matrices, our algorithm has $\\tilde O(\\varepsilon^{-1})$ complexity with an error $\\varepsilon$, achieving the nearly Heisenberg scaling. Subsequently, we study the identification of eigenvalues closest to a specified point or line, extending the results for ground energy and energy gap problems in Hermitian matrices. We achieve an accuracy scaling of $\\tilde O(\\varepsilon^{-2})$ for general diagonalizable matrices, further refining to $\\tilde O(\\varepsilon^{-1})$ under the condition of real eigenvalues or constant distance from the reference point. The algorithm's foundation lies in the synergy of three techniques: the relationship between eigenvalues of matrix $A$ and the minimum singular value of $A-\u03bcI$, quantum singular value threshold subroutine extended from quantum singular-value estimation, and problem-specific searching algorithms. Our algorithms find applications in diverse domains, including estimating the relaxation time of Markov chains, solving Liouvillian gaps in open quantum systems, and verifying PT-symmetry broken/unbroken phases. These applications underscore the significance of our quantum eigensolvers for problems across various disciplines.",
        "comments": "6+10 pages, 1+1 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12091"
    },
    {
        "doc_id": 247,
        "title": "Trainability of a quantum-classical machine in the NISQ era",
        "authors": [
            "Tarun Dutta",
            "Alex Jin",
            "Clarence Liu Huihong",
            "J I Latorre",
            "Manas Mukherjee"
        ],
        "subjects": [
            "Quantum Physics",
            "Applied Physics",
            "Atomic Physics"
        ],
        "abstract": "Advancements in classical computing have significantly enhanced machine learning applications, yet inherent limitations persist in terms of energy, resource and speed. Quantum machine learning algorithms offer a promising avenue to overcome these limitations but bring along their own challenges. This experimental study explores the limits of trainability of a real experimental quantum classical hybrid system implementing supervised training protocols, in an ion trap platform. Challenges associated with ion trap-coupled classical processor are addressed, highlighting the robustness of the genetic algorithm as a classical optimizer in navigating complex optimization landscape inherent in binary classification problems with many local minima. Experimental results, focused on a binary classification problem, reveal the superior efficiency and accuracy of the genetic algorithm compared to gradient-based optimizers. We intricately discuss why gradient-based optimizers may not be suitable in the NISQ era through thorough analysis. These findings contribute insights into the performance of quantum-classical hybrid systems, emphasizing the significance of efficient training strategies and hardware considerations for practical quantum machine learning applications. This work not only advances the understanding of hybrid quantum-classical systems but also underscores the potential impact on real-world challenges through the convergence of quantum and classical computing paradigms operating without the aid of classical simulators.",
        "comments": "30 pages, 21 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12089"
    },
    {
        "doc_id": 248,
        "title": "Atomistic calculation of the f0 attempt frequency in Fe3O4 magnetite nanoparticles",
        "authors": [
            "Roberto Moreno",
            "Sarah Jenkins",
            "Wyn Williams",
            "Richard F. L. Evans"
        ],
        "subjects": [
            "Materials Science"
        ],
        "abstract": "The Arrhenius law predicts the transition time between equilibrium states in physical systems due to thermal activation, with broad applications in material science, magnetic hyperthermia and paleomagnetism where it is used to estimate the transition time and thermal stability of assemblies of magnetic nanoparticles. Magnetite is a material of great importance in paleomagnetic studies and magnetic hyperthermia but existing estimates of the attempt frequency $f_0$ vary by several orders of magnitude in the range $10^7-10^{13}$ Hz, leading to significant uncertainty in their relaxation rate. Here we present a dynamical method enabling full parameterization of the Arrhenius-N\u00e9el law using atomistic spin dynamics. We determine the temperature and volume dependence of the attempt frequency of magnetite nanoparticles with cubic anisotropy and find a value of $f_0 = 0.562 \\pm 0.059$ GHz at room temperature. For particles with enhanced anisotropy we find a significant increase in the attempt frequency and a strong temperature dependence suggesting an important role of anisotropy. The method is applicable to a wide range of dynamical systems where different states can be clearly identified and enables robust estimates of domain state stabilities, with particular importance in the rapidly developing field of micromagnetic analysis of paleomagnetic recordings where samples can be numerically reconstructed to provide a better understanding of geomagnetic recording fidelity over geological time scales.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12080"
    },
    {
        "doc_id": 249,
        "title": "Backward wave optical parametric oscillation in a waveguide",
        "authors": [
            "Patrick Mutter",
            "Fredrik Laurell",
            "Valdas Pasiskevicius",
            "Andrius Zukauskas"
        ],
        "subjects": [
            "Optics",
            "Quantum Physics"
        ],
        "abstract": "A backward wave optical parametric oscillator (BWOPO) waveguide in periodically poled Rb-doped KTP is presented. The waveguide exhibits low loss (0.16 dB/cm) and has an oscillation threshold, almost 20 times lower than the corresponding bulk device. The backward wave has a narrow linewidth of 21 GHz at 1514.6 nm while the forward wave at 1688.7 nm has a spectrum replicating the pump. The unique spectral features of the BWOPO will unlock novel opportunities in low-power nonlinear integrated optics. A conversion efficiency of 8.4% was obtained limited by the emergence of backward stimulated polariton scattering.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12063"
    },
    {
        "doc_id": 250,
        "title": "Scalable Automated Verification for Cyber-Physical Systems in Isabelle/HOL",
        "authors": [
            "Jonathan Juli\u00e1n Huerta y Munive",
            "Simon Foster",
            "Mario Gleirscher",
            "Georg Struth",
            "Christian Pardillo Laursen",
            "Thomas Hickman"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Mathematical Software"
        ],
        "abstract": "We formally introduce IsaVODEs (Isabelle verification with Ordinary Differential Equations), a framework for the verification of cyber-physical systems. We describe the semantic foundations of the framework's formalisation in the Isabelle/HOL proof assistant. A user-friendly language specification based on a robust state model makes our framework flexible and adaptable to various engineering workflows. New additions to the framework increase both its expressivity and proof automation. Specifically, formalisations related to forward diamond correctness specifications, certification of unique solutions to ordinary differential equations (ODEs) as flows, and invariant reasoning for systems of ODEs contribute to the framework's scalability and usability. Various examples and an evaluation validate the effectiveness of our framework.",
        "comments": "Submitted to the Journal of Automated Reasoning",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12061"
    },
    {
        "doc_id": 251,
        "title": "The BSCE ASMR: an Advanced Subcritical Micro Reactor -- Development and Demonstration program with Neutonics Studies",
        "authors": [
            "A. Rummana",
            "R. Barlow",
            "G. Myneni",
            "S. M. Saad"
        ],
        "subjects": [
            "Accelerator Physics"
        ],
        "abstract": "We present a design for a small subcritical molten salt thorium breeder reactor driven by an electron accelerator. Such a reactor could provide a safe and simple power source fuelled by thorium, without generating long-lived minor actinides. We use both Geant4 and MCNPX simulations to study the production of photons and photoneutrons, the criticality and the breeding in a simple conceptual design. We show that the concept is on the edge of viability.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12056"
    },
    {
        "doc_id": 252,
        "title": "Twisting asymptotic symmetries and algebraically special vacuum solutions",
        "authors": [
            "Pujian Mao",
            "Weicheng Zhao"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Theory"
        ],
        "abstract": "In this paper, we study asymptotic symmetries and algebraically special exact solutions in the Newman-Penrose formalism. Removing the hypersurface orthogonal condition in the well studied Newman-Unti gauge, we obtain a generic asymptotic solution space which includes all possible origins of propagating degree of freedom. The asymptotic symmetry of the generalized system extends the Weyl-BMS symmetry by two independent local Lorentz transformations with non-trivial boundary charges, which reveals new boundary degrees of freedom. The generalized Newman-Unti gauge includes algebraically special condition in its most convenient form. Remarkably, the generic solutions satisfying the algebraically special condition truncate in the inverse power of radial expansions and the non-radial Newman-Penrose equations are explicitly solved at any order. Hence, we provide the most general algebraically special solution space and the derivation is self-contained in the Newman-Penrose formalism. The asymptotic symmetry with respect to the algebraically special condition is the standard Weyl-BMS symmetry and the symmetry parameters consist only the integration constant order. We present the Kerr solution and Taub-NUT solution in the generalized Newman-Unti gauge in a simple form.",
        "comments": "21 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12054"
    },
    {
        "doc_id": 253,
        "title": "From Trust to Disagreement: disentangling the interplay of Misinformation and Polarisation in the News Ecosystem",
        "authors": [
            "Donald Ruggiero Lo Sardo",
            "Emanuele Brugnoli",
            "Pietro Gravino",
            "Vittorio Loreto"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "The increasing pervasiveness of fruitless disagreement poses a considerable risk to social cohesion and constructive public discourse. While polarised discussions can exhibit significant distrust in the news, it is still largely unclear whether disagreement is somehow linked to misinformation. In this work, we exploit the results of `Cartesio', an online experiment to rate the trustworthiness of Italian news articles annotated for reliability by expert evaluators. We developed a metric for disagreement that allows for correct comparisons between news with different mean trust values. Our findings indicate that, though misinformation receives lower trust ratings than accurate information, it does not appear to be more controversial. Additionally, we examined the relationship between these findings and Facebook user engagement with news articles. Our results show that disagreement correlates with an increased likelihood of commenting, probably linked to inconclusive and long discussions. The emerging scenario is one in which fighting disinformation seems ineffective in countering polarisation. Disagreement focuses more on the divergence of opinions, trust, and their effects on social cohesion. This study offers a foundation for unsupervised news item analysis independent of expert annotation. Incorporating similar principles into the design of news distribution platforms and social media systems can enhance online interactions and foster the development of a less divisive news ecosystem.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12053"
    },
    {
        "doc_id": 254,
        "title": "Fast degree-preserving rewiring of complex networks",
        "authors": [
            "Shane Mannion",
            "Padraig MacCarron",
            "Akrati Saxena",
            "Frank W. Takes"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "In this paper we introduce a new fast degree-preserving network rewiring algorithm. Commonly used existing algorithms require a large number of iterations, in particular in the case of large dense networks. This can especially be problematic when we wish to study ensembles of networks. In this paper we focus on degree assortative rewiring, and overcome aforementioned scalability problems by performing a rewiring of all edges at once to achieve a very high assorativity value before rewiring samples of edges at once to reduce this high assortativity value to the target value. The proposed method performs better than existing methods by several orders of magnitude for a range of structurally diverse complex networks, both in terms of the number of iterations taken, and time taken to reach a given assortativity value. Here we test networks up to $\\approx 4,000$ nodes and $\\approx 88,000$ edges and find that the relative improvements in speed remain.",
        "comments": "13 pages, 14 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12047"
    },
    {
        "doc_id": 255,
        "title": "Toward QCD on Quantum Computer: Orbifold Lattice Approach",
        "authors": [
            "Georg Bergner",
            "Masanori Hanada",
            "Enrico Rinaldi",
            "Andreas Schafer"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology",
            "Nuclear Theory",
            "Quantum Physics"
        ],
        "abstract": "We propose an orbifold lattice formulation of QCD suitable for quantum simulations. The advantages come from the use of noncompact variables that makes qubitization and truncated Hamiltonian very simple. It is shown that SU(3) gauge group and quarks in fundamental representation can be implemented straightforwardly.",
        "comments": "24 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12045"
    },
    {
        "doc_id": 256,
        "title": "Machine Learning Based Prediction of Polaron-Vacancy Patterns on the TiO$_2$(110) Surface",
        "authors": [
            "Viktor C. Birschitzky",
            "Igor Sokolovic",
            "Michael Prezzi",
            "Krisztian Palotas",
            "Martin Setvin",
            "Ulrike Diebold",
            "Michele Reticcioli",
            "Cesare Franchini"
        ],
        "subjects": [
            "Materials Science"
        ],
        "abstract": "The multifaceted physics of oxides is shaped by their composition and the presence of defects, which are often accompanied by the formation of polarons. The simultaneous presence of polarons and defects, and their complex interactions, pose challenges for first-principles simulations and experimental techniques. In this study, we leverage machine learning and a first-principles database to analyze the distribution of surface oxygen vacancies (V$_{\\rm O}$) and induced small polarons on rutile TiO$_2$(110), effectively disentangling the interactions between polarons and defects. By combining neural-network supervised learning and simulated annealing, we elucidate the inhomogeneous V$_{\\rm O}$ distribution observed in scanning probe microscopy (SPM). Our innovative approach allows us to understand and predict defective surface patterns at previously inaccessible length scales, identifying the specific role of individual types of defects. Specifically, surface-polaron-stabilizing V$_{\\rm O}$-configurations are identified, which could have consequences for surface reactivity.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12042"
    },
    {
        "doc_id": 257,
        "title": "Trade-off between Bagging and Boosting for quantum separability-entanglement classification",
        "authors": [
            "Sanuja D. Mohanty",
            "Ram N. Patro",
            "Pradyut K. Biswal",
            "Biswajit Pradhan",
            "Sk Sazim"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Certifying whether an arbitrary quantum system is entangled or not, is, in general, an NP-hard problem. Though various necessary and sufficient conditions have already been explored in this regard for lower dimensional systems, it is hard to extend them to higher dimensions. Recently, an ensemble bagging and convex hull approximation (CHA) approach (together, BCHA) was proposed and it strongly suggests employing a machine learning technique for the separability-entanglement classification problem. However, BCHA does only incorporate the balanced dataset for classification tasks which results in lower average accuracy. In order to solve the data imbalance problem in the present literature, an exploration of the Boosting technique has been carried out, and a trade-off between the Boosting and Bagging-based ensemble classifier is explored for quantum separability problems. For the two-qubit and two-qutrit quantum systems, the pros and cons of the proposed random under-sampling boost CHA (RUSBCHA) for the quantum separability problem are compared with the state-of-the-art CHA and BCHA approaches. As the data is highly unbalanced, performance measures such as overall accuracy, average accuracy, F-measure, and G-mean are evaluated for a fair comparison. The outcomes suggest that RUSBCHA is an alternative to the BCHA approach. Also, for several cases, performance improvements are observed for RUSBCHA since the data is imbalanced.",
        "comments": "Comments are welcome",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12041"
    },
    {
        "doc_id": 258,
        "title": "Unfolding environmental $\u03b3$ flux spectrum with portable CZT detector",
        "authors": [
            "Taiyuan Liu",
            "Mingxuan Xue",
            "Haiping Peng",
            "Kangkang Zhao",
            "Deyong Duan",
            "Yichao Wang",
            "Changqing Feng",
            "Yifeng Wei",
            "Zizong Xu",
            "Xiaolian Wang"
        ],
        "subjects": [
            "Instrumentation and Detectors",
            "High Energy Physics - Experiment"
        ],
        "abstract": "Environmental $\u03b3$-rays constitute a crucial source of background in various nuclear, particle and quantum physics experiments. To evaluate the flux rate and the spectrum of $\u03b3$ background, we have developed a novel and straightforward approach to reconstruct the environmental $\u03b3$ flux spectrum by applying a portable CZT $\u03b3$ detector and iterative Bayesian unfolding, which possesses excellent transferability for broader applications. In this paper, the calibration and GEANT4 Monte-Carlo modeling of the CZT detector, the unfolding procedure as well as the uncertainty estimation are demonstrated in detail. The reconstructed spectrum reveals an environmental $\u03b3$ flux intensity of $3.3\\pm 0.3\\times 10^{7}$ (m$^2\\cdot$sr$\\cdot$hour)$^{-1}$ ranging from 73 to 3033 keV, along with characteristic peaks primarily arising from $^{232}$Th series, $^{238}$U series and $^{40}$K. We also give an instance of background rate evaluation with the unfolded spectrum for validation of the approach.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12034"
    },
    {
        "doc_id": 259,
        "title": "Topological Nature of Radiation Asymmetry in Bilayer Metagratings",
        "authors": [
            "Ze-Peng Zhuang",
            "Hao-Long Zeng",
            "Xiao-Dong Chen",
            "Xin-Tao He",
            "Jian-Wen Dong"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Manipulating radiation asymmetry of photonic structures is of particular interest in many photonic applications such as directional optical antenna, high efficiency on-chip lasers, and coherent light control. Here, we proposed a term of pseudo-polarization to reveal topological nature of radiation asymmetry in bilayer metagratings. Robust pseudo-polarization vortex with an integer topological charge exists in P-symmetry metagrating, allowing for tunable directionality ranging from -1 to 1 in synthetic parameter space. When P-symmetry-breaking, such vortex becomes pairs of C points due to the conservation law of charge, leading to the phase difference of radiation asymmetry from \u03c0/2 to 3\u03c0/2. Furthermore, topologically enabled coherent perfect absorption is robust with customized phase difference at will between two counter-propagating external light sources. This work can not only enrich the understanding of two particular topological photonic behavriors, i.e., bound state in the continuum and unidirectional guided resonance, but also provide a topological view on radiation asymmetry, opening an unexplored avenue for asymmetric light manipulation in on-chip laser, light-light switch and quantum emitters.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12030"
    },
    {
        "doc_id": 260,
        "title": "Quantum Characteristics Near Event Horizons",
        "authors": [
            "A. Ali",
            "S. Al-Kuwari",
            "M. Ghominejad",
            "M. T. Rahim",
            "S. Haddadi"
        ],
        "subjects": [
            "Quantum Physics",
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "We investigate the genuine multipartite entanglement, global entanglement, and quantum coherence among different configurations of a penta-partite system involving particles inside and outside the event horizon of a Schwarzschild black hole. We consider and analyze different scenarios based on how many particles are accessible. In each scenario, we evaluate first-order coherence, concurrence fill, and global concurrence under varying Hawking temperature and Dirac particle mode frequency. For the fully accessible scenario with all particles outside the event horizon, the measures exhibit non-monotonic behavior with a discernible trade-off. In the partially accessible scenarios with one particle inside the event horizon, monotonic variations and clear trade-offs are observed. Finally, in the scenario when two particles are inside the event horizon, concurrence fill becomes complex, attributed to the violation of the entanglement polygon inequality in curved space-time. This result reveals intricate relationships between entanglement and coherence around the event horizon of Schwarzchild black holes. Our findings suggest reevaluating entanglement polygon inequalities and concurrence fill for applicability in flat and curved space-times. These insights contribute to our understanding of quantum information dynamics and gravitational impacts on entanglement in extreme environments.",
        "comments": "11 pages, 8 figures. All comments are welcome",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12028"
    },
    {
        "doc_id": 261,
        "title": "pH modulates friction memory effects in protein folding",
        "authors": [
            "Benjamin A. Dalton",
            "Roland R. Netz"
        ],
        "subjects": [
            "Biological Physics"
        ],
        "abstract": "We study the non-Markovian folding dynamics of the $\u03b1$3D protein under low- and neutral-pH conditions. Recently published all-atom simulations of $\u03b1$3D by the Shaw group reveal that lowering the pH significantly reduces both native and non-native salt-bridge interactions, which dominate the folding dynamics. Here, we demonstrate that this physiochemical modulation directly perturbs the folding friction, which we evaluate using non-Markovian memory-kernel-extraction techniques. In doing so, we find that the reduction in pH not only decreases the magnitude of the time-dependent friction acting on the protein but also more dramatically shortens the time scale of the friction memory effects. As a result, the folding dynamics in the low pH system are well described by a purely Markovian model. In the neutral pH system, however, the memory time scale is of the same order as the folding time and is accelerated by a factor of 6 compared to a Markovian model prediction. We demonstrate that this memory-induced barrier-crossing speed-up is predicted by non-Markovian reaction-kinetic theories, confirming that non-Markovian models are, in general, necessary for a quantitative description of protein folding dynamics.",
        "comments": "4 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12027"
    },
    {
        "doc_id": 262,
        "title": "Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training",
        "authors": [
            "Vedant Dave",
            "Fotios Lygerakis",
            "Elmar Rueckert"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The rapidly evolving field of robotics necessitates methods that can facilitate the fusion of multiple modalities. Specifically, when it comes to interacting with tangible objects, effectively combining visual and tactile sensory data is key to understanding and navigating the complex dynamics of the physical world, enabling a more nuanced and adaptable response to changing environments. Nevertheless, much of the earlier work in merging these two sensory modalities has relied on supervised methods utilizing datasets labeled by humans.This paper introduces MViTac, a novel methodology that leverages contrastive learning to integrate vision and touch sensations in a self-supervised fashion. By availing both sensory inputs, MViTac leverages intra and inter-modality losses for learning representations, resulting in enhanced material property classification and more adept grasping prediction. Through a series of experiments, we showcase the effectiveness of our method and its superiority over existing state-of-the-art self-supervised and supervised techniques. In evaluating our methodology, we focus on two distinct tasks: material classification and grasping success prediction. Our results indicate that MViTac facilitates the development of improved modality encoders, yielding more robust representations as evidenced by linear probing assessments.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12024"
    },
    {
        "doc_id": 263,
        "title": "A Simulation of Optimal Dryness When Moving in the Rain or Snow Using MATLAB",
        "authors": [
            "Neil Zhao",
            "Emilee Brockner",
            "Asia Winslow",
            "Megan Seraydarian"
        ],
        "subjects": [
            "Discrete Mathematics",
            "Mathematical Software"
        ],
        "abstract": "The classic question of whether one should walk or run in the rain to remain the least wet has inspired a myriad of solutions ranging from physically performing test runs in raining conditions to mathematically modeling human movement through rain. This manuscript approaches the classical problem by simulating movement through rainfall using MATLAB. Our simulation was generalizable to include snowfall as well. An increase in walking speed resulted in a corresponding decrease in raindrop and snowflake collisions. When raindrops or snowflakes were given a horizontal movement vector due to wind, a local minimum in collisions was achieved when moving in parallel with the same horizontal speed as the raindrop; no local minimum was detected with antiparallel movement. In general, our simulation revealed that the faster one moves, the drier one remains.",
        "comments": "15 pages, 9 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12023"
    },
    {
        "doc_id": 264,
        "title": "Damping-Enhanced Magnon Transmission",
        "authors": [
            "Xiyin Ye",
            "Ke Xia",
            "Gerrit E. W. Bauer",
            "Tao Yu"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "The inevitable Gilbert damping in magnetization dynamics is usually regarded as detrimental to spin transport. Here we demonstrate in a ferromagnetic-insulator--normal-metal heterostructure that the strong momentum dependence and chirality of the eddy-current-induced damping causes also beneficial scattering properties. Here we show that a potential barrier that reflects magnon wave packets becomes transparent in the presence of a metallic cap layer, but only in one direction. We formulate the unidirectional transmission in terms of a generalized group velocity with an imaginary component and the magnon skin effect. This trick to turn presumably harmful dissipation into useful functionalities should be useful for future quantum magnonic devices.",
        "comments": "7 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12022"
    },
    {
        "doc_id": 265,
        "title": "Study of $\u03a5(10753)$ decays to $\u03c0^{+}\u03c0^{-}\u03a5(nS)$ final states at Belle II",
        "authors": [
            "Belle II Collaboration",
            "I. Adachi",
            "L. Aggarwal",
            "H. Ahmed",
            "H. Aihara",
            "N. Akopov",
            "A. Aloisio",
            "N. Anh Ky",
            "D. M. Asner",
            "H. Atmacan",
            "T. Aushev",
            "V. Aushev",
            "M. Aversano",
            "V. Babu",
            "H. Bae",
            "S. Bahinipati",
            "P. Bambade",
            "Sw. Banerjee",
            "S. Bansal",
            "M. Barrett",
            "J. Baudot",
            "A. Baur",
            "A. Beaubien",
            "F. Becherer",
            "J. Becker",
            "et al. (371 additional authors not shown)"
        ],
        "subjects": [
            "High Energy Physics - Experiment"
        ],
        "abstract": "We present an analysis of the process $e^{+}e^{-}\\to\u03c0^{+}\u03c0^{-}\u03a5(nS)$ (where $n$ = 1, 2, or 3) reconstructed in $19.6\\rm$ $\\rm fb^{-1}$ of Belle II data during a special run of the SuperKEKB collider at four energy points near the peak of the $\u03a5(10753)$ resonance. By analyzing the mass distribution of the $\u03c0^+\u03c0^-\u03a5(nS)$ system and the Born cross sections of the $e^{+}e^{-}\\to\u03c0^{+}\u03c0^{-}\u03a5(nS)$ process, we report the first observation of $\u03a5(10753)$ decays to the $\u03c0^{+}\u03c0^{-}\u03a5(1S)$ and $\u03c0^{+}\u03c0^{-}\u03a5(2S)$ final states, and find no evidence for decays to $\u03c0^{+}\u03c0^{-}\u03a5(3S)$. Possible intermediate states in the $\u03c0^+\u03c0^-\u03a5(1S,2S)$ transitions are also investigated, and no evidence for decays proceeding via the $\u03c0^\\mp Z_b^\\pm$ or $f_0(980)\u03a5(nS)$ intermediate states is found. We measure Born cross sections for the $e^{+}e^{-}\\to\u03c0^{+}\u03c0^{-}\u03a5(nS)$ process that, combined with results from Belle, improve the precision of measurements of the $\u03a5(10753)$ mass and width by nearly a factor of two to $(10756.3\\pm2.7\\pm0.6)$ MeV/$c^2$ and $(29.7\\pm8.5\\pm1.1)$ MeV, respectively. The relative ratios of the Born cross sections at the $\u03a5(10753)$ resonance peak are also reported for the first time.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12021"
    },
    {
        "doc_id": 266,
        "title": "Fault tolerance of stabilizer channels",
        "authors": [
            "Michael E. Beverland",
            "Shilin Huang",
            "Vadym Kliuchnikov"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Stabilizer channels, which are stabilizer circuits that implement logical operations while mapping from an input stabilizer code to an output stabilizer code, are ubiquitous for fault tolerant quantum computing not just with surface codes, but with general LDPC codes and Floquet codes. We introduce a rigorous and general formalism to analyze the fault tolerance properties of any stabilizer channel under a broad class of noise models. We provide rigorous but easy-to-work-with definitions and algorithms for the fault distance and hook faults for stabilizer channels. Additionally, we establish necessary conditions such that channel composition preserves the fault distance. We apply our framework to design and analyze fault tolerant stabilizer channels for surface codes, revealing novel aspects of fault tolerant circuits.",
        "comments": "27 pages, 23 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12017"
    },
    {
        "doc_id": 267,
        "title": "Reconstruction of air shower muon lateral distribution functions using integrator and binary modes of underground muon detectors",
        "authors": [
            "V. V. Kizakke Covilakam",
            "A. D. Supanitsky",
            "D. Ravignani"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "The investigation of cosmic rays holds significant importance in the realm of particle physics, enabling us to expand our understanding beyond atomic confines. However, the origin and characteristics of ultra-high-energy cosmic rays remain elusive, making them a crucial topic of exploration in the field of astroparticle physics. Currently, our examination of these cosmic rays relies on studying the extensive air showers (EAS) generated as they interact with atmospheric nuclei during their passage through Earth's atmosphere. Accurate comprehension of cosmic ray composition is vital in determining their source. Notably, the muon content of EAS and the atmospheric depth of the shower maximum serve as the most significant indicators of primary mass composition. In this study, we present two novel methods for reconstructing particle densities based on muon counts obtained from underground muon detectors (UMDs) at varying distances to the shower axis. Our methods were analyzed using Monte Carlo air shower simulations. To demonstrate these techniques, we utilized the muon content measurements from the UMD of the Pierre Auger cosmic ray Observatory, an array of detectors dedicated to measuring extensive air showers. Our newly developed reconstruction methods, employed with two distinct UMD data acquisition modes, showcased minimal bias and standard deviation. Furthermore, we conducted a comparative analysis of our approaches against previously established methodologies documented in existing literature.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12015"
    },
    {
        "doc_id": 268,
        "title": "Unraveling Generalized Parton Distributions Through Lorentz Symmetry and Partial DGLAP Knowledge",
        "authors": [
            "P. Dall'Olio",
            "F. De Soto",
            "C. Mezrag",
            "J. M. Morgado Ch\u00e1vez",
            "H. Moutarde",
            "J. Rodr\u00edguez-Quintero",
            "P. Sznajder",
            "J. Segovia"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "Relying on the polynomiality property of generalized parton distributions, which roots on Lorentz covariance, we prove that it is enough to know them at vanishing- and low-skewness within the DGLAP region to obtain a unique extension to their entire support up to a D-term. We put this idea in practice using two methods: Reconstruction using artificial neural networks and finite-elements methods. We benchmark our results against standard models for generalized parton distributions. In agreement with the formal expectation, we obtain a very accurate reconstructions for a maximal value of the skewness as low as 20% of the longitudinal momentum fraction. This result might be relevant for reconstruction of generalized parton distribution from experimental and lattice QCD data, where computations are for now, restricted in skewness.",
        "comments": "20 pages, 10 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12013"
    },
    {
        "doc_id": 269,
        "title": "Experimental investigation and scale analysis on melting of salty ice in a 3D-printed cavity filled with porous media",
        "authors": [
            "Xiaotian Liand Yuming Wang",
            "Wei Yang",
            "Wei Yao"
        ],
        "subjects": [
            "Applied Physics",
            "Fluid Dynamics"
        ],
        "abstract": "While significant interests have been devoted to the double diffusive phase change heat transfer of binary solutions, the understanding on the melting heat transfer of salty ice in porous media is still imcomplete. This work aims to explore the melting heat transfer characteristics of salty ice in a square cavity filled with homogeneous porous media subjected to lateral heating. In order to facilitate the visualization of melting dynamics in a uniform porous media, a three-dimensional (3D) printed transparent cavity filled with porous matrix was manufactured, featuring an open upper end. Aqueous solutions of sodium chloride at concentration both higher and lower than the eutectic concentration were investigated. Lateral heating experiments with constant heat flux were conducted in a subzero temperature environment. The effect of heating power, initial concentrations and different sizes of porous matrix was investigated. Distinct phenomena were observed based on the concentration of the aqueous solution. Specifically, the concentration lower than the eutectic concentration results in an upward bending melting interface. Whereas the concentration surpassing the eutectic concentration resulted in a downward bending melting interface. In the presence of salt, a melting convex appears at the bottom of the melting interface and manifests during the whole melting process. Notably, smaller matrix enables faster melting rate. Furthermore, three distinct stages were revealed in our experiments, characterized as conduction, mixture of conduction and ultimately convection stage. The correlations for Nu and the average propagation rate of mushy/liquid interface were established by order of magnitude analysis and fit well with the experiments.",
        "comments": "27 pages, 13 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12009"
    },
    {
        "doc_id": 270,
        "title": "Four Gluon Vertex from Lattice QCD",
        "authors": [
            "Manuel Cola\u00e7o",
            "Orlando Oliveira",
            "Paulo J. Silva"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Theory"
        ],
        "abstract": "A lattice QCD calculation for the four gluon one-particle irreducible Green function in the Landau gauge is discussed. Results for some of the associated form factors are reported for kinematical configurations with a single momentum scale. Our results show that the computation of this Green function requires large statistical ensembles with 10K or larger number of gauge configurations. The simulations considered herein have a clear Monte Carlo signal for momenta up to $\\sim 1$ GeV. The form factors show an hierarchy, with the form factor associated with the tree level Feynman rule being dominant and essentially constant for the range of momenta accessed. The remaining form factors seem to increase as the momentum decreases, suggesting that a possible $\\log$ divergence may occur. The computed form factors are, at least, in qualitative agreement with the results obtained with continuum approaches to this vertex, when available.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12008"
    },
    {
        "doc_id": 271,
        "title": "Interplay of Landau quantization and interminivalley scatterings in a weakly coupled moir\u00e9 superlattice",
        "authors": [
            "Yalong Yuan",
            "Le Liu",
            "Jundong Zhu",
            "Jingwei Dong",
            "Yanbang Chu",
            "Fanfan Wu",
            "Luojun Du",
            "Kenji Watanabe",
            "Takashi Taniguchi",
            "Dongxia Shi",
            "Guangyu Zhang",
            "Wei Yang"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "Double layer quantum systems are promising platforms for realizing novel quantum phases. Here, we report a study of quantum oscillations (QOs) in a weakly coupled double layer system, composed of a large angle twisted double bilayer graphene (TDBG). We observe two different QOs at low temperature, one with a periodicity in carrier density (n), i.e. Shubnikov de Haas oscillation (SdHO) due to Landau quantization, and the other one in displacement field (D), resulting a grid pattern. We quantify the interlayer coupling strength by measuring the interlayer capacitance from the grid pattern with a capacitance model, revealing an electron hole asymmetry. At high temperature when SdHO are thermal smeared, we observe resistance peaks when LLs from two minivalleys in the moir\u00e9 Brillion zone are aligned, regardless of carrier density; eventually, it results in a two fold increase of oscillating frequency in D, serving as a smoking gun evidence of the magneto intersubband oscillations (MISO) in a double layer system. The temperature dependence of MISO suggests electron-electron interaction between two minivalleys play a crucial rule in the scattering, and the scattering times obtained from MISO thermal damping are found to be correlated with the interlayer coupling strength. Our study reveals an intriguing interplay among Landau quantization, moir\u00e9 band structure, and scatterings.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12003"
    },
    {
        "doc_id": 272,
        "title": "A new look at $b \\to s$ observables in 331 models",
        "authors": [
            "Francesco Loparco"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "High Energy Physics - Lattice"
        ],
        "abstract": "Flavour changing neutral current (FCNC) processes are described by loop diagrams in the Standard Model (SM), while in 331 models, based on the gauge group $\\text{SU}(3)_C \\times \\text{SU}(3)_L \\times \\text{U}(1)_X$, they are dominated by tree-level exchanges of a new heavy neutral gauge boson $Z'$. Exploiting this feature, observables related to FCNC decays of $K$, $B_d$ and $B_s$ mesons can be considered in several variants of 331 models. The variants are distinguished by the value of a parameter $\u03b2$ that plays a key role in this framework. Imposing constraints on the $\u0394F = 2$ observables, we select possible ranges for the mass of the $Z'$ boson in correspondence to the values $\u03b2= \\pm k / \\sqrt{3}$, with $k = 1, 2$. The results are used to determine the impact of 331 models on $b \\to s$ processes and on the correlations among them, in the light of new experimental data recently released.",
        "comments": "latex, 26 pages, 8 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11999"
    },
    {
        "doc_id": 273,
        "title": "The Scavenger Hunt for Quasar Samples to Be Used as Cosmological Tools",
        "authors": [
            "Maria Giovanna Dainotti",
            "Giada Bargiacchi",
            "Aleksander \u0141ukasz Lenart",
            "Salvatore Capozziello"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Although the $\u039b$ Cold Dark Matter model is the most accredited cosmological model, information at high redshifts ($z$) between type Ia supernovae ($z=2.26$) and the Cosmic Microwave Background ($z=1100$) is crucial to validate this model further. To this end, we have discovered a sample of 1132 quasars up to $z=7.54$ exhibiting a reduced intrinsic dispersion of the relation between ultraviolet and X-ray fluxes, $\u03b4_\\mathrm{F}=0.22$ vs. $\u03b4_\\mathrm{F}=0.29$ ($24\\%$ less), than the original sample. This gold sample, once we correct the luminosities for selection biases and redshift evolution, enables us to determine the matter density parameter $\u03a9_M$ with a precision of 0.09. Unprecedentedly, this quasar sample is the only one that, as a standalone cosmological probe, yields such tight constraints on $\u03a9_M$ while being drawn from the same parent population of the initial sample.",
        "comments": "36 pages, 19 figures,2 table. Comments are welcome. Accepted in Galaxies",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11998"
    },
    {
        "doc_id": 274,
        "title": "Nonequlibrium Third Law of Thermodynamics",
        "authors": [
            "Faezeh Khodabandehlou"
        ],
        "subjects": [
            "Statistical Mechanics"
        ],
        "abstract": "The extended Third Law for nonequilibrium jump processes is studied in [1, 2], where the nonequilibrium heat capacity and the excess heat with corresponding quasipotential are introduced. The extended Third Law states that under two conditions, the nonequlibrium heat capacity vanishes as the temperature approaches zero. In this paper, we present a concise overview of key papers addressing the nonequilibrium Nernst postulate (the nonequilibrium Third Law of thermodynamics) and nonequilibrium calorimetry. The new result presented in this work include an interpretation of quasipotential in terms of the mean time taken by the Markov jump process, starting from a given state, to reach other states for the first time.",
        "comments": "Conference paper. 3rd International Workshop on Statistical Physics, December 13-15, 2023, Antofagasta, Chile",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11995"
    },
    {
        "doc_id": 275,
        "title": "Topological-charge-dependent dichroism and birefringence of optical vortices",
        "authors": [
            "Kayn A. Forbes",
            "Dale Green"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Material anisotropy and chirality produce polarization-dependent light-matter interactions. Absorption leads to linear and circular dichroism, whereas elastic forward scattering produces linear and circular birefringence. Here we highlight a form of dichroism and birefringence whereby ordered generic media display locally different absorption and scattering of a focused vortex beam that depends upon the sign of the topological charge $\\ell$. The light-matter interactions described in this work manifest purely through dominant electric-dipole coupling mechanisms and depend on the paraxial parameter to first-order. Previous topological-charge-dependent light-matter interactions required the significantly weaker higher-order multipole moments and are proportional to the paraxial parameter to second-order. The result represents a method of probing the nano-optics of advanced materials and the topological properties of structured light.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11992"
    },
    {
        "doc_id": 276,
        "title": "1/f noise in quantum nanoscience",
        "authors": [
            "Giuseppe Falci",
            "Pertti J. Hakonen",
            "Elisabetta Paladino"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Superconductivity"
        ],
        "abstract": "Fundamental issues of 1/f noise in quantum nanoscience are reviewed starting from basic statistical noise processes. Fundamental noise models based on two-level systems (TLS) are described. We emphasize the importance of TLSs in materials parameter fluctuations, such as dielectric constant. The present understanding of 1/f noise in superconducting quantum interferometers and in single electron devices is summarized. For coherent quantum nanoscience, we introduce superconducting qubits and the relation between decoherence and 1/f noise using the filter function formulation. We also clarify the qubit noise spectroscopy and emphasize the importance of materials with reduced 1/f noise for future quantum coherent nanodevices.",
        "comments": "15 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11989"
    },
    {
        "doc_id": 277,
        "title": "ChatGPT-4 and the satisfied Socrates",
        "authors": [
            "Bor Gregorcic",
            "Giulia Polverini"
        ],
        "subjects": [
            "Physics Education"
        ],
        "abstract": "In this paper, we follow up on the previously published paper \"ChatGPT and the frustrated Socrates\" by examining ChatGPT-4's ability to engage in Socratic dialogue in the role of a physics student. While one year ago its ability to engage such dialogue was poor and the dialogue unproductive, we see significant advancements in the chatbot's ability to productively respond to leading questions asked by a human teacher. We suggest that ChatGPT now has the potential to be used in teacher training to help pre- or in-service physics teachers hone their Socratic questioning skills.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11987"
    },
    {
        "doc_id": 278,
        "title": "Versatile quadrature antenna for precise control of large electron spin ensembles in diamond",
        "authors": [
            "Ruben Pellicer-Guridi",
            "Koen Custers",
            "Joseba Solozabal-Aldalur",
            "Alexey Brodolin",
            "Jason T. Francis",
            "Miguel Varga",
            "Jorge Casanova",
            "Margarethus M. Paulides",
            "Gabriel Molina-Terriza"
        ],
        "subjects": [
            "Instrumentation and Detectors",
            "Applied Physics",
            "Quantum Physics"
        ],
        "abstract": "We present an easily reproducible inexpensive microwave antenna that can generate a strong and homogeneous magnetic field of arbitrary polarization, which enables fast and coherent control of electron spins over a large volume. Unlike preceding works, we present a resonant antenna that maintains its resonant behaviour regardless of the proximity of other experimental hardware components. This robustness is crucial as it enables, amongst others, using microscope objectives with short working distances to perform wide field imaging/sensing with bulk diamonds. The antenna generates a magnetic field strength of 22.3 A/m for 1 W total driving power, which doubles the power efficiency compared with previously reported patch antenna designs. The magnetic field homogeneity in a volume of $1 \\text{mm}^3$ is within 6.6\\%. The antenna has a full width at half maximum bandwidth of $\\sim$160 MHz and its resonant frequency can be tuned over a 400 MHz range via four capacitors or varactors. The antenna has been tested and found to remain within safe handling temperatures during continuous-wave operation at 8 W. The files required to reproduce this antenna, which can be built on a standard and affordable double sided PCB, are provided open-source. This work facilitates a robust and versatile piece of instrumentation, being particularly appealing for applications such as high sensitivity magnetometry and wide field imaging/sensing with Nitrogen Vacancy centers.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11986"
    },
    {
        "doc_id": 279,
        "title": "Nano-optical investigation of grain boundaries, strain and edges in CVD grown MoS$_{2}$ monolayers",
        "authors": [
            "Frederico B. Sousa",
            "Rafael Battistella Nadas",
            "Rafael Martins",
            "Ana P. M. Barboza",
            "Jaqueline S. Soares",
            "Bernardo R. A. Neves",
            "Ive Silvestre",
            "Ado Jorio",
            "Leandro M. Malard"
        ],
        "subjects": [
            "Materials Science"
        ],
        "abstract": "The role of defects in two-dimensional semiconductors and how they affect the intrinsic properties of these materials have been a wide researched topic over the past decades. Optical characterization such as photoluminescence and Raman spectroscopies are important tools to probe their physical properties and the impact of defects. However, conventional optical techniques present a spatial resolution limitation lying in a $\u03bc$m-scale, which can be overcomed by the use of near-field optical measurements. Here, we use tip-enhanced photoluminescence and Raman spectroscopies to unveil nanoscale optical heterogeneities at grain boundaries, local strain fields and edges in grown MoS$_{2}$ monolayers. A noticeable enhancement of the exciton peak intensity corresponding to a trion emission quenching is observed at narrow regions down to 47 nm of width at grain boundaries related to doping effects. Besides, localized strain fields inside the sample lead to non-uniformities in the intensity and energy position of photoluminescence peaks. Finally, distinct samples present different nano-optical responses at their edges due to strain and passivation defects. The passivated defective edges show a photoluminescence intensity enhancement and energy blueshift as well as a frequency blueshift of the 2LA Raman mode. On the other hand, the strained edges display a photoluminescence energy redshift and frequency redshifts for E$_{2g}$ and 2LA Raman modes. Our work shows that different defect features can be only probed by using optical spectroscopies with a nanometric resolution, thus revealing hindered local impact of different nanoscale defects in two-dimensional materials.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11984"
    },
    {
        "doc_id": 280,
        "title": "On the uniqueness of compiling graphs under the parity transformation",
        "authors": [
            "Florian Dreier",
            "Wolfgang Lechner"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics",
            "Combinatorics"
        ],
        "abstract": "In this article, we establish a mathematical framework that utilizes concepts from graph theory to define the parity transformation as a mapping that encompasses all possible compiled hypergraphs, and investigate uniqueness properties of this mapping in more detail. By introducing so-called loop labelings, we derive an alternative expression of the preimage of any set of compiled hypergraphs under this encoding procedure when all equivalences classes of graphs are being considered. We then deduce equivalent conditions for the injectivity of the parity transformation on any subset of all equivalences classes of graphs. Moreover, we show concrete examples of optimization problems demonstrating that the parity transformation is not an injective mapping, and also introduce an important class of plaquette layouts and their corresponding set of constraints whose preimage is uniquely determined. In addition, we provide an algorithm which is based on classical algorithms from theoretical computer science and computes a compiled physical layout in this class in polynomial time.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11980"
    },
    {
        "doc_id": 281,
        "title": "$\u039b_{b}\\rightarrow Pl$ factorization in QCD",
        "authors": [
            "Lei-Yi Li",
            "Cai-Dian L\u00fc",
            "Jin Wang",
            "Yan-Bing Wei"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We calculate the form factors for the baryon number violation process of a heavy-flavor baryon decaying into a pseudoscalar meson and a lepton. In the framework of the Standard Model effective field theory, the leptoquark operators at the bottom quark scale, whose matrix elements define the form factors, are derived by integrating out the high energy physics. Under the QCD factorization approach, the form factors of the baryon number violation process at leading power can be factorized into the convolution of the long-distance hadron wave function as well as the short-distance hard and jet functions representing the hard scale and hard-collinear scale effects, separately. Based on measurements of the baryon number violation process by LHCb, we further impose constraints on the new physics constants of leptoquark operators.",
        "comments": "13 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11978"
    },
    {
        "doc_id": 282,
        "title": "Neutrino masses in cosmology",
        "authors": [
            "S. Gariazzo"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "We review the status of neutrino mass constraints obtained from cosmological observations, with a particular focus on the results derived considering Cosmic Microwave Background (CMB) data by various experiments (Planck, ACT and SPT), Baryon Acoustic Oscillation (BAO) determinations and other late-universe probes. We discuss the role played by priors and parameterizations in the Bayesian analyses, both at the time of determining neutrino masses or their ordering, and compare cosmological bounds with terrestrial constraints on both quantities.",
        "comments": "7 pages. Talk presented remotely at 21st Lomonosov Conference on Elementary Particle Physics, Moscow, August 24-30, 2023",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11976"
    },
    {
        "doc_id": 283,
        "title": "Plasmon-enhanced Direct Detection of sub-MeV Dark Matter",
        "authors": [
            "Zheng-Liang Liang",
            "Liangliang Su",
            "Lei Wu",
            "Bin Zhu"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Plasmon, a collective mode of electronic excitation in semiconductor materials, provides a unique avenue for the detection of light dark matter (DM). In this work, we first generalize the theoretical formalism of plasmon to treat the relativistic DM particles. We demonstrate that the plasmon resonance effect for sub-MeV DM can be significantly enhanced, particularly in scenarios of boosted DM with a light mediator. Utilizing the first data from SENSEI at SNOLAB, we derive a new strong limit on the sub-MeV DM-electron scattering cross section, which is more stringent than those from liquid detectors.",
        "comments": "6 pages(double column)+ 3 pages , 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11971"
    },
    {
        "doc_id": 284,
        "title": "Exploring descriptors for titanium microstructure via digital fingerprints from variational autoencoders",
        "authors": [
            "Michael D. White",
            "Gowtham Nimmal Haribabu",
            "Jeyapriya Thimukonda Jegadeesan",
            "Bikramjit Basu",
            "Philip J. Withers",
            "Chris P. Race"
        ],
        "subjects": [
            "Materials Science",
            "Computational Physics"
        ],
        "abstract": "Microstructure is key to controlling and understanding the properties of metallic materials, but traditional approaches to describing microstructure capture only a small number of features. To enable data-centric approaches to materials discovery, allow efficient storage of microstructural data and assist in quality control in metals processing, we require more complete descriptors of microstructure. The concept of microstructural fingerprinting, using machine learning (ML) to develop quantitative, low-dimensional descriptors of microstructures, has recently attracted significant attention. However, it is difficult to interpret conclusions drawn by ML algorithms, which are commonly referred to as \"black boxes\".\n  Here we explore variational autoencoders (VAEs), which can be trained to produce microstructural fingerprints in a continuous latent space. VAEs enable the reconstruction of images from fingerprints, allowing us to explore how key features of microstructure are encoded. We develop a VAE architecture based on ResNet18 and train it on Ti-6Al-4V optical micrographs as an example of an industrially important alloy where microstructural control is critical to performance. The latent space is explored in several ways, including by supplying interpolated and randomly perturbed fingerprints to the trained decoder and via dimensionality reduction to explore the distribution of microstructural features within the latent space of fingerprints. We show that the VAE fingerprints exhibit smooth, interpolable behaviour with stability to local perturbations, supporting their suitability as general purpose descriptors for microstructure. We also show that key properties of the microstructures are strongly correlated with position in the latent space, supporting the use of VAE fingerprints for quantitative exploration of process-structure-property relationships.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11967"
    },
    {
        "doc_id": 285,
        "title": "Not all Probability Density Functions are Tomograms",
        "authors": [
            "L. A. Markovich",
            "J. Urbanetz",
            "V. I. Man'ko"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "This paper delves into the significance of the tomographic probability density function (pdf) representation of quantum states, shedding light on the special classes of pdfs that can be tomograms. Instead of using wave functions or density operators on Hilbert spaces, tomograms, which are the true pdfs, are used to completely describe the states of quantum systems. Unlike quasi-pdfs, like the Wigner function, tomograms can be analysed using all the tools of classical probability theory for pdf estimation, which can allow a better quality of state reconstruction. This is particularly useful when dealing with non-Gaussian states where the pdfs are multi-mode. The knowledge of the family of distributions plays an important role in the application of both parametric and non-parametric density estimation methods. We show that not all pdfs can play the role of tomograms of quantum states and introduce the conditions that must be fulfilled by pdfs to be \"quantum\".",
        "comments": "21 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11966"
    },
    {
        "doc_id": 286,
        "title": "Coexistence of Topological and Normal Insulating Phases in Electro-Optically Tuned InAs/GaSb Bilayer Quantum Wells",
        "authors": [
            "Manuel Meyer",
            "Tobias F\u00e4hndrich",
            "Sebastian Schmid",
            "Adriana Wolf",
            "Sergey Krishtopenko",
            "Benoit Jouault",
            "Gerald Bastard",
            "Frederic Teppe",
            "Fabian Hartmann",
            "Sven H\u00f6fling"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "We report on the coexistence of both normal and topological insulating phases in InAs/GaSb bilayer quantum well induced by the built-in electric field tuned optically and electrically. The emergence of topological and normal insulating phases is assessed based on the evolution of the charge carrier densities, the resistivity dependence of the gap via in-plane magnetic fields and the thermal activation of carriers. For the Hall bar device tuned optically, we observe the fingerprints associated with the presence of only the topological insulating phase. For another Hall bar processed identically but with an additional top gate, the coexistence of normal and topological insulating phases is found by electrical tuning. Our finding paves the way for utilizing a new electro-optical tuning scheme to manipulate InAs/GaSb bilayer quantum wells to obtain trivial-topological insulating interfaces in the bulk rather than at the physical edge of the device.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11965"
    },
    {
        "doc_id": 287,
        "title": "Fried-Yennie gauge in pseudo-QED",
        "authors": [
            "Ana Mizher",
            "Alfredo Raya",
            "Kh\u00e9pani Raya"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Other Condensed Matter",
            "Strongly Correlated Electrons"
        ],
        "abstract": "The Fried-Yennie gauge is a covariant gauge for which the mass-shell renormalization procedure can be performed without introducing spurious infrared divergences to the theory. It is usually applied in calculations in regular Quantum-Electrodynamics (QED), but it is particularly interesting to be employed in the framework of pseudo-QED (PQED), where fermions are constrained to 2+1 dimensions while external fields interacting with these fermions live in the bulk of a 3+1 space. In this context, the gauge parameter can be adjusted to match the power of the external momentum in the denominator of the photon propagator, simplifying the infrared region without the need of a photon mass. In this work we apply for the first time this machinery to PQED, generalizing the procedure to calculate the self energy in arbitrary dimensions, allowing of course for different dimensionality of fermions and gauge fields.",
        "comments": "11 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11964"
    },
    {
        "doc_id": 288,
        "title": "Rogue waves and instability arising from long-wave-short-wave resonance beyond the integrable regime",
        "authors": [
            "Wen-Rong Sun",
            "Boris A. Malomed",
            "Jin-Hua Li"
        ],
        "subjects": [
            "Pattern Formation and Solitons",
            "Optics"
        ],
        "abstract": "We consider instability and localized patterns arising from long wave-short wave (LWSW) resonance in the non-integrable regime numerically. We study the stability and instability of elliptic-function periodic waves with respect to subharmonic perturbations, whose period is a multiple of the period of the elliptic waves. We thus find the modulational instability (MI) of the corresponding dnoidal waves. Upon varying parameters of dnoidal waves, spectrally unstable ones can be transformed into stable states via the Hamiltonian Hopf bifurcation. For snoidal waves, we find a transition of the dominant instability scenario between the MI and instability with a bubble-like spectrum. For cnoidal waves, we produce three variants of the MI. Evolution of the unstable states is also considered, leading to formation of rogue waves on top of the elliptic-wave and continuous-wave backgrounds.",
        "comments": "To be published in Physical Review E",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11959"
    },
    {
        "doc_id": 289,
        "title": "On the steadiness of symmetric solutions to two dimensional dispersive models",
        "authors": [
            "Long Pei",
            "Fengyang Xiao",
            "Pan Zhang"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "In this paper, we consider the steadiness of symmetric solutions to two dispersive models in shallow water and hyperelastic mechanics, respectively. These models are derived previously in the two-dimensional setting and can be viewed as the generalization of the Camassa-Holm and Kadomtsev-Petviashvili equations. For these two models, we prove that symmetry of classical solutions implies steadiness in the horizontal direction. We also confirm the such connection between symmetry and steadiness in weak formulation, which includes in particular the peaked solutions.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11953"
    },
    {
        "doc_id": 290,
        "title": "MITgcm-AD v2: Open source tangent linear and adjoint modeling framework for the oceans and atmosphere enabled by the Automatic Differentiation tool Tapenade",
        "authors": [
            "Shreyas Sunil Gaikwad",
            "Sri Hari Krishna Narayanan",
            "Laurent Hascoet",
            "Jean-Michel Campin",
            "Helen Pillar",
            "An Nguyen",
            "Jan H\u00fcckelheim",
            "Paul Hovland",
            "Patrick Heimbach"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "The Massachusetts Institute of Technology General Circulation Model (MITgcm) is widely used by the climate science community to simulate planetary atmosphere and ocean circulations. A defining feature of the MITgcm is that it has been developed to be compatible with an algorithmic differentiation (AD) tool, TAF, enabling the generation of tangent-linear and adjoint models. These provide gradient information which enables dynamics-based sensitivity and attribution studies, state and parameter estimation, and rigorous uncertainty quantification. Importantly, gradient information is essential for computing comprehensive sensitivities and performing efficient large-scale data assimilation, ensuring that observations collected from satellites and in-situ measuring instruments can be effectively used to optimize a large uncertain control space. As a result, the MITgcm forms the dynamical core of a key data assimilation product employed by the physical oceanography research community: Estimating the Circulation and Climate of the Ocean (ECCO) state estimate. Although MITgcm and ECCO are used extensively within the research community, the AD tool TAF is proprietary and hence inaccessible to a large proportion of these users. The new version 2 (MITgcm-AD v2) framework introduced here is based on the source-to-source AD tool Tapenade, which has recently been open-sourced. Another feature of Tapenade is that it stores required variables by default (instead of recomputing them) which simplifies the implementation of efficient, AD-compatible code. The framework has been integrated with the MITgcm model main branch and is now freely available.",
        "comments": "12 pages, 2 figures, 4 tables, submitted to Joint Laboratory on Extreme Scale Computing Future Generation Computer Systems (JLESC-FGCS)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11952"
    },
    {
        "doc_id": 291,
        "title": "Calcite, vaterite and aragonite forming on cement hydration from liquid and gaseous phase",
        "authors": [
            "E. T. Stepkowska",
            "J. L. P\u00e9rez Rodr\u00edguez",
            "M. J. Sayagu\u00e9s",
            "J. M. Mart\u00ednez Blanes"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Cement hydration products were studied as influenced by the hydration conditions (hydration time in liquid phase; relative humidity, RH, in gaseous phase). The formation of calcium hydroxide (portlandite, P) and its transformation to calcium carbonates is mainly discussed here.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11950"
    },
    {
        "doc_id": 292,
        "title": "The N(1440) Roper resonance in the nuclear model with explicit mesons",
        "authors": [
            "D. V. Fedorov"
        ],
        "subjects": [
            "Nuclear Theory",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We show that the N(1440) Roper resonance naturally appears in the nuclear model with explicit mesons as a structure in the continuum spectrum of the physical proton which in this calculation is made of a bare nucleon dressed with a pion cloud.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11947"
    },
    {
        "doc_id": 293,
        "title": "Single-Photon-Assisted Two-Photon Polymerization",
        "authors": [
            "Buse Unlu",
            "Maria Isabel \u00c1lvarez-Casta\u00f1o",
            "Antoine Boniface",
            "Ye Pu",
            "Christophe Moser"
        ],
        "subjects": [
            "Optics",
            "Applied Physics"
        ],
        "abstract": "Light-based additive manufacturing (AM) has revolutionized the fabrication of complex three-dimensional (3D) objects offering a cost-effective and high-speed alternative to traditional machining. One-photon polymerization is a key process in this advancement, standing out for rapid printing time, albeit with limited resolution. Two-photon polymerization (2PP) empowers AM with unprecedented resolution but is accompanied by a tradeoff of prolonged printing times. We propose combining the single-photon absorption (1PA) and 2PP to benefit from the dual capabilities, allowing for faster printing while maintaining high resolution and improved depth sectioning, respectively. In this study, we employ a blue light source to pre-excite a photocurable resin by 1PA followed by a precisely focused femtosecond (fs) beam to provide the missing energy necessary to reach the polymerization threshold to solidify the resin through two-photon absorption. First, we investigate the impact of pre-sensitization by blue light illumination on 2PP and demonstrate one order of magnitude faster printing time for a voxel size of 150 nm as compared to the same voxel size printed by 2PP only. Then, we build a custom 2PP printer utilizing blue light sensitization in a light-sheet mode and demonstrate successful 3D prints.",
        "comments": "18 pages, 11 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11942"
    },
    {
        "doc_id": 294,
        "title": "Influence of collisions on trapped-electron modes in tokamaks and low-shear stellarators",
        "authors": [
            "M. C. L. Morren",
            "J. H. E. Proll",
            "J. van Dijk",
            "M. J. Pueschel"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "The influence of collisions on the growth rate of trapped-electron modes (TEM) is assessed through both analytical linear gyrokinetics, and linear gyrokinetic simulations. Both methods are applied to the magnetic geometry of the DIII-D tokamak, as well as the Helically Symmetric eXperiment (HSX) and Wendelstein 7-X (W7-X) stellarators. Here we analytically investigate the influence of collisions on the TEM eigenmode frequency by a perturbative approach with an energy-dependent Krook operator. A universal finding for all geometries is a stabilisation of the growth rate at high collisionality, the rate of which, however, depends on the geometry. At low collisionality, a growth rate insensitive to the collisionality is obtained in DIII-D at all wavenumbers, and for high-wavenumber modes in HSX and W7-X. In contrast, for the low-wavenumber modes in HSX and W7-X a destabilisation is obtained. Linear gyrokinetic simulations for the same geometries confirm these qualitative trends. Additionally, the simulations show the destabilisation of the low-wavenumber modes in HSX and W7-X is a result of a collision-induced transition of the dominant mode towards the Universal Instability (UI), a trend which is also continued to high-wavenumbers in W7-X.",
        "comments": "42 pages, 20 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11937"
    },
    {
        "doc_id": 295,
        "title": "The Definition of a Photon Surface in an Invariant Spin Frame",
        "authors": [
            "Dipanjan Dey",
            "Alan A. Coley",
            "Nicholas T. Layden"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology"
        ],
        "abstract": "This paper defines the photon surface conditions using Cartan scalars within an invariant spin frame, offering a comprehensive description of the local spacetime geometry. By employing this approach, we gain novel insights into the geometry and dynamics of photon surfaces, independent of the global spacetime structure. We first discuss the photon surface conditions in a Petrov type-D spacetime manifold, and then we simplify those conditions assuming the existence of spherical symmetry. Finally, employing the simplified, spherically symmetric photon surface conditions, we explore the dynamics of photon surfaces in static, collapsing Lemaitre-Tolman-Bondi (LTB) spacetimes, and Vaidya spacetimes. Notably, we show that photon surfaces can emerge from the central singularity during the collapse of an inhomogeneous dust cloud modeled by a LTB spacetime. This underscores the significance of our findings in comprehending the potential observational implications of the physics near the ultra-high gravity region.",
        "comments": "12 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11936"
    },
    {
        "doc_id": 296,
        "title": "Two Determinant Distinguishable Cluster",
        "authors": [
            "Thomas Schraivogel",
            "Daniel Kats"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "A two reference determinant version of the distinguishable cluster with singles and doubles (DCSD) has been developed. We have implemented the two determinant distinguishable cluster (2D-DCSD) and the corresponding traditional 2D-CCSD method in a new open-source package written in Julia called ElemCo.jl. The methods were benchmarked on singlet and triplet excited states of valence and Rydberg character, as well as for singlet-triplet gaps of diradicals. It is demonstrated that the distinguishable cluster approximation improves the accuracy of 2D-CCSD.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11935"
    },
    {
        "doc_id": 297,
        "title": "Large deviation full counting statistics in adiabatic open quantum dynamics",
        "authors": [
            "Paulo J. Paulino",
            "Igor Lesanovsky",
            "Federico Carollo"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Quantum Physics"
        ],
        "abstract": "The state of an open quantum system undergoing an adiabatic process evolves by following the instantaneous stationary state of its time-dependent generator. This observation allows one to characterize, for a generic adiabatic evolution, the average dynamics of the open system. However, information about fluctuations of dynamical observables, such as the number of photons emitted or the time-integrated stochastic entropy production in single experimental runs, requires controlling the whole spectrum of the generator and not only the stationary state. Here, we show how such information can be obtained in adiabatic open quantum dynamics by exploiting tools from large deviation theory. We prove an adiabatic theorem for deformed generators, which allows us to encode, in a biased quantum state, the full counting statistics of generic time-integrated dynamical observables. We further compute the probability associated with an arbitrary \"rare\" time-history of the observable and derive a dynamics which realizes it in its typical behavior. Our results provide a way to characterize and engineer adiabatic open quantum dynamics and to control their fluctuations.",
        "comments": "7 + 8 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11933"
    },
    {
        "doc_id": 298,
        "title": "Combination of searches for pair-produced leptoquarks at $\\sqrt{s} = 13$ TeV with the ATLAS detector",
        "authors": [
            "ATLAS Collaboration"
        ],
        "subjects": [
            "High Energy Physics - Experiment"
        ],
        "abstract": "A statistical combination of various searches for pair-produced leptoquarks is presented, using the full LHC Run 2 (2015-2018) data set of $139$ fb$^{-1}$ collected with the ATLAS detector from proton-proton collisions at a centre-of-mass energy of $\\sqrt{s}=13$ TeV. All possible decays of the leptoquarks into quarks of the third generation and charged or neutral leptons of any generation are investigated. Since no significant deviations from the Standard Model expectation are observed in any of the individual analyses, combined exclusion limits are set on the production cross-sections for scalar and vector leptoquarks. The resulting lower bounds on leptoquark masses exceed those from the individual analyses by up to 100 GeV, depending on the signal hypothesis.",
        "comments": "36 pages in total, authorlist starting on p19, 7 figures, 2 tables submitted to Phys. Lett. B. All figures are available at http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/EXOT-2020-27",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11928"
    },
    {
        "doc_id": 299,
        "title": "Inertia drives concentration-wave turbulence in swimmer suspensions",
        "authors": [
            "Purnima Jain",
            "Navdeep Rana",
            "Sriram Ramaswamy",
            "Prasad Perlekar"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Fluid Dynamics"
        ],
        "abstract": "We discover an instability mechanism in suspensions of self-propelled particles that does not involve active stress. Instead, it is driven by a subtle interplay of inertia, swimmer motility, and concentration fluctuations, through a crucial time lag between the velocity and the concentration field. The resulting time-persistent state seen in our high-resolution numerical simulations consists of self-sustained waves of concentration and orientation, transiting from regular oscillations to wave turbulence. We analyze the statistical features of this active turbulence, including an intriguing connection to the Batchelor spectrum of passive scalars.",
        "comments": "11 pages and 9 figures including supplementary material",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11927"
    },
    {
        "doc_id": 300,
        "title": "Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning",
        "authors": [
            "Philip Amortila",
            "Tongyi Cao",
            "Akshay Krishnamurthy"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undesirable behavior, resulting in no misspecification amplification while still obtaining optimal statistical rates. As applications, we use this regression procedure to obtain new guarantees in offline and online reinforcement learning with misspecification and establish new separations between previously studied structural conditions and notions of coverage.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12216"
    },
    {
        "doc_id": 301,
        "title": "Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources",
        "authors": [
            "V\u00edctor Samuel P\u00e9rez-D\u00edaz",
            "Juan Rafael Mart\u00ednez-Galarza",
            "Alexander Caicedo",
            "Raffaele D'Abrusco"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics",
            "Artificial Intelligence"
        ],
        "abstract": "The automatic classification of X-ray detections is a necessary step in extracting astrophysical information from compiled catalogs of astrophysical sources. Classification is useful for the study of individual objects, statistics for population studies, as well as for anomaly detection, i.e., the identification of new unexplored phenomena, including transients and spectrally extreme sources. Despite the importance of this task, classification remains challenging in X-ray astronomy due to the lack of optical counterparts and representative training sets. We develop an alternative methodology that employs an unsupervised machine learning approach to provide probabilistic classes to Chandra Source Catalog sources with a limited number of labeled sources, and without ancillary information from optical and infrared catalogs. We provide a catalog of probabilistic classes for 8,756 sources, comprising a total of 14,507 detections, and demonstrate the success of the method at identifying emission from young stellar objects, as well as distinguishing between small-scale and large-scale compact accretors with a significant level of confidence. We investigate the consistency between the distribution of features among classified objects and well-established astrophysical hypotheses such as the unified AGN model. This provides interpretability to the probabilistic classifier. Code and tables are available publicly through GitHub. We provide a web playground for readers to explore our final classification at https://umlcaxs-playground.streamlit.app.",
        "comments": "21 pages, 11 figures. Accepted in MNRAS",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12203"
    },
    {
        "doc_id": 302,
        "title": "Using spatial extreme-value theory with machine learning to model and understand spatially compounding extremes",
        "authors": [
            "Jonathan Koh",
            "Daniel Steinfeld",
            "Olivia Martius"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "When extreme weather events affect large areas, their regional to sub-continental spatial scale is important for their impacts. We propose a novel methodology that combines spatial extreme-value theory with a machine learning (ML) algorithm to model weather extremes and quantify probabilities associated with the occurrence, intensity and spatial extent of these events. The model is here applied to Western European summertime heat extremes. Using new loss functions adapted to extreme values, we fit a theoretically-motivated spatial model to extreme positive temperature anomaly fields from 1959-2022, using the daily 500-hpa geopotential height fields across the Euro-Atlantic region and the local soil moisture as predictors. Our generative model reveals the importance of individual circulation features in determining different facets of heat extremes, thereby enriching our process understanding of them from a data-driven perspective. The occurrence, intensity, and spatial extent of heat extremes are sensitive to the relative position of individual ridges and troughs that are part of a large-scale wave pattern. Heat extremes in Europe are thus the result of a complex interplay between local and remote physical processes. Our approach is able to extrapolate beyond the range of the data to make risk-related probabilistic statements, and applies more generally to other weather extremes. It also offers an attractive alternative to physical model-based techniques, or to ML approaches that optimise scores focusing on predicting well the bulk instead of the tail of the data distribution.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12195"
    },
    {
        "doc_id": 303,
        "title": "Concentration inequalities for the sample correlation coefficient",
        "authors": [
            "Daniel Salnikov"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "The sample correlation coefficient $R$ plays an important role in many statistical analyses. We study the moments of $R$ under the bivariate Gaussian model assumption, provide a novel approximation for its finite sample mean and connect it with known results for the variance. We exploit these approximations to present non-asymptotic concentration inequalities for $R$. Finally, we illustrate our results in a simulation experiment that further validates the approximations presented in this work.",
        "comments": "10 pages, preprint",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12190"
    },
    {
        "doc_id": 304,
        "title": "Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE",
        "authors": [
            "Hong Wei",
            "James Xiao",
            "Yichao Zhang",
            "Xia Hong"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Image segmentation is a clustering task whereby each pixel is assigned a cluster label. Remote sensing data usually consists of multiple bands of spectral images in which there exist semantically meaningful land cover subregions, co-registered with other source data such as LIDAR (LIght Detection And Ranging) data, where available. This suggests that, in order to account for spatial correlation between pixels, a feature vector associated with each pixel may be a vectorized tensor representing the multiple bands and a local patch as appropriate. Similarly, multiple types of texture features based on a pixel's local patch would also be beneficial for encoding locally statistical information and spatial variations, without necessarily labelling pixel-wise a large amount of ground truth, then training a supervised model, which is sometimes impractical. In this work, by resorting to label only a small quantity of pixels, a new semi-supervised segmentation approach is proposed. Initially, over all pixels, an image data matrix is created in high dimensional feature space. Then, t-SNE projects the high dimensional data onto 3D embedding. By using radial basis functions as input features, which use the labelled data samples as centres, to pair with the output class labels, a modified canonical correlation analysis algorithm, referred to as RBF-CCA, is introduced which learns the associated projection matrix via the small labelled data set. The associated canonical variables, obtained for the full image, are applied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA algorithm has been implemented on several remotely sensed multispectral images, demonstrating excellent segmentation results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12164"
    },
    {
        "doc_id": 305,
        "title": "The accuracy of ALMA estimates of young disk radii and masses. Predicted observations from numerical simulations",
        "authors": [
            "Ngo-Duy Tung",
            "Leonardo Testi",
            "Ugo Lebreuilly",
            "Patrick Hennebelle",
            "Ana\u00eblle Maury",
            "Ralf S. Klessen",
            "Luca Cacciapuoti",
            "Matthias Gonz\u00e1lez",
            "Giovanni Rosotti",
            "Sergio Molinari"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics",
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "Protoplanetary disks, which are the natural consequence of the gravitational collapse of the dense molecular cloud cores, host the formation of the planetary systems known today in our universe. Numerous efforts have been dedicated to investigate the properties of these disks in the more mature Class II stage, either by using numerical simulations of disk evolution from a limited range of initial conditions or by observations of their dust continuum and line emission from specific molecular tracers, and to compare the results from the two standpoints. Yet few studies have investigated the main limitations at work when measuring the embedded Class 0/I disk properties from observations, especially in a statistical fashion. In this study, we provide a first attempt to compare the accuracy of some critical disk parameters in Class 0/I systems, as derived on real ALMA observational data, with the corresponding physical parameters that modellers can directly define in numerical simulations. The approach we follow is to provide full post-processing of the numerical simulations and apply on the synthetic observations the same techniques used by observers to derive the physical parameters. To that end, we performed 3D Monte Carlo radiative transfer and mock interferometric observations of the disk populations formed in an MHD simulation model of disk formation through the collapse of massive clumps with the tools RADMC-3D and CASA, respectively, to obtain their synthetic observations. With these observations, we re-employ the techniques commonly used in disk modelling from their continuum emissions to infer their properties that one would likely obtain if one observed them with real interferometers. We then demonstrate how their properties vary from the gas kinematics analyses to the dust continuum modelling.",
        "comments": "Accepted for publication in Astronomy & Astrophysics, 32 pages, 28 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12142"
    },
    {
        "doc_id": 306,
        "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
        "authors": [
            "John D. Mayfield",
            "Issam El Naqa"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Emerging Technologies",
            "Image and Video Processing"
        ],
        "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term Memory (LSTM) models were studied to provide sequential relationships for each timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot study, we compared three QCNN-LSTM models for binary classification of MS disability benchmarked against classical neural network architectures. Our hypothesis is that quantum models will provide competitive performance. Methods Matrix Product State (MPS), reverse Multistate Entanglement Renormalization Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM layer to process near-annual MRI data of patients diagnosed with MS. These were benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision Transformer (ViViT). Predicted logits were measured against ground truth labels of each patient's Extended Disability Severity Score (EDSS) using binary cross-entropy loss. Training/validation/holdout testing was partitioned using 5-fold cross validation with a total split of 60:20:20. Levene's test of variance was used to measure statistical difference and Student's t-test for paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively (p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73 and 0.77, respectively (p-value 0.631). Overall variance and mean were not statistically significant (p-value 0.713), however, time to train was significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218, respectively, p-value <0.001). Conclusion QCNN-LSTM models perform competitively to their classical counterparts with greater efficiency in train time. Clinically, these can add value in terms of efficiency to time-dependent deep learning prediction of disease progression based upon medical imaging.",
        "comments": "ACM Class:          I.2.0; I.2.6",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12132"
    },
    {
        "doc_id": 307,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 308,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 309,
        "title": "The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization",
        "authors": [
            "Matan Schliserman",
            "Uri Sherman",
            "Tomer Koren"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We study the generalization performance of gradient methods in the fundamental stochastic convex optimization setting, focusing on its dimension dependence. First, for full-batch gradient descent (GD) we give a construction of a learning problem in dimension $d=O(n^2)$, where the canonical version of GD (tuned for optimal performance of the empirical risk) trained with $n$ training examples converges, with constant probability, to an approximate empirical risk minimizer with $\u03a9(1)$ population excess risk. Our bound translates to a lower bound of $\u03a9(\\sqrt{d})$ on the number of training examples required for standard GD to reach a non-trivial test error, answering an open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b) and showing that a non-trivial dimension dependence is unavoidable. Furthermore, for standard one-pass stochastic gradient descent (SGD), we show that an application of the same construction technique provides a similar $\u03a9(\\sqrt{d})$ lower bound for the sample complexity of SGD to reach a non-trivial empirical error, despite achieving optimal test performance. This again provides an exponential improvement in the dimension dependence compared to previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an open question left therein.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12058"
    },
    {
        "doc_id": 310,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 311,
        "title": "Multi-objective optimisation using expected quantile improvement for decision making in disease outbreaks",
        "authors": [
            "Daria Semochkina",
            "Alexander I. J. Forrester",
            "David C Woods"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Optimization under uncertainty is important in many applications, particularly to inform policy and decision making in areas such as public health. A key source of uncertainty arises from the incorporation of environmental variables as inputs into computational models or simulators. Such variables represent uncontrollable features of the optimization problem and reliable decision making must account for the uncertainty they propagate to the simulator outputs. Often, multiple, competing objectives are defined from these outputs such that the final optimal decision is a compromise between different goals.\n  Here, we present emulation-based optimization methodology for such problems that extends expected quantile improvement (EQI) to address multi-objective optimization. Focusing on the practically important case of two objectives, we use a sequential design strategy to identify the Pareto front of optimal solutions. Uncertainty from the environmental variables is integrated out using Monte Carlo samples from the simulator. Interrogation of the expected output from the simulator is facilitated by use of (Gaussian process) emulators. The methodology is demonstrated on an optimization problem from public health involving the dispersion of anthrax spores across a spatial terrain. Environmental variables include meteorological features that impact the dispersion, and the methodology identifies the Pareto front even when there is considerable input uncertainty.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12031"
    },
    {
        "doc_id": 312,
        "title": "Four Gluon Vertex from Lattice QCD",
        "authors": [
            "Manuel Cola\u00e7o",
            "Orlando Oliveira",
            "Paulo J. Silva"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Theory"
        ],
        "abstract": "A lattice QCD calculation for the four gluon one-particle irreducible Green function in the Landau gauge is discussed. Results for some of the associated form factors are reported for kinematical configurations with a single momentum scale. Our results show that the computation of this Green function requires large statistical ensembles with 10K or larger number of gauge configurations. The simulations considered herein have a clear Monte Carlo signal for momenta up to $\\sim 1$ GeV. The form factors show an hierarchy, with the form factor associated with the tree level Feynman rule being dominant and essentially constant for the range of momenta accessed. The remaining form factors seem to increase as the momentum decreases, suggesting that a possible $\\log$ divergence may occur. The computed form factors are, at least, in qualitative agreement with the results obtained with continuum approaches to this vertex, when available.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12008"
    },
    {
        "doc_id": 313,
        "title": "Integrating Statistical Significance and Discriminative Power in Pattern Discovery",
        "authors": [
            "Leonardo Alexandre",
            "Rafael S. Costa",
            "Rui Henriques"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Pattern discovery plays a central role in both descriptive and predictive tasks across multiple domains. Actionable patterns must meet rigorous statistical significance criteria and, in the presence of target variables, further uphold discriminative power. Our work addresses the underexplored area of guiding pattern discovery by integrating statistical significance and discriminative power criteria into state-of-the-art algorithms while preserving pattern quality. We also address how pattern quality thresholds, imposed by some algorithms, can be rectified to accommodate these additional criteria. To test the proposed methodology, we select the triclustering task as the guiding pattern discovery case and extend well-known greedy and multi-objective optimization triclustering algorithms, $\u03b4$-Trimax and TriGen, that use various pattern quality criteria, such as Mean Squared Residual (MSR), Least Squared Lines (LSL), and Multi Slope Measure (MSL). Results from three case studies show the role of the proposed methodology in discovering patterns with pronounced improvements of discriminative power and statistical significance without quality deterioration, highlighting its importance in supervisedly guiding the search. Although the proposed methodology is motivated over multivariate time series data, it can be straightforwardly extended to pattern discovery tasks involving multivariate, N-way (N>3), transactional, and sequential data structures.\n  Availability: The code is freely available at https://github.com/JupitersMight/MOF_Triclustering under the MIT license.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12000"
    },
    {
        "doc_id": 314,
        "title": "Elasticity of self-organized frustrated disordered spring networks",
        "authors": [
            "Tommaso Pettinari",
            "Gustavo D\u00fcring",
            "Edan Lerner"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics"
        ],
        "abstract": "There have been some interesting recent advances in understanding the notion of mechanical disorder in structural glasses and the statistical mechanics of these systems' low-energy excitations. Here we contribute to these advances by studying a minimal model for structural glasses' elasticity in which the degree of mechanical disorder -- as characterized by recently introduced dimensionless quantifiers -- is readily tunable over a very large range. We comprehensively investigate a number of scaling laws observed for various macro-, meso- and microscopic elastic properties, and rationalize them using scaling arguments. Interestingly, we demonstrate that the model features the universal quartic glassy vibrational density of states as seen in many atomistic and molecular models of structural glasses formed by cooling a melt. The emergence of this universal glassy spectrum highlights the role of self-organization (towards mechanical equilibrium) in its formation, and elucidates why models featuring structural frustration alone do not feature the same universal glassy spectrum. Finally, we discuss relations to existing work in the context of strain-stiffening of elastic networks and of low-energy excitations in structural glasses, in addition to future research directions.",
        "comments": "9 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11996"
    },
    {
        "doc_id": 315,
        "title": "1/f noise in quantum nanoscience",
        "authors": [
            "Giuseppe Falci",
            "Pertti J. Hakonen",
            "Elisabetta Paladino"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Superconductivity"
        ],
        "abstract": "Fundamental issues of 1/f noise in quantum nanoscience are reviewed starting from basic statistical noise processes. Fundamental noise models based on two-level systems (TLS) are described. We emphasize the importance of TLSs in materials parameter fluctuations, such as dielectric constant. The present understanding of 1/f noise in superconducting quantum interferometers and in single electron devices is summarized. For coherent quantum nanoscience, we introduce superconducting qubits and the relation between decoherence and 1/f noise using the filter function formulation. We also clarify the qubit noise spectroscopy and emphasize the importance of materials with reduced 1/f noise for future quantum coherent nanodevices.",
        "comments": "15 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11989"
    },
    {
        "doc_id": 316,
        "title": "Cross-Validation Conformal Risk Control",
        "authors": [
            "Kfir M. Cohen",
            "Sangwoo Park",
            "Osvaldo Simeone",
            "Shlomo Shamai"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Conformal risk control (CRC) is a recently proposed technique that applies post-hoc to a conventional point predictor to provide calibration guarantees. Generalizing conformal prediction (CP), with CRC, calibration is ensured for a set predictor that is extracted from the point predictor to control a risk function such as the probability of miscoverage or the false negative rate. The original CRC requires the available data set to be split between training and validation data sets. This can be problematic when data availability is limited, resulting in inefficient set predictors. In this paper, a novel CRC method is introduced that is based on cross-validation, rather than on validation as the original CRC. The proposed cross-validation CRC (CV-CRC) extends a version of the jackknife-minmax from CP to CRC, allowing for the control of a broader range of risk functions. CV-CRC is proved to offer theoretical guarantees on the average risk of the set predictor. Furthermore, numerical experiments show that CV-CRC can reduce the average set size with respect to CRC when the available data are limited.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11974"
    },
    {
        "doc_id": 317,
        "title": "RUMBoost: Gradient Boosted Random Utility Models",
        "authors": [
            "Nicolas Salvad\u00e9",
            "Tim Hillel"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "This paper introduces the RUMBoost model, a novel discrete choice modelling approach that combines the interpretability and behavioural robustness of Random Utility Models (RUMs) with the generalisation and predictive ability of deep learning methods. We obtain the full functional form of non-linear utility specifications by replacing each linear parameter in the utility functions of a RUM with an ensemble of gradient boosted regression trees. This enables piece-wise constant utility values to be imputed for all alternatives directly from the data for any possible combination of input variables. We introduce additional constraints on the ensembles to ensure three crucial features of the utility specifications: (i) dependency of the utilities of each alternative on only the attributes of that alternative, (ii) monotonicity of marginal utilities, and (iii) an intrinsically interpretable functional form, where the exact response of the model is known throughout the entire input space. Furthermore, we introduce an optimisation-based smoothing technique that replaces the piece-wise constant utility values of alternative attributes with monotonic piece-wise cubic splines to identify non-linear parameters with defined gradient. We demonstrate the potential of the RUMBoost model compared to various ML and Random Utility benchmark models for revealed preference mode choice data from London. The results highlight the great predictive performance and the direct interpretability of our proposed approach. Furthermore, the smoothed attribute utility functions allow for the calculation of various behavioural indicators and marginal utilities. Finally, we demonstrate the flexibility of our methodology by showing how the RUMBoost model can be extended to complex model specifications, including attribute interactions, correlation within alternative error terms and heterogeneity within the population.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11954"
    },
    {
        "doc_id": 318,
        "title": "The Ensemble Kalman Filter for Dynamic Inverse Problems",
        "authors": [
            "Simon Weissmann",
            "Neil K. Chada",
            "Xin T. Tong"
        ],
        "subjects": [
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "In inverse problems, the goal is to estimate unknown model parameters from noisy observational data. Traditionally, inverse problems are solved under the assumption of a fixed forward operator describing the observation model. In this article, we consider the extension of this approach to situations where we have a dynamic forward model, motivated by applications in scientific computation and engineering. We specifically consider this extension for a derivative-free optimizer, the ensemble Kalman inversion (EKI). We introduce and justify a new methodology called dynamic-EKI, which is a particle-based method with a changing forward operator. We analyze our new method, presenting results related to the control of our particle system through its covariance structure. This analysis includes moment bounds and an ensemble collapse, which are essential for demonstrating a convergence result. We establish convergence in expectation and validate our theoretical findings through experiments with dynamic-EKI applied to a 2D Darcy flow partial differential equation.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11948"
    },
    {
        "doc_id": 319,
        "title": "Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent",
        "authors": [
            "Zhiyu Liu",
            "Zhi Han",
            "Yandong Tang",
            "Xi-Le Zhao",
            "Yao Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it is worth noting that our method does not require the precise estimation of the tensor tubal-rank. Even in cases where the tubal-rank is slightly overestimated, our approach continues to demonstrate robust performance. A series of experiments have been carried out to demonstrate that, as compared to other popular ones, our approach exhibits superior performance in multiple scenarios, in terms of the faster computational speed and the smaller convergence error.",
        "comments": "13 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11940"
    },
    {
        "doc_id": 320,
        "title": "Large deviation full counting statistics in adiabatic open quantum dynamics",
        "authors": [
            "Paulo J. Paulino",
            "Igor Lesanovsky",
            "Federico Carollo"
        ],
        "subjects": [
            "Statistical Mechanics",
            "Quantum Physics"
        ],
        "abstract": "The state of an open quantum system undergoing an adiabatic process evolves by following the instantaneous stationary state of its time-dependent generator. This observation allows one to characterize, for a generic adiabatic evolution, the average dynamics of the open system. However, information about fluctuations of dynamical observables, such as the number of photons emitted or the time-integrated stochastic entropy production in single experimental runs, requires controlling the whole spectrum of the generator and not only the stationary state. Here, we show how such information can be obtained in adiabatic open quantum dynamics by exploiting tools from large deviation theory. We prove an adiabatic theorem for deformed generators, which allows us to encode, in a biased quantum state, the full counting statistics of generic time-integrated dynamical observables. We further compute the probability associated with an arbitrary \"rare\" time-history of the observable and derive a dynamics which realizes it in its typical behavior. Our results provide a way to characterize and engineer adiabatic open quantum dynamics and to control their fluctuations.",
        "comments": "7 + 8 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11933"
    },
    {
        "doc_id": 321,
        "title": "Combination of searches for pair-produced leptoquarks at $\\sqrt{s} = 13$ TeV with the ATLAS detector",
        "authors": [
            "ATLAS Collaboration"
        ],
        "subjects": [
            "High Energy Physics - Experiment"
        ],
        "abstract": "A statistical combination of various searches for pair-produced leptoquarks is presented, using the full LHC Run 2 (2015-2018) data set of $139$ fb$^{-1}$ collected with the ATLAS detector from proton-proton collisions at a centre-of-mass energy of $\\sqrt{s}=13$ TeV. All possible decays of the leptoquarks into quarks of the third generation and charged or neutral leptons of any generation are investigated. Since no significant deviations from the Standard Model expectation are observed in any of the individual analyses, combined exclusion limits are set on the production cross-sections for scalar and vector leptoquarks. The resulting lower bounds on leptoquark masses exceed those from the individual analyses by up to 100 GeV, depending on the signal hypothesis.",
        "comments": "36 pages in total, authorlist starting on p19, 7 figures, 2 tables submitted to Phys. Lett. B. All figures are available at http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/EXOT-2020-27",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11928"
    },
    {
        "doc_id": 322,
        "title": "Inertia drives concentration-wave turbulence in swimmer suspensions",
        "authors": [
            "Purnima Jain",
            "Navdeep Rana",
            "Sriram Ramaswamy",
            "Prasad Perlekar"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Fluid Dynamics"
        ],
        "abstract": "We discover an instability mechanism in suspensions of self-propelled particles that does not involve active stress. Instead, it is driven by a subtle interplay of inertia, swimmer motility, and concentration fluctuations, through a crucial time lag between the velocity and the concentration field. The resulting time-persistent state seen in our high-resolution numerical simulations consists of self-sustained waves of concentration and orientation, transiting from regular oscillations to wave turbulence. We analyze the statistical features of this active turbulence, including an intriguing connection to the Batchelor spectrum of passive scalars.",
        "comments": "11 pages and 9 figures including supplementary material",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11927"
    },
    {
        "doc_id": 323,
        "title": "Comparison of Model Output Statistics and Neural Networks to Postprocess Wind Gusts",
        "authors": [
            "Cristina Primo Ramos",
            "Benedikt Schulz",
            "Sebastian Lerch",
            "Reinhold Hess"
        ],
        "subjects": [
            "Applications",
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Wind gust prediction plays an important role in warning strategies of national meteorological services due to the high impact of its extreme values. However, forecasting wind gusts is challenging because they are influenced by small-scale processes and local characteristics. To account for the different sources of uncertainty, meteorological centers run ensembles of forecasts and derive probabilities of wind gusts exceeding a threshold. These probabilities often exhibit systematic errors and require postprocessing. Model Output Statistics (MOS) is a common operational postprocessing technique, although more modern methods such as neural network-bases approaches have shown promising results in research studies. The transition from research to operations requires an exhaustive comparison of both techniques. Taking a first step into this direction, our study presents a comparison of a postprocessing technique based on linear and logistic regression approaches with different neural network methods proposed in the literature to improve wind gust predictions, specifically distributional regression networks and Bernstein quantile networks. We further contribute to investigating optimal design choices for neural network-based postprocessing methods regarding changes of the numerical model in the training period, the use of persistence predictors, and the temporal composition of training datasets. The performance of the different techniques is compared in terms of calibration, accuracy, reliability and resolution based on case studies of wind gust forecasts from the operational weather model of the German weather service and observations from 170 weather stations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11896"
    },
    {
        "doc_id": 324,
        "title": "Bootstrap prediction regions for daily curves of electricity demand and price using functional data",
        "authors": [
            "Rebeca Pel\u00e1ez",
            "Germ\u00e1n Aneiros",
            "Juan Vilar"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The aim of this paper is to compute one-day-ahead prediction regions for daily curves of electricity demand and price. Three model-based procedures to construct general prediction regions are proposed, all of them using bootstrap algorithms. The first proposed method considers any $L_p$ norm for functional data to measure the distance between curves, the second one is designed to take different variabilities along the curve into account, and the third one takes advantage of the notion of depth of a functional data. The regression model with functional response on which our proposed prediction regions are based is rather general: it allows to include both endogenous and exogenous functional variables, as well as exogenous scalar variables; in addition, the effect of such variables on the response one is modeled in a parametric, nonparametric or semi-parametric way. A comparative study is carried out to analyse the performance of these prediction regions for the electricity market of mainland Spain, in year 2012. This work extends and complements the methods and results in Aneiros et al. (2016) (focused on curve prediction) and Vilar et al. (2018) (focused on prediction intervals), which use the same database as here.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11885"
    },
    {
        "doc_id": 325,
        "title": "A theoretical framework for BL Her stars -- II. New period-luminosity relations in the Gaia passbands",
        "authors": [
            "Susmita Das",
            "L\u00e1szl\u00f3 Moln\u00e1r",
            "Shashi M. Kanbur",
            "Meridith Joyce",
            "Anupam Bhardwaj",
            "Harinder P. Singh",
            "Marcella Marconi",
            "Vincenzo Ripepi",
            "Radoslaw Smolec"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "We present new theoretical period-luminosity (PL) and period-Wesenheit (PW) relations for a fine grid of convective BL Her, the shortest period T2Cs, models computed using MESA-RSP and compare our results with the empirical relations from Gaia DR3. We use the state-of-the-art 1D non-linear radial stellar pulsation tool MESA-RSP to compute models of BL Her stars over a wide range of input parameters - metallicity (-2.0 dex $\\leq$ [Fe/H] $\\leq$ 0.0 dex), stellar mass (0.5M$_{\\odot}$-0.8M$_{\\odot}$), stellar luminosity (50L$_{\\odot}$-300L$_{\\odot}$) and effective temperature (full extent of the instability strip; in steps of 50K). The BL Her stars in the All Sky region exhibit statistically different PL slopes compared to the theoretical PL slopes computed using the four sets of convection parameters. We find the empirical PL and PW slopes from BL Her stars in the Magellanic Clouds to be statistically consistent with the theoretical relations computed using the different convection parameter sets in the Gaia passbands. There is negligible effect of metallicity on the PL relations in the individual Gaia passbands. However, there exists a small but significant negative coefficient of metallicity in the PWZ relations for the BL Her models using the four sets of convection parameters. This could be attributed to the increased sensitivity of bolometric corrections to metallicities at wavelengths shorter than the V band. Our BL Her models also suggest a dependence of the mass-luminosity relation on metallicity. We found the observed Fourier parameter space to be covered well by our models. Higher mass models (> 0.6M$_{\\odot}$) may be needed to reliably model the observed light curves of BL Her stars in the All Sky region. We also found the theoretical light curve structures (especially the Fourier amplitude parameters) to be affected by the choice of convection parameters.",
        "comments": "19 pages, 8 figures, accepted in Astronomy & Astrophysics",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11869"
    },
    {
        "doc_id": 326,
        "title": "Fast measurement of group index variation with ultimate precision using Hong-Ou-Mandel interferometry",
        "authors": [
            "Sandeep Singh",
            "Vimlesh Kumar",
            "G. K. Samanta"
        ],
        "subjects": [
            "Quantum Physics",
            "Optics"
        ],
        "abstract": "Hong-Ou-Mandel (HOM) interferometry has emerged as a valuable tool for quantum sensing applications, particularly in measuring physical parameters that influence the relative optical delay between pair photons. Unlike classical techniques, HOM-based quantum sensors offer higher resolution due to their intrinsic dispersion cancellation property. Despite this advantage, achieving precise measurements of optical delay crucial for practical applications often involves time-consuming integration and post-processing with traditional statistical methods. To address this challenge, our recent work focused on optimizing optical delay measurements in a time-efficient manner. By carefully selecting the length of a 1 mm periodically-poled KTP (PPKTP) crystal for pair photon generation, we achieved a remarkable group index measurement precision of $\\sim 6.75\\times 10^{-6}$ per centimeter of sample length, surpassing the previous maximum precision by over 400$\\%$. These current measurements maintain fast detection and high photon counts, which are essential for practical quantum sensing applications. The HOM-based method, while limiting the measurement range, can be extended by compensating for photon delay using an optical delay stage. As a proof-of-principle, we measured the group index variation of PPKTP over a temperature range up to 200$^{\\circ}$C with a precision in the range of one part per million ($\\sim$10$^{-6}$). This advancement not only contributes to quantum sensing but also holds promising implications for high-precision and long-range measurements in quantum optical coherence tomography.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11853"
    },
    {
        "doc_id": 327,
        "title": "Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials",
        "authors": [
            "Valentine Perrin",
            "Nathan Noiry",
            "Nicolas Loiseau",
            "Alex Nowak"
        ],
        "subjects": [
            "Methodology",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "Non-significant randomized control trials can hide subgroups of good responders to experimental drugs, thus hindering subsequent development. Identifying such heterogeneous treatment effects is key for precision medicine and many post-hoc analysis methods have been developed for that purpose. While several benchmarks have been carried out to identify the strengths and weaknesses of these methods, notably for binary and continuous endpoints, similar systematic empirical evaluation of subgroup analysis for time-to-event endpoints are lacking. This work aims to fill this gap by evaluating several subgroup analysis algorithms in the context of time-to-event outcomes, by means of three different research questions: Is there heterogeneity? What are the biomarkers responsible for such heterogeneity? Who are the good responders to treatment? In this context, we propose a new synthetic and semi-synthetic data generation process that allows one to explore a wide range of heterogeneity scenarios with precise control on the level of heterogeneity. We provide an open source Python package, available on Github, containing our generation process and our comprehensive benchmark framework. We hope this package will be useful to the research community for future investigations of heterogeneity of treatment effects and subgroup analysis methods benchmarking.",
        "comments": "9 pages, 8 figures, 2 tables. Code available at: https://github.com/owkin/hte. Comments are welcome!",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11842"
    },
    {
        "doc_id": 328,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 329,
        "title": "NSPT for $O(N)$ non-linear sigma model: the larger $N$ the better",
        "authors": [
            "Paolo Baglioni",
            "Francesco Di Renzo"
        ],
        "subjects": [
            "High Energy Physics - Lattice"
        ],
        "abstract": "The $O(N)$ non-linear sigma model (NLSM) is an example of field theory on a target space with nontrivial geometry. One interesting feature of NLSM is asymptotic freedom, which makes perturbative calculations interesting. Given the successes in Lattice Gauge Theories, Numerical Stochastic Perturbation Theory (NSPT) is a natural candidate for performing high-order computations also in the case of NLSM. However, in low-dimensional systems NSPT is known to display statistical fluctuations substantially increasing for increasing orders. In this work, we explore how for $O(N)$ NLSM this behaviour is strongly dependent on $N$. As largely expected on general grounds, the larger is $N$, the larger is the order at which a NSPT computation can be effectively performed.",
        "comments": "Proceedings of the 40th International Symposium on Lattice Field Theory (Lattice 2023), July 31st - August 4th, 2023, Fermilab, Batavia, Illinois, USA",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11833"
    },
    {
        "doc_id": 330,
        "title": "A Fair Evaluation of Various Deep Learning-Based Document Image Binarization Approaches",
        "authors": [
            "Richin Sukesh",
            "Mathias Seuret",
            "Anguelos Nicolaou",
            "Martin Mayr",
            "Vincent Christlein"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Binarization of document images is an important pre-processing step in the field of document analysis. Traditional image binarization techniques usually rely on histograms or local statistics to identify a valid threshold to differentiate between different aspects of the image. Deep learning techniques are able to generate binarized versions of the images by learning context-dependent features that are less error-prone to degradation typically occurring in document images. In recent years, many deep learning-based methods have been developed for document binarization. But which one to choose? There have been no studies that compare these methods rigorously. Therefore, this work focuses on the evaluation of different deep learning-based methods under the same evaluation protocol. We evaluate them on different Document Image Binarization Contest (DIBCO) datasets and obtain very heterogeneous results. We show that the DE-GAN model was able to perform better compared to other models when evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on the DIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset while SauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we make the code, all models and evaluation publicly available (https://github.com/RichSu95/Document_Binarization_Collection) to ensure reproducibility and simplify future binarization evaluations.",
        "comments": "DAS 2022",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11831"
    },
    {
        "doc_id": 331,
        "title": "Flexible Models for Simple Longitudinal Data",
        "authors": [
            "Helen Ogden"
        ],
        "subjects": [
            "Methodology",
            "Applications"
        ],
        "abstract": "We propose a new method for estimating subject-specific mean functions from longitudinal data. We aim to do this in a flexible manner (without restrictive assumptions about the shape of the subject-specific mean functions), while exploiting similarities in the mean functions between different subjects. Functional principal components analysis fulfils both requirements, and methods for functional principal components analysis have been developed for longitudinal data. However, we find that these existing methods sometimes give fitted mean functions which are more complex than needed to provide a good fit to the data. We develop a new penalised likelihood approach to flexibly model longitudinal data, with a penalty term to control the balance between fit to the data and smoothness of the subject-specific mean curves. We run simulation studies to demonstrate that the new method substantially improves the quality of inference relative to existing methods across a range of examples, and apply the method to data on changes in body composition in adolescent girls.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11827"
    },
    {
        "doc_id": 332,
        "title": "On the importance of factorization for fast binned likelihood inference",
        "authors": [
            "C\u00e9sar",
            "Jes\u00fas-Valls"
        ],
        "subjects": [
            "High Energy Physics - Experiment"
        ],
        "abstract": "Likelihood-based inference, central in modern particle physics data analysis requires the extensive evaluation of a likelihood function that depends on set of parameters defined by the statistical model under consideration. If an analytical expression for the likelihood can be defined from first principles the procedure is computationally straightforward. However, most experiments require approximating the likelihood numerically using large statistical samples of synthetic events generated using Monte Carlo methods. As a result, the likelihood consists of a comparison of the expected versus the observed event rates in a collection of histogram bins, defining binned likelihood functions. When this occurs, evaluating the likelihood function involves, on each occasion, recalculating the prediction in those bins, increasing the computational load of these analysis drastically. In this text, I highlight the importance of identifying which are the unique event configurations in the binned likelihood definition and I provide an exact formula to update the event rate predictions utilizing the minimum number of necessary calculations by means of factorization. The aim of the discussion is to decrease the computational load of widespread high-energy physics analyses, leading to substantial speed improvements and reduced carbon footprints.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11806"
    },
    {
        "doc_id": 333,
        "title": "Regression Copulas for Multivariate Responses",
        "authors": [
            "Nadja Klein",
            "Michael Stanley Smith",
            "David Nott",
            "Ryan Chrisholm"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "We propose a novel distributional regression model for a multivariate response vector based on a copula process over the covariate space. It uses the implicit copula of a Gaussian multivariate regression, which we call a ``regression copula''. To allow for large covariate vectors their coefficients are regularized using a novel multivariate extension of the horseshoe prior. Bayesian inference and distributional predictions are evaluated using efficient variational inference methods, allowing application to large datasets. An advantage of the approach is that the marginal distributions of the response vector can be estimated separately and accurately, resulting in predictive distributions that are marginally-calibrated. Two substantive applications of the methodology highlight its efficacy in multivariate modeling. The first is the econometric modeling and prediction of half-hourly regional Australian electricity prices. Here, our approach produces more accurate distributional forecasts than leading benchmark methods. The second is the evaluation of multivariate posteriors in likelihood-free inference (LFI) of a model for tree species abundance data, extending a previous univariate regression copula LFI method. In both applications, we demonstrate that our new approach exhibits a desirable marginal calibration property.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11804"
    },
    {
        "doc_id": 334,
        "title": "Stein EWMA Control Charts for Count Processes",
        "authors": [
            "Christian H. Wei\u00df"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The monitoring of serially independent or autocorrelated count processes is considered, having a Poisson or (negative) binomial marginal distribution under in-control conditions. Utilizing the corresponding Stein identities, exponentially weighted moving-average (EWMA) control charts are constructed, which can be flexibly adapted to uncover zero inflation, over- or underdispersion. The proposed Stein EWMA charts' performance is investigated by simulations, and their usefulness is demonstrated by a real-world data example from health surveillance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11789"
    },
    {
        "doc_id": 335,
        "title": "Very High-Energy ($>$50 GeV) Gamma-ray Flux Variability of Bright Fermi Blazars",
        "authors": [
            "Vaidehi S. Paliya"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Understanding the high-energy emission processes and variability patterns are two of the most challenging research problems associated with relativistic jets. In particular, the long-term (months-to-years) flux variability at very high energies (VHE, $>$50 GeV) has remained an unexplored domain so far. This is possibly due to the decreased sensitivity of the Fermi Large Area Telescope (LAT) above a few GeV, hence low photon statistics, and observing constraints associated with the ground-based Cherenkov telescopes. This paper reports the results obtained from the 0.05$-$2 TeV Fermi-LAT data analysis of a sample of 29 blazars with the primary objective to explore their months-to-year long VHE flux variability behavior. This systematic search has led to, for the first time, the detection of significant flux variations in 5 blazars at $>$99\\% confidence level, whereas, 8 of them exhibit variability albeit at a lower confidence level ($\\sim$95\\%-99\\%). A comparison of the 0.05$-$2 TeV flux variations with that observed at 0.1$-$50 GeV band has revealed similar variability behavior for most of the sources. However, complex variability patterns that are not reflected contemporaneously in both energy bands were also detected, thereby providing tantalizing clues about the underlying radiative mechanisms. These results open up a new dimension to unravel the VHE emission processes operating in relativistic jets, hence sowing the seeds for their future observations with the upcoming Cherenkov Telescope Array.",
        "comments": "ApJ, in press",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11762"
    },
    {
        "doc_id": 336,
        "title": "Texture Identification in Liquid Crystal-Protein Droplets using Evaporative Drying, Generalized Additive Modeling, and K-means Clustering",
        "authors": [
            "Anusuya Pal",
            "Amalesh Gope"
        ],
        "subjects": [
            "Soft Condensed Matter"
        ],
        "abstract": "Sessile drying droplets manifest distinct morphological patterns, encompassing diverse systems viz., DNA, proteins, blood, and protein-liquid crystal (LC) complexes. This study employs an integrated methodology that combines drying droplet, image texture analysis (features from First Order Statistics, Gray Level Co-occurrence Matrix, Gray Level Run Length Matrix, Gray Level Size Zone Matrix, and Gray Level Dependence Matrix), and statistical data analysis (Generalized Additive Modeling and K-means clustering). It provides a comprehensive qualitative and quantitative exploration by examining LC-protein droplets at varying initial phosphate buffered concentrations (0x, 0.25x, 0.5x, 0.75x, and 1x) during the drying process under optical microscopy with crossed polarizing configuration. Notably, it unveils distinct LC-protein textures across three drying stages: initial, middle, and final. The Generalized Additive Modeling (GAM) reveals that all the features significantly contribute to differentiating LC-protein droplets. Integrating the K-means clustering method with GAM analysis elucidates how textures evolve through the three drying stages compared to the entire drying process. Notably, the final drying stage stands out with well-defined, non-overlapping clusters, supporting the visual observations of unique LC textures. Furthermore, this paper contributes valuable insights, showcasing the efficacy of drying droplets as a rapid and straightforward tool for characterizing and classifying dynamic LC textures.",
        "comments": "23 pages, 5 figures, and 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11745"
    },
    {
        "doc_id": 337,
        "title": "Knowledge Navigation: Inferring the Interlocking Map of Knowledge from Research Trajectories",
        "authors": [
            "Shibing Xiang",
            "Bing Liu",
            "Yurui Huang",
            "Chaolin Tian",
            "Xin Jiang",
            "Yifang Ma"
        ],
        "subjects": [
            "Information Retrieval",
            "Digital Libraries",
            "Applications"
        ],
        "abstract": "\"If I have seen further, it is by standing on the shoulders of giants,\" Isaac Newton's renowned statement hints that new knowledge builds upon existing foundations, which means there exists an interdependent relationship between knowledge, which, yet uncovered, is implied in the historical development of scientific systems for hundreds of years. By leveraging natural language processing techniques, this study introduces an innovative embedding scheme designed to infer the \"knowledge interlocking map.\" This map, derived from the research trajectories of millions of scholars, reveals the intricate connections among knowledge. We validate that the inferred map effectively delineates disciplinary boundaries and captures the intricate relationships between diverse concepts. The utility of the interlocking map is showcased through multiple applications. Firstly, we demonstrated the multi-step analogy inferences within the knowledge space and the functional connectivity between concepts in different disciplines. Secondly, we trace the evolution of knowledge across domains, observing trends such as shifts from \"Theoretical\" to \"Applied\" or \"Chemistry\" to \"Biomedical\" along predefined functional directions. Lastly, by analyzing the high-dimensional knowledge network structure, we found that knowledge connects each other with shorter global pathways, and the interdisciplinary knowledge plays a critical role in accessibility of the global knowledge network. Our framework offers a novel approach to mining knowledge inheritance pathways in extensive scientific literature, which is of great significance for understanding scientific development patterns, tailoring scientific learning trajectories, and accelerating scientific progress.",
        "comments": "28 pages, 9 figures, 5 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11742"
    },
    {
        "doc_id": 338,
        "title": "The Bayes factor surface for searches for new physics",
        "authors": [
            "Andrew Fowlie"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Cosmology and Nongalactic Astrophysics",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "The Bayes factor surface is a new way to present results from experimental searches for new physics. Searches are regularly expressed in terms of phenomenological parameters - such as the mass and cross-section of a weakly interacting massive particle. Bayes factor surfaces indicate the strength of evidence for or against models relative to the background only model in terms of the phenomenological parameters that they predict. They provide a clear and direct measure of evidence, may be easily reinterpreted, but do not depend on choices of prior or parameterization. We demonstrate the Bayes factor surface with examples from dark matter, cosmology, and collider physics.",
        "comments": "15 pages, 5 figures, comments welcome",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11710"
    },
    {
        "doc_id": 339,
        "title": "Simulating Nighttime Visible Satellite Imagery of Tropical Cyclones Using Conditional Generative Adversarial Networks",
        "authors": [
            "Jinghuai Yao",
            "Puyuan Du",
            "Yucheng Zhao",
            "Yubo Wang"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics",
            "Machine Learning"
        ],
        "abstract": "Visible (VIS) imagery of satellites has various important applications in meteorology, including monitoring Tropical Cyclones (TCs). However, it is unavailable at night because of the lack of sunlight. This study presents a Conditional Generative Adversarial Networks (CGAN) model that generates highly accurate nighttime visible reflectance using infrared (IR) bands and sunlight direction parameters as input. The model was trained and validated using target area observations of the Advanced Himawari Imager (AHI) in the daytime. This study also presents the first nighttime model validation using the Day/Night Band (DNB) of the Visible/Infrared Imager Radiometer Suite (VIIRS). The daytime statistical results of the Structural Similarity Index Measure (SSIM), Peak Signal-to-Noise Ratio (PSNR), Root Mean Square Error (RMSE), Correlation Coefficient (CC), and Bias are 0.885, 28.3, 0.0428, 0.984, and -0.0016 respectively, completely surpassing the model performance of previous studies. The nighttime statistical results of SSIM, PSNR, RMSE, and CC are 0.821, 24.4, 0.0643, and 0.969 respectively, which are slightly negatively impacted by the parallax between satellites. We performed full-disk model validation which proves our model could also be readily applied in the tropical ocean without TCs in the northern hemisphere. This model contributes to the nighttime monitoring of meteorological phenomena by providing accurate AI-generated visible imagery with adjustable virtual sunlight directions.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11679"
    },
    {
        "doc_id": 340,
        "title": "Asymptotic distribution of spiked eigenvalues in the large signal-plus-noise models",
        "authors": [
            "Zeqin Lin",
            "Guangming Pan",
            "Peng Zhao",
            "Jia Zhou"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Consider large signal-plus-noise data matrices of the form $S + \u03a3^{1/2} X$, where $S$ is a low-rank deterministic signal matrix and the noise covariance matrix $\u03a3$ can be anisotropic. We establish the asymptotic joint distribution of its spiked singular values when the dimensionality and sample size are comparably large and the signals are supercritical under general assumptions concerning the structure of $(S, \u03a3)$ and the distribution of the random noise $X$. It turns out that the asymptotic distributions exhibit nonuniversality in the sense of dependence on the distributions of the entries of $X$, which contrasts with what has previously been established for the spiked sample eigenvalues in the context of spiked population models. Such a result yields the asymptotic distribution of the sample spiked eigenvalues associated with mixture models. We also explore the application of these findings in detecting mean heterogeneity of data matrices.",
        "comments": "59 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11672"
    },
    {
        "doc_id": 341,
        "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
        "authors": [
            "Haoyang Zheng",
            "Wei Deng",
            "Christian Moya",
            "Guang Lin"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde O}(\\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.",
        "comments": "50 pages, 1 figure, to appear in AISTATS 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11665"
    },
    {
        "doc_id": 342,
        "title": "Nonparametric Estimation via Variance-Reduced Sketching",
        "authors": [
            "Yuehaw Khoo",
            "Yifan Peng",
            "Daren Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "Nonparametric models are of great interest in various scientific and engineering disciplines. Classical kernel methods, while numerically robust and statistically sound in low-dimensional settings, become inadequate in higher-dimensional settings due to the curse of dimensionality. In this paper, we introduce a new framework called Variance-Reduced Sketching (VRS), specifically designed to estimate density functions and nonparametric regression functions in higher dimensions with a reduced curse of dimensionality. Our framework conceptualizes multivariable functions as infinite-size matrices, and facilitates a new sketching technique motivated by numerical linear algebra literature to reduce the variance in estimation problems. We demonstrate the robust numerical performance of VRS through a series of simulated experiments and real-world data applications. Notably, VRS shows remarkable improvement over existing neural network estimators and classical kernel methods in numerous density estimation and nonparametric regression models. Additionally, we offer theoretical justifications for VRS to support its ability to deliver nonparametric estimation with a reduced curse of dimensionality.",
        "comments": "64 pages, 8 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11646"
    },
    {
        "doc_id": 343,
        "title": "Efficient PSF Modeling with ShOpt.jl: A PSF Benchmarking Study with JWST NIRCam Imaging",
        "authors": [
            "Edward Berman",
            "Jacqueline McCleary",
            "Anton M. Koekemoer",
            "Maximilien Franco",
            "Nicole E. Drakos",
            "Daizhong Liu",
            "James W. Nightingale",
            "Marko Shuntov",
            "Diana Scognamiglio",
            "Richard Massey",
            "Guillaume Mahler",
            "Henry Joy McCracken",
            "Brant E. Robertson",
            "Andreas L. Faisst Caitlin M. Casey",
            "Jeyhan S. Kartaltepe"
        ],
        "subjects": [
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "With their high angular resolutions of 30-100 mas, large fields of view, and complex optical systems, imagers on next-generation optical/near-infrared space observatories, such as the Near-Infrared Camera (NIRCam) on the James Webb Space Telescope (JWST), present both new opportunities for science and also new challenges for empirical point spread function (PSF) characterization. In this context, we introduce ShOpt, a new PSF fitting tool developed in Julia and designed to bridge the advanced features of PIFF (PSFs in the Full Field of View) with the computational efficiency of PSFEx (PSF Extractor). Along with ShOpt, we propose a suite of non-parametric statistics suitable for evaluating PSF fit quality in space-based imaging. Our study benchmarks ShOpt against the established PSF fitters PSFEx and PIFF using real and simulated COSMOS-Web Survey imaging. We assess their respective PSF model fidelity with our proposed diagnostic statistics and investigate their computational efficiencies, focusing on their processing speed relative to the complexity and size of the PSF models. Despite being in active development, we find that ShOpt can already achieve PSF model fidelity comparable to PSFEx and PIFF while maintaining competitive processing speeds, constructing PSF models for large NIRCam mosaics within minutes.",
        "comments": "53 pages, 27 figures, submitted to Astronomical Journal",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11625"
    },
    {
        "doc_id": 344,
        "title": "Radiative decays of X(3872) discriminate between the molecular and compact interpretations",
        "authors": [
            "B. Grinstein",
            "L. Maiani",
            "A. D. Polosa"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "Radiative decays X --> psi(1S) + gamma and X --> psi(2S) + gamma might be expected to have a ratio of branching fractions following the phase space volumes ratio. However data suggest the opposite, indicating a value for R=B(X --> psi^prime + gamma) / B(X --> psi +gamma) consistently larger than one. In this paper we present a calculation of R for both a compact Born-Oppenheimer cc-bar q-qbar state and a DD^* molecule. In the former case R~1 or larger is found, a value to be confronted with forthcoming high statistics data analyses. In the molecular picture, with D and D^* mesons described by the universal wave function used by Voloshin, Braaten and Kusunoki, we find that R would be of order 10^-2. A more precise experimental measure would be extremely helpful in clarifying the true nature of the X(3872).",
        "comments": "12 pages, 9 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11623"
    },
    {
        "doc_id": 345,
        "title": "Efficient local linearity regularization to overcome catastrophic overfitting",
        "authors": [
            "Elias Abad Rocamora",
            "Fanghui Liu",
            "Grigorios G. Chrysos",
            "Pablo M. Olmos",
            "Volkan Cevher"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "Catastrophic overfitting (CO) in single-step adversarial training (AT) results in abrupt drops in the adversarial test accuracy (even down to 0%). For models trained with multi-step AT, it has been observed that the loss function behaves locally linearly with respect to the input, this is however lost in single-step AT. To address CO in single-step AT, several methods have been proposed to enforce local linearity of the loss via regularization. However, these regularization terms considerably slow down training due to Double Backpropagation. Instead, in this work, we introduce a regularization term, called ELLE, to mitigate CO effectively and efficiently in classical AT evaluations, as well as some more difficult regimes, e.g., large adversarial perturbations and long training schedules. Our regularization term can be theoretically linked to curvature of the loss function and is computationally cheaper than previous methods by avoiding Double Backpropagation. Our thorough experimental validation demonstrates that our work does not suffer from CO, even in challenging settings where previous works suffer from it. We also notice that adapting our regularization parameter during training (ELLE-A) greatly improves the performance, specially in large $\u03b5$ setups. Our implementation is available in https://github.com/LIONS-EPFL/ELLE .",
        "comments": "Accepted in ICLR 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11618"
    },
    {
        "doc_id": 346,
        "title": "An Interacting Wasserstein Gradient Flow Strategy to Robust Bayesian Inference",
        "authors": [
            "Felipe Igea",
            "Alice Cicirello"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "Model Updating is frequently used in Structural Health Monitoring to determine structures' operating conditions and whether maintenance is required. Data collected by sensors are used to update the values of some initially unknown physics-based model's parameters. Bayesian Inference techniques for model updating require the assumption of a prior distribution. This choice of prior may affect posterior predictions and subsequent decisions on maintenance requirements, specially under the typical case in engineering applications of little informative data. Therefore, understanding how the choice of prior may affect the posterior prediction is of great interest. In this paper, a Robust Bayesian Inference technique evaluates the optimal and worst-case prior in the vicinity of a chosen nominal prior, and their corresponding posteriors. This technique employs an interacting Wasserstein gradient flow formulation. Two numerical case studies are used to showcase the proposed algorithm: a double-banana-posterior and a double beam structure. Optimal and worst-case prior are modelled by specifying an ambiguity set containing any distribution at a statistical distance to the nominal prior, less or equal to the radius. Examples show how particles flow from an initial assumed Gaussian distribution to the optimal worst-case prior distribution that lies inside the defined ambiguity set, and the resulting particles from the approximation to the posterior. The resulting posteriors may be used to yield the lower and upper bounds on subsequent calculations used for decision-making. If the metric used for decision-making is not sensitive to the resulting posteriors, it may be assumed that decisions taken are robust to prior uncertainty.",
        "comments": "Preprint submitted to Data-Centric Engineering",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11607"
    },
    {
        "doc_id": 347,
        "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
        "authors": [
            "Yinuo Ren",
            "Chao Ma",
            "Lexing Ying"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Why do neural networks trained with large learning rates for a longer time often lead to better generalization? In this paper, we delve into this question by examining the relation between training and testing loss in neural networks. Through visualization of these losses, we note that the training trajectory with a large learning rate navigates through the minima manifold of the training loss, finally nearing the neighborhood of the testing loss minimum. Motivated by these findings, we introduce a nonlinear model whose loss landscapes mirror those observed for real neural networks. Upon investigating the training process using SGD on our model, we demonstrate that an extended phase with a large learning rate steers our model towards the minimum norm solution of the training loss, which may achieve near-optimal generalization, thereby affirming the empirically observed benefits of late learning rate decay.",
        "comments": "Accepted by AISTATS 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11600"
    },
    {
        "doc_id": 348,
        "title": "Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis",
        "authors": [
            "Sharu Theresa Jose",
            "Shana Moothedath"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We explore a stochastic contextual linear bandit problem where the agent observes a noisy, corrupted version of the true context through a noise channel with an unknown noise parameter. Our objective is to design an action policy that can approximate\" that of an oracle, which has access to the reward model, the channel parameter, and the predictive distribution of the true context from the observed noisy context. In a Bayesian framework, we introduce a Thompson sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting an information-theoretic analysis, we demonstrate the Bayesian regret of our algorithm concerning the oracle's action policy. We also extend this problem to a scenario where the agent observes the true context with some delay after receiving the reward and show that delayed true contexts lead to lower Bayesian regret. Finally, we empirically demonstrate the performance of the proposed algorithms against baselines.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11565"
    },
    {
        "doc_id": 349,
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "authors": [
            "Pratik Worah"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.\n  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11562"
    },
    {
        "doc_id": 350,
        "title": "Transfer Learning under Covariate Shift: Local $k$-Nearest Neighbours Regression with Heavy-Tailed Design",
        "authors": [
            "Petr Zamolodtchikov",
            "Hanyuan Hang"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Covariate shift is a common transfer learning scenario where the marginal distributions of input variables vary between source and target data while the conditional distribution of the output variable remains consistent. The existing notions describing differences between marginal distributions face limitations in handling scenarios with unbounded support, particularly when the target distribution has a heavier tail. To overcome these challenges, we introduce a new concept called density ratio exponent to quantify the relative decay rates of marginal distributions' tails under covariate shift. Furthermore, we propose the local k-nearest neighbour regressor for transfer learning, which adapts the number of nearest neighbours based on the marginal likelihood of each test sample. From a theoretical perspective, convergence rates with and without supervision information on the target domain are established. Those rates indicate that our estimator achieves faster convergence rates when the density ratio exponent satisfies certain conditions, highlighting the benefits of using density estimation for determining different numbers of nearest neighbours for each test sample. Our contributions enhance the understanding and applicability of transfer learning under covariate shift, especially in scenarios with unbounded support and heavy-tailed distributions.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11554"
    },
    {
        "doc_id": 351,
        "title": "Investigation of triangle counts in graphs evolved by uniform clustering attachment",
        "authors": [
            "N. M. Markovich",
            "M. Vai\u010diulis"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "The clustering attachment model introduced in the paper Bagrow and Brockmann (2013) may be used as an evolution tool of random networks. We propose a new clustering attachment model which can be considered as the limit of the former clustering attachment model as model parameter $\u03b1$ tends to zero. We focus on the study of a total triangle count that is considered in the literature as an important characteristic of the network clustering. It is proved that total triangle count tends to infinity a.s. for the proposed model. Our simulation study is used for the modeling of sequences of triangle counts. It is based on the interpretation of the clustering attachment as a generalized P\u00f3lya-Eggenberger urn model that is introduced here at first time.",
        "comments": "16 pages, 2 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11548"
    },
    {
        "doc_id": 352,
        "title": "A new flexible class of kernel-based tests of independence",
        "authors": [
            "Marija Cupari\u0107",
            "Bruno Ebner",
            "Bojana Milo\u0161evi\u0107"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "Spherical and hyperspherical data are commonly encountered in diverse applied research domains, underscoring the vital task of assessing independence within such data structures. In this context, we investigate the properties of test statistics relying on distance correlation measures originally introduced for the energy distance, and generalize the concept to strongly negative definite kernel-based distances. An important benefit of employing this method lies in its versatility across diverse forms of directional data, enabling the examination of independence among vectors of varying types. The applicability of tests is demonstrated on several real datasets.",
        "comments": "MSC Class:          62H11; 62H15; 62H20",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11540"
    },
    {
        "doc_id": 353,
        "title": "Addressing researcher degrees of freedom through minP adjustment",
        "authors": [
            "Maximilian M Mandl",
            "Andrea S Becker-Pennrich",
            "Ludwig C Hinske",
            "Sabine Hoffmann",
            "Anne-Laure Boulesteix"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "When different researchers study the same research question using the same dataset they may obtain different and potentially even conflicting results. This is because there is often substantial flexibility in researchers' analytical choices, an issue also referred to as ''researcher degrees of freedom''. Combined with selective reporting of the smallest p-value or largest effect, researcher degrees of freedom may lead to an increased rate of false positive and overoptimistic results. In this paper, we address this issue by formalizing the multiplicity of analysis strategies as a multiple testing problem. As the test statistics of different analysis strategies are usually highly dependent, a naive approach such as the Bonferroni correction is inappropriate because it leads to an unacceptable loss of power. Instead, we propose using the ''minP'' adjustment method, which takes potential test dependencies into account and approximates the underlying null distribution of the minimal p-value through a permutation-based procedure. This procedure is known to achieve more power than simpler approaches while ensuring a weak control of the family-wise error rate. We illustrate our approach for addressing researcher degrees of freedom by applying it to a study on the impact of perioperative paO2 on post-operative complications after neurosurgery. A total of 48 analysis strategies are considered and adjusted using the minP procedure. This approach allows to selectively report the result of the analysis strategy yielding the most convincing evidence, while controlling the type 1 error -- and thus the risk of publishing false positive results that may not be replicable.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11537"
    },
    {
        "doc_id": 354,
        "title": "Geometry-driven Bayesian Inference for Ultrametric Covariance Matrices",
        "authors": [
            "Tsung-Hung Yao",
            "Zhenke Wu",
            "Karthik Bharath",
            "Veerabhadran Baladandayuthapani"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Ultrametric matrices arise as covariance matrices in latent tree models for multivariate data with hierarchically correlated components. As a parameter space in a model, the set of ultrametric matrices is neither convex nor a smooth manifold, and focus in literature has hitherto mainly been restricted to estimation through projections and relaxation-based techniques. Leveraging the link between an ultrametric matrix and a rooted tree, we equip the set of ultrametric matrices with a convenient geometry based on the well-known geometry of phylogenetic trees, whose attractive properties (e.g. unique geodesics and Fr\u00e9chet means) the set of ultrametric matrices inherits. This results in a novel representation of an ultrametric matrix by coordinates of the tree space, which we then use to define a class of Markovian and consistent prior distributions on the set of ultrametric matrices in a Bayesian model, and develop an efficient algorithm to sample from the posterior distribution that generates updates by making intrinsic local moves along geodesics within the set of ultrametric matrices. In simulation studies, our proposed algorithm restores the underlying matrices with posterior samples that recover the tree topology with a high frequency of true topology and generate element-wise credible intervals with a high nominal coverage rate. We use the proposed algorithm on the pre-clinical cancer data to investigate the mechanism similarity by constructing the underlying treatment tree and identify treatments with high mechanism similarity also target correlated pathways in biological literature.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11515"
    },
    {
        "doc_id": 355,
        "title": "Topological superconductors in trapped-ion system and their Floquet engineering",
        "authors": [
            "Ming-Jian Gao",
            "Yu-Peng Ma",
            "Jun-Hong An"
        ],
        "subjects": [
            "Quantum Physics",
            "Superconductivity"
        ],
        "abstract": "Obeying non-Abelian statistics, Majorana fermion holds a promise to implement topological quantum computing. It was found that Majorana fermion can be simulated by the zero-energy excitation in a semiconducting nanowire with strong spin-orbit coupling interacting with a $s$-wave superconductor under a magnetic field. We here propose an alternative scheme to simulate the Majorana fermion in a trapped-ion system. Our dimitrized-ion configuration permits us to generate the Majorana modes not only at zero energy but also at the nonzero ones. We also investigate the controllability of the Majorana modes by Floquet engineering. It is found that a widely tunable number of Majorana modes are created on demand by applying a periodic driving on a topologically trivial trapped-ion system. Enriching the platforms for simulating Majorana fermion, our result would open another avenue for realizing topological quantum computing.",
        "comments": "8 pages and 4 figures in the main text and 3 pages in the supplentmental material",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11510"
    },
    {
        "doc_id": 356,
        "title": "Redundant multiple testing corrections: The fallacy of using family-based error rates to make inferences about individual hypotheses",
        "authors": [
            "Mark Rubin"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "During multiple testing, researchers often adjust their alpha level to control the familywise error rate for a statistical inference about a joint union alternative hypothesis (e.g., \"H1 or H2\"). However, in some cases, they do not make this inference and instead make separate inferences about each of the individual hypotheses that comprise the joint hypothesis (e.g., H1 and H2). For example, a researcher might use a Bonferroni correction to adjust their alpha level from the conventional level of 0.050 to 0.025 when testing H1 and H2, find a significant result for H1 (p < 0.025) and not for H2 (p > .0.025), and so claim support for H1 and not for H2. However, these separate individual inferences do not require an alpha adjustment. Only a statistical inference about the union alternative hypothesis \"H1 or H2\" requires an alpha adjustment because it is based on \"at least one\" significant result among the two tests, and so it depends on the familywise error rate. When a researcher corrects their alpha level during multiple testing but does not make an inference about the union alternative hypothesis, their correction is redundant. In the present article, I discuss this redundant correction problem, including its associated loss of statistical power and its potential causes vis-\u00e0-vis error rate confusions and the alpha adjustment ritual. I also provide three illustrations of redundant corrections from recent psychology studies. I conclude that redundant corrections represent a symptom of statisticism, and I call for a more nuanced and context-specific approach to multiple testing corrections.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11507"
    },
    {
        "doc_id": 357,
        "title": "Functional Limit Theorems for Hawkes Processes",
        "authors": [
            "Ulrich Horst",
            "Wei Xu"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritical processes critical ones with heavily dispersed child events display long-range dependencies.",
        "comments": "59 pages; Keywords and phrases: Hawkes process, functional limit theorem, regular variation, convergence rate",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11495"
    },
    {
        "doc_id": 358,
        "title": "Local Identification in the Instrumental Variable Multivariate Quantile Regression Model",
        "authors": [
            "Haruki Kono"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The instrumental variable (IV) quantile regression model introduced by Chernozhukov and Hansen (2005) is a useful tool for analyzing quantile treatment effects in the presence of endogeneity, but when outcome variables are multidimensional, it is silent on the joint distribution of different dimensions of each variable. To overcome this limitation, we propose an IV model built on the optimal-transport-based multivariate quantile that takes into account the correlation between the entries of the outcome variable. We then provide a local identification result for the model. Surprisingly, we find that the support size of the IV required for the identification is independent of the dimension of the outcome vector, as long as the IV is sufficiently informative. Our result follows from a general identification theorem that we establish, which has independent theoretical significance.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11422"
    },
    {
        "doc_id": 359,
        "title": "MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning",
        "authors": [
            "Mao Hong",
            "Zhiyue Zhang",
            "Yue Wu",
            "Yanxun Xu"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "Model-based offline reinforcement learning methods (RL) have achieved state-of-the-art performance in many decision-making problems thanks to their sample efficiency and generalizability. Despite these advancements, existing model-based offline RL approaches either focus on theoretical studies without developing practical algorithms or rely on a restricted parametric policy space, thus not fully leveraging the advantages of an unrestricted policy space inherent to model-based methods. To address this limitation, we develop MoMA, a model-based mirror ascent algorithm with general function approximations under partial coverage of offline data. MoMA distinguishes itself from existing literature by employing an unrestricted policy class. In each iteration, MoMA conservatively estimates the value function by a minimization procedure within a confidence set of transition models in the policy evaluation step, then updates the policy with general function approximations instead of commonly-used parametric policy classes in the policy improvement step. Under some mild assumptions, we establish theoretical guarantees of MoMA by proving an upper bound on the suboptimality of the returned policy. We also provide a practically implementable, approximate version of the algorithm. The effectiveness of MoMA is demonstrated via numerical studies.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11380"
    },
    {
        "doc_id": 360,
        "title": "When exposure affects subgroup membership: Framing relevant causal questions in perinatal epidemiology and beyond",
        "authors": [
            "Shalika Gupta",
            "Laura B. Balzer",
            "Moses R. Kamya",
            "Diane V. Havlir",
            "Maya L. Petersen"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Perinatal epidemiology often aims to evaluate exposures on infant outcomes. When the exposure affects the composition of people who give birth to live infants (e.g., by affecting fertility, behavior, or birth outcomes), this \"live birth process\" mediates the exposure effect on infant outcomes. Causal estimands previously proposed for this setting include the total exposure effect on composite birth and infant outcomes, controlled direct effects (e.g., enforcing birth), and principal stratum direct effects. Using perinatal HIV transmission in the SEARCH Study as a motivating example, we present two alternative causal estimands: 1) conditional total effects; and 2) conditional stochastic direct effects, formulated under a hypothetical intervention to draw mediator values from some distribution (possibly conditional on covariates). The proposed conditional total effect includes impacts of an intervention that operate by changing the types of people who have a live birth and the timing of births. The proposed conditional stochastic direct effects isolate the effect of an exposure on infant outcomes excluding any impacts through this live birth process. In SEARCH, this approach quantifies the impact of a universal testing and treatment intervention on infant HIV-free survival absent any effect of the intervention on the live birth process, within a clearly defined target population of women of reproductive age with HIV at study baseline. Our approach has implications for the evaluation of intervention effects in perinatal epidemiology broadly, and whenever causal effects within a subgroup are of interest and exposure affects membership in the subgroup.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11368"
    },
    {
        "doc_id": 361,
        "title": "Folding Custom Gates with Verifier Input",
        "authors": [
            "Aard Vark",
            "Yan X Zhang"
        ],
        "subjects": [
            "Cryptography and Security",
            "Logic in Computer Science"
        ],
        "abstract": "In the context of interactive proofs, a \"folding scheme\" (popularized by Nova) is a way to combine multiple instances of a constraint system into a single instance, so the validity of the multiple instances can statistically be reduced to the validity of a single one. We show how Nova folding can be generalized to ``custom'' gates and extra rounds of verifier randomness. As an application of this extension, we present Origami, the first (to our knowledge) known example of a folding scheme for lookups.",
        "comments": "MSC Class:          94A60",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11364"
    },
    {
        "doc_id": 362,
        "title": "The Exact Risks of Reference Panel-based Regularized Estimators",
        "authors": [
            "Buxin Su",
            "Qiang Sun",
            "Xiaochen Yang",
            "Bingxin Zhao"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "Reference panel-based estimators have become widely used in genetic prediction of complex traits due to their ability to address data privacy concerns and reduce computational and communication costs. These estimators estimate the covariance matrix of predictors using an external reference panel, instead of relying solely on the original training data. In this paper, we investigate the performance of reference panel-based $L_1$ and $L_2$ regularized estimators within a unified framework based on approximate message passing (AMP). We uncover several key factors that influence the accuracy of reference panel-based estimators, including the sample sizes of the training data and reference panels, the signal-to-noise ratio, the underlying sparsity of the signal, and the covariance matrix among predictors. Our findings reveal that, even when the sample size of the reference panel matches that of the training data, reference panel-based estimators tend to exhibit lower accuracy compared to traditional regularized estimators. Furthermore, we observe that this performance gap widens as the amount of training data increases, highlighting the importance of constructing large-scale reference panels to mitigate this issue. To support our theoretical analysis, we develop a novel non-separable matrix AMP framework capable of handling the complexities introduced by a general covariance matrix and the additional randomness associated with a reference panel. We validate our theoretical results through extensive simulation studies and real data analyses using the UK Biobank database.",
        "comments": "100 pages, 11 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11359"
    },
    {
        "doc_id": 363,
        "title": "Squared Wasserstein-2 Distance for Efficient Reconstruction of Stochastic Differential Equations",
        "authors": [
            "Mingtao Xia",
            "Xiangting Li",
            "Qijing Shen",
            "Tom Chou"
        ],
        "subjects": [
            "Probability",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "We provide an analysis of the squared Wasserstein-2 ($W_2$) distance between two probability distributions associated with two stochastic differential equations (SDEs). Based on this analysis, we propose the use of a squared $W_2$ distance-based loss functions in the \\textit{reconstruction} of SDEs from noisy data. To demonstrate the practicality of our Wasserstein distance-based loss functions, we performed numerical experiments that demonstrate the efficiency of our method in reconstructing SDEs that arise across a number of applications.",
        "comments": "37 pages, 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11354"
    },
    {
        "doc_id": 364,
        "title": "Geometric Insights and Empirical Observations on Covariate Adjustment and Stratified Randomization in Randomized Clinical Trials",
        "authors": [
            "Zhiwei Zhang"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The statistical efficiency of randomized clinical trials can be improved by incorporating information from baseline covariates (i.e., pre-treatment patient characteristics). This can be done in the design stage using a covariate-adaptive randomization scheme such as stratified (permutated block) randomization, or in the analysis stage through covariate adjustment. This article provides a geometric perspective on covariate adjustment and stratified randomization in a unified framework where all regular, asymptotically linear estimators are identified as augmented estimators. From this perspective, covariate adjustment can be viewed as an effort to approximate the optimal augmentation function, and stratified randomization aims to improve a given approximation by projecting it into an affine subspace containing the optimal augmentation function. The efficiency benefit of stratified randomization is asymptotically equivalent to making full use of stratum information in covariate adjustment, which can be achieved using a simple calibration procedure. Simulation results indicate that stratified randomization is clearly beneficial to unadjusted estimators and much less so to adjusted ones and that calibration is an effective way to recover the efficiency benefit of stratified randomization without actually performing stratified randomization. These insights and observations are illustrated using real clinical trial data.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11352"
    },
    {
        "doc_id": 365,
        "title": "Quantum Machine Learning: from NISQ to Fault Tolerance",
        "authors": [
            "Yunfei Wang",
            "Junyu Liu"
        ],
        "subjects": [
            "Quantum Physics",
            "Artificial Intelligence",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.",
        "comments": "28 pages. Invited review",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11351"
    },
    {
        "doc_id": 366,
        "title": "A study of experimental sensitivities to nucleon parton distributions with xFitter",
        "authors": [
            "Lucas Kotz"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "In collider physics, parton distribution functions (PDFs) play a crucial role in computing theoretical cross sections for scattering reactions. This study explores how different experimental data sets influence extracted PDFs in CTEQ-TEA and MSHT NNLO PDF analyses. To gauge the impact of experimental data, including the HERA and ZEUS combined charm and beauty production, LHCb 7 TeV charm and beauty production, and CMS 2.76 TeV W+c production, I utilize the $L_2$ sensitivity in the Hessian framework as a visual representation of their respective impacts. This sensitivity quantifies the statistical pulls on individual data sets against the best-fit PDFs, facilitating the identification of tensions among competing data sets. Using the QCD fitting framework xFitter, I extract the necessary values for plotting $L_2$ sensitivities for eight distinct data sets implemented in the program, employing recent PDF sets from the CTEQ-TEA and MSHT groups. The computed $L_2$ sensitivities estimate the potential impact of the examined data sets.",
        "comments": "11 pages, 11 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11350"
    },
    {
        "doc_id": 367,
        "title": "Optimization of random cost functions and statistical physics",
        "authors": [
            "Andrea Montanari"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks"
        ],
        "abstract": "This is the text of my report presented at the 29th Solvay Conference on Physics on `The Structure and Dynamics of Disordered Systems' held in Bruxelles from October 19 to 21, 2023. I consider the problem of minimizing a random energy function $H(\u03c3)$, where $\u03c3$ is an $N$-dimensional vector, in the high-dimensional regime $N\\gg 1$. Using as a reference point a 1986 paper by Fu and Anderson, I take stock of the progress on this question over the last 40 years. In particular, I focus on the influence and ramifications of ideas originating from statistical physics. My own conclusion is that several of the most fundamental questions in this area (which in 1986 were barely formulated) have now received mathematically rigorous answers, at least in simple -- yet highly nontrivial -- settings. Instrumental to this spectacular progress was the dialogue between different research communities: physics, computer science, mathematics.",
        "comments": "21 pages; 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11348"
    },
    {
        "doc_id": 368,
        "title": "Estimating Default Probability and Correlation using Stan",
        "authors": [
            "Jesus A. Pinera-Esquivel"
        ],
        "subjects": [
            "Applications",
            "Methodology"
        ],
        "abstract": "This work has the objective of estimating default probabilities and correlations of credit portfolios given default rate information through a Bayesian framework using Stan. We use Vasicek's single factor credit model to establish the theoretical framework for the behavior of the default rates, and use NUTS Markov Chain Monte Carlo to estimate the parameters. We compare the Bayesian estimates with classical estimates such as moments estimators and maximum likelihood estimates. We apply the methodology both to simulated data and to corporate default rates, and perform inferences through Bayesian methods in order to exhibit the advantages of such a framework. We perform default forecasting and exhibit the importance of an adequate estimation of default correlations, and exhibit the advantage of using Stan to perform sampling regarding prior choice.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11346"
    },
    {
        "doc_id": 369,
        "title": "Mortality Modelling using Generalized Estimating Equations",
        "authors": [
            "Reza Dastranj",
            "Martin Kolar"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "This paper presents an application of Generalized Estimating Equations (GEE) for analyzing age-specific death rates (ASDRs), constituting a longitudinal dataset with repeated measurements over time. GEE models, known for their robustness in handling correlated data, offer a reliable solution when individual data records lack independence, thus violating the commonly assumed independence and identically distributed (iid) condition in traditional models. In the context of ASDRs, where correlations emerge among observations within age groups, two distinct GEE models for single and multipopulation ASDRs are introduced, providing robust estimates for regression parameters and their variances. We explore correlation structures, encompassing independence, AR(1), unstructured, and exchangeable structures, offering a comprehensive evaluation of GEE model efficiency in both single and multipopulation ASDRs. We critically examines the strengths and limitations of GEE models, shedding light on their applicability for mortality forecasting. Through detailed model specifications and empirical illustrations, the study contributes to an enhanced understanding of the nuanced capabilities of GEE models in predicting mortality rates.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11332"
    },
    {
        "doc_id": 370,
        "title": "A Hierarchical Decision-Based Maintenance for a Complex Modular System Driven by the { MoMA} Algorithm",
        "authors": [
            "M. L. Gamiz",
            "D. Montoro-Cazorla",
            "M. C. Segovia-Garcia"
        ],
        "subjects": [
            "Systems and Control",
            "Methodology"
        ],
        "abstract": "This paper presents a maintenance policy for a modular system formed by K independent modules (n-subsystems) subjected to environmental conditions (shocks). For the modeling of this complex system, the use of the Matrix-Analytical Method (MAM) is proposed under a layered approach according to its hierarchical structure. Thus, the operational state of the system (top layer) depends on the states of the modules (middle layer), which in turn depend on the states of their components (bottom layer). This allows a detailed description of the system operation to plan maintenance actions appropriately and optimally. We propose a hierarchical decision-based maintenance strategy with periodic inspections as follows: at the time of the inspection, the condition of the system is first evaluated. If intervention is necessary, the modules are then checked to make individual decisions based on their states, and so on. Replacement or repair will be carried out as appropriate. An optimization problem is formulated as a function of the length of the inspection period and the intervention cost incurred over the useful life of the system. Our method shows the advantages, providing compact and implementable expressions. The model is illustrated on a submarine Electrical Control Unit (ECU).",
        "comments": "43 pages, 6 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11328"
    },
    {
        "doc_id": 371,
        "title": "Measuring hierarchically-organized interactions in dynamic networks through spectral entropy rates: theory, estimation, and illustrative application to physiological networks",
        "authors": [
            "Laura Sparacino",
            "Yuri Antonacci",
            "Gorana Mijatovic",
            "Luca Faes"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Recent advances in signal processing and information theory are boosting the development of new approaches for the data-driven modelling of complex network systems. In the fields of Network Physiology and Network Neuroscience where the signals of interest are often rich of oscillatory content, the spectral representation of network systems is essential to ascribe the analyzed interactions to specific oscillations with physiological meaning. In this context, the present work formalizes a coherent framework which integrates several information dynamics approaches to quantify node-specific, pairwise and higher-order interactions in network systems. The framework establishes a hierarchical organization of interactions of different order using measures of entropy rate, mutual information rate and O-information rate, to quantify respectively the dynamics of individual nodes, the links between pairs of nodes, and the redundant/synergistic hyperlinks between groups of nodes. All measures are formulated in the time domain, and then expanded to the spectral domain to obtain frequency-specific information. The practical computation of all measures is favored presenting a toolbox that implements their parametric and non-parametric estimation, and includes approaches to assess their statistical significance. The framework is illustrated first using theoretical examples where the properties of the measures are displayed in benchmark simulated network systems, and then applied to representative examples of multivariate time series in the context of Network Neuroscience and Network Physiology.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11327"
    },
    {
        "doc_id": 372,
        "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation",
        "authors": [
            "Nadav Benedek",
            "Lior Wolf"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "With the proliferation of large pre-trained language models (PLMs), fine-tuning all model parameters becomes increasingly inefficient, particularly when dealing with numerous downstream tasks that entail substantial training and storage costs. Several approaches aimed at achieving parameter-efficient fine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA) stands out as an archetypal method, incorporating trainable rank decomposition matrices into each target module. Nevertheless, LoRA does not consider the varying importance of each layer. To address these challenges, we introduce PRILoRA, which linearly allocates a different rank for each layer, in an increasing manner, and performs pruning throughout the training process, considering both the temporary magnitude of weights and the accumulated statistics of the input to any given layer. We validate the effectiveness of PRILoRA through extensive experiments on eight GLUE benchmarks, setting a new state of the art.",
        "comments": "EACL 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11316"
    },
    {
        "doc_id": 373,
        "title": "Weakly-Supervised Semantic Segmentation of Circular-Scan, Synthetic-Aperture-Sonar Imagery",
        "authors": [
            "Isaac J. Sledge",
            "Dominic M. Byrne",
            "Jonathan L. King",
            "Steven H. Ostertag",
            "Denton L. Woods",
            "James L. Prater",
            "Jermaine L. Kennedy",
            "Timothy M. Marston",
            "Jose C. Principe"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Image and Video Processing"
        ],
        "abstract": "We propose a weakly-supervised framework for the semantic segmentation of circular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our framework is trained in a supervised manner, on image-level labels, to uncover a set of semi-sparse, spatially-discriminative regions in each image. The classification uncertainty of each region is then evaluated. Those areas with the lowest uncertainties are then chosen to be weakly labeled segmentation seeds, at the pixel level, for the second part of the framework. Each of the seed extents are progressively resized according to an unsupervised, information-theoretic loss with structured-prediction regularizers. This reshaping process uses multi-scale, adaptively-weighted features to delineate class-specific transitions in local image content. Content-addressable memories are inserted at various parts of our framework so that it can leverage features from previously seen images to improve segmentation performance for related images.\n  We evaluate our weakly-supervised framework using real-world CSAS imagery that contains over ten seafloor classes and ten target classes. We show that our framework performs comparably to nine fully-supervised deep networks. Our framework also outperforms eleven of the best weakly-supervised deep networks. We achieve state-of-the-art performance when pre-training on natural imagery. The average absolute performance gap to the next-best weakly-supervised network is well over ten percent for both natural imagery and sonar imagery. This gap is found to be statistically significant.",
        "comments": "Submitted to the IEEE Journal of Oceanic Engineering",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11313"
    },
    {
        "doc_id": 374,
        "title": "Handling incomplete outcomes and covariates in cluster-randomized trials: doubly-robust estimation, efficiency considerations, and sensitivity analysis",
        "authors": [
            "Bingkai Wang",
            "Fan Li",
            "Rui Wang"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In cluster-randomized trials, missing data can occur in various ways, including missing values in outcomes and baseline covariates at the individual or cluster level, or completely missing information for non-participants. Among the various types of missing data in CRTs, missing outcomes have attracted the most attention. However, no existing method comprehensively addresses all the aforementioned types of missing data simultaneously due to their complexity. This gap in methodology may lead to confusion and potential pitfalls in the analysis of CRTs. In this article, we propose a doubly-robust estimator for a variety of estimands that simultaneously handles missing outcomes under a missing-at-random assumption, missing covariates with the missing-indicator method (with no constraint on missing covariate distributions), and missing cluster-population sizes via a uniform sampling framework. Furthermore, we provide three approaches to improve precision by choosing the optimal weights for intracluster correlation, leveraging machine learning, and modeling the propensity score for treatment assignment. To evaluate the impact of violated missing data assumptions, we additionally propose a sensitivity analysis that measures when missing data alter the conclusion of treatment effect estimation. Simulation studies and data applications both show that our proposed method is valid and superior to the existing methods.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11278"
    },
    {
        "doc_id": 375,
        "title": "Asymptotics for non-degenerate multivariate $U$-statistics with estimated nuisance parameters under the null and local alternative hypotheses",
        "authors": [
            "Alain Desgagn\u00e9",
            "Christian Genest",
            "Fr\u00e9d\u00e9ric Ouimet"
        ],
        "subjects": [
            "Statistics Theory",
            "Probability",
            "Applications",
            "Methodology"
        ],
        "abstract": "The large-sample behavior of non-degenerate multivariate $U$-statistics of arbitrary degree is investigated under the assumption that their kernel depends on parameters that can be estimated consistently. Mild regularity conditions are given which guarantee that once properly normalized, such statistics are asymptotically multivariate Gaussian both under the null hypothesis and sequences of local alternatives. The work of Randles (1982, Ann. Statist.) is extended in three ways: the data and the kernel values can be multivariate rather than univariate, the limiting behavior under local alternatives is studied for the first time, and the effect of knowing some of the nuisance parameters is quantified. These results can be applied to a broad range of goodness-of-fit testing contexts, as shown in one specific example.",
        "comments": "16 pages, 1 figure",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11272"
    },
    {
        "doc_id": 376,
        "title": "Assessing the Competitiveness of Matrix-Free Block Likelihood Estimation in Spatial Models",
        "authors": [
            "Alfredo Alegr\u00eda"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "In geostatistics, block likelihood offers a balance between statistical accuracy and computational efficiency when estimating covariance functions. This balance is reached by dividing the sample into blocks and computing a weighted sum of (sub) log-likelihoods corresponding to pairs of blocks. Practitioners often choose block sizes ranging from hundreds to a few thousand observations, inherently involving matrix-based implementations. An alternative, residing at the opposite end of this methodological spectrum, treats each observation as a block, resulting in the matrix-free pairwise likelihood method. We propose an additional alternative within this broad methodological landscape, systematically constructing blocks of size two and merging pairs of blocks through conditioning. Importantly, our method strategically avoids large-sized blocks, facilitating explicit calculations that ultimately do not rely on matrix computations. Studies with both simulated and real data validate the effectiveness of our approach, on one hand demonstrating its superiority over pairwise likelihood, and on the other, challenging the intuitive notion that employing matrix-based versions universally lead to better statistical performance.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11265"
    },
    {
        "doc_id": 377,
        "title": "Adaptive Bayesian Optimization Algorithm for Unpredictable Business Environments",
        "authors": [
            "Sarit Maitra"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This paper presents an innovative optimization framework and algorithm based on the Bayes theorem, featuring adaptive conditioning and jitter. The adaptive conditioning function dynamically modifies the mean objective function in each iteration, enhancing its adaptability. The mean function, representing the model's best estimate of the optimal value for the true objective function, is adjusted based on observed data. The framework also incorporates an adaptive acquisition jitter function, enhancing adaptability by adjusting the jitter of the acquisition function. It also introduces a robust objective function with a penalty term, aiming to generate robust solutions under uncertainty. The evaluation of the framework includes single-objective, decoupled multi-objective, and combined multi-objective functions. Statistical analyses, including t-statistics, p-values, and effect size measures, highlight the superiority of the proposed framework over the original Bayes optimization. The adaptive nature of the conditioning function allows the algorithm to seamlessly incorporate new data, making it particularly beneficial in dynamic optimization scenarios.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11264"
    },
    {
        "doc_id": 378,
        "title": "Estimating heterogeneous treatment effect from survival outcomes via (orthogonal) censoring unbiased learning",
        "authors": [
            "Shenbo Xu",
            "Raluca Cobzaru",
            "Bang Zheng",
            "Stan N. Finkelstein",
            "Roy E. Welsch",
            "Kenney Ng",
            "Ioanna Tzoulaki",
            "Zach Shahn"
        ],
        "subjects": [
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "Methods for estimating heterogeneous treatment effects (HTE) from observational data have largely focused on continuous or binary outcomes, with less attention paid to survival outcomes and almost none to settings with competing risks. In this work, we develop censoring unbiased transformations (CUTs) for survival outcomes both with and without competing risks.After converting time-to-event outcomes using these CUTs, direct application of HTE learners for continuous outcomes yields consistent estimates of heterogeneous cumulative incidence effects, total effects, and separable direct effects. Our CUTs enable application of a much larger set of state of the art HTE learners for censored outcomes than had previously been available, especially in competing risks settings. We provide generic model-free learner-specific oracle inequalities bounding the finite-sample excess risk. The oracle efficiency results depend on the oracle selector and estimated nuisance functions from all steps involved in the transformation. We demonstrate the empirical performance of the proposed methods in simulation studies.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11263"
    },
    {
        "doc_id": 379,
        "title": "Maximum Likelihood Estimators of Quantum Probabilities",
        "authors": [
            "Mirko Navara",
            "Jan \u0160evic"
        ],
        "subjects": [
            "Quantum Physics",
            "Statistics Theory"
        ],
        "abstract": "Classical probability theory is based on assumptions which are often violated in practice. Therefore quantum probability is a proposed alternative not only in quantum physics, but also in other sciences. However, so far it mostly criticizes the classical approach, but does not suggest a working alternative. Maximum likelihood estimators were given very low attention in this context. We show that they can be correctly defined and their computation in closed form is feasible at least in some cases.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11253"
    },
    {
        "doc_id": 380,
        "title": "AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking",
        "authors": [
            "Mehmet Y. Turali",
            "Mehmet E. Lorasdagi",
            "Ali T. Koc",
            "Suleyman S. Kozat"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Machine Learning"
        ],
        "abstract": "We study the problem of feature selection in general machine learning (ML) context, which is one of the most critical subjects in the field. Although, there exist many feature selection methods, however, these methods face challenges such as scalability, managing high-dimensional data, dealing with correlated features, adapting to variable feature importance, and integrating domain knowledge. To this end, we introduce the ``Adaptive Feature Selection with Binary Masking\" (AFS-BM) which remedies these problems. AFS-BM achieves this by joint optimization for simultaneous feature selection and model training. In particular, we do the joint optimization and binary masking to continuously adapt the set of features and model parameters during the training process. This approach leads to significant improvements in model accuracy and a reduction in computational requirements. We provide an extensive set of experiments where we compare AFS-BM with the established feature selection methods using well-known datasets from real-life competitions. Our results show that AFS-BM makes significant improvement in terms of accuracy and requires significantly less computational complexity. This is due to AFS-BM's ability to dynamically adjust to the changing importance of features during the training process, which an important contribution to the field. We openly share our code for the replicability of our results and to facilitate further research.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11250"
    },
    {
        "doc_id": 381,
        "title": "Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI",
        "authors": [
            "Alex Zarifis",
            "Peter Kawalek",
            "Aida Azadegan"
        ],
        "subjects": [
            "Computers and Society",
            "Artificial Intelligence"
        ],
        "abstract": "Trust and privacy have emerged as significant concerns in online transactions. Sharing information on health is especially sensitive but it is necessary for purchasing and utilizing health insurance. Evidence shows that consumers are increasingly comfortable with technology in place of humans, but the expanding use of AI potentially changes this. This research explores whether trust and privacy concern are barriers to the adoption of AI in health insurance. Two scenarios are compared: The first scenario has limited AI that is not in the interface and its presence is not explicitly revealed to the consumer. In the second scenario there is an AI interface and AI evaluation, and this is explicitly revealed to the consumer. The two scenarios were modeled and compared using SEM PLS-MGA. The findings show that trust is significantly lower in the second scenario where AI is visible. Privacy concerns are higher with AI but the difference is not statistically significant within the model.",
        "comments": "Journal of Internet Commerce (2021)",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11249"
    },
    {
        "doc_id": 382,
        "title": "Estimation with Pairwise Observations",
        "authors": [
            "Felix Chan",
            "Laszlo Matyas"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The paper introduces a new estimation method for the standard linear regression model. The procedure is not driven by the optimisation of any objective function rather, it is a simple weighted average of slopes from observation pairs. The paper shows that such estimator is consistent for carefully selected weights. Other properties, such as asymptotic distributions, have also been derived to facilitate valid statistical inference. Unlike traditional methods, such as Least Squares and Maximum Likelihood, among others, the estimated residual of this estimator is not by construction orthogonal to the explanatory variables of the model. This property allows a wide range of practical applications, such as the testing of endogeneity, i.e.,the correlation between the explanatory variables and the disturbance terms, and potentially several others.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11229"
    },
    {
        "doc_id": 383,
        "title": "On the Information Leakage Performance of Secure Finite Blocklength Transmissions over Rayleigh Fading Channels",
        "authors": [
            "Milad Tatar Mamaghani",
            "Xiangyun Zhou",
            "Nan Yang",
            "A. Lee Swindlehurst",
            "H. Vincent Poor"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "This paper presents a secrecy performance study of a wiretap communication system with finite blocklength (FBL) transmissions over Rayleigh fading channels, based on the definition of an average information leakage (AIL) metric. We evaluate the exact and closed-form approximate AIL performance, assuming that only statistical channel state information (CSI) of the eavesdropping link is available. Then, we reveal an inherent statistical relationship between the AIL metric in the FBL regime and the commonly-used secrecy outage probability in conventional infinite blocklength communications. Aiming to improve the secure communication performance of the considered system, we formulate a blocklength optimization problem and solve it via a low-complexity approach. Next, we present numerical results to verify our analytical findings and provide various important insights into the impacts of system parameters on the AIL. Specifically, our results indicate that i) compromising a small amount of AIL can lead to significant reliability improvements, and ii) the AIL experiences a secrecy floor in the high signal-to-noise ratio regime.",
        "comments": "6 pages, 5 figures. Accepted for presentation at the 2024 IEEE International Conference on Communications (CT Symposium), 9 - 13 June 2024, Denver, CO United States. Note: An extended version of this work is available as arXiv:2308.13184",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11219"
    },
    {
        "doc_id": 384,
        "title": "Bessel kernel determinants and integrable equations",
        "authors": [
            "Giulio Ruzza"
        ],
        "subjects": [
            "Exactly Solvable and Integrable Systems",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We derive differential equations for multiplicative statistics of the Bessel determinantal point process depending on two parameters. In particular, we prove that such statistics are solutions to an integrable nonlinear partial differential equation describing isospectral deformations of a Sturm--Liouville equation. We also derive identities relating solutions to the integrable partial differential equation and to the Sturm--Liouville equation which imply an analogue for Painlev\u00e9 V of Amir--Corwin--Quastel ``integro-differential Painlev\u00e9 II equation''. This equation reduces, in a degenerate limit, to the system of coupled Painlev\u00e9 V equations derived by Charlier and Doeraene for the generating function of the Bessel process, and to the Painlev\u00e9 V equation derived by Tracy and Widom for the gap probability of the Bessel process. Finally, we study an initial value problem for the integrable partial differential equation. The approach is based on Its--Izergin--Korepin--Slavnov theory of integrable operators and their associated Riemann--Hilbert problems.",
        "comments": "22 pages",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11213"
    },
    {
        "doc_id": 385,
        "title": "$\u03c0$- and $K$-meson properties for large $N_f$ and $N_c$",
        "authors": [
            "Aftab Ahmad",
            "Mumtaz Khan"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "Dynamical chiral symmetry restoration for higher number of light quark flavors $N_f$ and breaking for higher number of colors $N_c$ implies the suppression and enhancement of the dynamically generated quark mass. The study of various larger values of number of colors and flavors may have greater impact on the internal structure of light hadrons. In this work, we study the properties of the pion and kaon, such as mass, condensate, and leptonic decay constant, for various $N_f$ and $N_c$. We use the symmetry-preserving vector-vector flavor-dependent contact interaction model of quark. The dynamical quark masses are calculated by using the Schwinger-Dyson equation (SDE). The masses of the pion and kaon for different values of $N_f$ and $N_c$ are determined using the homogeneous Bethe-Salpeter equation. For fixed $N_f=2$ and $N_c$ is increased, the dynamically generated quark mass ( mass of up and down quarks), strange quark mass, meson in-condensate, and decay constant, all increases. The pion mass remains approximately constant until $N_c$ reaches around 6.5, after which it grows rapidly. On the other hand, the kaon mass increases slowly with increasing $N_c$ until it reaches approximately $N_c=7.5$, beyond which it rises quickly. When $N_c=3$ is fixed at and various values of $N_f$ are considered, all the parameter values decrease as a function of $N_f$, except for the pion and kaon mass, which increase above a critical value of $N_f$ around $8$. This is the region where chiral symmetry is restored, and the pion and kaon behave as free particles, similar to their behavior in the presence of a heat bath. The results obtained for fixed $N_f=2$ and $N_c=3$ are fairly in decent agreement with experimentally calculated statistics and previous model calculations based on the Schwinger-Dyson equation (SDE) and Bethe-Salpeter equation (BSE).",
        "comments": "11 pages, 16 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11186"
    },
    {
        "doc_id": 386,
        "title": "Fermionic signal of vacuum polarization in strong laser fields",
        "authors": [
            "Ya-Nan Dai",
            "Karen Z. Hatsagortsyan",
            "Christoph H. Keitel",
            "Yue-Yue Chen"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Plasma Physics"
        ],
        "abstract": "Vacuum polarization (VP) is investigated for the interaction of a polarized $\u03b3$-ray beam of GeV photons with a counterpropagating ultraintense laser pulse. In a conventional setup of a vacuum birefringence measurement, a VP signal is the emerging small circular (linear) polarization of the initially linearly (circularly) polarized probe photons. The pair production via the nonlinear Breit-Wheeler process in such a high-energy environment eliminates part of the $\u03b3$-photons in the outgoing $\u03b3$-beam, increasing the statistical error and decreasing the accuracy of this VP signal. In contrast, we investigate the conversion of the emerging circular polarization of $\u03b3$-photons into longitudinal polarization of the created positrons, considering the latter as the main VP signal. To study the VP effects in the highly nonlinear regime, where the Euler-Heisenberg effective Lagrangian method breaks down, we have developed a Monte-Carlo simulation method, incorporating vacuum birefringence and dichroism via the one-loop QED probabilities in the locally constant field approximation. Our Monte Carlo method will enable the study of VP effects in strong fields of arbitrary configuration. With 10~PW laser systems, we demonstrate the feasibility of detecting the fermionic signal of the VP effect at the 5$\u03c3$ confidence level with a few hours of measurement time.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11168"
    },
    {
        "doc_id": 387,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 388,
        "title": "Weaving classical turbulence with quantum skeleton",
        "authors": [
            "Weiyu Shen",
            "Jie Yao",
            "Yue Yang"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Quantum Gases",
            "Superconductivity"
        ],
        "abstract": "Matter entanglement is a common chaotic structure in both quantum and classical systems. Turbulence can be pictured as a tangle of vortex filaments in superfluids and viscous vortices in classical fluids. However, it is hard to explain how the statistical properties of turbulence arise from elemental structures. Here we use the quantum vortex tangle as a skeleton to generate an instantaneous classical turbulent field with intertwined vortex tubes. Combining the quantum skeleton and tunable vortex thickness makes the synthetic turbulence satisfy key statistical laws and provides valuable insights for elucidating energy cascade and extreme events. By manipulating the elemental structures, we customize turbulence with desired statistical features. This bottom-up approach of \"weaving\" turbulence provides a testbed for analyzing and modeling turbulence.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11149"
    },
    {
        "doc_id": 389,
        "title": "Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable",
        "authors": [
            "Yuta Kawakami",
            "Manabu Kuroki",
            "Jin Tian"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "There has been considerable recent interest in estimating heterogeneous causal effects. In this paper, we introduce conditional average partial causal effects (CAPCE) to reveal the heterogeneity of causal effects with continuous treatment. We provide conditions for identifying CAPCE in an instrumental variable setting. We develop three families of CAPCE estimators: sieve, parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze their statistical properties. We illustrate the proposed CAPCE estimators on synthetic and real-world data.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11130"
    },
    {
        "doc_id": 390,
        "title": "Regularized Estimation of Sparse Spectral Precision Matrices",
        "authors": [
            "Navonil Deb",
            "Amy Kuceyeski",
            "Sumanta Basu"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "Spectral precision matrix, the inverse of a spectral density matrix, is an object of central interest in frequency-domain analysis of multivariate time series. Estimation of spectral precision matrix is a key step in calculating partial coherency and graphical model selection of stationary time series. When the dimension of a multivariate time series is moderate to large, traditional estimators of spectral density matrices such as averaged periodograms tend to be severely ill-conditioned, and one needs to resort to suitable regularization strategies involving optimization over complex variables.\n  In this work, we propose complex graphical Lasso (CGLASSO), an $\\ell_1$-penalized estimator of spectral precision matrix based on local Whittle likelihood maximization. We develop fast $\\textit{pathwise coordinate descent}$ algorithms for implementing CGLASSO on large dimensional time series data sets. At its core, our algorithmic development relies on a ring isomorphism between complex and real matrices that helps map a number of optimization problems over complex variables to similar optimization problems over real variables. This finding may be of independent interest and more broadly applicable for high-dimensional statistical analysis with complex-valued data. We also present a complete non-asymptotic theory of our proposed estimator which shows that consistent estimation is possible in high-dimensional regime as long as the underlying spectral precision matrix is suitably sparse. We compare the performance of CGLASSO with competing alternatives on simulated data sets, and use it to construct partial coherence network among brain regions from a real fMRI data set.",
        "comments": "55 pages, 8 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11128"
    },
    {
        "doc_id": 391,
        "title": "Measures determined by their values on balls and Gromov-Wasserstein convergence",
        "authors": [
            "Anne van Delft",
            "Andrew J. Blumberg"
        ],
        "subjects": [
            "Algebraic Topology",
            "Probability"
        ],
        "abstract": "A classical question about a metric space is whether Borel measures on the space are determined by their values on balls. We show that for any given measure this property is stable under Gromov-Wasserstein convergence of metric measure spaces. We then use this result to show that suitable bounded subspaces of the space of persistence diagrams have the property that any Borel measure is determined by its values on balls. This justifies the use of empirical ball volumes for statistical testing in topological data analysis (TDA). Our intended application is to deploy the statistical foundations of van Delft and Blumberg (2023) for time series of random geometric objects in the context of TDA invariants, specifically persistent homology and zigzag persistence.",
        "comments": "MSC Class:          62R40; 55N31",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11125"
    },
    {
        "doc_id": 392,
        "title": "Constraint-based measures of shift and relative shift for discrete frequency distributions",
        "authors": [
            "Kenneth J. Locey",
            "Brian D. Stein"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Comparisons of frequency distributions often invoke the concept of shift to describe directional changes in properties such as the mean. In the present study, we sought to define shift as a property in and of itself. Specifically, we define distributional shift (DS) as the concentration of frequencies away from the discrete class having the greatest value (e.g., the right-most bin of a histogram). We derive a measure of DS using the normalized sum of exponentiated cumulative frequencies. We then define relative distributional shift (RDS) as the difference in DS between two distributions, revealing the magnitude and direction by which one distribution is concentrated to lesser or greater discrete classes relative to another. We find that RDS is highly related to popular measures that, while based on the comparison of frequency distributions, do not explicitly consider shift. While RDS provides a useful complement to other comparative measures, DS allows shift to be quantified as a property of individual distributions, similar in concept to a statistical moment.",
        "comments": "21 pages, 1 table, 6 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11119"
    },
    {
        "doc_id": 393,
        "title": "A Finger on the Pulse of Cardiovascular Health: Smartphone Photoplethysmography-Based Pulse Waveform Analysis for Blood Pressure Measurement",
        "authors": [
            "Ivan Liu",
            "Fangyuan Liu",
            "Qi Zhong",
            "Shiguang Ni"
        ],
        "subjects": [
            "Signal Processing",
            "Computers and Society"
        ],
        "abstract": "Routine blood pressure (BP) monitoring, crucial for health assessment, faces challenges such as limited access to medical-grade equipment and expertise. Portable cuff BP devices, on the other hand, are cumbersome to carry all day and often cost-prohibitive in less developed countries. Besides, these sphygmomanometer-based devices can cause discomfort and disrupt blood flow during measurement. This study explores the use of smartphones for continuous BP monitoring, focusing on overcoming the trust barriers associated with the opacity of machine learning models in predicting BP from low-quality PPG signals. Our approach included developing models based on cardiovascular literature, using simple statistical methods to estimate BP from smartphone PPG signals with comprehensive data pre-processing, applying SHAP for enhanced interpretability and feature identification, and comparing our methods against standard references using Bland-Altman analysis. Validated with data from 125 participants, the study demonstrated significant correlations in waveform features between smartphone and reference BP monitoring devices. The cross-validation of linear regression [MAE=9.86 and 8.01 mmHg for systolic blood pressure (SBP) and diastolic blood pressure (DBP), respectively] and random forest model (MAE=8.91 and 6.68 mmHg for SBP and DBP) using waveform-only variables demonstrated the feasibility of using a smartphone to estimate BP. Although SHAP analysis identified key feature sets, Bland-Altman results did not fully meet established thresholds (84.64% and 94.69% of MAE<15 mmHg for SBP and DBP, respectively). The study suggests the potential of smartphone cameras to enhance the accuracy and interpretability of machine learning models for daily BP estimation, but also indicates that smartphone PPG-based BP prediction is not yet a replacement for traditional medical devices.",
        "comments": "33 pages, 9 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11117"
    },
    {
        "doc_id": 394,
        "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
        "authors": [
            "Jiachen T. Wang",
            "Prateek Mittal",
            "Ruoxi Jia"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "This work aims to address an open problem in data valuation literature concerning the efficient computation of Data Shapley for weighted $K$ nearest neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label KNN with discretized weights as the utility function, we reframe the computation of WKNN-Shapley into a counting problem and introduce a quadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the best result from existing literature. We develop a deterministic approximation algorithm that further improves computational efficiency while maintaining the key fairness properties of the Shapley value. Through extensive experiments, we demonstrate WKNN-Shapley's computational efficiency and its superior performance in discerning data quality compared to its unweighted counterpart.",
        "comments": "AISTATS 2024 Oral",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11103"
    },
    {
        "doc_id": 395,
        "title": "Asymptotic Normality of the Conditional Value-at-Risk based Pickands Estimator",
        "authors": [
            "Yizhou Li",
            "Pawel Polak"
        ],
        "subjects": [
            "Statistics Theory",
            "Other Statistics"
        ],
        "abstract": "The Pickands estimator for the extreme value index is beneficial due to its universal consistency, location, and scale invariance, which sets it apart from other types of estimators. However, similar to many extreme value index estimators, it is marked by poor asymptotic efficiency. Chen (2021) introduces a Conditional Value-at-Risk (CVaR)-based Pickands estimator, establishes its consistency, and demonstrates through simulations that this estimator significantly reduces mean squared error while preserving its location and scale invariance. The initial focus of this paper is on demonstrating the weak convergence of the empirical CVaR in functional space. Subsequently, based on the established weak convergence, the paper presents the asymptotic normality of the CVaR-based Pickands estimator. It further supports these theoretical findings with empirical evidence obtained through simulation studies.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11096"
    },
    {
        "doc_id": 396,
        "title": "Learned Image Compression with Dual-Branch Encoder and Conditional Information Coding",
        "authors": [
            "Haisheng Fu",
            "Feng Liang",
            "Jie Liang",
            "Zhenman Fang",
            "Guohe Zhang",
            "Jingning Han"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Recent advancements in deep learning-based image compression are notable. However, prevalent schemes that employ a serial context-adaptive entropy model to enhance rate-distortion (R-D) performance are markedly slow. Furthermore, the complexities of the encoding and decoding networks are substantially high, rendering them unsuitable for some practical applications. In this paper, we propose two techniques to balance the trade-off between complexity and performance. First, we introduce two branching coding networks to independently learn a low-resolution latent representation and a high-resolution latent representation of the input image, discriminatively representing the global and local information therein. Second, we utilize the high-resolution latent representation as conditional information for the low-resolution latent representation, furnishing it with global information, thus aiding in the reduction of redundancy between low-resolution information. We do not utilize any serial entropy models. Instead, we employ a parallel channel-wise auto-regressive entropy model for encoding and decoding low-resolution and high-resolution latent representations. Experiments demonstrate that our method is approximately twice as fast in both encoding and decoding compared to the parallelizable checkerboard context model, and it also achieves a 1.2% improvement in R-D performance compared to state-of-the-art learned image compression schemes. Our method also outperforms classical image codecs including H.266/VVC-intra (4:4:4) and some recent learned methods in rate-distortion performance, as validated by both PSNR and MS-SSIM metrics on the Kodak dataset.",
        "comments": "Accepted by DCC2024",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11093"
    },
    {
        "doc_id": 397,
        "title": "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions",
        "authors": [
            "Adel Javanmard",
            "Lin Chen",
            "Vahab Mirrokni",
            "Ashwinkumar Badanidiyuru",
            "Gang Fu"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Statistics Theory",
            "Machine Learning"
        ],
        "abstract": "Due to the rise of privacy concerns, in many practical applications the training data is aggregated before being shared with the learner, in order to protect privacy of users' sensitive responses. In an aggregate learning framework, the dataset is grouped into bags of samples, where each bag is available only with an aggregate response, providing a summary of individuals' responses in that bag. In this paper, we study two natural loss functions for learning from aggregate responses: bag-level loss and the instance-level loss. In the former, the model is learnt by minimizing a loss between aggregate responses and aggregate model predictions, while in the latter the model aims to fit individual predictions to the aggregate responses. In this work, we show that the instance-level loss can be perceived as a regularized form of the bag-level loss. This observation lets us compare the two approaches with respect to bias and variance of the resulting estimators, and introduce a novel interpolating estimator which combines the two approaches. For linear regression tasks, we provide a precise characterization of the risk of the interpolating estimator in an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis allows us to theoretically understand the effect of different factors, such as bag size on the model prediction risk. In addition, we propose a mechanism for differentially private learning from aggregate responses and derive the optimal bag size in terms of prediction risk-privacy trade-off. We also carry out thorough experiments to corroborate our theory and show the efficacy of the interpolating estimator.",
        "comments": "To appear in the Twelfth International Conference on Learning Representations (ICLR 2024)",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11081"
    },
    {
        "doc_id": 398,
        "title": "Estimating the Hawkes process from a discretely observed sample path",
        "authors": [
            "Feng Chen",
            "Jeffrey Kwan",
            "Tom Stindl"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "The Hawkes process is a widely used model in many areas, such as\n  finance, seismology, neuroscience, epidemiology, and social\n  sciences. Estimation of the Hawkes process from continuous\n  observations of a sample path is relatively straightforward using\n  either the maximum likelihood or other methods. However, estimating\n  the parameters of a Hawkes process from observations of a sample\n  path at discrete time points only is challenging due to the\n  intractability of the likelihood with such data. In this work, we\n  introduce a method to estimate the Hawkes process from a discretely\n  observed sample path. The method takes advantage of a state-space\n  representation of the incomplete data problem and use the sequential\n  Monte Carlo (aka particle filtering) to approximate the likelihood\n  function. As an estimator of the likelihood function the SMC\n  approximation is unbiased, and therefore it can be used together\n  with the Metropolis-Hastings algorithm to construct Markov Chains to\n  approximate the likelihood distribution, or more generally, the\n  posterior distribution of model parameters. The performance of the\n  methodology is assessed using simulation experiments and compared\n  with other recently published methods. The proposed estimator is\n  found to have a smaller mean square error than the two benchmark\n  estimators. The proposed method has the additional advantage that\n  confidence intervals for the parameters are easily available. We\n  apply the proposed estimator to the analysis of weekly count data on\n  measles cases in Tokyo Japan and compare the results to those by\n  one of the benchmark methods.",
        "comments": "23 page, 5 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11075"
    },
    {
        "doc_id": 399,
        "title": "Efficient Data Reduction Strategies for Big Data and High-Dimensional LASSO Regressions",
        "authors": [
            "Xin Wang",
            "Min Yang",
            "William Li"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "The IBOSS approach proposed by Wang et al. (2019) selects the most informative subset of n points. It assumes that the ordinary least squares method is used and requires that the number of variables, p, is not large. However, in many practical problems, p is very large and penalty-based model fitting methods such as LASSO is used. We study the big data problems, in which both n and p are large. In the first part, we focus on reduction in data points. We develop theoretical results showing that the IBOSS type of approach can be applicable to penalty-based regressions such as LASSO. In the second part, we consider the situations where p is extremely large. We propose a two-step approach that involves first reducing the number of variables and then reducing the number of data points. Two separate algorithms are developed, whose performances are studied through extensive simulation studies. Compared to existing methods including well-known split-and-conquer approach, the proposed methods enjoy advantages in terms of estimation accuracy, prediction accuracy, and computation time.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11070"
    },
    {
        "doc_id": 400,
        "title": "Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning",
        "authors": [
            "Philip Amortila",
            "Tongyi Cao",
            "Akshay Krishnamurthy"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undesirable behavior, resulting in no misspecification amplification while still obtaining optimal statistical rates. As applications, we use this regression procedure to obtain new guarantees in offline and online reinforcement learning with misspecification and establish new separations between previously studied structural conditions and notions of coverage.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12216"
    },
    {
        "doc_id": 401,
        "title": "Empirical martingale projections via the adapted Wasserstein distance",
        "authors": [
            "Jose Blanchet",
            "Johannes Wiesel",
            "Erica Zhang",
            "Zhenyuan Zhang"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "Given a collection of multidimensional pairs $\\{(X_i,Y_i):1 \\leq i\\leq n\\}$, we study the problem of projecting the associated suitably smoothed empirical measure onto the space of martingale couplings (i.e. distributions satisfying $\\mathbb{E}[Y|X]=X$) using the adapted Wasserstein distance. We call the resulting distance the smoothed empirical martingale projection distance (SE-MPD), for which we obtain an explicit characterization. We also show that the space of martingale couplings remains invariant under the smoothing operation. We study the asymptotic limit of the SE-MPD, which converges at a parametric rate as the sample size increases if the pairs are either i.i.d. or satisfy appropriate mixing assumptions. Additional finite-sample results are also investigated. Using these results, we introduce a novel consistent martingale coupling hypothesis test, which we apply to test the existence of arbitrage opportunities in recently introduced neural network-based generative models for asset pricing calibration.",
        "comments": "55 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12197"
    },
    {
        "doc_id": 402,
        "title": "Poincar\u00e9 inequality and quantitative De Giorgi method for hypoelliptic operators",
        "authors": [
            "Francesca Anceschi",
            "Helge Dietert",
            "Jessica Guerand",
            "Am\u00e9lie Loher",
            "Cl\u00e9ment Mouhot",
            "Annalaura Rebucci"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We propose a systematic elementary approach based on trajectories to prove Poincar\u00e9 inequalities for hypoelliptic equations with an arbitrary number of H\u00f6rmander commutators, both in the local and in the non-local case. Our method generalises and simplifies the method introduced in Guerand-Mouhot (2022) in the local case with one commutator, and extended in Loher (2024) to the non-local case with one commutator. It draws inspiration from the paper Niebel-Zacher (2022), although we use different trajectories. We deduce Harnack inequalities and H\u00f6lder regularity along the line of the De Giorgi method. Our results recover those in Anceschi-Rebucci (2022) in the local case, and are new in the non-local case.",
        "comments": "21 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12194"
    },
    {
        "doc_id": 403,
        "title": "Concentration inequalities for the sample correlation coefficient",
        "authors": [
            "Daniel Salnikov"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "The sample correlation coefficient $R$ plays an important role in many statistical analyses. We study the moments of $R$ under the bivariate Gaussian model assumption, provide a novel approximation for its finite sample mean and connect it with known results for the variance. We exploit these approximations to present non-asymptotic concentration inequalities for $R$. Finally, we illustrate our results in a simulation experiment that further validates the approximations presented in this work.",
        "comments": "10 pages, preprint",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12190"
    },
    {
        "doc_id": 404,
        "title": "Tracking before detection using partial orders and optimization",
        "authors": [
            "Michael Robinson",
            "Michael Stein",
            "Henry S. Owen"
        ],
        "subjects": [
            "Dynamical Systems",
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "This article addresses the problem of multi-object tracking by using a non-deterministic model of target behaviors with hard constraints. To capture the evolution of target features as well as their locations, we permit objects to lie in a general topological target configuration space, rather than a Euclidean space. We obtain tracker performance bounds based on sample rates, and derive a flexible, agnostic tracking algorithm. We demonstrate our algorithm on two scenarios involving laboratory and field data.",
        "comments": "MSC Class:          37N99",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12182"
    },
    {
        "doc_id": 405,
        "title": "Robust stability analysis of an energy-efficient control in a Networked Control System with application to Unmanned Ground Vehicles",
        "authors": [
            "Antonio Gonzalez",
            "Angel Cuenca",
            "Julian Salt",
            "Jelle Jacobs"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "In this paper, the robust stability and disturbance rejection performance analysis of an energy-efficient control is addressed in the framework of Networked Control System (NCS). The control scheme under study integrates periodic event-triggered control, packet-based control, time-varying Kalman filter, dual-rate control and prediction techniques, whose design is aimed at reducing energy consumption and bandwidth usage. The robust stability against time-varying model uncertainties is analyzed by means of a suficient condition based on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the proposed approach is experimentally validated in a tracking control for an Unmanned Ground Vehicle (UGV), which is a battery-constrained mobile device with limited computation capacities.",
        "comments": "38 pages, 12 figures, Information Sciences, 2021",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12172"
    },
    {
        "doc_id": 406,
        "title": "Paralinearization of free boundary problems in fluid dynamics",
        "authors": [
            "Thomas Alazard"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "A classical topic in the mathematical theory of hydrodynamics is to study the evolution of the free surface separating air from an incompressible perfect fluid. The goal of this survey is to examine this problem for two important sets of equations: the water wave equations and the Hele-Shaw equations, including the Muskat problem. These equations are different in nature, dispersive or parabolic, but we will see that they can be studied using related tools. In particular, we will discuss a paradifferential approach to these problems.",
        "comments": "survey article",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12155"
    },
    {
        "doc_id": 407,
        "title": "Extension property for partial automorphisms of the $n$-partite and semigeneric tournaments",
        "authors": [
            "Jan Hubi\u010dka",
            "Colin Jahel",
            "Mat\u011bj Kone\u010dn\u00fd",
            "Marcin Sabok"
        ],
        "subjects": [
            "Combinatorics",
            "Discrete Mathematics",
            "Logic"
        ],
        "abstract": "We present a proof of the extension property for partial automorphisms (EPPA) for classes of finite $n$-partite tournaments for $n \\in \\{2,3,\\ldots,\u03c9\\}$, and for the class of finite semigeneric tournaments. We also prove that the generic $\u03c9$-partite tournament and the generic semigeneric tournament have ample generics.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12153"
    },
    {
        "doc_id": 408,
        "title": "Maximum principles for weakly $1$-coercive operators with applications to capillary and prescribed mean curvature graphs",
        "authors": [
            "Luis J. Al\u00edas",
            "Giulio Colombo",
            "Marco Rigoli"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Differential Geometry"
        ],
        "abstract": "In this paper we establish maximum principles for weakly 1-coercive operators $L$ on complete, non-compact Riemannian manifolds $M$. In particular, we search for conditions under which one can guarantee that solutions $u$ of differential equations of the form $L(u)\\geq f(u)$ satisfy $f(u)\\leq 0$ on $M$. The case of weakly $p$-coercive operators with $p>1$, including the $p$-Laplacian and in particular the Laplace-Beltrami operator for $p=2$, has been considered in a recent paper of ours. As a consequence of the main results we infer comparison principles for that kind of operators. Furthermore we apply them to geometric situations dealing with the mean curvature operator, which is a typical weakly 1-coercive operator. We first consider the case of $\\mathcal C^1$ operators $L$ acting on functions $u$ of class $\\mathcal C^2$ and, in the last section of the paper, we show how our results can be extended to the case of less regular operators $L$ acting on functions $u$ which are just continuous and locally $W^{1,1}$ regular.",
        "comments": "28 pages. Invited contribution to a special issue in honour of Professor Marcos Dajczer on the occasion of his 75th birthday. Comments are welcome!",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12152"
    },
    {
        "doc_id": 409,
        "title": "Uncoded Storage Coded Transmission Elastic Computing with Straggler Tolerance in Heterogeneous Systems",
        "authors": [
            "Xi Zhong",
            "Joerg Kliewer",
            "Mingyue Ji"
        ],
        "subjects": [
            "Information Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Optimization and Control"
        ],
        "abstract": "In 2018, Yang et al. introduced a novel and effective approach, using maximum distance separable (MDS) codes, to mitigate the impact of elasticity in cloud computing systems. This approach is referred to as coded elastic computing. Some limitations of this approach include that it assumes all virtual machines have the same computing speeds and storage capacities, and it cannot tolerate stragglers for matrix-matrix multiplications. In order to resolve these limitations, in this paper, we introduce a new combinatorial optimization framework, named uncoded storage coded transmission elastic computing (USCTEC), for heterogeneous speeds and storage constraints, aiming to minimize the expected computation time for matrix-matrix multiplications, under the consideration of straggler tolerance. Within this framework, we propose optimal solutions with straggler tolerance under relaxed storage constraints. Moreover, we propose a heuristic algorithm that considers the heterogeneous storage constraints. Our results demonstrate that the proposed algorithm outperforms baseline solutions utilizing cyclic storage placements, in terms of both expected computation time and storage size.",
        "comments": "6 pages, 1 figure, accepted in ICC 2024",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12151"
    },
    {
        "doc_id": 410,
        "title": "An Efficient Finite Difference-based Implicit Solver for Phase-Field Equations with Spatially and Temporally Varying Parameters",
        "authors": [
            "Zirui Mao",
            "G. R. Liu",
            "Michael J. Demkowicz"
        ],
        "subjects": [
            "Numerical Analysis",
            "Mathematical Physics"
        ],
        "abstract": "The phase field method is an effective tool for modeling microstructure evolution in materials. Many efficient implicit numerical solvers have been proposed for phase field simulations under uniform and time-invariant model parameters. We use Eyre's theorem to develop an unconditionally stable implicit solver for spatially non-uniform and time-varying model parameters. The accuracy, unconditional stability, and efficiency of the solver is validated against benchmarking examples. In its current form, the solver requires a uniform mesh and may only be applied to problems with periodic, Neumann, or mixed periodic and Neumann boundary conditions.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12147"
    },
    {
        "doc_id": 411,
        "title": "A short note on similarity of operator-valued multishifts",
        "authors": [
            "Soumitra Ghara",
            "Surjit Kumar",
            "Shailesh Trivedi"
        ],
        "subjects": [
            "Functional Analysis"
        ],
        "abstract": "A complete characterization of the similarity between two operator-valued multishifts with invertible operator weights is obtained purely in terms of operator weights. This generalizes several existing results of the unitary equivalence of two (multi)shifts. Further, we utilize the aforementioned similarity criteria to determine the similarity between two tuples of operators of multiplication by the coordinate functions on certain reproducing kernel Hilbert spaces determined by diagonal kernels.",
        "comments": "10 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12144"
    },
    {
        "doc_id": 412,
        "title": "Chebyshev Varieties",
        "authors": [
            "Za\u00efneb Bel-Afia",
            "Chiara Meroni",
            "Simon Telen"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Numerical Analysis"
        ],
        "abstract": "Chebyshev varieties are algebraic varieties parametrized by Chebyshev polynomials or their multivariate generalizations. We determine the dimension, degree, singular locus and defining equations of these varieties. We explain how they play the role of toric varieties in sparse polynomial root finding, when monomials are replaced by Chebyshev polynomials. We present numerical root finding algorithms that exploit our results.",
        "comments": "27 pages, 11 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12140"
    },
    {
        "doc_id": 413,
        "title": "Gradient Preserving Operator Inference: Data-Driven Reduced-Order Models for Equations with Gradient Structure",
        "authors": [
            "Yuwei Geng",
            "Jasdeep Singh",
            "Lili Ju",
            "Boris Kramer",
            "Zhu Wang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Hamiltonian Operator Inference has been introduced in [Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn structure-preserving reduced-order models (ROMs) for Hamiltonian systems. This approach constructs a low-dimensional model using only data and knowledge of the Hamiltonian function. Such ROMs can keep the intrinsic structure of the system, allowing them to capture the physics described by the governing equations. In this work, we extend this approach to more general systems that are either conservative or dissipative in energy, and which possess a gradient structure. We derive the optimization problems for inferring structure-preserving ROMs that preserve the gradient structure. We further derive an {\\em a priori} error estimate for the reduced-order approximation. To test the algorithms, we consider semi-discretized partial differential equations with gradient structure, such as the parameterized wave and Korteweg-de-Vries equations in the conservative case and the one- and two-dimensional Allen-Cahn equations in the dissipative case. The numerical results illustrate the accuracy, structure-preservation properties, and predictive capabilities of the gradient-preserving Operator Inference ROMs.",
        "comments": "30 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12138"
    },
    {
        "doc_id": 414,
        "title": "Generalized Minkowski formulas and rigidity results for anisotropic capillary hypersurfaces",
        "authors": [
            "Jinyu Gao",
            "Guanghan Li"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "We show the generalization of Hsiung-Minkowski integral formula for anisotropic capillary hypersurfaces in the half-space, which includes the weighted Hsiung-Minkowski formula and classical anisotropic Minkowski identity for closed hypersurfaces as special cases. As applications, we prove some anisotropic Alexandrov-type theorems and rigidity results for anisotropic capillary hypersurfaces. Specially, the uniqueness of the solution to the anisotropic Orlicz-Christoffel-Minkowski problem is obtained.",
        "comments": "16 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12137"
    },
    {
        "doc_id": 415,
        "title": "Accelerating Continuous Variable Coherent Ising Machines via Momentum",
        "authors": [
            "Robin Brown",
            "Davide Venturelli",
            "Marco Pavone",
            "David E. Bernal Neira"
        ],
        "subjects": [
            "Optimization and Control",
            "Emerging Technologies",
            "Quantum Physics"
        ],
        "abstract": "The Coherent Ising Machine (CIM) is a non-conventional architecture that takes inspiration from physical annealing processes to solve Ising problems heuristically. Its dynamics are naturally continuous and described by a set of ordinary differential equations that have been proven to be useful for the optimization of continuous variables non-convex quadratic optimization problems. The dynamics of such Continuous Variable CIMs (CV-CIM) encourage optimization via optical pulses whose amplitudes are determined by the negative gradient of the objective; however, standard gradient descent is known to be trapped by local minima and hampered by poor problem conditioning. In this work, we propose to modify the CV-CIM dynamics using more sophisticated pulse injections based on tried-and-true optimization techniques such as momentum and Adam. Through numerical experiments, we show that the momentum and Adam updates can significantly speed up the CV-CIM's convergence and improve sample diversity over the original CV-CIM dynamics. We also find that the Adam-CV-CIM's performance is more stable as a function of feedback strength, especially on poorly conditioned instances, resulting in an algorithm that is more robust, reliable, and easily tunable. More broadly, we identify the CIM dynamical framework as a fertile opportunity for exploring the intersection of classical optimization and modern analog computing.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12135"
    },
    {
        "doc_id": 416,
        "title": "Growth of products of subsets in finite simple groups",
        "authors": [
            "Daniele Dona",
            "Attila Mar\u00f3ti",
            "L\u00e1szl\u00f3 Pyber"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "We prove that the product of a subset and a normal subset inside any finite simple non-abelian group $G$ grows rapidly. More precisely, if $A$ and $B$ are two subsets with $B$ normal and neither of them is too large inside $G$, then $|AB| \\geq |A||B|^{1-\u03b5}$ where $\u03b5>0$ can be taken arbitrarily small. This is a somewhat surprising strengthening of a theorem of Liebeck, Schul, Shalev.",
        "comments": "7 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12128"
    },
    {
        "doc_id": 417,
        "title": "A game theoretic model of preventive demographic measures",
        "authors": [
            "O. A. Malafeyev",
            "M. A. Suvorov"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "The article constructs a game-theoretic model of preventive measures for the antagonistic game with nature, that is such a model in which two participants take part, one of which is a regulating body (government) that makes legislative decisions depending on the emerging external and internal conditions affecting the course of the demographic process, the second participant - internal and external conditions of the environment (nature). An example of such a game is given and the optimal strategy for the government is calculated.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12124"
    },
    {
        "doc_id": 418,
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Theoretical Economics"
        ],
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about centralization in block-building (due to, e.g., MEV and private order flow) and the outsourcing of block-building by validators to specialists (i.e., proposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers inevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve decentralization among proposers?\n  This paper develops mathematical models and results that offer answers to these questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block producer rewards, and staking costs, we quantify the extent to which heterogeneous rewards lead to concentration in the equilibrium staking distribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly reinvest rewards into staking, we quantify, as a function of the block producer heterogeneity, the rate at which stake concentrates on the most sophisticated block producers.\n  3. In a model with heterogeneous proposers and specialized builders, we quantify, as a function of the competitiveness of the builder ecosystem, the extent to which proposer-builder separation reduces the heterogeneity in rewards across different proposers.\n  Our models and results take advantage of connections to contest design, P\u00f3lya urn processes, and auction theory.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12120"
    },
    {
        "doc_id": 419,
        "title": "Envelopes of Horospheres and Weingarten Surfaces in Hyperbolic 3-Space",
        "authors": [
            "Charles L. Epstein"
        ],
        "subjects": [
            "Differential Geometry",
            "Analysis of PDEs",
            "Complex Variables"
        ],
        "abstract": "We derive basic differential geometric formulae for surfaces in hyperbolic space represented as envelopes of horospheres. The dual notion of parallel hypersurfaces is also studied. The representation is applied to prove existence and regularity theorems for Weingarten surfaces in H^3, which satisfy (1-a)K = a(2-H), for an a < 0, and have a specified boundary curve at infinity. These surfaces are shown to be closely connected to conformal mappings of domains in S^2 into the unit disk and provide Riemannian interpretations for some conformal invariants associated to such mappings.\n  This paper was originally written in 1984, before I learned to use TeX, and was typed by one of the secretaries in the Princeton Math Department. It was more or less, my first original work after my dissertation. For some reason, I was not able to get this paper published in a timely manner. The results and perspective in this paper have proved to be useful to a variety of people, some of whom asked me to render the article into TeX and post it to the arXiv. I had been seriously thinking about doing this, when Martin Bridgemen sent me a transcription of my original article into TeX. I am extremely grateful to him for the effort he has put into this project.\n  The paper is now formatted in a more or less modern AMS-article style, but for lots of additional punctuation, a few corrections and some minor stylistic changes, the content has been largely reproduced as it originally was. Remarks about the 'state-of-the-art' in hyperbolic geometry are obviously way out of date, as there has been enormous progress in many aspects of this still rich subject.",
        "comments": "I am enormously grateful to Martin and the community of mathematicians who have let me know, over the years, that this work was of some use to them",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12115"
    },
    {
        "doc_id": 420,
        "title": "A quantitative version of the Steinhaus theorem",
        "authors": [
            "Alex Iosevich",
            "Jonathan Pakianathan"
        ],
        "subjects": [
            "Classical Analysis and ODEs"
        ],
        "abstract": "The classical Steinhaus theorem (\\cite{Steinhaus1920}) says that if $A \\subset {\\Bbb R}^d$ has positive Lebesgue measure than $A-A=\\{x-y: x,y \\in A\\}$ contains an open ball. We obtain some quantitative lower bounds on the size of this ball and in some cases, relate it to natural geometric properties of $\\partial A$. We also study the process $K_n =\\frac{1}{2}(K_{n-1} - K_{n-1})$ when $K_0$ is a compact subset of $\\mathbb{R}^d$ and determine various aspects of its convergence to $Conv(K_1)$, the convex hull of $K_1$. We discuss some connections with convex geometry, Weyl tube formula and the Kakeya needle problem.\n  \\noindent\n  {\\it Keywords: Measure theory, Steinhaus theorem, Convex geometry, Weyl tube formula.}\n  \\noindent\n  2020 {\\it Mathematics Subject Classification:} Primary: 28A75, 52A27. Secondary: 52A30, 53A07.",
        "comments": "MSC Class:          28A75; 52A27; 52A30; 53A07",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12112"
    },
    {
        "doc_id": 421,
        "title": "Differentiation of integral Mittag-Leffler and integral Wright functions with respect to parameters",
        "authors": [
            "Alexander Apelblat",
            "Juan Luis Gonz\u00e1lez-Santander"
        ],
        "subjects": [
            "Classical Analysis and ODEs"
        ],
        "abstract": "Derivatives with respect to the parameters of the integral Mittag-Leffler function and the integral Wright function, recently introduced by us, are calculated. These derivatives can be expressed in the form of infinite sums of quotients of the digamma and gamma functions. In some particular cases, these infinite sums are calculated in closed-form with the help of MATHEMATICA. However, parameter differentiation reduction formulas are explicitly derived in order to check some of the results given by MATHEMATICA, as well as to provide many other new results. In addition, we present these infinite sums graphically for particular values of the parameters. Finally, new results for parameter derivatives of the Mittag-Leffler and Wright functions are reported in the Appendices.",
        "comments": "MSC Class:          33E12; 33C10; 33C20",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12110"
    },
    {
        "doc_id": 422,
        "title": "Engineered complete intersections: slightly degenerate Bernstein--Kouchnirenko--Khovanskii",
        "authors": [
            "Alexander Esterov"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "Geometry of sparse systems of polynomial equations (i.e. the ones with prescribed monomials and generic coefficients) is well studied in terms of their Newton polytopes. The results of this study are colloquially known as the Bernstein--Kouchnirenko--Khovanskii toolkit, and unfortunately are not applicable to many important systems, whose coefficients slightly fail to be generic.\n  This for instance happens if some of the equations are obtained from another one by taking partial derivatives or permuting the variables, or the equations are linear, realizing a non-trivial matroid, or in more advanced settings such as generalized Calabi--Yau complete intersections.\n  Such interesting examples (as well as many others) turn out to belong to a natural class of ``systems of equations that are nondegenerate upon cancellations''. We extend to this class several classical and folklore results of the Bernstein--Kouchnirenko--Khovanskii toolkit, such as the ones regarding the number and regularity of solutions, their irreducibility, tropicalization and Calabi--Yau-ness.",
        "comments": "29 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12099"
    },
    {
        "doc_id": 423,
        "title": "The inverse problem for a class of implicit differential equations and the coisotropic embedding theorem",
        "authors": [
            "Luca Schiavone"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics",
            "Differential Geometry"
        ],
        "abstract": "We carry on the approach used in [Sch] to provide a solution for the inverse problem of the calculus of variations for Maxwell equations in vacuum and we provide an abstract theory including all implicit differential equations that can be formulated in terms of vector fields over pre-symplectic manifolds.",
        "comments": "MSC Class:          53Dxx; 53Zxx; 49Sxx",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12096"
    },
    {
        "doc_id": 424,
        "title": "On the growth of resolvent of Toeplitz operators",
        "authors": [
            "Leonid Golinskii",
            "Stanislas Kupin",
            "Anna Vishnyakova"
        ],
        "subjects": [
            "Spectral Theory",
            "Complex Variables"
        ],
        "abstract": "We study the growth of the resolvent of a Toeplitz operator $T_b$, defined on the Hardy space, in terms of the distance to its spectrum $\u03c3(T_b)$. We are primarily interested in the case when the symbol $b$ is a Laurent polynomial (\\emph{i.e., } the matrix $T_b$ is banded). We show that for an arbitrary such symbol the growth of the resolvent is quadratic, and under certain additional assumption it is linear. We also prove the quadratic growth of the resolvent for a certain class of non-rational symbols.",
        "comments": "15 pages, 0 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12095"
    },
    {
        "doc_id": 425,
        "title": "Quantum Eigensolver for General Matrices",
        "authors": [
            "Xiao-Ming Zhang",
            "Yukun Zhang",
            "Wenhao He",
            "Xiao Yuan"
        ],
        "subjects": [
            "Quantum Physics",
            "Mesoscale and Nanoscale Physics",
            "Data Structures and Algorithms",
            "Numerical Analysis",
            "Computational Physics"
        ],
        "abstract": "The eigenvalue problem, a cornerstone in linear algebra, provides profound insights into studying matrix properties. Quantum algorithms addressing this problem have hitherto been constrained to special normal matrices assuming spectral decomposition, leaving the extension to general matrices an open challenge. In this work, we present a novel family of quantum algorithms tailored for solving the eigenvalue problem for general matrices, encompassing scenarios with complex eigenvalues or even defective matrices. Our approach begins by tackling the task of searching for an eigenvalue without additional constraints. For diagonalizable matrices, our algorithm has $\\tilde O(\\varepsilon^{-1})$ complexity with an error $\\varepsilon$, achieving the nearly Heisenberg scaling. Subsequently, we study the identification of eigenvalues closest to a specified point or line, extending the results for ground energy and energy gap problems in Hermitian matrices. We achieve an accuracy scaling of $\\tilde O(\\varepsilon^{-2})$ for general diagonalizable matrices, further refining to $\\tilde O(\\varepsilon^{-1})$ under the condition of real eigenvalues or constant distance from the reference point. The algorithm's foundation lies in the synergy of three techniques: the relationship between eigenvalues of matrix $A$ and the minimum singular value of $A-\u03bcI$, quantum singular value threshold subroutine extended from quantum singular-value estimation, and problem-specific searching algorithms. Our algorithms find applications in diverse domains, including estimating the relaxation time of Markov chains, solving Liouvillian gaps in open quantum systems, and verifying PT-symmetry broken/unbroken phases. These applications underscore the significance of our quantum eigensolvers for problems across various disciplines.",
        "comments": "6+10 pages, 1+1 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12091"
    },
    {
        "doc_id": 426,
        "title": "Sch\u00f6n complete intersections",
        "authors": [
            "Alexander Esterov"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "A complete intersection $f_1=\\cdots=f_k=0$ is sch\u00f6n, if $f_1=\\cdots=f_j=0$ defines a sch\u00f6n subvariety of an algebraic torus for every $j\\leqslant k$. This class includes nondegenerate complete intersections, critical loci of their coordinate projections, other simplest Thom--Boardman and multiple point strata of such projections, generalized Calabi--Yau complete intersections, equaltions of polynomial optimization, hyperplane arrangement complements, and many other interesting special varieties.\n  We study their Euler characteristics, connectednes, Calabi--Yau-ness, tropicalizations, etc., extending (in part conjecturally) the respective classical results about nondegenerate complete intersections.",
        "comments": "22 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12090"
    },
    {
        "doc_id": 427,
        "title": "Evaluations of $ \\sum_{k=1}^\\infty \\frac{x^k}{k^2\\binom{3k}{k}}$ and related series",
        "authors": [
            "Zhi-Wei Sun",
            "Yajun Zhou"
        ],
        "subjects": [
            "Combinatorics",
            "Number Theory"
        ],
        "abstract": "We perform polylogarithmic reductions for several classes of infinite sums motivated by Z.-W. Sun's related works in 2022--2023. For certain choices of parameters, these series can be expressed by cyclotomic multiple zeta values of levels $4$, $5$, $6$, $7$, $8$, $9$, $10$, and $12$. In particular, we obtain closed forms of the series $$\\sum_{k=0}^\\infty\\frac{x_0^k}{(k+1)\\binom{3k}k} \\ \\ \\text{and}\\ \\ \\sum_{k=1}^\\infty\\frac{x_0^k}{k^2\\binom{3k}k}$$ for any $x_0\\in(-27/4,27/4)$.",
        "comments": "23 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12083"
    },
    {
        "doc_id": 428,
        "title": "On the stability of hybrid polycycles",
        "authors": [
            "Paulo Santana",
            "Leonardo Pereira Serantola"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "In this paper we provide the stability of generic polycycles of hybrid planar vector fields, extending previous known results in the literature.",
        "comments": "10 pages and 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12081"
    },
    {
        "doc_id": 429,
        "title": "Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles",
        "authors": [
            "Maximilian Muschalik",
            "Fabian Fumagalli",
            "Barbara Hammer",
            "Eyke H\u00fcllermeier"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "While shallow decision trees may be interpretable, larger ensemble models like gradient-boosted trees, which often set the state of the art in machine learning problems involving tabular data, still remain black box models. As a remedy, the Shapley value (SV) is a well-known concept in explainable artificial intelligence (XAI) research for quantifying additive feature attributions of predictions. The model-specific TreeSHAP methodology solves the exponential complexity for retrieving exact SVs from tree-based models. Expanding beyond individual feature attribution, Shapley interactions reveal the impact of intricate feature interactions of any order. In this work, we present TreeSHAP-IQ, an efficient method to compute any-order additive Shapley interactions for predictions of tree-based models. TreeSHAP-IQ is supported by a mathematical framework that exploits polynomial arithmetic to compute the interaction scores in a single recursive traversal of the tree, akin to Linear TreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and explore interactions on well-established benchmark datasets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12069"
    },
    {
        "doc_id": 430,
        "title": "Annular Links from Thompson's Group $T$",
        "authors": [
            "Louisa Liles"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "In 2014 Jones showed how to associate links in the $3$-sphere to elements of Thompson's group $F$. We provide an analogue of this program for annular links and Thompson's group $T$. The main result is that any edge-signed graph embedded in the annulus is the Tait graph of an annular link built from an element of $T$. In analogy to the work of Aiello and Conti, we also show that the coefficients of certain unitary representations of $T$ recover the Jones polynomial of annular links.",
        "comments": "MSC Class:          57K14; 57K10",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12065"
    },
    {
        "doc_id": 431,
        "title": "Entropy numbers and box dimension of polynomials and holomorphic functions",
        "authors": [
            "Daniel Carando",
            "Carlos D'Andrea",
            "Leodan A. Torres",
            "Pablo Turco"
        ],
        "subjects": [
            "Functional Analysis"
        ],
        "abstract": "We study entropy numbers and box dimension of (the image of) homogeneous polynomials and holomorphic functions between Banach spaces. First, we see that entropy numbers and box dimensions of subsets of Banach spaces are related. We show that the box dimension of the image of a ball under a homogeneous polynomial is finite if and only if it spans a finite-dimensional subspace, but this is not true for holomorphic functions. Furthermore, we relate the entropy numbers of a holomorphic function to those of the polynomials of its Taylor series expansion. As a consequence, if the box dimension of the image of a ball by a holomorphic function $f$ is finite, then the entropy numbers of the polynomials in the Taylor series expansion of $f$ at any point of the ball belong to $\\ell_p$ for every $p>1$.",
        "comments": "17 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12059"
    },
    {
        "doc_id": 432,
        "title": "Asymptotic Analysis and Uniqueness of blowup solutions of non-quantized singular mean field equations",
        "authors": [
            "Daniele Bartoclucci",
            "Wen Yang",
            "Lei Zhang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "For singular mean field equations defined on a compact Riemann surface, we prove the uniqueness of bubbling solutions as far as blowup points are either regular points or non-quantized singular sources. In particular the uniqueness result covers the most general case improving all previous works of Bartolucci-Jevnikar-Lee-Yang \\cite{bart-4,bart-4-2} and Wu-Zhang \\cite{wu-zhang-ccm}. For example, unlike previous results, we drop the assumption of singular sources being critical points of a suitably defined Kirchoff-Routh type functional. Based on refined estimates which allow a major simplification of previous proofs, our new argument is robust and flexible enough to be applied to a wide range of problems requiring a delicate blowup analysis.",
        "comments": "76 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12057"
    },
    {
        "doc_id": 433,
        "title": "Navier-Stokes-Cahn-Hilliard equations on evolving surfaces",
        "authors": [
            "Charles M. Elliott",
            "Thomas Sales"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We derive a system of equations which can be seen as an evolving surface version of the diffuse interface \"Model H\" of Hohenberg and Halperin. We then consider the well-posedness for the corresponding (tangential) system when one prescribes the evolution of the surface. This well-posedness theory is considered for smooth potentials with polynomial growth, and a thermodynamically relevant singular potential - with some restrictions on initial data in the latter case.",
        "comments": "56 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12044"
    },
    {
        "doc_id": 434,
        "title": "Energy-Conserving Hermite Methods for Maxwell's Equations",
        "authors": [
            "Daniel Appelo",
            "Thomas Hagstrom",
            "Yann-Meing Law-Kam-Cio"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Energy-conserving Hermite methods for solving Maxwell's equations in dielectric and dispersive media are described and analyzed. In three space dimensions methods of order $2m$ to $2m+2$ require $(m+1)^3$ degrees-of-freedom per node for each field variable and can be explicitly marched in time with steps independent of $m$. We prove stability for time steps limited only by domain-of-dependence requirements along with error estimates in a special seminorm associated with the interpolation process. Numerical experiments are presented which demonstrate that Hermite methods of very high order enable the efficient simulation of electromagnetic wave propagation over thousands of wavelengths.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12043"
    },
    {
        "doc_id": 435,
        "title": "A Skew-Symmetric Energy Stable Almost Dissipation Free Formulation of the Compressible Navier-Stokes Equations",
        "authors": [
            "Jan Nordstr\u00f6m"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We show that a specific skew-symmetric formulation of the nonlinear terms in the compressible Navier-Stokes equations leads to an energy rate in terms of surface integrals only. No dissipative volume integrals contribute to the energy rate. We also discuss boundary conditions that bounds the surface integrals.",
        "comments": "MSC Class:          35M33                          ACM Class:          G.1.8",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12038"
    },
    {
        "doc_id": 436,
        "title": "A Survey of Advances in Optimization Methods for Wireless Communication System Design",
        "authors": [
            "Ya-Feng Liu",
            "Tsung-Hui Chang",
            "Mingyi Hong",
            "Zheyu Wu",
            "Anthony Man-Cho So",
            "Eduard A. Jorswieck",
            "Wei Yu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing",
            "Optimization and Control"
        ],
        "abstract": "Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recent advances in mathematical optimization theory and algorithms, from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing and/or developing suitable optimization algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.",
        "comments": "47 pages, 10 figures, submitted for possible publication",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12025"
    },
    {
        "doc_id": 437,
        "title": "A Simulation of Optimal Dryness When Moving in the Rain or Snow Using MATLAB",
        "authors": [
            "Neil Zhao",
            "Emilee Brockner",
            "Asia Winslow",
            "Megan Seraydarian"
        ],
        "subjects": [
            "Discrete Mathematics",
            "Mathematical Software"
        ],
        "abstract": "The classic question of whether one should walk or run in the rain to remain the least wet has inspired a myriad of solutions ranging from physically performing test runs in raining conditions to mathematically modeling human movement through rain. This manuscript approaches the classical problem by simulating movement through rainfall using MATLAB. Our simulation was generalizable to include snowfall as well. An increase in walking speed resulted in a corresponding decrease in raindrop and snowflake collisions. When raindrops or snowflakes were given a horizontal movement vector due to wind, a local minimum in collisions was achieved when moving in parallel with the same horizontal speed as the raindrop; no local minimum was detected with antiparallel movement. In general, our simulation revealed that the faster one moves, the drier one remains.",
        "comments": "15 pages, 9 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12023"
    },
    {
        "doc_id": 438,
        "title": "Capacity in Besov and Triebel-Lizorkin spaces with generalized smoothness",
        "authors": [
            "Nijjwal Karak",
            "Debarati Mondal"
        ],
        "subjects": [
            "Functional Analysis"
        ],
        "abstract": "We prove a lower bound estimate for capacities in Hajlasz-Besov, Hajlasz-Triebel-Lizorkin and Hajlasz-Sobolev spaces with generalized smoothness defined on metric spaces in terms of Netrusov-Hausdorff content or Hausdorff content.",
        "comments": "To appear in Georgian Mathematical Journal",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12020"
    },
    {
        "doc_id": 439,
        "title": "Annotated square root computation in Liber Abaci and De Practica Geometrie by Fibonacci",
        "authors": [
            "Trond Steihaug"
        ],
        "subjects": [
            "History and Overview"
        ],
        "abstract": "We study the square root computation by Leonardo Fibonacci (or Leonardo of Pisa) in his MSS Liber Abaci from c1202 and c1228 and De Practica Geometrie from c1220. We annotate a translation of Liber Abaci based on transcripts from 1857 and 2020 and a translation from 2002 and a transcription of De Practica Geometrie from 1862 and a translation from 2008. We show that Fibonacci is demonstrating the same method for all examples in the MSS and that this method deviates from the traditional description of the digit--by--digit method. The description of the method used by Fibonacci is all verbal and summarized in tables for each square root example. The manuscripts and transcription of the Latin texts are incomplete for some of the examples and the transcription and translation contains minor discrepancies and some of the tables are incomplete and the missing digits are inserted.",
        "comments": "35 pages and 16 included figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12016"
    },
    {
        "doc_id": 440,
        "title": "On a class of interdiction problems with partition matroids: complexity and polynomial-time algorithms",
        "authors": [
            "Sergey S. Ketkov",
            "Oleg A. Prokopyev"
        ],
        "subjects": [
            "Computational Complexity",
            "Optimization and Control"
        ],
        "abstract": "In this study, we consider a class of linear matroid interdiction problems, where the feasible sets for the upper-level decision-maker (referred to as the leader) and the lower-level decision-maker (referred to as the follower) are given by partition matroids with a common ground set. In contrast to classical network interdiction models where the leader is subject to a single budget constraint, in our setting, both the leader and the follower are subject to several independent cardinality constraints and engage in a zero-sum game. While a single-level linear integer programming problem over a partition matroid is known to be polynomially solvable, we prove that the considered bilevel problem is NP-hard, even when the objective function coefficients are all binary. On a positive note, it turns out that, if the number of cardinality constraints is fixed for either the leader or the follower, then the considered class of bilevel problems admits several polynomial-time solution schemes. Specifically, these schemes are based on a single-level dual reformulation, a dynamic programming-based approach, and a 2-flip local search algorithm for the leader.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12010"
    },
    {
        "doc_id": 441,
        "title": "Arithmetic degrees of dynamical systems over fields of characteristic zero",
        "authors": [
            "Wenbin Luo",
            "Jiarui Song"
        ],
        "subjects": [
            "Number Theory",
            "Algebraic Geometry"
        ],
        "abstract": "In this article, we generalize the arithmetic degree and its related theory to dynamical systems defined over an arbitrary field $\\mathbf{k}$ of characteristic $0$. We first consider a dynamical system $(X,f)$ over a finitely generated field $K$ over $\\mb{Q}$, we introduce the arithmetic degrees for $\\ov{K}$-points by using Moriwaki heights. We study the arithmetic dynamical degree of $(X,f)$ and establish the relative degree formula. The relative degree formula gives a proof of the fundamental inequality $\\ov\u03b1(f,x)\\leq \u03bb_1(f)$ in this setting. By taking a spread-out, we extend the definition of arithmetic degrees to dynamical systems over the field $\\mathbf k$ of characteristic $0$. We demonstrate that our definition is independent of the choice of the spread-out. Moreover, in this setting, we prove certain special cases of the Kawaguchi-Silverman conjecture. A main novelty of this paper is that, we give a characterization of arithmetic degrees of \"transcendental points\" in the case $\\mathbf k=\\C$, from which we deduce that $\u03b1(f,x)=\u03bb_1(f)$ for very general $x\\in X(\\mb{C})$ when $f$ is an endomorphism.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11982"
    },
    {
        "doc_id": 442,
        "title": "On the uniqueness of compiling graphs under the parity transformation",
        "authors": [
            "Florian Dreier",
            "Wolfgang Lechner"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics",
            "Combinatorics"
        ],
        "abstract": "In this article, we establish a mathematical framework that utilizes concepts from graph theory to define the parity transformation as a mapping that encompasses all possible compiled hypergraphs, and investigate uniqueness properties of this mapping in more detail. By introducing so-called loop labelings, we derive an alternative expression of the preimage of any set of compiled hypergraphs under this encoding procedure when all equivalences classes of graphs are being considered. We then deduce equivalent conditions for the injectivity of the parity transformation on any subset of all equivalences classes of graphs. Moreover, we show concrete examples of optimization problems demonstrating that the parity transformation is not an injective mapping, and also introduce an important class of plaquette layouts and their corresponding set of constraints whose preimage is uniquely determined. In addition, we provide an algorithm which is based on classical algorithms from theoretical computer science and computes a compiled physical layout in this class in polynomial time.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11980"
    },
    {
        "doc_id": 443,
        "title": "Dualizations of approximations, $\\aleph_1$-projectivity, and Vop\u011bnka's Principles",
        "authors": [
            "Asmae Ben Yassine",
            "Jan Trlifaj"
        ],
        "subjects": [
            "Representation Theory",
            "Category Theory",
            "Logic",
            "Rings and Algebras"
        ],
        "abstract": "The approximation classes of modules that arise as components of cotorsion pairs are tied up by Salce's duality. Here we consider general approximation classes of modules and investigate possibilities of dualization in dependence on closure properties of these classes. While some proofs are easily dualized, other dualizations require large cardinal principles, and some fail in ZFC, with counterexamples provided by classes of $\\aleph_1$-projective modules over non-perfect rings. For example, we show that Vop\u011bnka's Principle implies that each covering class of modules closed under homomorphic images is of the form Gen($M$) for a module $M$, and that the latter property restricted to classes generated by $\\aleph_1$-free abelian groups implies Weak Vop\u011bnka's Principle.",
        "comments": "MSC Class:          16D90 (Primary); 03E55; 16D40; 18G25; 20K20 (Secondary)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11979"
    },
    {
        "doc_id": 444,
        "title": "A finiteness principle for distance functions on Riemannian surfaces with H\u00f6lder continuous curvature",
        "authors": [
            "Rotem Assouline"
        ],
        "subjects": [
            "Differential Geometry",
            "Metric Geometry"
        ],
        "abstract": "We study distance functions from geodesics to points on Riemannian surfaces with H\u00f6lder continuous Gauss curvature, and prove a finiteness principle in the spirit of Whitney extension theory for such functions. Our result can be viewed as a finiteness principle for isometric embedding of a certain type of metric spaces into Riemannian surfaces, with control over the H\u00f6lder seminorm of the Gauss curvature.",
        "comments": "38 pages, 2 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11962"
    },
    {
        "doc_id": 445,
        "title": "General duality and dual attainment for adapted transport",
        "authors": [
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "We investigate duality and existence of dual optimizers for several adapted optimal transport problems under minimal assumptions. This includes the causal and bicausal transport, the barycenter problem, and a general multimarginal problem incorporating causality constraints. Moreover, we discuss applications of our results in robust finance. We consider a non-dominated model of several financial markets where stocks are traded dynamically, but the joint stock dynamics are unknown. We show that a no-arbitrage assumption in a quasi-sure sense naturally leads to sets of multicausal couplings. Consequently, computing the robust superhedging price is equivalent to solving an adapted transport problem, and finding a superhedging strategy means solving the corresponding dual.",
        "comments": "32 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11958"
    },
    {
        "doc_id": 446,
        "title": "Biquandle Power Brackets",
        "authors": [
            "Neslihan G\u00fcg\u00fcmc\u00fc",
            "Sam Nelson"
        ],
        "subjects": [
            "Geometric Topology",
            "Quantum Algebra"
        ],
        "abstract": "In this paper, we introduce biquandle power brackets, an infinite family of invariants of oriented links containing the classical skein invariants and the quandle and biquandle 2-cocycle invariants as special cases. Biquandle power brackets are generalizations of biquandle brackets in which the values of Kauffman states also depend on the biquandle colors they admit. We provide example computations and discuss the relationship between these new invariants and the previous cases.",
        "comments": "14 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11956"
    },
    {
        "doc_id": 447,
        "title": "Weighted holomorphic polynomial approximation",
        "authors": [
            "S. Charpentier",
            "N. Levenberg",
            "F. Wielonsky"
        ],
        "subjects": [
            "Complex Variables",
            "Classical Analysis and ODEs"
        ],
        "abstract": "For $G$ an open set in $\\mathbb{C}$ and $W$ a non-vanishing holomorphic function in $G$, in the late 1990's, Pritsker and Varga characterized pairs $(G,W)$ having the property that any $f$ holomorphic in $G$ can be locally uniformly approximated in $G$ by weighted holomorphic polynomials $\\{W(z)^np_n(z)\\}, \\ deg(p_n)\\leq n$. We further develop their theory in first proving a quantitative Bernstein-Walsh type theorem for certain pairs $(G,W)$. Then we consider the special case where $W(z)=1/(1+z)$ and $G$ is a loop of the lemniscate $\\{z\\in \\mathbb{C}: |z(z+1)|=1/4\\}$. We show the normalized measures associated to the zeros of the $n-th$ order Taylor polynomial about $0$ of the function $(1+z)^{-n}$ converge to the weighted equilibrium measure of $\\overline G$ with weight $|W|$ as $n\\to \\infty$. This mimics the motivational case of Pritsker and Varga where $G$ is the inside of the Szego curve and $W(z)=e^{-z}$. Lastly, we initiate a study of weighted holomorphic polynomial approximation in $\\mathbb{C}^n, \\ n>1$.",
        "comments": "21 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11955"
    },
    {
        "doc_id": 448,
        "title": "On the steadiness of symmetric solutions to two dimensional dispersive models",
        "authors": [
            "Long Pei",
            "Fengyang Xiao",
            "Pan Zhang"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "In this paper, we consider the steadiness of symmetric solutions to two dispersive models in shallow water and hyperelastic mechanics, respectively. These models are derived previously in the two-dimensional setting and can be viewed as the generalization of the Camassa-Holm and Kadomtsev-Petviashvili equations. For these two models, we prove that symmetry of classical solutions implies steadiness in the horizontal direction. We also confirm the such connection between symmetry and steadiness in weak formulation, which includes in particular the peaked solutions.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11953"
    },
    {
        "doc_id": 449,
        "title": "A Stabilised Semi-Implicit Double-Point Material Point Method for Soil-Water Coupled Problems",
        "authors": [
            "Mian Xie",
            "Pedro Navas",
            "Susana Lopez-Querol"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "A semi-implicit two-phase double-point Material Point Method (MPM) formulation, based on the incremental fractional-step method to model large deformation geotechnical problems has been derived. The semi-implicit formulation has two advantages compared with the explicit approach: the time step is independent of the water phase, and the pore pressure field is more stable. The semi-implicit MPM models based on the incremental fractional-step method available in the literature consist of modelling the soil and water mixture using a single set of material points only, in order to save computational time. In this study, we further derive this formulation with two sets of material points to represent the soil and water phases separately. The stress oscillations that are frequently found in the water and soil phases are stabilised with this approach. A new stabilisation method is developed based on the modified F-bar method. The proposed method is validated with two numerical examples under small and large deformations, respectively. After that, Nor-Sand constitutive soil model is used to simulate landslides. Numerical examples show an excellent performance of the proposed coupled MPM and the stabilisation method. The formulation with two sets of material points yields significantly different but more reliable results in the landslides analysis, compared with the single-point approach. Additionally, this research shows that the additional computational cost caused by the additional water material points is acceptable. Therefore, it is recommended to use two sets of material points for certain large deformation geotechnical problems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11951"
    },
    {
        "doc_id": 450,
        "title": "The Ensemble Kalman Filter for Dynamic Inverse Problems",
        "authors": [
            "Simon Weissmann",
            "Neil K. Chada",
            "Xin T. Tong"
        ],
        "subjects": [
            "Numerical Analysis",
            "Methodology"
        ],
        "abstract": "In inverse problems, the goal is to estimate unknown model parameters from noisy observational data. Traditionally, inverse problems are solved under the assumption of a fixed forward operator describing the observation model. In this article, we consider the extension of this approach to situations where we have a dynamic forward model, motivated by applications in scientific computation and engineering. We specifically consider this extension for a derivative-free optimizer, the ensemble Kalman inversion (EKI). We introduce and justify a new methodology called dynamic-EKI, which is a particle-based method with a changing forward operator. We analyze our new method, presenting results related to the control of our particle system through its covariance structure. This analysis includes moment bounds and an ensemble collapse, which are essential for demonstrating a convergence result. We establish convergence in expectation and validate our theoretical findings through experiments with dynamic-EKI applied to a 2D Darcy flow partial differential equation.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11948"
    },
    {
        "doc_id": 451,
        "title": "Friedrichs systems on an interval",
        "authors": [
            "Marko Erceg",
            "Sandeep Kumar Soni"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "There has been significant developments in the classification of boundary conditions of positive symmetric systems, also known as Friedrichs systems, after the introduction of operator theoretic framework. We take a step forward towards applying the abstract theory to the classical framework by studying Friedrichs systems on an interval. Dealing with some difficulties related to the smoothness of eigenvectors, here we present an explicit expression for the dimensions of the kernels of Friedrichs operators only in terms of the values of the coefficients at the end-points of the interval. In particular, this allows for a characterisation of all admissible boundary conditions, i.e.~those leading to bijective realisations.",
        "comments": "MSC Class:          34B05; 35F45; 46C05; 47B28",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11941"
    },
    {
        "doc_id": 452,
        "title": "Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent",
        "authors": [
            "Zhiyu Liu",
            "Zhi Han",
            "Yandong Tang",
            "Xi-Le Zhao",
            "Yao Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it is worth noting that our method does not require the precise estimation of the tensor tubal-rank. Even in cases where the tubal-rank is slightly overestimated, our approach continues to demonstrate robust performance. A series of experiments have been carried out to demonstrate that, as compared to other popular ones, our approach exhibits superior performance in multiple scenarios, in terms of the faster computational speed and the smaller convergence error.",
        "comments": "13 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11940"
    },
    {
        "doc_id": 453,
        "title": "A new proof of the Willmore inequality via a divergence inequality",
        "authors": [
            "Carla Cederbaum",
            "Anabel Miehe"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Differential Geometry"
        ],
        "abstract": "We present a new proof of the Willmore inequality for an arbitrary bounded domain $\u03a9\\subset\\mathbb{R}^{n}$ with smooth boundary. Our proof is based on a parametric geometric inequality involving the electrostatic potential for the domain $\u03a9$; this geometric inequality is derived from a geometric differential inequality in divergence form. Our parametric geometric inequality also allows us to give new proofs of the quantitative Willmore-type and the weighted Minkowski inequalities by Agostiniani and Mazzieri.",
        "comments": "25 pages, 1 figure. Comments very welcome",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11939"
    },
    {
        "doc_id": 454,
        "title": "On the existential theory of the completions of a global field",
        "authors": [
            "Philip Dittmann",
            "Arno Fehm"
        ],
        "subjects": [
            "Logic",
            "Number Theory"
        ],
        "abstract": "We discuss the common existential theory of all or almost all completions of a global function field.",
        "comments": "MSC Class:          03C60; 12L05; 12L12; 12J20; 14G05; 11G25",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11930"
    },
    {
        "doc_id": 455,
        "title": "Large deviations of the empirical spectral measure of supercritical sparse Wigner matrices",
        "authors": [
            "Fanny Augeri"
        ],
        "subjects": [
            "Probability",
            "Mathematical Physics",
            "Combinatorics"
        ],
        "abstract": "Let $\u039e$ be the adjacency matrix of an Erd\u0151s-R\u00e9nyi graph on $n$ vertices and with parameter $p$ and consider $A$ a $n\\times n$ centered random symmetric matrix with bounded i.i.d. entries above the diagonal. When the mean degree $np$ diverges, the empirical spectral measure of the normalized Hadamard product $(A \\circ \u039e)/\\sqrt{np}$ converges weakly in probability to the semicircle law. In the regime where $p\\ll 1$ and $ np \\gg \\log n$, we prove a large deviations principle for the empirical spectral measure with speed $n^2p$ and with a good rate function solution of a certain variational problem. The rate function reveals in particular that the only possible deviations at the exponential scale $n^2p$ are around measures coming from Quadratic Vector Equations. As a byproduct, we obtain a large deviations principle for the empirical spectral measure of supercritical Erd\u0151s-R\u00e9nyi graphs.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11925"
    },
    {
        "doc_id": 456,
        "title": "Ultraknots and limit knots",
        "authors": [
            "Benjamin Bode"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "We prove that every knot type in $\\mathbb{R}^3$ can be parametrised by a smooth function $f:S^1\\to\\mathbb{R}^3$, $f(t)=(x(t),y(t),z(t))$ such that all derivatives $f^{(n)}(t)=(x^{(n)}(t),y^{(n)}(t),z^{(n)}(t))$, $n\\in\\mathbb{N}$, parametrise knots and every knot type appears in the corresponding sequence of knots. We also study knot types that arise as limits of such sequences.",
        "comments": "17 pages, 1 figure",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11918"
    },
    {
        "doc_id": 457,
        "title": "Raviolo vertex algebras, cochains and conformal blocks",
        "authors": [
            "Luigi Alfonsi",
            "Hyungrok Kim",
            "Charles A. S. Young"
        ],
        "subjects": [
            "Quantum Algebra"
        ],
        "abstract": "Raviolo vertex algebras were introduced recently by Garner and Williams in arXiv:2308.04414. Working at the level of cochain complexes, in the present paper we construct spaces of conformal blocks, or more precisely their duals, coinvariants, in the raviolo setting. We prove that the raviolo state-field map correctly captures the limiting behaviour of coinvariants as marked points collide.",
        "comments": "47 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11917"
    },
    {
        "doc_id": 458,
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "Several of the classical results in social choice theory demonstrate that in order for many voting systems to be well-behaved the set domain of individual preferences must satisfy some kind of restriction, such as being single-peaked on a political axis. As a consequence it becomes interesting to measure how diverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference diversity, focusing on the abundance of distinct suborders one subsets of the alternative. We provide a common generalisation of the frequently used concepts of ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our theorems imply a ceiling for the local diversity in domains on large sets of alternatives, which show that in this measure Black's single-peaked domain is in fact optimal. We also demonstrate that for some numbers of alternatives, there are Condorcet domains which have largest local diversity without having maximum order.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11912"
    },
    {
        "doc_id": 459,
        "title": "3D Space Trajectories and beyond: Abstract Art Creation with 3D Printing",
        "authors": [
            "Thierry Dana-Picard",
            "Matias Tejera",
            "Eva Ulbrich"
        ],
        "subjects": [
            "Computational Geometry",
            "Mathematical Software",
            "Symbolic Computation"
        ],
        "abstract": "We present simple models of trajectories in space, both in 2D and in 3D. The first examples, which model bicircular moves in the same direction, are classical curves (epicycloids, etc.). Then, we explore bicircular moves in reverse direction and tricircular moves in 2D and 3D, to explore complex visualisations of extraplanetary movements. These moves are studied in a plane setting. Then, adding increasing complexity, we explore them in a non planar setting (which is a closer model of the real situation). The exploration is followed by using these approaches for creating mathematical art in 2D and 3D printed objects, providing new ways of mathematical representations. Students' activities are organized around this exploration.",
        "comments": "In Proceedings ADG 2023, arXiv:2401.10725",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11909"
    },
    {
        "doc_id": 460,
        "title": "The Locus Story of a Rocking Camel in a Medical Center in the City of Freistadt",
        "authors": [
            "Anna K\u00e4ferb\u00f6ck",
            "Zolt\u00e1n Kov\u00e1cs"
        ],
        "subjects": [
            "Robotics",
            "Computational Geometry",
            "Mathematical Software",
            "Symbolic Computation"
        ],
        "abstract": "We give an example of automated geometry reasoning for an imaginary classroom project by using the free software package GeoGebra Discovery. The project is motivated by a publicly available toy, a rocking camel, installed at a medical center in Upper Austria. We explain how the process of a false conjecture, experimenting, modeling, a precise mathematical setup, and then a proof by automated reasoning could help extend mathematical knowledge at secondary school level and above.",
        "comments": "In Proceedings ADG 2023, arXiv:2401.10725",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11908"
    },
    {
        "doc_id": 461,
        "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad problem: Lessons Learned",
        "authors": [
            "Bel\u00e9n Ari\u00f1o-Morera",
            "Zolt\u00e1n Kov\u00e1cs",
            "Tom\u00e1s Recio",
            "Piedad Tolmos"
        ],
        "subjects": [
            "Symbolic Computation",
            "Artificial Intelligence",
            "Computational Geometry",
            "Mathematical Software"
        ],
        "abstract": "We address, through the automated reasoning tools in GeoGebra Discovery, a problem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying to solve this problem gives rise to four different kind of feedback: the almost instantaneous, automated solution of the proposed problem; the measure of its complexity, according to some recent proposals; the automated discovery of a generalization of the given assertion, showing that the same statement is true over more general polygons than those mentioned in the problem; and the difficulties associated to the analysis of the surprising and involved high number of degenerate cases that appear when using the LocusEquation command in this problem. In our communication we will describe and reflect on these diverse issues, enhancing its exemplar role for showing some of the advantages, problems, and current fields of development of GeoGebra Discovery.",
        "comments": "In Proceedings ADG 2023, arXiv:2401.10725",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11906"
    },
    {
        "doc_id": 462,
        "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving",
        "authors": [
            "Salwa Tabet Gonzalez",
            "Predrag Jani\u010di\u0107",
            "Julien Narboux"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Logic in Computer Science",
            "Mathematical Software"
        ],
        "abstract": "Conjecturing and theorem proving are activities at the center of mathematical practice and are difficult to separate. In this paper, we propose a framework for completing incomplete conjectures and incomplete proofs. The framework can turn a conjecture with missing assumptions and with an under-specified goal into a proper theorem. Also, the proposed framework can help in completing a proof sketch into a human-readable and machine-checkable proof. Our approach is focused on synthetic geometry, and uses coherent logic and constraint solving. The proposed approach is uniform for all three kinds of tasks, flexible and, to our knowledge, unique such approach.",
        "comments": "In Proceedings ADG 2023, arXiv:2401.10725",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11898"
    },
    {
        "doc_id": 463,
        "title": "Shape uncertainty quantification of Maxwell eigenvalues and -modes with application to TESLA cavities",
        "authors": [
            "J\u00fcrgen D\u00f6lz",
            "David Ebert",
            "Sebastian Sch\u00f6ps",
            "Anna Ziegler"
        ],
        "subjects": [
            "Numerical Analysis",
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "We consider Maxwell eigenvalue problems on uncertain shapes with perfectly conducting TESLA cavities being the driving example. Due to the shape uncertainty, the resulting eigenvalues and eigenmodes are also uncertain and it is well known that the eigenvalues may exhibit crossings or bifurcations under perturbation. We discuss how the shape uncertainties can be modelled using the domain mapping approach and how the deformation mapping can be expressed as coefficients in Maxwell's equations. Using derivatives of these coefficients and derivatives of the eigenpairs, we follow a perturbation approach to compute approximations of mean and covariance of the eigenpairs. For small perturbations, these approximations are faster and more accurate than Monte Carlo or similar sampling-based strategies. Numerical experiments for a three-dimensional 9-cell TESLA cavity are presented.",
        "comments": "MSC Class:          47A75; 65J10; 65C05; 65C20; 35Q61",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11890"
    },
    {
        "doc_id": 464,
        "title": "$q$-Rational functions and interpolation with complete Nevanlinna Pick Kernels",
        "authors": [
            "Daniel Alpay",
            "Paula Cerejeiras",
            "Uwe Kaehler",
            "Baruch Schneider"
        ],
        "subjects": [
            "Complex Variables"
        ],
        "abstract": "In this paper we introduce the concept of matrix-valued $q$-rational functions. In comparison to the classic case we give different characterizations with principal emphasise on realizations and discuss algebraic manipulations. We also study the concept of Schur multipliers and complete Nevanlinna Pick kernels in this context and provide first applications in terms of an interpolation problem using Schur multipliers and complete Nevanlinna Pick kernels.",
        "comments": "MSC Class:          47A56; 05A30; 30C10; 32A70",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11887"
    },
    {
        "doc_id": 465,
        "title": "Some Properties of Proper Power Graphs in Finite Abelian Groups",
        "authors": [
            "Dhawlath. G",
            "Raja. V"
        ],
        "subjects": [
            "Group Theory",
            "Combinatorics"
        ],
        "abstract": "The power graph of a group $G$, denoted as $P(G)$, constitutes a simple undirected graph characterized by its vertex set $G$. Specifically, vertices $a,b$ exhibit adjacency exclusively if $a$ belongs to the cyclic subgroup generated by $b$ or vice versa. The corresponding proper power graph of $G$ is obtained by taking $P(G)$ and removing a vertex corresponding to the identity element, which is denoted as $P^*(G)$. In the context of finite abelian groups, this article establishes the sufficient and necessary conditions for the proper power graph's connectedness. Moreover, a precise upper bound for the diameter of $P^*(G)$ in finite abelian groups is provided with sharpness. This article also explores the study of vertex connectivity, center, and planarity.",
        "comments": "12 pages and 2 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11873"
    },
    {
        "doc_id": 466,
        "title": "On the strong Feller property of the heat equation on quantum graphs with Kirchoff noise",
        "authors": [
            "Mohamed Fkirine",
            "Mih\u00e1ly Kov\u00e1cs",
            "Eszter Sikolya"
        ],
        "subjects": [
            "Dynamical Systems",
            "Probability"
        ],
        "abstract": "We consider a so-called quantum graph with standard continuity and Kirchhoff vertex conditions where the Kirchhoff vertex condition is perturbed by Gaussian noise. The strong Feller property of the stochastic parabolic problem is investigated by considering the associated Kirchhoff null-controllability problem. We give an abstract characterization of both problems and apply the abstract result to show that the quantum graph setting is very different from the classical one dimensional boundary noise setting, where the transition semigroup is known to be strong Feller, by giving examples and counterexamples to the strong Feller property. We also comment on the existence and uniqueness of the invariant measure and the regularity of the solution.",
        "comments": "MSC Class:          Primary: 81Q35; 60H15; 35R60; Secondary: 35R02; 47D06; 93E03",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11866"
    },
    {
        "doc_id": 467,
        "title": "Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation",
        "authors": [
            "Xunyu Zhu",
            "Jian Li",
            "Yong Liu",
            "Can Ma",
            "Weiping Wang"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "This work addresses the challenge of democratizing advanced Large Language Models (LLMs) by compressing their mathematical reasoning capabilities into sub-billion parameter Small Language Models (SLMs) without compromising performance. We introduce Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations to construct an EoTD dataset for fine-tuning SLMs. Additionally, we propose the Mix Thoughts Distillation (MTD) framework to enhance the reasoning performance of SLMs. This involves creating a reasoning dataset with multiple thought processes and using it for fine-tuning. Our experimental findings demonstrate that EoTD significantly boosts the reasoning abilities of SLMs, while MTD enables these models to achieve state-of-the-art reasoning performance.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11864"
    },
    {
        "doc_id": 468,
        "title": "Superdiffusive limits for Bessel-driven stochastic kinetics",
        "authors": [
            "Miha Bre\u0161ar",
            "Conrado da Costa",
            "Aleksandar Mijatovi\u0107",
            "Andrew Wade"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "We prove anomalous-diffusion scaling for a one-dimensional stochastic kinetic dynamics, in which the stochastic drift is driven by an exogenous Bessel noise, and also includes endogenous volatility which is permitted to have arbitrary dependence with the exogenous noise. We identify the superdiffusive scaling exponent for the model, and prove a weak convergence result on the corresponding scale. We show how our result extends to admit, as exogenous noise processes, not only Bessel processes but more general processes satisfying certain asymptotic conditions.",
        "comments": "15 pages, 1 figure, for a short YouTube video describing the results, see https://youtu.be/O20plic5Ko8?si=-cg5XGdZlkO9WvYr",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11863"
    },
    {
        "doc_id": 469,
        "title": "Optimization in Sanger Sequencing",
        "authors": [
            "Luisa Carpente",
            "Ana Cerdeira-Pena",
            "Silvia Lorenzo-Freire",
            "\u00c1ngeles S. Places"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Optimization and Control"
        ],
        "abstract": "The main objective of this paper is to solve the optimization problem that is associated with the classification of DNA samples in PCR plates for Sanger sequencing. To achieve this goal, we design an integer linear programming model. Given that the real instances involve the classification of thousands of samples and the linear model can only be solved for small instances, the paper includes a heuristic to cope with bigger problems. The heuristic algorithm is based on the simulated annealing technique. This algorithm obtains satisfactory solutions to the problem in a short amount of time. It has been tested with real data and yields improved results compared to some commercial software typically used in (clinical) laboratories. Moreover, the algorithm has already been implemented in the laboratory and is being successfully used.",
        "comments": "\u00a92019. This manuscript version is made available under the CC-BY-NC-ND 4.0 license (https://creativecommons.org/licenses/by-nc-nd/4.0/). This version of the article has been accepted for publication in Computers & Operations Research. The Version of Record is available online at https://doi.org/10.1016/j.cor.2019.05.011",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11854"
    },
    {
        "doc_id": 470,
        "title": "Self-Labeling the Job Shop Scheduling Problem",
        "authors": [
            "Andrea Corsini",
            "Angelo Porrello",
            "Simone Calderara",
            "Mauro Dell'Amico"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Combinatorics"
        ],
        "abstract": "In this work, we propose a Self-Supervised training strategy specifically designed for combinatorial problems. One of the main obstacles in applying supervised paradigms to such problems is the requirement of expensive target solutions as ground-truth, often produced with costly exact solvers. Inspired by Semi- and Self-Supervised learning, we show that it is possible to easily train generative models by sampling multiple solutions and using the best one according to the problem objective as a pseudo-label. In this way, we iteratively improve the model generation capability by relying only on its self-supervision, completely removing the need for optimality information. We prove the effectiveness of this Self-Labeling strategy on the Job Shop Scheduling (JSP), a complex combinatorial problem that is receiving much attention from the Reinforcement Learning community. We propose a generative model based on the well-known Pointer Network and train it with our strategy. Experiments on two popular benchmarks demonstrate the potential of this approach as the resulting models outperform constructive heuristics and current state-of-the-art Reinforcement Learning proposals.",
        "comments": "ACM Class:          I.2; G.2",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11849"
    },
    {
        "doc_id": 471,
        "title": "Sparse discovery of differential equations based on multi-fidelity Gaussian process",
        "authors": [
            "Yuhuang Meng",
            "Yue Qiu"
        ],
        "subjects": [
            "Numerical Analysis",
            "Machine Learning"
        ],
        "abstract": "Sparse identification of differential equations aims to compute the analytic expressions from the observed data explicitly. However, there exist two primary challenges. Firstly, it exhibits sensitivity to the noise in the observed data, particularly for the derivatives computations. Secondly, existing literature predominantly concentrates on single-fidelity (SF) data, which imposes limitations on its applicability due to the computational cost. In this paper, we present two novel approaches to address these problems from the view of uncertainty quantification. We construct a surrogate model employing the Gaussian process regression (GPR) to mitigate the effect of noise in the observed data, quantify its uncertainty, and ultimately recover the equations accurately. Subsequently, we exploit the multi-fidelity Gaussian processes (MFGP) to address scenarios involving multi-fidelity (MF), sparse, and noisy observed data. We demonstrate the robustness and effectiveness of our methodologies through several numerical experiments.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11825"
    },
    {
        "doc_id": 472,
        "title": "A note on evolution equations with modified Hartree Nonlinearity",
        "authors": [
            "Khaldi Said"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We introduce a mathematical model in $\\mathbb{R}^{n}$ for evolution equations with modified generalized Hartree nonlinearity given by $S_{\u03b1,p,q}(u)=I_\u03b1(|u|^{p+q}).$ One can see that this nonlinearity is not integrable due to the boundedness property of Riesz potential. In other words, we cannot deal with the Cauchy problem of semi-linear evolution equations with $S_{\u03b1,p,q}(u)$ and $L^{1}$-initial velocity.\n  We will show that $S_{\u03b1,p,q}(u)$ produces the same semi-critical exponent that guarantees the global existence of small data solutions as in the well known generalized Hartree nonlinearity $H_{\u03b1,p,q}(u)=|u|^{p}I_\u03b1(|u|^{q})$ provided that the initial velocity belongs to $L^{m}(\\mathbb{R}^{n})$, with $m>1$.\n  We can expect a relation between some physical systems that are modeled and solved using Hartree nonlinearity and those in their modified form due to this coincidence property in the semi-critical exponent.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11821"
    },
    {
        "doc_id": 473,
        "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese",
        "authors": [
            "Liang Xu",
            "Hang Xue",
            "Lei Zhu",
            "Kangkang Zhao"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate the mathematical reasoning abilities of Chinese language models. SC-Math6 is designed as an upgraded Chinese version of the GSM8K dataset with enhanced difficulty, diversity, and application scope. It consists of over 2000 mathematical word problems requiring multi-step reasoning and providing natural language solutions. We propose an innovative scheme to quantify the reasoning capability of large models based on performance over problems with different reasoning steps. Experiments on 12 representative Chinese models demonstrate a clear stratification of reasoning levels, with top models like GPT-4 showing superior performance. SC-Math6 fills the gap in Chinese mathematical reasoning benchmarks and provides a comprehensive testbed to advance the intelligence of Chinese language models.",
        "comments": "8 pages, 7 figures, 4 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11819"
    },
    {
        "doc_id": 474,
        "title": "Direct constructions of some group divisible designs with block size $4$ and up to $50$ points",
        "authors": [
            "R. Julian. R. Abel",
            "Thomas Britz",
            "Yudhistira A. Bunjamin",
            "Diana Combe"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "In this note, we give direct constructions of some group divisible designs (GDDs) with block size $4$ that have up to $50$ points.",
        "comments": "arXiv admin note: text overlap with arXiv:2309.12823",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11809"
    },
    {
        "doc_id": 475,
        "title": "The weakness of finding descending sequences in ill-founded linear orders",
        "authors": [
            "Jun Le Goh",
            "Arno Pauly",
            "Manlio Valenti"
        ],
        "subjects": [
            "Logic",
            "Logic in Computer Science",
            "Combinatorics"
        ],
        "abstract": "We prove that the Weihrauch degree of the problem of finding a bad sequence in a non-well quasi order ($\\mathsf{BS}$) is strictly above that of finding a descending sequence in an ill-founded linear order ($\\mathsf{DS}$). This corrects our mistaken claim in arXiv:2010.03840, which stated that they are Weihrauch equivalent. We prove that K\u00f6nig's lemma $\\mathsf{KL}$ is not Weihrauch reducible to $\\mathsf{DS}$ either, resolving the main open question raised in arXiv:2010.03840.",
        "comments": "4 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11807"
    },
    {
        "doc_id": 476,
        "title": "Type problem and the first eigenvalue",
        "authors": [
            "Bo-Yong Chen",
            "Yuanpu Xiong"
        ],
        "subjects": [
            "Differential Geometry",
            "Complex Variables"
        ],
        "abstract": "In this paper, we study the relationship between the type problem and the asymptotic behavior of the first eigenvalues $\u03bb_1(B_r)$ of ``balls'' $B_r:=\\{\u03c1<r\\}$ on a complete Riemannian manfold $M$ as $r\\rightarrow +\\infty$, where $\u03c1$ is a Lipschitz continuous exhaustion function with $|\\nabla\u03c1|\\leq1$ a.e. on $M$. We show that $M$ is hyperbolic whenever \\[ \u039b_*:= \\liminf_{r\\rightarrow +\\infty} \\{ r^2 \u03bb_1(B_r)\\} >18.624\\cdots. \\] Moreover, an upper bound of $\u039b_*$ in terms of volume growth $\u03bd_*:=\\liminf_{r\\rightarrow +\\infty} \\frac{\\log |B_r|}{\\log r}$ is given as follows \\[ {\u039b_*} \\lesssim \\begin{cases} \u03bd_*^2,\\ \\ \\ &\u03bd_*\\gg1,\\\\ \u03bd_*\\log\\frac{1}{\u03bd_*},&1<\u03bd_*\\ll1. \\end{cases} \\] The exponent $2$ for $\u03bd_*\\gg1$ turns out to be the best possible.",
        "comments": "21 pages. Comments welcome!",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11803"
    },
    {
        "doc_id": 477,
        "title": "Spherical Density-Equalizing Map for Genus-0 Closed Surfaces",
        "authors": [
            "Zhiyuan Lyu",
            "Lok Ming Lui",
            "Gary P. T. Choi"
        ],
        "subjects": [
            "Graphics",
            "Computational Geometry",
            "Differential Geometry",
            "Numerical Analysis"
        ],
        "abstract": "Density-equalizing maps are a class of mapping methods in which the shape deformation is driven by prescribed density information. In recent years, they have been widely used for data visualization on planar domains and planar parameterization of open surfaces. However, the theory and computation of density-equalizing maps for closed surfaces are much less explored. In this work, we develop a novel method for computing spherical density-equalizing maps for genus-0 closed surfaces. Specifically, we first compute a conformal parameterization of the given genus-0 closed surface onto the unit sphere. Then, we perform density equalization on the spherical domain based on the given density information to achieve a spherical density-equalizing map. The bijectivity of the mapping is guaranteed using quasi-conformal theory. We further propose a method for incorporating the harmonic energy and landmark constraints into our formulation to achieve landmark-aligned spherical density-equalizing maps balancing different distortion measures. Using the proposed methods, a large variety of spherical parameterizations can be achieved. Applications to surface registration, remeshing, and data visualization are presented to demonstrate the effectiveness of our methods.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11795"
    },
    {
        "doc_id": 478,
        "title": "Obtaining the pseudoinverse solution of singular range-symmetric linear systems with GMRES-type methods",
        "authors": [
            "Kai Du",
            "Jia-Jun Fan",
            "Fang Wang"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "It is well known that for singular inconsistent range-symmetric linear systems, the generalized minimal residual (GMRES) method determines a least squares solution without breakdown. The reached least squares solution may be or not be the pseudoinverse solution. We show that a lift strategy can be used to obtain the pseudoinverse solution. In addition, we propose a new iterative method named RSMAR (minimum $\\mathbf A$-residual) for range-symmetric linear systems $\\mathbf A\\mathbf x=\\mathbf b$. At step $k$ RSMAR minimizes $\\|\\mathbf A\\mathbf r_k\\|$ in the $k$th Krylov subspace generated with $\\{\\mathbf A, \\mathbf r_0\\}$ rather than $\\|\\mathbf r_k\\|$, where $\\mathbf r_k$ is the $k$th residual vector and $\\|\\cdot\\|$ denotes the Euclidean vector norm. We show that RSMAR and GMRES terminate with the same least squares solution when applied to range-symmetric linear systems. We provide two implementations for RSMAR. Our numerical experiments show that RSMAR is the most suitable method among GMRES-type methods for singular inconsistent range-symmetric linear systems.",
        "comments": "22 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11788"
    },
    {
        "doc_id": 479,
        "title": "A Comparative Study of Numerical Methods for Approximating the Solutions of a Macroscopic Automated-Vehicle Traffic Flow Model",
        "authors": [
            "George Titakis",
            "Iasson Karafyllis",
            "Dionysis Theodosis",
            "Ioannis Papamichail",
            "Markos Papageorgiou"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this paper, a particle method is used to approximate the solutions of a \"fluid-like\" macroscopic traffic flow model for automated vehicles. It is shown that this method preserves certain differential inequalities that hold for the macroscopic traffic model: mass is preserved, the mechanical energy is decaying and an energy functional is also decaying. To demonstrate the advantages of the particle method under consideration, a comparison with other numerical methods for viscous compressible fluid models is provided. Since the solutions of the macroscopic traffic model can be approximated by the solutions of a reduced model consisting of a single nonlinear heat-type partial differential equation, the numerical solutions produced by the particle method are also compared with the numerical solutions of the reduced model. Finally, a traffic simulation scenario and a comparison with the Aw-Rascle-Zhang (ARZ) model are provided, illustrating the advantages of the use of automated vehicles.",
        "comments": "34 pages, 19 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11787"
    },
    {
        "doc_id": 480,
        "title": "EPIC: a provable accelerated Eigensolver based on Preconditioning and Implicit Convexity",
        "authors": [
            "Nian Shao",
            "Wenbin Chen",
            "Zhaojun Bai"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "This paper is concerned with the extraction of the smallest eigenvalue and the corresponding eigenvector of a symmetric positive definite matrix pencil. We reveal implicit convexity of the eigenvalue problem in Euclidean space. A provable accelerated eigensolver based on preconditioning and implicit convexity (EPIC) is proposed. Theoretical analysis shows the acceleration of EPIC with the rate of convergence resembling the expected rate of convergence of the well-known locally optimal preconditioned conjugate gradient (LOPCG). A complete proof of the expected rate of convergence of LOPCG is elusive so far. Numerical results confirm our theoretical findings of EPIC.",
        "comments": "MSC Class:          15A08; 65F08; 65F15; 90C25",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11786"
    },
    {
        "doc_id": 481,
        "title": "Kleisli categories, T-categories and internal categories",
        "authors": [
            "Dominique Bourn"
        ],
        "subjects": [
            "Category Theory"
        ],
        "abstract": "We investigate the properties of the Kleisli category KlT of a monad (T,\u03bb,\u03bc) on a category E and in particular the existence of (some kind of) pullbacks. This culminates when the monad is cartesian. In this case, we show that any T-category in E in the sense of A. Burroni coincides with a special kind of internal category in KlT . So, it is the case in particular for T -operads and T -multicategories. More unexpectedly, this, in turn, sheds new lights on internal categories and n-categories.",
        "comments": "46 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11781"
    },
    {
        "doc_id": 482,
        "title": "Numerical Solutions for Stochastic Continuous-time Algebraic Riccati Equations",
        "authors": [
            "Tsung-Ming Huang",
            "Yueh-Cheng Kuo",
            "Ren-Cang Li",
            "Wen-Wei Lin"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "We are concerned with efficient numerical methods for stochastic continuous-time algebraic Riccati equations (SCARE). Such equations frequently arise from the state-dependent Riccati equation approach which is perhaps the only systematic way today to study nonlinear control problems. Often involved Riccati-type equations are of small scale, but have to be solved repeatedly in real time. Important applications include the 3D missile/target engagement, the F16 aircraft flight control, and the quadrotor optimal control, to name a few. A new inner-outer iterative method that combines the fixed-point strategy and the structure-preserving doubling algorithm (SDA) is proposed. It is proved that the method is monotonically convergent, and in particular, taking the zero matrix as initial, the method converges to the desired stabilizing solution. Previously, Newton's method has been called to solve SCARE, but it was mostly investigated from its theoretic aspect than numerical aspect in terms of robust and efficient numerical implementation. For that reason, we revisit Newton's method for SCARE, focusing on how to calculate each Newton iterative step efficiently so that Newton's method for SCARE can become practical. It is proposed to use our new inner-outer iterative method, which is provably convergent, to provide critical initial starting points for Newton's method to ensure its convergence. Finally several numerical experiments are conducted to validate the new method and robust implementation of Newton's method.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11774"
    },
    {
        "doc_id": 483,
        "title": "Bordism of flow modules and exact Lagrangians",
        "authors": [
            "Noah Porcelli",
            "Ivan Smith"
        ],
        "subjects": [
            "Symplectic Geometry",
            "Algebraic Topology"
        ],
        "abstract": "For a stably framed Liouville manifold X , we construct a \"Donaldson-Fukaya category over the sphere spectrum\" F(X; S). The objects are closed exact Lagrangians whose Gauss maps are nullhomotopic compatibly with the ambient stable framing, and the morphisms are bordism classes of framed flow modules over Lagrangian Floer flow categories; this is enriched in modules over the framed bordism ring. We develop an obstruction theory for lifting quasi-isomorphisms in the usual Fukaya category to quasi-isomorphisms in appropriate truncations or quotients of F(X; S). Applications include constraints on the smooth structure of exact Lagrangians in certain plumbings, and the construction of non-trivial symplectic mapping classes which act trivially on the integral Fukaya category for a wide class of affine varieties.",
        "comments": "Comments welcome!",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11766"
    },
    {
        "doc_id": 484,
        "title": "G. S. Tseytin's seven-relation semigroup with undecidable word problem",
        "authors": [
            "Carl-Fredrik Nyberg-Brodda"
        ],
        "subjects": [
            "History and Overview",
            "Group Theory"
        ],
        "abstract": "We give an introduction to the ideas behind G. S. Tseytin's 1958 construction of a seven-relation semigroup with undecidable word problem. We give a history of the ideas leading up to its construction, some intuition for the proof, and provide an overview of some subsequent results and developments which stem from this remarkable semigroup. An English translation of Tseytin's article by the author of the present article is supplemented at the end of the article (the Russian original was published in Trudy Mat. Inst. Steklov 52 (1958), pp. 172--189).",
        "comments": "22 page original article + 16 page translation. Comments welcome!",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11757"
    },
    {
        "doc_id": 485,
        "title": "Univalent Enriched Categories and the Enriched Rezk Completion",
        "authors": [
            "Niels van der Weide"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Category Theory"
        ],
        "abstract": "Enriched categories are categories whose sets of morphisms are enriched with extra structure. Such categories play a prominent role in the study of higher categories, homotopy theory, and the semantics of programming languages. In this paper, we study univalent enriched categories. We prove that all essentially surjective and fully faithful functors between univalent enriched categories are equivalences, and we show that every enriched category admits a Rezk completion. Finally, we use the Rezk completion for enriched categories to construct univalent enriched Kleisli categories.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11752"
    },
    {
        "doc_id": 486,
        "title": "On Rosser theories",
        "authors": [
            "Yong Cheng"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "Rosser theories play an important role in the study of the incompleteness phenomenon and mete-mathematics of arithmetic. In this paper, we first define notions of $n$-Rosser theories, exact $n$-Rosser theories, effectively $n$-Rosser theories and effectively exact $n$-Rosser theories (see Definition 1.8). Our definitions are not restricted to arithmetic languages. Then we systematically examine properties of $n$-Rosser theories and relationships among them. Especially, we generalize some important theorems about Rosser theories for RE sets in the literature to $n$-Rosser theories in a general setting.",
        "comments": "26 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11749"
    },
    {
        "doc_id": 487,
        "title": "Transition probability of discrete geodesic flow on the standard non-uniform quotient of $PGL_3$",
        "authors": [
            "Sanghoon Kwon"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "We describe the local transition probability of a singular diagonal action on the standard non-uniform quotient of $PGL_3$ associated to the type 1 geodesic flow. As a consequence, we deduce the strongly positive recurrence property of the geodesic flow.",
        "comments": "11 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11747"
    },
    {
        "doc_id": 488,
        "title": "Finite horizon optimal control of reaction-diffusion SIV epidemic system with stochastic environment",
        "authors": [
            "Zong Wang"
        ],
        "subjects": [
            "Optimization and Control",
            "Dynamical Systems"
        ],
        "abstract": "This contribution mainly focuses on the finite horizon optimal control problems of a susceptible-infected-vaccinated(SIV) epidemic system governed by reaction-diffusion equations and Markov switching. Stochastic dynamic programming is employed to find the optimal vaccination effort and economic return for a stochastic reaction diffusion SIV epidemic model. To achieve this, a key step is to show the existence and uniqueness of invariant measure for the model. Then, we obtained the necessary and sufficient conditions for the near-optimal control. Furthermore, we give an algorithm to approximate the Hamilton-Jacobi Bellman (HJB) equation. Finally, some numerical simulations are presented to confirm our analytic results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11744"
    },
    {
        "doc_id": 489,
        "title": "On partial endomorphisms of a star graph",
        "authors": [
            "Ilinka Dimitrova",
            "V\u00edtor H. Fernandes",
            "J\u00f6rg Koppitz"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "In this paper we consider the monoids of all partial endomorphisms, of all partial weak endomorphisms, of all injective partial endomorphisms, of all partial strong endomorphisms and of all partial strong weak endomorphisms of a star graph with a finite number of vertices. Our main objective is to determine their ranks. We also describe their Green's relations, calculate their cardinalities and study their regularity.",
        "comments": "MSC Class:          20M20; 20M10; 05C12; 05C25",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11741"
    },
    {
        "doc_id": 490,
        "title": "Sphractal: Estimating the Fractal Dimension of Surfaces Computed from Precise Atomic Coordinates via Box-Counting Algorithm",
        "authors": [
            "Jonathan Yik Chang Ting",
            "Andrew Thomas Agars Wood",
            "Amanda Susan Barnard"
        ],
        "subjects": [
            "Mathematical Software",
            "Atomic Physics",
            "Computational Physics"
        ],
        "abstract": "The fractal dimension of a surface allows its degree of roughness to be characterised quantitatively. However, limited effort has been attempted to compute the fractal dimension of surfaces computed from precisely known atomic coordinates from computational biomolecular and nanomaterial studies. This work proposes methods to estimate the fractal dimension of the surface of any three-dimensional object composed of spheres, by representing it as either a voxelised point cloud or a mathematically exact surface, and computing its box-counting dimension. Sphractal is published as a Python package that provides these functionalities, and its utility is demonstrated on a set of simulated palladium nanoparticle data.",
        "comments": "46 pages, 26 figures, submitted to Advanced Theory and Simulations",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11737"
    },
    {
        "doc_id": 491,
        "title": "Approximate solutions to a nonlinear functional differential equation",
        "authors": [
            "Nicholas Hale",
            "Enrique Thomann",
            "JAC Weideman"
        ],
        "subjects": [
            "Classical Analysis and ODEs",
            "Numerical Analysis"
        ],
        "abstract": "A functional differential equation related to the logistic equation is studied by a combination of numerical and perturbation methods. Parameter regions are identified where the solution to the nonlinear problem is approximated well by known series solutions of the linear version of the equation. The solution space for a certain class of functions is then mapped out using a continuation approach.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11733"
    },
    {
        "doc_id": 492,
        "title": "M\u00f6bius Inversion and Duality for Summations of Stable Graphs",
        "authors": [
            "Zhiyuan Wang",
            "Jian Zhou"
        ],
        "subjects": [
            "Combinatorics",
            "Mathematical Physics",
            "Algebraic Geometry"
        ],
        "abstract": "Using the stratifications of Deligne-Mumford moduli spaces $\\overline{\\mathcal M}_{g,n}$ indexed by stable graphs, we introduce a partially ordered set of stable graphs by defining a partial ordering on the set of connected stable graphs of genus $g$ with $n$ external edges. By modifying the usual definition of zeta function and M\u00f6bius function of a poset, we introduce generalized ($\\mathbb Q$-valued) zeta function and generalized ($\\mathbb Q$-valued) M\u00f6bius function of the poset of stable graphs. We use them to proved a generalized M\u00f6bius inversion formula for functions on the poset of stable graphs. Two applications related to duality in earlier work are also presented.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11717"
    },
    {
        "doc_id": 493,
        "title": "Integrality of Hecke eigenvalues and the growth of Hecke fields",
        "authors": [
            "Kenji Sakugawa",
            "Shingo Sugiyama"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We prove that Hecke eigenvalues for any Hilbert and Siegel modular forms are algebraic integers. Our method does not rely on cohomologicality nor Galois representations. We apply the integrality of Hecke eigenvalues for Hilbert modular forms of non-parallel weight to the estimation of the growth of Hecke fields of Hilbert cusp forms with non-vanishing central $L$-values. As a further application, we give the growth of the fields of rationality of cuspidal automorphic representations of ${\\rm GL}_{2d}(\\mathbb{A}_\\mathbb{Q})$ for a prime number $d$ with non-vanishing central $L$-values. We also apply the integrality of Hecke eigenvalues for holomorphic Siegel cusp forms of general degree in order to give the growth of the Hecke fields of those forms.",
        "comments": "MSC Class:          Primary 11F60; Secondary 11F41; 11F46; 11F75; 11R04",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11716"
    },
    {
        "doc_id": 494,
        "title": "Conjugate Direction Methods Under Inconsistent Systems",
        "authors": [
            "Alexander Lim",
            "Yang Liu",
            "Fred Roosta"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Since the development of the conjugate gradient (CG) method in 1952 by Hestenes and Stiefel, CG, has become an indispensable tool in computational mathematics for solving positive definite linear systems. On the other hand, the conjugate residual (CR) method, closely related CG and introduced by Stiefel in 1955 for the same settings, remains relatively less known outside the numerical linear algebra community. Since their inception, these methods -- henceforth collectively referred to as conjugate direction methods -- have been extended beyond positive definite to indefinite, albeit consistent, settings. Going one step further, in this paper, we investigate theoretical and empirical properties of these methods under inconsistent systems. Among other things, we show that small modifications to the original algorithms allow for the pseudo-inverse solution. Furthermore, we show that CR is essentially equivalent to the minimum residual method, proposed by Paige and Saunders in 1975, in such contexts. Lastly, we conduct a series of numerical experiments to shed lights on their numerical stability (or lack thereof) and their performance for inconsistent systems. Surprisingly, we will demonstrate that, unlike CR and contrary to popular belief, CG can exhibit significant numerical instability, bordering on catastrophe in some instances.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11714"
    },
    {
        "doc_id": 495,
        "title": "A First Step Towards Runtime Analysis of Evolutionary Neural Architecture Search",
        "authors": [
            "Zeqiong Lv",
            "Chao Qian",
            "Yanan Sun"
        ],
        "subjects": [
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Evolutionary neural architecture search (ENAS) employs evolutionary algorithms to find high-performing neural architectures automatically, and has achieved great success. However, compared to the empirical success, its rigorous theoretical analysis has yet to be touched. This work goes preliminary steps toward the mathematical runtime analysis of ENAS. In particular, we define a binary classification problem UNIFORM, and formulate an explicit fitness function to represent the relationship between neural architecture and classification accuracy. Furthermore, we consider (1+1)-ENAS algorithm with mutation to optimize the neural architecture, and obtain the following runtime bounds: 1) the one-bit mutation finds the optimum in an expected runtime of $O(n)$ and $\u03a9(\\log n)$; 2) the multi-bit mutation finds the optimum in an expected runtime of $\u0398(n)$. These theoretical results show that one-bit and multi-bit mutations achieve nearly the same performance on UNIFORM. We provide insight into the choices of mutation in the ENAS community: although multi-bit mutation can change the step size to prevent a local trap, this may not always improve runtime. Empirical results also verify the equivalence of these two mutation operators. This work begins the runtime analysis of ENAS, laying the foundation for further theoretical studies to guide the design of ENAS.",
        "comments": "8 pages, 3 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11712"
    },
    {
        "doc_id": 496,
        "title": "A translation of \"On the positive representation of polynomials\" by Ernst Meissner",
        "authors": [
            "Hannah K. Wayment-Steele"
        ],
        "subjects": [
            "History and Overview"
        ],
        "abstract": "We provide an English translation of \"\u00dcber positive Darstellungen von Polynomen\" by Ernst Meissner, originally published 1911 in Mathematische Annalen (70) 223-235.",
        "comments": "We welcome feedback on this translation to wayment (at) brandeis (dot) edu",
        "date": "10 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.11693"
    },
    {
        "doc_id": 497,
        "title": "Dynamic learning of synchronization in nonlinear coupled systems",
        "authors": [
            "Yong Wu",
            "Qianming Ding",
            "Weifang Huang",
            "Tianyu Li",
            "Dong Yu",
            "Ya Jia"
        ],
        "subjects": [
            "Biological Physics",
            "Chaotic Dynamics"
        ],
        "abstract": "Synchronous phenomenon exists in various natural and engineering systems. To obtain synchronization states within nonlinear coupled systems, we develop mathematical optimization techniques for the dynamic learning of synchronization (DLS) to capture the state differences between nodes within the system and dynamically adjust weights. By utilizing our novel algorithm formulae, nonlinear coupled systems can maintain a stable state of synchronization after appropriate weight adjustments. We present several variants of the DLS techniques including the self-adaptive, the supervised and the hybrid methods, all of which reliably demonstrate their capability to facilitate synchronization in heterogeneous networks, such as small-world, scale-free, and random networks. As application of DLS technique, we first validate the efficacy of our DLS technique by using a simple FitzHugh-Nagumo neural network, and the effects of the technique on both global and local synchronization are studied. Then the DLS technique is applied to a complex nonlinear system, i.e., the network of Hodgkin-Huxley neurons with chemical synaptic coupling model. This study offers a novel perspective on comprehending synchronization phenomena within nonlinear systems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11691"
    },
    {
        "doc_id": 498,
        "title": "Two Necessary and Sufficient Conditions to the Solvability of the Exterior Dirichlet Problem for the Monge-Amp\u00e8re Equation",
        "authors": [
            "Cong Wang",
            "Jiguang Bao"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "The present paper provides two necessary and sufficient conditions for the existence of solutions to the exterior Dirichlet problem of the Monge-Amp\u00e8re equation with prescribed asymptotic behavior at infinity. By an adapted smooth approximation argument, we prove that the problem is solvable if and only if the boundary value is semi-convex with respect to the inner boundary, which is our first proposed new concept. Along the lines of Perron's method for Laplace equation, we obtain the threshold for solvability in the asymptotic behavior at infinity of the solution, and remove the $C^2$ regularity assumptions on the boundary value and on the inner boundary which are required in the proofs of the corresponding existence theorems in the recent literatures.",
        "comments": "30 pages, 2 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11690"
    },
    {
        "doc_id": 499,
        "title": "A system of NLS arising in optical material without Galilean symmetry",
        "authors": [
            "Yuan Li",
            "Kai Wang",
            "Qingxuan Wang"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider a system of NLS with cubic interactions arising in nonlinear optics without Galilean symmetry. The absence of Galilean symmetry can lead to many difficulties, such as global existence and blowup problems; see [Comm. Partial Differential Equations 46, 11 (2021), 2134-2170]. In this paper, we mainly focus on the influence of the absence of this symmetry on the traveling waves of the NLS system. Firstly, we obtain the existence of traveling solitary wave solutions that are non-radial and complex-valued. Secondly, using the asymptotic analysis method, when the frequency is sufficiently large, we establish the high frequency limit of the traveling solitary wave solution. Finally, for the mass critical case, we provide a novel condition for the existence of global solutions which is significantly different from the classical. In particular, this new condition breaks the traditional optimal assumption about initial data.",
        "comments": "28 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11683"
    },
    {
        "doc_id": 500,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 501,
        "title": "Matching biomolecular structures by registration of point clouds",
        "authors": [
            "Michael Habeck",
            "Andreas Kr\u00f6pelin",
            "Nima Vakili"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Motivation: Assessing the match between two biomolecular structures is at the heart of structural analyses such as superposition, alignment and docking. These tasks are typically solved with specialized structure-matching techniques implemented in software for protein structural alignment, rigid-body docking, or rigid fitting into cryo-EM maps. Results: We present a unifying framework to compare biomolecular structures by applying ideas from computer vision. The structures are represented as three-dimensional point clouds and compared by quantifying their overlap. We use the kernel correlation to measure point cloud overlap, and discuss local and global optimization strategies for maximizing the kernel correlation over the space of rigid transformations. We derive a majorization-minimization procedure that can be used to register two point clouds without establishing a point-to-point correspondence. We demonstrate that the majorization-minimization algorithms outperform the commonly used Iterative Closest Point registration algorithm. Furthermore, we discuss and benchmark a randomization strategy for globally optimizing the kernel correlation. We illustrate the approach on various 3D fitting problems such as the comparison of circularly permuted structures and rigid fitting of cryo-EM maps or bead models from small-angle scattering.",
        "comments": "18 pages (main text), 7 figures (main text)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12082"
    },
    {
        "doc_id": 502,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Mariam de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 503,
        "title": "Approximating a linear dynamical system from non-sequential data",
        "authors": [
            "Cliff Stein",
            "Pratik Worah"
        ],
        "subjects": [
            "Genomics"
        ],
        "abstract": "Given non-sequential snapshots from instances of a dynamical system, we design a compressed sensing based algorithm that reconstructs the dynamical system. We formally prove that successful reconstruction is possible under the assumption that we can construct an approximate clock from a subset of the coordinates of the underlying system.\n  As an application, we argue that our assumption is likely true for genomic datasets, and we recover the underlying nuclear receptor networks and predict pathways, as opposed to genes, that may differentiate phenotypes in some publicly available datasets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11858"
    },
    {
        "doc_id": 504,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 505,
        "title": "Full-dimensional characterisation of time-warped spike-time stimulus-response distribution geometries",
        "authors": [
            "James B Isbister"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Characterising the representation of sensory stimuli in the brain is a fundamental scientific endeavor, which can illuminate principles of information coding. Most characterizations reduce the dimensionality of neural data by converting spike trains to firing rates or binned spike counts, applying explicitly named methods of ``dimensionality reduction'', or collapsing trial-to-trial variability. Characterisation of the full-dimensional geometry of timing-based representations may provide unexpected insights into how complex high-dimensional information is encoded. Recent research shows that the distribution of representations elicited over trials of a single stimulus can be geometrically characterized without the application of dimensionality reduction, maintaining the temporal spiking information of individual neurons in a cell assembly and illuminating rich geometric structure. We extend these results, showing that precise spike time patterns for larger cell assemblies are time-warped (i.e. stretched or compressed) on each trial. Moreover, by geometrically characterizing distributions of large spike time patterns, our analysis supports the hypothesis that the degree to which a spike time pattern is time-warped depends on the cortical area's background activity level on a single trial. Finally, we suggest that the proliferation of large electrophysiology datasets and the increasing concentration of ``neural geometrists'', creates ideal conditions for characterization of full-dimensional spike time representations, in complement to dimensionality reduction approaches.",
        "comments": "Accepted as an extended abstract at the NeurReps workshop at NeurIPS 2023. The workshop doesn't publish extended abstracts so submitting here",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11784"
    },
    {
        "doc_id": 506,
        "title": "Impact of temporal interaction on the evolution of cooperation",
        "authors": [
            "Yujie He",
            "Tianyu Ren",
            "Junjun Zheng",
            "Huawen Liang"
        ],
        "subjects": [
            "Physics and Society",
            "Social and Information Networks",
            "Populations and Evolution"
        ],
        "abstract": "This research investigates the impact of dynamic interactions with time-varying topologies on the evolution of cooperative behaviours in social dilemmas. Traditional research has focused on deterministic rules governing pairwise interactions, yet the impact of interaction frequency and synchronicity on cooperation remains underexplored. Addressing this gap, our work introduces two temporal interaction mechanisms to model the stochastic or periodic participation of individuals in these games, acknowledging real-life variances due to exogenous temporal factors and geographical time differences. We consider that the interaction state significantly influences both game payoff calculations and the strategy updating process, offering new insights into the emergence and sustainability of cooperation. Our results indicate that maximum game participation frequency is suboptimal under a stochastic interaction mechanism. Instead, an intermediate region of activation probability yields the highest cooperation level, especially under strong dilemma conditions. This suggests that a balance between inactivity security and interaction frequency is crucial. Furthermore, local synchronization of interactions within specific areas is shown to be beneficial, as time differences hinder the spread of cross-structures but promote the formation of dense cooperative clusters with smoother boundaries. Our findings provide an intuitive understanding of node-based temporality and probabilistic interactions, contributing to the broader discourse on resolving social dilemmas.",
        "comments": "7 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11782"
    },
    {
        "doc_id": 507,
        "title": "Combining oligo pools and Golden Gate cloning to create protein variant libraries or guide RNA libraries for CRISPR applications",
        "authors": [
            "Alicia Maci\u00e1 Valero",
            "Rianne C. Prins",
            "Thijs de Vroet",
            "Sonja Billerbeck"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biomolecules"
        ],
        "abstract": "Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 350 bases), a higher error rate compared to alternative synthesis methods, and the presence of truncated molecules in the pool due to incomplete synthesis. Here, we provide users with a comprehensive protocol that details how oligo pools can be used in combination with Golden Gate cloning to create user-defined protein mutant libraries, as well as single guide RNA libraries for CRISPR applications. Our methods are optimized to work within the Yeast Toolkit Golden Gate scheme, but are in principle compatible with any other Golden Gate-based modular cloning toolkit and extendable to other restriction enzyme-based cloning methods beyond Golden Gate. Our methods yield high-quality, affordable, in-house variant libraries.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11746"
    },
    {
        "doc_id": 508,
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "authors": [
            "Chaoqian Wang",
            "Matja\u017e Perc",
            "Attila Szolnoki"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Statistical Mechanics",
            "Computational Complexity",
            "Cellular Automata and Lattice Gases",
            "Populations and Evolution"
        ],
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Ball-and-Box problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11686"
    },
    {
        "doc_id": 509,
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "authors": [
            "Courtney Golden",
            "Dan Ilan",
            "Nicholas Cebry",
            "Christopher Batten"
        ],
        "subjects": [
            "Hardware Architecture",
            "Genomics"
        ],
        "abstract": "DNA sequence alignment is an important workload in computational genomics. Reference-guided DNA assembly involves aligning many read sequences against candidate locations in a long reference genome. To reduce the computational load of this alignment, candidate locations can be pre-filtered using simpler alignment algorithms like edit distance. Prior work has explored accelerating filtering on simulated compute-in-DRAM, due to the massive parallelism of compute-in-memory architectures. In this paper, we present work-in-progress on accelerating filtering using a commercial compute-in-SRAM accelerator. We leverage the recently released Gemini accelerator platform from GSI Technology, which is the first, to our knowledge, commercial-scale compute-in-SRAM system. We accelerate the Myers' bit-parallel edit distance algorithm, producing average speedups of 14.1x over single-core CPU performance. Individual query/candidate alignments produce speedups of up to 24.1x. These early results suggest this novel architecture is well-suited to accelerating the filtering step of sequence-to-sequence DNA alignment.",
        "comments": "Journal ref:        5th Workshop on Accelerator Architecture in Computational Biology and Bioinformatics (AACBB), June 2023",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11685"
    },
    {
        "doc_id": 510,
        "title": "Modern approaches to improving phase contrast electron microscopy",
        "authors": [
            "Jeremy J. Axelrod",
            "Jessie T. Zhang",
            "Petar N. Petrov",
            "Robert M. Glaeser",
            "Holger Mueller"
        ],
        "subjects": [
            "Quantitative Methods",
            "Optics",
            "Biomolecules"
        ],
        "abstract": "Although defocus can be used to generate partial phase contrast in transmission electron microscope images, cryo-electron microscopy (cryo-EM) can be further improved by the development of phase plates which increase contrast by applying a phase shift to the unscattered part of the electron beam. Many approaches have been investigated, including the ponderomotive interaction between light and electrons. We review the recent successes achieved with this method in high-resolution, single-particle cryo-EM. We also review the status of using pulsed or near-field enhanced laser light as alternatives, along with approaches that use scanning transmission electron microscopy (STEM) with a segmented detector rather than a phase plate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11678"
    },
    {
        "doc_id": 511,
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "authors": [
            "Pratik Worah"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.\n  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11562"
    },
    {
        "doc_id": 512,
        "title": "Understanding Hepatitis B Virus Infection through Hepatocyte Proliferation and Capsid Recycling",
        "authors": [
            "Rupchand Sutradhar",
            "D C Dalal"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "Proliferation of uninfected as well as infected hepatocytes and recycling of DNA-containing\n  capsids are two major mechanisms playing significant roles in the clearance of hepatitis B\n  virus (HBV) infection. In this study, the temporal dynamics of this infection are investigated\n  through two in silico bio-mathematical models considering both proliferation of hepatocytes\n  and the recycling of capsids. Both models are formulated on the basis of a key finding in the existing literature: mitosis of infected yields in two uninfected progenies. In the first model,\n  we examine regular proliferation (occurs continuously), while the second model deals with the\n  irregular proliferation (happens when the total number of liver cells decreases to less than 70%\n  of its initial volume). The models are calibrated with the experimental data obtained from\n  an adult chimpanzee. Results of this study suggest that when both hepatocytes proliferate\n  with equal rate, proliferation aids the individual in a rapid recovery from the acute infection\n  whereas in the case of chronic infection, the severity of the infection increases if the proliferation\n  occurs frequently. On the other hand, if the infected cells proliferate at a slower rate than uninfected cells, the proliferation of uninfected hepatocytes contributes to increase the infection,\n  but the proliferation of infected hepatocytes acts to reduce the infection from the long-term\n  perspective. Furthermore, it is also observed that the differences between the outcomes of\n  regular and irregular proliferations are substantial and noteworthy.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11481"
    },
    {
        "doc_id": 513,
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "authors": [
            "Li Yin",
            "Xiong Yu",
            "Fan Wenxin",
            "Wang Kai",
            "Yu Qingqing",
            "Si Liping",
            "van der Smagt Patrick",
            "Tang Jun",
            "Chen Nutan"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.\n  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM models, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these RMSEs are significantly lower than the random prediction error of $4.55$.\n  Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11447"
    },
    {
        "doc_id": 514,
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "authors": [
            "Haoqiang Guo",
            "Sendong Zhao",
            "Haochun Wang",
            "Yanrui Du",
            "Bing Qin"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Biomolecules"
        ],
        "abstract": "Deep learning is now widely used in drug discovery, providing significant acceleration and cost reduction. As the most fundamental building block, molecular representation is essential for predicting molecular properties to enable various downstream applications. Most existing methods attempt to incorporate more information to learn better representations. However, not all features are equally important for a specific task. Ignoring this would potentially compromise the training efficiency and predictive accuracy. To address this issue, we propose a novel approach, which treats language models as an agent and molecular pretraining models as a knowledge base. The agent accentuates task-relevant features in the molecular representation by understanding the natural language description of the task, just as a tailor customizes clothes for clients. Thus, we call this approach MolTailor. Evaluations demonstrate MolTailor's superior performance over baselines, validating the efficacy of enhancing relevance for molecular representation learning. This illustrates the potential of language model guided optimization to better exploit and unleash the capabilities of existing powerful molecular representation methods. Our codes and appendix are available at https://github.com/SCIR-HI/MolTailor.",
        "comments": "Accepted by AAAI 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11403"
    },
    {
        "doc_id": 515,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 516,
        "title": "Sensory adaptation in a continuum model of bacterial chemotaxis -- working range, cost-accuracy relation, and coupled systems",
        "authors": [
            "Vansh Kharbanda",
            "Benedikt Sabass"
        ],
        "subjects": [
            "Cell Behavior",
            "Soft Condensed Matter"
        ],
        "abstract": "Sensory adaptation enables organisms to adjust their perception in a changing environment. A paradigm is bacterial chemotaxis, where the output activity of chemoreceptors is adapted to different baseline concentrations via receptor methylation. The range of internal receptor states limits the stimulus magnitude to which these systems can adapt. Here, we employ a highly idealized, Langevin-equation based model to study how the finite range of state variables affects the adaptation accuracy and the energy dissipation in individual and coupled systems. Maintaining an adaptive state requires constant energy dissipation. We show that the steady-state dissipation rate increases approximately linearly with the adaptation accuracy for varying stimulus magnitudes in the so-called perfect adaptation limit. This result complements the well-known logarithmic cost-accuracy relationship for varying chemical driving. Next, we study linearly coupled pairs of sensory units. We find that the interaction reduces the dissipation rate per unit and affects the overall cost-accuracy relationship. A coupling of the slow methylation variables results in a better accuracy than a coupling of activities. Overall, the findings highlight the significance of both the working range and collective operation mode as crucial design factors that impact the accuracy and energy expenditure of molecular adaptation networks.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11341"
    },
    {
        "doc_id": 517,
        "title": "Uncertainty quantification of receptor ligand binding sites prediction",
        "authors": [
            "Nanjie Chen",
            "Dongliang Yu",
            "Dmitri Beglov",
            "Mark Kon",
            "Julio Enrique Castrillon Candas"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Recent advancements in protein docking site prediction have highlighted the limitations of traditional rigid docking algorithms, like PIPER, which often neglect critical stochastic elements such as solvent-induced fluctuations. These oversights can lead to inaccuracies in identifying viable docking sites due to the complexity of high-dimensional, stochastic energy manifolds with low regularity. To address this issue, our research introduces a novel model where the molecular shapes of ligands and receptors are represented using multi-variate Karhunen-Lo `eve (KL) expansions. This method effectively captures the stochastic nature of energy manifolds, allowing for a more accurate representation of molecular interactions.Developed as a plugin for PIPER, our scientific computing software enhances the platform, delivering robust uncertainty measures for the energy manifolds of ranked binding sites. Our results demonstrate that top-ranked binding sites, characterized by lower uncertainty in the stochastic energy manifold, align closely with actual docking sites. Conversely, sites with higher uncertainty correlate with less optimal docking positions. This distinction not only validates our approach but also sets a new standard in protein docking predictions, offering substantial implications for future molecular interaction research and drug development.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11312"
    },
    {
        "doc_id": 518,
        "title": "Seasonality of primary productivity affects coastal species more than its magnitude",
        "authors": [
            "Carlota Muniz",
            "Christopher McQuaid",
            "Nicolas Weidberg"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "While the importance of extreme conditions is recognised, patterns in species abundances are often interpreted through average environmental conditions within their distributional range. For marine species with pelagic larvae, temperature and phytoplankton concentration are key variables. Along the south coast of South Africa, conspicuous spatial patterns in recruitment rates and the abundances of different mussel species exist, with focal areas characterized by large populations. We studied 15 years of sea surface temperature (SST) and chlorophyll-a (chl-a) satellite data, using spectral analyses to partition their temporal variability over ecologically relevant time periods, including seasonal (101 to 365 days) and intra-seasonal cycles (20 to 100 days). Adult cover and mussel recruitment were measured at 10 sites along the south coast and regression models showed that about 70 percent of the variability in recruitment and adult cover was explained by seasonal variability in chl-a, while mean annual chl-a and SST only explained 30 percent of the recruitment, with no significant effect for adult cover. SST and chl-a at two upwelling centres showed less predictable seasonal cycles during the second half of the study period with a significant cooling trend during austral autumn, coinciding with one of the mussel reproductive peaks. This likely reflects recent changes in the Agulhas Current, the world largest western boundary current, which affects coastal ecosystems by driving upwelling.",
        "comments": "Journal ref:        Science of the Total Environment, 757:143740, 2021",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11289"
    },
    {
        "doc_id": 519,
        "title": "Smart Drug-Delivery Systems for Cancer Nanotherapy",
        "authors": [
            "Paola Sanchez-Moreno",
            "Juan Luis Ortega-Vinuesa",
            "Jose Manuel Peula-Garcia",
            "Juan Antonio Marchal",
            "Houria Boulaiz"
        ],
        "subjects": [
            "Tissues and Organs",
            "Mesoscale and Nanoscale Physics",
            "Biological Physics"
        ],
        "abstract": "Despite all the advances achieved in the field of tumor-biology research, in most cases conventional therapies including chemotherapy are still the leading choices. The main disadvantage of these treatments, in addition to the low solubility of many antitumor drugs, is their lack of specificity, which explains the frequent occurrence of serious side effects due to nonspecific drug uptake by healthy cells. Progress in nanotechnology and its application in medicine have provided new opportunities and different smart systems. Such systems can improve the intracellular delivery of the drugs due to their multifunctionality and targeting potential. The purpose of this manuscript is to review and analyze the recent progress made in nanotherapy applied to cancer treatment. First, we provide a global overview of cancer and different smart nanoparticles currently used in oncology. Then, we analyze in detail the development of drug-delivery strategies in cancer therapy, focusing mainly on the intravenously administered smart nanoparticles with protein corona to avoid immune-system clearance. Finally, we discuss the challenges, clinical trials, and future directions of the nanoparticle-based therapy in cancer.",
        "comments": "Preprint version, 25 pages, 7 figures, 3 tables. Authors thank to Bentham Science the posibility of deposit the ACCEPTED VERSION of the peer-reviewed article after 12 months of publication on journal web site on arXiv repository. The published manuscript is available at EurekaSelect via https://www.eurekaselect.com/openurl/content.php?genre=article&doi=10.2174/1389450117666160527142544",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11192"
    },
    {
        "doc_id": 520,
        "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge",
        "authors": [
            "Chih-Hsuan Wei",
            "Alexis Allot",
            "Po-Ting Lai",
            "Robert Leaman",
            "Shubo Tian",
            "Ling Luo",
            "Qiao Jin",
            "Zhizheng Wang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "subjects": [
            "Computation and Language",
            "Quantitative Methods"
        ],
        "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves the factuality and verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive set of features and tools that allow researchers to navigate the ever-expanding wealth of biomedical literature, expediting research and unlocking valuable insights for scientific discovery.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11048"
    },
    {
        "doc_id": 521,
        "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
        "authors": [
            "Minkai Xu",
            "Jiaqi Han",
            "Aaron Lou",
            "Jean Kossaifi",
            "Arvind Ramanathan",
            "Kamyar Azizzadenesheli",
            "Jure Leskovec",
            "Stefano Ermon",
            "Anima Anandkumar"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis",
            "Quantitative Methods"
        ],
        "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11037"
    },
    {
        "doc_id": 522,
        "title": "Clustering Molecular Energy Landscapes by Adaptive Network Embedding",
        "authors": [
            "Paula Mercurio",
            "Di Liu"
        ],
        "subjects": [
            "Biomolecules",
            "Statistical Mechanics",
            "Machine Learning"
        ],
        "abstract": "In order to efficiently explore the chemical space of all possible small molecules, a common approach is to compress the dimension of the system to facilitate downstream machine learning tasks. Towards this end, we present a data driven approach for clustering potential energy landscapes of molecular structures by applying recently developed Network Embedding techniques, to obtain latent variables defined through the embedding function. To scale up the method, we also incorporate an entropy sensitive adaptive scheme for hierarchical sampling of the energy landscape, based on Metadynamics and Transition Path Theory. By taking into account the kinetic information implied by a system's energy landscape, we are able to interpret dynamical node-node relationships in reduced dimensions. We demonstrate the framework through Lennard-Jones (LJ) clusters and a human DNA sequence.",
        "comments": "19 pages, 10 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10972"
    },
    {
        "doc_id": 523,
        "title": "Homogenisation of nonlinear blood flow in periodic networks: the limit of small haematocrit heterogeneity",
        "authors": [
            "Y. Ben-Ami",
            "B. D. Wood",
            "J. M. Pitt-Francis",
            "P. K. Maini",
            "H. M. Byrne"
        ],
        "subjects": [
            "Tissues and Organs",
            "Soft Condensed Matter",
            "Biological Physics"
        ],
        "abstract": "In this work we develop a homogenisation methodology to upscale mathematical descriptions of microcirculatory blood flow from the microscale (where individual vessels are resolved) to the macroscopic (or tissue) scale. Due to the assumed two-phase nature of blood and specific features of red blood cells (RBCs), mathematical models for blood flow in the microcirculation are highly nonlinear, coupling the flow and RBC concentrations (haematocrit). In contrast to previous works which accomplished blood-flow homogenisation by assuming that the haematocrit level remains constant, here we allow for spatial heterogeneity in the haematocrit concentration and thus begin with a nonlinear microscale model. We simplify the analysis by considering the limit of small haematocrit heterogeneity which prevails when variations in haematocrit concentration between neighbouring vessels are small. Homogenisation results in a system of coupled, nonlinear partial differential equations describing the flow and haematocrit transport at the macroscale, in which a nonlinear Darcy-type model relates the flow and pressure gradient via a haematocrit-dependent permeability tensor. During the analysis we obtain further that haematocrit transport at the macroscale is governed by a purely advective equation. Applying the theory to particular examples of two- and three-dimensional geometries of periodic networks, we calculate the effective permeability tensor associated with blood flow in these vascular networks. We demonstrate how the statistical distribution of vessel lengths and diameters, together with the average haematocrit level, affect the statistical properties of the macroscopic permeability tensor. These data can be used to simulate blood flow and haematocrit transport at the macroscale.",
        "comments": "34 pages, 8 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10932"
    },
    {
        "doc_id": 524,
        "title": "A Chaotic Associative Memory",
        "authors": [
            "Nurani Rajagopal Rohan",
            "Sayan Gupta",
            "V. Srinivasa Chakravarthy"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Chaotic Dynamics"
        ],
        "abstract": "We propose a novel Chaotic Associative Memory model using a network of chaotic Rossler systems and investigate the storage capacity and retrieval capabilities of this model as a function of increasing periodicity and chaos. In early models of associate memory networks, memories were modeled as fixed points, which may be mathematically convenient but has poor neurobiological plausibility. Since brain dynamics is inherently oscillatory, attempts have been made to construct associative memories using nonlinear oscillatory networks. However, oscillatory associative memories are plagued by the problem of poor storage capacity, though efforts have been made to improve capacity by adding higher order oscillatory modes. The chaotic associative memory proposed here exploits the continuous spectrum of chaotic elements and has higher storage capacity than previously described oscillatory associate memories.",
        "comments": "10 pages, 8 Figures, Submitted to \"Chaos: An Interdisciplinary Journal of Nonlinear Science\"",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10922"
    },
    {
        "doc_id": 525,
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "authors": [
            "Jason Toy",
            "Josh MacAdam",
            "Phil Tabor"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
        "comments": "9 pages, 4 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10910"
    },
    {
        "doc_id": 526,
        "title": "Novel community data in ecology -- properties and prospects",
        "authors": [
            "Florian Hartig",
            "Nerea Abrego",
            "Alex Bush",
            "Jonathan M. Chase",
            "Gurutzeta Guillera-Arroita",
            "Mathew A. Leibold",
            "Otso Ovaskainen",
            "Lo\u00efc Pellissier",
            "Maximilian Pichler",
            "Giovanni Poggiato",
            "Laura Pollock",
            "Sara Si-Moussi",
            "Wilfried Thuiller",
            "Duarte S. Viana",
            "David I. Warton",
            "Damaris Zurell",
            "Douglas W. Yu"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "New technologies for acquiring biological information such as eDNA, acoustic or optical sensors, make it possible to generate spatial community observations at unprecedented scales. The potential of these novel community data to standardize community observations at high spatial, temporal, and taxonomic resolution and at large spatial scale ('many rows and many columns') has been widely discussed, but so far, there has been little integration of these data with ecological models and theory. Here, we review these developments and highlight emerging solutions, focusing on statistical methods for analyzing novel community data, in particular joint species distribution models; the new ecological questions that can be answered with these data; and the potential implications of these developments for policy and conservation.",
        "comments": "Journal ref:        Trends in Ecology & Evolution, 2024",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10860"
    },
    {
        "doc_id": 527,
        "title": "Exploring the role of structure in a time constrained decision task",
        "authors": [
            "Naomi Chaix-Eichel",
            "Gautham Venugopal",
            "Thomas Boraud",
            "Nicolas P. Rougier"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "The structure of the basal ganglia is remarkably similar across a number of species (often described in terms of direct, indirect and hyperdirect pathways) and is deeply involved in decision making and action selection. In this article, we are interested in exploring the role of structure when solving a decision task while avoiding to make any strong assumption regarding the actual structure. To do so, we exploit the echo state network paradigm that allows to solve complex task based on a random architecture. Considering a temporal decision task, the question is whether a specific structure allows for better performance and if so, whether this structure shares some similarity with the basal ganglia. Our results highlight the advantage of having a slow (direct) and a fast (hyperdirect) pathway that allows to deal with late information during a decision making task.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10849"
    },
    {
        "doc_id": 528,
        "title": "Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer Subtype Diagnosis",
        "authors": [
            "Charles Theodore Kent",
            "Leila Bagheriye",
            "Johan Kwisthout"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Machine Learning",
            "Genomics",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Recent strides in the field of neural computation has seen the adoption of Winner Take All (WTA) circuits to facilitate the unification of hierarchical Bayesian inference and spiking neural networks as a neurobiologically plausible model of information processing. Current research commonly validates the performance of these networks via classification tasks, particularly of the MNIST dataset. However, researchers have not yet reached consensus about how best to translate the stochastic responses from these networks into discrete decisions, a process known as population decoding. Despite being an often underexamined part of SNNs, in this work we show that population decoding has a significanct impact on the classification performance of WTA networks. For this purpose, we apply a WTA network to the problem of cancer subtype diagnosis from multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing so we utilise a novel implementation of gene similarity networks, a feature encoding technique based on Kohoens self organising map algorithm. We further show that the impact of selecting certain population decoding methods is amplified when facing imbalanced datasets.",
        "comments": "This paper has been accepted in BIOINFORMATICS 2024 (BIOSTEC 2024)",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10844"
    },
    {
        "doc_id": 529,
        "title": "DeepRLI: A Multi-objective Framework for Universal Protein--Ligand Interaction Prediction",
        "authors": [
            "Haoyu Lin",
            "Shiwei Wang",
            "Jintao Zhu",
            "Yibo Li",
            "Jianfeng Pei",
            "Luhua Lai"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Protein (receptor)--ligand interaction prediction is a critical component in computer-aided drug design, significantly influencing molecular docking and virtual screening processes. Despite the development of numerous scoring functions in recent years, particularly those employing machine learning, accurately and efficiently predicting binding affinities for protein--ligand complexes remains a formidable challenge. Most contemporary methods are tailored for specific tasks, such as binding affinity prediction, binding pose prediction, or virtual screening, often failing to encompass all aspects. In this study, we put forward DeepRLI, a novel protein--ligand interaction prediction architecture. It encodes each protein--ligand complex into a fully connected graph, retaining the integrity of the topological and spatial structure, and leverages the improved graph transformer layers with cosine envelope as the central module of the neural network, thus exhibiting superior scoring power. In order to equip the model to generalize to conformations beyond the confines of crystal structures and to adapt to molecular docking and virtual screening tasks, we propose a multi-objective strategy, that is, the model outputs three scores for scoring and ranking, docking, and screening, and the training process optimizes these three objectives simultaneously. For the latter two objectives, we augment the dataset through a docking procedure, incorporate suitable physics-informed blocks and employ an effective contrastive learning approach. Eventually, our model manifests a balanced performance across scoring, ranking, docking, and screening, thereby demonstrating its ability to handle a range of tasks. Overall, this research contributes a multi-objective framework for universal protein--ligand interaction prediction, augmenting the landscape of structure-based drug design.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10806"
    },
    {
        "doc_id": 530,
        "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks",
        "authors": [
            "Heorhii Skovorodnikov",
            "Hoda Alkhzaimi"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Genomics"
        ],
        "abstract": "With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples via spectral analysis yielding conclusions for countermeasures against such attacks.",
        "comments": "15 pages, core code available at: https://github.com/HeorhiiS/fimba-attack",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10657"
    },
    {
        "doc_id": 531,
        "title": "Exact analytical algorithm for solvent accessible surface area and derivatives in implicit solvent molecular simulations on GPUs",
        "authors": [
            "Xin Cao",
            "Michelle H. Hummel",
            "Yuzhang Wang",
            "Carlos Simmerling",
            "Evangelos A. Coutsias"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "In this paper, we present dSASA (differentiable SASA), an exact geometric method to calculate solvent accessible surface area (SASA) analytically along with atomic derivatives on GPUs. The atoms in a molecule are first assigned to tetrahedra in groups of four atoms by Delaunay tetrahedrization adapted for efficient GPU implementation and the SASA values for atoms and molecules are calculated based on the tetrahedrization information and inclusion-exclusion method. The SASA values from the numerical icosahedral-based method can be reproduced with more than 98% accuracy for both proteins and RNAs. Having been implemented on GPUs and incorporated into the software Amber, we can apply dSASA to implicit solvent molecular dynamics simulations with inclusion of this nonpolar term. The current GPU version of GB/SA simulations has been accelerated up to nearly 20-fold compared to the CPU version and it outperforms LCPO as the system size increases. The performance and importance of the nonpolar part in implicit solvent modeling are demonstrated in GB/SA simulations of proteins and accurate SASA calculation of nucleic acids.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10462"
    },
    {
        "doc_id": 532,
        "title": "Ecosystem models cannot predict the consequences of conservation decisions",
        "authors": [
            "Larissa Lubiana Botelho",
            "Cailan Jeynes-Smith",
            "Sarah Vollert",
            "Michael Bode"
        ],
        "subjects": [
            "Populations and Evolution",
            "Quantitative Methods"
        ],
        "abstract": "Ecosystem models are often used to predict the consequences of management decisions in applied ecology, including fisheries management and threatened species conservation. These models are high-dimensional, parameter-rich, and nonlinear, yet limited data is available to calibrate them, and they are rarely tested or validated. Consequently, the accuracy of their forecasts, and their utility as decision-support tools is a matter of debate. In this paper, we calibrate ecosystem models to time-series data from 110 different experimental microcosm ecosystems, each containing between three and five interacting species. We then assess how often these calibrated models offer accurate and useful predictions about how the ecosystem will respond to a set of standard management interventions. Our results show that for each timeseries dataset, a large number of very different parameter sets offer equivalent, good fits. However, these calibrated ecosystem models have poor predictive accuracy when forecasting future dynamics and offer ambiguous predictions about how species in the ecosystem will respond to management interventions. Closer inspection reveals that the ecosystem models fail because calibration cannot determine the types of interactions that occur within the ecosystem. Our findings call into question claims that ecosystem modelling can support applied ecological decision-making when they are calibrated against real-world datasets.",
        "comments": "23 pages (main text + supplementary material) 9 figures (main text + supplementary material)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10439"
    },
    {
        "doc_id": 533,
        "title": "Diffusion of intrinsically disordered proteins within viscoelastic membraneless droplets",
        "authors": [
            "Fuga Watanabe",
            "Takuma Akimoto",
            "Robert B. Best",
            "Kresten Lindorff-Larsen",
            "Ralf Metzler",
            "Eiji Yamamoto"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Biological Physics",
            "Computational Physics",
            "Biomolecules"
        ],
        "abstract": "In living cells, intrinsically disordered proteins (IDPs), such as FUS and DDX4, undergo phase separation, forming biomolecular condensates. Using molecular dynamics simulations, we investigate their behavior in their respective homogenous droplets. We find that the proteins exhibit transient subdiffusion due to the viscoelastic nature and confinement effects in the droplets. The conformation and the instantaneous diffusivity of the proteins significantly vary between the interior and the interface of the droplet, resulting in non-Gaussianity in the displacement distributions. This study highlights key aspects of IDP behavior in biomolecular condensates.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10438"
    },
    {
        "doc_id": 534,
        "title": "Exploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies",
        "authors": [
            "Gang Qu",
            "Anton Orlichenko",
            "Junqi Wang",
            "Gemeng Zhang",
            "Li Xiao",
            "Aiying Zhang",
            "Zhengming Ding",
            "Yu-Ping Wang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined graph structure to depict associations between brain regions, a detail not solely provided by FCs. To bridge this gap, we introduce the Gated Graph Transformer (GGT) framework, designed to predict cognitive metrics based on FCs. Empirical validation on the Philadelphia Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of our model, further accentuating its potential in identifying pivotal neural connectivities that correlate with human cognitive processes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10348"
    },
    {
        "doc_id": 535,
        "title": "DrugAssist: A Large Language Model for Molecule Optimization",
        "authors": [
            "Geyan Ye",
            "Xibao Cai",
            "Houtim Lai",
            "Xing Wang",
            "Junhong Huang",
            "Longyue Wang",
            "Wei Liu",
            "Xiangxiang Zeng"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called MolOpt-Instructions for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.",
        "comments": "Geyan Ye and Xibao Cai are equal contributors; Longyue Wang is corresponding author",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10334"
    },
    {
        "doc_id": 536,
        "title": "Fine scale depth regulation of invertebrate larvae around coastal fronts",
        "authors": [
            "Nicolas Weidberg",
            "Wayne Goschen",
            "Jennifer M. Jackson",
            "Paula Pattrick",
            "Christopher D. McQuaid",
            "Francesca Porri"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Vertical migrations of zooplankters have been widely described, but their active movements through shallow, highly dynamic water columns within the inner shelf may be more complex and difficult to characterize. In this study, invertebrate larvae, currents, and hydrographic variables were sampled at different depths during and after the presence of fronts on three different cruises off the southern coast of South Africa. Internal wave dynamics were observed in the hydrographic data set but also through satellite imagery, although strong surface convergent currents were absent and thermal stratification was weak. During the first two cruises, fronts were more conspicuous and they preceded strong onshore currents at depth which developed with the rising tide. Vertical distributions of larvae changed accordingly, with higher abundances at these deep layers once the front disappeared. The third cruise was carried out during slack tides, the front was not conspicuous, deep strong onshore currents did not occur afterward and larval distributions did not change consistently through time. Overall, the vertical distributions of many larval taxa matched the vertical profiles of shoreward currents and multivariate analyses revealed that these flows structured the larval community, which was neither influenced by temperature nor chlorophyll. Thus, the ability to regulate active vertical positioning may enhance shoreward advection and determine nearshore larval distributions.",
        "comments": "Journal ref:        Limnology and Oceanography. 64 - 2, pp. 785 - 802, 2019",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10303"
    },
    {
        "doc_id": 537,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 538,
        "title": "Mechanisms of nearshore retention and offshore export of mussel larvae over the Agulhas Bank",
        "authors": [
            "Nicolas Weidberg",
            "Francesca Porri",
            "Charles von der Meden",
            "Jennifer M. Jackson",
            "Wayne Goschen",
            "Christopher McQuaid"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Ecological connectivity is critical for population dynamics but in many benthic species it is complicated by a planktonic larval phase, whose dispersal remains poorly understood. Using a plankton pump, we examine the distribution of intertidal mussel larvae along three axes: alongshore, cross-shelf and by depth during a large scale (600 km) cruise over the Agulhas Bank off southern Africa in August/September 2010. As a general pattern, higher veliger abundances were found close to the coast. Our analyses of the nearshore flow, estimated from ADCP data and the vertical distribution of larvae, show that onshore larval retention may be mediated by active vertical swimming through the water column guided by light and wind-induced turbulence. A massive offshore export of larvae off St Francis Bay was, however, observed during an Agulhas Current meander which influenced inner shelf waters. We hypothesize that, by increasing and homogenizing flow, the Agulhas Current may erase the effects of larval vertical positioning on onshore retention and transport larvae offshore. Our study highlights the need to integrate the effects of complex, region-specific physical dynamics with the swimming behaviour of larvae in order to explain their spatial distribution, population connectivity and the consequences for population dynamics.",
        "comments": "Journal ref:        Journal of Plankton Research. 37 - 6, pp. 1166 - 1180. Oxford Journals, 11/2015",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10292"
    },
    {
        "doc_id": 539,
        "title": "Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning",
        "authors": [
            "Ryan Cho",
            "Mobasshira Zaman",
            "Kyu Taek Cho",
            "Jaejin Hwang"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Neurons and Cognition"
        ],
        "abstract": "This study aimed to analyze brain activity during various STEM activities, exploring the feasibility of classifying between different tasks. EEG brain data from twenty subjects engaged in five cognitive tasks were collected and segmented into 4-second clips. Power spectral densities of brain frequency waves were then analyzed. Testing different k-intervals with XGBoost, Random Forest, and Bagging Classifier revealed that Random Forest performed best, achieving a testing accuracy of 91.07% at an interval size of two. When utilizing all four EEG channels, cognitive flexibility was most recognizable. Task-specific classification accuracy showed the right frontal lobe excelled in mathematical processing and planning, the left frontal lobe in cognitive flexibility and mental flexibility, and the left temporoparietal lobe in connections. Notably, numerous connections between frontal and temporoparietal lobes were observed during STEM activities. This study contributes to a deeper understanding of implementing machine learning in analyzing brain activity and sheds light on the brain's mechanisms.",
        "comments": "20 pages, 7 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10285"
    },
    {
        "doc_id": 540,
        "title": "EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model",
        "authors": [
            "Yuqi Chen",
            "Kan Ren",
            "Kaitao Song",
            "Yansen Wang",
            "Yifan Wang",
            "Dongsheng Li",
            "Lili Qiu"
        ],
        "subjects": [
            "Signal Processing",
            "Artificial Intelligence",
            "Machine Learning",
            "Multimedia",
            "Neurons and Cognition"
        ],
        "abstract": "Self-supervised learning has emerged as a highly effective approach in the fields of natural language processing and computer vision. It is also applicable to brain signals such as electroencephalography (EEG) data, given the abundance of available unlabeled data that exist in a wide spectrum of real-world medical applications ranging from seizure detection to wave analysis. The existing works leveraging self-supervised learning on EEG modeling mainly focus on pretraining upon each individual dataset corresponding to a single downstream task, which cannot leverage the power of abundant data, and they may derive sub-optimal solutions with a lack of generalization. Moreover, these methods rely on end-to-end model learning which is not easy for humans to understand. In this paper, we present a novel EEG foundation model, namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained model cannot only learn universal representations on EEG signals with adaptable performance on various downstream tasks but also provide interpretable outcomes of the useful patterns within the data. To validate the effectiveness of our model, we extensively evaluate it on various downstream tasks and assess the performance under different transfer settings. Furthermore, we demonstrate how the learned model exhibits transferable anomaly detection performance and provides valuable interpretability of the acquired patterns via self-supervised learning.",
        "comments": "A preprint version of an ongoing work",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10278"
    },
    {
        "doc_id": 541,
        "title": "Evolving Diploid Boolean and Multi-Valued Gene Networks",
        "authors": [
            "Larry Bull"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Boolean networks have been widely used to explore aspects of gene regulation, traditionally with a single network. A modified form of the model to explore the effects of increasing the number of gene states has also recently been introduced. In this paper, these discrete dynamical networks are evolved as diploids within rugged fitness landscapes to explore their behaviour. Results suggest the general properties of haploid networks in similar circumstances remain for diploids. The previously proposed inherent fitness landscape smoothing properties of eukaryotic sex are shown to be exhibited in these dynamical systems, as is their propensity to change in size based upon the characteristics of the network and fitness landscape.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.01694",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10237"
    },
    {
        "doc_id": 542,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 543,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 544,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 545,
        "title": "Correlating fluorescence microscopy, optical and magnetic tweezers to study single chiral biopolymers, tested on DNA plectoneme formation dynamics",
        "authors": [
            "Jack W Shepherd",
            "Sebastien Guilbaud",
            "Zhaokun Zhou",
            "Jamieson Howard",
            "Matthew Burman",
            "Charley Schaefer",
            "Adam Kerrigan",
            "Clare Steele-King",
            "Agnes Noy",
            "Mark C Leake"
        ],
        "subjects": [
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Biopolymer topology is critical for determining interactions inside cell environments, exemplified by DNA where its response to mechanical perturbation is as important as biochemical properties to its cellular roles. The dynamic structures of chiral biopolymers exhibit complex dependence with extension and torsion, however the physical mechanisms underpinning the emergence of structural motifs upon physiological twisting and stretching are poorly understood due to technological limitations in correlating force, torque and spatial localization information. We present COMBI-Tweez (Combined Optical and Magnetic BIomolecule TWEEZers), a transformative tool that overcomes these challenges by integrating optical trapping, time-resolved electromagnetic tweezers, and fluorescence microscopy, demonstrated on single DNA molecules, that can controllably form and visualise higher order structural motifs including plectonemes. This technology combined with cutting-edge MD simulations provides quantitative insight into complex dynamic structures relevant to DNA cellular processes and can be adapted to study a range of filamentous biopolymers.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10087"
    },
    {
        "doc_id": 546,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 547,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 548,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 549,
        "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
        "authors": [
            "Zofia Rudnicka",
            "Janusz Szczepanski",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in the medical image scan segmentation, and intelligent visual-content generation, i.e. computer-generated three-dimensional (3D) images in the context of Extended Reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes also with possible developments and open challenges in AI application in Extended Reality-based solutions. Finally, the future lines of research and development directions of Artificial Intelligence applications both in medical image segmentation and Extended Reality-based medical solutions are discussed",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09857"
    },
    {
        "doc_id": 550,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 551,
        "title": "The impact of Covid-19 vaccination in Aotearoa New Zealand: a modelling study",
        "authors": [
            "Samik Datta",
            "Giorgia Vattiato",
            "Oliver J Maclaren",
            "Ning Hua",
            "Andrew Sporle",
            "Michael J Plank"
        ],
        "subjects": [
            "Populations and Evolution",
            "Physics and Society"
        ],
        "abstract": "Aotearoa New Zealand implemented a Covid-19 elimination strategy in 2020 and 2021, which enabled a large majority of the population to be vaccinated before being exposed to the virus. This strategy delivered one of the lowest pandemic mortality rates in the world. However, quantitative estimates of the population-level health benefits of vaccination are lacking. Here, we use a validated mathematical model to investigate counterfactual scenarios with differing levels of vaccine coverage in different age and ethnicity groups. The model builds on earlier research by adding age- and time-dependent case ascertainment, the effect of antiviral medications, improved hospitalisation rate estimates, and the impact of relaxing control measures. The model was used for scenario analysis and policy advice for the New Zealand Government in 2022 and 2023. We compare the number of Covid-19 hospitalisations, deaths, and years of life lost in each counterfactual scenario to a baseline scenario that is fitted to epidemiological data between January 2022 and June 2023. Our results estimate that vaccines saved 6650 (95% credible interval [4424, 10180]) lives, and prevented 74500 [51000, 115400] years of life lost and 45100 [34400, 55600] hospitalisations during this 18-month period. Making the same comparison before the benefit of antiviral medications is accounted for, the estimated number of lives saved by vaccines increases to 7604 [5080, 11942]. Due to inequities in the vaccine rollout, vaccination rates among M\u0101ori were lower than in people of European ethnicity. Our results show that, if vaccination rates had been equitable, an estimated 11-26% of the 292 M\u0101ori Covid-19 deaths that were recorded in this time period could have been prevented. We conclude that Covid-19 vaccination greatly reduced health burden in New Zealand and that equity needs to be a key focus of future vaccination programmes.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09679"
    },
    {
        "doc_id": 552,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 553,
        "title": "Molecular causality in the advent of foundation models",
        "authors": [
            "Sebastian Lobentanzer",
            "Pablo Rodriguez-Mier",
            "Stefan Bauer",
            "Julio Saez-Rodriguez"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Correlation is not causation. As simple as this widely agreed-upon statement may seem, scientifically defining causality and using it to drive our modern biomedical research is immensely challenging. In this perspective, we attempt to synergise the partly disparate fields of systems biology, causal reasoning, and machine learning, to inform future approaches in the field of systems biology and molecular networks.",
        "comments": "22 pages, 0 figures, 87 references; submitted to MSB",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09558"
    },
    {
        "doc_id": 554,
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "Junhao Wen",
            "Mathilde Antoniades",
            "Zhijian Yang",
            "Gyujoon Hwang",
            "Ioanna Skampardoni",
            "Rongguang Wang",
            "Christos Davatzikos"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing",
            "Quantitative Methods"
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09517"
    },
    {
        "doc_id": 555,
        "title": "Is the Emergence of Life an Expected Phase Transition in the Evolving Universe?",
        "authors": [
            "Stuart Kauffman",
            "Andrea Roli"
        ],
        "subjects": [
            "Populations and Evolution",
            "Biological Physics"
        ],
        "abstract": "We propose a novel definition of life in terms of which its emergence in the universe is expected, and its ever-creative open-ended evolution is entailed by no law. Living organisms are Kantian Wholes that achieve Catalytic Closure, Constraint Closure, and Spatial Closure. We here unite for the first time two established mathematical theories, namely Collectively Autocatalytic Sets and the Theory of the Adjacent Possible. The former establishes that a first-order phase transition to molecular reproduction is expected in the chemical evolution of the universe where the diversity and complexity of molecules increases; the latter posits that, under loose hypotheses, if the system starts with a small number of beginning molecules, each of which can combine with copies of itself or other molecules to make new molecules, over time the number of kinds of molecules increases slowly but then explodes upward hyperbolically. Together these theories imply that life is expected as a phase transition in the evolving universe. The familiar distinction between software and hardware loses its meaning in living cells. We propose new ways to study the phylogeny of metabolisms, new astronomical ways to search for life on exoplanets, new experiments to seek the emergence of the most rudimentary life, and the hint of a coherent testable pathway to prokaryotes with template replication and coding.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09514"
    },
    {
        "doc_id": 556,
        "title": "Role of Upwelling on Larval Dispersal and Productivity of Gooseneck Barnacle Populations in the Cantabrian Sea: Management Implications",
        "authors": [
            "Antonella Rivera",
            "Nicolas Weidberg",
            "Antonio F. Pardi\u00f1as",
            "Ricardo Gonzalez-Gil",
            "Luc\u0131a Garc\u0131a- Florez",
            "Jose Luis Acu\u00f1a"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "The effect of coastal upwelling on the recruitment and connectivity of coastal marine populations has rarely been characterized to a level of detail to be included into sound fishery management strategies. The gooseneck barnacle (Pollicipes pollicipes) fishery at the Cantabrian Coast (Northern Spain) is located at the fringes of the NW Spanish Upwelling system. This fishery is being co-managed through a fine-scale, interspersed set of protected rocks where each rock receives a distinct level of protection. Such interspersion is potentially beneficial, but the extent to which such spacing is consistent with mean larval dispersal distances is as yet unknown. We have simulated the spread of gooseneck barnacle larvae in the Central Cantabrian Coast using a high-resolution time-series of current profiles measured at a nearshore location. During a year of high upwelling activity (2009), theoretical recruitment success was 94% with peak recruitment predicted 56 km west of the emission point. However, for a year of low upwelling activity (2011) theoretical recruitment success dropped to 15.4% and peak recruitment was expected 13 km east of the emission point. This is consistent with a positive correlation between catch rates and the Integrated Upwelling Index, using a 4-year lag to allow recruits to reach commercial size. Furthermore, a net long-term westward larval transport was estimated by means of mitochondrial cytochrome c oxidase subunit I (COI) sequences for five populations in the Cantabrian Sea. Our results call into question the role of long distance dispersal, driven by the mesoscale processes in the area, in gooseneck barnacle populations and point to the prevalent role of small-scale, asymmetric connectivity more consistent with the typical scale of the co-management process in this fishery.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09513"
    },
    {
        "doc_id": 557,
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Haotian Lu",
            "Yexin Wu",
            "Zexin Yuan",
            "Shengdian Jiang",
            "Jiaxiang Wu",
            "Yimin Wang",
            "Junchi Yan"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09500"
    },
    {
        "doc_id": 558,
        "title": "Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "Jiayu Chang",
            "Shiyu Wang",
            "Chen Ling",
            "Zhaohui Qin",
            "Liang Zhao"
        ],
        "subjects": [
            "Quantitative Methods",
            "Information Retrieval"
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations.",
        "comments": "This is the official paper accepted by AAAI 2024 Workshop on Large Language Models for Biological Discoveries",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09490"
    },
    {
        "doc_id": 559,
        "title": "The Interplay Between Logical Phenomena and the Cognitive System of the Mind",
        "authors": [
            "Kazem Haghnejad Azar"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In this article, we employ mathematical concepts as a tool to examine the phenomenon of consciousness experience and logical phenomena. Through our investigation, we aim to demonstrate that our experiences, while not confined to limitations, cannot be neatly encapsulated within a singular collection. Our conscious experience emerges as a result of the developmental and augmentative trajectory of our cognitive system. As our cognitive abilities undergo refinement and advancement, our capacity for logical thinking likewise evolves, thereby manifesting a heightened level of conscious experience. The primary objective of this article is to embark upon a profound exploration of the concept of logical experience, delving into the intricate process by which these experiences are derived from our mind.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09465"
    },
    {
        "doc_id": 560,
        "title": "Diffusion-Driven Generative Framework for Molecular Conformation Prediction",
        "authors": [
            "Bobin Yang",
            "Jie Deng",
            "Zhenghan Chen",
            "Ruoxue Wu"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "The task of deducing three-dimensional molecular configurations from their two-dimensional graph representations holds paramount importance in the fields of computational chemistry and pharmaceutical development. The rapid advancement of machine learning, particularly within the domain of deep generative networks, has revolutionized the precision of predictive modeling in this context. Traditional approaches often adopt a two-step strategy: initially estimating interatomic distances and subsequently refining the spatial molecular structure by solving a distance geometry problem. However, this sequential approach occasionally falls short in accurately capturing the intricacies of local atomic arrangements, thereby compromising the fidelity of the resulting structural models. Addressing these limitations, this research introduces a cutting-edge generative framework named \\method{}. This framework is grounded in the principles of diffusion observed in classical non-equilibrium thermodynamics. \\method{} views atoms as discrete entities and excels in guiding the reversal of diffusion, transforming a distribution of stochastic noise back into coherent molecular structures through a process akin to a Markov chain. This transformation commences with the initial representation of a molecular graph in an abstract latent space, culminating in the realization of three-dimensional structures via a sophisticated bilevel optimization scheme meticulously tailored to meet the specific requirements of the task. One of the formidable challenges in this modeling endeavor involves preserving roto-translational invariance to ensure that the generated molecular conformations adhere to the laws of physics. Extensive experimental evaluations confirm the efficacy of the proposed \\method{} in comparison to state-of-the-art methods.",
        "comments": "arXiv admin note: text overlap with arXiv:2105.07246 by other authors",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09451"
    },
    {
        "doc_id": 561,
        "title": "Regenerative Medicine for Tendon/Ligament Injuries: De Novo Equine Tendon/Ligament Neotissue Generation and Application",
        "authors": [
            "Takashi Taguchi"
        ],
        "subjects": [
            "Tissues and Organs"
        ],
        "abstract": "Tendon and ligament injuries are debilitating conditions across species. Poor regenerative capacities of these tissues limit restoration of original functions. The first study of this dissertation evaluated the effect of cellular administration on tendon/ligament injuries in horses using meta-analysis. The findings led to the second study that engineered implantable de novo tendon neotissue using equine adipose-derived multipotent stromal cells and collagen type I. The neotendon was evaluated for its biocompatibility and therapeutic potential in the third study using immunocompetent and immunocompromised rat bilateral calcaneal tendon elongation model. The fourth study investigated the therapeutic effects of neotendon in surgically-induced non-terminal equine accessory ligament of deep digital flexor tendon injury model.",
        "comments": " ",
        "date": "24 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09423"
    },
    {
        "doc_id": 562,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 563,
        "title": "Graph-based vulnerability assessment of resting-state functional brain networks in full-term neonates",
        "authors": [
            "Mahshid Fouladivanda",
            "Kamran Kazemi",
            "Habibollah Danyali",
            "Ardalan Aarabi"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Quantitative Methods"
        ],
        "abstract": "Network disruption during early brain development can result in long-term cognitive impairments. In this study, we investigated rich-club organization in resting-state functional brain networks in full-term neonates using a multiscale connectivity analysis. We further identified the most influential nodes, also called spreaders, having higher impacts on the flow of information throughout the network. The network vulnerability to damage to rich-club (RC) connectivity within and between resting-state networks was also assessed using a graph-based vulnerability analysis. Our results revealed a rich club organization and small-world topology for resting-state functional brain networks in full term neonates, regardless of the network size. Interconnected mostly through short-range connections, functional rich-club hubs were confined to sensory-motor, cognitive-attention-salience (CAS), default mode, and language-auditory networks with an average cross-scale overlap of 36%, 20%, 15% and 12%, respectively. The majority of the functional hubs also showed high spreading potential, except for several non-RC spreaders within CAS and temporal networks. The functional networks exhibited high vulnerability to loss of RC nodes within sensorimotor cortices, resulting in a significant increase and decrease in network segregation and integration, respectively. The network vulnerability to damage to RC nodes within the language-auditory, cognitive-attention-salience, and default mode networks was also significant but relatively less prominent. Our findings suggest that the network integration in neonates can be highly compromised by damage to RC connectivity due to brain immaturity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09255"
    },
    {
        "doc_id": 564,
        "title": "Reproducibility via neural fields of visual illusions induced by localized stimuli",
        "authors": [
            "Cyprien Tamekue",
            "Dario Prandi",
            "Yacine Chitour"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Pattern Formation and Solitons"
        ],
        "abstract": "This paper investigates the replication of experiments by Billock and Tsou [PNAS, 2007] using the controllability of neural fields of Amari-type modelling the cortical activity in the primary visual cortex (V1), focusing on a regular funnel pattern localised in the fovea or the peripheral visual field. The aim is to understand and model the visual phenomena observed in these experiments, emphasising their nonlinear nature. The study involves designing sensory inputs simulating the visual stimuli from Billock and Tsou's experiments. The after-images induced by these inputs are then theoretically and numerically studied to determine their capacity to replicate the experimentally observed visual effects. A key aspect of this research is investigating the effects induced by the nonlinear nature of neural responses. In particular, by highlighting the importance of both excitatory and inhibitory neurons in the emergence of certain visual phenomena, this study suggests that an interplay of both types of neuronal activities plays an essential role in visual processes, challenging the assumption that the latter is mainly driven by excitatory activities alone.",
        "comments": "MSC Class:          92C20; 35B36; 45A05; 45G15; 45K05; 65R20",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09108"
    },
    {
        "doc_id": 565,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 566,
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "authors": [
            "Ziyang Yu",
            "Wenbing Huang",
            "Yang Liu"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08986"
    },
    {
        "doc_id": 567,
        "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
        "authors": [
            "Zahra Sheikhbahaee",
            "Adam Safron",
            "Casper Hesp",
            "Guillaume Dumas"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08873"
    },
    {
        "doc_id": 568,
        "title": "Using i-vectors for subject-independent cross-session EEG transfer learning",
        "authors": [
            "Jonathan Lasko",
            "Jeff Ma",
            "Mike Nicoletti",
            "Jonathan Sussman-Fort",
            "Sooyoung Jeong",
            "William Hartmann"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Cognitive load classification is the task of automatically determining an individual's utilization of working memory resources during performance of a task based on physiologic measures such as electroencephalography (EEG). In this paper, we follow a cross-disciplinary approach, where tools and methodologies from speech processing are used to tackle this problem. The corpus we use was released publicly in 2021 as part of the first passive brain-computer interface competition on cross-session workload estimation. We present our approach which used i-vector-based neural network classifiers to accomplish inter-subject cross-session EEG transfer learning, achieving 18% relative improvement over equivalent subject-dependent models. We also report experiments showing how our subject-independent models perform competitively on held-out subjects and improve with additional subject data, suggesting that subject-dependent training is not required for effective cognitive load determination.",
        "comments": "11 pages",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08851"
    },
    {
        "doc_id": 569,
        "title": "On the maximum value of the stairs2 index",
        "authors": [
            "Bryan Currie",
            "Kristina Wicke"
        ],
        "subjects": [
            "Combinatorics",
            "Populations and Evolution"
        ],
        "abstract": "Measures of tree balance play an important role in different research areas such as mathematical phylogenetics or theoretical computer science. The balance of a tree is usually quantified in a single number, called a balance or imbalance index, and several such indices exist in the literature. Here, we focus on the stairs2 balance index for rooted binary trees, which was first introduced in the context of viral phylogenetics but has not been fully analyzed from a mathematical viewpoint yet. While it is known that the caterpillar tree uniquely minimizes the stairs2 index for all leaf numbers and the fully balanced tree uniquely maximizes the stairs2 index for leaf numbers that are powers of two, understanding the maximum value and maximal trees for arbitrary leaf numbers is an open problem in the literature. In this note, we fill this gap by showing that for all leaf numbers, there is a unique rooted binary tree maximizing the stairs2 index. Additionally, we obtain recursive and closed expressions for the maximum value of the stairs2 index of a rooted binary tree with $n$ leaves.",
        "comments": "12 pages, 1 figure",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08838"
    },
    {
        "doc_id": 570,
        "title": "Mechanical constraints and cell cycle regulation in models of collective cell migration",
        "authors": [
            "Carles Falc\u00f3",
            "Daniel J. Cohen",
            "Jos\u00e9 A. Carrillo",
            "Ruth E. Baker"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biological Physics"
        ],
        "abstract": "The spatiotemporal coordination and regulation of cell proliferation is fundamental in many aspects of development and tissue maintenance. Cells have the ability to adapt their division rates in response to mechanical checkpoints, yet we do not fully understand how cell proliferation regulation impacts cell migration phenomena. Here, we present a minimal continuum model of cell migration with cell cycle dynamics, which includes mechanical constraints and hence can account for cell proliferation regulation. By combining minimal mathematical modelling, Bayesian inference, and recent experimental data, we quantify the impact of mechanical constraints across different cell cycle stages in epithelial tissue expansion experiments. Our model suggests that cells sense local density and adapt cell cycle progression in response, during G1 and the combined S/G2/M phases, providing an explicit relationship between each cell cycle stage duration and local tissue density, which is consistent with several experimental observations. Finally, we compare our mathematical model predictions to different experiments studying cell cycle regulation and present a quantitative analysis on the impact of mechanical constraints on cell migration patterns. Our work presents a systematic approach for investigating and analysing cell cycle data, providing mechanistic insights into how individual cells regulate proliferation, based on population-based experimental measurements.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08805"
    },
    {
        "doc_id": 571,
        "title": "Machine Learning-Based Analysis of Ebola Virus' Impact on Gene Expression in Nonhuman Primates",
        "authors": [
            "Mostafa Rezapour",
            "Muhammad Khalid Khan Niazi",
            "Hao Lu",
            "Aarthi Narayanan",
            "Metin Nafi Gurcan"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "This study introduces the Supervised Magnitude-Altitude Scoring (SMAS) methodology, a machine learning-based approach, for analyzing gene expression data obtained from nonhuman primates (NHPs) infected with Ebola virus (EBOV). We utilize a comprehensive dataset of NanoString gene expression profiles from Ebola-infected NHPs, deploying the SMAS system for nuanced host-pathogen interaction analysis. SMAS effectively combines gene selection based on statistical significance and expression changes, employing linear classifiers such as logistic regression to accurately differentiate between RT-qPCR positive and negative NHP samples. A key finding of our research is the identification of IFI6 and IFI27 as critical biomarkers, demonstrating exceptional predictive performance with 100% accuracy and Area Under the Curve (AUC) metrics in classifying various stages of Ebola infection. Alongside IFI6 and IFI27, genes, including MX1, OAS1, and ISG15, were significantly upregulated, highlighting their essential roles in the immune response to EBOV. Our results underscore the efficacy of the SMAS method in revealing complex genetic interactions and response mechanisms during EBOV infection. This research provides valuable insights into EBOV pathogenesis and aids in developing more precise diagnostic tools and therapeutic strategies to address EBOV infection in particular and viral infection in general.",
        "comments": "28 pages, 8 figures, 2 tables",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08738"
    },
    {
        "doc_id": 572,
        "title": "Survival Analysis of Young Triple-Negative Breast Cancer Patients",
        "authors": [
            "M. Mehdi Owrang O",
            "Fariba Jafari Horestani",
            "Ginger Schwarz"
        ],
        "subjects": [
            "Quantitative Methods",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "Breast cancer prognosis is crucial for effective treatment, with the disease more common in women over 40 years old but rare under 40 years old, where less than 5 percent of cases occur in the U.S. Studies indicate a worse prognosis in younger women, which varies by ethnicity. Breast cancers are classified based on receptors like estrogen, progesterone, and HER2. Triple-negative breast cancer (TNBC), lacking these receptors, accounts for about 15 percent of cases and is more prevalent in younger patients, often resulting in poorer outcomes. Nevertheless, the impact of age on TNBC prognosis remains unclear. Factors like age, race, tumor grade, size, and lymph node status are studied for their role in TNBC's clinical outcomes, but current research is inconclusive about age-related differences. This study uses SEER data set to examine the influence of younger age on survivability in TNBC patients, aiming to determine if age is a significant prognostic factor. Our experimental results on SEER dataset confirm the existing research reports that TNBC patients have worse prognosis compared to non-TNBC based on age. Our main goal was to investigate whether younger age has any significance on the survivability of TNBC patients. Experimental results do not show that younger age has any significance on the prognosis and survival rate of the TNBC patients",
        "comments": "31 Pages, 11 Figures, 7 Tables, Peer-reviewed article",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08712"
    },
    {
        "doc_id": 573,
        "title": "On Image Search in Histopathology",
        "authors": [
            "H. R. Tizhoosh",
            "Liron Pantanowitz"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Information Retrieval",
            "Quantitative Methods"
        ],
        "abstract": "Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for nuanced quantification of cellular structures across diverse tissue types, facilitating comparisons and enabling inferences about diagnosis, prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08699"
    },
    {
        "doc_id": 574,
        "title": "Concept Alignment",
        "authors": [
            "Sunayana Rane",
            "Polyphony J. Bruna",
            "Ilia Sucholutsky",
            "Christopher Kello",
            "Thomas L. Griffiths"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Neurons and Cognition"
        ],
        "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has focused on value alignment, broadly referring to creating AI systems that share human values. We argue that before we can even attempt to align values, it is imperative that AI systems and humans align the concepts they use to understand the world. We integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. We summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. Finally, we explain how we can leverage the tools already being developed in cognitive science and AI research to accelerate progress towards concept alignment.",
        "comments": "NeurIPS MP2 Workshop 2023",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08672"
    },
    {
        "doc_id": 575,
        "title": "Validation and Comparison of Non-Stationary Cognitive Models: A Diffusion Model Application",
        "authors": [
            "Lukas Schumacher",
            "Martin Schnuerch",
            "Andreas Voss",
            "Stefan T. Radev"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "Cognitive processes undergo various fluctuations and transient states across different temporal scales. Superstatistics are emerging as a flexible framework for incorporating such non-stationary dynamics into existing cognitive model classes. In this work, we provide the first experimental validation of superstatistics and formal comparison of four non-stationary diffusion decision models in a specifically designed perceptual decision-making task. Task difficulty and speed-accuracy trade-off were systematically manipulated to induce expected changes in model parameters. To validate our models, we assess whether the inferred parameter trajectories align with the patterns and sequences of the experimental manipulations. To address computational challenges, we present novel deep learning techniques for amortized Bayesian estimation and comparison of models with time-varying parameters. Our findings indicate that transition models incorporating both gradual and abrupt parameter shifts provide the best fit to the empirical data. Moreover, we find that the inferred parameter trajectories closely mirror the sequence of experimental manipulations. Posterior re-simulations further underscore the ability of the models to faithfully reproduce critical data patterns. Accordingly, our results suggest that the inferred non-stationary dynamics may reflect actual changes in the targeted psychological constructs. We argue that our initial experimental validation paves the way for the widespread application of superstatistics in cognitive modeling and beyond.",
        "comments": " ",
        "date": "7 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08626"
    },
    {
        "doc_id": 576,
        "title": "Dynamic Brain Behaviours in Stroke: A Longitudinal Investigation Based on fMRI Analysis",
        "authors": [
            "Kaichao Wu",
            "Beth Jelfs",
            "Katrina Neville",
            "Qiang Fang"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Background: The brain's functional network constantly adapts to external changes. However, the mechanisms underlying this dynamic adaptive behavior in stroke patients with motor injuries and its role in post-stroke motor recovery remain poorly understood.\n  Method: This study conducted a long-term investigation involving 15 first-stroke patients. Each participant underwent five fMRI scans distributed equally over a six-month period. Using functional neuroimaging data, time-varying functional modularity in post-stroke patients was detected, and subsequently, the dynamic brain behaviors, including recruitment, integration, and flexibility, along with their longitudinal changes, were assessed.\n  Results: Our findings reveal that stroke lesions lead to significant and enduring alterations in all three dynamic behaviors within functional brain networks. Furthermore, during the six-month recovery period, patients who exhibited good and poor recovery showed notable differences in recruitment and flexibility, indicating distinct recovery trajectories for these groups. Notably, when predicting post-stroke recovery status, whole-brain recruitment emerged as a robust and reliable feature, achieving an AUC of 85.93\n  Significance: Our study offers a comprehensive depiction of dynamic brain behavior in the post-ischemic-stroke brain, with a focus on longitudinal changes concurrent with functional recovery. These dynamic patterns hold promise as valuable tools for evaluating and predicting motor recovery following stroke.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08607"
    },
    {
        "doc_id": 577,
        "title": "Long cycles in linear thresholding systems",
        "authors": [
            "Anna Laddach",
            "Michael Shapiro"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Linear thresholding systems have been used as a model of neural activation and more recently proposed as a model of gene regulation. Here we exhibit linear thresholding systems whose dynamics produce surprisingly long cycles.",
        "comments": "3 pages",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08605"
    },
    {
        "doc_id": 578,
        "title": "From Conceptual Spaces to Quantum Concepts: Formalising and Learning Structured Conceptual Models",
        "authors": [
            "Sean Tull",
            "Razin A. Shaikh",
            "Sara Sabrina Zemljic",
            "Stephen Clark"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence",
            "Quantum Physics"
        ],
        "abstract": "In this article we present a new modelling framework for structured concepts using a category-theoretic generalisation of conceptual spaces, and show how the conceptual representations can be learned automatically from data, using two very different instantiations: one classical and one quantum. A contribution of the work is a thorough category-theoretic formalisation of our framework. We claim that the use of category theory, and in particular the use of string diagrams to describe quantum processes, helps elucidate some of the most important features of our approach. We build upon Gardenfors' classical framework of conceptual spaces, in which cognition is modelled geometrically through the use of convex spaces, which in turn factorise in terms of simpler spaces called domains. We show how concepts from the domains of shape, colour, size and position can be learned from images of simple shapes, where concepts are represented as Gaussians in the classical implementation, and quantum effects in the quantum one. In the classical case we develop a new model which is inspired by the Beta-VAE model of concepts, but is designed to be more closely connected with language, so that the names of concepts form part of the graphical model. In the quantum case, concepts are learned by a hybrid classical-quantum network trained to perform concept classification, where the classical image processing is carried out by a convolutional neural network and the quantum representations are produced by a parameterised quantum circuit. Finally, we consider the question of whether our quantum models of concepts can be considered conceptual spaces in the Gardenfors sense.",
        "comments": "This article consolidates our previous reports on concept formalisation and learning: arXiv:2302.14822 and arXiv:2203.11216",
        "date": "6 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08585"
    },
    {
        "doc_id": 579,
        "title": "How cytoskeletal crosstalk makes cells move: bridging cell-free and cell studies",
        "authors": [
            "James P. Conboy",
            "Irene Ist\u00fariz Petitjean",
            "Anouk van der Net",
            "Gijsje H. Koenderink"
        ],
        "subjects": [
            "Biological Physics",
            "Cell Behavior"
        ],
        "abstract": "Cell migration is a fundamental process for life and is highly dependent on the dynamical and mechanical properties of the cytoskeleton. Intensive physical and biochemical crosstalk between actin, microtubules, and intermediate filaments ensures their coordination to facilitate and enable migration. In this review we discuss the different mechanical aspects that govern cell migration and provide, for each mechanical aspect, a novel perspective by juxtaposing two complementary approaches to the biophysical study of cytoskeletal crosstalk: live-cell studies (often referred to as top-down studies) and cell-free studies (often referred to as bottom-up studies). We summarize the main findings from both experimental approaches, and we provide our perspective on bridging the two perspectives to address the open questions of how cytoskeletal crosstalk governs cell migration and makes cells move.",
        "comments": "4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08368"
    },
    {
        "doc_id": 580,
        "title": "dabih -- encrypted data storage and sharing platform",
        "authors": [
            "Michael Huttner",
            "Jakob Simeth",
            "Renato Liguori",
            "Fulvia Ferrazzi",
            "Rainer Spang"
        ],
        "subjects": [
            "Cryptography and Security",
            "Software Engineering",
            "Genomics"
        ],
        "abstract": "Background: The secure management of sensitive clinical data, particularly human genomics data, has become a critical requirement in modern biomedical research. Although the necessary software and algorithms are readily available, their use by non-IT experts poses significant challenges.\n  Methods: We developed dabih, an open-source web application specifically designed to facilitate user-friendly encrypted data management. dabih enables web-based uploading, storing, sharing, and downloading of sensitive data in any format. Its approach to data security involves a two-stage envelope encryption process. We combine symmetric-key encryption for data and public-key encryption as key encapsulation mechanism. The private key necessary for decrypting the data remains exclusively on the owner's device. Thus, accessing data is impossible without explicit permission from the keyholder.\n  Results: dabih is available open-source on GitHub https://github.com/spang-lab/dabih, as ready to use containers on docker hub and includes a command line interface and a graphical bulk upload tool as pre-built binaries. Documentation is available as part of the web application.\n  Conclusions: dabih enables everyone to use strong cryptography for their data, while being just as simple to use as other, non-encrypted, data storage solutions. All the cryptography occurs seamlessly in the background as users interact with a secure web portal, simply by dragging and dropping files.",
        "comments": "16 pages including 4 figures and 5 appendices",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08333"
    },
    {
        "doc_id": 581,
        "title": "Multifractal organization of EEG signals in Multiple Sclerosis",
        "authors": [
            "Marcin W\u0105torek",
            "Wojciech Tomczyk",
            "Magda Gaw\u0142owska",
            "Natalia Golonka-Afek",
            "Aleksandra \u017byrkowska",
            "Monika Marona",
            "Marcin Wnuk",
            "Agnieszka S\u0142owik",
            "Jeremi K. Ochab",
            "Magdalena Fafrowicz",
            "Tadeusz Marek",
            "Pawe\u0142 O\u015bwi\u0119cimka"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Disordered Systems and Neural Networks",
            "Adaptation and Self-Organizing Systems",
            "Quantitative Methods"
        ],
        "abstract": "Quantifying the complex/multifractal organization of the brain signals is crucial to fully understanding the brain processes and structure. In this contribution, we performed the multifractal analysis of the electroencephalographic (EEG) data obtained from a controlled multiple sclerosis (MS) study, focusing on the correlation between the degree of multifractality, disease duration, and disability level. Our results reveal a significant correspondence between the complexity of the time series and multiple sclerosis development, quantified respectively by scaling exponents and the Expanded Disability Status Scale (EDSS). Namely, for some brain regions, a well-developed multifractality and little persistence of the time series were identified in patients with a high level of disability, whereas the control group and patients with low EDSS were characterised by persistence and monofractality of the signals. The analysis of the cross-correlations between EEG signals supported these results, with the most significant differences identified for patients with EDSS $> 1$ and the combined group of patients with EDSS $\\leq 1$ and controls. No association between the multifractality and disease duration was observed, indicating that the multifractal organisation of the data is a hallmark of developing the disease. The observed complexity/multifractality of EEG signals is hypothetically a result of neuronal compensation -- i.e., of optimizing neural processes in the presence of structural brain degeneration. The presented study is highly relevant due to the multifractal formalism used to quantify complexity and due to scarce resting-state EEG evidence for cortical reorganization associated with compensation.",
        "comments": "39 pages, including supplementary materials (11 figures, 4 tables)",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08321"
    },
    {
        "doc_id": 582,
        "title": "Sources of HIV infections among MSM with a migration background: a viral phylogenetic case study in Amsterdam, the Netherlands",
        "authors": [
            "Alexandra Blenkinsop",
            "Nikos Pantazis",
            "Evangelia Georgia Kostaki",
            "Lysandros Sofocleous",
            "Ard van Sighem",
            "Daniela Bezemer",
            "Thijs van de Laar",
            "Marc van der Valk",
            "Peter Reiss",
            "Godelieve de Bree",
            "Oliver Ratmann"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Background: Men and women with a migration background comprise an increasing proportion of incident HIV cases across Western Europe. Several studies indicate a substantial proportion acquire HIV post-migration.\n  Methods: We used partial HIV consensus sequences with linked demographic and clinical data from the opt-out ATHENA cohort of people with HIV in the Netherlands to quantify population-level sources of transmission to Dutch-born and foreign-born Amsterdam men who have sex with men (MSM) between 2010-2021. We identified phylogenetically and epidemiologically possible transmission pairs in local transmission chains and interpreted these in the context of estimated infection dates, quantifying transmission dynamics between sub-populations by world region of birth.\n  Results: We estimate the majority of Amsterdam MSM who acquired their infection locally had a Dutch-born Amsterdam MSM source (56% [53-58%]). Dutch-born MSM were the predominant source population of infections among almost all foreign-born Amsterdam MSM sub-populations. Stratifying by two-year intervals indicated shifts in transmission dynamics, with a majority of infections originating from foreign-born MSM since 2018, although uncertainty ranges remained wide.\n  Conclusions: In the context of declining HIV incidence among Amsterdam MSM, our data suggest whilst native-born MSM have predominantly driven transmissions in 2010-2021, the contribution from foreign-born MSM living in Amsterdam is increasing.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08308"
    },
    {
        "doc_id": 583,
        "title": "Attention-Based CNN-BiLSTM for Sleep State Classification of Spatiotemporal Wide-Field Calcium Imaging Data",
        "authors": [
            "Xiaohui Zhang",
            "Eric C. Landsness",
            "Hanyang Miao",
            "Wei Chen",
            "Michelle Tang",
            "Lindsey M. Brier",
            "Joseph P. Culver",
            "Jin-Moo Lee",
            "Mark A. Anastasio"
        ],
        "subjects": [
            "Image and Video Processing",
            "Neurons and Cognition"
        ],
        "abstract": "Background: Wide-field calcium imaging (WFCI) with genetically encoded calcium indicators allows for spatiotemporal recordings of neuronal activity in mice. When applied to the study of sleep, WFCI data are manually scored into the sleep states of wakefulness, non-REM (NREM) and REM by use of adjunct EEG and EMG recordings. However, this process is time-consuming, invasive and often suffers from low inter- and intra-rater reliability. Therefore, an automated sleep state classification method that operates on spatiotemporal WFCI data is desired. New Method: A hybrid network architecture consisting of a convolutional neural network (CNN) to extract spatial features of image frames and a bidirectional long short-term memory network (BiLSTM) with attention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Results: Sleep states were classified with an accuracy of 84% and Cohen's kappa of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while posterior area contributes most to the identification of wakefulness. The attention scores indicated that the proposed network focuses on short- and long-range temporal dependency in a state-specific manner. Comparison with Existing Method: On a 3-hour WFCI recording, the CNN-BiLSTM achieved a kappa of 0.67, comparable to a kappa of 0.65 corresponding to the human EEG/EMG-based scoring. Conclusions: The CNN-BiLSTM effectively classifies sleep states from spatiotemporal WFCI data and will enable broader application of WFCI in sleep.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08098"
    },
    {
        "doc_id": 584,
        "title": "A new model of trust based on neural information processing",
        "authors": [
            "Scott E. Allen",
            "Ren\u00e9 F. Kizilcec",
            "A. David Redish"
        ],
        "subjects": [
            "General Economics",
            "Human-Computer Interaction",
            "Neurons and Cognition"
        ],
        "abstract": "More than 30 years of research has firmly established the vital role of trust in human organizations and relationships, but the underlying mechanisms by which people build, lose, and rebuild trust remains incompletely understood. We propose a mechanistic model of trust that is grounded in the modern neuroscience of decision making. Since trust requires anticipating the future actions of others, any mechanistic model must be built upon up-to-date theories on how the brain learns, represents, and processes information about the future within its decision-making systems. Contemporary neuroscience has revealed that decision making arises from multiple parallel systems that perform distinct, complementary information processing. Each system represents information in different forms, and therefore learns via different mechanisms. When an act of trust is reciprocated or violated, this provides new information that can be used to anticipate future actions. The taxonomy of neural information representations that is the basis for the system boundaries between neural decision-making systems provides a taxonomy for categorizing different forms of trust and generating mechanistic predictions about how these forms of trust are learned and manifested in human behavior. Three key predictions arising from our model are (1) strategic risk-taking can reveal how to best proceed in a relationship, (2) human organizations and environments can be intentionally designed to encourage trust among their members, and (3) violations of trust need not always degrade trust, but can also provide opportunities to build trust.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08064"
    },
    {
        "doc_id": 585,
        "title": "Understanding YTHDF2-mediated mRNA Degradation By m6A-BERT-Deg",
        "authors": [
            "Ting-He Zhang",
            "Sumin Jo",
            "Michelle Zhang",
            "Kai Wang",
            "Shou-Jiang Gao",
            "Yufei Huang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "N6-methyladenosine (m6A) is the most abundant mRNA modification within mammalian cells, holding pivotal significance in the regulation of mRNA stability, translation, and splicing. Furthermore, it plays a critical role in the regulation of RNA degradation by primarily recruiting the YTHDF2 reader protein. However, the selective regulation of mRNA decay of the m6A-methylated mRNA through YTHDF2 binding is poorly understood. To improve our understanding, we developed m6A-BERT-Deg, a BERT model adapted for predicting YTHDF2-mediated degradation of m6A-methylated mRNAs. We meticulously assembled a high-quality training dataset by integrating multiple data sources for the HeLa cell line. To overcome the limitation of small training samples, we employed a pre-training-fine-tuning strategy by first performing a self-supervised pre-training of the model on 427,760 unlabeled m6A site sequences. The test results demonstrated the importance of this pre-training strategy in enabling m6A-BERT-Deg to outperform other benchmark models. We further conducted a comprehensive model interpretation and revealed a surprising finding that the presence of co-factors in proximity to m6A sites may disrupt YTHDF2-mediated mRNA degradation, subsequently enhancing mRNA stability. We also extended our analyses to the HEK293 cell line, shedding light on the context-dependent YTHDF2-mediated mRNA degradation.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08004"
    },
    {
        "doc_id": 586,
        "title": "Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series Clustering",
        "authors": [
            "Hamid Ghaderi",
            "Brandon Foreman",
            "Chandan K. Reddy",
            "Vignesh Subbian"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Traumatic Brain Injury (TBI) presents a broad spectrum of clinical presentations and outcomes due to its inherent heterogeneity, leading to diverse recovery trajectories and varied therapeutic responses. While many studies have delved into TBI phenotyping for distinct patient populations, identifying TBI phenotypes that consistently generalize across various settings and populations remains a critical research gap. Our research addresses this by employing multivariate time-series clustering to unveil TBI's dynamic intricates. Utilizing a self-supervised learning-based approach to clustering multivariate time-Series data with missing values (SLAC-Time), we analyzed both the research-centric TRACK-TBI and the real-world MIMIC-IV datasets. Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of clusters remained consistent across these datasets, underscoring SLAC-Time's stability across heterogeneous datasets. Our analysis revealed three generalizable TBI phenotypes (\u03b1, \\b{eta}, and \u03b3), each exhibiting distinct non-temporal features during emergency department visits, and temporal feature profiles throughout ICU stays. Specifically, phenotype \u03b1 represents mild TBI with a remarkably consistent clinical presentation. In contrast, phenotype \\b{eta} signifies severe TBI with diverse clinical manifestations, and phenotype \u03b3 represents a moderate TBI profile in terms of severity and clinical diversity. Age is a significant determinant of TBI outcomes, with older cohorts recording higher mortality rates. Importantly, while certain features varied by age, the core characteristics of TBI manifestations tied to each phenotype remain consistent across diverse populations.",
        "comments": "25 pages, 10 figures, 4 tables, submitted to Computers in Biology and Medicine",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08002"
    },
    {
        "doc_id": 587,
        "title": "Integrate Any Omics: Towards genome-wide data integration for patient stratification",
        "authors": [
            "Shihao Ma",
            "Andy G. X. Zeng",
            "Benjamin Haibe-Kains",
            "Anna Goldenberg",
            "John E Dick",
            "Bo Wang"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "High-throughput omics profiling advancements have greatly enhanced cancer patient stratification. However, incomplete data in multi-omics integration presents a significant challenge, as traditional methods like sample exclusion or imputation often compromise biological diversity and dependencies. Furthermore, the critical task of accurately classifying new patients with partial omics data into existing subtypes is commonly overlooked. To address these issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised framework for integrating incomplete multi-omics data and classifying new samples. IntegrAO first combines partially overlapping patient graphs from diverse omics sources and utilizes graph neural networks to produce unified patient embeddings. Our systematic evaluation across five cancer cohorts involving six omics modalities demonstrates IntegrAO's robustness to missing data and its accuracy in classifying new samples with partial profiles. An acute myeloid leukemia case study further validates its capability to uncover biological and clinical heterogeneity in incomplete datasets. IntegrAO's ability to handle heterogeneous and incomplete data makes it an essential tool for precision oncology, offering a holistic approach to patient characterization.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07937"
    },
    {
        "doc_id": 588,
        "title": "Predicting heteropolymer interactions: demixing and hypermixing of disordered protein sequences",
        "authors": [
            "Kyosuke Adachi",
            "Kyogo Kawaguchi"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Cells contain multiple condensates which spontaneously form due to the heterotypic interactions between their components. Although the proteins and disordered region sequences that are responsible for condensate formation have been extensively studied, the rule of interactions between the components that allow demixing, i.e., the coexistence of multiple condensates, is yet to be elucidated. Here we construct an effective theory of the interaction between heteropolymers by fitting it to the molecular dynamics simulation results obtained for more than 200 sequences sampled from the disordered regions of human proteins. We find that the sum of amino acid pair interactions across two heteropolymers predicts the Boyle temperature qualitatively well, which can be quantitatively improved by the dimer pair approximation, where we incorporate the effect of neighboring amino acids in the sequences. The improved theory, combined with the finding of a metric that captures the effective interaction strength between distinct sequences, allowed the selection of up to three disordered region sequences that demix with each other in multicomponent simulations, as well as the generation of artificial sequences that demix with a given sequence. The theory points to a generic sequence design strategy to demix or hypermix thanks to the low dimensional nature of the space of the interactions that we identify. As a consequence of the geometric arguments in the space of interactions, we find that the number of distinct sequences that can demix with each other is strongly constrained, irrespective of the choice of the coarse-grained model. Altogether, we construct a theoretical basis for methods to estimate the effective interaction between heteropolymers, which can be utilized in predicting phase separation properties as well as rules of assignment in the localization and functions of disordered proteins.",
        "comments": "20 pages, 21 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07826"
    },
    {
        "doc_id": 589,
        "title": "Phenotyping calcification in vascular tissues using artificial intelligence",
        "authors": [
            "Mehdi Ramezanpour",
            "Anne M. Robertson",
            "Yasutaka Tobe",
            "Xiaowei Jia",
            "Juan R. Cebral"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Data Analysis, Statistics and Probability",
            "Quantitative Methods",
            "Tissues and Organs"
        ],
        "abstract": "Vascular calcification is implicated as an important factor in major adverse cardiovascular events (MACE), including heart attack and stroke. A controversy remains over how to integrate the diverse forms of vascular calcification into clinical risk assessment tools. Even the commonly used calcium score for coronary arteries, which assumes risk scales positively with total calcification, has important inconsistencies. Fundamental studies are needed to determine how risk is influenced by the diverse calcification phenotypes. However, studies of these kinds are hindered by the lack of high-throughput, objective, and non-destructive tools for classifying calcification in imaging data sets. Here, we introduce a new classification system for phenotyping calcification along with a semi-automated, non-destructive pipeline that can distinguish these phenotypes in even atherosclerotic tissues. The pipeline includes a deep-learning-based framework for segmenting lipid pools in noisy micro-CT images and an unsupervised clustering framework for categorizing calcification based on size, clustering, and topology. This approach is illustrated for five vascular specimens, providing phenotyping for thousands of calcification particles across as many as 3200 images in less than seven hours. Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for tissue and lipid pool, respectively, with training and validation needed on only 13 images despite the high heterogeneity in these tissues. By introducing an efficient and comprehensive approach to phenotyping calcification, this work enables large-scale studies to identify a more reliable indicator of the risk of cardiovascular events, a leading cause of global mortality and morbidity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07825"
    },
    {
        "doc_id": 590,
        "title": "Animal-associated marine Acidobacteria with a rich natural product repertoire",
        "authors": [
            "Stefan Leopold-Messer",
            "Clara Chepkirui",
            "Mathijs F. J. Mabesoone",
            "Joshua Mayer",
            "Lucas Paoli",
            "Shinichi Sunagawa",
            "Agustinus R. Uria",
            "Toshiyuki Wakimoto",
            "J\u00f6rn Piel"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Sponges have long been recognized as a rich source of bioactive natural products. Various studies suggest that many of these compounds are produced by symbiotic bacteria. However, substance supplies and functional insights about the producers remain limited because cultivation remains unsuccessful. To identify alternative, sustainable sources of sponge-derived polyketides, we computationally analyzed 5289 characterized and orphan trans-acyltransferase polyketide synthases, enzymes with widespread roles in polyketide biosynthesis by bacterial symbionts. The analytical workflow predicted marine animal-derived Acidobacteria of the family Acanthopleuribacteraceae with large sets of biosynthetic gene clusters to be enriched in sponge-type chemistry. Targeted compound isolation from a chiton-associated strain yielded new congeners of the phorboxazoles and calyculins, potent and scarce cytotoxins exclusively known from sponges. These first natural products of Acidobacteria and new coral metagenomic data on a third family member suggest animal-associated Acanthopleuribacteraceae as a rich source of sponge-type as well as novel metabolites",
        "comments": "Journal ref:        Chem, 9 (12), 2023, pp. 3696-3713",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07730"
    },
    {
        "doc_id": 591,
        "title": "Comprehensive Joint Modeling of First-Line Therapeutics in Non-Small Cell Lung Cancer",
        "authors": [
            "Benjamin Schneider",
            "S\u00e9bastien Benzekry",
            "Jonathan Mochel"
        ],
        "subjects": [
            "Cell Behavior",
            "Tissues and Organs"
        ],
        "abstract": "First-line antiproliferatives for non-small cell lung cancer (NSCLC) have a relatively high failure rate due to high intrinsic resistance rates and acquired resistance rates to therapy. 57% patients are diagnosed in late-stage disease due to the tendency of early-stage NSCLC to be asymptomatic. For patients first diagnosed with metastatic disease the 5-year survival rate is approximately 5%. To help accelerate the development of novel therapeutics and computer-based tools for optimizing individual therapy, we have collated data from 11 different clinical trials in NSCLC and developed a semi-mechanistic, clinical model of NSCLC growth and pharmacodynamics relative to the various therapeutics represented in the study. In this study, we have produced extremely precise estimates of clinical parameters fundamental to cancer modeling such as the rate of acquired resistance to various pharmaceuticals, the relationship between drug concentration and rate of cancer cell death, as well as the fine temporal dynamics of anti-VEGF therapy. In the simulation sets documented in this study, we have used the model to make meaningful descriptions of efficacy gain in making bevacizumab-antiproliferative combination therapy sequential, over a series of days, rather than concurrent.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07719"
    },
    {
        "doc_id": 592,
        "title": "Ion channels in critical membranes: clustering, cooperativity, and memory effects",
        "authors": [
            "Antonio Suma",
            "Daniel Sigg",
            "Seamus Gallagher",
            "Giuseppe Gonnella",
            "Vincenzo Carnevale"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Much progress has been made in elucidating the inner workings of voltage-gated ion channels, but less understood is the influence of lipid rafts on gating kinetics. Here we propose that state-dependent channel affinity for different lipid species provides a unified explanation for the experimentally observed behaviors of clustering, cooperativity, and hysteresis. We develop models of diffusing lipids and channels engaged in Ising-like interactions to investigate the collective behaviors driven by raft formation in critical membranes close to the demixing transition. The model channels demonstrate lipid-mediated long-range interactions, activation curve steepening, and long-term memory in ionic currents. These behaviors likely play a role in channel-mediated cellular signaling and suggest a universal mechanism for self-organization of biomolecular assemblies.",
        "comments": "14 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07660"
    },
    {
        "doc_id": 593,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 594,
        "title": "Measuring multisensory integration in reaction time: the relative entropy approach",
        "authors": [
            "Hans Colonius",
            "Adele Diederich"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "A classic definition of multisensory integration (MI) has been proposed as ``the presence of a (statistically) significant change in the response to a cross-modal stimulus complex compared to unimodal stimuli''. However, this general definition did not result in a broad consensus on how to quantify the amount of MI in the context of reaction time (RT). In this brief note, we argue that numeric measures of reaction times that only involve mean or median RTs do not uncover the information required to fully assess the effect of multisensory integration. We suggest instead novel measures that include the entire RT distributions functions. The central role is played by relative entropy (aka Kullback-Leibler divergence), a statistical concept in information theory, statistics, and machine learning to measure the (non-symmetric) distance between probability distributions. We provide a number of theoretical examples, but empirical applications and statistical testing are postponed to later study.",
        "comments": "9 pages, 1 figure",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07568"
    },
    {
        "doc_id": 595,
        "title": "Vitamin K content of Australian-grown horticultural commodities",
        "authors": [
            "Eleanor Dunlop",
            "Judy Cunningham",
            "Paul Adorno",
            "Georgios Dabos",
            "Stuart K Johnson",
            "Lucinda J Black"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Vitamin K is emerging as a multi-function vitamin that plays a role in bone, brain and vascular health. Vitamin K composition data remain limited globally and Australia has lacked nationally representative data for vitamin K1 (phylloquinone, PK) in horticultural commodities. Primary samples (n = 927) of 90 different Australian-grown fruit, vegetable and nut commodities were purchased in three Australian cities. We measured PK in duplicate in 95 composite samples using liquid chromatography with electrospray ionisation-tandem mass spectrometry. The greatest mean concentrations of PK were found in kale (565 ug/100 g), baby spinach (255 ug/100 g) and Brussels sprouts (195 ug/100 g). The data contribute to the global collection of vitamin K food composition data. They add to the evidence that PK concentrations vary markedly between geographic regions, supporting development of region-specific datasets for national food composition databases that do not yet contain data for vitamin K.",
        "comments": "22 pages, 2 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07473"
    },
    {
        "doc_id": 596,
        "title": "Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks",
        "authors": [
            "Maria Mircea",
            "Diego Garlaschelli",
            "Stefan Semrau"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning",
            "Biological Physics",
            "Molecular Networks"
        ],
        "abstract": "One of the main goals of developmental biology is to reveal the gene regulatory networks (GRNs) underlying the robust differentiation of multipotent progenitors into precisely specified cell types. Most existing methods to infer GRNs from experimental data have limited predictive power as the inferred GRNs merely reflect gene expression similarity or correlation. Here, we demonstrate, how physics-informed neural networks (PINNs) can be used to infer the parameters of predictive, dynamical GRNs that provide mechanistic understanding of biological processes. Specifically we study GRNs that exhibit bifurcation behavior and can therefore model cell differentiation. We show that PINNs outperform regular feed-forward neural networks on the parameter inference task and analyze two relevant experimental scenarios: 1. a system with cell communication for which gene expression trajectories are available and 2. snapshot measurements of a cell population in which cell communication is absent. Our analysis will inform the design of future experiments to be analyzed with PINNs and provides a starting point to explore this powerful class of neural network models further.",
        "comments": "25 pages, 8 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07379"
    },
    {
        "doc_id": 597,
        "title": "Robust Genomic Prediction and Heritability Estimation using Density Power Divergence",
        "authors": [
            "Upama Paul Chowdhury",
            "Susmita Das",
            "Abhik Ghosh"
        ],
        "subjects": [
            "Methodology",
            "Genomics",
            "Applications"
        ],
        "abstract": "This manuscript delves into the intersection of genomics and phenotypic prediction, focusing on the statistical innovation required to navigate the complexities introduced by noisy covariates and confounders. The primary emphasis is on the development of advanced robust statistical models tailored for genomic prediction from single nucleotide polymorphism (SNP) data collected from genome-wide association studies (GWAS) in plant and animal breeding and multi-field trials. The manuscript explores the limitations of traditional marker-assisted recurrent selection, highlighting the significance of incorporating all estimated effects of marker loci into the statistical framework and aiming to reduce the high dimensionality of GWAS data while preserving critical information. This paper introduces a new robust statistical framework for genomic prediction, employing one-stage and two-stage linear mixed model analyses along with utilizing the popular robust minimum density power divergence estimator (MDPDE) to estimate genetic effects on phenotypic traits. The study illustrates the superior performance of the proposed MDPDE-based genomic prediction and associated heritability estimation procedures over existing competitors through extensive empirical experiments on artificial datasets and application to a real-life maize breeding dataset. The results showcase the robustness and accuracy of the proposed MDPDE-based approaches, especially in the presence of data contamination, emphasizing their potential applications in improving breeding programs and advancing genomic prediction of phenotyping traits.",
        "comments": "Under Review",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07344"
    },
    {
        "doc_id": 598,
        "title": "Phenotypic switching mechanisms determine the structure of cell migration into extracellular matrix under the `go-or-grow' hypothesis",
        "authors": [
            "Rebecca M. Crossley",
            "Kevin J. Painter",
            "Tommaso Lorenzi",
            "Philip K. Maini",
            "Ruth E. Baker"
        ],
        "subjects": [
            "Cell Behavior"
        ],
        "abstract": "A fundamental feature of collective cell migration is phenotypic heterogeneity which, for example, influences tumour progression and relapse. While current mathematical models often consider discrete phenotypic structuring of the cell population, in-line with the `go-or-grow' hypothesis \\cite{hatzikirou2012go, stepien2018traveling}, they regularly overlook the role that the environment may play in determining the cells' phenotype during migration. Comparing a previously studied volume-filling model for a homogeneous population of generalist cells that can proliferate, move and degrade extracellular matrix (ECM) \\cite{crossley2023travelling} to a novel model for a heterogeneous population comprising two distinct sub-populations of specialist cells that can either move and degrade ECM or proliferate, this study explores how different hypothetical phenotypic switching mechanisms affect the speed and structure of the invading cell populations. Through a continuum model derived from its individual-based counterpart, insights into the influence of the ECM and the impact of phenotypic switching on migrating cell populations emerge. Notably, specialist cell populations that cannot switch phenotype show reduced invasiveness compared to generalist cell populations, while implementing different forms of switching significantly alters the structure of migrating cell fronts. This key result suggests that the structure of an invading cell population could be used to infer the underlying mechanisms governing phenotypic switching.",
        "comments": "34 pages, 11 figures",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07279"
    },
    {
        "doc_id": 599,
        "title": "Balancing reaction-diffusion network for cell polarization pattern with stability and asymmetry",
        "authors": [
            "Yixuan Chen",
            "Guoye Guan",
            "Lei-Han Tang",
            "Chao Tang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Cell polarization is a critical process that separates molecules into two distinct regions in prokaryotic and eukaryotic cells, guiding biological processes such as cell division and cell differentiation. Although several underlying antagonistic reaction-diffusion networks capable of setting up cell polarization have been identified experimentally and theoretically, our understanding of how to manipulate pattern stability and asymmetry remains incomplete, especially when only a subset of network components are known. Here we present numerical results to show that the polarized pattern of an antagonistic 2-node network collapses into a homogeneous state when subjected to single-sided self-regulation, single-sided additional regulation, or unequal system parameters. However, polarity can be restored through a combination of two modifications that have opposing effects. Additionally, spatially inhomogeneous parameters favoring respective domains stabilize their interface at designated locations. To connect our findings to cell polarity studies of the nematode Caenorhabditis elegans zygote, we reconstituted a 5-node network where a 4-node circuit with full mutual inhibitions between anterior and posterior is modified by a mutual activation in the anterior and an additional mutual inhibition between the anterior and the posterior. Once again, a generic set of kinetic parameters moves the interface towards either the anterior or posterior end, yet a polarized pattern can be stabilized through spatial tuning of one or more parameters coupled to intracellular or extracellular cues. A user-friendly software, PolarSim, is introduced to facilitate the exploration of networks with alternative node numbers, parameter values, and regulatory pathways.",
        "comments": " ",
        "date": "14 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07227"
    }
]