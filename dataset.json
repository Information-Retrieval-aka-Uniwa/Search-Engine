[
    {
        "doc_id": 0,
        "title": "Identification of Nonseparable Models with Endogenous Control Variables",
        "authors": [
            "Kaicheng Chen",
            "Kyoo il Kim"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "We study identification of the treatment effects in a class of nonseparable models with the presence of potentially endogenous control variables. We show that given the treatment variable and the controls are measurably separated, the usual conditional independence condition or availability of excluded instrument suffices for identification.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14395"
    },
    {
        "doc_id": 1,
        "title": "Using Geographically Weighted Models to Explore Temporal and Spatial Varying Impacts on Commute Trip Change Due to Covid-19",
        "authors": [
            "Saeed Saleh Namadi",
            "Behnam Tahmasbi",
            "Asal Mehditabrizi",
            "Aref Darzi",
            "Deb Niemeier"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "COVID-19 has deeply affected daily life and travel behaviors. Understanding these changes is crucial, prompting an investigation into socio-demographic and socio-economic factors. This study used large-scale mobile device location data in Washington, D.C., Maryland, and Virginia (DMV area) to unveil the impacts of these variables on commute trip changes. It reflected short and long-term impacts through linear regression and geographically weighted regression models. Findings indicated that counties with a higher percentage of people using walking and biking during the initial phase of COVID-19 experienced greater reductions in commute trips. For the long-term effect in November, the impact of active modes became insignificant, and individuals using public modes showed more significant trip reductions. Positive correlations were observed between median income levels and reduced commute trips. Sectors requiring ongoing outdoor operations during the pandemic showed substantial negative correlations. In the DMV area, counties with a higher proportion of Democratic voters experienced less trip reduction. Applying Geographically Weighted Regression models captured local spatial relationships, showing the emergence of local correlations as the pandemic evolved, suggesting a geographical impact pattern. Initially global, the pandemic's impact on commuting behaviors became more influenced by spatial factors over time, showing localized effects.",
        "comments": "28 pages, 8 figures, accepted at TRR 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14306"
    },
    {
        "doc_id": 2,
        "title": "spINAR: An R Package for Semiparametric and Parametric Estimation and Bootstrapping of Integer-Valued Autoregressive (INAR) Models",
        "authors": [
            "Maxime Faymonville",
            "Javiera Riffo",
            "Jonas Rieger",
            "Carsten Jentsch"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "Although the statistical literature extensively covers continuous-valued time series processes and their parametric, non-parametric and semiparametric estimation, the literature on count data time series is considerably less advanced. Among the count data time series models, the integer-valued autoregressive (INAR) model is arguably the most popular one finding applications in a wide variety of fields such as medical sciences, environmentology and economics. While many contributions have been made during the last decades, the majority of the literature focuses on parametric INAR models and estimation techniques. Our emphasis is on the complex but efficient and non-restrictive semiparametric estimation of INAR models. The appeal of this approach lies in the absence of a commitment to a parametric family of innovation distributions. In this paper, we describe the need and the features of our R package spINAR which combines semiparametric simulation, estimation and bootstrapping of INAR models also covering its parametric versions.",
        "comments": "3 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14239"
    },
    {
        "doc_id": 3,
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics",
            "Trading and Market Microstructure"
        ],
        "abstract": "In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14199"
    },
    {
        "doc_id": 4,
        "title": "Costly Persuasion by a Partially Informed Sender",
        "authors": [
            "Shaofei Jiang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "I study a model of costly Bayesian persuasion by a privately and partially informed sender who conducts a public experiment. The cost of running an experiment is the expected reduction of a weighted log-likelihood ratio function of the sender's belief. This is microfounded by a Wald's sequential sampling problem where good news and bad news cost differently. I focus on equilibria that satisfy the D1 criterion. The equilibrium outcome depends on the relative costs of drawing good and bad news in the experiment. If bad news is more costly, there exists a unique separating equilibrium, and the receiver unambiguously benefits from the sender's private information. If good news is more costly, the single-crossing property fails. There may exist pooling and partial pooling equilibria, and in some equilibria, the receiver strictly suffers from sender private information.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14087"
    },
    {
        "doc_id": 5,
        "title": "Influence of climate variability on the potential forage production of a mown permanent grassland in the French Massif Central",
        "authors": [
            "I\u00f1igo G\u00f3mara",
            "Gianni Bellocchi",
            "Rapha\u00ebl Martin",
            "Bel\u00e9n Rodr\u00edguez-Fonseca",
            "Margarita Ruiz-Ramos"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Climate Services (CS) provide support to decision makers across socio-economic sectors. In the agricultural sector, one of the most important CS applications is to provide timely and accurate yield forecasts based on climate prediction. In this study, the Pasture Simulation model (PaSim) was used to simulate, for the period 1959-2015, the forage production of a mown grassland system (Laqueuille, Massif Central of France) under different management conditions, with meteorological inputs extracted from the SAFRAN atmospheric database. The aim was to generate purely climate-dependent timeseries of optimal forage production, a variable that was maximized by brighter and warmer weather conditions at the grassland. A long-term increase was observed in simulated forage yield, with the 1995-2015 average being 29% higher than the 1959-1979 average. Such increase seems consistent with observed rising trends in temperature and CO2, and multi-decadal changes in incident solar radiation. At interannual timescales, sea surface temperature anomalies of the Mediterranean (MED), Tropical North Atlantic (TNA), equatorial Pacific (El Ni\u00f1o Southern Oscillation) and the North Atlantic Oscillation (NAO) index were found robustly correlated with annual forage yield values. Relying only on climatic predictors, we developed a stepwise statistical multi-regression model with leave-one-out cross-validation. Under specific management conditions (e.g., three annual cuts) and from one to five months in advance, the generated model successfully provided a p-value<0.01 in correlation (t-test), a root mean square error percentage (%RMSE) of 14.6% and a 71.43% hit rate predicting above/below average years in terms of forage yield collection.",
        "comments": "Journal ref:        Gomara I, Bellocchi G, Martin R, Rodriguez-Fonseca B, Ruiz-Ramos M (2020) Agricultural and Forest Meteorology, 280, 107768",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14053"
    },
    {
        "doc_id": 6,
        "title": "Engineering a sustainable world by enhancing the scope of systems of systems engineering and mastering dynamics",
        "authors": [
            "Rasmus Adler",
            "Frank Elberzhager",
            "Florian Baldauf"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Engineering a sustainable world requires to consider various systems that interact with each other. These systems include ecological systems, economical systems, social systems and tech-nical systems. They are loosely coupled, geographically distributed, evolve permanently and generate emergent behavior. As these are characteristics of systems of systems (SoS), we discuss the engi-neering of a sustainable world from a SoS engineering perspective. We studied SoS engineering in context of a research project, which aims at political recommendations and a research roadmap for engineering dynamic SoS. The project included an exhaustive literature review, interviews and work-shops with representatives from industry and academia from different application domains. Based on these results and observations, we will discuss how suitable the current state-of-the-art in SoS engi-neering is in order to engineer sustainability. Sustainability was a major driver for SoS engineering in all domains, but we argue that the current scope of SoS engineering is too limited in order to engineer sustainability. Further, we argue that mastering dynamics in this larger scope is essential to engineer sustainability and that this is accompanied by dynamic adaptation of technological SoS.",
        "comments": "Accepted at the INCOSE EMEA WSEC Workshop and Conference, Sevilla, Spain - 24-26 April, 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14047"
    },
    {
        "doc_id": 7,
        "title": "Measuring multidimensional inequality: a new proposal based on the Fourier transform",
        "authors": [
            "Paolo Giudici",
            "Emanuela Raffinetti",
            "Giuseppe Toscani"
        ],
        "subjects": [
            "Physics and Society",
            "Information Theory",
            "Probability"
        ],
        "abstract": "Inequality measures are quantitative measures that take values in the unit interval, with a zero value characterizing perfect equality. Although originally proposed to measure economic inequalities, they can be applied to several other situations, in which one is interested in the mutual variability between a set of observations, rather than in their deviations from the mean. While unidimensional measures of inequality, such as the Gini index, are widely known and employed, multidimensional measures, such as Lorenz Zonoids, are difficult to interpret and computationally expensive and, for these reasons, are not much well known. To overcome the problem, in this paper we propose a new scaling invariant multidimensional inequality index, based on the Fourier transform, which exhibits a number of interesting properties, and whose application to the multidimensional case is rather straightforward to calculate and interpret.",
        "comments": "arXiv admin note: text overlap with arXiv:2310.20483",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14012"
    },
    {
        "doc_id": 8,
        "title": "Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru",
        "authors": [
            "Tanmay Ghosh",
            "Nithin Nagaraj"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics"
        ],
        "abstract": "The decision making involved behind the mode choice is critical for transportation planning. While statistical learning techniques like discrete choice models have been used traditionally, machine learning (ML) models have gained traction recently among the transportation planners due to their higher predictive performance. However, the black box nature of ML models pose significant interpretability challenges, limiting their practical application in decision and policy making. This study utilised a dataset of $1350$ households belonging to low and low-middle income bracket in the city of Bengaluru to investigate mode choice decision making behaviour using Multinomial logit model and ML classifiers like decision trees, random forests, extreme gradient boosting and support vector machines. In terms of accuracy, random forest model performed the best ($0.788$ on training data and $0.605$ on testing data) compared to all the other models. This research has adopted modern interpretability techniques like feature importance and individual conditional expectation plots to explain the decision making behaviour using ML models. A higher travel costs significantly reduce the predicted probability of bus usage compared to other modes (a $0.66\\%$ and $0.34\\%$ reduction using Random Forests and XGBoost model for $10\\%$ increase in travel cost). However, reducing travel time by $10\\%$ increases the preference for the metro ($0.16\\%$ in Random Forests and 0.42% in XGBoost). This research augments the ongoing research on mode choice analysis using machine learning techniques, which would help in improving the understanding of the performance of these models with real-world data in terms of both accuracy and interpretability.",
        "comments": "65 pages, 26 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13977"
    },
    {
        "doc_id": 9,
        "title": "Principal Component Regression to Study the Impact of Economic Factors on Disadvantaged Communities",
        "authors": [
            "Narmadha M. Mohankumar",
            "Milan Jain",
            "Heng Wan",
            "Sumitrra Ganguli",
            "Kyle D. Wilson",
            "David M. Anderson"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "The Council on Environmental Quality's Climate and Economic Justice Screening Tool defines \"disadvantaged communities\" (DAC) in the USA, highlighting census tracts where benefits of climate and energy investments are not accruing. We use a principal component generalized linear model, which addresses the intertwined nature of economic factors, income and employment and model their relationship to DAC status. Our study 1) identifies the most significant income groups and employment industries that impact DAC status, 2) provides the probability of DAC status across census tracts and compares the predictive accuracy with widely used machine learning approaches, 3) obtains historical predictions of the probability of DAC status, 4) obtains spatial downscaling of DAC status across block groups. Our study provides valuable insights for policymakers and stakeholders to develop strategies that promote sustainable development and address inequities in climate and energy investments in the USA.",
        "comments": "13 pages, 9 figures, 2 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13880"
    },
    {
        "doc_id": 10,
        "title": "SoK: Game-Theoretic Cybersecurity: Assumptions, Models, Gaps, and Bridges",
        "authors": [
            "Brandon Collins",
            "Shouhuai Xu",
            "Philip N. Brown"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security"
        ],
        "abstract": "The discipline of game theory was introduced in the context of economics, and has been applied to study cyber attacker and defender behaviors. While adaptions have been made to accommodate features in the cyber domain, these studies are inherently limited by the root of game theory in economic systems where players (i.e., agents) may be selfish but not malicious. In this SoK, we systematize the major cybersecurity problems that have been studied with the game-theoretic approach, the assumptions that have been made, the models and solution concepts that have been proposed. The systematization leads to a characterization of the technical gaps that must be addressed in order to make game-theoretic cybersecurity models truly useful. We explore bridges to address them.",
        "comments": "21 pages, Finished October 17th, 2023",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13815"
    },
    {
        "doc_id": 11,
        "title": "Optimal Queueing Regimes",
        "authors": [
            "Marco Scarsini",
            "Eran Shmaya"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory",
            "Probability"
        ],
        "abstract": "We consider an M/M/1 queueing model where customers can strategically decide whether to join the queue or balk and when to renege. We characterize the class of queueing regimes such that, for any parameters of the model, the socially efficient behavior is an equilibrium outcome.",
        "comments": "MSC Class:          91A40; 60J28",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13812"
    },
    {
        "doc_id": 12,
        "title": "The Arrival of Fast Internet and Employment in Africa: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Hjort and Poulsen (2019) frames the staggered arrival of submarine Internet cables on the shores of Africa circa 2010 as a difference-in-differences natural experiment in broadband access. The paper finds positive impacts on individual- and firm-level employment and nighttime light emissions. These results are largely ascribable to geocoding errors; to discontinuities from a satellite changeover at end-2009; and to a definition of the treated zone that has unclear technological basis, is narrower than the spatial resolution of nearly all the data sources, and is weakly representative of the geography of broadband availability.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13694"
    },
    {
        "doc_id": 13,
        "title": "Trusting AI in High-stake Decision Making",
        "authors": [
            "Ali Saffarini"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "The use of artificial intelligence models has recently grown common; we may use them to write lines of code for us, summarize readings, draft emails, or even illustrate images. But when it comes to important decisions we need to make, such as choosing between job offers or implementing certain economic policies, our level of confidence and trust in AI falls. This raises an intriguing point of exploration which I tackle in this paper - What would need to happen for people to trust artificial intelligence for important decisions? In this paper, I elaborate on how trust in AI for high-stake decisions would be accomplished if the technology was anthropomorphized because its anthropomorphism would overcome psychological barriers that are necessary to overcome for us to trust AI for important decisions.",
        "comments": "14 Pages, 0 Figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13689"
    },
    {
        "doc_id": 14,
        "title": "In the Aftermath of Oil Prices Fall of 2014/2015-Socioeconomic Facts and Changes in the Public Policies in the Sultanate of Oman",
        "authors": [
            "Osama A. Marzouk"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Since the start of its national renaissance in 1970, the Sultanate of Oman (Oman) has gone over a major development in several areas, such as education, infrastructure, and urbanization. This has been powered by the revenues from exporting crude oil and natural gas, which together form the skeleton of the country's economy. In the second half of 2014, the oil prices declined strongly to about 50% of its price. This was followed by another moderate decline in the second half of 2015 and the beginning of 2016, leaving the barrel price at a low level below 30 US$ in January 2016 (as compared to above 110 US$ in June 2014). This drop had direct impacts on the economy of Oman, manifested in a large budget deficit, reduced governmental expenditure, reduced or cancelled subsidy of fuels and electricity, increase in the water tariff, and decline in deposits in banks. The country is coping with this through its 9th five-year plan (2016-2020), which adopts a strategy of diversifying the income and relying less on the traditional oil and gas sector. The country has also taken measures to facilitate private businesses. This article sheds light on these topics as well as miscellaneous data about Oman.",
        "comments": "17 pages, 16 figures, 5 tables, 44 references",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13688"
    },
    {
        "doc_id": 15,
        "title": "Econometric Approach to Analyzing Determinants of Sustained Prosperity",
        "authors": [
            "Anika Dixit"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Every year, substantial resources are allocated to foreign aid with the aim of catalyzing prosperity and development in recipient countries. The diverse body of research on the relationship between aid and gross domestic product (GDP) has yielded varying results, finding evidence of both positive, negative, and negligible associations between the two. This study employs econometric techniques, namely Fully Modified Ordinary Least Squares Regression (FMOLS) and the Generalized Method of Moments (GMM), to explore the intricate links between innovation and different types of official development assistance (ODA) with the overarching construct of prosperity. The paper also reviews the linkages between foundational metrics, such as the rule of law, education, and economic infrastructure and services, in enabling self-sustaining prosperity. Drawing upon panel data of relevant determinants for 74 countries across the years 2013 to 2021, the study found that there was a negligible relationship between both ODA and innovation indices with prosperity. Notably, foreign aid targeted specifically toward education was observed to have a positive impact on prosperity, as was the presence of rule of law in a state. The results of the study are then examined through the lens of a case-study on Reliance Jio, exemplifying how the company engineered an ecosystem that harnessed resources and facilitated infrastructure development, thereby contributing to self-sustaining economic growth and prosperity in India.",
        "comments": "15 pages including 7 tables, and references",
        "date": "22 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13687"
    },
    {
        "doc_id": 16,
        "title": "Capturing the Tax-Revenue Bracketing System via a predator-prey model: Evidence from South Africa",
        "authors": [
            "Leonard Mushunje"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Revenues obtained from the corporate tax heads play significant roles in any economy as they can be prioritized for producing public goods and employment creations, among others. As such, corporate tax revenue should be paid enough attention. This study, therefore, explores the tax-revenue harvesting system of an economy where we focused on the corporate tax head. The system comprises three players; the government and formal and informal firms. We applied the predator-prey model to model the effect of the government-gazetted tax rate on corporate survivability. It is a new approach to modeling economic system relations and games. Critical combinatory points are derived, with stability analysis provided after that. Dynamics associated with the tax-revenue system are established and critically analyzed. Lastly, we provide the mathematical way the system can be optimized for the government to harvest as much Revenue as possible, including optimal conditions.",
        "comments": "18 Pages",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13686"
    },
    {
        "doc_id": 17,
        "title": "Determinants of Hotels and Restaurants entrepreneurship: A study using GEM data",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The objective of this work is to assess the influence of certain factors on the likelihood of being a Hotels and Restaurants (H&R) entrepreneur. The factors evaluated are demographic and economic variables, variables related to perceptions of the environment and personal traits, and variables measuring the individual's intellectual and social capital. The work uses logistic regression techniques to analyze a sample of 33,711 individuals in the countries participating in the GEM project in 2008. The findings show that age, gender, income, perception of opportunities, fear of failure, entrepreneurial ability, knowing other entrepreneurs and being a business angel are explanatory factors of the probability of being an H&R entrepreneur.",
        "comments": "Journal ref:        International Journal of Hospitality Management, 31(2), 579-587 (2012)",
        "date": "18 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13685"
    },
    {
        "doc_id": 18,
        "title": "Global Entrepreneurship Monitor versus Panel Study of Entrepreneurial Dynamics: comparing their intellectual structures",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Salustiano Martinez-Fierro",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "In the past 15 years, two international observatories have been intensively studying entrepreneurship using empirical studies with different methodologies: GEM and PSED. Both projects have generated a considerable volume of scientific production, and their intellectual structures are worth analyzing. The current work is an exploratory study of the knowledge base of the articles generated by each of these two observatories and published in prestigious journals. The value added of this work lies in its novel characterization of the intellectual structure of entrepreneurship according to the academic production of these two initiatives. The results may be of interest to the managers and members of these observatories, as well as to academics, researchers, sponsors and policymakers interested in entrepreneurship.",
        "comments": "Journal ref:        (2015). Global entrepreneurship monitor versus panel study of entrepreneurial dynamics: comparing their intellectual structures. International Entrepreneurship and Management Journal, 11(3), 571-597",
        "date": "18 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13684"
    },
    {
        "doc_id": 19,
        "title": "Relationship between work-family balance, employee well-being and job performance",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Antonio Rafael Ramos-Rodriguez"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Purpose: To assess the impact of the existence of and access to different work-family policies on employee well-being and job performance.\n  Design-methodology-approach: Hypothesis testing was performed using a structural equation model based on a PLS-SEM approach applied to a sample of 1,511 employees of the Spanish banking sector.\n  Findings: The results obtained demonstrate that the existence and true access to different types of work-family policies such as flexible working hours (flexi-time), long leaves, and flexible work location (flexi-place) are not directly related to job performance, but indirectly so, when mediated by the well-being of employees generated by work-family policies. In a similar vein, true access to employee and family support services also has an indirect positive impact on job performance mediated by the well-being produced. In contrast, the mere existence of employee and family support services does not have any direct or indirect effect on job performance.\n  Originality-value: This study makes a theoretical and empirical contribution to better understand the impact that of the existence of and access to work-family policies on job performance mediated by employee well-being. In this sense, we posited and tested an unpublished theoretical model where the concept of employee well-being gains special relevance at academic and organizational level due to its implications for human resource management.",
        "comments": "Journal ref:        Academia Revista Latinoamericana de Administracion, 30(1), pp. 40-58 (2017)",
        "date": "15 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13683"
    },
    {
        "doc_id": 20,
        "title": "Why not now? Intended timing in entrepreneurial intentions",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Purpose: Understanding the formation of entrepreneurial intentions is critical, given that it is the first step in the entrepreneurial process. Although entrepreneurial intention has been extensively studied, little attention has been paid on the intended timing of future entrepreneurial projects. This paper analyses entrepreneurial intentions among final-year university students after graduation in terms of the timeframe to start a business. Potentially rapid entrepreneurs and entrepreneurs-in-waiting were compared using the Theory of Planned Behaviour (TPB). Methodology: A variance-based structural equation modelling approach was used for the sample of 851 final-year university students with entrepreneurial intentions who participated in GUESSS project. Findings: The results obtained contribute to the understanding of how entrepreneurial intentions are formed, particularly, how intended timing plays a moderating role in the relationships of the variables of the theoretical model of TPB. This study provides empirical evidence that significant differences exist between potential rapid entrepreneurs and entrepreneurs-in-waiting. Practical implications: The findings of this study have practical implications for entrepreneurship education, and they can help policy makers develop more effective policies and programs to promote entrepreneurship. Originality: Intention-based models have traditionally examined the intent -- but not the timing -- of new venture creation. However, the time elapsed between the formation of the entrepreneurial intent and the identification of a business opportunity can vary considerably. Therefore, analysing the moderating role of intended timing could be relevant to entrepreneurial intention research.",
        "comments": "Journal ref:        International Entrepreneurship and Management Journal, 15:1221-1246 (2019)",
        "date": "15 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13682"
    },
    {
        "doc_id": 21,
        "title": "Moderating effects of gender and family responsibilities on the relations between work-family policies and job performance",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Antonio Rafael Ramos-Rodriguez"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This study analyzes the impact of work-family policies (WFP) on job performance, and the possible moderating role of gender and family responsibilities. Hypothesis testing was performed using a structural equation model based on a PLS-SEM approach applied to a sample of 1,511 employees of the Spanish banking sector. The results show that neither the existence nor the accessibility of the WFP has a direct, positive impact on performance, unlike what we expected, but both have an indirect effect via the well-being generated by these policies. We also find that neither gender nor family responsibilities have a significant moderating role on these relations, contrary to what we initially expected.",
        "comments": "Journal ref:        International Journal of Human Resource Management, 32 (2021)",
        "date": "12 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13681"
    },
    {
        "doc_id": 22,
        "title": "Determinants of the Propensity for Innovation among Entrepreneurs in the Tourism Industry",
        "authors": [
            "Miguel Angel Montanes-Del-Rio",
            "Jose Aurelio Medina-Garrido"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Tourism's increasing share of Gross Domestic Product throughout the world, its impact on employment and its continuous growth justifies the interest it raises amongst entrepreneurs and public authorities. However, this growth coexists with intense competition; as a result of which, tourism companies must continuously innovate in order to survive and grow. This is evident in the diversification of tourism products and destinations, the improvement of business processes and the incorporation of new technologies for intermediation, amongst other examples. This paper expounds on the factors that explain the propensity for innovation amongst tourism entrepreneurs and it may help governments to promote innovation that is based on those determining factors. The hypotheses are tested using a logistic regression on 699 international tourism entrepreneurs, taken from the 2014 Global Adult Population Survey of the Global Entrepreneurship Monitor project. The propensity for innovation amongst tourism entrepreneurs has a statistically significant relationship to gender, age, level of education and informal investments in previous businesses.",
        "comments": "Journal ref:        Sustainability 12:5003 (2020)",
        "date": "5 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13679"
    },
    {
        "doc_id": 23,
        "title": "I Can't Go to Work Tomorrow! Work-Family Policies, Well-Being and Absenteeism",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Jaime Sanchez-Ortiz"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Among the main causes of absenteeism are health problems, emotional problems, and inadequate work-family policies (WFP). This paper analyses the impact of the existence and accessibility of WFP on work absenteeism, by considering the mediating role of the well-being, which includes emotional as well as physical or health problems, that is generated by these policies. We differentiate between the existence of the WFP and its accessibility, as the mere existence of the WFP in an organisation is not enough. Additionally, workers must be able to access these policies easily and without retaliation of any kind. The model includes the hierarchy and the gender as moderating variables. To test the proposed hypotheses, a structural equation model based on the partial least squares structural equation modelling (PLS-SEM) approach is applied to a sample of employees in the service sector in Spain. On the one hand, the findings show that the existence of WFP has no direct effect on absenteeism; however, accessibility to these policies does have a direct effect on absenteeism. On the other hand, both the existence and accessibility of WFP have positive direct effects on emotional well-being. In addition, emotional well-being is positively related to physical well-being which, in turn, promotes a reduction in absenteeism. Finally, significant differences in the relationship between the existence of WFP and emotional well-being confirm the special difficulty of female managers in reconciling family life and work life.",
        "comments": "Journal ref:        Sustainability 12:5519 (2020)",
        "date": "5 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13678"
    },
    {
        "doc_id": 24,
        "title": "The impact of Hong Kong's anti-ELAB movement on political related firms",
        "authors": [
            "Ziqi Wang"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "Hong Kong's anti-ELAB movement had a significant impact on the stock market the stock price of listed companies. Using the number of protestors as the measurement of daily protesting intensity from 2019/6/6 to 2020/1/17, this paper documents that the stock price of listed companies associated with the pan-democratic parties were more negatively affected by protesting than other companies. Furthermore, this paper finds that after the implementation of the anti-mask law, protesting had a positive impact on red chips but a negative impact on companies related to pan-democracy parties. Therefore, this paper believes that after the central government and the HKSAR government adopted strict measures to stop violence and chaos, the value of the political connection of red chips became positive while the value of the connection with pan-democracy parties became negative.",
        "comments": "34 pages, 13 tables",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13676"
    },
    {
        "doc_id": 25,
        "title": "Social costs of curcular economy in European Union",
        "authors": [
            "Shteryo Nozharov"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Two fundamental issues are incorporated in the present monograph: the issue related to the quantification of the social costs and the issue, related to the defining of the circular economy concept as a theoretical model. The analysis is based on the methodology of the new institutional economics, which fact distinguishes it from the many other circular economy analysis based on the neo-classical methodological apparatus.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13675"
    },
    {
        "doc_id": 26,
        "title": "Analisis de la incidencia de la inversion extranjera directa y la inversion nacional, en el crecimiento economico de Chile",
        "authors": [
            "Alvear Guzman Katherine",
            "Campozano Buele Jenner",
            "Duran Canarte Paulette",
            "Holguin Cedeno Roger",
            "Mejia Crespin Fernando"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The research aims to assess the impact of foreign direct investment (FDI) and domestic investment on Chile's economic growth. By elucidating the relationship between FDI and domestic investment, the study contributes valuable insights for economic policy formulation and future investments. The findings hold significance in shaping Chile's international perception as an investment destination, potentially influencing its standing in the global economic landscape. Demonstrating that FDI is a significant driver of economic growth could enhance confidence among foreign investors. The project's importance lies in contributing to economic knowledge and guiding strategic decisions for sustainable economic growth in Chile. Understanding the interplay of FDI and domestic investment allows for a balanced approach, promoting stable economic development and mitigating issues like excessive reliance on foreign investment. The study highlights the theory of internationalization as a conceptual framework for understanding the motives and strategies of multinational companies investing abroad. Leveraging data from sources like the Central Bank of Chile, the research analyzes variables such as Chile's economic growth (GDP), FDI, and domestic investment. The hypothesis posits a significant long-term causal relationship between FDI, National Investment (NI), and Chile's Economic Growth (GDP). Statistical analysis using the Eviews 6 software tool confirms that attracting foreign investments and promoting internal investment are imperative for sustainable economic growth in Chile.",
        "comments": "in Spanish language",
        "date": "13 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13674"
    },
    {
        "doc_id": 27,
        "title": "Sacred Ecology: The Environmental Impact of African Traditional Religions",
        "authors": [
            "Neha Deopa",
            "Daniele Rinaldo"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Do religions codify ecological principles? This paper explores theoretically and empirically the role religious beliefs play in shaping environmental interactions. We study African Traditional Religions (ATR) which place forests within a sacred sphere. We build a model of non-market interactions of the mean-field type where the actions of agents with heterogeneous religious beliefs continuously affect the spatial density of forest cover. The equilibrium extraction policy shows how individual beliefs and their distribution among the population can be a key driver of forest conservation. The model also characterizes the role of resource scarcity in both individual and population extraction decisions. We test the model predictions empirically relying on the unique case of Benin, where ATR adherence is freely reported. Using an instrumental variable strategy that exploits the variation in proximity to the Benin-Nigerian border, we find that a 1 standard deviation increase in ATR adherence has a 0.4 standard deviation positive impact on forest cover change. We study the impact of historically belonging to the ancient Kingdom of Dahomey, birthplace of the Vodun religion. Using the original boundaries as a spatial discontinuity, we find positive evidence of Dahomey affiliation on contemporary forest change. Lastly, we compare observed forest cover to counterfactual outcomes by simulating the absence of ATR beliefs across the population.",
        "comments": " ",
        "date": "9 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13673"
    },
    {
        "doc_id": 28,
        "title": "Determinants of renewable energy consumption in Madagascar: Evidence from feature selection algorithms",
        "authors": [
            "Franck Ramaharo",
            "Fitiavana Randriamifidy"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "The aim of this note is to identify the factors influencing renewable energy consumption in Madagascar. We tested 12 features covering macroeconomic, financial, social, and environmental aspects, including economic growth, domestic investment, foreign direct investment, financial development, industrial development, inflation, income distribution, trade openness, exchange rate, tourism development, environmental quality, and urbanization. To assess their significance, we assumed a linear relationship between renewable energy consumption and these features over the 1990-2021 period. Next, we applied different machine learning feature selection algorithms classified as filter-based (relative importance for linear regression, correlation method), embedded (LASSO), and wrapper-based (best subset regression, stepwise regression, recursive feature elimination, iterative predictor weighting partial least squares, Boruta, simulated annealing, and genetic algorithms) methods. Our analysis revealed that the five most influential drivers stem from macroeconomic aspects. We found that domestic investment, foreign direct investment, and inflation positively contribute to the adoption of renewable energy sources. On the other hand, industrial development and trade openness negatively affect renewable energy consumption in Madagascar.",
        "comments": "21 pages, 4 tables, 1 figure",
        "date": "27 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13671"
    },
    {
        "doc_id": 29,
        "title": "\"The Roller Conduction Effect\" from the A-share Data Evidence",
        "authors": [
            "Wenbo Lyu"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "In the post-epidemic era, consumption recovery has obvious time and space transmission laws, and there are different valuation criteria for consumption segments. Using the A-share data of the consumption recovery stage from January to April 2022, this paper quantitatively compares the rotation effect between different consumption sectors when the valuation returns to the reasonable range. According to the new classification of \"sensory-based consumption\", it interprets the internal logic of digital consumption as A consumption upgrade tool and a higher valuation target, and expounds the \"the roller conduction effect\". The law of consumption recovery and valuation return period is explained from the perspective of time and space conduction. The study found that in the early stage of consumption recovery, the recovery of consumer confidence was slow. In this period, A-shares were mainly dominated by the stock capital game, and there was an obvious plate rotation law in the game. Being familiar with this law has strong significance, which not only helps policy makers to adjust the direction of policy guidance, but also helps financial investors to make better investment strategies. The disadvantage of this paper is that it has not yet studied the roller conduction effect of the global financial market, and more rigorous mathematical models are still needed to support the definition of stock funds, which is also the main direction of the author's future research.",
        "comments": "11 pages",
        "date": "15 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13670"
    },
    {
        "doc_id": 30,
        "title": "Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach",
        "authors": [
            "Yuling Yan",
            "Martin J. Wainwright"
        ],
        "subjects": [
            "Statistics Theory",
            "Econometrics",
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\u00e9r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13665"
    },
    {
        "doc_id": 31,
        "title": "Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity",
        "authors": [
            "Ernesto Colacrai",
            "Federico Cinus",
            "Gianmarco De Francisci Morales",
            "Michele Starnini"
        ],
        "subjects": [
            "Social and Information Networks",
            "Computers and Society",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy. While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies. In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass. We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022. By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes. In addition, we characterize users by their demographic attributes (age, gender, and affluence).\n  We find significant homophily for interactions along the social axis of the political compass and demographic attributes. Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%. In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%. Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology. Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions. By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13656"
    },
    {
        "doc_id": 32,
        "title": "Dynamic Risk Management in Cyber Physical Systems",
        "authors": [
            "Daniel Schneider",
            "Jan Reich",
            "Rasmus Adler",
            "Peter Liggesmeyer"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Cyber Physical Systems (CPS) enable new kinds of applications as well as significant improvements of existing ones in numerous different application domains. A major trait of upcoming CPS is an increasing degree of automation up to the point of autonomy, as there is a huge potential for economic success as well as for ecologic and societal improvements. However, to unlock the full potential of such (cooperative and automated) CPS, we first need to overcome several significant engineering challenges, where safety assurance is a particularly important one. Unfortunately, established safety assurance methods and standards do not live up to this task, as they have been designed with closed and less complex systems in mind. This paper structures safety assurance challenges of cooperative automated CPS, provides an overview on our vision of dynamic risk management and describes already existing building blocks.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13539"
    },
    {
        "doc_id": 33,
        "title": "Symbolic Equation Solving via Reinforcement Learning",
        "authors": [
            "Lennart Dabelow",
            "Masahito Ueda"
        ],
        "subjects": [
            "Machine Learning",
            "Symbolic Computation"
        ],
        "abstract": "Machine-learning methods are gradually being adopted in a great variety of social, economic, and scientific contexts, yet they are notorious for struggling with exact mathematics. A typical example is computer algebra, which includes tasks like simplifying mathematical terms, calculating formal derivatives, or finding exact solutions of algebraic equations. Traditional software packages for these purposes are commonly based on a huge database of rules for how a specific operation (e.g., differentiation) transforms a certain term (e.g., sine function) into another one (e.g., cosine function). Thus far, these rules have usually needed to be discovered and subsequently programmed by humans. Focusing on the paradigmatic example of solving linear equations in symbolic form, we demonstrate how the process of finding elementary transformation rules and step-by-step solutions can be automated using reinforcement learning with deep neural networks.",
        "comments": "12 pages, 4 figures + appendices 17 pages, 1 figure, 16 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13447"
    },
    {
        "doc_id": 34,
        "title": "New accessibility measures based on unconventional big data sources",
        "authors": [
            "G. Arbia",
            "V. Nardelli",
            "N. Salvini",
            "I. Valentini"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "In health econometric studies we are often interested in quantifying aspects related to the accessibility to medical infrastructures. The increasing availability of data automatically collected through unconventional sources (such as webscraping, crowdsourcing or internet of things) recently opened previously unconceivable opportunities to researchers interested in measuring accessibility and to use it as a tool for real-time monitoring, surveillance and health policies definition. This paper contributes to this strand of literature proposing new accessibility measures that can be continuously feeded by automatic data collection. We present new measures of accessibility and we illustrate their use to study the territorial impact of supply-side shocks of health facilities. We also illustrate the potential of our proposal with a case study based on a huge set of data (related to the Emergency Departments in Milan, Italy) that have been webscraped for the purpose of this paper every 5 minutes since November 2021 to March 2022, amounting to approximately 5 million observations.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13370"
    },
    {
        "doc_id": 35,
        "title": "Organizing Scientific Knowledge From Energy System Research Using the Open Research Knowledge Graph",
        "authors": [
            "Oliver Karras",
            "Jan G\u00f6pfert",
            "Patrick Kuckertz",
            "Tristan Pelser",
            "S\u00f6ren Auer"
        ],
        "subjects": [
            "Digital Libraries"
        ],
        "abstract": "Engineering sciences, such as energy system research, play an important role in developing solutions to technical, environmental, economic, and social challenges of our modern society. In this context, the transformation of energy systems into climate-neutral systems is one of the key strategies for mitigating climate change. For the transformation of energy systems, engineers model, simulate and analyze scenarios and transformation pathways to initiate debates about possible transformation strategies. For these debates and research in general, all steps of the research process must be traceable to guarantee the trustworthiness of published results, avoid redundancies, and ensure their social acceptance. However, the analysis of energy systems is an interdisciplinary field as the investigations of large, complex energy systems often require the use of different software applications and large amounts of heterogeneous data. Engineers must therefore communicate, understand, and (re)use heterogeneous scientific knowledge and data. Although the importance of FAIR scientific knowledge and data in the engineering sciences and energy system research is increasing, little research has been conducted on this topic. When it comes to publishing scientific knowledge and data from publications, software, and datasets (such as models, scenarios, and simulations) openly available and transparent, energy system research lags behind other research domains. According to Schmitt et al. and Nie\u00dfe et al., engineers need technical support in the form of infrastructures, services, and terminologies to improve communication, understanding, and (re)use of scientific knowledge and data.",
        "comments": "1. NFDI4Energy Conference",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13365"
    },
    {
        "doc_id": 36,
        "title": "Realized Stochastic Volatility Model with Skew-t Distributions for Improved Volatility and Quantile Forecasting",
        "authors": [
            "Makoto Takahashi",
            "Yuta Yamauchi",
            "Toshiaki Watanabe",
            "Yasuhiro Omori"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Forecasting volatility and quantiles of financial returns is essential for accurately measuring financial tail risks, such as value-at-risk and expected shortfall. The critical elements in these forecasts involve understanding the distribution of financial returns and accurately estimating volatility. This paper introduces an advancement to the traditional stochastic volatility model, termed the realized stochastic volatility model, which integrates realized volatility as a precise estimator of volatility. To capture the well-known characteristics of return distribution, namely skewness and heavy tails, we incorporate three types of skew-t distributions. Among these, two distributions include the skew-normal feature, offering enhanced flexibility in modeling the return distribution. We employ a Bayesian estimation approach using the Markov chain Monte Carlo method and apply it to major stock indices. Our empirical analysis, utilizing data from US and Japanese stock indices, indicates that the inclusion of both skewness and heavy tails in daily returns significantly improves the accuracy of volatility and quantile forecasts.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13179"
    },
    {
        "doc_id": 37,
        "title": "Boundary Technology Costs for Economic Viability of Long-Duration Energy Storage Systems",
        "authors": [
            "Patricia Silva",
            "Alexandre Moreira",
            "Miguel Heleno",
            "Andre Luis Marcato"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "The urgent need for decarbonization in the energy sector has led to an increased emphasis on the integration of renewable energy sources, such as wind and solar, into power grids. While these resources offer significant environmental benefits, they also introduce challenges related to intermittency and variability. Long-duration energy storage (LDES) technologies have emerged as a very promising solution to address these challenges by storing excess energy during periods of high generation and delivering it when demand is high or renewable resources are scarce for a sustained amount of time. This paper introduces a novel methodology for estimating the boundary technology cost of LDES systems for economic viability in decarbonized energy systems. Our methodology is applied to estimate the boundary costs in 2050 for the state of California to achieve full retirement of gas power plants. California's ambitious decarbonization goals and transition to a renewable energy-based power system present an ideal context for examining the role of LDES. The results also offer insights into the needed capacity expansion planning and the operational contribution of LDES in the California's energy landscape, taking into account the unique energy demand profiles and renewable resource availability of the region. Our findings are intended to provide complementary information to guide decision-makers, energy planners, and any other stakeholders in making informed choices about LDES investment in the context of a decarbonized energy future.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13163"
    },
    {
        "doc_id": 38,
        "title": "Environmental impacts, nutritional profiles, and retail prices of commonly sold retail food items in 181 countries: an observational study",
        "authors": [
            "Elena M. Martinez",
            "Nicole Tichenor Blackstone",
            "Parke E. Wilde",
            "Anna W. Herforth",
            "William A. Masters"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Affordability is often seen as a barrier to consuming sustainable diets. This study provides the first worldwide test of how retail food prices relate to empirically estimated environmental impacts and nutritional profile scores between and within food groups. We use prices for 811 retail food items commonly sold in 181 countries during 2011 and 2017, matched to estimated carbon and water footprints and nutritional profiles, to test whether healthier and more environmentally sustainable foods are more expensive between and within food groups. We find that within almost all groups, less expensive items have significantly lower carbon and water footprints. Associations are strongest for animal source foods, where each 10% lower price is associated with 20 grams lower CO2-equivalent carbon and 5 liters lower water footprint per 100kcal. Gradients between price and nutritional profile vary by food group, price range, and nutritional attribute. In contrast, lower-priced items have lower nutritional value in only some groups over some price ranges, and that relationship is sometimes reversed. These findings reveal opportunities to reduce financial and environmental costs of diets, contributing to transitions towards healthier, more environmentally sustainable food systems.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13159"
    },
    {
        "doc_id": 39,
        "title": "Three Variations on Money Pump, Common Prior, and Trade",
        "authors": [
            "Ziv Hellman",
            "Miklos Pinter"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We consider finite information structures, and quest for the answer of the question: What is the proper definition of prior?\n  In the single player setting we conclude that a probability distribution is a prior if it is disintegrable, because this definition excludes money pump.\n  In the multiplayer setting our analysis does not boil down to one proper notion of common prior (the multiplayer version of prior). The appropriate notion is a choice of the modeller in this setting. We consider three variants of money pump, each \"defines\" a notion of common prior.\n  Furthermore, we also consider three variants of trade, each correspond to one of the money pump variants, hence to one of the common prior variants.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13132"
    },
    {
        "doc_id": 40,
        "title": "Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge",
        "authors": [
            "Ruixin Song",
            "Gabriel Spadon",
            "Sarah Bailey",
            "Ronald Pelot",
            "Stan Matwin",
            "Amilcar Soares"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Social and Information Networks",
            "Applications"
        ],
        "abstract": "Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive species risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape.",
        "comments": "26 pages, 7 figures, under review",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13098"
    },
    {
        "doc_id": 41,
        "title": "Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems",
        "authors": [
            "Michelle R. Greene",
            "Mariam Josyula",
            "Wentao Si",
            "Jennifer A. Hart"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States. This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets. By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems. There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.",
        "comments": "20 pages, 3 figures, 3 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13097"
    },
    {
        "doc_id": 42,
        "title": "Importance of the spectral emissivity measurements at working temperature to determine the efficiency of a solar selective coating",
        "authors": [
            "Telmo Ech\u00e1niz",
            "I\u00f1igo Seti\u00e9n-Fern\u00e1ndez",
            "Ra\u00fal Benjam\u00edn P\u00e9rez-S\u00e1ez",
            "Carlos Prieto",
            "Ram\u00f3n Escobar Galindo",
            "Manuel Jos\u00e9 Tello"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "The total emissivity of the absorbing surfaces is a critical parameter in the calculation of the radiative thermal losses in solar thermal collectors. This is because the radiative heat losses have a significant economic impact on the final cost of the electricity produced in a solar thermal plant. This paper demonstrates the need to calculate the total emissivity from spectral emissivity measurements at the working temperature of the solar thermal collector, instead of using extrapolated values from spectral emissivities measured at room temperature. Usual uncertainties produced by the estimation of the total emissivity, in which its temperature dependence is only introduced by the Planck function, are analyzed.",
        "comments": "4 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13095"
    },
    {
        "doc_id": 43,
        "title": "Towards Trustable Language Models: Investigating Information Quality of Large Language Models",
        "authors": [
            "Rick Rejeleene",
            "Xiaowei Xu",
            "John Talburt"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.",
        "comments": "31 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13086"
    },
    {
        "doc_id": 44,
        "title": "Inference under partial identification with minimax test statistics",
        "authors": [
            "Isaac Loh"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "We provide a means of computing and estimating the asymptotic distributions of test statistics based on an outer minimization of an inner maximization. Such test statistics, which arise frequently in moment models, are of special interest in providing hypothesis tests under partial identification. Under general conditions, we provide an asymptotic characterization of such test statistics using the minimax theorem, and a means of computing critical values using the bootstrap. Making some light regularity assumptions, our results provide a basis for several asymptotic approximations that have been provided for partially identified hypothesis tests, and extend them by mitigating their dependence on local linear approximations of the parameter space. These asymptotic results are generally simple to state and straightforward to compute (e.g. adversarially).",
        "comments": "MSC Class:          Primary 62G10; Secondary 62G20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13057"
    },
    {
        "doc_id": 45,
        "title": "Distributed Empirical Likelihood Inference With or Without Byzantine Failures",
        "authors": [
            "Qihua Wang",
            "Jinye Du",
            "Ying Sheng"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Empirical likelihood is a very important nonparametric approach which is of wide application. However, it is hard and even infeasible to calculate the empirical log-likelihood ratio statistic with massive data. The main challenge is the calculation of the Lagrange multiplier. This motivates us to develop a distributed empirical likelihood method by calculating the Lagrange multiplier in a multi-round distributed manner. It is shown that the distributed empirical log-likelihood ratio statistic is asymptotically standard chi-squared under some mild conditions. The proposed algorithm is communication-efficient and achieves the desired accuracy in a few rounds. Further, the distributed empirical likelihood method is extended to the case of Byzantine failures. A machine selection algorithm is developed to identify the worker machines without Byzantine failures such that the distributed empirical likelihood method can be applied. The proposed methods are evaluated by numerical simulations and illustrated with an analysis of airline on-time performance study and a surface climate analysis of Yangtze River Economic Belt.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12827"
    },
    {
        "doc_id": 46,
        "title": "Generative AI Triggers Welfare-Reducing Decisions in Humans",
        "authors": [
            "Fabian Dvorak",
            "Regina Stumpf",
            "Sebastian Fehrler",
            "Urs Fischbacher"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Generative artificial intelligence (AI) is poised to reshape the way individuals communicate and interact. While this form of AI has the potential to efficiently make numerous human decisions, there is limited understanding of how individuals respond to its use in social interaction. In particular, it remains unclear how individuals engage with algorithms when the interaction entails consequences for other people. Here, we report the results of a large-scale pre-registered online experiment (N = 3,552) indicating diminished fairness, trust, trustworthiness, cooperation, and coordination by human players in economic twoplayer games, when the decision of the interaction partner is taken over by ChatGPT. On the contrary, we observe no adverse welfare effects when individuals are uncertain about whether they are interacting with a human or generative AI. Therefore, the promotion of AI transparency, often suggested as a solution to mitigate the negative impacts of generative AI on society, shows a detrimental effect on welfare in our study. Concurrently, participants frequently delegate decisions to ChatGPT, particularly when the AI's involvement is undisclosed, and individuals struggle to discern between AI and human decisions.",
        "comments": "19 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12773"
    },
    {
        "doc_id": 47,
        "title": "Improving single-molecule conductance measurements with change point detection from the econometrics toolbox",
        "authors": [
            "Joseph M. Hamill",
            "William Bro-J\u00f8rgensen",
            "Zolt\u00e1n Balogh",
            "Haixing Li",
            "Susanne Leitherer",
            "David Solomon",
            "Andr\u00e1s Halbritter",
            "Gemma Solomon"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Soft Condensed Matter"
        ],
        "abstract": "Structural breaks occur in timeseries data across a broad range of fields, from economics to nanosciences. For measurements of single-molecule break junctions, structural breaks in conductance versus displacement data occur when the molecular junction ruptures. This moment is significant because the molecule is likely in its most extended geometry, and therefore resembles most closely the geometry used in theoretical predictions. Conventional single-molecule break junction data analysis, on the other hand, typically uses the entire molecular plateau to estimate the single-molecule conductance, which skews the estimate when the plateau is sloped. Borrowing from econometrics, where the study of structural breaks is well established, we present change point detection (CPD) as a tool to search for junction rupture in single-molecule break junction data, and improve estimates in single-molecule conductance. We demonstrate that using CPD instead of the conventional 1D conductance histogram to determine the mean molecular conductance yields a standard deviation in the estimate of typically half that of the conventional approach, greatly improving accuracy. We apply CPD to three separate data sets, two on 4,4'-bipyridine and one on a silane, two at room temperature and one at 4 K, two in one lab, one in another, to show the wide applicability of even the simplest of CPD algorithms: the Chow test. This versatility and better accuracy will propagate into more accurate theoretical simulations. These improved metrics, in turn, will further improve any downstream analyses, including all emerging machine learning approaches.",
        "comments": "33 pages and 11 figures and supporting material of 8 pages and 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12769"
    },
    {
        "doc_id": 48,
        "title": "Optimal design of a local renewable electricity supply system for power-intensive production processes with demand response",
        "authors": [
            "Sonja H. M. Germscheid",
            "Benedikt Nilges",
            "Niklas von der Assen",
            "Alexander Mitsos",
            "Manuel Dahmen"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This work studies synergies arising from combining industrial demand response and local renewable electricity supply. To this end, we optimize the design of a local electricity generation and storage system with an integrated demand response scheduling of a continuous power-intensive production process in a multi-stage problem. We optimize both total annualized cost and global warming impact and consider local photovoltaic and wind electricity generation, an electric battery, and electricity trading on day-ahead and intraday market. We find that installing a battery can reduce emissions and enable large trading volumes on the electricity markets, but significantly increases cost. Economic and ecologic process and battery operation are driven primarily by the electricity price and grid emission factor, respectively, rather than locally generated electricity. A parameter study reveals that economic savings from the local system and flexibilizing the process behave almost additive.",
        "comments": "manuscript (32 pages, 9 figures, 6 tables), supporting materials (11 pages, 9 figures, 2 tables)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12759"
    },
    {
        "doc_id": 49,
        "title": "Multicausal transport: barycenters and dynamic matching",
        "authors": [
            "Beatrice Acciaio",
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "We introduce a multivariate version of adapted transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agents' types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.",
        "comments": "26 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12748"
    },
    {
        "doc_id": 50,
        "title": "Arrow's single peaked domains, richness, and domains for plurality and the Borda count",
        "authors": [
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper we extend the study of Arrow's generalisation of Black's single-peaked domain and connect this to domains where voting rules satisfy different versions of independence of irrelevant alternatives.\n  First we report on a computational generation of all non-isomorphic Arrow's single-peaked domains on $n\\leq 9$ alternatives. Next, we introduce a quantitative measure of richness for domains, as the largest number $r$ such that every alternative is given every rank between 1 and $r$ by the orders in the domain. We investigate the richness of Arrow's single-peaked domains and prove that Black's single-peaked domain has the highest possible richness, but it is not the only domain which attains the maximum.\n  After this we connect Arrow's single-peaked domains to the discussion by Dasgupta, Maskin and others of domains on which plurality and the Borda count satisfy different versions of Independence of Irrelevant alternatives (IIA). For Nash's version of IIA and plurality, it turns out the domains are exactly the duals of Arrow's single-peaked domains. As a consequence there can be at most two alternatives which are ranked first in any such domain.\n  For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum domain size which is exponentially smaller than $2^{n-1}$, the size of Black's single-peaked domain.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12547"
    },
    {
        "doc_id": 51,
        "title": "Moen Meets Rotemberg: An Earthly Model of the Divine Coincidence",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "This paper proposes a model of the divine coincidence, explaining its recent appearance in US data. The divine coincidence matters because it helps explain the behavior of inflation after the pandemic, and it guarantees that the full-employment and price-stability mandates of the Federal Reserve coincide. In the model, a Phillips curve relating unemployment to inflation arises from Moen's (1997) directed search. The Phillips curve is nonvertical thanks to Rotemberg's (1982) price-adjustment costs. The model's Phillips curve guarantees that the rate of inflation is on target whenever the rate of unemployment is efficient, generating the divine coincidence. If we assume that wage decreases -- which reduce workers' morale -- are more costly to producers than price increases -- which upset customers -- the Phillips curve also displays a kink at the point of divine coincidence.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12475"
    },
    {
        "doc_id": 52,
        "title": "Convex-Concave Zero-sum Markov Stackelberg Games",
        "authors": [
            "Denizalp Goktas",
            "Arjun Prakash",
            "Amy Greenwald"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "Zero-sum Markov Stackelberg games can be used to model myriad problems, in domains ranging from economics to human robot interaction. In this paper, we develop policy gradient methods that solve these games in continuous state and action settings using noisy gradient estimates computed from observed trajectories of play. When the games are convex-concave, we prove that our algorithms converge to Stackelberg equilibrium in polynomial time. We also show that reach-avoid problems are naturally modeled as convex-concave zero-sum Markov Stackelberg games, and that Stackelberg equilibrium policies are more effective than their Nash counterparts in these problems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12437"
    },
    {
        "doc_id": 53,
        "title": "A Unified Approach to Second and Third Degree Price Discrimination",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Michael C. Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory"
        ],
        "abstract": "We analyze the welfare impact of a monopolist able to segment a multiproduct market and offer differentiated price menus within each segment. We characterize a family of extremal distributions such that all achievable welfare outcomes can be reached by selecting segments from within these distributions. This family of distributions arises as the solution to the consumer maximizing distribution of values for multigood markets. With these results, we analyze the effect of segmentation on consumer surplus and prices in both interior and extremal markets, including conditions under which there exists a segmentation benefiting all consumers. Finally, we present an efficient algorithm for computing segmentations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12366"
    },
    {
        "doc_id": 54,
        "title": "Business Model Contributions to Bank Profit Performance: A Machine Learning Approach",
        "authors": [
            "F. Bolivar",
            "Miguel A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the relation between bank profit performance and business models. Using a machine learning-based approach, we propose a methodological strategy in which balance sheet components' contributions to profitability are the identification instruments of business models. We apply this strategy to the European Union banking system from 1997 to 2021. Our main findings indicate that the standard retail-oriented business model is the profile that performs best in terms of profitability, whereas adopting a non-specialized business profile is a strategic decision that leads to poor profitability. Additionally, our findings suggest that the effect of high capital ratios on profitability depends on the business profile. The contributions of business models to profitability decreased during the Great Recession. Although the situation showed signs of improvement afterward, the European Union banking system's ability to yield returns is still problematic in the post-crisis period, even for the best-performing group.",
        "comments": "46 pages, 10 tables, 3 figures, submitted version of a paper published in Research in International Business and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12334"
    },
    {
        "doc_id": 55,
        "title": "Bank Business Models, Size, and Profitability",
        "authors": [
            "F. Bolivar",
            "M. A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "To examine the relation between profitability and business models (BMs) across bank sizes, the paper proposes a research strategy based on machine learning techniques. This strategy allows for analyzing whether size and profit performance underlie BM heterogeneity, with BM identification being based on how the components of the bank portfolio contribute to profitability. The empirical exercise focuses on the European Union banking system. Our results suggest that banks with analogous levels of performance and different sizes share strategic features. Additionally, high capital ratios seem compatible with high profitability if banks, relative to their size peers, adopt a standard retail BM.",
        "comments": "14 pages, 1 figure, 3 tables, accepted version of an article published in Finance Research Letters",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12323"
    },
    {
        "doc_id": 56,
        "title": "The outcomes of generative AI are exactly the Nash equilibria of a non-potential game",
        "authors": [
            "Boualem Djehiche",
            "Hamidou Tembine"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "In this article we show that the asymptotic outcomes of both shallow and deep neural networks such as those used in BloombergGPT to generate economic time series are exactly the Nash equilibria of a non-potential game. We then design and analyze deep neural network algorithms that converge to these equilibria. The methodology is extended to federated deep neural networks between clusters of regional servers and on-device clients. Finally, the variational inequalities behind large language models including encoder-decoder related transformers are established.",
        "comments": "24 pages. Accepted and to appear in: International Econometric Conference of Vietnam",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12321"
    },
    {
        "doc_id": 57,
        "title": "The Risk-Return Relation in the Corporate Loan Market",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the hypothesis that returns play a risk-compensating role in the market for corporate revolving lines of credit. Specifically, we test whether borrower risk and the expected return on these debt instruments are positively related. Our main findings support this prediction, in contrast to the only previous work that examined this problem two decades ago. Nevertheless, we find evidence of mispricing regarding the risk of deteriorating firms using their facilities more intensively and during the subprime crisis.",
        "comments": "56 pages, 3 figurees, 7 tables, accepted version of a paper published in the North American Journal of Economics and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12315"
    },
    {
        "doc_id": 58,
        "title": "Interpreting Event-Studies from Recent Difference-in-Differences Methods",
        "authors": [
            "Jonathan Roth"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This note discusses the interpretation of event-study plots produced by recent difference-in-differences methods. I show that even when specialized to the case of non-staggered treatment timing, the default plots produced by software for three of the most popular recent methods (de Chaisemartin and D'Haultfoeuille, 2020; Callaway and SantAnna, 2021; Borusyak, Jaravel and Spiess, 2024) do not match those of traditional two-way fixed effects (TWFE) event-studies: the new methods may show a kink or jump at the time of treatment even when the TWFE event-study shows a straight line. This difference stems from the fact that the new methods construct the pre-treatment coefficients asymmetrically from the post-treatment coefficients. As a result, visual heuristics for analyzing TWFE event-study plots should not be immediately applied to those from these methods. I conclude with practical recommendations for constructing and interpreting event-study plots when using these methods.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12309"
    },
    {
        "doc_id": 59,
        "title": "Pricing and Usage: An Empirical Analysis of Lines of Credit",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The hypothesis that committed revolving credit lines with fixed spreads can provide firms with interest rate insurance is a standard feature of models on these credit facilities' interest rate structure. Nevertheless, this hypothesis has not been tested. Its empirical examination is the main contribution of this paper. To perform this analysis, and given the unavailability of data, we hand-collect data on usage at the credit line level itself. The resulting dataset enables us also to take into account characteristics of credit lines that have been ignored by previous research. One of them is that credit lines can have simultaneously fixed and performance-based spreads.",
        "comments": "32 pages, 7 tables, accepted version of a paper published in the Journal of International Financial Markets, Institutions and Money",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12301"
    },
    {
        "doc_id": 60,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 61,
        "title": "The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review",
        "authors": [
            "Chandregowda Pachegowda"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ],
        "abstract": "Artificial intelligence (AI) is an emerging technology that has the potential to transform many aspects of society, including the economy, healthcare, and transportation. This article synthesizes recent research literature on the global impact of AI, exploring its potential benefits and risks. The article highlights the implications of AI, including its impact on economic, ethical, social, security & privacy, and job displacement aspects. It discusses the ethical concerns surrounding AI development, including issues of bias, security, and privacy violations. To ensure the responsible development and deployment of AI, collaboration between government, industry, and academia is essential. The article concludes by emphasizing the importance of public engagement and education to promote awareness and understanding of AI's impact on society at large.",
        "comments": "4 pages",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.12223"
    },
    {
        "doc_id": 62,
        "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
        "authors": [
            "Tahereh Zarrat Ehsan",
            "Seyed Mehdi Mohtavipour"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal chicken health conditions, minimizing economic losses and bolstering profitability. This paper presents a novel real-time framework for analyzing chicken behavior in cage-free poultry houses to detect abnormal behaviors. Specifically, two significant abnormalities, namely inactive broiler and huddling behavior, are investigated in this study. The proposed framework comprises three key steps: (1) chicken detection utilizing a state-of-the-art deep learning model, (2) tracking individual chickens across consecutive frames with a fast tracker module, and (3) detecting abnormal behaviors within the video stream. Experimental studies are conducted to evaluate the efficacy of the proposed algorithm in accurately assessing chicken behavior. The results illustrate that our framework provides a precise and efficient solution for real-time anomaly detection, facilitating timely interventions to maintain chicken health and enhance overall productivity on poultry farms. Github: https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
        "comments": "11 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12176"
    },
    {
        "doc_id": 63,
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Theoretical Economics"
        ],
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about centralization in block-building (due to, e.g., MEV and private order flow) and the outsourcing of block-building by validators to specialists (i.e., proposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers inevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve decentralization among proposers?\n  This paper develops mathematical models and results that offer answers to these questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block producer rewards, and staking costs, we quantify the extent to which heterogeneous rewards lead to concentration in the equilibrium staking distribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly reinvest rewards into staking, we quantify, as a function of the block producer heterogeneity, the rate at which stake concentrates on the most sophisticated block producers.\n  3. In a model with heterogeneous proposers and specialized builders, we quantify, as a function of the competitiveness of the builder ecosystem, the extent to which proposer-builder separation reduces the heterogeneity in rewards across different proposers.\n  Our models and results take advantage of connections to contest design, P\u00f3lya urn processes, and auction theory.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12120"
    },
    {
        "doc_id": 64,
        "title": "Measures of the Capital Network of the U.S. Economy",
        "authors": [
            "Ben Klemens"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "About two million U.S. corporations and partnerships are linked to each other and human investors by about 15 million owner-subsidiary links. Comparable social networks such as corporate board memberships and socially-built systems such as the network of Internet links are \"small worlds,\" meaning a network with a small diameter and link densities with a power-law distribution, but these properties had not yet been measured for the business entity network. This article shows that both inbound links and outbound links display a power-law distribution with a coefficient of concentration estimable to within a generally narrow confidence interval, overall, for subnetworks including only business entities, only for the great connected component of the network, and in subnetworks with edges associated with certain industries, for all years 2009-2021. In contrast to other networks with power-law distributed link densities, the network is mostly a tree, and has a diameter an order of magnitude larger than a small-world network with the same link distribution. The regularity of the power-law distribution indicates that its coefficient can be used as a new, well-defined macroeconomic metric for the concentration of capital flows in an economy. Economists might use it as a new measure of market concentration which is more comprehensive than measures based only on the few biggest firms. Comparing capital link concentrations across countries would facilitate modeling the relationship between business network characteristics and other macroeconomic indicators.",
        "comments": "18 pages. JEL classifications: L14; C81; M42; G34",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12118"
    },
    {
        "doc_id": 65,
        "title": "Metrics matter, a Formal comment on Ward et al Plos-One 2016 paper : Is decoupling GDP growth from environmental impact possible?",
        "authors": [
            "Herv\u00e9 Bercegol",
            "Paul E. Brockway"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The Ward et al. (2016) Plos-One paper is an important, heavily-cited paper in the decoupling literature. The authors present evidence of 1990-2015 growth in material and energy consumption and GDP at a world level, and for selected countries. They find only relative decoupling has occurred, leading to their central claim that future absolute decoupling is implausible. However, the authors have made two key errors in their collected data: GDP data is in current prices which includes inflation, and their global material use data is the total mass of fossil energy materials. Strictly, GDP data should be in constant prices to allow for its comparison over time, and material inputs to an economy should be the sum of mineral raw materials. Amending for these errors, we find much smaller levels of energy-GDP relative decoupling, and no materials-GDP decoupling at all at a global level. We check these new results by adding data for 1900-1990 to provide a longer time series, and find consistently low (and even no) levels of global relative decoupling of material use. The central claim for materials over the implausibility of future absolute decoupling therefore not only remains valid but is reinforced by the corrected datasets.",
        "comments": "6 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12100"
    },
    {
        "doc_id": 66,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 67,
        "title": "Market Responses to Genuine Versus Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers",
        "authors": [
            "Chen Liang",
            "Murat Tunc",
            "Gordon Burtch"
        ],
        "subjects": [
            "General Economics",
            "Computers and Society",
            "Human-Computer Interaction"
        ],
        "abstract": "Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about the motivations of donors in these charity fundraisers, resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity, based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of strategic generosity), and based on an individual's degree of social exposure within the NFT marketplace. We show that charity-NFT \"relisters\" experience significant penalties in the market, in terms of the prices they are able to command on other NFT listings, particularly among those who relist quickly and those who are more socially exposed. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12064"
    },
    {
        "doc_id": 68,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 69,
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "Several of the classical results in social choice theory demonstrate that in order for many voting systems to be well-behaved the set domain of individual preferences must satisfy some kind of restriction, such as being single-peaked on a political axis. As a consequence it becomes interesting to measure how diverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference diversity, focusing on the abundance of distinct suborders one subsets of the alternative. We provide a common generalisation of the frequently used concepts of ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our theorems imply a ceiling for the local diversity in domains on large sets of alternatives, which show that in this measure Black's single-peaked domain is in fact optimal. We also demonstrate that for some numbers of alternatives, there are Condorcet domains which have largest local diversity without having maximum order.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11912"
    },
    {
        "doc_id": 70,
        "title": "Efficiency in random allocation with ordinal rules",
        "authors": [
            "Samson Alva",
            "Eun Jeong Heo",
            "Vikram Manjunath"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study ordinal rules for allocating indivisible goods via lottery. Ordinality requires a rule to consider only how agents rank degenerate lotteries and may be necessitated by cognitive, informational, or as we show, incentive constraints. The limited responsiveness of ordinal rules to agents' preferences means that they can only satisfy welfare properties based on first order stochastic dominance, which is incomplete.\n  We define a new efficiency concept for ordinal rules. While ordinality and efficiency together are incompatible with the usual notions of fairness and somewhat limit randomization, they do leave room for a rich class of rules. We demonstrate this through a characterization of all ordinal, efficient, strategy-proof, non-bossy, boundedly invariant, and neutral rules.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11899"
    },
    {
        "doc_id": 71,
        "title": "Finite horizon optimal control of reaction-diffusion SIV epidemic system with stochastic environment",
        "authors": [
            "Zong Wang"
        ],
        "subjects": [
            "Optimization and Control",
            "Dynamical Systems"
        ],
        "abstract": "This contribution mainly focuses on the finite horizon optimal control problems of a susceptible-infected-vaccinated(SIV) epidemic system governed by reaction-diffusion equations and Markov switching. Stochastic dynamic programming is employed to find the optimal vaccination effort and economic return for a stochastic reaction diffusion SIV epidemic model. To achieve this, a key step is to show the existence and uniqueness of invariant measure for the model. Then, we obtained the necessary and sufficient conditions for the near-optimal control. Furthermore, we give an algorithm to approximate the Hamilton-Jacobi Bellman (HJB) equation. Finally, some numerical simulations are presented to confirm our analytic results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11744"
    },
    {
        "doc_id": 72,
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "authors": [
            "Yu Zhu",
            "Kang Li",
            "Lequan Yu",
            "Pheng-Ann Heng"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.",
        "comments": "Accepted by AAAI 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11674"
    },
    {
        "doc_id": 73,
        "title": "Analyzing the Impact of Financial Inclusion on Economic Growth in Bangladesh",
        "authors": [
            "Ganapati Kumar Biswas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial inclusion is touted one of the principal drivers for economic growth for an economy. The study aims to explore the impact of financial inclusion on economic growth in Bangladesh. In my study, I used the number of loan accounts as the proxy for financial inclusion. Using time series data from spans from 2004-2021, the study revealed that there exists a long-run relationship between GDP, financial inclusion, and other macroeconomic variables in Bangladesh. The study also found that financial inclusion had a positive impact on economic growth of Bangladesh during the study period. Therefore, the policymakers and the central bank of Bangladesh as the apex authority of financial system should promote financial inclusion activities to achieve sustainable economic growth.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11585"
    },
    {
        "doc_id": 74,
        "title": "A note on the stability of Monotone Markov Chains",
        "authors": [
            "Bar Light"
        ],
        "subjects": [
            "Probability",
            "Theoretical Economics"
        ],
        "abstract": "This note studies monotone Markov chains a subclass of Markov chains with extensive applications in operations research and economics. While the properties that ensure the global stability of these chains are well studied, their establishment often relies on the fulfillment of a certain splitting condition. We address the challenges of verifying the splitting condition, by introducing simple, applicable conditions that ensure global stability. The simplicity of these conditions is demonstrated through various examples including autoregressive processes and portfolio allocation problems.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11568"
    },
    {
        "doc_id": 75,
        "title": "Taxi dispatching strategies with compensations",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski",
            "Javier Palanca",
            "Javier Bajo"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi vehicles are key elements in daily traffic activity. The advance of ICT and geo-positioning systems has given rise to new opportunities for improving the efficiency of taxi fleets in terms of waiting times of passengers, cost and time for drivers, traffic density, CO2 emissions, etc., by using more informed, intelligent dispatching. Still, the explicit spatial and temporal components, as well as the scale and, in particular, the dynamicity of the problem of pairing passengers and taxis in big towns, render traditional approaches for solving standard assignment problem useless for this purpose, and call for intelligent approximation strategies based on domain-specific heuristics. Furthermore, taxi drivers are often autonomous actors and may not agree to participate in assignments that, though globally efficient, may not be sufficently beneficial for them individually. This paper presents a new heuristic algorithm for taxi assignment to customers that considers taxi reassignments if this may lead to globally better solutions. In addition, as such new assignments may reduce the expected revenues of individual drivers, we propose an economic compensation scheme to make individually rational drivers agree to proposed modifications in their assigned clients. We carried out a set of experiments, where several commonly used assignment strategies are compared to three different instantiations of our heuristic algorithm. The results indicate that our proposal has the potential to reduce customer waiting times in fleets of autonomous taxis, while being also beneficial from an economic point of view.",
        "comments": "ACM Class:          I.2.1",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11553"
    },
    {
        "doc_id": 76,
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "authors": [
            "Zhigang Wang",
            "Xu Zhang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Transformer-based models are becoming deeper and larger recently. For better scalability, an underlying training solution in industry is to split billions of parameters (tensors) into many tasks and then run them across homogeneous accelerators (e.g., GPUs). However, such dedicated compute cluster is prohibitively expensive in academia and moderate companies. An economic replacement is to aggregate existing heterogeneous devices and share resources among multi-tenants. Nevertheless, static hardware configurations and dynamic resource contention definitely cause straggling tasks, which heavily slows down the overall training efficiency. Existing works feature contributions mainly tailored for traditional data parallelism. They cannot work well for the new tensor parallelism due to strict communication and correctness constraints.\n  In this paper we first present ZERO-resizing, a novel dynamic workload balancing technique without any data migration. We tune workloads in real-time by temporarily resizing matrices involved in core tensor-related computations. We particularly design data imputation and priority selection policies to respectively satisfy consistency constraint required by normal training and reduce the accuracy loss. We also give a lightweight data migration technique without loss of accuracy, to cope with heavy heterogeneity. Our final SEMI-migration solution is built on top of these two techniques and can adaptively distinguish their respective balancing missions, to achieve an overall success in efficiency and accuracy. Extensive experiments on the representative Colossal-AI platform validate the effectiveness of our proposals.",
        "comments": "13 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11469"
    },
    {
        "doc_id": 77,
        "title": "Local Identification in the Instrumental Variable Multivariate Quantile Regression Model",
        "authors": [
            "Haruki Kono"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The instrumental variable (IV) quantile regression model introduced by Chernozhukov and Hansen (2005) is a useful tool for analyzing quantile treatment effects in the presence of endogeneity, but when outcome variables are multidimensional, it is silent on the joint distribution of different dimensions of each variable. To overcome this limitation, we propose an IV model built on the optimal-transport-based multivariate quantile that takes into account the correlation between the entries of the outcome variable. We then provide a local identification result for the model. Surprisingly, we find that the support size of the IV required for the identification is independent of the dimension of the outcome vector, as long as the IV is sufficiently informative. Our result follows from a general identification theorem that we establish, which has independent theoretical significance.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11422"
    },
    {
        "doc_id": 78,
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "authors": [
            "Md Zubair",
            "Md. Shahidul Salim",
            "Mehrab Mustafy Rahman",
            "Mohammad Jahid Ibna Basher",
            "Shahin Imran",
            "Iqbal H. Sarker"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with higher accuracy. These predictions guide our system to assist the farmers in making feasible decisions about planting, irrigation, harvesting, and so on. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.",
        "comments": "16 pages, 14 figures and 12 tables. Submitted to Engineering Application of Artificial Intelligence (Elsevier)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11410"
    },
    {
        "doc_id": 79,
        "title": "Fake Google restaurant reviews and the implications for consumers and restaurants",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The use of online reviews to aid with purchase decisions is popular among consumers as it is a simple heuristic tool based on the reported experiences of other consumers. However, not all online reviews are written by real consumers or reflect actual experiences, and present implications for consumers and businesses. This study examines the effects of fake online reviews written by artificial intelligence (AI) on consumer decision making. Respondents were surveyed about their attitudes and habits concerning online reviews using an online questionnaire (n=351), and participated in a restaurant choice experiment using varying proportions of fake and real reviews. While the findings confirm prior studies, new insights are gained about the confusion for consumers and consequences for businesses when reviews written by AI are believed rather than real reviews. The study presents a fake review detection model using logistic regression modeling to score and flag reviews as a solution.",
        "comments": "pp.1-158, 41 tables, 11 figures. Doctor of Business Administration Dissertation",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11345"
    },
    {
        "doc_id": 80,
        "title": "An income-based approach to modeling commuting distance in the Toronto area",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The purpose of this article is to propose a novel model of the effects of changes in shelter and driving costs on car commuting distances in the overheated Toronto housing market from 2011 to 2016. The model borrows from theoretical concepts of microeconomics and urban geography to examine the Toronto housing market. Using 2011 and 2016 Census data for census metropolitan areas (CMAs) and census agglomerations (CAs) in Southern Ontario and computed driving costs, the model of car commuting distance is based on variables of allocation of monthly household income to monthly shelter costs and driving costs as a function of the car driving distance to Toronto. Using this model, we can predict the effect on car commuting distance due to changes in any of the variables. The model also offers an explanation for communities of Toronto car commuters beyond a driving radius that we might expect for daily commuting. The model confirms that increases in shelter costs in the Toronto housing market from 2011 to 2016 have forced the boundaries of feasible housing locations outward, and forced households to move farther away, thus increasing car commuting distance.",
        "comments": "pp.1-40, 8 tables, 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11343"
    },
    {
        "doc_id": 81,
        "title": "Coevolution of Resource and Strategies in Common-Pool Resource Dilemmas: A Coupled Human-Environmental System Model",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Yongliang Yang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "Common-pool resource governance requires users to cooperate and avoid overexploitation, but defection and free-riding often undermine cooperation. We model a human-environmental system that integrates dynamics of resource and users' strategies. The resource follows a logistic function that depends on natural growth rate, carrying capacity, and extraction rates of cooperators and defectors. The users' strategies evolve according to different processes that capture effects of payoff, resource, and noise. We analyze the feedback between resource availability and strategic adaptation, and explores the conditions for the emergence and maintenance of cooperation. We find different processes lead to different regimes of equilibrium solutions and resource levels depending on the parameter configuration and initial conditions. We also show that some processes can enhance the sustainability of the resource by making the users more responsive to the resource scarcity. The paper advances the understanding of human-environmental system and offers insights for resource governance policies and interventions.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11269"
    },
    {
        "doc_id": 82,
        "title": "Estimation with Pairwise Observations",
        "authors": [
            "Felix Chan",
            "Laszlo Matyas"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The paper introduces a new estimation method for the standard linear regression model. The procedure is not driven by the optimisation of any objective function rather, it is a simple weighted average of slopes from observation pairs. The paper shows that such estimator is consistent for carefully selected weights. Other properties, such as asymptotic distributions, have also been derived to facilitate valid statistical inference. Unlike traditional methods, such as Least Squares and Maximum Likelihood, among others, the estimated residual of this estimator is not by construction orthogonal to the explanatory variables of the model. This property allows a wide range of practical applications, such as the testing of endogeneity, i.e.,the correlation between the explanatory variables and the disturbance terms, and potentially several others.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11229"
    },
    {
        "doc_id": 83,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 84,
        "title": "Long-term Effects of India's Childhood Immunization Program on Earnings and Consumption Expenditure: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Summan, Nandi, and Bloom (2023; SNB) finds that exposure of babies to India's Universal Immunization Programme (UIP) in the late 1980s increased their weekly wages in early adulthood by 0.138 log points and per-capita household consumption 0.028 points. But the results are attained by regressing on age, in years, while controlling for year of birth--two variables that, as constructed, are nearly collinear. The results are therefore attributable to trends during the one-year survey period, such as inflation. A randomization exercise shows that when the true impacts are zero, the SNB estimator averages 0.088 points for wages and 0.039 points for consumption.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11100"
    },
    {
        "doc_id": 85,
        "title": "Information Based Inference in Models with Set-Valued Predictions and Misspecification",
        "authors": [
            "Hiroaki Kaido",
            "Francesca Molinari"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This paper proposes an information-based inference method for partially identified parameters in incomplete models that is valid both when the model is correctly specified and when it is misspecified. Key features of the method are: (i) it is based on minimizing a suitably defined Kullback-Leibler information criterion that accounts for incompleteness of the model and delivers a non-empty pseudo-true set; (ii) it is computationally tractable; (iii) its implementation is the same for both correctly and incorrectly specified models; (iv) it exploits all information provided by variation in discrete and continuous covariates; (v) it relies on Rao's score statistic, which is shown to be asymptotically pivotal.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11046"
    },
    {
        "doc_id": 86,
        "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models",
        "authors": [
            "Ben Aoki-Sherwood",
            "Catherine Bregou",
            "David Liben-Nowell",
            "Kiran Tomlinson",
            "Thomas Zeng"
        ],
        "subjects": [
            "Machine Learning",
            "Multiagent Systems",
            "Econometrics"
        ],
        "abstract": "A common theory of choice posits that individuals make choices in a two-step process, first selecting some subset of the alternatives to consider before making a selection from the resulting consideration set. However, inferring unobserved consideration sets (or item consideration probabilities) in this \"consider then choose\" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We consider a natural extension of consider-then-choose models to a top-$k$ ranking setting, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that knowledge of item utilities allows us to infer bounds on the relative sizes of consideration probabilities. Additionally, given a condition on the expected consideration set size, we derive absolute upper and lower bounds on item consideration probabilities. We also provide algorithms to tighten those bounds on consideration probabilities by propagating inferred constraints. Thus, we show that we can learn useful information about consideration probabilities despite not being able to identify them precisely. We demonstrate our methods on a ranking dataset from a psychology experiment with two different ranking tasks (one with fixed consideration sets and one with unknown consideration sets). This combination of data allows us to estimate utilities and then learn about unknown consideration probabilities using our bounds.",
        "comments": "11 pages; accepted as an extended abstract to AAMAS '24",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11016"
    },
    {
        "doc_id": 87,
        "title": "Subjective Causality",
        "authors": [
            "Joseph Y. Halpern",
            "Evan Piermont"
        ],
        "subjects": [
            "Theoretical Economics",
            "Artificial Intelligence",
            "Logic in Computer Science"
        ],
        "abstract": "We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are consistent with some causal model and to identify causal judgements from observed behavior.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10937"
    },
    {
        "doc_id": 88,
        "title": "An Experimental Study of Decentralized Matching",
        "authors": [
            "Federico Echenique",
            "Alejandro Robinson-Cort\u00e9s",
            "Leeat Yariv"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "We present an experimental study of decentralized two-sided matching markets with no transfers. Experimental participants are informed of everyone's preferences and can make arbitrary non-binding match offers that get finalized when a period of market inactivity has elapsed. Several insights emerge. First, stable outcomes are prevalent. Second, while centralized clearinghouses commonly aim at implementing extremal stable matchings, our decentralized markets most frequently culminate in the median stable matching. Third, preferences' cardinal representations impact the stable partners participants match with. Last, the dynamics underlying our results exhibit strategic sophistication, with agents successfully avoiding cycles of blocking pairs.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10872"
    },
    {
        "doc_id": 89,
        "title": "Aberration compensation for the anamorphic triplet",
        "authors": [
            "Dmitry Zhuridov"
        ],
        "subjects": [
            "Optics",
            "Applied Physics",
            "Instrumentation and Detectors"
        ],
        "abstract": "Compensation of the generalized spherical aberrations is discussed for the plane-symmetric and anamorphic optical systems. The compensation rules are derived for an economical three-component double-plane symmetric telescopic system containing two cylindrical mirrors and one toroidal lens. Anamorphic systems, which provide large magnifications in the two orthogonal directions, are presented.",
        "comments": "4 pages, 4 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10762"
    },
    {
        "doc_id": 90,
        "title": "Methodology to assess prosumer participation in European electricity markets",
        "authors": [
            "Rub\u00e9n Rodr\u00edguez-Vilches",
            "Francisco Mart\u00edn-Mart\u00ednez",
            "\u00c1lvaro S\u00e1nchez-Miralles",
            "Javier Rodrigo Guti\u00e9rrez de la C\u00e1mara",
            "Sergio Mu\u00f1oz Delgado"
        ],
        "subjects": [
            "Physics and Society",
            "Systems and Control"
        ],
        "abstract": "The emergence of distributed generation and the electrification of demand have opened the possibility for prosumers to participate in electricity markets, receiving economic benefits on their bills and contributing to the reduction of carbon emissions, aligning with United Nations Sustainable Development Goal 7. Consumers and prosumers can participate through implicit and explicit demand flexibility and (collective) self-consumption. This study analyses the potential markets in which prosumers can participate and indicates whether these are currently open. The markets studied include day-ahead, intraday, ancillary services, adequacy services, constraint management, and local flexibility markets. Additionally, collective self-consumption is analysed as a service through which prosumers can participate in the electricity market. Previous studies are usually focused on a single market or in a single country, making impossible a complete comparison. This analysis has been done in Spain, Italy, Croatia, and the United Kingdom as representative countries to obtain a methodology to assess countries' openness to prosumer participation in electricity markets, comparing regulatory frameworks and assigning scores based on their prosumer inclusion across various markets. This work updates current literature reviews with the changes and a new description of local market designs in Spain. This methodology can be used to compare other countries' grade of openness. The results of this study show that the analysed countries can be categorised into three groups: almost open, partially open, and closed markets. Analysing the differences, recommendations on the following steps to foster user participation are suggested for each group.",
        "comments": "Journal ref:        Renewable and Sustainable Energy Reviews Volume 191, March 2024, 114179",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10696"
    },
    {
        "doc_id": 91,
        "title": "Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing",
        "authors": [
            "Wolfgang Maass",
            "Ankit Agrawal",
            "Alessandro Ciani",
            "Sven Danz",
            "Alejandro Delgadillo",
            "Philipp Ganser",
            "Pascal Kienast",
            "Marco Kulig",
            "Valentina K\u00f6nig",
            "Nil Rodellas-Gr\u00e0cia",
            "Rivan Rughubar",
            "Stefan Schr\u00f6der",
            "Marc Stautner",
            "Hannah Stein",
            "Tobias Stollenwerk",
            "Daniel Zeuch",
            "Frank K. Wilhelm"
        ],
        "subjects": [
            "Quantum Physics",
            "Systems and Control"
        ],
        "abstract": "Quantum computing (QC) and machine learning (ML), taken individually or combined into quantum-assisted ML (QML), are ascending computing paradigms whose calculations come with huge potential for speedup, increase in precision, and resource reductions. Likely improvements for numerical simulations in engineering imply the possibility of a strong economic impact on the manufacturing industry. In this project report, we propose a framework for a quantum computing-enhanced service ecosystem for simulation in manufacturing, consisting of various layers ranging from hardware to algorithms to service and organizational layers. In addition, we give insight into the current state of the art of applications research based on QC and QML, both from a scientific and an industrial point of view. We further analyse two high-value use cases with the aim of a quantitative evaluation of these new computing paradigms for industrially-relevant settings.",
        "comments": "10 pages, 3 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10623"
    },
    {
        "doc_id": 92,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 93,
        "title": "Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest Machine Learning",
        "authors": [
            "Zaina Abu Hweij",
            "Florence Liang",
            "Sophie Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Medical Physics"
        ],
        "abstract": "Acute compartment syndrome (ACS) is an orthopedic emergency, caused by elevated pressure within a muscle compartment, that leads to permanent tissue damage and eventually death. Diagnosis of ACS relies heavily on patient-reported symptoms, a method that is clinically unreliable and often supplemented with invasive intracompartmental pressure measurements. This study proposes a continuous, objective, noninvasive diagnostic for ACS. The device detects ACS through a random forest machine learning model that uses pressure readings from force-sensitive resistors (FSRs) placed on the skin. The final diagnosis is exported real-time to a web application via Bluetooth. To validate the diagnostic, a data set containing FSR measurements and the corresponding simulated intracompartmental pressure was created. The diagnostic achieved an accuracy, on par to the invasive gold standard, of 97%. The device excelled in key performance metrics including precision, sensitivity, and F1 score. Manufactured for 73 USD, our device may be an economic alternative to needle-based diagnostics. These results demonstrate the potential of noninvasive ACS diagnostics to meet clinical standards and enhance patient care.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10386"
    },
    {
        "doc_id": 94,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 95,
        "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms",
        "authors": [
            "Iris Yan"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere. GS can cause severe damages to satellites, power grids, and communication infrastructures. Estimate of direct economic impacts of a large scale GS exceeds $40 billion a day in the US. Early prediction is critical in preventing and minimizing the hazards. However, current methods either predict several hours ahead but fail to identify all types of GS, or make predictions within short time, e.g., one hour ahead of the occurrence. This work aims to predict all types of geomagnetic storms reliably and as early as possible using big data and machine learning algorithms. By fusing big data collected from multiple ground stations in the world on different aspects of solar measurements and using Random Forests regression with feature selection and downsampling on minor geomagnetic storm instances (which carry majority of the data), we are able to achieve an accuracy of 82.55% on data collected in 2021 when making early predictions three hours in advance. Given that important predictive features such as historic Kp indices are measured every 3 hours and their importance decay quickly with the amount of time in advance, an early prediction of 3 hours ahead of time is believed to be close to the practical limit.",
        "comments": "14 pages, 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10290"
    },
    {
        "doc_id": 96,
        "title": "How industrial clusters influence the growth of the regional GDP: A spatial-approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Steffen Loeber"
        ],
        "subjects": [
            "General Economics",
            "Econometrics"
        ],
        "abstract": "In this paper, we employ spatial econometric methods to analyze panel data from German NUTS 3 regions. Our goal is to gain a deeper understanding of the significance and interdependence of industry clusters in shaping the dynamics of GDP. To achieve a more nuanced spatial differentiation, we introduce indicator matrices for each industry sector which allows for extending the spatial Durbin model to a new version of it. This approach is essential due to both the economic importance of these sectors and the potential issue of omitted variables. Failing to account for industry sectors can lead to omitted variable bias and estimation problems. To assess the effects of the major industry sectors, we incorporate eight distinct branches of industry into our analysis. According to prevailing economic theory, these clusters should have a positive impact on the regions they are associated with. Our findings indeed reveal highly significant impacts, which can be either positive or negative, of specific sectors on local GDP growth. Spatially, we observe that direct and indirect effects can exhibit opposite signs, indicative of heightened competitiveness within and between industry sectors. Therefore, we recommend that industry sectors should be taken into consideration when conducting spatial analysis of GDP. Doing so allows for a more comprehensive understanding of the economic dynamics at play.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10261"
    },
    {
        "doc_id": 97,
        "title": "Nowcasting Madagascar's real GDP using machine learning algorithms",
        "authors": [
            "Franck Ramaharo",
            "Gerzhino Rasolofomanana"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "We investigate the predictive power of different machine learning algorithms to nowcast Madagascar's gross domestic product (GDP). We trained popular regression models, including linear regularized regression (Ridge, Lasso, Elastic-net), dimensionality reduction model (principal component regression), k-nearest neighbors algorithm (k-NN regression), support vector regression (linear SVR), and tree-based ensemble models (Random forest and XGBoost regressions), on 10 Malagasy quarterly macroeconomic leading indicators over the period 2007Q1--2022Q4, and we used simple econometric models as a benchmark. We measured the nowcast accuracy of each model by calculating the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by aggregating individual predictions, consistently outperforms traditional econometric models. We conclude that machine learning models can deliver more accurate and timely nowcasts of Malagasy economic performance and provide policymakers with additional guidance for data-driven decision making.",
        "comments": "13 pages, 6 figures, 5 tables",
        "date": "24 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10255"
    },
    {
        "doc_id": 98,
        "title": "Equilibrium Multiplicity: A Systematic Approach using Homotopies, with an Application to Chicago",
        "authors": [
            "Amine C-L. Ouazad"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Discrete choice models with social interactions or spillovers may exhibit multiple equilibria. This paper provides a systematic approach to enumerating them for a quantitative spatial model with discrete locations, social interactions, and elastic housing supply. The approach relies on two homotopies. A homotopy is a smooth function that transforms the solutions of a simpler city where solutions are known, to a city with heterogeneous locations and finite supply elasticity. The first homotopy is that, in the set of cities with perfectly elastic floor surface supply, an economy with heterogeneous locations is homotopic to an economy with homogeneous locations, whose solutions can be comprehensively enumerated. Such an economy is epsilon close to an economy whose equilibria are the zeros of a system of polynomials. This is a well-studied area of mathematics where the enumeration of equilibria can be guaranteed. The second homotopy is that a city with perfectly elastic housing supply is homotopic to a city with an arbitrary supply elasticity. In a small number of cases, the path may bifurcate and a single path yields two or more equilibria. By running the method on thousands of cities, we obtain a large number of equilibria. Each equilibrium has different population distributions. We provide a method that is computationally feasible for economies with a large number of locations choices, with an empirical application to the City of Chicago. There exist multiple ``counterfactual Chicagos'' consistent with the estimated parameters. Population distribution, prices, and welfare are not uniquely pinned down by amenities. The paper's method can be applied to models in trade and IO. Further applications of algebraic geometry are suggested.",
        "comments": "MSC Class:          91; 90; 65                          ACM Class:          G.3; J.4; I.6",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10181"
    },
    {
        "doc_id": 99,
        "title": "Nowcasting economic activity in European regions using a mixed-frequency dynamic factor model",
        "authors": [
            "Luca Barbaglia",
            "Lorenzo Frattarolo",
            "Niko Hauzenberger",
            "Dominik Hirschbuehl",
            "Florian Huber",
            "Luca Onorante",
            "Michael Pfarrhofer",
            "Luca Tiozzo Pezzoli"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Timely information about the state of regional economies can be essential for planning, implementing and evaluating locally targeted economic policies. However, European regional accounts for output are published at an annual frequency and with a two-year delay. To obtain robust and more timely measures in a computationally efficient manner, we propose a mixed-frequency dynamic factor model that accounts for national information to produce high-frequency estimates of the regional gross value added (GVA). We show that our model produces reliable nowcasts of GVA in 162 regions across 12 European countries.",
        "comments": "JEL: C22, C53, R11; keywords: factor models, mixed-frequency, nowcasting, regional data",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10054"
    },
    {
        "doc_id": 100,
        "title": "O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold",
        "authors": [
            "Tolson Bell",
            "Alan Frieze"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Combinatorics"
        ],
        "abstract": "The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler. Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time. In this paper, we give a theoretical insertion time bound for this algorithm. More precisely, for every $d\\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists. We show that for any $d\\ge 4$ hashes and load factor $c<c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$.",
        "comments": "19 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14394"
    },
    {
        "doc_id": 101,
        "title": "Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem",
        "authors": [
            "Kaifeng Bu",
            "Weichen Gu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We establish an entropic, quantum central limit theorem and quantum inverse sumset theorem in discrete-variable quantum systems describing qudits or qubits. Both results are enabled by using our recently-discovered quantum convolution. We show that the exponential rate of convergence of the entropic central limit theorem is bounded by the magic gap. We also establish an ``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose a conjecture called ``convolutional strong subaddivity,'' which leads to the triangle inequality for the quantum Ruzsa divergence. A byproduct of this work is a magic measure to quantify the nonstabilizer nature of a state, based on the quantum Ruzsa divergence.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14385"
    },
    {
        "doc_id": 102,
        "title": "Butterfly Points and Hyperspace Selections",
        "authors": [
            "Valentin Gutev"
        ],
        "subjects": [
            "General Topology"
        ],
        "abstract": "If $f$ is a continuous selection for the Vietoris hyperspace $\\mathscr{F}(X)$ of the nonempty closed subsets of a space $X$, then the point $f(X)\\in X$ is not as arbitrary as it might seem at first glance. In this paper, we will characterise these points by local properties at them. Briefly, we will show that $p=f(X)$ is a strong butterfly point precisely when it has a countable clopen base in $\\overline{U}$ for some open set $U\\subset X\\setminus\\{p\\}$ with $\\overline{U}=U\\cup\\{p\\}$. Moreover, the same is valid when $X$ is totally disconnected at $p=f(X)$ and $p$ is only assumed to be a butterfly point. This gives the complete affirmative solution to a question raised previously by the author. Finally, when $p=f(X)$ lacks the above local base-like property, we will show that $\\mathscr{F}(X)$ has a continuous selection $h$ with the stronger property that $h(S)=p$ for every closed $S\\subset X$ with $p\\in S$.",
        "comments": "MSC Class:          54A20; 54B20; 54C65",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14384"
    },
    {
        "doc_id": 103,
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "subjects": [
            "Computational Complexity",
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We devise a parameterized family of distributions, the high-entropy step distributions (HES), which are expressive enough to capture near-optima of spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime and yet permit low-degree Sum-of-Squares (SoS) certificates that no such distribution can achieve value slightly larger than the true optimum. This yields a SoS optimization program and rounding scheme that attains near-optimal solutions for spherical spin glasses in the fRSB regime. In other regimes, the same results occur at the ALG value, which is a conjectured best-value attainable by any polynomial time algorithm. These SoS programs optimize over families of distributions of possible solutions, and circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure by instead proving the same bounds only in expectation on solution distributions that can be produced by the chosen rounding algorithm. The new SoS hierarchy does not make any specific reference to the spherical spin glass problem, and we conjecture that it can be applied to a broad range of average-case problems to obtain value that is optimal among polynomial-time algorithms. We give evidence for this with examples of ensembles that provably fool certain local iterative algorithms but for which there is either proof or evidence that the SoS program is better. This opens the door to addressing a question posed by Barak about the possible optimality of SoS on average-case optimization problems, and by Schramm about reductions between different families of algorithms for average-case problems. In this paper, we give low-degree SoS proofs certifying key properties about HES distributions as well as the ALG threshold for spherical spin glasses. The rounding algorithm is introduced and analyzed in a companion paper.",
        "comments": "130 pages, 0 figures. First of two companion papers",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14383"
    },
    {
        "doc_id": 104,
        "title": "An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Numerical Analysis",
            "Machine Learning"
        ],
        "abstract": "The recent introduction of the Least-Squares Support Vector Regression (LS-SVR) algorithm for solving differential and integral equations has sparked interest. In this study, we expand the application of this algorithm to address systems of differential-algebraic equations (DAEs). Our work presents a novel approach to solving general DAEs in an operator format by establishing connections between the LS-SVR machine learning model, weighted residual methods, and Legendre orthogonal polynomials. To assess the effectiveness of our proposed method, we conduct simulations involving various DAE scenarios, such as nonlinear systems, fractional-order derivatives, integro-differential, and partial DAEs. Finally, we carry out comparisons between our proposed method and currently established state-of-the-art approaches, demonstrating its reliability and effectiveness.",
        "comments": "17 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14382"
    },
    {
        "doc_id": 105,
        "title": "Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs",
        "authors": [
            "Martin Hanik",
            "Gabriele Steidl",
            "Christoph von Tycowicz"
        ],
        "subjects": [
            "Machine Learning",
            "Differential Geometry"
        ],
        "abstract": "We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.",
        "comments": "MSC Class:          53Z50                          ACM Class:          I.2.4",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14381"
    },
    {
        "doc_id": 106,
        "title": "Splines on Cayley Graphs of the Symmetric Group",
        "authors": [
            "Nathan R. T. Lesnevich"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "A spline is an assignment of polynomials to the vertices of a graph whose edges are labeled by ideals, where the difference of two polynomials labeling adjacent vertices must belong to the corresponding ideal. The set of splines forms a ring. We consider spline rings where the underlying graph is the Cayley graph of a symmetric group generated by a collection of transpositions. These rings generalize the GKM construction for equivariant cohomology rings of flag, regular semisimple Hessenberg, and permutohedral varieties. These cohomology rings carry two actions of the symmetric group $S_n$ whose graded characters are both of general interest in algebraic combinatorics. In this paper, we generalize the graded $S_n$-representations from the cohomologies of the above varieties to splines on Cayley graphs of $S_n$, then (1) give explicit module and ring generators for whenever the $S_n$-generating set is minimal, (2) give a combinatorial characterization of when graded pieces of one $S_n$-representation is trivial, and (3) compute the first degree piece of both graded characters for all generating sets.",
        "comments": "55 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14380"
    },
    {
        "doc_id": 107,
        "title": "An analytic version of stable arithmetic regularity",
        "authors": [
            "Gabriel Conant",
            "Anand Pillay"
        ],
        "subjects": [
            "Logic",
            "Combinatorics",
            "Group Theory"
        ],
        "abstract": "We prove a structure theorem for stable functions on amenable groups, which extends the arithmetic regularity lemma for stable subsets of finite groups. Given a group $G$, a function $f\\colon G\\to [-1,1]$ is called stable if the binary function $f(x\\cdot y)$ is stable in the sense of continuous logic. Roughly speaking, our main result says that if $G$ is amenable, then any stable function on $G$ is almost constant on all translates of a unitary Bohr set in $G$ of bounded complexity. The proof uses ingredients from topological dynamics and continuous model theory. We also discuss some applications, including a short proof of the noncommutative analogue of Bogolyubov's Lemma for amenable groups.",
        "comments": "22 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14363"
    },
    {
        "doc_id": 108,
        "title": "Initial data for Minkowski stability with arbitrary decay",
        "authors": [
            "Allen Juntao Fang",
            "J\u00e9r\u00e9mie Szeftel",
            "Arthur Touati"
        ],
        "subjects": [
            "Analysis of PDEs",
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "We construct and parametrize solutions to the constraint equations of general relativity in a neighborhood of Minkowski spacetime with arbitrary prescribed decay properties at infinity. We thus provide a large class of initial data for the results on stability of Minkowski which include a mass term in the asymptotics. Due to the symmetries of Minkowski, a naive linear perturbation fails. Our construction is based on a simplified conformal method, a reduction to transverse traceless perturbations and a nonlinear fixed point argument where we face linear obstructions coming from the cokernels of both the linearized constraint operator and the Laplace operator. To tackle these obstructions, we introduce a well-chosen truncated black hole around which to perturb. The control of the parameters of the truncated black hole is the most technical part of the proof, since its center of mass and angular momentum could be arbitrarily large.",
        "comments": "86 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14353"
    },
    {
        "doc_id": 109,
        "title": "Computing Derivations on Nilpotent Quadratic Lie Algebras",
        "authors": [
            "Pilar Benito",
            "Javier R\u00e1ndez-Ib\u00e1\u00f1ez",
            "Jorge Rold\u00e1n-L\u00f3pez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Every non-solvable and non-semisimple quadratic Lie algebra can be obtained as a double extension of a solvable quadratic Lie algebra. Thanks to a partial classification of nilpotent Lie algebras and this result, we can design different techniques to obtain any quadratic Lie algebra whose (solvable) radical ideal is nilpotent. To achieve this, we propose two alternative methods, both involving the use of quotients. In addition to their mathematical description, both approaches introduced in this paper have been computationally implemented and are publicly available to use for generating these algebras.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14348"
    },
    {
        "doc_id": 110,
        "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
        "authors": [
            "Thomas F. Varley",
            "Joshua Bongard"
        ],
        "subjects": [
            "Information Theory",
            "Dynamical Systems",
            "Chaotic Dynamics",
            "Cellular Automata and Lattice Gases"
        ],
        "abstract": "There has recently been an explosion of interest in how \"higher-order\" structures emerge in complex systems. This \"emergent\" organization has been found in a variety of natural and artificial systems, although at present the field lacks a unified understanding of what the consequences of higher-order synergies and redundancies are for systems. Typical research treat the presence (or absence) of synergistic information as a dependent variable and report changes in the level of synergy in response to some change in the system. Here, we attempt to flip the script: rather than treating higher-order information as a dependent variable, we use evolutionary optimization to evolve boolean networks with significant higher-order redundancies, synergies, or statistical complexity. We then analyse these evolved populations of networks using established tools for characterizing discrete dynamics: the number of attractors, average transient length, and Derrida coefficient. We also assess the capacity of the systems to integrate information. We find that high-synergy systems are unstable and chaotic, but with a high capacity to integrate information. In contrast, evolved redundant systems are extremely stable, but have negligible capacity to integrate information. Finally, the complex systems that balance integration and segregation (known as Tononi-Sporns-Edelman complexity) show features of both chaosticity and stability, with a greater capacity to integrate information than the redundant systems while being more stable than the random and synergistic systems. We conclude that there may be a fundamental trade-off between the robustness of a systems dynamics and its capacity to integrate information (which inherently requires flexibility and sensitivity), and that certain kinds of complexity naturally balance this trade-off.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14347"
    },
    {
        "doc_id": 111,
        "title": "The Comma Sequence: A Simple Sequence With Bizarre Properties",
        "authors": [
            "Eric Angelini",
            "Michael S. Branicky",
            "Giovanni Resta",
            "N. J. A. Sloane",
            "David W. Wilson"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "The ``comma sequence'' starts with 1 and is defined by the property that if k and k' are consecutive terms, the two-digit number formed from the last digit of k and the first digit of k' is equal to the difference k'-k. If there is more than one such k', choose the smallest, but if there is no such k' the sequence terminates. The sequence begins 1, 12, 35, 94, 135, ... and, surprisingly, ends at term 2137453, which is 99999945. The paper analyzes the sequence and its generalizations to other starting values and other bases. A slight change in the rules allows infinitely long comma sequences to exist.",
        "comments": "19 pages, 4 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14346"
    },
    {
        "doc_id": 112,
        "title": "From the Choi Formalism in Infinite Dimensions to Unique Decompositions of Generators of Completely Positive Dynamical Semigroups",
        "authors": [
            "Frederik vom Ende"
        ],
        "subjects": [
            "Functional Analysis",
            "Mathematical Physics",
            "Quantum Physics"
        ],
        "abstract": "Given any separable complex Hilbert space, any trace-class operator $B$ which does not have purely imaginary trace, and any generator $L$ of a norm-continuous one-parameter semigroup of completely positive maps we prove that there exists a unique bounded operator $K$ and a unique completely positive map $\u03a6$ such that (i) $L=K(\\cdot)+(\\cdot)K^*+\u03a6$, (ii) the superoperator $\u03a6(B^*(\\cdot)B)$ is trace class and has vanishing trace, and (iii) ${\\rm tr}(B^*K)$ is a real number. Central to our proof is a modified version of the Choi formalism which relates completely positive maps to positive semi-definite operators. We characterize when this correspondence is injective and surjective, respectively, which in turn explains why the proof idea of our main result cannot extend to non-separable Hilbert spaces. In particular, we find examples of positive semi-definite operators which have empty pre-image under the Choi formalism as soon as the underlying Hilbert space is infinite-dimensional.",
        "comments": "25+3 pages. Generalizes arXiv:2310.04037 to infinite dimensions. To be submitted to J. Funct. Anal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14344"
    },
    {
        "doc_id": 113,
        "title": "Efficient Construction of Long Orientable Sequences",
        "authors": [
            "Daniel Gabric",
            "Joe Sawada"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Information Theory",
            "Combinatorics"
        ],
        "abstract": "An orientable sequence of order $n$ is a cyclic binary sequence such that each length-$n$ substring appears at most once \\emph{in either direction}. Maximal length orientable sequences are known only for $n\\leq 7$, and a trivial upper bound on their length is $2^{n-1} - 2^{\\lfloor(n-1)/2\\rfloor}$. This paper presents the first efficient algorithm to construct orientable sequences with asymptotically optimal length; more specifically, our algorithm constructs orientable sequences via cycle-joining and a successor-rule approach requiring $O(n)$ time per symbol and $O(n)$ space. This answers a longstanding open question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)]. Our sequences are applied to find new longest-known orientable sequences for $n\\leq 20$.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14341"
    },
    {
        "doc_id": 114,
        "title": "Vanishing center-of-mass limit of the corotational Oldroyd-B polymeric fluid-structure interaction problem",
        "authors": [
            "Prince Romeo Mensah"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider the Oldroyd-B model for a dilute corotational polymer fluid with center-of-mass diffusion that is interacting with a viscoelastic shell. We show that any family of strong solutions of the system described above that is parametrized by the center-of-mass diffusion coefficient converges, as the coefficient goes to zero, to a weak solution of a corotational polymer fluid-structure interaction system without center-of-mass diffusion but with essentially bounded polymer number density and extra stress tensor.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14337"
    },
    {
        "doc_id": 115,
        "title": "On the diameter of a super-order-commuting graph",
        "authors": [
            "Janko Bra\u010di\u010d",
            "Bojan Kuzma"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We answer a question about the diameter of an order-super-commuting graph on a symmetric group by studying the number-theoretical concept of $d$-complete sequences of primes in arithmetic progression.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14335"
    },
    {
        "doc_id": 116,
        "title": "On strong growth conditions for weighted spaces of entire functions",
        "authors": [
            "Gerhard Schindl"
        ],
        "subjects": [
            "Functional Analysis",
            "Complex Variables"
        ],
        "abstract": "We characterize the inclusion relations between weighted classes of entire functions with rapid decreasing growth and study strong growth comparison relations between given weights. In our considerations first we focus on weights defined in terms of the so-called associated weight function where the weight(system) is based on a given sequence. Then the abstract weight function case is reduced to the weight sequence setting by using the so-called associated weight sequence. Finally, we compare weighted entire function spaces defined in terms of so-called dilatation-type and exponential-type weight systems.",
        "comments": "30 pages; this is the second part of the first version of submission arXiv:2211.14374. The proofs of Prop. 4.7 & 4.12, and hence of Cor. 4.14, in the first part contain a technical gap; in the appendix of this paper we provide a correction",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14330"
    },
    {
        "doc_id": 117,
        "title": "Planar binary trees, noncrossing partitions and the operator-valued S-transform",
        "authors": [
            "Kurusch Ebrahimi-Fard",
            "Timothe Ringeard"
        ],
        "subjects": [
            "Combinatorics",
            "Probability"
        ],
        "abstract": "We revisit Voiculescu's S-transform in the operator-valued setting and its twisted multiplicativity property, using a specific bijection between planar binary trees and noncrossing partitions.",
        "comments": "MSC Class:          46L54; 06A07; 16W60",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14318"
    },
    {
        "doc_id": 118,
        "title": "Higher categories",
        "authors": [
            "Rune Haugseng"
        ],
        "subjects": [
            "Category Theory",
            "Algebraic Topology"
        ],
        "abstract": "Invited contribution to the Encyclopedia of Mathematical Physics. We give an introduction to the homotopical theory of higher categories, focused on motivating the definitions of the basic objects, namely $\\infty$-categories and $(\\infty,n)$-categories.",
        "comments": "33 pages; contribution to Encyclopedia of Mathematical Physics, 2nd ed",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14311"
    },
    {
        "doc_id": 119,
        "title": "A high-order discontinuous Galerkin method for the numerical modeling of epileptic seizures",
        "authors": [
            "Caterina Beatrice Leimer Saglio",
            "Stefano Pagani",
            "Mattia Corti",
            "Paola F. Antonietti"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Epilepsy is a clinical neurological disorder characterized by recurrent and spontaneous seizures consisting of abnormal high-frequency electrical activity in the brain. In this condition, the transmembrane potential dynamics are characterized by rapid and sharp wavefronts traveling along the heterogeneous and anisotropic conduction pathways of the brain. This work employs the monodomain model, coupled with specific neuronal ionic models characterizing ion concentration dynamics, to mathematically describe brain tissue electrophysiology in grey and white matter at the organ scale. This multiscale model is discretized in space with the high-order discontinuous Galerkin method on polygonal and polyhedral grids (PolyDG) and advanced in time with a Crank-Nicolson scheme. This ensures, on the one hand, efficient and accurate simulations of the high-frequency electrical activity that is responsible for epileptic seizure and, on the other hand, keeps reasonably low the computational costs by a suitable combination of high-order approximations and agglomerated polytopal meshes. We numerically investigate synthetic test cases on a two-dimensional heterogeneous squared domain discretized with a polygonal grid, and on a two-dimensional brainstem in a sagittal plane with an agglomerated polygonal grid that takes full advantage of the flexibility of the PolyDG approximation of the semidiscrete formulation. Finally, we provide a theoretical analysis of stability and an a-priori convergence analysis for a simplified mathematical problem.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14310"
    },
    {
        "doc_id": 120,
        "title": "Andr\u00e9-Quillen cohomology in the context of curved algebras",
        "authors": [
            "Joan Bellier-Mill\u00e8s",
            "Sinan Yalin"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "K-Theory and Homology",
            "Symplectic Geometry"
        ],
        "abstract": "The Andr\u00e9-Quillen cohomology of an algebra with coefficients in a module is defined by deriving a functor based on K\u00e4hler differential forms. It can be computed using a cofibrant resolution of the algebra in a model category structure where weak equivalences are quasi-isomorphisms. This construction works for algebras over an operad, providing a cohomology theory tailored for each type of algebra. For curved algebras however, the notion of quasi-isomorphism is meaningless. The occurrence and importance of curved structures in various research topics (symplectic topology, deformation theory, derived geometry, mathematical physics) motivate the development of their homotopy theory and Andr\u00e9-Quillen cohomology theory. To get a homotopical context with an appropriate notion of weak equivalence, we consider filtered complete modules with a predifferential inducing a differential on the associated graded. Curved algebras in such modules are algebras over a curved operad. In this article, we consider curved operads which are not necessarily augmented. Bar and cobar constructions adapted to these curved operads are developed, as well as Koszul duality theory. Consequently, we obtain homotopy versions of our curved algebras and make it explicit for interesting cases. Two main examples are the curved operads encoding curved unital associative algebras and curved complex Lie algebras. In particular, homotopy curved unital associative algebras describe the structure of Floer complexes of lagrangian submanifolds and Fukaya categories in symplectic topology. Bar and cobar constructions for curved algebras are also developed, and we obtain resolutions from which we compute their Andr\u00e9-Quillen cohomology with module coefficients. Our computations in the case of curved complex Lie algebras reveal an interesting link between their Andr\u00e9-Quillen cohomology and derived complex analytic geometry.",
        "comments": "78 pages, comments welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14309"
    },
    {
        "doc_id": 121,
        "title": "Some determinants involving quadratic residues modulo primes",
        "authors": [
            "Zhi-Wei Sun"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "In this paper we evaluate several determinants involving quadratic residues modulo primes. For example, for any prime $p>3$ with $p\\equiv3\\pmod4$ and $a,b\\in\\mathbb Z$ with $p\\nmid ab$, we prove that $$\\det\\left[1+\\tan\u03c0\\frac{aj^2+bk^2}p\\right]_{1\\le j,k\\le\\frac{p-1}2}=\\begin{cases}-2^{(p-1)/2}p^{(p-3)/4}&\\text{if}\\ (\\frac{ab}p)=1, \\\\p^{(p-3)/4}&\\text{if}\\ (\\frac{ab}p)=-1,\\end{cases}$$ where $(\\frac{\\cdot}p)$ denotes the Legendre symbol. We also pose some conjectures for further research.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14301"
    },
    {
        "doc_id": 122,
        "title": "Characterising the Haar measure on the $p$-adic rotation groups via inverse limits of measure spaces",
        "authors": [
            "Paolo Aniello",
            "Sonia L'Innocente",
            "Stefano Mancini",
            "Vincenzo Parisi",
            "Ilaria Svampa",
            "Andreas Winter"
        ],
        "subjects": [
            "Mathematical Physics",
            "Functional Analysis",
            "Group Theory",
            "Number Theory"
        ],
        "abstract": "We determine the Haar measure on the compact $p$-adic special orthogonal groups of rotations $\\mathrm{SO}(d)_p$ in dimension $d=2,3$, by exploiting the machinery of inverse limits of measure spaces, for every prime $p>2$. We characterise $\\mathrm{SO}(d)_p$ as inverse limits of finite groups, of which we provide parametrisations and orders, together with an equivalent description through a multivariable Hensel lifting. Supplying these finite groups with their normalised counting measures, we get an inverse family of Haar measure spaces for each $\\mathrm{SO}(d)_p$. Finally, we constructively prove the existence of the so-called inverse limit measure of these inverse families, which is explicitly computable, and prove that it gives the Haar measure on $\\mathrm{SO}(d)_p$. Our results pave the way towards the study of the irreducible projective unitary representations of the $p$-adic rotation groups, with potential applications to the recently proposed $p$-adic quantum information theory.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14298"
    },
    {
        "doc_id": 123,
        "title": "PWM strategy with harmonics injection and modulated frequency triangular carrier. A review",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Francisco Perez- Hidalgo",
            "Francisco Vargas-Merino",
            "JuanR Heredia-Larrubia"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "A new, programmed pulse width modulation (PWM) technique to control power inverters, which uses a harmonic injection modulator and a frequency modulated triangular carrier, synchronized with the modulating signal is presented in this paper. The instantaneous carrier frequency is adjusted according to a periodic function synchronized with the fundamental term of the modulating signal, in order to maintain the average value of the instantaneous frequency as an odd positive integer multiple of 3, for each period of the modulating signal which is known as the average modulation order. The advantages of using the proposed technique over the conventional PWM techniques are the reduction in the total harmonic distortion and shift the frequency up of the temporal harmonics for any average modulation order. The experimental results show the viability of optimizing the time harmonics generated to minimize the vibrations in an induction motor or avoid the resonant frequencies.The mathematical formulation for the output modulated voltage is defined and the results are also checked experimentally and compared to a sinusoidal PWM technique",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14297"
    },
    {
        "doc_id": 124,
        "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts",
        "authors": [
            "Maciej Besta",
            "Florim Memedi",
            "Zhenyu Zhang",
            "Robert Gerstenberger",
            "Nils Blach",
            "Piotr Nyczyk",
            "Marcin Copik",
            "Grzegorz Kwa\u015bniewski",
            "J\u00fcrgen M\u00fcller",
            "Lukas Gianinazzi",
            "Ales Kubicek",
            "Hubert Niewiadomski",
            "Onur Mutlu",
            "Torsten Hoefler"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models' (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxonomy of structure-enhanced LLM reasoning schemes. We focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. We refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the LLM context. Our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. We also outline theoretical underpinnings, relationships between prompting and others parts of the LLM ecosystem such as knowledge bases, and the associated research challenges. Our work will help to advance future prompt engineering techniques.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14295"
    },
    {
        "doc_id": 125,
        "title": "On the Algebraic Classification of Non-singular Flexible Kokotsakis Polyhedra",
        "authors": [
            "Yang Liu",
            "Yi Ouyang",
            "Dominik L. Michels"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Across various scientific and engineering domains, a growing interest in flexible and deployable structures is becoming evident. These structures facilitate seamless transitions between distinct states of shape and find broad applicability ranging from robotics and solar cells to meta-materials and architecture. In this contribution, we study a class of mechanisms known as Kokotsakis polyhedra with a quadrangular base. These are $3\\times3$ quadrilateral meshes whose faces are rigid bodies and joined by hinges at the common edges. Compared to prior work, the quadrilateral faces do not have to be planar. In general, such meshes are not flexible, and the problem of finding and classifying the flexible ones is old, but until now largely unsolved. It appears that the tangent values of the dihedral angles between different faces are algebraically related through polynomials. Specifically, by fixing one angle as a parameter, the others can be parameterized algebraically and hence belong to an extended rational function field of the parameter. We use this approach to characterize shape restrictions resulting in flexible polyhedra.",
        "comments": "MSC Class:          12D05; 12F05; 52C25",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14291"
    },
    {
        "doc_id": 126,
        "title": "Modelling Micro-Doppler Signature of Drone Propellers in Distributed ISAC",
        "authors": [
            "Heraldo Cesar Alves Costa",
            "Saw James Myint",
            "Carsten Andrich",
            "Sebastian W. Giehl",
            "Christian Schneider",
            "Reiner S. Thom\u00e4"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Integrated Sensing and Communication (ISAC) comprises detection and analysis of non-cooperative targets by exploiting the resources of the mobile radio system. In this context, micro-Doppler is of great importance for target classification, in order to distinguish objects with local movements. For developing algorithms for target classification, it is necessary to have a large amount of target signatures. Aiming to generate these data, this paper proposes a mathematical model for the micro-Doppler of drone rotating propellers, and validate the proposed model by comparing it to measured micro-Doppler. Results show that the proposed mathematical model can generate micro-Doppler data very similar to those from measurement data.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14287"
    },
    {
        "doc_id": 127,
        "title": "An Instance-Based Approach to the Trace Reconstruction Problem",
        "authors": [
            "Kayvon Mazooji",
            "Ilan Shomorony"
        ],
        "subjects": [
            "Information Theory",
            "Data Structures and Algorithms",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\" Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.",
        "comments": "7 pages, accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14277"
    },
    {
        "doc_id": 128,
        "title": "Bifurcation of Dividing Surfaces Constructed from Period-Doubling Bifurcations of Periodic Orbits in a Caldera Potential Energy Surface",
        "authors": [
            "Matthaios Katsanikas",
            "Makrina Agaoglou",
            "Stephen Wiggins"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Dynamical Systems",
            "Chemical Physics"
        ],
        "abstract": "In this work we analyze the bifurcation of dividing surfaces that occurs as a result of two period-doubling bifurcations in a 2D caldera-type potential. We study the structure, the range, the minimum and maximum extents of the periodic orbit dividing surfaces before and after a subcritical period-doubling bifurcation of the family of the central minimum of the potential energy surface. Furthermore, we repeat the same study for the case of a supercritical perioddoubling bifurcation of the family of the central minimum of the potential energy surface. We will discuss and compare the results for the two cases of bifurcations of dividing surfaces.",
        "comments": "15 pages. arXiv admin note: text overlap with arXiv:2107.09623",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14275"
    },
    {
        "doc_id": 129,
        "title": "Uniformly rotating vortices for the lake equation",
        "authors": [
            "Taoufik Hmidi",
            "Haroune Houamed",
            "Emeric Roulley",
            "Mohamed Zerguine"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We investigate the existence of time-periodic vortex patch solutions, in both simply and doubly-connected cases, for the two-dimensional lake equation where the depth function of the lake is assumed to be non-degenerate and radial. The proofs employ bifurcation techniques, where the most challenging steps are related to the regularity study of some nonlinear functionals and the spectral analysis of their linearized operators around Rankine type vortices. The main difficulties stem from the roughness and the implicit form of the Green function connecting the fluid vorticity and its stream function. We handle in part these issues by exploring the asymptotic structure of the solutions to the associated elliptic problem. As to the distribution of the spectrum, it is tackled by a fixed-point argument through a perturbative approach.",
        "comments": "65 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14273"
    },
    {
        "doc_id": 130,
        "title": "Diagrammatic representations of 3-periodic entanglements",
        "authors": [
            "Toky Andriamanalina",
            "Myfanwy E. Evans",
            "Sonia Mahmoudi"
        ],
        "subjects": [
            "Geometric Topology",
            "Algebraic Topology"
        ],
        "abstract": "Diagrams enable the use of various algebraic and geometric tools in analysing and classifying knots. In this paper we introduce a new diagrammatic representation of triply periodic entangled structures, which are embeddings of simple curves in $\\mathbb{R}^3$ that are invariant under translations along three non-coplanar axes. These diagrams require an extended set of new moves in addition to the Reidemeister moves, which we show to preserve ambient isotopies of triply periodic entangled structures. We use the diagrams to define the crossing number and the unknotting number of the triply periodic entanglements, demonstrating the practicality of the diagrammatic representation.",
        "comments": "Report number:          RIKEN-iTHEMS-Report-24                          MSC Class:          57K10; 57K12 (Primary) 57K35 (Secondary)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14254"
    },
    {
        "doc_id": 131,
        "title": "Asymptotic limit of linear parabolic equations with spatio-temporal degenerated potentials",
        "authors": [
            "Pablo \u00c0lvarez-Caudevilla",
            "Matthieu Bonnivard",
            "Antoine Lemenant"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we observe how the heat equation in a non-cylindrical domain can arise as the asymptotic limit of a parabolic problem in a cylindrical domain, by adding a potential that vanishes outside the limit domain. This can be seen as a parabolic version of a previous work by the first and last authors, concerning the stationary case. We provide a strong convergence result for the solution by use of energetic methods and $\u0393$-convergence technics. Then, we establish an exponential decay estimate coming from an adaptation of an argument due to B. Simon.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14249"
    },
    {
        "doc_id": 132,
        "title": "Asymptotic behaviour for a class of quasilinear cooperative eigenvalue problems",
        "authors": [
            "Pablo Alvarez-Caudevilla"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "This work is devoted to the analysis of the asymptotic behaviour of a parameter dependent quasilinear cooperative eigenvalue system when a parameter in front of some non-negative potentials goes to infinity. In particular we consider operators of $p$-Laplacian type. We prove that the eigenfunctions concentrate on the subdomains where those potentials vanish at the limit, while the eigenvalue approaches to an upper bound that will depend on those subdomains as well. We also show several properties for the unusual limiting problems obtained here.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14247"
    },
    {
        "doc_id": 133,
        "title": "A stationary population model with an interior interface-type boundary",
        "authors": [
            "Pablo Alvarez-Caudevilla",
            "Cristina Br\u00e4ndle"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We propose a stationary system that might be regarded as a migration model of some population abandoning their original place of abode and becoming part of another population, once they reach the interface boundary. To do so, we show a model where each population follows a logistic equation in their own environment while assuming spatial heterogeneities. Moreover, both populations are coupled through the common boundary, which acts as a permeable membrane on which their flow moves in and out. The main goal we face in this work will be to describe the precise interplay between the stationary solutions with respect to the parameters involved in the problem, in particular the growth rate of the populations and the coupling parameter involved on the boundary where the interchange of flux is taking place.",
        "comments": "28 pages, 1 figure",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14246"
    },
    {
        "doc_id": 134,
        "title": "Counting rational points in non-singular curves",
        "authors": [
            "Chunhui Liu"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "In this paper, we will give a uniform upper bound of the number of rational points of bounded height in non-singular curves by applying the global determinant method.",
        "comments": "8 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14245"
    },
    {
        "doc_id": 135,
        "title": "Equivariant $\\mathcal{D}$-stability for Actions of Tensor Categories",
        "authors": [
            "Samuel Evington",
            "Sergio Gir\u00f3n Pacheco",
            "Corey Jones"
        ],
        "subjects": [
            "Operator Algebras",
            "Quantum Algebra"
        ],
        "abstract": "We introduce a notion of equivariant $\\mathcal{D}$-stability for actions of unitary tensor categories on C$^*$-algebras. We show that, when $\\mathcal{D}$ is strongly self-absorbing, equivariant $\\mathcal{D}$-stability of an action is equivalent to a unital embedding of $\\mathcal{D}$ into a certain subalgebra of Kirchberg's central sequence algebra. We use this to show $\\mathcal{Z}$-stability for a large class of AF-actions.",
        "comments": "13 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14238"
    },
    {
        "doc_id": 136,
        "title": "Existence and regularity of random attractors for stochastic evolution equations driven by rough noise",
        "authors": [
            "Alexandra Neamtu",
            "Tim Seitz"
        ],
        "subjects": [
            "Probability",
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "This work establishes the existence and regularity of random pullback attractors for parabolic partial differential equations with rough nonlinear multiplicative noise under natural assumptions on the coefficients. To this aim, we combine tools from rough path theory and random dynamical systems.~An application is given by partial differential equations with rough boundary noise, for which flow transformations are not available.",
        "comments": "31 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14235"
    },
    {
        "doc_id": 137,
        "title": "Bounds for the number of moves between pants decompositions, and between triangulations",
        "authors": [
            "Marc Lackenby",
            "Mehdi Yazdi"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "Given two pants decompositions of a compact orientable surface $S$, we give an upper bound for their distance in the pants graph that depends logarithmically on their intersection number and polynomially on the Euler characteristic of $S$. As a consequence, we find an upper bound on the volume of the convex core of a maximal cusp (which is a hyperbolic structures on $S \\times \\mathbb{R}$ where given pants decompositions of the conformal boundary are pinched to annular cusps). As a further application, we give an upper bound for the Weil--Petersson distance between two points in the Teichm\u00fcller space of $S$ in terms of their corresponding short pants decompositions. Similarly, given two one-vertex triangulations of $S$, we give an upper bound for the number of flips and twist maps needed to convert one triangulation into the other. The proofs rely on using pre-triangulations, train tracks, and an algorithm of Agol, Hass, and Thurston.",
        "comments": "43 pages, 12 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14233"
    },
    {
        "doc_id": 138,
        "title": "Strongly k-recursive sequences",
        "authors": [
            "Daniel Krenn",
            "Jeffrey Shallit"
        ],
        "subjects": [
            "Formal Languages and Automata Theory",
            "Discrete Mathematics",
            "Combinatorics"
        ],
        "abstract": "Drawing inspiration from a recent paper of Heuberger, Krenn, and Lipnik, we define the class of strongly k-recursive sequences. We show that every k-automatic sequence is strongly $k$-recursive, therefore k-recursive, and discuss that the converse is not true.\n  We also show that the class of strongly k-recursive sequences is a proper subclass of the class of k-regular sequences, and we present some explicit examples. We then extend the proof techniques to answer the same question for the class of k-recursive sequences.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14231"
    },
    {
        "doc_id": 139,
        "title": "A variational characterization of Einstein-Brillouin-Keller quantization",
        "authors": [
            "Kai Cieliebak",
            "Urs Frauenfelder"
        ],
        "subjects": [
            "Symplectic Geometry"
        ],
        "abstract": "In this paper we explain how to construct the EBK spectrum from the marked action spectrum and derive a minimax formula for concave toric domains. In the special case of the billiard on the disk we show that while the action spectrum is algebraic the EBK spectrum has infinite transcendence degree under the assumption that Schanuel's conjecture is true.",
        "comments": "19 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14223"
    },
    {
        "doc_id": 140,
        "title": "Fixed point subgroups of a supertight automorphism",
        "authors": [
            "Ulla Karhum\u00e4ki"
        ],
        "subjects": [
            "Group Theory",
            "Logic"
        ],
        "abstract": "Let $G$ be an infinite simple group of finite Morley rank and $\u03b1$ a supertight automorphism of $G$ so that the fixed point subgroup $P_n:=C_G(\u03b1^n)$ is pseudofinite for all $n\\in \\mathbb{N}\\setminus\\{0\\}$. It is know (using CFSG) that the socle $S_n:={\\rm Soc}(P_n)$ is a (twisted) Chevalley group over a pseudofinite field. We prove that there is $r\\in \\mathbb{N}\\setminus\\{0\\}$ so that for each $n$ we have $[P_n:S_n] < r$ and that there is no $m \\in \\mathbb{N}\\setminus \\{0\\}$ so that for each $n$ the sizes of the Sylow $2$-subgroups of $S_n$ are bounded by $m$. We also note that in the recent identification result of $G$ under the assumption ${\\rm pr}_2(G)=1$, the use of CFSG is not needed.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14222"
    },
    {
        "doc_id": 141,
        "title": "Orthogonal almost complex structure and its Nijenhuis tensor",
        "authors": [
            "Zizhou Tang",
            "Wenjiao Yan"
        ],
        "subjects": [
            "Differential Geometry",
            "Complex Variables"
        ],
        "abstract": "In this paper, we demonstrate that on an almost Hermitian manifold $(M^{2n}, J, ds^2)$, a 2-form $\\varphi=S^*\u03a6$, the pulling back of the K\u00e4hler form $\u03a6$ on the twistor bundle over $M^{2n}$, is non-degenerate if the squared norm $|N|^2$ of the Nijenhuis tensor is less than $\\frac{64}{5}$ when $n\\geq 3$ or less than $16$ when $n=2$. As a corollary, there exists no orthogonal almost complex structure on the standard sphere $(S^6, ds_0^2)$ with $|N|^2<\\frac{64}{5}$ everywhere.",
        "comments": "11pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14213"
    },
    {
        "doc_id": 142,
        "title": "On the growth of torsion in the cohomology of some arithmetic groups of $\\mathbb{Q}$-rank one",
        "authors": [
            "Werner Mueller",
            "Fr\u00e9d\u00e9ric Rochon"
        ],
        "subjects": [
            "Differential Geometry",
            "Geometric Topology",
            "Number Theory"
        ],
        "abstract": "Given a number field $F$ with ring of integers $\\mathcal{O}_{F}$, one can associate to any torsion free subgroup of $\\operatorname{SL}(2,\\mathcal{O}_{F})$ of finite index a complete Riemannian manifold of finite volume with fibered cusp ends. For natural choices of flat vector bundles on such a manifold, we show that analytic torsion is identified with the Reidemeister torsion of the Borel-Serre compactification. This is used to obtain exponential growth of torsion in the cohomology for sequences of congruence subgroups.",
        "comments": "45 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14205"
    },
    {
        "doc_id": 143,
        "title": "Dynamic image reconstruction in MPI with RESESOP-Kaczmarz",
        "authors": [
            "Marius Nitzsche",
            "Bernadette N Hahn"
        ],
        "subjects": [
            "Optimization and Control",
            "Numerical Analysis"
        ],
        "abstract": "In Magnetic Particle Imaging (MPI), it is typically assumed that the studied specimen is stationary during the data acquisition. In practical applications however, the searched-for 3D distribution of the magnetic nanoparticles might show a dynamic behavior, caused by e.g. breathing or movement of the blood. Neglecting those dynamics during the reconstruction step results in motion artifacts and a reduced image quality.\n  This article addresses the challenge of capturing high quality images in the presence of motion. A promising technique provides the Regularized Sequential Subspace Optimization (RESESOP) algorithm, which takes dynamics as model inexactness into account, significantly improving reconstruction compared to standard static algorithms like regularized Kaczmarz. Notably, this algorithm operates with minimal prior information and the method allows for subframe reconstruction, making it suitable for scenarios with rapid particle movement. The performance of the proposed method is demonstrated on both simulated and real data sets.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14202"
    },
    {
        "doc_id": 144,
        "title": "Proof of conjectures on series with summands involving $ \\binom{2k}{k}8^k/(\\binom{3k}{k}\\binom{6k}{3k})$",
        "authors": [
            "Zhi-Wei Sun",
            "Yajun Zhou"
        ],
        "subjects": [
            "Classical Analysis and ODEs",
            "Number Theory"
        ],
        "abstract": "Using cyclotomic multiple zeta values of level $8$, we confirm and generalize several conjectural identities on infinite series with summands involving $\\binom{2k}k8^k/(\\binom{3k}k\\binom{6k}{3k})$. For example, we prove that \\[\\sum_{k=0}^\\infty\\frac{(350k-17)\\binom{2k}k8^k} {\\binom{3k}k\\binom{6k}{3k}}=15\\sqrt2\\,\u03c0+27\\] and \\[\\sum_{k=1}^\\infty\\frac{\\left\\{(5k-1)\\left[16\\mathsf H_{2k-1}^{(2)}-3\\mathsf H_{k-1}^{(2)}\\right]-\\frac{12(6k-1)}{(2k-1)^2}\\right\\}\\binom{2k}k8^k} {k(2k-1)\\binom{3k}k\\binom{6k}{3k}}=\\frac{\u03c0^3}{12\\sqrt2},\\] where $\\mathsf H^{(2)}_m$ denotes the second-order harmonic number $\\sum_{0<j\\leq m}\\frac1{j^2}$.",
        "comments": "23 pages, 5 tables. A sequel to arXiv:2401.12083v1",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14197"
    },
    {
        "doc_id": 145,
        "title": "A few remarks on effectivity and good minimal models",
        "authors": [
            "Vladimir Lazi\u0107"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "We prove several results relating the nonvanishing and the existence of good minimal models of different pairs that have the same underlying variety.",
        "comments": "MSC Class:          14E30",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14190"
    },
    {
        "doc_id": 146,
        "title": "Form Convex Hull to Coancavity: Surface Contraction Around a Point Set",
        "authors": [
            "Netzer Moriya"
        ],
        "subjects": [
            "Optimization and Control",
            "Geometric Topology"
        ],
        "abstract": "This paper investigates the transformation of a convex hull, derived from a d-dimensional point cloud, into a concave surface. Our primary focus is on the development of a methodology that ensures all points in the point cloud are encapsulated within a closed, non-intersecting concave surface. The study begins with the initial convex hull and employs an iterative process of facet replacement and expansion to evolve the surface into Scc, which accurately conforms to the complex geometry of the point cloud.",
        "comments": "15 pages, 3 figures 1 theorem",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14189"
    },
    {
        "doc_id": 147,
        "title": "Fourth-order operators with unbounded coefficients",
        "authors": [
            "Federica Gregorio",
            "Chiara Spina",
            "Cristian Tacelli"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We prove that operators of the form $A=-a(x)^2\u0394^{2}$, with $|D a(x)|\\leq c a(x)^\\frac{1}{2}$, generate analytic semigroups in $L^p(\\mathbb{R}^N)$ for $1<p\\leq\\infty$ and in $C_b(\\mathbb{R}^N)$. In particular, we deduce generation results for the operator $A :=- (1+|x|^2)^\u03b1 \u0394^{2}$, $0<\u03b1<2$. Moreover, we characterize the maximal domain of such operators in $L^p(\\mathbb{R}^N)$ for $1<p<\\infty$.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14187"
    },
    {
        "doc_id": 148,
        "title": "Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Yaniv Proselkov",
            "Alexandra Brintrup"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Multiagent Systems",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Recent global disruptions, such as the pandemic and geopolitical conflicts, have profoundly exposed vulnerabilities in traditional supply chains, requiring exploration of more resilient alternatives. Autonomous supply chains (ASCs) have emerged as a potential solution, offering increased visibility, flexibility, and resilience in turbulent trade environments. Despite discussions in industry and academia over several years, ASCs lack well-established theoretical foundations. This paper addresses this research gap by presenting a formal definition of ASC along with its defining characteristics and auxiliary concepts. We propose a layered conceptual framework called the MIISI model. An illustrative case study focusing on the meat supply chain demonstrates an initial ASC implementation based on this conceptual model. Additionally, we introduce a seven-level supply chain autonomy reference model, delineating a trajectory towards achieving a full supply chain autonomy. Recognising that this work represents an initial endeavour, we emphasise the need for continued exploration in this emerging domain. We anticipate that this work will stimulate further research, both theoretical and technical, and contribute to the continual evolution of ASCs.",
        "comments": "This paper includes 20 pages and 8 figures",
        "date": "13 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.14183"
    },
    {
        "doc_id": 149,
        "title": "Harnack inequalities for kinetic integral equations",
        "authors": [
            "Francesca Anceschi",
            "Giampiero Palatucci",
            "Mirco Piccinini"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We deal with a wide class of kinetic equations, $$ \\big[ \\partial_t + v\\cdot\\nabla_x\\big] f = \\mathcal{L}_v f. $$ Above, the diffusion term $\\mathcal{L}_v$ is an integro-differential operator, whose nonnegative kernel is of fractional order $s\\in(0,1)$ having merely measurable coefficients. Amongst other results, we are able to prove that nonnegative weak solutions $f$ do satisfy $$ \\sup_{Q^-} f \\ \\leq \\ c\\inf_{Q^+} f, $$ where $Q^{\\pm}$ are suitable slanted cylinders. No a-priori boundedness is assumed, as usually in the literature, since we are also able to prove a general interpolation inequality in turn giving local boundedness which is valid even for weak subsolutions with no sign assumptions.\n  To our knowledge, this is the very first time that a strong Harnack inequality is proven for kinetic integro-differential-type equations.\n  A new independent result, a Besicovitch-type covering argument for very general kinetic geometries, is also stated and proved.",
        "comments": "41 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14182"
    },
    {
        "doc_id": 150,
        "title": "On the strong separation condition for self-similar iterated function systems with random translations",
        "authors": [
            "Simon Baker",
            "Derong Kong",
            "Zhiqiang Wang"
        ],
        "subjects": [
            "Dynamical Systems",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Given a self-similar iterated function system $\u03a6=\\{ \u03c6_i(x)=\u03c1_i O_i x+t_i \\}_{i=1}^m$ acting on $\\mathbb{R}^d$, we can generate a parameterised family of iterated function systems by replacing each $t_i$ with a random vector in $\\mathbb{R}^d$. In this paper we study whether a Lebesgue typical member of this family will satisfy the strong separation condition. Our main results show that if the similarity dimension of $\u03a6$ is sufficiently small, then a Lebesgue typical member of this family will satisfy the strong separation condition.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14175"
    },
    {
        "doc_id": 151,
        "title": "A finite volume method preserving the invariant region property for the quasimonotone reaction-diffusion systems",
        "authors": [
            "Huifang Zhou"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We present a finite volume method preserving the invariant region property (IRP) for the reaction-diffusion systems with quasimonotone functions, including nondecreasing, decreasing, and mixed quasimonotone systems. The diffusion terms and time derivatives are discretized by a finite volume method satisfying the discrete maximum principle (DMP) and the backward Euler method, respectively. The discretization leads to an implicit and nonlinear scheme, and it is proved to preserve the invariant region property unconditionally. We construct an iterative algorithm and prove the invariant region property ar each iteration step. Numerical examples are shown to confirm the accuracy and invariant region property of our scheme.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14169"
    },
    {
        "doc_id": 152,
        "title": "Dynamics of a particle under the Gravitational Potential of a Massive Annulus: properties and equilibrium description",
        "authors": [
            "Eva Tresaco",
            "Antonio Elipe",
            "Andr\u00e9s Riaguas"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "This paper studies the main features of the dynamics around a massive annular disk. The first part addresses the difficulties finding an appropriated expression of the gravitational potential of a massive disk, which will be used to define the differential equations of motion of our dynamical system. The second part describes the main features of the dynamics with special attention to equilibrium of the system.",
        "comments": "MSC Class:          14J60 (Primary)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14164"
    },
    {
        "doc_id": 153,
        "title": "The stabilizer-free weak Galerkin finite element method for the Biharmonic equation using polynomials of reduced order",
        "authors": [
            "Shanshan Gu",
            "Qilong Zhai"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this article, we decrease the degree of the polynomials on the boundary of the weak functions and modify the definition of the weak laplacian which are introduced in \\cite{BiharmonicSFWG} to use the SFWG method for the biharmonic equation. Then we propose the relevant numerical format and obtain the optimal order of error estimates in $H^2$ and $L^2$ norms. Finally, we confirm the estimates using numerical experiments.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14163"
    },
    {
        "doc_id": 154,
        "title": "A view toward homomorphisms and cv-polynomials between double Ore extensions",
        "authors": [
            "Mar\u00eda Camila Ram\u00edrez",
            "Armando Reyes"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Motivated by the theory of homomorphisms and cv-polynomials of Ore extensions formulated by several mathematicians, the rol of double Ore extensions introduced by Zhang and Zhang in the classification of Artin-Schelter regular algebras of dimension four, and that there are no inclusions between the classes of all double Ore extensions of an algebra and of all length two iterated Ore extensions of the same algebra, our aim in this paper is to present a first approach toward a theory of homomorphisms and cv-polynomials between double Ore extensions. We obtain several results on the characterizations of cv-polynomials and their relations with inner derivations of the ring of coefficients of the double algebra, and show that the computation of homomorphisms corresponding to these polynomials is non-trivial. We illustrate our results with different examples including Nakayama automorphisms of trimmed double Ore extensions.",
        "comments": "25 pages. arXiv admin note: text overlap with arXiv:0909.3238 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14162"
    },
    {
        "doc_id": 155,
        "title": "A Mathematical Theory of Semantic Communication: Overview",
        "authors": [
            "Kai Niu",
            "Ping Zhang"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "Semantic communication initiates a new direction for future communication. In this paper, we aim to establish a systematic framework of semantic information theory (SIT). First, we propose a semantic communication model and define the synonymous mapping to indicate the critical relationship between semantic information and syntactic information. Based on this core concept, we introduce the measures of semantic information, such as semantic entropy $H_s(\\tilde{U})$, up/down semantic mutual information $I^s(\\tilde{X};\\tilde{Y})$ $(I_s(\\tilde{X};\\tilde{Y}))$, semantic capacity $C_s=\\max_{p(x)}I^s(\\tilde{X};\\tilde{Y})$, and semantic rate-distortion function $R_s(D)=\\min_{p(\\hat{x}|x):\\mathbb{E}d_s(\\tilde{x},\\hat{\\tilde{x}})\\leq D}I_s(\\tilde{X};\\hat{\\tilde{X}})$. Furthermore, we prove three coding theorems of SIT, that is, the semantic source coding theorem, semantic channel coding theorem, and semantic rate-distortion coding theorem. We find that the limits of information theory are extended by using synonymous mapping, that is, $H_s(\\tilde{U})\\leq H(U)$, $C_s\\geq C$ and $R_s(D)\\leq R(D)$. All these works composite the basis of semantic information theory. In summary, the theoretic framework proposed in this paper is a natural extension of classic information theory and may reveal great performance potential for future communication.",
        "comments": "6 pages, 2 figures. This paper is submitted to the 2024 IEEE International Symposium on Information Theory (ISIT 2024). arXiv admin note: substantial text overlap with arXiv:2401.13387",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14160"
    },
    {
        "doc_id": 156,
        "title": "A robust consensus + innovations-based distributed parameter estimator",
        "authors": [
            "Nicolai Lorenz-Meyer",
            "Juan G. Rueda-Escobedo",
            "Jaime A. Moreno",
            "Johannes Schiffer"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "While distributed parameter estimation has been extensively studied in the literature, little has been achieved in terms of robust analysis and tuning methods in the presence of disturbances. However, disturbances such as measurement noise and model mismatches occur in any real-world setting. Therefore, providing tuning methods with specific robustness guarantees would greatly benefit the practical application. To address these issues, we recast the error dynamics of a continuous-time version of the widely used consensus + innovations-based distributed parameter estimator to reflect the error dynamics induced by the classical gradient descent algorithm. This paves the way for the construction of a strong Lyapunov function. Based on this result, we derive linear matrix inequality-based tools for tuning the algorithm gains such that a guaranteed upper bound on the L2-gain with respect to parameter variations, measurement noise, and disturbances in the communication channels is achieved. An application example illustrates the efficiency of the method.",
        "comments": "13 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14158"
    },
    {
        "doc_id": 157,
        "title": "Traces of vanishing H\u00f6lder spaces",
        "authors": [
            "Kaushik Mohanta",
            "Carlos Mudarra",
            "Tuomas Oikari"
        ],
        "subjects": [
            "Classical Analysis and ODEs",
            "Functional Analysis"
        ],
        "abstract": "For an arbitrary subset $E\\subset\\mathbb{R}^n$ and a modulus of continuity $\u03c9$, we define the subspaces of vanishing jets $\\dot{\\operatorname{VJ}}^{m,\u03c9}_\u0393(E)$ of the jet spaces $\\dot{\\operatorname{J}}^{m,\u03c9}(E),$ for the vanishing scales $\u0393\\in \\{\\operatorname{small},\\operatorname{large},\\operatorname{far}\\},$ and up to order $m\\in \\mathbb{N} \\cup \\lbrace 0 \\rbrace.$ We show that each $\u0393$-vanishing jet of order $m$ is obtained by restricting a \\emph{globally} defined function whose $m$th derivative is in the $\u0393$-vanishing H\u00f6lder space. This amounts to proving that the linear Whitney extension operator preserves separately each of the vanishing scales from $E$ to the whole ambient space $\\mathbb{R}^n.$\n  Further results will soon appear in a second version of this manuscript.",
        "comments": "17 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14156"
    },
    {
        "doc_id": 158,
        "title": "On Abel's Problem about Logarithmic Integrals in Positive Characteristic",
        "authors": [
            "Florian F\u00fcrnsinn",
            "Herwig Hauser",
            "Hiraku Kawanoue"
        ],
        "subjects": [
            "Number Theory",
            "Commutative Algebra",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Linear differential equations with polynomial coefficients over a field $K$ of positive characteristic $p$ with local exponents in the prime field have a basis of solutions in the differential extension $\\mathcal{R}_p=K(z_1, z_2, \\ldots)(\\!( x)\\!)$ of $K(x)$, where $x'=1, z_1'=1/x$ and $z_i'=z_{i-1}'/z_{i-1}$. For differential equations of order $1$ it is shown that there exists a solution $y$ whose projections $y\\vert_{z_{i+1}=z_{i+2}=\\cdots=0}$ are algebraic over the field of rational functions $K(x, z_1, \\ldots, z_{i})$ for all $i$. This can be seen as a characteristic $p$ analogue of Abel's problem about the algebraicity of logarithmic integrals. Further, the existence of infinite product representations of these solutions is shown. As a main tool $p^i$-curvatures are introduced, generalizing the notion of the $p$-curvature.",
        "comments": "25 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14154"
    },
    {
        "doc_id": 159,
        "title": "Cohomology of toric diagrams",
        "authors": [
            "Grigory Solomadin"
        ],
        "subjects": [
            "Algebraic Topology"
        ],
        "abstract": "In this note, integral cohomology of homotopy colimits for toric diagrams and their classifying spaces over regular CW posets are described in terms of sheaf cohomology. Split $T$-CW-complexes with CW orbit poset $C$ have such decomposition (up to a homeomorphism) in terms of a $T$-diagram $D$ over $C$. Equivariant formality for $hocolim\\ D$ is equivalent to $H^{odd}(hocolim\\ D)=0$ (over $\\mathbb{Q}$, or over $\\mathbb{Z}$ for connected stabilizers) provided that $C$ is an oriented homology manifold. The integral singular cohomology groups and bigraded Betti numbers are computed in this setting. Similar descriptions are provided for skeleta of toric manifolds and compact nonsingular toric varieties. The cohomological orbit spectral sequence collapse over $\\mathbb{Z}$ at page $2$ is proved for any compact toric variety.",
        "comments": "27 pages; comments are welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14146"
    },
    {
        "doc_id": 160,
        "title": "Mathematical Tri-State Model for Bee Shimmering Propagation Dynamics",
        "authors": [
            "Navin Patel",
            "Henri Huijberts",
            "Kaspar Althoefer",
            "Ketao Zhang"
        ],
        "subjects": [
            "Adaptation and Self-Organizing Systems",
            "Dynamical Systems",
            "Biological Physics"
        ],
        "abstract": "Bees undergo a self-organised process known as shimmering, where they form emergent patterns when they interact with each other on the nest surface as a defence mechanism in response to predator attacks. Many experimental studies have empirically investigated how the transfer of information to neighbouring bees propagates in various shimmering processes by measuring shimmering wave strength. However, there is no analytical modelling of the collective defence mechanism in nature. Here we introduce the first analytical tri-state Inactive-Active-Relapse (IAR) model to formulate the intrinsic process of bee shimmering. The major shimmering behaviour is shown to emerge under theoretical conditions which is demonstrated numerically and visually by simulating 1,000,000 bee agents, while the number of agents is scalable. Furthermore, we elaborate on these mathematical results to construct a wave strength function to demonstrate the accuracy of shimmering dynamics. The constructed wave strength function can be adapted to peak between 50-150ms which supports the experimental studies. Our results provide a foundation for further theoretical understanding of bee shimmering wave dynamics and could serve as inspiration for modelling other self-organised phenomena across scientific applications.",
        "comments": "20 pages, 7 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14145"
    },
    {
        "doc_id": 161,
        "title": "Generalized (co)homology of symmetric quandles over homogeneous Beck modules",
        "authors": [
            "Biswadeep Karmakar",
            "Deepanshi Saraf",
            "Mahender Singh"
        ],
        "subjects": [
            "Quantum Algebra",
            "Geometric Topology"
        ],
        "abstract": "A quandle equipped with a good involution is referred to as symmetric. It is known that the cohomology of symmetric quandles gives rise to strong cocycle invariants for classical and surface links, even when they are not necessarily oriented. In this paper, we introduce the category of symmetric quandle modules and prove that these modules completely determine the Beck modules in the category of symmetric quandles. Consequently, this establishes suitable coefficient objects for constructing appropriate (co)homology theories. We develop an extension theory of modules over symmetric quandles and propose a generalized (co)homology theory for symmetric quandles with coefficients in a homogeneous Beck module, which also recovers the symmetric quandle (co)homology developed by Kamada and Oshiro [Trans. Amer. Math. Soc. (2010)]. Our constructions also apply to symmetric racks. We conclude by establishing an explicit isomorphism between the second cohomology of a symmetric quandle and the first cohomology of its associated group.",
        "comments": "30 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14143"
    },
    {
        "doc_id": 162,
        "title": "On the discriminants of truncated logarithmic polynomials",
        "authors": [
            "John Cullinan",
            "Rylan Gajek-Leonard"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We provide evidence for a conjecture of Yamamura that the truncated logarithmic polynomials \\[ F_n(x) = 1 + x + \\frac{x^2}{2} + \\cdots + \\frac{x^n}{n} \\] have Galois group $S_n$ for all $n \\geq 1$.",
        "comments": "9 pages. Submitted for publication",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14138"
    },
    {
        "doc_id": 163,
        "title": "Comparison of approaches for boundary feedback control of hyperbolic systems",
        "authors": [
            "Michael Herty",
            "Ferdinand Thein"
        ],
        "subjects": [
            "Optimization and Control",
            "Analysis of PDEs"
        ],
        "abstract": "The interest in boundary feedback control of multi-dimensional hyperbolic systems is increasing. In the present work we want to compare some of the recent results available in the literature.",
        "comments": "arXiv admin note: text overlap with arXiv:2303.05598",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14137"
    },
    {
        "doc_id": 164,
        "title": "The Shizuta-Kawashima Condition for the Barotropic SHTC Two Fluid Model",
        "authors": [
            "Ferdinand Thein"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "Recently the barotropic two fluid model belonging to the class of \\emph{symmetric hyperbolic thermodynamically compatible} (SHTC) systems was studied in detail in \\cite{Thein2022}. There the question was raised whether the dissipative structure introduced by the source terms satisfies the Shizuta-Kawashima condition. This well-known condition is a sufficient criterion for the existence of global smooth solutions of the studied system. In this work we exploit the dissipative structure of the system under consideration and verify that the Shizuta-Kawashima condition holds.",
        "comments": "Submitted and accepted for the proceedings of the XVIII International Conference on Hyperbolic Problems: Theory, Numerics, Applications. (HYP2022)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14134"
    },
    {
        "doc_id": 165,
        "title": "A note on cohomological vanishing theorems",
        "authors": [
            "Mohsen Asgharzadeh"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We study $cd(M,N):=\\sup\\{j:H^j_{m}(M,N)\\neq0\\}$, and we prove the following over $AB$-rings: $cd(M,N)<\\infty$ iff $cd(M, N)\\leq2 dim R$. For locally free over the punctured spectrum, we present the better bound, namely $cd(M, N)<\\infty$ iff $cd(M, N)\\leq dim R,$ and show this is sharp for maximal Cohen-Macaulay, and prove that this detects freeness of $M$. We present some explicit examples to compute $cd(M, N)$. Now, suppose $R$ is only Cohen-Macaulay and of prime characteristic equipped with the Frobenius map $\\varphi$. We show for some $n\\gg 0$ that $cd(^{\\varphi_n}R,M)<\\infty$ iff $id_R(M)<\\infty.$ This presents some criteria on regularity. Also, some vanishing results on $Ext^i_R(^{\\varphi}R,-)$ are given, where $(-)\\in\\{R,^{\\varphi}R\\}$. We determine conditions under which the vanishing $Ext^i_R(^{\\varphi}R,-)$ of restricted many $i$-th, implies the vanishing of all.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14133"
    },
    {
        "doc_id": 166,
        "title": "Equivariant Manifold Neural ODEs and Differential Invariants",
        "authors": [
            "Emma Andersdotter",
            "Fredrik Ohlsson"
        ],
        "subjects": [
            "Machine Learning",
            "Dynamical Systems"
        ],
        "abstract": "In this paper we develop a manifestly geometric framework for equivariant manifold neural ordinary differential equations (NODEs), and use it to analyse their modelling capabilities for symmetric data. First, we consider the action of a Lie group $G$ on a smooth manifold $M$ and establish the equivalence between equivariance of vector fields, symmetries of the corresponding Cauchy problems, and equivariance of the associated NODEs. We also propose a novel formulation of the equivariant NODEs in terms of the differential invariants of the action of $G$ on $M$, based on Lie theory for symmetries of differential equations, which provides an efficient parameterisation of the space of equivariant vector fields in a way that is agnostic to both the manifold $M$ and the symmetry group $G$. Second, we construct augmented manifold NODEs, through embeddings into equivariant flows, and show that they are universal approximators of equivariant diffeomorphisms on any path-connected $M$. Furthermore, we show that the augmented NODEs can be incorporated in the geometric framework and parameterised using higher order differential invariants. Finally, we consider the induced action of $G$ on different fields on $M$ and show how it can be used to generalise previous work, on, e.g., continuous normalizing flows, to equivariant models in any geometry.",
        "comments": "17 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14131"
    },
    {
        "doc_id": 167,
        "title": "Universal Weil cohomology",
        "authors": [
            "L. Barbieri-Viale",
            "B. Kahn"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Category Theory",
            "K-Theory and Homology",
            "Number Theory"
        ],
        "abstract": "We construct a new Weil cohomology for smooth projective varieties over a field, universal among Weil cohomologies with values in rigid additive tensor categories. A similar universal problem for Weil cohomologies with values in rigid abelian tensor categories also has a solution. We give a variant for Weil cohomologies satisfying more axioms, like Weak and Hard Lefschetz. As a consequence, we get a different construction of Andr\u00e9's category of motives for motivated correspondences and show that it has a universal property. This theory extends over suitable bases.",
        "comments": "MSC Class:          18F99; 14F99",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14127"
    },
    {
        "doc_id": 168,
        "title": "On the length of an arithmetic progression of the form ${3^x+2^y}$",
        "authors": [
            "Hongnan Chen",
            "Fenglin Huang",
            "Sihui Zhang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "The conclusion that the length of an arithmetic progression of the form ${3^x+2^y}$ is at most six is proved.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14125"
    },
    {
        "doc_id": 169,
        "title": "Epimorphisms and Acyclic Types in Univalent Mathematics",
        "authors": [
            "Ulrik Buchholtz",
            "Tom de Jong",
            "Egbert Rijke"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Algebraic Topology",
            "Category Theory"
        ],
        "abstract": "We characterize the epimorphisms in homotopy type theory (HoTT) as the fiberwise acyclic maps and develop a type-theoretic treatment of acyclic maps and types in the context of synthetic homotopy theory. We present examples and applications in group theory, such as the acyclicity of the Higman group, through the identification of groups with $0$-connected, pointed $1$-types. Many of our results are formalized as part of the agda-unimath library.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14106"
    },
    {
        "doc_id": 170,
        "title": "Inverse source problem for discrete Helmholtz equation",
        "authors": [
            "Roman Novikov",
            "Basant Lal Sharma"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "We consider multi-frequency inverse source problem for the discrete Helmholtz operator on the square lattice $\\mathbb{Z}^d$, $d \\ge 1$. We consider this problem for the cases with and without phase information. We prove uniqueness results and present examples of non-uniqueness for this problem for the case of compactly supported source function. Relations with inverse scattering problem for the discrete Schr\u00f6dinger operators in the Born approximation are also provided.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14103"
    },
    {
        "doc_id": 171,
        "title": "Large time behavior of solutions to semilinear evolution inequalities in an annulus: the critical cases",
        "authors": [
            "Meiirkhan B. Borikhanov",
            "Berikbol T. Torebek"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In the present paper, we consider the parabolic and hyperbolic inequalities with a singular potentials and with a critical nonlinearities in the annulus domain. The problems are studied with Neumann-type and Dirichlet-type boundary conditions on the boundary. Moreover, we study the systems of problems too. We have proved that the above problems are globally unsolvable in critical cases, thereby filling the gaps the recent results by Jleli and Samet in [J. Math. Anal. Appl. 514: 2 (2022)] and in [Anal. Math. Phys. 12: 90 (2022)]. Proofs are carried out using the method of test functions with logarithmic arguments, which is being developed for the first time in bounded domains.",
        "comments": "22 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14102"
    },
    {
        "doc_id": 172,
        "title": "Randomized Complexity of Mean Computation and the Adaption Problem",
        "authors": [
            "Stefan Heinrich"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Recently the adaption problem of Information-Based Complexity (IBC) for linear problems in the randomized setting was solved in Heinrich (J. Complexity 82, 2024, 101821). Several papers treating further aspects of this problem followed. However, all examples obtained so far were vector-valued. In this paper we settle the scalar-valued case. We study the complexity of mean computation in finite dimensional sequence spaces with mixed $L_p^N$ norms. We determine the $n$-th minimal errors in the randomized adaptive and non-adaptive setting. It turns out that among the problems considered there are examples where adaptive and non-adaptive $n$-th minimal errors deviate by a power of $n$. The gap can be (up to log factors) of the order $n^{1/4}$. We also show how to turn such results into infinite dimensional examples with suitable deviation for all $n$ simultaneously.",
        "comments": "35 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14100"
    },
    {
        "doc_id": 173,
        "title": "On a transformation of triple $q$-series and Rogers--Hecke type series",
        "authors": [
            "Zhi-Guo Liu"
        ],
        "subjects": [
            "Complex Variables",
            "Combinatorics",
            "Number Theory",
            "Quantum Algebra"
        ],
        "abstract": "Using the method of $q$-exponential differential operator we give an extension of the Sears $_4\u03c6_3$ transformation formula. Based on this extended formula and a $q$-series expansion formula for an analytic function around the origin, we present a transformation formula for triple $q$-series, which includes several interesting special cases, especially a double $q$-series summation formula. Some application of this transformation formula to Rogers--Hecke type series are discussed. More than 100 Rogers--Hecke type identities including Andrews's identities for the sums of three squares and the sums of three triangular numbers are obtained.",
        "comments": "41pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14099"
    },
    {
        "doc_id": 174,
        "title": "Prescribed mean curvature hypersurfaces in conformal product manifolds",
        "authors": [
            "Qiang Gao",
            "Hengyu Zhou"
        ],
        "subjects": [
            "Differential Geometry",
            "Analysis of PDEs"
        ],
        "abstract": "In this paper we give the existence of prescribed mean curvature (PMC) hypersurfaces in conformal product manifolds with (possibly empty) $C^{1,\u03b1}$ fixed graphical boundaries under a barrier condition. This generalizes Gerhardt's result in conformally flat spaces. It provides new examples of the Plateau problem of PMC hypersurfaces with clear topology under high dimensions. In addition, if a quasi-decreasing condition of PMC functions is satisfied, such PMC hypersurfaces are $C^1$ graphs.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14097"
    },
    {
        "doc_id": 175,
        "title": "The admissible KMS bundles on classifiable C$^*$-algebras",
        "authors": [
            "Robert Neagu"
        ],
        "subjects": [
            "Operator Algebras"
        ],
        "abstract": "Given any unital, finite, classifiable C$^*$-algebra $A$ with real rank zero and any compact simplex bundle with the fibre at zero being homeomorphic to the space of tracial states on $A$, we show that there exists a flow on $A$ realising this simplex. Moreover, we show that given any unital UCT Kirchberg algebra $A$ and any proper simplex bundle with empty fibre at zero, there exists a flow on $A$ realising this simplex.",
        "comments": "35 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14096"
    },
    {
        "doc_id": 176,
        "title": "ODC and ROC curves, comparison curves, and stochastic dominance",
        "authors": [
            "Teresa Ledwina",
            "Adam Zagda\u0144ski"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "We discuss two novel approaches to the classical two-sample problem. Our starting point are properly standardized and combined, very popular in several areas of statistics and data analysis, ordinal dominance and receiver characteristic curves, denoted by ODC and ROC, respectively. The proposed new curves are termed the comparison curves. Their estimates, being weighted rank processes on (0,1), form the basis of inference. These weighted processes are intuitive, well-suited for visual inspection of data at hand, and are also useful for constructing some formal inferential procedures. They can be applied to several variants of two-sample problem. Their use can help to improve some existing procedures both in terms of power and the ability to identify the sources of departures from the postulated model. To simplify interpretation of finite sample results we restrict attention to values of the processes on a finite grid of points. This results in the so-called bar plots (B-plots) which readably summarize the information contained in the data. What is more, we show that B-plots along with adjusted simultaneous acceptance regions provide principled information about where the model departs from the data. This leads to a framework which facilitates identification of regions with locally significant differences.\n  We show an implementation of the considered techniques to a standard stochastic dominance testing problem. Some min-type statistics are introduced and investigated. A simulation study compares two tests pertinent to the comparison curves to well-established tests in the literature and demonstrates the strong and competitive performance of the former in many typical situations. Some real data applications illustrate simplicity and practical usefulness of the proposed approaches. A range of other applications of considered weighted processes is briefly discussed too.",
        "comments": "45 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14094"
    },
    {
        "doc_id": 177,
        "title": "Generating Likely Counterfactuals Using Sum-Product Networks",
        "authors": [
            "Jiri Nemecek",
            "Tomas Pevny",
            "Jakub Marecek"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI systems need to be explained. These decisions are often explainable only post hoc, where counterfactual explanations are popular. The question of what constitutes the best counterfactual explanation must consider multiple aspects, where \"distance from the sample\" is the most common. We argue that this requirement frequently leads to explanations that are unlikely and, therefore, of limited value. Here, we present a system that provides high-likelihood explanations. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest. A numerical comparison against several methods for generating counterfactual explanations is provided.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14086"
    },
    {
        "doc_id": 178,
        "title": "Accelerating Fractional PINNs using Operational Matrices of Derivative",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis"
        ],
        "abstract": "This paper presents a novel operational matrix method to accelerate the training of fractional Physics-Informed Neural Networks (fPINNs). Our approach involves a non-uniform discretization of the fractional Caputo operator, facilitating swift computation of fractional derivatives within Caputo-type fractional differential problems with $0<\u03b1<1$. In this methodology, the operational matrix is precomputed, and during the training phase, automatic differentiation is replaced with a matrix-vector product. While our methodology is compatible with any network, we particularly highlight its successful implementation in PINNs, emphasizing the enhanced accuracy achieved when utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates Legendre polynomials into the PINN structure, providing a significant boost in accuracy. The effectiveness of our proposed method is validated across diverse differential equations, including Delay Differential Equations (DDEs) and Systems of Differential Algebraic Equations (DAEs). To demonstrate its versatility, we extend the application of the method to systems of differential equations, specifically addressing nonlinear Pantograph fractional-order DDEs/DAEs. The results are supported by a comprehensive analysis of numerical outcomes.",
        "comments": "19 pages, 11 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14081"
    },
    {
        "doc_id": 179,
        "title": "Minimal doubling for small subsets in compact Lie groups",
        "authors": [
            "Simon Machado"
        ],
        "subjects": [
            "Group Theory",
            "Combinatorics"
        ],
        "abstract": "We prove a sharp bound for the minimal doubling of a small measurable subset of a compact connected Lie group. Namely, let $G$ be a compact connected Lie group of dimension $d_G$, we show that for every $\u03b5> 0$ and for all measurable subsets $A$ of small enough Haar measure, we have\n  $$ \u03bc_G(A^2) > \\left(2^{d_G - d_H}-\u03b5\\right)\u03bc_G(A)$$\n  where $d_H$ is the maximal dimension of a proper closed subgroup $H$. This settles a conjecture of Breuillard and Green and recovers - with completely different methods - a recent result of Jing--Tran--Zhang corresponding to the case $G=SO_3(\\mathbb{R})$.\n  Going beyond the scope of this conjecture, our methods enable us to prove a stability result asserting that the only subsets close to saturating this inequality are essentially neighbourhoods of proper subgroups i.e. of the form\n  $$H_\u03b4:=\\{g \\in G: d(g,H)<\u03b4\\}$$\n  where $H$ denotes a maximal closed subgroup, $d$ denotes a bi-invariant distance on $G$ and $\u03b4>0$.\n  Our approach relies on two \\emph{a priori} unrelated toolsets: optimal transports and its recent applications to the Brunn--Minkowski inequality, and the structure theory of compact approximate subgroups.",
        "comments": "34 pages; comments welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14062"
    },
    {
        "doc_id": 180,
        "title": "On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications",
        "authors": [
            "Arnold Filtser"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Computational Geometry",
            "Combinatorics"
        ],
        "abstract": "Given a metric space $(X,d_X)$, a $(\u03b2,s,\u0394)$-sparse cover is a collection of clusters $\\mathcal{C}\\subseteq P(X)$ with diameter at most $\u0394$, such that for every point $x\\in X$, the ball $B_X(x,\\frac\u0394\u03b2)$ is fully contained in some cluster $C\\in \\mathcal{C}$, and $x$ belongs to at most $s$ clusters in $\\mathcal{C}$. Our main contribution is to show that the shortest path metric of every $K_r$-minor free graphs admits $(O(r),O(r^2),\u0394)$-sparse cover, and for every $\u03b5>0$, $(4+\u03b5,O(\\frac1\u03b5)^r,\u0394)$-sparse cover (for arbitrary $\u0394>0$). We then use this sparse cover to show that every $K_r$-minor free graph embeds into $\\ell_\\infty^{\\tilde{O}(\\frac1\u03b5)^{r+1}\\cdot\\log n}$ with distortion $3+\\eps$ (resp. into $\\ell_\\infty^{\\tilde{O}(r^2)\\cdot\\log n}$ with distortion $O(r)$). Further, we provide applications of these sparse covers into padded decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy at bulk, name independent routing, and path reporting distance oracles.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14060"
    },
    {
        "doc_id": 181,
        "title": "Functors induced by comma categories",
        "authors": [
            "Suddhasattwa Das"
        ],
        "subjects": [
            "Category Theory"
        ],
        "abstract": "The purpose of category theory is to provide a collective description of many arrangements in mathematics, such as topological space, Banach spaces and game theory. Within this collective description, the perspective from any individual member of the collection is provided by its associated left or right slice. The assignment of slices to objects extends to a functor from the base category, into the category of categories. We extend this observation to a more general situation of two categories $\\mathcal{A}$ and $\\mathcal{B}$ mapping into a third category $\\mathcal{C}$, via functors $F,G$. Such arrangements abound in mathematics, and are studied via the comma category $\\left[ F; G\\right]$. Objects in this category are morphisms between objects of $\\mathcal{A}$ and $\\mathcal{B}$, via the functors $F,G$. We show that these objects also have a natural interpretation as functors between slice categories of $\\mathcal{A}$ and $\\mathcal{B}$. Thus even though $\\mathcal{A}$ and $\\mathcal{B}$ may have completely disparate structures, some functors between their slices can be interpreted as morphisms in $\\mathcal{C}$.",
        "comments": "MSC Class:          18A05; 18A40; 18A35; 18A25",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14059"
    },
    {
        "doc_id": 182,
        "title": "A Wells-like exact sequence for abelian extensions of relative Rota--Baxter groups",
        "authors": [
            "Pragya Belwal",
            "Nishant Rathee"
        ],
        "subjects": [
            "Group Theory",
            "Quantum Algebra",
            "Rings and Algebras"
        ],
        "abstract": "Relative Rota--Baxter groups, a generalization of Rota--Baxter groups, are closely connected to skew left braces, which play a fundamental role in understanding non-degenerate set-theoretical solutions to the Yang-Baxter equation. In this paper, we explore the inducibility problem for automorphisms of abelian extensions of relative Rota--Baxter groups. This problem is intricately linked to the recently introduced second cohomology of relative Rota--Baxter groups. Specifically, we prove a Wells-like exact sequence for abelian extensions of relative Rota--Baxter groups. The sequence establishes a connection among the group of derivations, certain automorphism group, and the second cohomology of relative Rota--Baxter groups, thereby giving precise structural relationships between these groups.",
        "comments": "22 pages. arXiv admin note: text overlap with arXiv:2309.00692, arXiv:2311.12384",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14058"
    },
    {
        "doc_id": 183,
        "title": "Multi-machine preventative maintenance scheduling with imperfect interventions: a restless bandit approach",
        "authors": [
            "Diego Ruiz-Hernandez",
            "Jes\u00fas Mar\u00eda Pinar-P\u00e9rez",
            "David Delgado-G\u00f3mez"
        ],
        "subjects": [
            "Discrete Mathematics",
            "Numerical Analysis"
        ],
        "abstract": "In this paper we address the problem of allocating the efforts of a collection of repairmen to a number of deteriorating machines in order to reduce operation costs and to mitigate the cost (and likelihood) of unexpected failures. Notwithstanding these preventive maintenance interventions are aimed at returning the machine to a so-called as-good-as-new state, unforeseeable factors may imply that maintenance interventions are not perfect and the machine is only returned to an earlier (uncertain) state of wear. The problem is modelled as a restless bandit problem and an index policy for the sequential allocation of maintenance tasks is proposed. A series of numerical experiments shows the strong performance of the proposed policy. Moreover, the methodology is of interest in the general context of dynamic resource allocation and restless bandit problems, as well as being useful in the particular imperfect maintenance model described.",
        "comments": "Published in Computers and Operations Research (ELSEVIER), July 2020. DOI: https://doi.org/10.1016/j.cor.2020.104927 Article available under the terms of the CC-BY-NC-ND licence",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14055"
    },
    {
        "doc_id": 184,
        "title": "Small cover approach to the suprema of positive canonical processes",
        "authors": [
            "Witold Bednorz",
            "Rafa\u0142 Martynek",
            "Rafa\u0142 Meller"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "We extend the recent result of Park and Pham concerning the positive selector process to canonical processes generated by i.i.d. nonnegative random variables satisfying minimal tail assumptions. We also provide a result of the same nature for canonical processes based on general i.i.d. positive variables.",
        "comments": "MSC Class:          60G15; 60G17",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14045"
    },
    {
        "doc_id": 185,
        "title": "P-measures in models without P-points",
        "authors": [
            "Piotr Borodulin-Nadzieja",
            "Jonathan Cancino-Manr\u00edquez",
            "Adam Morawski"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "We answer in negative the problem if the existence of a P-measure implies the existence of a P-point. Namely, we show that if we add random reals to a certain unique P-point model, then in the resulting model we will have a P-measure but not P-points. Also, we investigate the question if there is a P-measure in the Silver model. We show that rapid filters cannot be extended to a P-measure in the extension by $\u03c9$ product of Silver forcings and that in the model obtained by the product of $\u03c9_2$ many Silver forcings there are no P-measures of countable Maharam type",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14042"
    },
    {
        "doc_id": 186,
        "title": "Fredholm determinants, continued fractions, Jost and Evans functions for a Jacobi matrix associated with the 2D-Euler equations",
        "authors": [
            "Yuri Latushkin",
            "Shibi Vasudevan"
        ],
        "subjects": [
            "Spectral Theory",
            "Mathematical Physics",
            "Analysis of PDEs",
            "Fluid Dynamics"
        ],
        "abstract": "For a second order difference equation that arises in the study of stability of unidirectional (generalized Kolmogorov) flows for the Euler equations of ideal fluids on the two dimensional torus, we relate the following five functions of the spectral parameter: the Fredholm determinants of the Birman-Schwinger operator pencils associated with the second order equation and the equivalent system of the first order equations; the Jost function constructed by means of the Jost solutions of the second order equation; the Evans function constructed by means of the matrix valued Jost solutions of the first order system, and, finally, to backward and forward continued fractions associated with the second order difference equation. We prove that all five functions are equal, and that their zeros are the discrete eigenvalues of the second order difference equation. We use this to improve an instability result for a generalization of the Kolmogorov (unidirectional) flow for the Euler equation on the 2D torus.",
        "comments": "Results in this paper improve and extend the results of arXiv:1901.01367v3 on the instability of unidirectional flows",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14037"
    },
    {
        "doc_id": 187,
        "title": "Towards a Systems Theory of Algorithms",
        "authors": [
            "Florian D\u00f6rfler",
            "Zhiyu He",
            "Giuseppe Belgioioso",
            "Saverio Bolognani",
            "John Lygeros",
            "Michael Muehlebach"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Traditionally, numerical algorithms are seen as isolated pieces of code confined to an {\\em in silico} existence. However, this perspective is not appropriate for many modern computational approaches in control, learning, or optimization, wherein {\\em in vivo} algorithms interact with their environment. Examples of such {\\em open} include various real-time optimization-based control strategies, reinforcement learning, decision-making architectures, online optimization, and many more. Further, even {\\em closed} algorithms in learning or optimization are increasingly abstracted in block diagrams with interacting dynamic modules and pipelines. In this opinion paper, we state our vision on a to-be-cultivated {\\em systems theory of algorithms} and argue in favour of viewing algorithms as open dynamical systems interacting with other algorithms, physical systems, humans, or databases. Remarkably, the manifold tools developed under the umbrella of systems theory also provide valuable insights into this burgeoning paradigm shift and its accompanying challenges in the algorithmic world. We survey various instances where the principles of algorithmic systems theory are being developed and outline pertinent modeling, analysis, and design challenges.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14029"
    },
    {
        "doc_id": 188,
        "title": "Comparison of modularity-based approaches for nodes clustering in binary hypergraphs",
        "authors": [
            "Veronica Poda",
            "Catherine Matias"
        ],
        "subjects": [
            "Social and Information Networks",
            "Combinatorics",
            "Data Analysis, Statistics and Probability",
            "Applications"
        ],
        "abstract": "We conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14028"
    },
    {
        "doc_id": 189,
        "title": "On $p$-adic Minkowski's Theorems",
        "authors": [
            "Yingpu Deng"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Dual lattice is an important concept of Euclidean lattices. In this paper, we first give the right definition of the concept of the dual lattice of a $p$-adic lattice from the duality theory of locally compact abelian groups. The concrete constructions of ``basic characters'' of local fields given in Weil's famous book ``Basic Number Theory'' help us to do so. We then prove some important properties of the dual lattice of a $p$-adic lattice, which can be viewed as $p$-adic analogues of the famous Minkowski's first, second theorems for Euclidean lattices. We do this simultaneously for local fields $\\mathbb{Q}_p$ (the field of $p$-adic numbers) and $\\mathbb{F}_p((T))$ (the field of formal power-series of one indeterminate with coefficients in the finite field with $p$ elements).",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14023"
    },
    {
        "doc_id": 190,
        "title": "Orbit problems for free-abelian times free groups and related families",
        "authors": [
            "Andr\u00e9 Carvalho",
            "Jordi Delgado"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "We prove that the Brinkmann Problems (BrP & BrCP) and the twisted-conjugacy Problem (TCP) are decidable for any endomorphism of a free-abelian times free (FATF) group Fn x Z^m. Furthermore, we prove the decidability of the two-sided Brinkmann conjugacy problem (2BrCP) for monomorphisms of FATF groups (and combine it with TCP) to derive the decidability of the conjugacy problem for ascending HNN extensions of FATF groups.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14020"
    },
    {
        "doc_id": 191,
        "title": "Low-rank matrices, tournaments, and symmetric designs",
        "authors": [
            "Niranjan Balachandran",
            "Brahadeesh Sankarnarayanan"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Let $\\mathbf{a} = (a_{i})_{i \\geq 1}$ be a sequence in a field $\\mathbb{F}$, and $f \\colon \\mathbb{F} \\times \\mathbb{F} \\to \\mathbb{F}$ be a function such that $f(a_{i},a_{i}) \\neq 0$ for all $i \\geq 1$. For any tournament $T$ over $[n]$, consider the $n \\times n$ symmetric matrix $M_{T}$ with zero diagonal whose $(i,j)$th entry (for$(i < j$) is $f(a_{i},a_{j})$ if $i \\to j$ in $T$, and $f(a_{j},a_{i})$ if $j \\to i$ in $T$. It is known (cf. Balachandran et al, Linear Algebra Appl. 658 (2023), 310-318) that if $T$ is a uniformly random tournament over $[n]$, then $\\operatorname{rank}(M_{T}) \\geq (\\frac{1}{2}-o(1))n$ with high probability when $\\operatorname{char}(\\mathbb{F}) \\neq 2$ and $f$ is a linear function.\n  In this paper, we investigate the other extremal question: how low can the ranks of such matrices be? We work with sequences $\\mathbf{a}$ that take only two distinct values, so the rank of any such $n \\times n$ matrix is at least $n/2$. First, we show that the rank of any such matrix depends on whether an associated bipartite graph has certain eigenvalues of high multiplicity. Using this, we show that if $f$ is linear, then there are real matrices $M_{T}(f;\\mathbf{a})$ of rank at most $\\frac{n}{2} + O(1)$. For rational matrices, we show that for each $\\varepsilon > 0$ we can find a sequence $\\mathbf{a}(\\varepsilon)$ for which there are matrices $M_{T}(f;\\mathbf{a})$ of rank at most $(\\frac{1}{2} + \\varepsilon)n + O(1)$. These matrices are constructed from symmetric designs, and we also use them to produce bisection-closed families of size greater than $\\lfloor 3n/2 \\rfloor - 2$ for $n \\leq 15$, which improves the previously best known bound (cf. Balachandran et al, Electron J. Combin. 26 (2019), #P2.40).",
        "comments": "11 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14015"
    },
    {
        "doc_id": 192,
        "title": "Measuring multidimensional inequality: a new proposal based on the Fourier transform",
        "authors": [
            "Paolo Giudici",
            "Emanuela Raffinetti",
            "Giuseppe Toscani"
        ],
        "subjects": [
            "Physics and Society",
            "Information Theory",
            "Probability"
        ],
        "abstract": "Inequality measures are quantitative measures that take values in the unit interval, with a zero value characterizing perfect equality. Although originally proposed to measure economic inequalities, they can be applied to several other situations, in which one is interested in the mutual variability between a set of observations, rather than in their deviations from the mean. While unidimensional measures of inequality, such as the Gini index, are widely known and employed, multidimensional measures, such as Lorenz Zonoids, are difficult to interpret and computationally expensive and, for these reasons, are not much well known. To overcome the problem, in this paper we propose a new scaling invariant multidimensional inequality index, based on the Fourier transform, which exhibits a number of interesting properties, and whose application to the multidimensional case is rather straightforward to calculate and interpret.",
        "comments": "arXiv admin note: text overlap with arXiv:2310.20483",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14012"
    },
    {
        "doc_id": 193,
        "title": "Lifting multiplicative lattices to ideal sytems",
        "authors": [
            "Tiberiu Dumitrescu",
            "Mihai Epure",
            "Alexandru Gica"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We present a mechanism which lifts a multiplicative lattice to a (weak) ideal system on some monoid.",
        "comments": "6 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14001"
    },
    {
        "doc_id": 194,
        "title": "Optimal Degenerations of K-unstable Fano threefolds",
        "authors": [
            "Minghao Miao",
            "Linsheng Wang"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Differential Geometry"
        ],
        "abstract": "We explicitly determine the optimal degenerations of Fano threefolds $X$ in family No 2.23 of Mori-Mukai's list as predicted by the Hamilton-Tian conjecture. More precisely, we find a special degeneration $(\\mathcal{X}, \u03be_0)$ of $X$ such that $(\\mathcal{X}_0, \u03be_0)$ is weighted K-polystable, which is equivalent to $(\\mathcal{X}_0, \u03be_0)$ admitting a K\u00e4hler-Ricci soliton (KRS) by \\cite{HL23} and \\cite{BLXZ23}. Furthermore, we study the moduli spaces of $(\\mathcal{X}_0, \u03be_0)$. The $\\mathbf{H}$-invariant of $X$ divides the natural parameter space into two strata, which leads to different moduli spaces of KRS Fano varieties. We show that one of them is isomorphic to the GIT-moduli space of biconic curves $C\\subseteq \\mathbb{P}^1\\times \\mathbb{P}^1$, and the other one is a single point.",
        "comments": "28 pages, comments are very welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13999"
    },
    {
        "doc_id": 195,
        "title": "A Combinatorial Formula for the Wedderburn Decomposition of Rational Group Algebras of Split Metacyclic $p$-groups",
        "authors": [
            "Ram Karan Choudhary",
            "Sunil Kumar Prajapati"
        ],
        "subjects": [
            "Representation Theory",
            "Rings and Algebras"
        ],
        "abstract": "In this article, we present a concise combinatorial formula for efficiently determining the Wedderburn decomposition of rational group algebra associated with a split metacyclic $p$-group $G$, where $p$ is an odd prime. We also provide a combinatorial formula to count irreducible rational representations of $G$ of distinct degrees.",
        "comments": "arXiv admin note: text overlap with arXiv:2106.12781 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13994"
    },
    {
        "doc_id": 196,
        "title": "Inclusions of simple C$^*$-algebras arising from compact group actions",
        "authors": [
            "Miho Mukohara"
        ],
        "subjects": [
            "Operator Algebras"
        ],
        "abstract": "Inclusions of operator algebras have long been studied. In particular, inclusions arising from actions of compact groups on factors were studied by Izumi-Longo-Popa and others. The correspondence between intermediate subfactors and subgroups is called the Galois correspondence. Analogues for actions on C$^*$-algebras have been studied by Izumi, Cameron-Smith, Peligrad, and others. In this article, we give examples of compact group actions on simple C$^*$-algebras for which the Galois correspondence holds.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13989"
    },
    {
        "doc_id": 197,
        "title": "Homogeneity of magnetic trajectories in the real special linear group",
        "authors": [
            "Jun-ichi Inoguchi",
            "Marian-Ioan Munteanu"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "We prove the homogeneity of contact magnetic curves in the real special linear group of degree $2$. Every contact magnetic trajectory is a product of a homogeneous geodesic and a charged Reeb flow.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13988"
    },
    {
        "doc_id": 198,
        "title": "A new analysis of empirical interpolation methods and Chebyshev greedy algorithms",
        "authors": [
            "Yuwen Li"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We present new convergence estimates of generalized empirical interpolation methods in terms of the entropy numbers of the parametrized function class. Our analysis is transparent and leads to sharper convergence rates than the classical analysis via the Kolmogorov n-width. In addition, we also derive novel entropy-based convergence estimates of the Chebyshev greedy algorithm for sparse n-term nonlinear approximation of a target function. This also improves classical convergence analysis when corresponding entropy numbers decay fast enough.",
        "comments": "MSC Class:          41A46; 41A65; 65J05; 65M12",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13985"
    },
    {
        "doc_id": 199,
        "title": "Squarefree numbers in short intervals",
        "authors": [
            "Mayank Pandey"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We show that there exists $\u03b7> 0$ such that the interval $[X, X + X^{\\frac 15 - \u03b7}]$ contains a squarefree number for all large $X$. This improves on an earlier result of Filaseta and Trifonov who showed that there is a squarefree number in $[X, X + cX^{\\frac 15}\\log X]$ for some $c > 0$ and all large $X$.\n  We introduce a new technique to count lattice points near curves, which we use to bound in critical ranges the number of integers in a short interval divisible by a large square. This uses as an input Green and Tao's quantitative version of Leibman's theorem on the equidistribution of polynomial orbits in nilmanifolds.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13981"
    },
    {
        "doc_id": 200,
        "title": "Nucleosynthesis in magnetorotational supernovae: impact of the magnetic field configuration",
        "authors": [
            "M. Reichert",
            "M. Bugli",
            "J. Guilet",
            "M. Obergaulinger",
            "M. \u00c1. Aloy",
            "A. Arcones"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "The production of heavy elements is one of the main by-products of the explosive end of massive stars. A long sought goal is finding differentiated patterns in the nucleosynthesis yields, which could permit identifying a number of properties of the explosive core. Among them, the traces of the magnetic field topology are particularly important for \\emph{extreme} supernova explosions, most likely hosted by magnetorotational effects. We investigate the nucleosynthesis of five state-of-the-art magnetohydrodynamic models with fast rotation that have been previously calculated in full 3D and that involve an accurate neutrino transport (M1). One of the models does not contain any magnetic field and synthesizes elements around the iron group, in agreement with other CC-SNe models in literature. All other models host a strong magnetic field of the same intensity, but with different topology. For the first time, we investigate the nucleosynthesis of MR-SNe models with a quadrupolar magnetic field and a 90 degree tilted dipole. We obtain a large variety of ejecta compositions reaching from iron nuclei to nuclei up to the third r-process peak. We assess the robustness of our results by considering the impact of different nuclear physics uncertainties such as different nuclear masses, $\u03b2^{-}$-decays and $\u03b2^{-}$-delayed neutron emission probabilities, neutrino reactions, fission, and a feedback of nuclear energy on the temperature. We find that the qualitative results do not change with different nuclear physics input. The properties of the explosion dynamics and the magnetic field configuration are the dominant factors determining the ejecta composition.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14402"
    },
    {
        "doc_id": 201,
        "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes",
        "authors": [
            "Ege Ozguroglu",
            "Ruoshi Liu",
            "D\u00eddac Sur\u00eds",
            "Dian Chen",
            "Achal Dave",
            "Pavel Tokmakov",
            "Carl Vondrick"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.",
        "comments": "Website: https://gestalt.cs.columbia.edu/",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14398"
    },
    {
        "doc_id": 202,
        "title": "Entanglement entropy and deconfined criticality: emergent SO(5) symmetry and proper lattice bipartition",
        "authors": [
            "Jonathan D'Emidio",
            "Anders W. Sandvik"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "High Energy Physics - Lattice"
        ],
        "abstract": "We study the R\u00e9nyi entanglement entropy (EE) of the two-dimensional $J$-$Q$ model, the emblematic quantum spin model of deconfined criticality at the phase transition between antiferromagnetic and valence-bond-solid ground states. Quantum Monte Carlo simulations with an improved EE scheme reveal critical corner contributions that scale logarithmically with the system size, with a coefficient in remarkable agreement with the form expected from a large-$N$ conformal field theory with SO($N=5$) symmetry. However, details of the bipartition of the lattice are crucial in order to observe this behavior. If the subsystem for the reduced density matrix does not properly accommodate valence-bond fluctuations, logarithmic contributions appear even for corner-less bipartitions. We here use a $45^\\circ$ tilted cut on the square lattice. Beyond supporting an SO($5$) deconfined quantum critical point, our results for both the regular and tilted cuts demonstrate important microscopic aspects of the EE that are not captured by conformal field theory.",
        "comments": "5 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14396"
    },
    {
        "doc_id": 203,
        "title": "Summing up perturbation series around superintegrable point",
        "authors": [
            "A. Mironov",
            "A. Morozov",
            "A. Popolitov",
            "Sh. Shakirov"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Mathematical Physics"
        ],
        "abstract": "We work out explicit formulas for correlators in the Gaussian matrix model perturbed by a logarithmic potential, i.e. by inserting Miwa variables. In this paper, we concentrate on the example of a single Miwa variable. The ordinary Gaussian model is superintegrable, i.e. the average of the Schur functions $S_Q$ is an explicit function of the Young diagram $Q$. The question is what happens to this property after perturbation. We show that the entire perturbation series can be nicely summed up into a kind of Borel transform of a universal exponential function, while the dependence on $R$ enters through a polynomial factor in front of this exponential. Moreover, these polynomials can be described explicitly through a single additional structure, which we call ``truncation'' of the Young diagram $Q$. It is unclear if one can call this an extended superintegrability, but at least it is a tremendously simple deformation of it. Moreover, the vanishing Gaussian correlators remain vanishing and, hence, are not deformed at all.",
        "comments": "15 pages + Appendix (7 pages)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14392"
    },
    {
        "doc_id": 204,
        "title": "Weakening of magnetic braking in cataclysmic variables explains the dearth of period bouncers",
        "authors": [
            "Arnab Sarkar",
            "Antonio C. Rodriguez",
            "Sivan Ginzburg",
            "Lev Yungelson",
            "Christopher A. Tout"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Period bouncers are cataclysmic variables (CVs) that have evolved past their orbital period minimum. The strong disagreement between theory and observations of the relative fraction of period bouncers is a severe shortcoming in the understanding of CV evolution. We test the implications of the hypothesis that magnetic braking (MB), which is suggested to be an additional angular momentum loss (AML) mechanism for CVs below the period gap ($P_\\mathrm{orb}\\lesssim 120$ min), weakens around their period minimum. We compute the evolution of CV donors below the period gap using the MESA code, assuming that the evolution of the system is driven by AML by gravitational wave radiation (GWR) and MB. We parametrize the MB strength as $\\mathrm{AML_{MB}}=\u03ba\\mathrm{AML_{GWR}}$. We compute two qualitatively different sets of models, one where $\u03ba$ is a constant and the other where $\u03ba$ depends on stellar parameters. We find that in the latter set of models, $\u03ba$ decreases as the CV approaches the period minimum ($P_\\mathrm{orb}\\approx80\\,$ min), beyond which $\u03ba\\approx0$. This stalls their evolution so that they spend a long time in the observed period minimum spike ($80\\lesssim P_\\mathrm{orb}/\\,\\mathrm{min}\\lesssim 86$). Here they become difficult to distinguish from pre-bounce systems in the spike. A strong decrease in mass-transfer rate makes them virtually undetectable as they evolve further. We also discuss the physical processes, such as dynamo action, white dwarf magnetism and dead zones, that may cause such a weakening of MB at short orbital periods. The weakening magnetic braking formalism solves the problem of the lack of period bouncers in CV observational surveys.",
        "comments": "Submitted to A&A Letters. Comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14389"
    },
    {
        "doc_id": 205,
        "title": "Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem",
        "authors": [
            "Kaifeng Bu",
            "Weichen Gu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We establish an entropic, quantum central limit theorem and quantum inverse sumset theorem in discrete-variable quantum systems describing qudits or qubits. Both results are enabled by using our recently-discovered quantum convolution. We show that the exponential rate of convergence of the entropic central limit theorem is bounded by the magic gap. We also establish an ``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose a conjecture called ``convolutional strong subaddivity,'' which leads to the triangle inequality for the quantum Ruzsa divergence. A byproduct of this work is a magic measure to quantify the nonstabilizer nature of a state, based on the quantum Ruzsa divergence.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14385"
    },
    {
        "doc_id": 206,
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "subjects": [
            "Computational Complexity",
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We devise a parameterized family of distributions, the high-entropy step distributions (HES), which are expressive enough to capture near-optima of spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime and yet permit low-degree Sum-of-Squares (SoS) certificates that no such distribution can achieve value slightly larger than the true optimum. This yields a SoS optimization program and rounding scheme that attains near-optimal solutions for spherical spin glasses in the fRSB regime. In other regimes, the same results occur at the ALG value, which is a conjectured best-value attainable by any polynomial time algorithm. These SoS programs optimize over families of distributions of possible solutions, and circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure by instead proving the same bounds only in expectation on solution distributions that can be produced by the chosen rounding algorithm. The new SoS hierarchy does not make any specific reference to the spherical spin glass problem, and we conjecture that it can be applied to a broad range of average-case problems to obtain value that is optimal among polynomial-time algorithms. We give evidence for this with examples of ensembles that provably fool certain local iterative algorithms but for which there is either proof or evidence that the SoS program is better. This opens the door to addressing a question posed by Barak about the possible optimality of SoS on average-case optimization problems, and by Schramm about reductions between different families of algorithms for average-case problems. In this paper, we give low-degree SoS proofs certifying key properties about HES distributions as well as the ALG threshold for spherical spin glasses. The rounding algorithm is introduced and analyzed in a companion paper.",
        "comments": "130 pages, 0 figures. First of two companion papers",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14383"
    },
    {
        "doc_id": 207,
        "title": "Electrotaxis of self-propelling artificial swimmers in microchannels",
        "authors": [
            "Carola M. Buness",
            "Avi Rana",
            "Corinna C. Maass",
            "Ranabir Dey"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Fluid Dynamics"
        ],
        "abstract": "Ciliated microswimmers and flagellated bacteria alter their swimming trajectories to follow the direction of an applied electric field exhibiting electrotaxis. Both for matters of application and physical modelling, it is instructive to study such behaviour in synthetic swimmers. We show here that under an external electric field, self-propelling active droplets autonomously modify their swimming trajectories in microchannels, even undergoing `U-turns', to exhibit robust electrotaxis. Depending on the relative initial orientations of the microswimmer and the external electric field, the active droplet can also navigate upstream of an external flow following a centre-line motion, instead of the oscillatory upstream trajectory observed in absence of electric field. Using a hydrodynamic theory model, we show that the electrically induced angular velocity and electrophoretic effects, along with the microswimmer motility and its hydrodynamic interactions with the microchannel walls, play crucial roles in dictating the electrotactic trajectories and dynamics. Specifically, the transformation in the trajectories during upstream swimming against an external flow under an electric field can be understood as a reverse Hopf bifurcation for a dynamical system. Our study provides a simple methodology and a systematic understanding of manoeuvring active droplets in microconfinements for micro-robotic applications especially in biotechnology.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14376"
    },
    {
        "doc_id": 208,
        "title": "Spatially Resolved Conductivity of Rectangular Interconnects considering Surface Scattering -- Part II: Circuit-Compatible Modeling",
        "authors": [
            "Xinkang Chen",
            "Sumeet Kumar Gupta"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Interconnect conductivity modeling is a critical aspect for modern chip design. Surface scattering -- an important scattering mechanism in scaled interconnects is usually captured using Fuchs-Sondheimer (FS) model which offers the average behavior of the interconnect. However, to support the modern interconnect structures (such as tapered geometries), modeling spatial dependency of conductivity becomes important. In Part I of this work, we presented a spatially resolved FS (SRFS) model for rectangular interconnects derived from the fundamental FS approach. While the proposed SRFS model offers both spatial-dependency of conductivity and its direct relationship with the physical parameters, its complex expression is not suitable for incorporation in circuit simulations. In this part, we build upon our SRFS model to propose a circuit-compatible conductivity model for rectangular interconnects accounting for 2D surface scattering. The proposed circuit-compatible model offers spatial resolution of conductivity as well as explicit dependence on the physical parameters such as electron mean free path ($\u03bb_0$), specularity ($p$) and interconnect geometry. We validate our circuit-compatible model over a range of interconnect width/height (and $\u03bb_0$) and p values and show a close match with the physical SRFS model proposed in Part I (with error < 0.7%). We also compare our circuit-compatible model with a previous spatially resolved analytical model (appropriately modified for a fair comparison) and show that our model captures the spatial resolution of conductivity and the dependence on physical parameters more accurately. Finally, we present a semi-analytical equation for the average conductivity based on our circuit-compatible model.",
        "comments": "10 pages, 8 figures in process to submit to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14374"
    },
    {
        "doc_id": 209,
        "title": "Modeling Global Surface Dust Deposition Using Physics-Informed Neural Networks",
        "authors": [
            "Constanza A. Molina Catricheo",
            "Fabrice Lambert",
            "Julien Salomon",
            "Elwin van 't Wout"
        ],
        "subjects": [
            "Geophysics"
        ],
        "abstract": "Paleoclimatic measurements serve to understand geophysical processes and evaluate climate model performances. However, their spatial coverage is generally sparse and unevenly distributed across the globe. Statistical interpolation methods are the prevalent techniques to grid such data, but these purely data-driven approaches sometimes produce results that are incoherent with our knowledge of the physical world. Physics-Informed Neural Networks (PINNs) follow an innovative approach to data analysis and physical modeling through machine learning, as they incorporate physical principles into the data-driven learning process. Here, we develop PINNs to reconstruct global maps of atmospheric dust surface deposition fluxes from measurement data in paleoclimatic archives, for the Holocene and Last Glacial Maximum periods. We design an advection-diffusion equation to consider dominant wind directions at various latitudes, which prevents dust particles from flowing upwind. Our PINN improves on standard kriging interpolation by allowing variable asymmetry around data points. The reconstructions display realistic dust plumes from continental sources towards ocean basins following prevailing winds.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14372"
    },
    {
        "doc_id": 210,
        "title": "Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input",
        "authors": [
            "Enrico Picco",
            "Lina Jaurigue",
            "Kathy L\u00fcdge",
            "Serge Massar"
        ],
        "subjects": [
            "Emerging Technologies",
            "Artificial Intelligence",
            "Neural and Evolutionary Computing",
            "Optics"
        ],
        "abstract": "We present an experimental validation of a recently proposed optimization technique for reservoir computing, using an optoelectronic setup. Reservoir computing is a robust framework for signal processing applications, and the development of efficient optimization approaches remains a key challenge. The technique we address leverages solely a delayed version of the input signal to identify the optimal operational region of the reservoir, simplifying the traditionally time-consuming task of hyperparameter tuning. We verify the effectiveness of this approach on different benchmark tasks and reservoir operating conditions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14371"
    },
    {
        "doc_id": 211,
        "title": "Anomalous localization in spin-chain with tilted interactions",
        "authors": [
            "Arindam Mallick",
            "Jakub Zakrzewski"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Quantum Gases",
            "Strongly Correlated Electrons",
            "High Energy Physics - Lattice",
            "Quantum Physics"
        ],
        "abstract": "The localization properties of a disorder-free spin chain with inhomogeneous interactions are studied. In particular, we consider interaction strength growing linearly along the chain for systems with different interaction ranges. Using exact diagonalization we find the participation ratio of all eigenstates which allows us to quantify the localization volume in the Hilbert space. Surprisingly the localization volume changes nonmonotonically with the interaction range. The model for the infinite interaction range resembles the Schwinger model of lattice gauge theory in staggered formalism. The model studied may be implemented in state-of-the-art cold atomic devices and could reveal hidden features in disorder-free confinement phenomena.",
        "comments": "11 pages, 9 figures. Comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14369"
    },
    {
        "doc_id": 212,
        "title": "Spectral Gaps of 2D and 3D Many-body Quantum Systems in the Thermodynamic Limit",
        "authors": [
            "Illya V. Lukin",
            "Andrii G. Sotnikov",
            "Jacob M. Leamer",
            "Alicia B. Magann",
            "Denys I. Bondar"
        ],
        "subjects": [
            "Quantum Physics",
            "Strongly Correlated Electrons"
        ],
        "abstract": "We present an expression for the spectral gap, opening up new possibilities for performing and accelerating spectral calculations of quantum many-body systems. We develop and demonstrate one such possibility in the context of tensor network simulations. Our approach requires only minor modifications of the widely used Simple Update method and is computationally lightweight relative to other approaches. We validate it by computing spectral gaps of the 2D and 3D transverse-field Ising models and find strong agreement with previously reported perturbation theory results.",
        "comments": "7 pages and 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14368"
    },
    {
        "doc_id": 213,
        "title": "Spatially Resolved Conductivity of Rectangular Interconnects considering Surface Scattering -- Part I: Physical Modeling",
        "authors": [
            "Xinkang Chen",
            "Sumeet Kumar Gupta"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Accurate modeling of interconnect conductivity is important for performance evaluation of chips in advanced technologies. Surface scattering in interconnects is usually treated by using Fuchs-Sondheimer (FS) approach. While the FS model offer explicit inclusion of the physical parameters, it lacks spatial dependence of conductivity across the interconnect cross-section. To capture the space-dependency of conductivity, an empirical modeling approach based on \"cosh\" function has been proposed, but it lacks physical insights. In this work, we present a 2D spatially resolved FS (SRFS) model for rectangular interconnects derived from the Boltzmann transport equations. The proposed SRFS model for surface scattering offers both spatial dependence and explicit relation of conductivity to physical parameters such as mean free path and specularity of electrons and interconnect geometry. We highlight the importance of physics-based spatially resolved conductivity model by showing the differences in the spatial profiles between the proposed physical approach and the previous empirical approach. In Part II of this work, we build upon the SRFS approach to propose a compact model for spatially-resolved conductivity accounting for surface scattering in rectangular interconnects.",
        "comments": "12 pages, 8 figures, in process to submit to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14366"
    },
    {
        "doc_id": 214,
        "title": "Impact of dynamical regionalization on precipitation biases and teleconnections over West Africa",
        "authors": [
            "I\u00f1igo G\u00f3mara",
            "Elsa Mohino",
            "Teresa Losada",
            "Marta Dom\u00ednguez",
            "Roberto Su\u00e1rez-Moreno",
            "Bel\u00e9n Rodr\u00edguez-Fonseca"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics",
            "Geophysics"
        ],
        "abstract": "West African societies are highly dependent on the West African Monsoon (WAM).Thus, a correct representation of the WAM in climate models is of paramount importance. In this article, the ability of 8 CMIP5 historical General Circulation Models (GCMs) and 4 CORDEX-Africa Regional Climate Models (RCMs) to characterize the WAM dynamics and variability is assessed for the period July-August-September 1979-2004. Simulations are compared with observations. Uncertainties in RCM performance and lateral boundary conditions are assessed individually. Results show that both GCMs and RCMs have trouble to simulate the northward migration of the Intertropical Convergence Zone in boreal summer. The greatest bias improvements are obtained after regionalization of the most inaccurate GCM simulations. To assess WAM variability, a Maximum Covariance Analysis is performed between Sea Surface Temperature and precipitation anomalies in observations, GCM and RCM simulations. The assessed variability patterns are: El Nino-Southern Oscillation (ENSO); the eastern Mediterranean (MED); and the Atlantic Equatorial Mode (EM). Evidence is given that regionalization of the ENSO-WAM teleconnection does not provide any added value. Unlike GCMs, RCMs are unable to precisely represent the ENSO impact on air subsidence over West Africa. Contrastingly, the simulation of the MED-WAM teleconnection is improved after regionalization. Humidity advection and convergence over the Sahel area are better simulated by RCMs. Finally, no robust conclusions can be determined for the EM-WAM teleconnection, which cannot be isolated for the 1979-2004 period. The novel results in this article will help to select the most appropriate RCM simulations to study WAM teleconnections.",
        "comments": "Journal ref:        Clim Dyn 50, 4481-4506 (2018)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14364"
    },
    {
        "doc_id": 215,
        "title": "Universal collective Larmor-Silin mode emerging in magnetized correlated Dirac fermions",
        "authors": [
            "Chuang Chen",
            "Yuan Da Liao",
            "Chengkang Zhou",
            "Gaopei Pan",
            "Zi Yang Meng",
            "Yang Qi"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Mesoscale and Nanoscale Physics",
            "Materials Science"
        ],
        "abstract": "Employing large-scale quantum Monte Carlo simulations, we find in magnetized interacting Dirac fermion model, there emerges a new and universal collective Larmor-Silin spin wave mode in the transverse dynamical spin susceptibility. Such mode purely originates from the interaction among Dirac fermions and distinguishes itself from the usual particle-hole continuum with finite lifetime and clear dispersion. Our unbiased numerical results offer the dynamic signature of this new collective excitations in interacting Dirac fermion systems, and provide experimental guidance for inelastic neutron scattering, electron spin resonance and other spectroscopic approaches in the investigation of such universal collective modes in quantum Moire materials, topological insulators and quantum spin liquid materials under magnetic field, with quintessential interaction nature beyond the commonly assumed noninteracting Dirac fermion or spinon approximations.",
        "comments": "11 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14358"
    },
    {
        "doc_id": 216,
        "title": "Near-field radiative heat transfer between shifted graphene gratings",
        "authors": [
            "Minggang Luo",
            "Youssef Jeyar",
            "Brahim Guizal",
            "Mauro Antezza"
        ],
        "subjects": [
            "Optics",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics"
        ],
        "abstract": "We examine the near-field radiative heat transfer between finite-thickness planar fused silica slabs covered with graphene gratings, through the utilization of the exact Fourier modal method augmented with local basis functions (FMM-LBF), with focus on the lateral shift effect. To do so, we propose and validate a minor modification of the FMM-LBF theory to account for the lateral shift. This approach goes far beyond the effective medium approximation because this latter cannot account for the lateral shift. We show that the heat flux can exhibit significant oscillations with the lateral shift and, at short separation, it can experience up to a 60%-70% reduction compared to the aligned case. Such a lateral shift effect is found to be sensitive to the geometric factor $d/D$ (separation distance to grating period ratio). When $d/D>2$ (realized through large separation or small grating period), the two graphene gratings see each other as an effective whole rather than in detail, and thus the lateral shift effect on heat transfer becomes less important. Therefore, we can clearly distinguish two asymptotic regimes for radiative heat transfer: the LSE (Lateral Shift Effect) regime, where a significant lateral shift effect is observed, and the non-LSE regime, where this effect is negligible. Furthermore, regardless of the lateral shift, the radiative heat flux shows an obvious and non-monotonic dependence on the graphene chemical potential. That is, we can get an optimal radiative heat flux (peaking at about 0.3eV chemical potential) by $\\textit{in situ}$ modulating the chemical potential. This work has the potential to unveil new avenues for harnessing the lateral shift effect on radiative heat transfer in graphene-based nanodevices.",
        "comments": "13 pages, 13 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14357"
    },
    {
        "doc_id": 217,
        "title": "Exact surface energy of the Hubbard model with unparallel boundary magnetic fields",
        "authors": [
            "Pei Sun",
            "Yi Qiao",
            "Junpeng Cao",
            "Wen-Li Yang"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "In this paper, we study the exact physical quantities in the thermodynamic limit of the one-dimensional Hubbard model with unparallel boundary magnetic fields based on the off-diagonal Bethe ansatz solution. At the half-filling, we obtain the different patterns of Bethe roots of the reduced Bethe ansatz equations for the different boundary parameters. According to them, we obtain the densities of states, ground state energy density and surface energy. Our results show that the system has the stable boundary bound states when the boundary magnetic fields satisfy some constraints.",
        "comments": "13 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14356"
    },
    {
        "doc_id": 218,
        "title": "Initial data for Minkowski stability with arbitrary decay",
        "authors": [
            "Allen Juntao Fang",
            "J\u00e9r\u00e9mie Szeftel",
            "Arthur Touati"
        ],
        "subjects": [
            "Analysis of PDEs",
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "We construct and parametrize solutions to the constraint equations of general relativity in a neighborhood of Minkowski spacetime with arbitrary prescribed decay properties at infinity. We thus provide a large class of initial data for the results on stability of Minkowski which include a mass term in the asymptotics. Due to the symmetries of Minkowski, a naive linear perturbation fails. Our construction is based on a simplified conformal method, a reduction to transverse traceless perturbations and a nonlinear fixed point argument where we face linear obstructions coming from the cokernels of both the linearized constraint operator and the Laplace operator. To tackle these obstructions, we introduce a well-chosen truncated black hole around which to perturb. The control of the parameters of the truncated black hole is the most technical part of the proof, since its center of mass and angular momentum could be arbitrarily large.",
        "comments": "86 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14353"
    },
    {
        "doc_id": 219,
        "title": "Uncovering Heterogeneity of Solar Flare Mechanism With Mixture Models",
        "authors": [
            "Bach Viet Do",
            "Yang Chen",
            "XuanLong Nguyen",
            "Ward Manchester"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Applications",
            "Methodology"
        ],
        "abstract": "The physics of solar flares occurring on the Sun is highly complex and far from fully understood. However, observations show that solar eruptions are associated with the intense kilogauss fields of active regions, where free energies are stored with field-aligned electric currents. With the advent of high-quality data sources such as the Geostationary Operational Environmental Satellites (GOES) and Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI), recent works on solar flare forecasting have been focusing on data-driven methods. In particular, black box machine learning and deep learning models are increasingly adopted in which underlying data structures are not modeled explicitly. If the active regions indeed follow the same laws of physics, there should be similar patterns shared among them, reflected by the observations. Yet, these black box models currently used in the literature do not explicitly characterize the heterogeneous nature of the solar flare data, within and between active regions. In this paper, we propose two finite mixture models designed to capture the heterogeneous patterns of active regions and their associated solar flare events. With extensive numerical studies, we demonstrate the usefulness of our proposed method for both resolving the sample imbalance issue and modeling the heterogeneity for rare energetic solar flare events.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14345"
    },
    {
        "doc_id": 220,
        "title": "From the Choi Formalism in Infinite Dimensions to Unique Decompositions of Generators of Completely Positive Dynamical Semigroups",
        "authors": [
            "Frederik vom Ende"
        ],
        "subjects": [
            "Functional Analysis",
            "Mathematical Physics",
            "Quantum Physics"
        ],
        "abstract": "Given any separable complex Hilbert space, any trace-class operator $B$ which does not have purely imaginary trace, and any generator $L$ of a norm-continuous one-parameter semigroup of completely positive maps we prove that there exists a unique bounded operator $K$ and a unique completely positive map $\u03a6$ such that (i) $L=K(\\cdot)+(\\cdot)K^*+\u03a6$, (ii) the superoperator $\u03a6(B^*(\\cdot)B)$ is trace class and has vanishing trace, and (iii) ${\\rm tr}(B^*K)$ is a real number. Central to our proof is a modified version of the Choi formalism which relates completely positive maps to positive semi-definite operators. We characterize when this correspondence is injective and surjective, respectively, which in turn explains why the proof idea of our main result cannot extend to non-separable Hilbert spaces. In particular, we find examples of positive semi-definite operators which have empty pre-image under the Choi formalism as soon as the underlying Hilbert space is infinite-dimensional.",
        "comments": "25+3 pages. Generalizes arXiv:2310.04037 to infinite dimensions. To be submitted to J. Funct. Anal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14344"
    },
    {
        "doc_id": 221,
        "title": "Probing Quantum Entanglement from Quantum Correction to Newtonian Potential Energy",
        "authors": [
            "A. Belhaj",
            "S. E. Ennadifi",
            "L. Jebli"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics"
        ],
        "abstract": "Inspired by string theory ideas, we probe quantum entanglement from the gravitational potential energy. Concretely, we reconsider the study of quantum corrections to the Newtonian potential energy by treating a massive two-particle system $m_{1}$ and $m_{2}$ with size dimensions $r_{1}$ ad $% r_{2}$ where the two particles separated by a distance $d$ are under only their mutual classical gravitational interaction $V_{r}\\left( r_{1}\\text{, }% r_{2}\\right) $. Exploring such a size-dependent gravitational behavior and taking the limit $r_{1}$, $r_{2}\\ll d$, we investigate the associated quantum biparticle state and express its evolution after an interaction time $\u03c4$. Among others, we show that the two masses cannot be separable due to the induced gravitational entanglement in terms of the accumulated quantum phase $\u03b4\u03c6=\u03b4V_{g}\u03c4/\\hbar $. By analogy with the classical gravity, we derive the expression of the resulting extremely weak entanglement force from the corresponding gravitational entanglement energy. Then, we provide certain entanglement diagnostics.",
        "comments": "13 Pages, Latex, 0 Figure, 0 Table, Hand conducted work. To appear in Physica Scripta (2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14342"
    },
    {
        "doc_id": 222,
        "title": "Quantum Variational Algorithms for the Allocation of Resources in a Cloud/Edge Architecture",
        "authors": [
            "Carlo Mastroianni",
            "Francesco Plastina",
            "Jacopo Settino",
            "Andrea Vinci"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks",
            "Other Condensed Matter"
        ],
        "abstract": "Modern Cloud/Edge architectures need to orchestrate multiple layers of heterogeneous computing nodes, including pervasive sensors/actuators, distributed Edge/Fog nodes, centralized data centers and quantum devices. The optimal assignment and scheduling of computation on the different nodes is a very difficult problem, with NP-hard complexity. In this paper, we explore the possibility of solving this problem with variational quantum algorithms, which can become a viable alternative to classical algorithms in the near future. In particular, we compare the performances, in terms of success probability, of two algorithms, i.e., Quantum Approximate Optimization Algorithm (QAOA) and Variational Quantum Eigensolver (VQE). The simulation experiments, performed for a set of simple problems, show that the VQE algorithm ensures better performances when it is equipped with appropriate circuit ansatzes that are able to restrict the search space. Moreover, experiments executed on real quantum hardware show that the execution time, when increasing the size of the problem, grows much more slowly than the trend obtained with classical computation, which is known to be exponential.",
        "comments": "14 pages, 13 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14339"
    },
    {
        "doc_id": 223,
        "title": "Momentum, energy and vorticity balances in deep-water surface gravity waves",
        "authors": [
            "Aidan Blaser",
            "Rapha\u00ebl Benamran",
            "A. Bia Villas B\u00f4as",
            "Luc Lenain",
            "Nick Pizzo"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "The particle trajectories in irrotational, incompressible and inviscid deep-water surface gravity waves are open, leading to a net drift in the direction of wave propagation commonly referred to as the Stokes Drift, which is responsible for catalysing surface wave-induced mixing in the ocean and transporting marine debris. A balance between phase-averaged momentum density, kinetic energy density and vorticity for irrotational, monochromatic and periodic two-dimensional water waves is derived by working directly within the Lagrangian reference frame, which tracks particle trajectories as a function of their labels and time. This balance should be expected as all three of these quantities are conserved following particles in this system. Vorticity in particular is always conserved along particles in two-dimensional inviscid flow, and as such even in its absence it is the value of the vorticity which fundamentally sets the drift, which in the Lagrangian frame is identified as the phase-averaged momentum density of the system. A relationship between the drift and the geometric mean water level of particles is found at the surface and applications for potential new ways of inferring drift are discussed. Finally, an example of an initially quiescent fluid driven by a wavelike pressure disturbance is considered, showing how the net momentum and energy from the surface disturbance transfer to the wave field, recognizing the source of the mean Lagrangian drift as the net momentum required to generate an irrotational surface wave by any conservative force.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14334"
    },
    {
        "doc_id": 224,
        "title": "Rotating effects on the photoionization cross-section of a 2D quantum ring",
        "authors": [
            "Carlos Magno O. Pereira",
            "Frankbelson dos S. Azevedo",
            "Lu\u00eds Fernando C. Pereira",
            "Edilberto O. Silva"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Quantum Physics"
        ],
        "abstract": "In this letter, we investigate the nonrelativistic quantum motion of a charged particle within a rotating frame, taking into account the Aharonov-Bohm (AB) effect and a uniform magnetic field. Our analysis entails the derivation of the equation of motion and the corresponding radial equation to describe the system. Solving the resulting radial equation enables us to determine the eigenvalues and eigenfunctions, providing a clear expression for the energy levels. Furthermore, our numerical analysis highlights the substantial influence of rotation on both energy levels and optical properties. Specifically, we evaluate the photoionization cross-section (PCS) with and without the effects of rotation. To elucidate the impact of rotation on the photoionization process of the system, we present graphics that offer an appealing visualization of the intrinsic nature of the physics involved.",
        "comments": "6 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14333"
    },
    {
        "doc_id": 225,
        "title": "Tripartite entanglement and tripartite steering in three-qubit pure states induced by vacuum-one-photon superpositions",
        "authors": [
            "Jian Wang",
            "Huan Liu",
            "Xue-feng Zhan",
            "Xue-xiang Xu"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Utilizing a tritter with variable parameter $T$ and induced by vacuum-one-photon superpositions $\\left\\vert 0\\right\\rangle +\u03b1\\left\\vert 1\\right\\rangle $ with $\u03b1=\\left\\vert \u03b1\\right\\vert e^{i\u03c6}$, we generate a class of three-qubit pure states. These states take the form of $\\left\\vert \u03c8\\right\\rangle _{123}=c_{0}\\left\\vert 000\\right\\rangle +c_{1}\\left\\vert 100\\right\\rangle +c_{2}\\left\\vert 010\\right\\rangle +c_{3}\\left\\vert 001\\right\\rangle $. The coefficients ($ c_{0}$, $c_{1}$, $c_{2}$, and $c_{3}$) can be manipulated through interaction parameters ($\\left\\vert \u03b1\\right\\vert $, $\u03c6$, and $T$). In line with Xie and Eberly's work[Phys. Rev. Lett. 127, 040403 (2021)], we investigate the genuine tripartite entanglement for $\\left\\vert \u03c8\\right\\rangle _{123}$ using the concurrence triangle measure. Drawing on Hao et al.'s research [Phys. Rev. Lett. 128, 120402 (2021)], we examine tripartite steering for $\\left\\vert \u03c8\\right\\rangle _{123}$ under certain measurements based on the uncertainty relations criterion. We identify nine potential configurations exhibiting varying steerability across different parameter spaces. It is important to highlight that while the state $% \\left\\vert \u03c8\\right\\rangle _{123}$ exhibits entanglement, steering remains unattainable in a substantial portion of the parameter space.",
        "comments": "10 pages, 8 figures, comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14328"
    },
    {
        "doc_id": 226,
        "title": "Practical Phase-Space Electronic Hamiltonians for Ab Initio Dynamics",
        "authors": [
            "Zhen Tao",
            "Tian Qiu",
            "Mansi Bhati",
            "Xuezhi Bian",
            "Titouan Duston",
            "Jonathan Rawlinson",
            "Robert G. Littlejohn",
            "Joseph E. Subotnik"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Modern electronic structure theory is built around the Born-Oppenheimer approximation and the construction of an electronic Hamiltonian H_{el}(X) that depends on the nuclear position X (and not the nuclear momentum P). In this article, using the well-known theory of electron translation (Gamma') and rotational (Gamma'') factors to couple electronic transitions to nuclear motion, we construct a practical phase-space electronic Hamiltonian that depends on both nuclear position and momentum, H_{PS}(X,P). While classical Born-Oppenheimer dynamics that run along the eigensurfaces of the operator H_{el}(X) can recover many nuclear properties correctly, we present some evidence that motion along the eigensurfaces of H_{PS}(X,P) can better capture both nuclear and electronic properties (including the elusive electronic momentum studied by Nafie). Moreover, only the latter (as opposed to the former) conserves the total linear and angular momentum in general.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14327"
    },
    {
        "doc_id": 227,
        "title": "Radiative corrections to di-meson tau decays",
        "authors": [
            "Alejandro Miranda"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We review radiative corrections to tau decays into two mesons discussing their impact in new physics searches.",
        "comments": "5 pages, 1 figure. Accepted for publication in the proceedings of the HADRON 2023 Conference, Genova, Italy, 5-9 June 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14326"
    },
    {
        "doc_id": 228,
        "title": "Invisible neutrino decay at long-baseline neutrino oscillation experiments",
        "authors": [
            "Christoph A. Ternes",
            "Giulia Pagliaroli"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We perform an updated analysis of long-baseline accelerator data in the framework of neutrino oscillations in presence of invisible neutrino decay. We analyze data from T2K, NOvA and MINOS/MINOS+ and show that the combined analysis of all experiments improves the previous bound from long-baseline data by approximately one order of magnitude.",
        "comments": "v1: 7 pages, 2 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14316"
    },
    {
        "doc_id": 229,
        "title": "MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems",
        "authors": [
            "Xinyu Gao",
            "Zhijie Wang",
            "Yang Feng",
            "Lei Ma",
            "Zhenyu Chen",
            "Baowen Xu"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms. With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems. Similar to traditional software, adequate testing is also required for AI-enabled MSF systems. Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-/point cloud-based object detection systems). There remains a lack of emphasis on generating multi-modal test cases for MSF systems. To address these limitations, we design and implement MultiTest, a fitness-guided metamorphic testing method for complex MSF perception systems. MultiTest employs a physical-aware approach to synthesize realistic multi-modal object instances and insert them into critical positions of background images and point clouds. A fitness metric is designed to guide and boost the test generation process. We conduct extensive experiments with five SOTA perception systems to evaluate MultiTest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement. The results show that MultiTest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test. Moreover, retraining an MSF system on the test cases generated by MultiTest can improve the system's robustness.",
        "comments": "The first two authors contributed equally. To appear in the proceedings of the 46th International Conference on Software Engineering (ICSE 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14314"
    },
    {
        "doc_id": 230,
        "title": "Temperature Separation in a Vortex Tube and Solar Convection",
        "authors": [
            "Haibin Chen",
            "Rong Wu"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "Why does the temperature gradient within a vortex tube deviate significantly from the adiabatic gradient is an important but unresolved issue. A new theory from solar physics suggests that the vorticity gradient, like the temperature gradient, can suppress or promote convection depending on the conditions, causing the temperature gradient to deviate significantly from or approach the adiabatic gradient. The gas near the wall has a very high vorticity, which can provide a large buoyancy force, driving some fluid parcels to undergo multiple collisions and reach near the axis, achieving temperature separation.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14313"
    },
    {
        "doc_id": 231,
        "title": "Theory of Acoustic Polarons in the Two-Dimensional SSH Model Applied to the Layered Superatomic Semiconductor Re6Se8Cl2",
        "authors": [
            "Petra Shih",
            "Timothy C. Berkelbach"
        ],
        "subjects": [
            "Materials Science",
            "Chemical Physics"
        ],
        "abstract": "Layered superatomic semiconductors, whose buildings blocks are atomically precise molecular clusters, exhibit interesting electronic and vibrational properties. In recent work [Science 382, 438 (2023)], transient reflection microscopy revealed quasi-ballistic exciton dynamics in Re6Se8Cl2, which was attributed to the formation of polarons due to coupling with acoustic phonons. Here, we characterize the electronic, excitonic, and phononic properties with periodic density functional theory. We further parameterize a polaron Hamiltonian with nonlocal [Su-Schrieffer-Heeger (SSH)] coupling to acoustic phonon to study the polaron ground state binding energy and dispersion relation with variational wavefunctions. We calculate a polaron binding energy of about 10 meV at room temperature, and the maximum group velocity of our polaron dispersion relation is 1.5 km/s, which is similar to the experimentally observed exciton transport velocity.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14312"
    },
    {
        "doc_id": 232,
        "title": "Higher categories",
        "authors": [
            "Rune Haugseng"
        ],
        "subjects": [
            "Category Theory",
            "Algebraic Topology"
        ],
        "abstract": "Invited contribution to the Encyclopedia of Mathematical Physics. We give an introduction to the homotopical theory of higher categories, focused on motivating the definitions of the basic objects, namely $\\infty$-categories and $(\\infty,n)$-categories.",
        "comments": "33 pages; contribution to Encyclopedia of Mathematical Physics, 2nd ed",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14311"
    },
    {
        "doc_id": 233,
        "title": "Andr\u00e9-Quillen cohomology in the context of curved algebras",
        "authors": [
            "Joan Bellier-Mill\u00e8s",
            "Sinan Yalin"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "K-Theory and Homology",
            "Symplectic Geometry"
        ],
        "abstract": "The Andr\u00e9-Quillen cohomology of an algebra with coefficients in a module is defined by deriving a functor based on K\u00e4hler differential forms. It can be computed using a cofibrant resolution of the algebra in a model category structure where weak equivalences are quasi-isomorphisms. This construction works for algebras over an operad, providing a cohomology theory tailored for each type of algebra. For curved algebras however, the notion of quasi-isomorphism is meaningless. The occurrence and importance of curved structures in various research topics (symplectic topology, deformation theory, derived geometry, mathematical physics) motivate the development of their homotopy theory and Andr\u00e9-Quillen cohomology theory. To get a homotopical context with an appropriate notion of weak equivalence, we consider filtered complete modules with a predifferential inducing a differential on the associated graded. Curved algebras in such modules are algebras over a curved operad. In this article, we consider curved operads which are not necessarily augmented. Bar and cobar constructions adapted to these curved operads are developed, as well as Koszul duality theory. Consequently, we obtain homotopy versions of our curved algebras and make it explicit for interesting cases. Two main examples are the curved operads encoding curved unital associative algebras and curved complex Lie algebras. In particular, homotopy curved unital associative algebras describe the structure of Floer complexes of lagrangian submanifolds and Fukaya categories in symplectic topology. Bar and cobar constructions for curved algebras are also developed, and we obtain resolutions from which we compute their Andr\u00e9-Quillen cohomology with module coefficients. Our computations in the case of curved complex Lie algebras reveal an interesting link between their Andr\u00e9-Quillen cohomology and derived complex analytic geometry.",
        "comments": "78 pages, comments welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14309"
    },
    {
        "doc_id": 234,
        "title": "The soaring kite: a tale of two punctured tori",
        "authors": [
            "Mathieu Giroux",
            "Andrzej Pokraka",
            "Franziska Porkert",
            "Yoann Sohnle"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "High Energy Physics - Phenomenology",
            "Mathematical Physics"
        ],
        "abstract": "We consider the 5-mass kite family of self-energy Feynman integrals and present a systematic approach for constructing an epsilon-form basis, along with its differential equation pulled back onto the moduli space of two tori. Each torus is associated with one of the two distinct elliptic curves this family depends on. We demonstrate how the locations of relevant punctures, which are required to parametrize the full image of the kinematic space onto this moduli space, can be extracted from integrals over maximal cuts. A boundary value is provided such that the differential equation is systematically solved in terms of iterated integrals over g-kernels and modular forms. Then, the numerical evaluation of the master integrals is discussed, and important challenges in that regard are emphasized. In an appendix, we introduce new relations between g-kernels.",
        "comments": "59 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14307"
    },
    {
        "doc_id": 235,
        "title": "$\u03bde\\to\u03bde$ scattering with massive Dirac or Majorana neutrinos and general interactions",
        "authors": [
            "Juan Manuel M\u00e1rquez",
            "Pablo Roig",
            "M\u00f3nica Salinas"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We calculate the neutrino-electron elastic scattering cross section, extending the results previously obtained in arXiv:1702.05721v2, in the presence of generic new interactions that take into account all the effects caused by finite neutrino masses. We address the potential significance of a heavy neutrino sector during precision measurements, particularly for tau neutrinos scattering with masses in the MeV range, for which the existing upper bounds on $|U_{\u03c44}|^2$ would result in conceivably measurable contributions. Finally, we comment on the possibility to distinguish between Dirac and Majorana neutrinos, including the analysis of the new emerging parameters and its application to illustrative model-dependent scenarios.",
        "comments": "22 pages, 1 figure",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14305"
    },
    {
        "doc_id": 236,
        "title": "Correlation function and the inverse problem in the $BD$ interaction",
        "authors": [
            "Hai-Peng Li",
            "Jing-Yu Yi",
            "Chu-Wen Xiao",
            "De-Liang Yao",
            "Wei-Hong Liang",
            "Eulogio Oset"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We carry a study of the correlation functions of the $B^0 D^+, B^+ D^0$ system, which develops a bound state by about $40$ MeV, using input consistent with the $T_{cc}(3875)$ state. Then we face the inverse problem of starting from these correlation functions to determine scattering observables related to the system, including the existence of the bound state and its molecular nature. The important output of the approach is the uncertainty by which these observables can be obtained, assuming errors in the $B^0 D^+, B^+ D^0$ correlation functions typical of current ones in present correlation functions. We observe that it is possible to obtain scattering lengths and effective ranges with relative high precision and the existence of a bound state. While the pole position is obtained with errors of the order of $50 \\%$ of the binding energy, the molecular probability of the state is obtained with a very small error of the order of $6\\%$. All these findings can serve as motivation to perform such measurements in future runs of high energy hadron collisions.",
        "comments": "16 pages, 3 figures, 7 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14302"
    },
    {
        "doc_id": 237,
        "title": "Amorphous silicon detectors for proton beam monitoring in FLASH radiotherapy",
        "authors": [
            "Nicolas Wyrsch",
            "Luca Antognini",
            "Christophe Ballif",
            "Saverio Braccini",
            "Pierluigi Casolaro",
            "Sylvain Dunand",
            "Alexander Gottstein",
            "Matt Large",
            "Isidre Mateu",
            "Jonathan Thomet"
        ],
        "subjects": [
            "High Energy Physics - Experiment",
            "Materials Science"
        ],
        "abstract": "Ultra-high dose rate radiation therapy (FLASH) based on proton irradiation is of major interest for cancer treatments but creates new challenges for dose monitoring. Amorphous hydrogenated silicon is known to be one of the most radiation-hard semiconductors. In this study, detectors based on this material are investigated at proton dose rates similar to or exceeding those required for FLASH therapy. Tested detectors comprise two different types of contacts, two different thicknesses deposited either on glass or on polyimide substrates. All detectors exhibit excellent linear behaviour as a function of dose rate up to a value of 20 kGy/s. Linearity is achieved independently of the depletion condition of the device and remarkably in passive (unbiased) conditions. The degradation of the performance as a function of the dose rate and its recovery are also discussed.",
        "comments": "16 pages, 9 figures, presented at 29th Internation Conference on Solid-State Dosimetry, 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14300"
    },
    {
        "doc_id": 238,
        "title": "The overlooked significance of the unbiased exponential phasefactor in the determination of the finite-density lattice QCD equation of state",
        "authors": [
            "Sabarnya Mitra"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology",
            "Nuclear Experiment",
            "Nuclear Theory"
        ],
        "abstract": "Within the framework of (2+1)-flavor QCD at finite temperature and chemical potential, we present results using high statistics data and demonstrate how the phasefactor of low order unbiased exponential resummation offers excellent prediction, proving to be an alternative reliable estimator of the radius of convergence of the eighth order QCD Taylor series at finite baryon density measured using the ratio and the Merci-Roberts estimators. We construct a new non-trivial unbiased phasefactor for complex isospin chemical potentials $\\muI$ and highlight its novelty. We find that this new unbiased phasefactor is very much capable of indicating the onset of non-monotonicity in finite $\\muI$ thermodynamics, which we illustrate by comparing the phasefactor results with that of low order cumulants of $\\muI$ fluctuations for non-vanishing $\\muI$. We also furnish results establishing that this unbiased phasefactor is reliable in manifesting the beginning of the overlap problem for finite, real $\\muI$. The errorbars increase drastically across the indications provided by the phasefactor which becomes very apparent from the coincidence between the phasefactor and the maximum of the errorbar slopes.",
        "comments": "9 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14299"
    },
    {
        "doc_id": 239,
        "title": "Characterising the Haar measure on the $p$-adic rotation groups via inverse limits of measure spaces",
        "authors": [
            "Paolo Aniello",
            "Sonia L'Innocente",
            "Stefano Mancini",
            "Vincenzo Parisi",
            "Ilaria Svampa",
            "Andreas Winter"
        ],
        "subjects": [
            "Mathematical Physics",
            "Functional Analysis",
            "Group Theory",
            "Number Theory"
        ],
        "abstract": "We determine the Haar measure on the compact $p$-adic special orthogonal groups of rotations $\\mathrm{SO}(d)_p$ in dimension $d=2,3$, by exploiting the machinery of inverse limits of measure spaces, for every prime $p>2$. We characterise $\\mathrm{SO}(d)_p$ as inverse limits of finite groups, of which we provide parametrisations and orders, together with an equivalent description through a multivariable Hensel lifting. Supplying these finite groups with their normalised counting measures, we get an inverse family of Haar measure spaces for each $\\mathrm{SO}(d)_p$. Finally, we constructively prove the existence of the so-called inverse limit measure of these inverse families, which is explicitly computable, and prove that it gives the Haar measure on $\\mathrm{SO}(d)_p$. Our results pave the way towards the study of the irreducible projective unitary representations of the $p$-adic rotation groups, with potential applications to the recently proposed $p$-adic quantum information theory.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14298"
    },
    {
        "doc_id": 240,
        "title": "The three-pion $K$-matrix at NLO in ChPT",
        "authors": [
            "Jorge Baeza-Ballesteros",
            "Johan Bijnens",
            "Tom\u00e1\u0161 Husek",
            "Fernando Romero-L\u00f3pez",
            "Stephen R. Sharpe",
            "Mattias Sj\u00f6"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Lattice",
            "Nuclear Theory"
        ],
        "abstract": "The three-particle $K$-matrix, $\\mathcal{K}_{\\mathrm{df},3}$, is a scheme-dependent quantity that parametrizes short-range three-particle interactions in the relativistic-field-theory three-particle finite-volume formalism. In this work, we compute its value for systems of three pions in all isospin channels through next-to-leading order in Chiral Perturbation Theory, generalizing previous work done at maximum isospin. We obtain analytic expressions through quadratic order (or cubic order, in the case of zero isospin) in the expansion about the three-pion threshold.",
        "comments": "44 pages, 8 figures, 10 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14293"
    },
    {
        "doc_id": 241,
        "title": "Quantum Electrometer for Time-Resolved Material Science at the Atomic Lattice Scale",
        "authors": [
            "Gregor Pieplow",
            "Cem G\u00fcney Torun",
            "Joseph H. D. Munns",
            "Franziska Marie Herrmann",
            "Andreas Thies",
            "Tommaso Pregnolato",
            "Tim Schr\u00f6der"
        ],
        "subjects": [
            "Applied Physics",
            "Materials Science",
            "Quantum Physics"
        ],
        "abstract": "The detection of individual charges plays a crucial role in fundamental material science and the advancement of classical and quantum high-performance technologies that operate with low noise. However, resolving charges at the lattice scale in a time-resolved manner has not been achieved so far. Here, we present the development of an electrometer, leveraging on the spectroscopy of an optically-active spin defect embedded in a solid-state material with a non-linear Stark response. By applying our approach to diamond, a widely used platform for quantum technology applications, we successfully localize charge traps, quantify their impact on transport dynamics and noise generation, analyze relevant material properties, and develop strategies for material optimization.",
        "comments": "Main: 9 pages, 5 figures; Supplement: 14 pages, 10 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14290"
    },
    {
        "doc_id": 242,
        "title": "How far can we see back in time in high-energy collisions using charm quarks?",
        "authors": [
            "Laszlo Gyulai",
            "Gabor Biro",
            "Robert Vertesi",
            "Gergely Gabor Barnafoldi"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We use open charm production to estimate how far we can see back in time in high-energy hadron-hadron collisions. We analyze the transverse momentum distributions of the identified D mesons from pp, p-Pb and A-A collisions at the ALICE and STAR experiments covering the energy range from $\\sqrt{s_{\\rm NN}} = 200$ GeV up to 7 TeV. Within a non-extensive statistical framework, the common Tsallis parameters for D mesons represent higher temperature and more degrees of freedom than that of light-flavour hadrons. The production of D mesons corresponds to a significantly earlier proper time, $\u03c4_{\\rm D} = (0.18 \\pm 0.06) \u03c4_{\\rm LF}$.",
        "comments": "18 pages, 6 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14282"
    },
    {
        "doc_id": 243,
        "title": "Bifurcation of Dividing Surfaces Constructed from Period-Doubling Bifurcations of Periodic Orbits in a Caldera Potential Energy Surface",
        "authors": [
            "Matthaios Katsanikas",
            "Makrina Agaoglou",
            "Stephen Wiggins"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Dynamical Systems",
            "Chemical Physics"
        ],
        "abstract": "In this work we analyze the bifurcation of dividing surfaces that occurs as a result of two period-doubling bifurcations in a 2D caldera-type potential. We study the structure, the range, the minimum and maximum extents of the periodic orbit dividing surfaces before and after a subcritical period-doubling bifurcation of the family of the central minimum of the potential energy surface. Furthermore, we repeat the same study for the case of a supercritical perioddoubling bifurcation of the family of the central minimum of the potential energy surface. We will discuss and compare the results for the two cases of bifurcations of dividing surfaces.",
        "comments": "15 pages. arXiv admin note: text overlap with arXiv:2107.09623",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14275"
    },
    {
        "doc_id": 244,
        "title": "Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables",
        "authors": [
            "Max Rosenkranz",
            "Karl A. Kalina",
            "J\u00f6rg Brummund",
            "WaiChing Sun",
            "Markus K\u00e4stner"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "We present an approach for the data-driven modeling of nonlinear viscoelastic materials at small strains which is based on physics-augmented neural networks (NNs) and requires only stress and strain paths for training. The model is built on the concept of generalized standard materials and is therefore thermodynamically consistent by construction. It consists of a free energy and a dissipation potential, which can be either expressed by the components of their tensor arguments or by a suitable set of invariants. The two potentials are described by fully/partially input convex neural networks. For training of the NN model by paths of stress and strain, an efficient and flexible training method based on a recurrent cell, particularly a long short-term memory cell, is developed to automatically generate the internal variable(s) during the training process. The proposed method is benchmarked and thoroughly compared with existing approaches. These include a method that obtains the internal variable by integrating the evolution equation over the entire sequence, while the other method uses an an auxiliary feedforward neural network for the internal variable(s). Databases for training are generated by using a conventional nonlinear viscoelastic reference model, where 3D and 2D plane strain data with either ideal or noisy stresses are generated. The coordinate-based and the invariant-based formulation are compared and the advantages of the latter are demonstrated. Afterwards, the invariant-based model is calibrated by applying the three training methods using ideal or noisy stress data. All methods yield good results, but differ in computation time and usability for large data sets. The presented training method based on a recurrent cell turns out to be particularly robust and widely applicable and thus represents a promising approach for the calibration of other types of models as well.",
        "comments": "21 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14270"
    },
    {
        "doc_id": 245,
        "title": "Phenomenology of TMD parton distributions in Drell-Yan and $Z^0$ boson production in a hadron structure oriented approach",
        "authors": [
            "F. Aslan",
            "M. Boglione",
            "J. O. Gonzalez-Hernandez",
            "T. Rainaldi",
            "T. C. Rogers",
            "A. Simonelli"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We present a first practical implementation of a recently proposed hadron structure oriented (HSO) approach to TMD phenomenology applied to Drell-Yan like processes, including lepton pair production at moderate $Q^2$ and $Z^0$ boson production. We compare and contrast general features of our methodology with other common practices and emphasize the improvements derived from our approach that we view as essential for applications where extracting details of nonperturbative transverse hadron structure is a major goal. These include the HSO's preservation of a basic TMD parton-model-like framework even while accounting for full TMD factorization and evolution, explicit preservation of the integral relationship between TMD and collinear pdfs, and the ability to meaningfully compare different theoretical models of nonperturbative TMD parton distributions. In our examples, we show that there is significant sensitivity at moderate $Q^2$ to both the form of the nonperturbative transverse momentum dependence and the parametrization of collinear parton densities. However, we also find that evolving to $Q^2 = M_Z^2$, without fitting, results in a satisfactory postdiction of existing data for $Z^0$ production, nearly independently of the modeling of nonperturbative transverse momentum behavior. We argue that this demonstrates that moderate $Q$ measurements should be given greater weight than high $Q$ measurements in extractions of nonperturbative transverse momentum dependence. We also obtain new extractions of the nonperturbative Collins-Soper kernel within the HSO approach. We discuss its features and compare with some earlier extractions.",
        "comments": "33 pages, 9 figures, 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14266"
    },
    {
        "doc_id": 246,
        "title": "Existence and characterization of edge states in an acoustic trimer Su-Schrieffer-Heeger model",
        "authors": [
            "I. Ioannou Sougleridis",
            "A. Anastasiadis",
            "O. Richoux",
            "V. Achilleos",
            "G. Theocharis",
            "V. Pagneux",
            "F. K. Diakonos"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "We report on a direct mapping of acoustic slender waveguides to the one dimensional trimer Su- Schrieffer-Heeger model, with neither chiral nor mirror symmetry. Importantly, we can choose to perform this mapping for either the acoustic velocity or pressure. We demonstrate that, for finite systems, this choice is necessarily linked to the boundary conditions. It allows for the unveiling of the edge states of the acoustic system through an edge state phase diagram. An experimental realization of our setup in the audible regime corroborates our theoretical predictions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14264"
    },
    {
        "doc_id": 247,
        "title": "Room temperature nonlocal detection of charge-spin interconversion in a topological insulator",
        "authors": [
            "Anamul Md. Hoque",
            "Lars Sj\u00f6str\u00f6m",
            "Dmitrii Khokhriakov",
            "Bing Zhao",
            "Saroj P. Dash"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "Topological insulators (TIs) are emerging materials for next-generation low-power nanoelectronic and spintronic device applications. TIs possess non-trivial spin-momentum locking features in the topological surface states in addition to the spin-Hall effect (SHE), and Rashba states due to high spin-orbit coupling (SOC) properties. These phenomena are vital for observing the charge-spin conversion (CSC) processes for spin-based memory, logic and quantum technologies. Although CSC has been observed in TIs by potentiometric measurements, reliable nonlocal detection has so far been limited to cryogenic temperatures up to T = 15 K. Here, we report nonlocal detection of CSC and its inverse effect in the TI compound Bi1.5Sb0.5Te1.7Se1.3 at room temperature using a van der Waals heterostructure with a graphene spin-valve device. The lateral nonlocal device design with graphene allows observation of both spin-switch and Hanle spin precession signals for generation, injection and detection of spin currents by the TI. Detailed bias- and gate-dependent measurements in different geometries prove the robustness of the CSC effects in the TI. These findings demonstrate the possibility of using topological materials to make all-electrical room-temperature spintronic devices.",
        "comments": "12 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14262"
    },
    {
        "doc_id": 248,
        "title": "Conservation laws and the foundations of quantum mechanics",
        "authors": [
            "Yakir Aharonov",
            "Sandu Popescu",
            "Daniel Rohrlich"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "In a recent paper, PNAS, 118, e1921529118 (2021), it was argued that while the standard definition of conservation laws in quantum mechanics, which is of a statistical character, is perfectly valid, it misses essential features of nature and it can and must be revisited to address the issue of conservation/non-conservation in individual cases. Specifically, in the above paper an experiment was presented in which it can be proven that in some individual cases energy is not conserved, despite being conserved statistically. It was felt however that this is worrisome, and that something must be wrong if there are individual instances in which conservation doesn't hold, even though this is not required by the standard conservation law. Here we revisit that experiment and show that although its results are correct, there is a way to circumvent them and ensure individual case conservation in that situation. The solution is however quite unusual, challenging one of the basic assumptions of quantum mechanics, namely that any quantum state can be prepared, and it involves a time-holistic, double non-conservation effect. Our results bring new light on the role of the preparation stage of the initial state of a particle and on the interplay of conservation laws and frames of reference. We also conjecture that when such a full analysis of any conservation experiment is performed, conservation is obeyed in every individual case.",
        "comments": "Journal ref:        PNAS, 120 (41) e2220810120 (2023)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14261"
    },
    {
        "doc_id": 249,
        "title": "Stability and Transport of Gyrokinetic Critical Pedestals",
        "authors": [
            "J. F. Parisi",
            "A. O. Nelson",
            "W. Guttenfelder",
            "R. Gaur",
            "J. W. Berkery",
            "S. M. Kaye",
            "K. Barada",
            "C. Clauser",
            "A. Diallo",
            "D. R. Hatch",
            "A. Kleiner",
            "M. Lampert",
            "T. Macwan",
            "J. E. Menard"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "A gyrokinetic threshold model for pedestal width-height scaling prediction is applied to multiple devices and to a shaping and aspect-ratio scan giving $\u0394_{\\mathrm{ped}} = 0.92 A^{1.04} \u03ba^{-1.24} 0.38^\u03b4 \u03b2_{\u03b8,\\mathrm{ped}}^{1.05}$ for pedestal width $\u0394_{\\mathrm{ped}}$, aspect-ratio $A$, elongation $\u03ba$, triangularity $\u03b4$, and normalized pedestal height $\u03b2_{\u03b8,\\mathrm{ped}}$. We also find a width-transport scaling $\u0394_{\\mathrm{ped} } = 0.028 \\left(q_e/\u0393_e - 1.7 \\right)^{1.5} \\sim \u03b7_e ^{1.5}$ where $q_e$ and $\u0393_e$ are turbulent electron heat and particle fluxes and $\u03b7_e = \\nabla \\ln T_e / \\nabla \\ln n_e$ for electron temperature $T_e$ and density $n_e$. Pedestals close to those limited by kinetic-ballooning-modes (KBMs) have modified turbulent transport properties compared to strongly driven KBMs. The role of flow shear is studied as a width-height scaling constraint and pedestal saturation mechanism for a standard and wide pedestal discharge.",
        "comments": "34 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14260"
    },
    {
        "doc_id": 250,
        "title": "Mpemba effects in nonequilibrium open quantum systems",
        "authors": [
            "Xuanhua Wang",
            "Jin Wang"
        ],
        "subjects": [
            "Quantum Physics",
            "Statistical Mechanics",
            "Chemical Physics"
        ],
        "abstract": "Originally, the Mpemba effect (MPE) is referred to the faster icing of a higher-temperature system than a system of a lower temperature. This concept was later generalized to anomalous decays of certain system quantities to the equilibrium states. In this study, we investigate the scenario when a system has no such equilibrium state to approach. Instead, the system is put in contact with two different baths, and only a nonequilibrium state exists, sustained by constant energy injection from the surrounding thermal baths. Firstly, we show that the nonequilibrium conditions can dramatically enlarge the parameter regimes where the MPE emerges. Secondly, we demonstrate that the anomalous MPEs and inverse MPEs emerge in the evolution of quantum correlations in the two-site fermionic system and that nonequilibrium conditions can expedite or delay the MPEs. Thirdly, we show that the nonequilibrium-induced quantum coherence can have considerable contributions to the emergence of the MPE which the conventional Lindbladian dynamics fails to capture.",
        "comments": "9 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14259"
    },
    {
        "doc_id": 251,
        "title": "On the vapour compression in cavitation bubbles",
        "authors": [
            "Davide Bernardo Preso",
            "Daniel Fuster",
            "Armand Baptiste Sieber",
            "Danail Obreschkow",
            "Mohamed Farhat"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "The composition of the gaseous phase of cavitation bubbles and its role on the collapse remains to date poorly understood. In this work, experiments of single cavitation bubbles in aqueous ammonia serve as a novel approach to investigate the effect of the vapour contained in a bubble on its collapse. We find that the higher vapour pressure of more concentrated aqueous ammonia acts as a resistance to the collapse, reducing the total energy dissipation. In line with visual observation, acoustic measurements, and luminescence recordings, it is also observed that higher vapour pressures contribute to a more spherical collapse, likely hindering the growth of interface instabilities by decreasing the collapse velocities and accelerations. Remarkably, we evidence a strong difference between the effective damping and the energy of the shock emission, suggesting that the latter is not the dominant dissipation mechanism at collapse as predicted from classical correction models accounting for slightly compressible liquids. Furthermore, our results suggest that the vapour inside collapsing bubbles gets compressed, consistently with previous studies performed in the context of single bubble sonoluminescence, addressing the question about the ability of vapours to readily condense during a bubble collapse in similar regimes. These findings provide insights into the identification of the influence of the bubble content and the energy exchanges of the bubble with its surrounding media, eventually paving the way to a more efficient use of cavitation in engineering and biomedical applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14253"
    },
    {
        "doc_id": 252,
        "title": "Variational Neural and Tensor Network Approximations of Thermal States",
        "authors": [
            "Sirui Lu",
            "Giacomo Giudice",
            "J. Ignacio Cirac"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks",
            "Strongly Correlated Electrons"
        ],
        "abstract": "We introduce a variational Monte Carlo algorithm for approximating finite-temperature quantum many-body systems, based on the minimization of a modified free energy. We employ a variety of trial states -- both tensor networks as well as neural networks -- as variational ans\u00e4tze for our numerical optimization. We benchmark and compare different constructions in the above classes, both for one- and two-dimensional problems, with systems made of up to \\(N=100\\) spins. Despite excellent results in one dimension, our results suggest that the numerical ans\u00e4tze employed have certain expressive limitations for tackling more challenging two-dimensional systems.",
        "comments": "7+9 pages, 3+4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14243"
    },
    {
        "doc_id": 253,
        "title": "Short-Time Infrequent Metadynamics for Improved Kinetics Inference",
        "authors": [
            "Ofir Blumer",
            "Shlomi Reuveni",
            "Barak Hirshberg"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Infrequent Metadynamics is a popular method to obtain the rate of long timescale processes from accelerated simulations. The inference procedure is based on rescaling the first-passage times of Metadynamics trajectories using a bias-dependent acceleration factor. While useful in many cases, it is limited to Poisson kinetics, and a reliable estimation of the unbiased rate requires slow bias deposition and prior knowledge of efficient collective variables. Here, we propose an improved inference scheme, which is based on two key observations: 1) The time-independent rate of Poisson processes can be estimated using short trajectories only. 2) Short trajectories experience minimal bias, and their rescaled first-passage times follow the unbiased distribution even for relatively high deposition rates and suboptimal collective variables. Therefore, by limiting the inference procedure to short timescales, we obtain an improved tradeoff between speedup and accuracy at no additional computational cost, especially when employing suboptimal collective variables. We demonstrate the improved inference scheme for a model system and two molecular systems.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14237"
    },
    {
        "doc_id": 254,
        "title": "Unraveling how winds and surface heat fluxes control the Atlantic Ocean's meridional heat transport",
        "authors": [
            "Dhruv Bhagtani",
            "Andrew McC. Hogg",
            "Ryan M. Holmes",
            "Navid C. Constantinou"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "The North Atlantic Ocean circulation, fueled by winds and surface buoyancy fluxes, carries 1.25$\\,$PettaWatts of heat poleward in the subtropics, and plays an important role in regulating global weather and climate patterns. Using a series of simulations with perturbed surface forcing, we study how winds and surface heat flux gradients affect the Atlantic meridional heat transport. We decompose the Atlantic meridional heat transport into contributions from circulation cells at warm and cold temperatures (resembling a subtropical gyre and the dense overturning circulation respectively), and a mixed circulation that contains water masses traversing both these cells. Variations in wind stress initially alter the amount of heat carried by the warm and mixed cells, but on long time scales ($>$10 years), changes in the temperature distribution restore the heat transport to equilibrium. Changes in surface buoyancy forcing control the cold cell's circulation, and its associated meridional heat flux, through high-latitude processes.",
        "comments": "13 pages, 3 figures, submitted to the Geophysical Research Letters",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14230"
    },
    {
        "doc_id": 255,
        "title": "Exploring the time axis within medium-modified jets",
        "authors": [
            "Liliana Apolin\u00e1rio",
            "Pablo Guerrero-Rodr\u00edguez",
            "Korinna Zapp"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "In this manuscript, we illustrate how to use the newly proposed $\u03c4$ re-clustering algorithm to select jets with different degrees of quenching without biasing their initial transverse momentum spectrum. Our study is based on Z+jet simulated events using the JEWEL Monte Carlo event generator to account for jet quenching effects. We apply the $\u03c4$ re-clustering algorithm to extract a proxy for a time axis (formation time) within the evolving medium. This information allows us to label jets according to their fragmentation pattern and select populations with enhanced sensitivity to quenching effects. Our results illustrate the potential of jets as precision tools for QGP tomography. Further, we show that the discussed method minimizes the biases stemming from $p_{T}$-, $dR$- or mass-based jet selection.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14229"
    },
    {
        "doc_id": 256,
        "title": "Periodically Forced Nonlinear Oscillatory Acoustic Vacuum",
        "authors": [
            "Makrina Agaoglou",
            "Michal Feckan",
            "Michal Pospisil",
            "Vassilis M. Rothos",
            "Alexander F. Vakakis"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "In this work, we study the in-plane oscillations of a finite lattice of particles coupled by linear springs under distributed harmonic excitation. Melnikov-type analysis is applied for the persistence of periodic oscillations of a reduced system.",
        "comments": "11 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14227"
    },
    {
        "doc_id": 257,
        "title": "On the well-posedness of inverse problems under information field theory: application to model-form error detection",
        "authors": [
            "Alex Alberts",
            "Ilias Bilionis"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "We derive properties of information field theory (IFT) as applied to inverse problems. The results here can be extended to methodologies which can be seen as limiting cases of IFT, such as Gaussian process regression and physics-informed machine learning. We first define the concept of a well-posed inverse problem within the context of IFT, and pose a few useful theorems for conditions in which an inverse problem becomes well-posed. Using the Gaussian random field interpretation of IFT, we show how identifying parameters of a covariance kernel becomes a well-posed inverse problem under certain conditions. An expression for the Hessian of the inverse problem log posterior is derived to construct the results. A specific focus is placed on the inverse problem of detecting model-form error. We provide an example where the physics are assumed to be the Poisson equation and prove conditions for which identifying model-form error in this case becomes a well-posed inverse problem under IFT.",
        "comments": "16 pages. Will be presented at SIAM Conference on Uncertainty Quantification 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14224"
    },
    {
        "doc_id": 258,
        "title": "Application of performance portability solutions for GPUs and many-core CPUs to track reconstruction kernels",
        "authors": [
            "Ka Hei Martin Kwok",
            "Matti Kortelainen",
            "Giuseppe Cerati",
            "Alexei Strelchenko",
            "Oliver Gutsche",
            "Allison Reinsvold Hall",
            "Steve Lantz",
            "Michael Reid",
            "Daniel Riley",
            "Sophie Berkman",
            "Seyong Lee",
            "Hammad Ather",
            "Boyana Norris",
            "Cong Wang"
        ],
        "subjects": [
            "Accelerator Physics"
        ],
        "abstract": "Next generation High-Energy Physics (HEP) experiments are presented with significant computational challenges, both in terms of data volume and processing power. Using compute accelerators, such as GPUs, is one of the promising ways to provide the necessary computational power to meet the challenge. The current programming models for compute accelerators often involve using architecture-specific programming languages promoted by the hardware vendors and hence limit the set of platforms that the code can run on. Developing software with platform restrictions is especially unfeasible for HEP communities as it takes significant effort to convert typical HEP algorithms into ones that are efficient for compute accelerators. Multiple performance portability solutions have recently emerged and provide an alternative path for using compute accelerators, which allow the code to be executed on hardware from different vendors. We apply several portability solutions, such as Kokkos, SYCL, C++17 std::execution::par and Alpaka, on two mini-apps extracted from the mkFit project: p2z and p2r. These apps include basic kernels for a Kalman filter track fit, such as propagation and update of track parameters, for detectors at a fixed z or fixed r position, respectively. The two mini-apps explore different memory layout formats.\n  We report on the development experience with different portability solutions, as well as their performance on GPUs and many-core CPUs, measured as the throughput of the kernels from different GPU and CPU vendors such as NVIDIA, AMD and Intel.",
        "comments": "26th Intl Conf Computing High Energy & Nuclear Phys (CHEP 2023)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14221"
    },
    {
        "doc_id": 259,
        "title": "Shocks, clouds and atomic outflows in active galactic nuclei hosting relativistic jets",
        "authors": [
            "Manel Perucho"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Astrophysics of Galaxies"
        ],
        "abstract": "A number of observations have revealed atomic and/or molecular lines in active galaxies hosting jets and outflows. Line widths indicate outward motions of hundreds to few thousands of kilometers per second. They appear associated to the presence of radio emission in Gigahert-peaked spectrum (GPS) and compact steep spectrum (CSS) sources, with linear sizes < 10 kpc. Numerical simulations have shown that the bow shocks triggered by relativistic jets in their host galaxies drive ionisation and turbulence in the interstellar medium (ISM). However, the presence of atomic lines requires rapid recombination of ionised gas, which seems to be hard to explain from the physical conditions revealed so far by numerical simulations of powerful jets. The aim of this paper is to provide a global frame to explain the presence of lines in terms of jet and shock evolution, and fix the parameter space in which the atomic and molecular outflows might occur. This parameter space is inspired by numerical simulations and basic analytical models of jet evolution as a background. Our results show that a plausible, general explanation involves momentum transfer and heating to the interstellar medium gas by jet triggered shocks within the inner kiloparsecs. The presence of post-shock atomic gas is possible in the case of shocks interacting with dense clouds that remain relatively stable after the shock passage. According to our results, current numerical simulations cannot reproduce the physical conditions to explain the presence of atomic and molecular outflows in young radio-sources. However, I show that these outflows might occur in low-power jets at all scales, and predict a trend towards powerful jets showing lines at CSS scales, when clouds have cooled to recombination temperatures.",
        "comments": "Accepted for publication in Astronomy & Astrophysics",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14218"
    },
    {
        "doc_id": 260,
        "title": "The explicit form of the unitary representation of the Poincar\u00e9 group for vector-valued wave functions (massive and massless), with applications to photon's localization and position operators",
        "authors": [
            "Arkadiusz Jadczyk"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "We geometrically derive the explicit form of the Unitary representation of the Poincare group and use it to apply speed-of-light boosts to simple polarization basis to end up with Hawton-Baylis photon position operator with commuting components. We give explicit formulas for other photon boost eigenmodes. We investigate the underlying affine connections on the light cone in momentum space and find that while Pryce connection is metric semi-symmetric, the flat Hawton-Baylis connection is not semi-symmetric. Finally we discuss localizability of photon states localized on closed loops and show that photon states on the circle, both unnormalized improper states and finite norm wave packet smeared over washer-like regions are strictly localized with respect to Hawton-Baylis operators with commuting components and also with respect to the noncommutative Jauch-Piron-Amrein POV measure.",
        "comments": "30 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14217"
    },
    {
        "doc_id": 261,
        "title": "At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition",
        "authors": [
            "Ashok Dahal",
            "Rapha\u00ebl Huser",
            "Luigi Lombardo"
        ],
        "subjects": [
            "Machine Learning",
            "Geophysics",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple return periods. We also use our model to further explore landslide hazard for the same return periods under different climate change scenarios up to the end of the century. Our results show that the proposed model performs excellently and can be used to model landslide hazard in a unified manner. Geomorphologically, we find that under both climate change scenarios (SSP245 and SSP885), landslide hazard is likely to increase up to two times on average in the lower Himalayan regions while remaining the same in the middle Himalayan region whilst decreasing slightly in the upper Himalayan region areas.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14210"
    },
    {
        "doc_id": 262,
        "title": "Quantum information recovery from black hole with projective measurement",
        "authors": [
            "Ran Li",
            "Jin Wang"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Theory",
            "Quantum Physics"
        ],
        "abstract": "We studied the Hayden-Preskill thought experiment with the local projective measurement. Compared to the original model, the measurement is applied on the Hawking radiation that was emitted after throwing the quantum diary into the black hole. Within this setup, we explored various aspects of this model, including the information recovery from the black hole, the relation to the black hole final state proposal, the relation between the Yoshida-Kitaev protocol and Petz recovery map, the effects of the decoherence, and the quantum simulations of the decoding protocols. These aspects may provide us new insights into the non-perturbative nature of quantum black holes.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14207"
    },
    {
        "doc_id": 263,
        "title": "Experimental investigations of underwater and airborne noises produced by a large hovercraft in Ural River estuary",
        "authors": [
            "A. I. Vedenev",
            "O. Yu. Kochetov",
            "A. A. Lunkov",
            "A. S. Shurup",
            "S. S. Kassymbekova"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Simultaneous measurements of underwater and airborne noises produced by Griffon Hoverwork BHT130 hovercraft were carried out in environmentally sensitive area - wildlife preserve in the area of the Ural River estuary near the Caspian Sea shelf. Measurements were organized to assess the possible negative impact of noise from hovercraft on fish and birds in wildlife preserve. The particle velocity of underwater noise was estimated by using a gradient-type vector receiver. That was a distinctive aspect of the underwater noise studies since the majority of fish perceives the sound in terms of vibration of particles, and only a few as the pressure. Using synchronous recording of underwater and airborne noises, the mutual correlation of these data was investigated. The obtained correlation levels between underwater and airborne noises produced by hovercraft can be used for simplified estimation of the upper boundary of underwater noise level by measuring levels of airborne noise. The measured and estimated maximal levels of underwater noises of hovercraft are considerably lower than noises from conventional vessels with underwater engines, that makes hovercraft attractive alternative for use in locations with high underwater noise requirements, such as Ural River estuary and Caspian Sea shelf.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14204"
    },
    {
        "doc_id": 264,
        "title": "Investigating Organic Carbon and Thermal History of CM Carbonaceous Chondrites Using Spectroscopy and Laboratory Techniques",
        "authors": [
            "Safoura Tanbakouei",
            "Rui-Lin Cheng",
            "Binlong Ye",
            "Josep Ryan Michalski",
            "Ashley J. King"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics",
            "Instrumentation and Methods for Astrophysics",
            "Geophysics"
        ],
        "abstract": "The CM chondrites are characterized as primary accretionary rocks which originate from primitive water-rich asteroids formed during the early Solar System. Here, we study the mineralogy and organic characteristics of right CM and one ungrouped chondrite to better understand their alteration history; Queen Alexandra Range 93005 (QUE 93005), Murchison, LaPaz Icefield 02333 (LAP 02333), Miller Range (MIL 13005), Mackay Glacier 05231 (MCY 05231), Northwest Africa 8534 (NWA 8534), Northwest Africa 3340 (NWA 3340), Yamato 86695 (Y-86695), and the ungrouped carbonaceous chondrite Belgica 7904 (B-7904). Raman spectroscopy has been employed to detect the presence of organic carbon in the samples, specifically through the G band at approximately 1580 cm-1 and D band at around 1350 cm-1. The properties of organic matter in meteorites serve as valuable indicators for characterizing the structure and crystallinity of carbonaceous materials and estimating their thermal metamorphism degree. The R1 parameter, defined as the peak height ratio of the D and G bands, provides a quantifiable measure of this structural organization. Raman spectra are used to show the general mineralogy, thermal history and heating stage of CM and ungrouped chondrites. X-ray diffraction patterns further indicate the mineralogical compositions of the samples. Visible to near-infrared (VNIR) and attenuated total reflection (ATR) reflectance spectra illustrate the trends related to their mineralogy and furthermore infer aqueous alteration, thermal history of CM carbonaceous chondrites, formation and evolution of their parent bodies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14201"
    },
    {
        "doc_id": 265,
        "title": "Speeding up Fermionic Lattice Calculations with Photonic Accelerated Inverters",
        "authors": [
            "Felipe Attanasio",
            "Marc Bauer",
            "Jelle Dijkstra",
            "Timoteo Lee",
            "Jan M. Pawlowski",
            "Wolfram Pernice"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "Applied Physics",
            "Computational Physics"
        ],
        "abstract": "Lattice field theory (LFT) is the standard non-perturbative method to perform numerical calculations of quantum field theory. However, the typical bottleneck of fermionic lattice calculations is the inversion of the Dirac matrix. This inversion is solved by iterative methods, like the conjugate gradient algorithm, where matrix-vector multiplications (MVMs) are the main operation. Photonic integrated circuits excel in performing quick and energy-efficient MVMs, but at the same time, they are known to have low accuracy. This can be overcome by using mixed precision methods. In this paper, we explore the idea of using photonic technology to fulfil the demand for computational power of fermionic lattice calculations. These methods have the potential to reduce computation costs by one order of magnitude. Because of the hybrid nature of these methods, we call these 'photonic accelerated inverters (PAIs)'.",
        "comments": "10 pages, 8 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14200"
    },
    {
        "doc_id": 266,
        "title": "Deep Learning to Improve the Sensitivity of Di-Higgs Searches in the $4b$ Channel",
        "authors": [
            "Cheng-Wei Chiang",
            "Feng-Yang Hsieh",
            "Shih-Chieh Hsu",
            "Ian Low"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The study of di-Higgs events, both resonant and non-resonant, plays a crucial role in understanding the fundamental interactions of the Higgs boson. In this work we consider di-Higgs events decaying into four $b$-quarks and propose to improve the experimental sensitivity by utilizing a novel machine learning algorithm known as Symmetry Preserving Attention Network (\\textsc{Spa-Net}) -- a neural network structure whose architecture is designed to incorporate the inherent symmetries in particle reconstruction tasks. We demonstrate that the \\textsc{Spa-Net} can enhance the experimental reach over baseline methods such as the cut-based and the Deep Neural Networks (DNN)-based analyses. At the Large Hadron Collider, with a 14-TeV centre-of-mass energy and an integrated luminosity of 300 fb$^{-1}$, the \\textsc{Spa-Net} allows us to establish 95\\% C.L. upper limits in resonant production cross-sections that are 10\\% to 45\\% stronger than baseline methods. For non-resonant di-Higgs production, \\textsc{Spa-Net} enables us to constrain the self-coupling that is 9\\% more stringent than the baseline method.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14198"
    },
    {
        "doc_id": 267,
        "title": "Sensitivity of two-mode SRF cavity to generic electromagnetic interactions of ultralight dark matter",
        "authors": [
            "Chang-Jie Dai",
            "Tong Li",
            "Rui-Jia Zhang"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The ultralight dark matter (ULDM) such as axion or wavelike scalar plays as a plausible DM candidate. Recently, the possible non-standard ULDM couplings draw much attention. In this work we investigate the detection of electromagnetic couplings in a few benchmark models of ULDM. For illustration, we consider the generic axion electrodynamics including CP violating coupling as well as the newly proposed axion electromagnetodynamics. The superconducting radio frequency (SRF) cavity with two-mode has more advantages than the traditional cavity approach with static background field. We utilize the two-mode SRF cavity to probe the generic couplings of ULDM with frequency lower than GHz. The choices of the transverse electromagnetic modes are explicitly specified for the detection. We show the sensitivity of the SRF cavity to the axion couplings in the above frameworks.",
        "comments": "26 pages, 3 figures, 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14195"
    },
    {
        "doc_id": 268,
        "title": "Interactions of the Pseudoscalar Meson Octet and the Baryon Decuplet in the Continuum and a Finite Volume",
        "authors": [
            "Teng Ji",
            "Xiang-Kun Dong",
            "Ulf-G. Mei\u00dfner"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "High Energy Physics - Lattice",
            "Nuclear Theory"
        ],
        "abstract": "This study focuses on the interaction of the pseudoscalar meson octet and the baryon decuplet. In the continuum, it is observed that several $J^{P}=\\frac32^-$ baryon resonances can be produced by the Weinberg-Tomozawa interaction in unitarized chiral perturbation theory, including the $N(1875)$, $\u03a3(1670)$, $\u03a3(1910)$, $\u039e(1820)$ and $\u03a9(2012)$. Among them, the $\u039e(1820)$ and $\u03a3(1670)$ may exhibit a potential two-pole structures. The unitarized chiral perturbation approach is then applied as the underlying theory to predict the energy levels of these systems in a finite volume. These energy levels are well described by the $K$-matrix parameterization constrained by flavor SU(3) symmetry. With the parameters from the best fits, the poles extracted from the $K$-matrix parameterization closely correspond to those derived from the underlying chiral effective field theory, as long as they are close to physical region and not significantly higher than the lowest relevant threshold.",
        "comments": "11 pages, 6 figures and 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14188"
    },
    {
        "doc_id": 269,
        "title": "Non-symmetrical sparking may hint \"zits'' on a pulsar surface",
        "authors": [
            "Zhengli Wang",
            "Jiguang Lu",
            "Jingchen Jiang",
            "Shunshun Cao",
            "Weiyang Wang",
            "Enwei Liang",
            "Renxin Xu"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Pulsar electrodynamics could be relevant to the physics of stellar surface, which remains poorly understood for more than half a centenary and is difficult to probe due to the absence of direct and clear observational evidence. Nevertheless, highly-sensitive telescopes (e.g., China's Five-hundred-meter Aperture Spherical radio Telescope, FAST) may play an essential role in solving the problem since the predicted surface condition would have quite different characteristics in some models of pulsar structure, especially after the establishment of the standard model of particle physics. For instance, small hills (or ``zit'') may exist on solid strangeon star surface with rigidity, preferential discharge, i.e., gap sparking, may occur around the hills in the polar cap region. In this work, with the 110-min polarization observation of PSR B0950+08 targeted by FAST, we report that the gap sparking is significantly non-symmetrical to the meridian plane on which the rotational and magnetic axes lie. It is then speculated that this asymmetry could be the result of preferential sparking around zits which might rise randomly on pulsar surface. Some polarization features of both single pulses and the mean pulse, as well as the cross-correlation function of different emission regions, have also been presented.",
        "comments": "Accepted for publication in Astronomische Nachrichten",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14181"
    },
    {
        "doc_id": 270,
        "title": "Magnetic fields of protoplanetary disks",
        "authors": [
            "Sergey A. Khaibrakhmanov"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Earth and Planetary Astrophysics",
            "Plasma Physics"
        ],
        "abstract": "We review the current status of studies on accretion and protoplanetary disks of young stars with large-scale magnetic fields. Observational data on magnetic fields of the disks are compiled and analysed. Modern analytical and numerical MHD models of protoplanetary disks are discussed. The mechanisms of angular momentum transport via turbulence, magnetic tensions and outflows are outlined. We consider the influence of Ohmic dissipation, magnetic ambipolar diffusion, magnetic buoyancy, and the Hall effect on the evolution of the magnetic flux in disks. Modern MHD models of accretion disks show that the magnetic field can influence the structure of protoplanetary disks. We argue that the available observational data on the magnetic fields in protoplanetary disks can be interpreted within the framework of fossil magnetic field theory. We summarize the problems of the modern theory of accretion and protoplanetary disks with magnetic fields and also outline the prospects for further research.",
        "comments": "31 pages, 1 table, 2 figures, accepted to Astronomical and Astrophysical Transactions",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14180"
    },
    {
        "doc_id": 271,
        "title": "Deep Neural Networks as Variational Solutions for Correlated Open Quantum Systems",
        "authors": [
            "Johannes Mellak",
            "Enrico Arrigoni",
            "Wolfgang von der Linden"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks"
        ],
        "abstract": "In this work we apply deep neural networks to find the non-equilibrium steady state solution to correlated open quantum many-body systems. Motivated by the ongoing search to find more powerful representations of (mixed) quantum states, we design a simple prototypical convolutional neural network and show that parametrizing the density matrix directly with more powerful models can yield better variational ansatz functions and improve upon results reached by neural density operator based on the restricted Boltzmann machine. Hereby we give up the explicit restriction to positive semi-definite density matrices. However, this is fulfilled again to good approximation by optimizing the parameters. The great advantage of this approach is that it opens up the possibility of exploring more complex network architectures that can be tailored to specific physical properties. We show how translation invariance can be enforced effortlessly and reach better results with fewer parameters. We present results for the dissipative one-dimensional transverse-field Ising model and a two-dimensional dissipative Heisenberg model compared to exact values.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14179"
    },
    {
        "doc_id": 272,
        "title": "Multicasting Optical Reconfigurable Switch",
        "authors": [
            "Niyazi Ulas Dinc",
            "Mustafa Yildirim",
            "Christophe Moser",
            "Demetri Psaltis"
        ],
        "subjects": [
            "Optics",
            "Networking and Internet Architecture"
        ],
        "abstract": "Artificial Intelligence (AI) demands large data flows within datacenters, heavily relying on multicasting data transfers. As AI models scale, the requirement for high-bandwidth and low-latency networking compounds. The common use of electrical packet switching faces limitations due to its optical-electrical-optical conversion bottleneck. Optical switches, while bandwidth-agnostic and low-latency, suffer from having only unicast or non-scalable multicasting capability. This paper introduces an optical switching technique addressing the scalable multicasting challenge. Our approach enables arbitrarily programmable simultaneous unicast and multicast connectivity, eliminating the need for optical splitters that hinder scalability due to optical power loss. We use phase modulation in multiple planes, tailored to implement any multicast connectivity map. Using phase modulation enables wavelength selectivity on top of spatial selectivity, resulting in an optical switch that implements space-wavelength routing. We conducted simulations and experiments to validate our approach. Our results affirm the concept's feasibility and effectiveness, as a multicasting switch.",
        "comments": "12 pages, 3 figures, article",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14173"
    },
    {
        "doc_id": 273,
        "title": "No-go guide for the Hubble tension: late-time or local-scale new physics",
        "authors": [
            "Lu Huang",
            "Shao-Jiang Wang",
            "Wang-Wei Yu"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "The standard model of modern cosmology might be cracked by the recent persistent hot debate on the Hubble-constant ($H_0$) tension, which manifests itself as the sound-horizon ($r_s$) tension or absolute-magnitude ($M_B$) tension if deeming the origin of the Hubble tension from modifying the early or late Universe, respectively. In this Letter, we achieve a fully model-independent constraint (fitting a model-independent global parameterization to a model-independent inverse distant ladder with a model-independent high-redshift calibration) on late-time models with strong evidence against homogeneous new physics over the $\u039b$-cold-dark ($\u039b$CDM) model. Further using this model-independent constraint to calibrate sufficiently local supernovae with corresponding late-time models extrapolated below the homogeneity scale, we find surprisingly that, although both $H_0$ tension and $M_B$ tension are absent in our local Universe, a combination of $H_0$ and $M_B$ as the intercept $a_B$ of the magnitude-redshift relation exhibits $3\\sim 7\u03c3$ tension even for the $\u039b$CDM model. This $a_B$ tension seems to call for local-scale inhomogeneous new physics disguised as local observational systematics.",
        "comments": "5 pages + references, 1 table and 3 figures, codes can be found at https://github.com/huanglu37/No-go-guide-for-the-Hubble-tension-late-time-or-local-scale-new-physics and chains can be found at https://zenodo.org/records/10559728",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14170"
    },
    {
        "doc_id": 274,
        "title": "Runaway Electron Dynamics in ITER Disruptions with Shattered Pellet Injections",
        "authors": [
            "Oskar Vallhagen",
            "Lise Hanebring",
            "Javier Artola",
            "Michael Lehnen",
            "Eric Nardon",
            "T\u00fcnde F\u00fcl\u00f6p",
            "Mathias Hoppe",
            "Sarah Newton",
            "Istvan Pusztai"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "This study systematically explores the parameter space of disruption mitigation through shattered pellet injection in ITER with a focus on runaway electron dynamics, using the disruption modelling tool DREAM. The physics fidelity is considerably increased compared to previous studies, by e.g., using realistic magnetic geometry, resistive wall configuration, thermal quench onset criteria, as well as including additional effects, such as ion transport and enhanced runaway electron transport during the thermal quench. The work aims to provide a fairly comprehensive coverage of experimentally feasible scenarios, considering plasmas representative of both non-activated and high-performance DT operation, different thermal quench onset criteria and transport levels, a wide range of hydrogen and neon quantities injected in one or two stages, and pellets with various characteristic shard sizes. Using a staggered injection scheme, with a pure hydrogen injection preceding a mixed hydrogen-neon injection, we find injection parameters leading to acceptable runaway electron currents in all investigated discharges without activated runaway sources. Dividing the injection into two stages is found to significantly enhance the assimilation and minimize runaway electron generation due to the hot-tail mechanism. However, while a staggered injection outperforms a single stage injection also in cases with radioactive runaway electron sources, no cases with acceptable runaway electron currents are found for a DT-plasma with a 15 MA plasma current.",
        "comments": "16 pages, 7 figures, submitted to Nuclear Fusion",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14167"
    },
    {
        "doc_id": 275,
        "title": "QCD analysis of the $P$-wave charmonium electromagnetic Dalitz decays $h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-}$",
        "authors": [
            "Chao-Jie Fan",
            "Jun-Kang He"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The $P$-wave charmonium electromagnetic Dalitz decays $h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-}$ $(\\ell=e, \u03bc)$ with large recoil momentum are investigated in the framework of perturbative QCD, and the soft contributions from the small recoil momentum region are described by the overlap of soft wave functions. The transition form factors $f_{h_{c}\u03b7^{(\\prime)}}(q^{2})$ and the normalized transition form factors $F_{h_{c} \u03b7^{(\\prime)}}(q^{2})$ in full kinematic region are derived for the first time. It is noticed that there are no extra IR divergences at the one-loop level and the tree level, and the transition form factors in which the relativistic corrections from the internal momentum of $h_{c}$ are taken into account are insensitive to both the shapes of $\u03b7^{(\\prime)}$ distribution amplitudes and the invariant mass of the lepton pair in the large recoil momentum region. Furthermore, we find that the contributions from the soft mechanism and those from hard mechanism are comparable with each other in the branching ratios $\\mathcal{B}(h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-})$. By employing the obtained $F_{h_{c} \u03b7^{(\\prime)}}(q^{2})$, we give the predictions of the branching ratios $\\mathcal{B}(h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-})$, which may come within the range of measurement of present or near-future experiments.",
        "comments": "32 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14152"
    },
    {
        "doc_id": 276,
        "title": "Polarized and bright telecom C-band single-photon source from InP-based quantum dots coupled to elliptical Bragg gratings",
        "authors": [
            "Zhenxuan Ge",
            "Tunghsun Chung",
            "Yu-Ming He",
            "Mohamed Benyoucef",
            "Yongheng Huo"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Bright, polarized, and high-purity single-photon sources in telecom wavelengths are crucial components in long-distance quantum communication, optical quantum computation and quantum networks. Semiconductor InAs/InP quantum dots (QDs) combined with photonic cavities provide a competitive path leading to optimal single-photon sources in this range. Here, we demonstrate a bright and polarized single-photon source operating in the telecom C-band based on an elliptical Bragg grating (EBG) cavity. With a significant Purcell enhancement of 5.25$\\pm$0.05, the device achieves a polarization ratio of 0.986, single-photon purity of g^2 (0)=0.078$\\pm$0.016 and single-polarized photon collection efficiency of ~ 24% at the first lens (NA=0.65) without blinking. These findings suggest that C-band QD-based single-photon sources are potential candidates for advancing quantum communication.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14150"
    },
    {
        "doc_id": 277,
        "title": "Mathematical Tri-State Model for Bee Shimmering Propagation Dynamics",
        "authors": [
            "Navin Patel",
            "Henri Huijberts",
            "Kaspar Althoefer",
            "Ketao Zhang"
        ],
        "subjects": [
            "Adaptation and Self-Organizing Systems",
            "Dynamical Systems",
            "Biological Physics"
        ],
        "abstract": "Bees undergo a self-organised process known as shimmering, where they form emergent patterns when they interact with each other on the nest surface as a defence mechanism in response to predator attacks. Many experimental studies have empirically investigated how the transfer of information to neighbouring bees propagates in various shimmering processes by measuring shimmering wave strength. However, there is no analytical modelling of the collective defence mechanism in nature. Here we introduce the first analytical tri-state Inactive-Active-Relapse (IAR) model to formulate the intrinsic process of bee shimmering. The major shimmering behaviour is shown to emerge under theoretical conditions which is demonstrated numerically and visually by simulating 1,000,000 bee agents, while the number of agents is scalable. Furthermore, we elaborate on these mathematical results to construct a wave strength function to demonstrate the accuracy of shimmering dynamics. The constructed wave strength function can be adapted to peak between 50-150ms which supports the experimental studies. Our results provide a foundation for further theoretical understanding of bee shimmering wave dynamics and could serve as inspiration for modelling other self-organised phenomena across scientific applications.",
        "comments": "20 pages, 7 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14145"
    },
    {
        "doc_id": 278,
        "title": "Efficient photon-pair generation empowered by dual quasi-bound states in the continuum",
        "authors": [
            "Tingting Liu",
            "Meibao Qin",
            "Siqi Feng",
            "Xu Tu",
            "Tianjing Guo",
            "Feng Wu",
            "Shuyuan Xiao"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Here we demonstrate the efficient photon-pair generation via spontaneous parametric down conversion from a semiconductor metasurface supporting dual quasi-bound states in the continuum (quasi-BICs). In a simple metasurface design composed of AlGaAs ellipse nano-cyclinders, the two high-$Q$ quasi-BIC resonances that coincide with the generated signal and idler frequencies significantly boost the local electric field. This leads to a substantial enhancement in the reverse classical nonlinear process of sum frequency generation and subsequently the remarkable high generation rate of photon pairs under the quantum-classical correspondence principle. Within a narrowband wavelength regime around the quasi-BIC resonances, the rate of pair production is enhanced up to $\\sim10^{4}$ Hz, two orders of magnitude larger than that in the Mie resonant AlGaAs nanoantennas. Moreover, the photon pair emission is mainly concentrated in the normal direction with respect to the metasurface, and shows tunable rate with the $Q$ factor by engineering the rotation angle of nano-cylinders. The presented work enables nanoscale sources of high-quality entangled photons which will find applications in advanced quantum imaging and communications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14140"
    },
    {
        "doc_id": 279,
        "title": "Micro and Nano 3D investigation of complex gut alterations-dementia interplay",
        "authors": [
            "F. Palermo",
            "N. Marrocco",
            "L. Dacom",
            "E. Grisafi",
            "M. Musella",
            "A. Sanna",
            "L. Massimi",
            "I. Bukreeva",
            "O. Junemann",
            "M. Eckermann",
            "P. Cloetens",
            "T. Weitkamp",
            "N. Kerlero de Rosbo",
            "C. Balducci",
            "A. Cedola"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Alzheimer's disease (AD), a debilitating neurodegenerative disorder, remains one of the foremost public health challenges of our time. Despite decades of research, its etiology largely remains enigmatic. Recently, attention has turned to the gut-brain axis, a complex network of communication between the gastrointestinal tract and the brain, as a potential player in the pathogenesis of AD. Here we exploited X-ray Phase Contrast Tomography to provide an in-depth analysis of the link between the gut condition and AD, exploring gut anatomy and structure in murine models. We conducted a comprehensive analysis by comparing the outcomes in various mouse models of cognitive impairment, including AD, frail mice, and frontotemporal dementia (FTD) affected mice. We discovered an association between substantial changes in the gut structure and the presence of amyloid-beta (A\\b{eta}) in the brain. We found that the most important gut alterations are related to A\\b{eta} occurrence in the brain. In particular, we investigated the gut morphology, the distribution of enteric micro-processes and neurons in the ileum. Understanding the intricate interplay between gut condition and dementia may open new avenues for early AD diagnosis and treatment offering hope for a future where these diseases may be more effectively addressed.",
        "comments": "9 pages and 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14139"
    },
    {
        "doc_id": 280,
        "title": "Homoclinic chaos in a pair of parametrically-driven coupled SQUIDs",
        "authors": [
            "M. Agaoglou",
            "V. M. Rothos",
            "H. Susanto"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Mathematical Physics"
        ],
        "abstract": "An rf superconducting quantum interference device (SQUID) consists of a superconducting ring interrupted by a Josephson junction (JJ). When driven by an alternating magnetic field, the induced supercurrents around the ring are determined by the JJ through the celebrated Josephson relations. This system exhibits rich nonlinear behavior, including chaotic effects. We study the dynamics of a pair of parametrically-driven coupled SQUIDs arranged in series. We take advantage of the weak damping that characterizes these systems to perform a multiple-scales analysis and obtain amplitude equations, describing the slow dynamics of the system. This picture allows us to expose the existence of homoclinic orbits in the dynamics of the integrable part of the slow equations of motion. Using high-dimensional Melnikov theory, we are able to obtain explicit parameter values for which these orbits persist in the full system, consisting of both Hamiltonian and non-Hamiltonian perturbations, to form so-called Silnikov orbits, indicating a loss of integrability and the existence of chaos.",
        "comments": "4 pages. arXiv admin note: text overlap with arXiv:1007.3939 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14128"
    },
    {
        "doc_id": 281,
        "title": "Spatially Resolved High Voltage Kelvin Probe Force Microcopy: A Novel Avenue for Examining Electrical Phenomena at Nanoscale",
        "authors": [
            "Conor J. McCluskey",
            "Niyorjyoti Sharma",
            "Jesi R. Maguire",
            "Serene Pauly",
            "Andrew Rogers",
            "TJ Lindsay",
            "Kristina M. Holsgrove",
            "Brian J. Rodriguez",
            "Navneet Soin",
            "John Marty Gregg",
            "Raymond G. P. McQuaid",
            "Amit Kumar"
        ],
        "subjects": [
            "Materials Science",
            "Applied Physics"
        ],
        "abstract": "Kelvin probe microscopy (KPFM) is a well-established scanning probe technique, used to measure surface potential accurately; it has found extensive use in the study of a range of materials phenomena. In its conventional form, KPFM frustratingly precludes imaging samples or scenarios where large surface potential exists or large surface potential gradients are created outside the typical +/-10V window. If the potential regime measurable via KPFM could be expanded, to enable precise and reliable metrology, through a high voltage KPFM (HV-KPFM) adaptation, it could open up pathways towards a range of novel experiments, where the detection limit of regular KPFM has so far prevented the use of the technique. In this work, HV-KPFM has been realised and shown to be capable of measuring large surface potential and potential gradients with accuracy and precision. The technique has been employed to study a range of materials (positive temperature coefficient of resistivity ceramics, charge storage fluoropolymers and pyroelectrics) where accurate spatially resolved mapping of surface potential within high voltage regime facilitates novel physical insight. The results demonstrate that HV-KPFM can be used as an effective tool to fill in existing gaps in surface potential measurements while also opening routes for novel studies in materials physics.",
        "comments": "Main Text: 16 pages, 5 figures Supplementary information:4 pages, 2 tables and 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14124"
    },
    {
        "doc_id": 282,
        "title": "Heavy baryon decays into light meson and dark baryon within LCSR",
        "authors": [
            "Yu-Ji Shi",
            "Ye Xing",
            "Zhi-Peng Xing"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We studied the decays of Heavy baryon into a pseudoscalar meson and a dark baryon in the recently developed $B$-Mesogenesis scenario, where the two types of effective Lagrangians proposed by the scenario are both considered. The decay amplitudes of $\u039b_b^0$ are calculated by light-cone sum rules using its light-cone distribution amplitudes. The decay amplitudes of $\u039e_b^{0,\\pm}$ are related with those of $\u039b_b^0$ through a flavor SU(3) analysis. The uncertainties of threshold parameter and the Borel parameter are both considered in the numerical calculation. The values of effective coupling constants in the $B$-Mesogenesis are taken as their upper limits that obtained from our previous study on the inclusive decay. The upper limits of the decay branching fractions are presented as functions of the dark baryon mass.",
        "comments": "21 pages, 9 figures, 3 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14120"
    },
    {
        "doc_id": 283,
        "title": "Pseudoscalar mesons from a PNJL model at zero temperature",
        "authors": [
            "R. M. Aguirre",
            "O. Louren\u00e7o"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We study pseudoscalar $\u03c0$, $K$ and $\u03b7$ meson properties, such as masses and couplings, in dense matter at zero temperature. We use a recently proposed phenomenological quark model, known as the PNJL0, which takes into account the confinement/deconfinement phase transition by means of the traced Polyakov loop ($\u03a6$) which serves as an order parameter at zero temperature. We consider two different scenarios, namely, symmetric quark matter with equal chemical potentials for all the flavors, and the beta equilibrated matter. In the latter case the hadron-quark phase transition is implemented by a two model approach. For the hadron side we use a relativistic mean-field model with density dependent couplings. We show that $\u03a6$ induces abrupt changes in the mesons properties with gap sizes regulated by the phenomenological gluonic sector of the model.",
        "comments": "14 pages, 12 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14119"
    },
    {
        "doc_id": 284,
        "title": "Uniqueness of photon sphere for Reissner-Nordstr\u00f6m electric-magnetic system",
        "authors": [
            "Marek Rogatko"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Theory"
        ],
        "abstract": "Uniqueness of static, asymptotically flat, non-extremal {\\it photon sphere} in Einstein-Maxwell spacetime with electric and magnetic charges has been proved. Using conformal positive energy theorem, as well as, the positive mass theorem and adequate conformal transformations, we envisage the two alternative ways of proving that the exterior region of a certain radius of the studied static {\\it photon sphere}, is characterized by ADM mass, electric and magnetic charges.",
        "comments": "22 pages, RevTex, to be published in Phys.Rev.D15",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14116"
    },
    {
        "doc_id": 285,
        "title": "Development of a Silicon Drift Detector Array to Search for keV-scale Sterile Neutrinos with the KATRIN Experiment",
        "authors": [
            "Daniel Siegmann",
            "Frank Edzards",
            "Christina Bruch",
            "Matteo Biassoni",
            "Marco Carminati",
            "Martin Descher",
            "Carlo Fiorini",
            "Christian Forstner",
            "Andrew Gavin",
            "Matteo Gugiatti",
            "Roman Hiller",
            "Dominic Hinz",
            "Thibaut Houdy",
            "Anton Huber",
            "Pietro King",
            "Peter Lechner",
            "Steffen Lichter",
            "Danilo Mie\u00dfner",
            "Andrea Nava",
            "Anthony Onillon",
            "David C. Radford",
            "Daniela Spreng",
            "Markus Steidl",
            "Paolo Trigilio",
            "Korbinian Urban",
            "et al. (3 additional authors not shown)"
        ],
        "subjects": [
            "Instrumentation and Detectors"
        ],
        "abstract": "Sterile neutrinos in the keV mass range present a viable candidate for dark matter. They can be detected through single $\u03b2$ decay, where they cause small spectral distortions. The Karlsruhe Tritium Neutrino (KATRIN) experiment aims to search for keV-scale sterile neutrinos with high sensitivity. To achieve this, the KATRIN beamline will be equipped with a novel multi-pixel silicon drift detector focal plane array named TRISTAN. In this study, we present the performance of a TRISTAN detector module, a component of the eventual 9-module system. Our investigation encompasses spectroscopic aspects such as noise performance, energy resolution, linearity, and stability.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14114"
    },
    {
        "doc_id": 286,
        "title": "CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks",
        "authors": [
            "Andrei Tomut",
            "Saeed S. Jahromi",
            "Sukhbinder Singh",
            "Faysal Ishtiaq",
            "Cesar Mu\u00f1oz",
            "Prabdeep Singh Bajaj",
            "Ali Elborady",
            "Gianni del Bimbo",
            "Mehrazin Alizadeh",
            "David Montero",
            "Pablo Martin-Ramiro",
            "Muhammad Ibrahim",
            "Oussama Tahiri Alaoui",
            "John Malcolm",
            "Samuel Mugel",
            "Roman Orus"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantum Physics"
        ],
        "abstract": "Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly in generative Artificial Intelligence (AI), but their immense size poses significant challenges, such as huge training and inference costs, substantial energy demands, and limitations for on-site deployment. Traditional compression methods such as pruning, distillation, and low-rank approximation focus on reducing the effective number of neurons in the network, while quantization focuses on reducing the numerical precision of individual weights to reduce the model size while keeping the number of neurons fixed. While these compression methods have been relatively successful in practice, there's no compelling reason to believe that truncating the number of neurons is an optimal strategy. In this context, this paper introduces CompactifAI, an innovative LLM compression approach using quantum-inspired Tensor Networks that focuses on the model's correlation space instead, allowing for a more controlled, refined and interpretable model compression. Our method is versatile and can be implemented with - or on top of - other compression techniques. As a benchmark, we demonstrate that CompactifAI alone enables compression of the LlaMA-2 7B model to only $30\\%$ of its original size while recovering over $90\\%$ of the original accuracy after a brief distributed retraining.",
        "comments": "4 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14109"
    },
    {
        "doc_id": 287,
        "title": "Travelling waves in nonlinear magneto-inductive lattices",
        "authors": [
            "M. Agaoglou",
            "M. Feckan",
            "M. Pospisil",
            "V. M. Rothos",
            "H. Susanto"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "We consider a lattice equation modelling one-dimensional metamaterials formed by a discrete array of nonlinear resonators. We focus on periodic travelling waves due to the presence of a periodic force. The existence and uniqueness results of periodic travelling waves of the system are presented. Our analytical results are found to be in good agreement with direct numerical computations",
        "comments": "21 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14108"
    },
    {
        "doc_id": 288,
        "title": "Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement",
        "authors": [
            "Aaqib Saeed",
            "Dimitris Spathis",
            "Jungwoo Oh",
            "Edward Choi",
            "Ali Etemad"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Wearable technologies enable continuous monitoring of various health metrics, such as physical activity, heart rate, sleep, and stress levels. A key challenge with wearable data is obtaining quality labels. Unlike modalities like video where the videos themselves can be effectively used to label objects or events, wearable data do not contain obvious cues about the physical manifestation of the users and usually require rich metadata. As a result, label noise can become an increasingly thorny issue when labeling such data. In this paper, we propose a novel solution to address noisy label learning, entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initially learns a seed model using weak labels. Next, it fine-tunes the seed model using a handful of expert corrections. Finally, it achieves better generalizability and robustness by merging the seed and fine-tuned models via weighted parameter averaging. We evaluate our approach on four challenging tasks and datasets, and compare it against eight competitive baselines designed to deal with noisy labels. We show that FHLR achieves significantly better performance when learning from noisy labels and achieves state-of-the-art by a large margin, with up to 19% accuracy improvement under symmetric and asymmetric noise. Notably, we find that FHLR is particularly robust to increased label noise, unlike prior works that suffer from severe performance degradation. Our work not only achieves better generalization in high-stakes health sensing benchmarks but also sheds light on how noise affects commonly-used models.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14107"
    },
    {
        "doc_id": 289,
        "title": "Inverse source problem for discrete Helmholtz equation",
        "authors": [
            "Roman Novikov",
            "Basant Lal Sharma"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "We consider multi-frequency inverse source problem for the discrete Helmholtz operator on the square lattice $\\mathbb{Z}^d$, $d \\ge 1$. We consider this problem for the cases with and without phase information. We prove uniqueness results and present examples of non-uniqueness for this problem for the case of compactly supported source function. Relations with inverse scattering problem for the discrete Schr\u00f6dinger operators in the Born approximation are also provided.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14103"
    },
    {
        "doc_id": 290,
        "title": "Few-magnon excitations in a frustrated spin-$S$ ferromagnetic chain",
        "authors": [
            "Jiawei Li",
            "Ye Cao",
            "Ning Wu"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Quantum Physics"
        ],
        "abstract": "We study few-magnon excitations in a finite-size spin-$S$ ferromagnetic nearest-neighbor (NN) XXZ chain with additional antiferromagnetic next-nearest-neighbor (NNN) interaction $J'$ and single-ion (SI) anisotropy $D$. Using a set of exact two-magnon Bloch states, the two-magnon problem is mapped to a single-particle one on an effective open chain with both NN and NNN hoppings. For the commensurate momentum $k=-\u03c0$, the effective chain is decoupled into two NN open chains that can be exactly solved via a plane-wave ansatz. Based on this, we identify in the $\u0394'-D/|J'|$ plane (with $\u0394'$ the anisotropy parameter for the NNN coupling) the regions supporting the SI or NNN exchange two-magnon bound states near the edge of the band. We prove that there always exists a lower-energy NN exchange two-magnon bound state near the band edge. For $S=1/2$, we numerically calculate the $n$-magnon spectra for $n\\leq5$ by using a spin-operator matrix element method. The corresponding $n$-magnon commensurate instability regions are determined for finite chains and consistent results with prior literature are observed.",
        "comments": "10 pages, 9 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14101"
    },
    {
        "doc_id": 291,
        "title": "Carry Your Fault: A Fault Propagation Attack on Side-Channel Protected LWE-based KEM",
        "authors": [
            "Suparna Kundu",
            "Siddhartha Chowdhury",
            "Sayandeep Saha",
            "Angshuman Karmakar",
            "Debdeep Mukhopadhyay",
            "Ingrid Verbauwhede"
        ],
        "subjects": [
            "Cryptography and Security"
        ],
        "abstract": "Post-quantum cryptographic (PQC) algorithms, especially those based on the learning with errors (LWE) problem, have been subjected to several physical attacks in the recent past. Although the attacks broadly belong to two classes - passive side-channel attacks and active fault attacks, the attack strategies vary significantly due to the inherent complexities of such algorithms. Exploring further attack surfaces is, therefore, an important step for eventually securing the deployment of these algorithms. Also, it is important to test the robustness of the already proposed countermeasures in this regard. In this work, we propose a new fault attack on side-channel secure masked implementation of LWE-based key-encapsulation mechanisms (KEMs) exploiting fault propagation. The attack typically originates due to an algorithmic modification widely used to enable masking, namely the Arithmetic-to-Boolean (A2B) conversion. We exploit the data dependency of the adder carry chain in A2B and extract sensitive information, albeit masking (of arbitrary order) being present. As a practical demonstration of the exploitability of this information leakage, we show key recovery attacks of Kyber, although the leakage also exists for other schemes like Saber. The attack on Kyber targets the decapsulation module and utilizes Belief Propagation (BP) for key recovery. To the best of our knowledge, it is the first attack exploiting an algorithmic component introduced to ease masking rather than only exploiting the randomness introduced by masking to obtain desired faults (as done by Delvaux). Finally, we performed both simulated and electromagnetic (EM) fault-based practical validation of the attack for an open-source first-order secure Kyber implementation running on an STM32 platform.",
        "comments": "ACM Class:          E.3.3",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14098"
    },
    {
        "doc_id": 292,
        "title": "Evaluating User Experience and Data Quality in a Gamified Data Collection for Appearance-Based Gaze Estimation",
        "authors": [
            "Mingtao Yue",
            "Tomomi Sayuda",
            "Miles Pennington",
            "Yusuke Sugano"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "Appearance-based gaze estimation, which uses only a regular camera to estimate human gaze, is important in various application fields. While the technique faces data bias issues, data collection protocol is often demanding, and collecting data from a wide range of participants is difficult. It is an important challenge to design opportunities that allow a diverse range of people to participate while ensuring the quality of the training data. To tackle this challenge, we introduce a novel gamified approach for collecting training data. In this game, two players communicate words via eye gaze through a transparent letter board. Images captured during gameplay serve as valuable training data for gaze estimation models. The game is designed as a physical installation that involves communication between players, and it is expected to attract the interest of diverse participants. We assess the game's significance on data quality and user experience through a comparative user study.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14095"
    },
    {
        "doc_id": 293,
        "title": "GQHAN: A Grover-inspired Quantum Hard Attention Network",
        "authors": [
            "Ren-Xin Zhao",
            "Jinjing Shi",
            "Xuelong Li"
        ],
        "subjects": [
            "Quantum Physics",
            "Artificial Intelligence"
        ],
        "abstract": "Numerous current Quantum Machine Learning (QML) models exhibit an inadequacy in discerning the significance of quantum data, resulting in diminished efficacy when handling extensive quantum datasets. Hard Attention Mechanism (HAM), anticipated to efficiently tackle the above QML bottlenecks, encounters the substantial challenge of non-differentiability, consequently constraining its extensive applicability. In response to the dilemma of HAM and QML, a Grover-inspired Quantum Hard Attention Mechanism (GQHAM) consisting of a Flexible Oracle (FO) and an Adaptive Diffusion Operator (ADO) is proposed. Notably, the FO is designed to surmount the non-differentiable issue by executing the activation or masking of Discrete Primitives (DPs) with Flexible Control (FC) to weave various discrete destinies. Based on this, such discrete choice can be visualized with a specially defined Quantum Hard Attention Score (QHAS). Furthermore, a trainable ADO is devised to boost the generality and flexibility of GQHAM. At last, a Grover-inspired Quantum Hard Attention Network (GQHAN) based on QGHAM is constructed on PennyLane platform for Fashion MNIST binary classification. Experimental findings demonstrate that GQHAN adeptly surmounts the non-differentiability hurdle, surpassing the efficacy of extant quantum soft self-attention mechanisms in accuracies and learning ability. In noise experiments, GQHAN is robuster to bit-flip noise in accuracy and amplitude damping noise in learning performance. Predictably, the proposal of GQHAN enriches the Quantum Attention Mechanism (QAM), lays the foundation for future quantum computers to process large-scale data, and promotes the development of quantum computer vision.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14089"
    },
    {
        "doc_id": 294,
        "title": "Spatially localized scalar structures on hyperscaling violating geometries",
        "authors": [
            "I. Andrade",
            "M. A. Marques",
            "R. Menezes",
            "D. C. Moreira"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "General Relativity and Quantum Cosmology",
            "Pattern Formation and Solitons"
        ],
        "abstract": "In this work, we investigate probe scalar field models preserving covariance on fixed, static background geometries that present hyperscaling violation properties. We develop a first-order framework that rises from restrictions on the dynamical and hyperscaling violating exponents. The results show that stable, analytical kink-like solutions and their respective energy densities can be obtained for a general class of models. In the canonical model, in particular, these solutions minimize the energy of the system.",
        "comments": "12 pages, 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14082"
    },
    {
        "doc_id": 295,
        "title": "Accelerating Fractional PINNs using Operational Matrices of Derivative",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis"
        ],
        "abstract": "This paper presents a novel operational matrix method to accelerate the training of fractional Physics-Informed Neural Networks (fPINNs). Our approach involves a non-uniform discretization of the fractional Caputo operator, facilitating swift computation of fractional derivatives within Caputo-type fractional differential problems with $0<\u03b1<1$. In this methodology, the operational matrix is precomputed, and during the training phase, automatic differentiation is replaced with a matrix-vector product. While our methodology is compatible with any network, we particularly highlight its successful implementation in PINNs, emphasizing the enhanced accuracy achieved when utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates Legendre polynomials into the PINN structure, providing a significant boost in accuracy. The effectiveness of our proposed method is validated across diverse differential equations, including Delay Differential Equations (DDEs) and Systems of Differential Algebraic Equations (DAEs). To demonstrate its versatility, we extend the application of the method to systems of differential equations, specifically addressing nonlinear Pantograph fractional-order DDEs/DAEs. The results are supported by a comprehensive analysis of numerical outcomes.",
        "comments": "19 pages, 11 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14081"
    },
    {
        "doc_id": 296,
        "title": "Light-induced photodissociation on the lowest three electronic states of NaH molecule",
        "authors": [
            "Otabek Umarov",
            "Andr\u00e1s Csehi",
            "P\u00e9ter Badank\u00f3",
            "G\u00e1bor J. Hal\u00e1sz",
            "\u00c1gnes Vib\u00f3k"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "It has been known that electronic conical intersections in a molecular system can also be created by laser light even in diatomics. The direct consequence of these light-induced degeneracies is the appearance of a strong mixing between the electronic and vibrational motions, which has a strong fingerprint on the ultrafast nuclear dynamics. In the present work, pump and probe numerical simulations have been performed with the NaH molecule involving the first three singlet electronic states (X1\u03a3+(X), A1\u03a3+(A) and B1\u03a0(B)) and several light-induced degeneracies in the numerical description. To demonstrate the impact of the multiple light-induced non-adiabatic effects together with the molecular rotation on the dynamical properties of the molecule, the dissociation probabilities, kinetic energy release spectra (KER) and the angular distributions of the photofragments were calculated by discussing the role of the permanent dipole moment as well.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14080"
    },
    {
        "doc_id": 297,
        "title": "Generation of High-Brilliance Polarized $\u03b3$-Rays via Vacuum Birefringence",
        "authors": [
            "Chong Lv",
            "Feng Wan",
            "Yousef I. Salamin",
            "Qian Zhao",
            "Mamutjan Ababekri",
            "Ruirui Xu",
            "Jian-Xing Li"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "High-brilliance circularly polarized $\u03b3$-photon beams are of great significance for a wide range of applications. However, their generation through nonlinear Compton scattering must require a high-density longitudinally-spin-polarized electron beam and consequently is still a great challenge. Here, we put forward a novel method to generate such $\u03b3$-photon beams via the vacuum dichroism (VD)-assisted vacuum birefringence (VB) effect, only utilizing a well-established unpolarized electron beam. We split a linearly polarized (LP) laser pulse into two subpulses with the first one colliding with a dense unpolarized electron beam to generate an LP $\u03b3$-photon beam (via nonlinear Compton scattering), which then further collides with the second subpulse and is transformed into a circularly polarized one via the VB effect. We find that by manipulating the relative polarization of two subpulses, one can ``purify'' the polarization of the $\u03b3$-photon beam via the VD effect, thereby significantly enhancing the circular polarization of the $\u03b3$-photon beam. Due to the VD assistance, the VB effect reaches optimal when the relative polarization is nearly $30^\\circ$, not the widely used $45^\\circ$ in the common VB detection methods. Our results show that one can obtain a circularly polarized $\u03b3$-photon beam with degree of about 30% (43%) for energies above 500 (1000) MeV and brilliance of about $10^{24}~(10^{23})~\\mathrm{photons / (s \\cdot mm^2 \\cdot mrad^{2} \\cdot 0.1\\%BW)}$ at $500~(1000)$ MeV by using a currently feasible laser with a peak intensity of about $10^{22}~\\mathrm{W/cm^2}$. And, it can be further improved to above 60% (75%) by increasing the laser pulse duration. Moreover, our method can also be used to efficiently confirm the well-known VB effect itself, which has been predicted a very long time ago but has not been directly observed in experiments yet.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14075"
    },
    {
        "doc_id": 298,
        "title": "Optical phase encoding in pulsed approach to reservoir computing",
        "authors": [
            "Johan Henaff",
            "Matthieu Ansquer",
            "Miguel C Soriano",
            "Roberta Zambrini",
            "Nicolas Treps",
            "Valentina Parigi"
        ],
        "subjects": [
            "Quantum Physics",
            "Optics"
        ],
        "abstract": "The exploitation of the full structure of multimode light fields enables compelling capabilities in many fields including classical and quantum information science. We exploit data-encoding on the optical phase of the pulses of a femtosecond laser source for a photonic implementation of a reservoir computing protocol. Rather than intensity detection, data-reading is done via homodyne detection that accesses combinations of amplitude and phase of the field. Numerical and experimental results on NARMA tasks and laser dynamic predictions are shown. We discuss perspectives for quantum enhanced protocols.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14073"
    },
    {
        "doc_id": 299,
        "title": "Gamma rays from dark matter spikes in EAGLE simulations",
        "authors": [
            "J. Aschersleben",
            "G. Bertone",
            "D. Horns",
            "E. Moulin",
            "R. F. Peletier",
            "M. Vecchi"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "Intermediate Mass Black Holes (IMBHs) with a mass range between $100 \\, \\text{M}_\\odot$ and $10^6 \\, \\text{M}_\\odot$ are expected to be surrounded by high dark matter densities, so-called dark matter spikes. The high density of self-annihilating WIMPs in these spikes leads to copious gamma-ray production. Sufficiently nearby IMBHs could therefore appear as unidentified gamma-ray sources. However, the number of IMBHs and their distribution within our own Milky Way is currently unknown. In this work, we provide a mock catalogue of IMBHs and their dark matter spikes obtained from the EAGLE simulations, in which black holes with a mass of $10^5 \\, \\text{M}_\\odot/h$ are seeded into the centre of halos greater than $10^{10} \\, \\text{M}_\\odot/h$ to model black hole feedback influencing the formation of galaxies. The catalogue contains the coordinates and dark matter spike parameters for over 8700 IMBHs present in about 400 Milky Way-like galaxies. We expect about $19^{+13}_{-8}$ IMBHs within our own galaxy, mainly distributed in the Galactic Centre and the Galactic Plane. In the most optimistic scenario, we find that current and future gamma-ray observatories, such as Fermi-LAT, H.E.S.S. and CTA, would be sensitive enough to probe the cross section of dark matter self-annihilation around IMBHs down to many orders of magnitude below the thermal relic cross section for dark matter particles with masses from GeV to TeV. We have made the IMBH mock catalogue and the source code for our analysis publicly available, providing the resources to study dark matter self-annihilation around IMBHs with current and upcoming gamma-ray observatories.",
        "comments": "25 pages, 10 figures, submitted to Journal of Cosmology and Astroparticle Physics",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14072"
    },
    {
        "doc_id": 300,
        "title": "Higher order approximation of option prices in Barndorff-Nielsen and Shephard models",
        "authors": [
            "\u00c1lvaro Guinea Juli\u00e1",
            "Alet Roux"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We present an approximation method based on the mixing formula (Hull & White 1987, Romano & Touzi 1997) for pricing European options in Barndorff-Nielsen and Shephard models. This approximation is based on a Taylor expansion of the option price. It is implemented using a recursive algorithm that allows us to obtain closed form approximations of the option price of any order (subject to technical conditions on the background driving L\u00e9vy process). This method can be used for any type of Barndorff-Nielsen and Shephard stochastic volatility model. Explicit results are presented in the case where the stationary distribution of the background driving L\u00e9vy process is inverse Gaussian or gamma. In both of these cases, the approximation compares favorably to option prices produced by the characteristic function. In particular, we also perform an error analysis of the approximation, which is partially based on the results of Das & Langren\u00e9 (2022). We obtain asymptotic results for the error of the $N^{\\text{th}}$ order approximation and error bounds when the variance process satisfies an inverse Gaussian Ornstein-Uhlenbeck process or a gamma Ornstein-Uhlenbeck process.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14390"
    },
    {
        "doc_id": 301,
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics",
            "Trading and Market Microstructure"
        ],
        "abstract": "In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14199"
    },
    {
        "doc_id": 302,
        "title": "Discrete Hawkes process with flexible residual distribution and filtered historical simulation",
        "authors": [
            "Kyungsub Lee"
        ],
        "subjects": [
            "Statistical Finance",
            "Methodology"
        ],
        "abstract": "We introduce a new model which can be considered as a extended version of the Hawkes process in a discrete sense. This model enables the integration of various residual distributions while preserving the fundamental properties of the original Hawkes process. The rich nature of this model enables a filtered historical simulation which incorporate the properties of original time series more accurately. The process naturally extends to multi-variate models with easy implementations of estimation and simulation. We investigate the effect of flexible residual distribution on estimation of high frequency financial data compared with the Hawkes process.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13890"
    },
    {
        "doc_id": 303,
        "title": "The impact of Hong Kong's anti-ELAB movement on political related firms",
        "authors": [
            "Ziqi Wang"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "Hong Kong's anti-ELAB movement had a significant impact on the stock market the stock price of listed companies. Using the number of protestors as the measurement of daily protesting intensity from 2019/6/6 to 2020/1/17, this paper documents that the stock price of listed companies associated with the pan-democratic parties were more negatively affected by protesting than other companies. Furthermore, this paper finds that after the implementation of the anti-mask law, protesting had a positive impact on red chips but a negative impact on companies related to pan-democracy parties. Therefore, this paper believes that after the central government and the HKSAR government adopted strict measures to stop violence and chaos, the value of the political connection of red chips became positive while the value of the connection with pan-democracy parties became negative.",
        "comments": "34 pages, 13 tables",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13676"
    },
    {
        "doc_id": 304,
        "title": "Real-time Risk Metrics for Programmatic Stablecoin Crypto Asset-Liability Management (CALM)",
        "authors": [
            "Marcel Bluhm",
            "Adrian Cachinero Vasiljevi\u0107",
            "S\u00e9bastien Derivaux",
            "S\u00f8ren Terp H\u00f8rl\u00fcck Jessen"
        ],
        "subjects": [
            "Risk Management",
            "Cryptography and Security",
            "General Finance"
        ],
        "abstract": "Stablecoins have turned out to be the \"killer\" use case of the growing digital asset space. However, risk management frameworks, including regulatory ones, have been largely absent. In this paper, we address the critical question of measuring and managing risk in stablecoin protocols, which operate on public blockchain infrastructure. The on-chain environment makes it possible to monitor risk and automate its management via transparent smart-contracts in real-time. We propose two risk metrics covering capitalization and liquidity of stablecoin protocols. We then explore in a case-study type analysis how our risk management framework can be applied to DAI, the biggest decentralized stablecoin by market capitalisation to-date, governed by MakerDAO. Based on our findings, we recommend that the protocol explores implementing automatic capital buffer adjustments and dynamic maturity gap matching. Our analysis demonstrates the practical benefits for scalable (prudential) risk management stemming from real-time availability of high-quality, granular, tamper-resistant on-chain data in the digital asset space. We name this approach Crypto Asset-Liability Management (CALM).",
        "comments": "The authors would like to thank Professor Moorad Choudhry for review comments on an earlier draft. Submitted for the SNB-CIF Conference on Cryptoassets and Financial Innovation, 24 May 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13399"
    },
    {
        "doc_id": 305,
        "title": "An Explicit Scheme for Pathwise XVA Computations",
        "authors": [
            "Lokman Abbas-Turki",
            "St\u00e9phane Cr\u00e9pey",
            "Botao Li",
            "Bouazza Saadeddine"
        ],
        "subjects": [
            "Risk Management",
            "Numerical Analysis",
            "Computational Finance",
            "Machine Learning"
        ],
        "abstract": "Motivated by the equations of cross valuation adjustments (XVAs) in the realistic case where capital is deemed fungible as a source of funding for variation margin, we introduce a simulation/regression scheme for a class of anticipated BSDEs, where the coefficient entails a conditional expected shortfall of the martingale part of the solution. The scheme is explicit in time and uses neural network least-squares and quantile regressions for the embedded conditional expectations and expected shortfall computations. An a posteriori Monte Carlo validation procedure allows assessing the regression error of the scheme at each time step. The superiority of this scheme with respect to Picard iterations is illustrated in a high-dimensional and hybrid market/default risks XVA use-case.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13314"
    },
    {
        "doc_id": 306,
        "title": "Optimizing Transition Strategies for Small to Medium Sized Portfolios",
        "authors": [
            "Nakul Upadhya",
            "Alexandre Granzer-Guay"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "This work discusses the benefits of constrained portfolio turnover strategies for small to medium-sized portfolios. We propose a dynamic multi-period model that aims to minimize transaction costs and maximize terminal wealth levels whilst adhering to strict portfolio turnover constraints. Our results demonstrate that using our framework in combination with a reasonable forecast, can lead to higher portfolio values and lower transaction costs on average when compared to a naive, single-period model. Such results were maintained given different problem cases, such as, trading horizon, assets under management, wealth levels, etc. In addition, the proposed model lends itself to a reformulation that makes use of the column generation algorithm which can be strategically leveraged to reduce complexity and solving times.",
        "comments": "All of the discussed experiments and presented results can be reproduced using our code at https://github.com/upadhyan/Portfolio-Changeover-Optimization",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13126"
    },
    {
        "doc_id": 307,
        "title": "Reference-dependent asset pricing with a stochastic consumption-dividend ratio",
        "authors": [
            "Luca De Gennaro Aquino",
            "Xuedong He",
            "Moris Simon Strub",
            "Yuting Yang"
        ],
        "subjects": [
            "Mathematical Finance",
            "General Finance"
        ],
        "abstract": "We study a discrete-time consumption-based capital asset pricing model under expectations-based reference-dependent preferences. More precisely, we consider an endowment economy populated by a representative agent who derives utility from current consumption and from gains and losses in consumption with respect to a forward-looking, stochastic reference point. First, we consider a general model in which the agent's preferences include both contemporaneous gain-loss utility, that is, utility from the difference between current consumption and previously held expectations about current consumption, and prospective gain-loss utility, that is, utility from the difference between intertemporal beliefs about future consumption. A semi-closed form solution for equilibrium asset prices is derived for this case. We then specialize to a model in which the agent derives contemporaneous gain-loss utility only, obtaining equilibrium asset prices in closed form. Extensive numerical experiments show that, with plausible values of risk aversion and loss aversion, our models can generate equity premia that match empirical estimates. Interestingly, the models turn out to be consistent with some well-known empirical facts, namely procyclical variation in the price-dividend ratio and countercyclical variation in the conditional expected equity premium and in the conditional volatility of the equity premium. Furthermore, we find that prospective gain-loss utility is necessary for the model to predict reasonable values of the price-dividend ratio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12856"
    },
    {
        "doc_id": 308,
        "title": "New approximate stochastic dominance approaches for Enhanced Indexation models",
        "authors": [
            "Francesco Cesarone",
            "Justo Puerto"
        ],
        "subjects": [
            "Portfolio Management",
            "Computational Finance",
            "General Finance"
        ],
        "abstract": "In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczynski (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12669"
    },
    {
        "doc_id": 309,
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "authors": [
            "Henri Arno",
            "Klaas Mulier",
            "Joke Baeck",
            "Thomas Demeester"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Computational Finance"
        ],
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.",
        "comments": "Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12652"
    },
    {
        "doc_id": 310,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 311,
        "title": "General duality and dual attainment for adapted transport",
        "authors": [
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "We investigate duality and existence of dual optimizers for several adapted optimal transport problems under minimal assumptions. This includes the causal and bicausal transport, the barycenter problem, and a general multimarginal problem incorporating causality constraints. Moreover, we discuss applications of our results in robust finance. We consider a non-dominated model of several financial markets where stocks are traded dynamically, but the joint stock dynamics are unknown. We show that a no-arbitrage assumption in a quasi-sure sense naturally leads to sets of multicausal couplings. Consequently, computing the robust superhedging price is equivalent to solving an adapted transport problem, and finding a superhedging strategy means solving the corresponding dual.",
        "comments": "32 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11958"
    },
    {
        "doc_id": 312,
        "title": "Forecasting and Backtesting Gradient Allocations of Expected Shortfall",
        "authors": [
            "Takaaki Koike",
            "Cathy W. S. Chen",
            "Edward M. H. Lin"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Capital allocation is a procedure for quantifying the contribution of each source of risk to aggregated risk. The gradient allocation rule, also known as the Euler principle, is a prevalent rule of capital allocation under which the allocated capital captures the diversification benefit of the marginal risk as a component of overall risk. This research concentrates on Expected Shortfall (ES) as a regulatory standard and focuses on the gradient allocations of ES, also called ES contributions. We achieve the comprehensive treatment of backtesting the tuple of ES contributions in the framework of the traditional and comparative backtests based on the concepts of joint identifiability and multi-objective elicitability. For robust forecast evaluation against the choice of scoring function, we further develop Murphy diagrams for ES contributions as graphical tools to check whether one forecast dominates another under a class of scoring functions. Finally, leveraging the recent concept of multi-objective elicitability, we propose a novel semiparametric model for forecasting dynamic ES contributions based on a compositional regression model. In an empirical analysis of stock returns we evaluate and compare a variety of models for forecasting dynamic ES contributions and demonstrate the outstanding performance of the proposed model.",
        "comments": "MSC Class:          62F07; 62P05; 91B30",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11701"
    },
    {
        "doc_id": 313,
        "title": "A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting",
        "authors": [
            "Riaz Ud Din",
            "Salman Ahmed",
            "Saddam Hussain Khan"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.",
        "comments": "30 pages, 16 Figures, 4 Tables",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11621"
    },
    {
        "doc_id": 314,
        "title": "The geometry of multi-curve interest rate models",
        "authors": [
            "Claudio Fontana",
            "Giacomo Lanaro",
            "Agatha Murgoci"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We study the problems of consistency and of the existence of finite-dimensional realizations for multi-curve interest rate models of Heath-Jarrow-Morton type, generalizing the geometric approach developed by T. Bj\u00f6rk and co-authors in the classical single-curve setting. We characterize when a multi-curve interest rate model is consistent with a given parameterized family of forward curves and spreads and when a model can be realized by a finite-dimensional state process. We illustrate the general theory in a number of model classes and examples, providing explicit constructions of finite-dimensional realizations. Based on these theoretical results, we perform the calibration of a three-curve Hull-White model to market data and analyse the stability of the estimated parameters.",
        "comments": "28 pages, 2 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11619"
    },
    {
        "doc_id": 315,
        "title": "Functional Limit Theorems for Hawkes Processes",
        "authors": [
            "Ulrich Horst",
            "Wei Xu"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritical processes critical ones with heavily dispersed child events display long-range dependencies.",
        "comments": "59 pages; Keywords and phrases: Hawkes process, functional limit theorem, regular variation, convergence rate",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11495"
    },
    {
        "doc_id": 316,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 317,
        "title": "Data-driven Option Pricing",
        "authors": [
            "Min Dai",
            "Hanqing Jin",
            "Xi Yang"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "We propose an innovative data-driven option pricing methodology that relies exclusively on the dataset of historical underlying asset prices. While the dataset is rooted in the objective world, option prices are commonly expressed as discounted expectations of their terminal payoffs in a risk-neutral world. Bridging this gap motivates us to identify a pricing kernel process, transforming option pricing into evaluating expectations in the objective world. We recover the pricing kernel by solving a utility maximization problem, and evaluate the expectations in terms of a functional optimization problem. Leveraging the deep learning technique, we design data-driven algorithms to solve both optimization problems over the dataset. Numerical experiments are presented to demonstrate the efficiency of our methodology.",
        "comments": "15 pages, 3 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11158"
    },
    {
        "doc_id": 318,
        "title": "BioFinBERT: Finetuning Large Language Models (LLMs) to Analyze Sentiment of Press Releases and Financial Text Around Inflection Points of Biotech Stocks",
        "authors": [
            "Valentina Aparicio",
            "Daniel Gordon",
            "Sebastian G. Huayamares",
            "Yuhuai Luo"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "Large language models (LLMs) are deep learning algorithms being used to perform natural language processing tasks in various fields, from social sciences to finance and biomedical sciences. Developing and training a new LLM can be very computationally expensive, so it is becoming a common practice to take existing LLMs and finetune them with carefully curated datasets for desired applications in different fields. Here, we present BioFinBERT, a finetuned LLM to perform financial sentiment analysis of public text associated with stocks of companies in the biotechnology sector. The stocks of biotech companies developing highly innovative and risky therapeutic drugs tend to respond very positively or negatively upon a successful or failed clinical readout or regulatory approval of their drug, respectively. These clinical or regulatory results are disclosed by the biotech companies via press releases, which are followed by a significant stock response in many cases. In our attempt to design a LLM capable of analyzing the sentiment of these press releases,we first finetuned BioBERT, a biomedical language representation model designed for biomedical text mining, using financial textual databases. Our finetuned model, termed BioFinBERT, was then used to perform financial sentiment analysis of various biotech-related press releases and financial text around inflection points that significantly affected the price of biotech stocks.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11011"
    },
    {
        "doc_id": 319,
        "title": "Forecasting Cryptocurrency Staking Rewards",
        "authors": [
            "Sauren Gupta",
            "Apoorva Hathi Katharaki",
            "Yifan Xu",
            "Bhaskar Krishnamachari",
            "Rajarshi Gupta"
        ],
        "subjects": [
            "Statistical Finance",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This research explores a relatively unexplored area of predicting cryptocurrency staking rewards, offering potential insights to researchers and investors. We investigate two predictive methodologies: a) a straightforward sliding-window average, and b) linear regression models predicated on historical data. The findings reveal that ETH staking rewards can be forecasted with an RMSE within 0.7% and 1.1% of the mean value for 1-day and 7-day look-aheads respectively, using a 7-day sliding-window average approach. Additionally, we discern diverse prediction accuracies across various cryptocurrencies, including SOL, XTZ, ATOM, and MATIC. Linear regression is identified as superior to the moving-window average for perdicting in the short term for XTZ and ATOM. The results underscore the generally stable and predictable nature of staking rewards for most assets, with MATIC presenting a noteworthy exception.",
        "comments": "9 pages, 18 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10931"
    },
    {
        "doc_id": 320,
        "title": "Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock",
        "authors": [
            "Dengxin Huang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "This document presents a stock market analysis conducted on a dataset consisting of 750 instances and 16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section, feature engineering, data preparation, model selection, and insights from the analysis. The Fama French 3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear regression being the best-performing model.",
        "comments": "9 pages, 7 figures",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10903"
    },
    {
        "doc_id": 321,
        "title": "Stylized Facts and Market Microstructure: An In-Depth Exploration of German Bond Futures Market",
        "authors": [
            "Hamza Bodor",
            "Laurent Carlier"
        ],
        "subjects": [
            "Statistical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper presents an in-depth analysis of stylized facts in the context of futures on German bonds. The study examines four futures contracts on German bonds: Schatz, Bobl, Bund and Buxl, using tick-by-tick limit order book datasets. It uncovers a range of stylized facts and empirical observations, including the distribution of order sizes, patterns of order flow, and inter-arrival times of orders. The findings reveal both commonalities and unique characteristics across the different futures, thereby enriching our understanding of these markets. Furthermore, the paper introduces insightful realism metrics that can be used to benchmark market simulators. The study contributes to the literature on financial stylized facts by extending empirical observations to this class of assets, which has been relatively underexplored in existing research. This work provides valuable guidance for the development of more accurate and realistic market simulators.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10722"
    },
    {
        "doc_id": 322,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 323,
        "title": "Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review",
        "authors": [
            "Lars Ericson",
            "Xuejun Zhu",
            "Xusi Han",
            "Rao Fu",
            "Shuang Li",
            "Steve Guo",
            "Ping Hu"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "In the financial services industry, forecasting the risk factor distribution conditional on the history and the current market environment is the key to market risk modeling in general and value at risk (VaR) model in particular. As one of the most widely adopted VaR models in commercial banks, Historical simulation (HS) uses the empirical distribution of daily returns in a historical window as the forecast distribution of risk factor returns in the next day. The objectives for financial time series generation are to generate synthetic data paths with good variety, and similar distribution and dynamics to the original historical data. In this paper, we apply multiple existing deep generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for conditional time series generation, and propose and test two new methods for conditional multi-step time series generation, namely Encoder-Decoder CGAN and Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a set of KPIs to measure the quality of the generated time series for financial modeling. The KPIs cover distribution distance, autocorrelation and backtesting. All models (HS, parametric and neural networks) are tested on both historical USD yield curve data and additional data simulated from GARCH and CIR processes. The study shows that top performing models are HS, GARCH and CWGAN models. Future research directions in this area are also discussed.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10370"
    },
    {
        "doc_id": 324,
        "title": "Interplay between Cryptocurrency Transactions and Online Financial Forums",
        "authors": [
            "Ana Fern\u00e1ndez Vilas",
            "Rebeca P. D\u00edaz Redondo",
            "Daniel Couto Cancela",
            "Alejandro Torrado Pazos"
        ],
        "subjects": [
            "General Finance",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Cryptocurrencies are a type of digital money meant to provide security and anonymity while using cryptography techniques. Although cryptocurrencies represent a breakthrough and provide some important benefits, their usage poses some risks that are a result of the lack of supervising institutions and transparency. Because disinformation and volatility is discouraging for personal investors, cryptocurrencies emerged hand-in-hand with the proliferation of online users' communities and forums as places to share information that can alleviate users' mistrust. This research focuses on the study of the interplay between these cryptocurrency forums and fluctuations in cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin (BTC) and a related active discussion community, Bitcointalk, are analyzed. This study shows that the activity of Bitcointalk forum keeps a direct relationship with the trend in the values of BTC, therefore analysis of this interaction would be a perfect base to support personal investments in a non-regulated market and, to confirm whether cryptocurrency forums show evidences to detect abnormal behaviors in BTC values as well as to predict or estimate these values. The experiment highlights that forum data can explain specific events in the financial field. It also underlines the relevance of quotes (regular mechanism to response a post) at periods: (1) when there is a high concentration of posts around certain topics; (2) when peaks in the BTC price are observed; and, (3) when the BTC price gradually shifts downwards and users intend to sell.",
        "comments": "Journal ref:        Mathematics 2021, 9(4), 411;",
        "date": "27 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10238"
    },
    {
        "doc_id": 325,
        "title": "An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)",
        "authors": [
            "Garvit Arora",
            "Shubhangi Shubhangi",
            "Ying Wu",
            "Xuan Mei"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10162"
    },
    {
        "doc_id": 326,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 327,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 328,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 329,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 330,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 331,
        "title": "Mean-Field SDEs driven by $G$-Brownian Motion",
        "authors": [
            "Karl-Wilhelm Georg Bollweg",
            "Thilo Meyer-Brandis"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We extend the notion of mean-field SDEs to SDEs driven by $G$-Brownian motion. More precisely, we consider a $G$-SDE where the coefficients depend not only on time and the current state but also on the solution as random variable.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09113"
    },
    {
        "doc_id": 332,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 333,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 334,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 335,
        "title": "Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Xi Chen",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "subjects": [
            "General Finance",
            "Cryptography and Security"
        ],
        "abstract": "Lido, the leading Liquid Staking Derivative (LSD) provider on Ethereum, allows users to stake an arbitrary amount of ETH to receive stETH, which can be integrated with Decentralized Finance (DeFi) protocols such as Aave. The composability between Lido and Aave enables a novel strategy called \"leverage staking\", where users stake ETH on Lido to acquire stETH, utilize stETH as collateral on Aave to borrow ETH, and then restake the borrowed ETH on Lido. Users can iteratively execute this process to optimize potential returns based on their risk profile.\n  This paper systematically studies the opportunities and risks associated with leverage staking. We are the first to formalize the leverage staking strategy within the Lido-Aave ecosystem. Our empirical study identifies 262 leverage staking positions on Ethereum, with an aggregated staking amount of 295,243 ETH (482M USD). We discover that 90.13% of leverage staking positions have achieved higher returns than conventional staking. Furthermore, we perform stress tests to evaluate the risk introduced by leverage staking under extreme conditions. We find that leverage staking significantly amplifies the risk of cascading liquidations. We hope this paper can inform and encourage the development of robust risk management approaches to protect the Lido-Aave LSD ecosystem.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08610"
    },
    {
        "doc_id": 336,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 337,
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We consider two data driven approaches, Reinforcement Learning (RL) and Deep Trajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call option without and with transaction cost according to a quadratic hedging P&L objective at maturity (\"variance-optimal hedging\" or \"final quadratic hedging\"). We study the performance of the two approaches under various market environments (modeled via the Black-Scholes and/or the log-normal SABR model) to understand their advantages and limitations. Without transaction costs and in the Black-Scholes model, both approaches match the performance of the variance-optimal Delta hedge. In the log-normal SABR model without transaction costs, they match the performance of the variance-optimal Barlett's Delta hedge. Agents trained on Black-Scholes trajectories with matching initial volatility but used on SABR trajectories match the performance of Bartlett's Delta hedge in average cost, but show substantially wider variance. To apply RL approaches to these problems, P&L at maturity is written as sum of step-wise contributions and variants of RL algorithms are implemented and used that minimize expectation of second moments of such sums.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.07996",
        "date": "20 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08600"
    },
    {
        "doc_id": 338,
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Organizations use cash management models to control balances to both avoid overdrafts and obtain a profit from short-term investments. Most management models are based on control bounds which are derived from the assumption of a particular cash flow probability distribution. In this paper, we relax this strong assumption to fit cash management models to data by means of stochastic and linear programming. We also introduce ensembles of random cash management models which are built by randomly selecting a subsequence of the original cash flow data set. We illustrate our approach by means of a real case study showing that a small random sample of data is enough to fit sufficiently good bound-based models.",
        "comments": "19 pages,6 figures, 1 table",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08548"
    },
    {
        "doc_id": 339,
        "title": "Dynamic portfolio selection under generalized disappointment aversion",
        "authors": [
            "Zongxia Liang",
            "Sheng Wang",
            "Jianming Xia",
            "Fengyi Yuan"
        ],
        "subjects": [
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "This paper addresses the continuous-time portfolio selection problem under generalized disappointment aversion (GDA). The implicit definition of the certainty equivalent within GDA preferences introduces time inconsistency to this problem. We provide the sufficient and necessary conditions for a strategy to be an equilibrium by a fully nonlinear ordinary differential equation (ODE). Through an exploration of the existence and uniqueness of solution to the ODE, we establish the existence and uniqueness of the equilibrium. Our findings indicate that under disappointment aversion (DA) preferences, non-participation in the stock market is the unique equilibrium. The numerical analysis reveals that, under GDA preferences, the investment proportion in the stock market consistently remains smaller than the investment proportion under the classical Expected Utility (EU) theory.",
        "comments": "27 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08323"
    },
    {
        "doc_id": 340,
        "title": "Do backrun auctions protect traders?",
        "authors": [
            "Andrew W. Macpherson"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Distributed, Parallel, and Cluster Computing",
            "Computer Science and Game Theory"
        ],
        "abstract": "We study a new \"laminated\" queueing model for orders on batched trading venues such as decentralised exchanges. The model aims to capture and generalise transaction queueing infrastructure that has arisen to organise MEV activity on public blockchains such as Ethereum, providing convenient channels for sophisticated agents to extract value by acting on end-user order flow by performing arbitrage and related HFT activities. In our model, market orders are interspersed with orders created by arbitrageurs that under idealised conditions reset the marginal price to a global equilibrium between each trade, improving predictability of execution for liquidity traders.\n  If an arbitrageur has a chance to land multiple opportunities in a row, he may attempt to manipulate the execution price of the intervening market order by a probabilistic blind sandwiching strategy. To study how bad this manipulation can get, we introduce and bound a price manipulation coefficient that measures the deviation from global equilibrium of local pricing quoted by a rational arbitrageur. We exhibit cases in which this coefficient is well approximated by a \"zeta value' with interpretable and empirically measurable parameters.",
        "comments": "Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08302"
    },
    {
        "doc_id": 341,
        "title": "Optimal Insurance to Maximize Exponential Utility when Premium is Computed by a Convex Functional",
        "authors": [
            "Jingyi Cao",
            "Dongchen Li",
            "Virginia R. Young",
            "Bin Zou"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Risk Management"
        ],
        "abstract": "We find the optimal indemnity to maximize the expected utility of terminal wealth of a buyer of insurance whose preferences are modeled by an exponential utility. The insurance premium is computed by a convex functional. We obtain a necessary condition for the optimal indemnity; then, because the candidate optimal indemnity is given implicitly, we use that necessary condition to develop a numerical algorithm to compute it. We prove that the numerical algorithm converges to a unique indemnity that, indeed, equals the optimal policy. We also illustrate our results with numerical examples.",
        "comments": "12 pages, 3 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08094"
    },
    {
        "doc_id": 342,
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option Pricing",
        "authors": [
            "Ce Wang"
        ],
        "subjects": [
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two regression models fitted at each time step to price game options. Although the original LSMC can be used to price game options with an enlarged range of path in regression and a modified cashflow updating rule, we identified a drawback of such approach, which motivated us to propose our approach. We implemented numerical examples with benchmarks using binomial tree and numerical PDE, and it showed that our method produces more reliable results comparing to the original LSMC.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08093"
    },
    {
        "doc_id": 343,
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "authors": [
            "Shubham Singh",
            "Mayur Bhat"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Pricing of Securities"
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "comments": "12 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08077"
    },
    {
        "doc_id": 344,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 345,
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "authors": [
            "Samuel Vandak",
            "Geoffrey Goodell"
        ],
        "subjects": [
            "Computers and Society",
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "comments": "34 pages, 19 figures, 5 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07682"
    },
    {
        "doc_id": 346,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 347,
        "title": "Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Design/methodology/approach This research evaluated the databases of SQL, No-SQL and graph databases to compare and contrast efficiency and performance. To perform this experiment the data were collected from multiple sources including stock price and financial news. Python is used as an interface to connect and query databases (to create database structures according to the feed file structure, to load data into tables, objects, to read data , to connect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM (Large language model) including RAG (Retrieval Augmented Generation) with Machine Learning, deep learning, NLP (natural language processing) or Decision Analytics are computationally expensive. Finding a better option to consume less resources and time to get the result. Findings The Graph database of ESG (Environmental, Social and Governance) is comparatively better and can be considered for extended analytics to integrate ESG in business and investment. Practical implications A graph ML with a RAG architecture model can be introduced as a new framework with less computationally expensive LLM application in the equity filtering process for portfolio management. Originality/value Filtering out selective stocks out of two thousand or more listed companies in any stock exchange for active investment, consuming less resource consumption especially memory and energy to integrate artificial intelligence and ESG in business and investment.",
        "comments": "10 pages, 17 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07483"
    },
    {
        "doc_id": 348,
        "title": "Herd Behavior in Optimal Investment: A Dual-Agent Approach with Investment Opinion and Rational Decision Decomposition",
        "authors": [
            "Huisheng Wang",
            "H. Vicky Zhao"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control",
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "In this paper, we study the optimal investment problem involving two agents, where the decision of one agent is influenced by the other. To measure the distance between two agents' decisions, we introduce the average deviation. We formulate the stochastic optimal control problem considering herd behavior and derive the analytical solution through the variational method. We theoretically analyze the impact of users' herd behavior on the optimal decision by decomposing it into their rational decisions, which is called the rational decision decomposition. Furthermore, to quantify the preference for their rational decision over that of the other agent, we introduce the agent's investment opinion. Our study is validated through simulations on real stock data.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07183"
    },
    {
        "doc_id": 349,
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Chris Tanner"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Research in quantitative reasoning within the financial domain indeed necessitates the use of realistic tasks and data, primarily because of the significant impact of decisions made in business and finance. Financial professionals often interact with documents hundreds of pages long, but most research datasets drastically reduce this context length. To address this, we introduce a long-document financial QA task. We augment 7,621 questions from the existing FinQA dataset with full-document context, extending the average context length for each question from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and long-context language models on the augmented data. Our results show that DocFinQA provides challenges for even the strongest, state-of-the-art systems.",
        "comments": "13 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06915"
    },
    {
        "doc_id": 350,
        "title": "A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assessed in a series of numerical experiments involving the Merton jump-diffusion model.",
        "comments": "16 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06740"
    },
    {
        "doc_id": 351,
        "title": "Equity auction dynamics: latent liquidity models with activity acceleration",
        "authors": [
            "Mohammed Salek",
            "Damien Challet",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Finance"
        ],
        "abstract": "Equity auctions display several distinctive characteristics in contrast to continuous trading. As the auction time approaches, the rate of events accelerates causing a substantial liquidity buildup around the indicative price. This, in turn, results in a reduced price impact and decreased volatility of the indicative price. In this study, we adapt the latent/revealed order book framework to the specifics of equity auctions. We provide precise measurements of the model parameters, including order submissions, cancellations, and diffusion rates. Our setup allows us to describe the full dynamics of the average order book during closing auctions in Euronext Paris. These findings support the relevance of the latent liquidity framework in describing limit order book dynamics. Lastly, we analyze the factors contributing to a sub-diffusive indicative price and demonstrate the absence of indicative price predictability.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06724"
    },
    {
        "doc_id": 352,
        "title": "SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks",
        "authors": [
            "Alessio Brini",
            "Giacomo Toscano"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents financial assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with high-frequency prices of the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net shows improved accuracy, compared to alternative econometric and machine-learning-based models. Further, our results show that SpotV2Net maintains accuracy when performing intraday multi-step forecasts. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer, a model-agnostic interpretability tool and thereby uncover subgraphs that are critical to a node's predictions.",
        "comments": "34 pages, 9 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06249"
    },
    {
        "doc_id": 353,
        "title": "CNN-DRL for Scalable Actions in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Haseebullah Jumakhan",
            "Amir Mirzaeinia"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "The published MLP-based DRL in finance has difficulties in learning the dynamics of the environment when the action scale increases. If the buying and selling increase to one thousand shares, the MLP agent will not be able to effectively adapt to the environment. To address this, we designed a CNN agent that concatenates the data from the last ninety days of the daily feature vector to create the CNN input matrix. Our extensive experiments demonstrate that the MLP-based agent experiences a loss corresponding to the initial environment setup, while our designed CNN remains stable, effectively learns the environment, and leads to an increase in rewards.",
        "comments": "10th Annual Conf. on Computational Science & Computational Intelligence",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06179"
    },
    {
        "doc_id": 354,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 355,
        "title": "Multimodal Gen-AI for Fundamental Investment Research",
        "authors": [
            "Lezhi Li",
            "Ting-Yu Chang",
            "Hai Wang"
        ],
        "subjects": [
            "General Finance",
            "Machine Learning"
        ],
        "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.",
        "comments": " ",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06164"
    },
    {
        "doc_id": 356,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 357,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 358,
        "title": "StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks",
        "authors": [
            "Bohan Ma",
            "Yiheng Wang",
            "Yuchao Lu",
            "Tianzixuan Hu",
            "Jinling Xu",
            "Patrick Houlihan"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Machine Learning"
        ],
        "abstract": "Amidst ongoing market recalibration and increasing investor optimism, the U.S. stock market is experiencing a resurgence, prompting the need for sophisticated tools to protect and grow portfolios. Addressing this, we introduce \"Stockformer,\" a cutting-edge deep learning framework optimized for swing trading, featuring the TopKDropout method for enhanced stock selection. By integrating STL decomposition and self-attention networks, Stockformer utilizes the S&P 500's complex data to refine stock return predictions. Our methodology entailed segmenting data for training and validation (January 2021 to January 2023) and testing (February to June 2023). During testing, Stockformer's predictions outperformed ten industry models, achieving superior precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a remarkable accuracy rate of 62.39% in detecting market trends. In our backtests, Stockformer's swing trading strategy yielded a cumulative return of 13.19% and an annualized return of 30.80%, significantly surpassing current state-of-the-art models. Stockformer has emerged as a beacon of innovation in these volatile times, offering investors a potent tool for market forecasting. To advance the field and foster community collaboration, we have open-sourced Stockformer, available at https://github.com/Eric991005/Stockformer.",
        "comments": "Currently under consideration for publication in the International Journal of Forecasting",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06139"
    },
    {
        "doc_id": 359,
        "title": "Quantum Probability Theoretic Asset Return Modeling: A Novel Schr\u00f6dinger-Like Trading Equation and Multimodal Distribution",
        "authors": [
            "Li Lin"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "Quantum theory provides a comprehensive framework for quantifying uncertainty, often applied in quantum finance to explore the stochastic nature of asset returns. This perspective likens returns to microscopic particle motion, governed by quantum probabilities akin to physical laws. However, such approaches presuppose specific microscopic quantum effects in return changes, a premise criticized for lack of guarantee. This paper diverges by asserting that quantum probability is a mathematical extension of classical probability to complex numbers. It isn't exclusively tied to microscopic quantum phenomena, bypassing the need for quantum effects in returns.By directly linking quantum probability's mathematical structure to traders' decisions and market behaviors, it avoids assuming quantum effects for returns and invoking the wave function. The complex phase of quantum probability, capturing transitions between long and short decisions while considering information interaction among traders, offers an inherent advantage over classical probability in characterizing the multimodal distribution of asset returns.Utilizing Fourier decomposition, we derive a Schr\u00f6dinger-like trading equation, where each term explicitly corresponds to implications of market trading. The equation indicates discrete energy levels in financial trading, with returns following a normal distribution at the lowest level. As the market transitions to higher trading levels, a phase shift occurs in the return distribution, leading to multimodality and fat tails. Empirical research on the Chinese stock market supports the existence of energy levels and multimodal distributions derived from this quantum probability asset returns model.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05823"
    },
    {
        "doc_id": 360,
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "authors": [
            "Frank Xing"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Multiagent Systems",
            "General Finance"
        ],
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
        "comments": "15 pages",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05799"
    },
    {
        "doc_id": 361,
        "title": "Super-hedging-pricing formulas and Immediate-Profit arbitrage for market models under random horizon",
        "authors": [
            "Tahir Choulli",
            "Emmanuel Lepinette"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Probability",
            "Pricing of Securities"
        ],
        "abstract": "In this paper, we consider the discrete-time setting, and the market model described by (S,F,T)$. Herein F is the ``public\" flow of information which is available to all agents overtime, S is the discounted price process of d-tradable assets, and T is an arbitrary random time whose occurrence might not be observable via F. Thus, we consider the larger flow G which incorporates F and makes T an observable random time. This framework covers the credit risk theory setting, the life insurance setting and the setting of employee stock option valuation. For the stopped model (S^T,G) and for various vulnerable claims, based on this model, we address the super-hedging pricing valuation problem and its intrinsic Immediate-Profit arbitrage (IP hereafter for short). Our first main contribution lies in singling out the impact of change of prior and/or information on conditional essential supremum, which is a vital tool in super-hedging pricing. The second main contribution consists of describing as explicit as possible how the set of super-hedging prices expands under the stochasticity of T and its risks, and we address the IP arbitrage for (S^T,G) as well. The third main contribution resides in elaborating as explicit as possible pricing formulas for vulnerable claims, and singling out the various informational risks in the prices' dynamics.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05713"
    },
    {
        "doc_id": 362,
        "title": "Boundary conditions at infinity for Black-Scholes equations",
        "authors": [
            "Yukihiro Tsuzuki"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance"
        ],
        "abstract": "We propose numerical procedures for computing the prices of forward contracts where the underlying asset price is a Markovian local martingale. If the underlying process is a strict local martingale, multiple solutions exist for the corresponding Black-Scholes equations, and the derivative prices are characterized as the minimal solutions. Our prices are upper and lower bounds obtained using numerical methods on a finite grid under the respective boundary conditions. These bounds and the boundary values converge to the exact value as the underlying price approaches infinity. The proposed procedures are demonstrated through numerical tests.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05549"
    },
    {
        "doc_id": 363,
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "authors": [
            "Baptiste Lefort",
            "Eric Benhamou",
            "Jean-Jacques Ohana",
            "David Saltiel",
            "Beatrice Guez",
            "Damien Challet"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence"
        ],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05447"
    },
    {
        "doc_id": 364,
        "title": "An adaptive network-based approach for advanced forecasting of cryptocurrency values",
        "authors": [
            "Ali Mehrban",
            "Pegah Ahadian"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This paper describes an architecture for predicting the price of cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy Inference System (ANFIS). Historical data of cryptocurrencies and indexes that are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D), and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach the data are hybrid and backpropagation algorithms, as well as grid partition, subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which are used in data clustering. The architectural performance designed in this paper has been compared with different inputs and neural network models in terms of statistical evaluation criteria. Finally, the proposed method can predict the price of digital currencies in a short time.",
        "comments": "11 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05441"
    },
    {
        "doc_id": 365,
        "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification",
        "authors": [
            "Zinuo You",
            "Pengju Zhang",
            "Jin Zheng",
            "John Cartlidge"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).",
        "comments": "5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05430"
    },
    {
        "doc_id": 366,
        "title": "Introduction of L0 norm and application of L1 and C1 norm in the study of time-series",
        "authors": [
            "Victor Ujaldon Garcia"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Four markets are considered: Cryptocurrencies / South American exchange rate / Spanish Banking indices and European Indices and studied using TDA (Topological Data Analysis) tools. These tools are used to predict and showcase both strengths and weakness of the current TDA tools. In this paper a new tool $L0$ norm is defined and complemented with the already existing $C1$ norm.",
        "comments": "14 pages 8 figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05423"
    },
    {
        "doc_id": 367,
        "title": "Multiple-bubble testing in the cryptocurrency market: a case study of bitcoin",
        "authors": [
            "Sanaz Behzadi",
            "Mahmonir Bayanati",
            "Hamed Nozari"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Economic periods and financial crises have highlighted the importance of evaluating financial markets to investors and researchers in recent decades.",
        "comments": " ",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05417"
    },
    {
        "doc_id": 368,
        "title": "On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors",
        "authors": [
            "Xinshuai Dong",
            "Haoyue Dai",
            "Yewen Fan",
            "Songyao Jin",
            "Sathyamoorthy Rajendran",
            "Kun Zhang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Financial data is generally time series in essence and thus suffers from three fundamental issues: the mismatch in time resolution, the time-varying property of the distribution - nonstationarity, and causal factors that are important but unknown/unobserved. In this paper, we follow a causal perspective to systematically look into these three demons in finance. Specifically, we reexamine these issues in the context of causality, which gives rise to a novel and inspiring understanding of how the issues can be addressed. Following this perspective, we provide systematic solutions to these problems, which hopefully would serve as a foundation for future research in the area.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05414"
    },
    {
        "doc_id": 369,
        "title": "RIVCoin: an alternative, integrated, CeFi/DeFi-Vaulted Cryptocurrency",
        "authors": [
            "Roberto Rivera",
            "Guido Rocco",
            "Massimiliano Marzo",
            "Enrico Talin"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "This whitepaper introduces RIVCoin, a cryptocurrency built on Cosmos, fully stabilized by a diversified portfolio of both CeFi and DeFi assets, available in a digital, non-custodial wallet called RIV Wallet, that aims to provide Users an easy way to access the cryptocurrency markets, compliant to the strictest AML laws and regulations up to date. The token is a cryptocurrency at any time stabilized by a basket of assets: reserves are invested in a portfolio composed long term by 50% of CeFi assets, comprised of Fixed Income, Equity, Mutual and Hedge Funds and 50% of diversified strategies focused on digital assets, mainly staking and LP farming on the major, battle tested DeFi protocols. The cryptocurrency, as well as the dollar before Bretton Woods, is always fully stabilized by vaulted proof of assets: it is born and managed as a decentralized token, minted by a Decentralized Autonomous Organization, and entirely stabilized by assets evaluated by professional independent third parties. Users will trade, pool, and exchange the token without any intermediary, being able to merge them into a Liquidity Pool whose rewards will be composed by both the trading fees and the liquidity rewards derived from the reserve's seigniorage.\n  Users who wish and decide to pool RIVCoin in the Liquidity Pool will receive additional RIVCoin for themselves, and new RIVCoin are minted when the reserves increase in value or in case of purchase of new RIVCoin. The proposed model allows for alignment of incentives: decreasing the risk exposure by wealthier Users, but implicitly increasing that of smaller ones to a level perceived by them as still sustainable. Users indirectly benefit from the access to the rewards of sophisticated cryptocurrency portfolios hitherto precluded to them, without this turning into a disadvantage for the wealthy User.",
        "comments": " ",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05393"
    },
    {
        "doc_id": 370,
        "title": "Optimal Linear Signal: An Unsupervised Machine Learning Framework to Optimize PnL with Linear Signals",
        "authors": [
            "Pierre Renucci"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "This study presents an unsupervised machine learning approach for optimizing Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL generated from signals constructed linearly from exogenous variables. The methodology employs a linear relationship between exogenous variables and the trading signal, with the objective of maximizing the Sharpe Ratio through parameter optimization. Empirical application on an ETF representing U.S. Treasury bonds demonstrates the model's effectiveness, supported by regularization techniques to mitigate overfitting. The study concludes with potential avenues for further development, including generalized time steps and enhanced corrective terms.",
        "comments": "The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05337"
    },
    {
        "doc_id": 371,
        "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks",
        "authors": [
            "Zhang Chern Lee",
            "Wei Yun Tan",
            "Hoong Khen Koo",
            "Wilson Pang"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio",
        "comments": "19 pages, 5 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05264"
    },
    {
        "doc_id": 372,
        "title": "A Mean Field Game between Informed Traders and a Broker",
        "authors": [
            "Philippe Bergault",
            "Leandro S\u00e1nchez-Betancourt"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Optimization and Control"
        ],
        "abstract": "We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G\u00e2teaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05257"
    },
    {
        "doc_id": 373,
        "title": "On the Martingale Schr\u00f6dinger Bridge between Two Distributions",
        "authors": [
            "Marcel Nutz",
            "Johannes Wiesel"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We study a martingale Schr\u00f6dinger bridge problem: given two probability distributions, find their martingale coupling with minimal relative entropy. Our main result provides Schr\u00f6dinger potentials for this coupling. Namely, under certain conditions, the log-density of the optimal coupling is given by a triplet of real functions representing the marginal and martingale constraints. The potentials are also described as the solution of a dual problem.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05209"
    },
    {
        "doc_id": 374,
        "title": "Markowitz Portfolio Construction at Seventy",
        "authors": [
            "Stephen Boyd",
            "Kasper Johansson",
            "Ronald Kahn",
            "Philipp Schiele",
            "Thomas Schmelzer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "More than seventy years ago Harry Markowitz formulated portfolio construction as an optimization problem that trades off expected return and risk, defined as the standard deviation of the portfolio returns. Since then the method has been extended to include many practical constraints and objective terms, such as transaction cost or leverage limits. Despite several criticisms of Markowitz's method, for example its sensitivity to poor forecasts of the return statistics, it has become the dominant quantitative method for portfolio construction in practice. In this article we describe an extension of Markowitz's method that addresses many practical effects and gracefully handles the uncertainty inherent in return statistics forecasting. Like Markowitz's original formulation, the extension is also a convex optimization problem, which can be solved with high reliability and speed.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05080"
    },
    {
        "doc_id": 375,
        "title": "Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin",
        "authors": [
            "Didier Sornette",
            "Yu Zhang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least $200$ weeks with an exponent approximately equal to $0.9$, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between $0.3$ and $2.5$ depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to $-1.5$, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04702"
    },
    {
        "doc_id": 376,
        "title": "Proof of Efficient Liquidity: A Staking Mechanism for Capital Efficient Liquidity",
        "authors": [
            "Arman Abgaryan",
            "Utkarsh Sharma",
            "Joshua Tobkin"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "The Proof of Efficient Liquidity (PoEL) protocol, designed for specialised Proof of Stake (PoS) consensus-based blockchain infrastructures that incorporate intrinsic DeFi applications, aims to support sustainable liquidity bootstrapping and network security. This innovative mechanism efficiently utilises budgeted staking rewards to attract and sustain liquidity through a risk structuring engine and incentive allocation strategy, both of which are designed to maximise capital efficiency. The proposed protocol seeks to serve the dual objective of - (i) capital creation, by efficiently attracting risk capital, and maximising its operational utility for intrinsic DeFi applications, thereby asserting sustainability; and (ii) enhancing the adopting blockchain network's economic security, by augmenting their staking (PoS) mechanism with a harmonious layer seeking to attract a diversity of digital assets. Finally, in the appendix, we seek to generalise the financial incentivisation protocol to the notion of service fee credits, such that it utilises the network's auxiliary services as a means to propagate incentives to attract liquidity and facilitate the network to achieve the critical mass of usage necessary for sustained operations and growth.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04521"
    },
    {
        "doc_id": 377,
        "title": "Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks",
        "authors": [
            "Zan Yu",
            "Lianzeng Zhang"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Risk Management"
        ],
        "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.",
        "comments": "23 pages; 5 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04378"
    },
    {
        "doc_id": 378,
        "title": "Expiring Assets in Automated Market Makers",
        "authors": [
            "Kenan Wood",
            "Maurice Herlihy",
            "Hammurabi Mendes",
            "Jonad Pulaj"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Mathematical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "An automated market maker (AMM) is a state machine that manages pools of assets, allowing parties to buy and sell those assets according to a fixed mathematical formula. AMMs are typically implemented as smart contracts on blockchains, and its prices are kept in line with the overall market price by arbitrage: if the AMM undervalues an asset with respect to the market, an \"arbitrageur\" can make a risk-free profit by buying just enough of that asset to bring the AMM's price back in line with the market.\n  AMMs, however, are not designed for assets that expire: that is, assets that cannot be produced or resold after a specified date. As assets approach expiration, arbitrage may not be able to reconcile supply and demand, and the liquidity providers that funded the AMM may have excessive exposure to risk due to rapid price variations.\n  This paper formally describes the design of a decentralized exchange (DEX) for assets that expire, combining aspects of AMMs and limit-order books. We ensure liveness and market clearance, providing mechanisms for liquidity providers to control their exposure to risk and adjust prices dynamically in response to situations where arbitrage may fail.",
        "comments": "33 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04289"
    },
    {
        "doc_id": 379,
        "title": "Economic Forces in Stock Returns",
        "authors": [
            "Yue Chen",
            "Mohan Li"
        ],
        "subjects": [
            "General Economics",
            "Statistical Finance"
        ],
        "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.",
        "comments": "11 pages, 10 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04132"
    },
    {
        "doc_id": 380,
        "title": "Decomposing Smiles: A Time Change Approach",
        "authors": [
            "Liexin Cheng",
            "Xue Cheng"
        ],
        "subjects": [
            "Pricing of Securities",
            "Mathematical Finance"
        ],
        "abstract": "We develop a novel time-change approach to study the shape of implied volatility smiles. The method is applicable to common semimartingale models, including jump-diffusion, rough volatility and infinite activity models. We approximate the at-the-money skew and curvature with an improved moment-based formula. The moments are further explicitly computed under a time change framework. The limiting skew and curvature for several models are considered. We also test the accuracy of the short-term approximation results on models via numerical methods and on empirical data. Finally, we apply the method to the calibration problem.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03776"
    },
    {
        "doc_id": 381,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "subjects": [
            "Computational Finance",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation with S&P 100 stocks, MarketSenseAI outperformed the benchmark index by 13%, achieving returns up to 40%, while maintaining a risk profile comparable to the market. These results demonstrate the efficacy of Large Language Models in complex financial decision-making and mark a significant advancement in the integration of AI into financial analysis and investment strategies. This research contributes to the financial AI field, presenting an innovative approach and underscoring the transformative potential of AI in revolutionizing traditional financial analysis investment methodologies.",
        "comments": "15 pages, 12 figures, 12 tables",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03737"
    },
    {
        "doc_id": 382,
        "title": "Structured factor copulas for modeling the systemic risk of European and United States banks",
        "authors": [
            "Hoang Nguyen",
            "Audron\u0117 Virbickait\u0117",
            "M. Concepci\u00f3n Aus\u00edn",
            "Pedro Galeano"
        ],
        "subjects": [
            "Statistical Finance",
            "Applications"
        ],
        "abstract": "In this paper, we employ Credit Default Swaps (CDS) to model the joint and conditional distress probabilities of banks in Europe and the U.S. using factor copulas. We propose multi-factor, structured factor, and factor-vine models where the banks in the sample are clustered according to their geographic location. We find that within each region, the co-dependence between banks is best described using both, systematic and idiosyncratic, financial contagion channels. However, if we consider the banking system as a whole, then the systematic contagion channel prevails, meaning that the distress probabilities are driven by a latent global factor and region-specific factors. In all cases, the co-dependence structure of bank CDS spreads is highly correlated in the tail. The out-of-sample forecasts of several measures of systematic risk allow us to identify the periods of distress in the banking sector over the recent years including the COVID-19 pandemic, the interest rate hikes in 2022, and the banking crisis in 2023.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03443"
    },
    {
        "doc_id": 383,
        "title": "Modelling and Predicting the Conditional Variance of Bitcoin Daily Returns: Comparsion of Markov Switching GARCH and SV Models",
        "authors": [
            "Dennis Koch",
            "Vahidin Jeleskovic",
            "Zahid I. Younas"
        ],
        "subjects": [
            "Statistical Finance",
            "Risk Management"
        ],
        "abstract": "This paper introduces a unique and valuable research design aimed at analyzing Bitcoin price volatility. To achieve this, a range of models from the Markov Switching-GARCH and Stochastic Autoregressive Volatility (SARV) model classes are considered and their out-of-sample forecasting performance is thoroughly examined. The paper provides insights into the rationale behind the recommendation for a two-stage estimation approach, emphasizing the separate estimation of coefficients in the mean and variance equations. The results presented in this paper indicate that Stochastic Volatility models, particularly SARV models, outperform MS-GARCH models in forecasting Bitcoin price volatility. Moreover, the study suggests that in certain situations, persistent simple GARCH models may even outperform Markov-Switching GARCH models in predicting the variance of Bitcoin log returns. These findings offer valuable guidance for risk management experts, highlighting the potential advantages of SARV models in managing and forecasting Bitcoin price volatility.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03393"
    },
    {
        "doc_id": 384,
        "title": "Volatility models in practice: Rough, Path-dependent or Markovian?",
        "authors": [
            "Eduardo Abi Jaber",
            "Shaun",
            "Li"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "An extensive empirical study of the class of Volterra Bergomi models using SPX options data between 2011 and 2022 reveals the following fact-check on two fundamental claims echoed in the rough volatility literature:\n  Do rough volatility models with Hurst index $H \\in (0,1/2)$ really capture well SPX implied volatility surface with very few parameters? No, rough volatility models are inconsistent with the global shape of SPX smiles. They suffer from severe structural limitations imposed by the roughness component, with the Hurst parameter $H \\in (0,1/2)$ controlling the smile in a poor way. In particular, the SPX at-the-money skew is incompatible with the power-law shape generated by rough volatility models. The skew of rough volatility models increases too fast on the short end, and decays too slow on the longer end where \"negative\" $H$ is sometimes needed.\n  Do rough volatility models really outperform consistently their classical Markovian counterparts? No, for short maturities they underperform their one-factor Markovian counterpart with the same number of parameters. For longer maturities, they do not systematically outperform the one-factor model and significantly underperform when compared to an under-parametrized two-factor Markovian model with only one additional calibratable parameter.\n  On the positive side: our study identifies a (non-rough) path-dependent Bergomi model and an under-parametrized two-factor Markovian Bergomi model that consistently outperform their rough counterpart in capturing SPX smiles between one week and three years with only 3 to 4 calibratable parameters. \\end{abstract}",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03345"
    },
    {
        "doc_id": 385,
        "title": "Negatively dependent optimal risk sharing",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Risk Management"
        ],
        "abstract": "We analyze the problem of optimally sharing risk using allocations that exhibit counter-monotonicity, the most extreme form of negative dependence. Counter-monotonic allocations take the form of either \"winner-takes-all\" lotteries or \"loser-loses-all\" lotteries, and we respectively refer to these (normalized) cases as jackpot or scapegoat allocations. Our main theorem, the counter-monotonic improvement theorem, states that for a given set of random variables that are either all bounded from below or all bounded from above, one can always find a set of counter-monotonic random variables such that each component is greater or equal than its counterpart in the convex order. We show that Pareto optimal allocations, if they exist, must be jackpot allocations when all agents are risk seeking. We essentially obtain the opposite when all agents have discontinuous Bernoulli utility functions, as scapegoat allocations maximize the probability of being above the discontinuity threshold. We also consider the case of rank-dependent expected utility (RDU) agents and find conditions which guarantee that RDU agents prefer jackpot allocations. We provide an application for the mining of cryptocurrencies and show that in contrast to risk-averse miners, RDU miners with small computing power never join a mining pool. Finally, we characterize the competitive equilibria with risk-seeking agents, providing a first and second fundamental theorem of welfare economics where all equilibrium allocations are jackpot allocations.",
        "comments": "35 pages, 1 figure, Keywords: Pareto optimality, Risk sharing, Counter-monotonicity, Risk seeking, Rank-dependent expected utility, Cryptocurrency mining pools",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03328"
    },
    {
        "doc_id": 386,
        "title": "Optimal Order Execution subject to Reservation Strategies under Execution Risk",
        "authors": [
            "Xue Cheng",
            "Peng Guo",
            "Tai-ho Wang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under order fill uncertainty. A broker-dealer agency is authorized to execute an order of trading on client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reservation strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon. Optimal strategy in feedback form is obtained in closed form. In the absence of execution risk, the optimal strategies subject to reservation strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reservation strategies using implementation shortfall and target close orders as basis. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03305"
    },
    {
        "doc_id": 387,
        "title": "Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning",
        "authors": [
            "Hong-Gi Shin",
            "Sukhyun Jeong",
            "Eui-Yeon Kim",
            "Sungho Hong",
            "Young-Jin Cho",
            "Yong-Hoon Choi"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence"
        ],
        "abstract": "Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.",
        "comments": "Accepted by ICOIN 2024",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02710"
    },
    {
        "doc_id": 388,
        "title": "Displaying risk in mergers: a diagrammatic approach for exchange ratio determination",
        "authors": [
            "Alessandra Mainini",
            "Enrico Moretto",
            "Daniela Visetti"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This article extends, in a stochastic setting, previous results in the determination of feasible exchange ratios for merging companies. A first outcome is that shareholders of the companies involved in the merging process face both an upper and a lower bounds for acceptable exchange ratios. Secondly, in order for the improved `bargaining region' to be intelligibly displayed, the diagrammatic approach developed by Kulpa is exploited.",
        "comments": " ",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02681"
    },
    {
        "doc_id": 389,
        "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization Approach",
        "authors": [
            "Albert Dorador"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02601"
    },
    {
        "doc_id": 390,
        "title": "Opinion formation in the world trade network",
        "authors": [
            "C\u00e9lestin Coquid\u00e9",
            "Jos\u00e9 Lages",
            "Dima L. Shepelyansky"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Mechanics",
            "Social and Information Networks",
            "Physics and Society"
        ],
        "abstract": "We extend the opinion formation approach to probe the world influence of economical organizations. Our opinion formation model mimics a battle between currencies within the international trade network. Based on the United Nations Comtrade database, we construct the world trade network for the years of the last decade from 2010 to 2020. We consider different core groups constituted by countries preferring to trade in a specific currency. We will consider principally two core groups, namely, 5 Anglo-Saxon countries which prefer to trade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical currency, hereafter called BRI, pegged to their economies. We determine the trade currency preference of the other countries via a Monte Carlo process depending on the direct transactions between the countries. The results obtained in the frame of this mathematical model show that starting from year 2014 the majority of the world countries would have preferred to trade in BRI than USD. The Monte Carlo process reaches a steady state with 3 distinct groups: two groups of countries preferring, whatever is the initial distribution of the trade currency preferences, to trade, one in BRI and the other in USD, and a third group of countries swinging as a whole between USD and BRI depending on the initial distribution of the trade currency preferences. We also analyze the battle between USD, EUR and BRI, and present the reduced Google matrix description of the trade relations between the Anglo-Saxon countries and the BRICS+.",
        "comments": "16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02378"
    },
    {
        "doc_id": 391,
        "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
        "authors": [
            "Zeynep Hilal Kilimci",
            "Mustafa Yalcin"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02124"
    },
    {
        "doc_id": 392,
        "title": "Forecasting Bitcoin Volatility: A Comparative Analysis of Volatility Approaches",
        "authors": [
            "Cristina Chinazzo",
            "Vahidin Jeleskovic"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper conducts an extensive analysis of Bitcoin return series, with a primary focus on three volatility metrics: historical volatility (calculated as the sample standard deviation), forecasted volatility (derived from GARCH-type models), and implied volatility (computed from the emerging Bitcoin options market). These measures of volatility serve as indicators of market expectations for conditional volatility and are compared to elucidate their differences and similarities. The central finding of this study underscores a notably high expected level of volatility, both on a daily and annual basis, across all the methodologies employed. However, it's crucial to emphasize the potential challenges stemming from suboptimal liquidity in the Bitcoin options market. These liquidity constraints may lead to discrepancies in the computed values of implied volatility, particularly in scenarios involving extreme moneyness or maturity. This analysis provides valuable insights into Bitcoin's volatility landscape, shedding light on the unique characteristics and dynamics of this cryptocurrency within the context of financial markets.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02049"
    },
    {
        "doc_id": 393,
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "subjects": [
            "Computational Finance",
            "Numerical Analysis"
        ],
        "abstract": "This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01758"
    },
    {
        "doc_id": 394,
        "title": "Text mining arXiv: a look through quantitative finance papers",
        "authors": [
            "Michele Leonardo Bianchi"
        ],
        "subjects": [
            "Digital Libraries",
            "Information Retrieval",
            "General Finance"
        ],
        "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01751"
    },
    {
        "doc_id": 395,
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "authors": [
            "Lioba Heimbach",
            "Vabuk Pahari",
            "Eric Schertenleib"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.\n  In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum's biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 137 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum's total block value and outline possible mitigations.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01622"
    },
    {
        "doc_id": 396,
        "title": "An arbitrage driven price dynamics of Automated Market Makers in the presence of fees",
        "authors": [
            "Joseph Najnudel",
            "Shen-Ning Tung",
            "Kazutoshi Yamazaki",
            "Ju-Yi Yen"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",
        "comments": " ",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01526"
    },
    {
        "doc_id": 397,
        "title": "Nash Equilibria in Greenhouse Gas Offset Credit Markets",
        "authors": [
            "Liam Welsh",
            "Sebastian Jaimungal"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "In response to the global climate crisis, governments worldwide are introducing legislation to reduce greenhouse gas (GHG) emissions to help mitigate environmental catastrophes. One method to encourage emission reductions is to incentivize carbon capturing and carbon reducing projects while simultaneously penalising excess GHG output. Firms that invest in carbon capturing projects or reduce their emissions can receive offset credits (OCs) in return. These OCs can be used for regulatory purposes to offset their excess emissions in a compliance period. OCs may also be traded between firms. Thus, firms have the choice between investing in projects to generate OCs or to trade OCs. In this work, we present a novel market framework and characterise the optimal behaviour of GHG OC market participants in both single-player and two-player settings. We analyse both a single-period and multi-period setting. As the market model does not elicit a closed form solution, we develop a numerical methodology to estimate players' optimal behaviours in accordance to the Nash equilibria. Our findings indicate the actions players take are dependent on the scale of their project opportunities as well as their fellow market participants. We demonstrate the importance of behaving optimally via simulations in order to offset emission penalties and the importance of investing in GHG reducing or capturing projects from a financial perspective.",
        "comments": "MSC Class:          91G99; 35Q91; 91-08; 91A80; 91B74",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01427"
    },
    {
        "doc_id": 398,
        "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces",
        "authors": [
            "Farshud Sorourifar",
            "Thomas Banker",
            "Joel A. Paulson"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.",
        "comments": "9 pages, 2 figures consisting of 6 and 4 plots, accepted to NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01398"
    },
    {
        "doc_id": 399,
        "title": "Almost Perfect Shadow Prices",
        "authors": [
            "Eberhard Mayerhofer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a na\u00efve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",
        "comments": "15 pages",
        "date": "1 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00970"
    },
    {
        "doc_id": 400,
        "title": "Health Digital Twins Supported by Artificial Intelligence-based Algorithms and Extended Reality in Cardiology",
        "authors": [
            "Zofia Rudnicka",
            "Klaudia Proniewska",
            "Mark Perkins",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, significant efforts have been made to create Health Digital Twins (HDTs), digital twins for clinical applications. Heart modeling is one of the fastest-growing fields, which favors the effective application of HDTs. The clinical application of HDTs will be increasingly widespread in the future of healthcare services and has a huge potential to form part of the mainstream in medicine. However, it requires the development of both models and algorithms for the analysis of medical data, and advances in Artificial Intelligence (AI) based algorithms have already revolutionized image segmentation processes. Precise segmentation of lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapy. In this paper, a brief overview of recent achievements in HDT technologies in the field of cardiology, including interventional cardiology was conducted. HDTs were studied taking into account the application of Extended Reality (XR) and AI, as well as data security, technical risks, and ethics-related issues. Special emphasis was put on automatic segmentation issues. It appears that improvements in data processing will focus on automatic segmentation of medical imaging in addition to three-dimensional (3D) pictures to reconstruct the anatomy of the heart and torso that can be displayed in XR-based devices. This will contribute to the development of effective heart diagnostics. The combination of AI, XR, and an HDT-based solution will help to avoid technical errors and serve as a universal methodology in the development of personalized cardiology. Additionally, we describe potential applications, limitations, and further research directions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14208"
    },
    {
        "doc_id": 401,
        "title": "Validation of Golden Gate assemblies using highly multiplexed Nanopore amplicon sequencing",
        "authors": [
            "Adan A. Ramirez Rojas",
            "Cedric K. Brinkmann",
            "Daniel Schindler"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Golden Gate cloning has revolutionized synthetic biology. Its concept of modular, highly characterized libraries of parts that can be combined into higher order assemblies allows engineering principles to be applied to biological systems. The basic parts, typically stored in level 0 plasmids, are sequence validated by the method of choice and can be combined into higher order assemblies on demand. Higher order assemblies are typically transcriptional units, and multiple transcriptional units can be assembled into multi-gene constructs. Higher order Golden Gate assembly based on defined and validated parts usually does not introduce sequence changes. Therefore, simple validation of the assemblies, e.g. by colony PCR or restriction digest pattern analysis, is sufficient. However, in many experimental setups, researchers do not use defined parts, but rather part libraries, resulting in assemblies of high combinatorial complexity where sequencing again becomes mandatory. Here we present a detailed protocol for the use of a highly multiplexed dual barcode amplicon sequencing using the Nanopore sequencing platform for in-house sequence validation. The workflow, called DuBA.flow, is a start-to-finish procedure that provides all necessary steps from a single colony to the final easy-to-interpret sequencing report.",
        "comments": "25 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14191"
    },
    {
        "doc_id": 402,
        "title": "Dual-trigger release of berberine chloride from the Gelatin/Perfluorohexane core-shell structure",
        "authors": [
            "Mahshid Givarian",
            "Fathollah Moztarzadeh",
            "Maryam Ghaffari",
            "AmirHossein Bahmanpour",
            "Maryam Mollazadeh-Bajestani",
            "Manijhe Mokhtari-Dizaji",
            "Fatemeh Mehradnia"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "The development of smart nanocarriers that enable controlled drug release in response to internal and external triggers is an emerging approach for targeted therapy. This study focused on designing pH-sensitive, ultrasound-responsive gelatin/perfluorohexane (PFH) nanodroplets loaded with berberine chloride as a model drug. The nanodroplets were prepared using an emulsion technique and optimized by varying process parameters like homogenization rate, polymer concentration, surfactant, drug, and perfluorocarbon content. The optimal formulation yielded nanodroplets with a particle size of 281.7 nm, a drug encapsulation efficiency of 66.8, and a passive drug release of 15.4 within 24 hours. Characterization confirmed successful encapsulation and pH-responsive behavior. Ultrasound stimulation significantly enhanced drug release, with 150 kHz being more effective than 1 MHz in triggering acoustic droplet vaporization while minimizing heat generation. After 10 minutes of radiation, the optimal formulation showed 89.4% cumulative drug release. The nanodroplets displayed stability over one month at 4\u00b0C. Overall, the dual-triggered nanodroplets demonstrate excellent potential for controlled delivery and targeted release of berberine chloride.",
        "comments": "39 pages and 5 figures, to appear in Applied Biochemistry and Biotechnology journal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14172"
    },
    {
        "doc_id": 403,
        "title": "Label-free detection of exosomes from different cellular sources based on surface-enhanced Raman spectroscopy combined with machine learning models",
        "authors": [
            "Yang Lia",
            "Xiaoming Lyu",
            "Kuo Zhan",
            "Haoyu Ji",
            "Lei Qin",
            "JianAn Huang"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Exosomes are significant facilitators of inter-cellular communication that can unveil cell-cell interactions, signaling pathways, regulatory mechanisms and disease diagnostics. Nonetheless, current analysis required large amount of data for exosome identification that it hampers efficient and timely mechanism study and diagnostics. Here, we used a machine-learning assisted Surface-enhanced Raman spectroscopy (SERS) method to detect exosomes derived from six distinct cell lines (HepG2, Hela, 143B, LO-2, BMSC, and H8) with small amount of data. By employing sodium borohydride-reduced silver nanoparticles and sodium borohydride solution as an aggregating agent, 100 SERS spectra of the each types of exosomes were collected and then subjected to multivariate and machine learning analysis. By integrating Principal Component Analysis with Support Vector Machine (PCA-SVM) models, our analysis achieved a high accuracy rate of 94.4% in predicting exosomes originating from various cellular sources. In comparison to other machine learning analysis, our method used small amount of SERS data to allow a simple and rapid exosome detection, which enables a timely subsequent study of cell-cell interactions, communication mechanisms, and disease mechanisms in life sciences.",
        "comments": "5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14104"
    },
    {
        "doc_id": 404,
        "title": "Left/Right Brain, human motor control and the implications for robotics",
        "authors": [
            "Jarrad Rinaldo",
            "Levin Kuhlmann",
            "Jason Friedman",
            "Gideon Kowadlo"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Machine Learning",
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "Neural Network movement controllers promise a variety of advantages over conventional control methods however they are not widely adopted due to their inability to produce reliably precise movements. This research explores a bilateral neural network architecture as a control system for motor tasks. We aimed to achieve hemispheric specialisation similar to what is observed in humans across different tasks; the dominant system (usually the right hand, left hemisphere) excels at tasks involving coordination and efficiency of movement, and the non-dominant system performs better at tasks requiring positional stability. Specialisation was achieved by training the hemispheres with different loss functions tailored toward the expected behaviour of the respective hemispheres. We compared bilateral models with and without specialised hemispheres, with and without inter-hemispheric connectivity (representing the biological Corpus Callosum), and unilateral models with and without specialisation. The models were trained and tested on two tasks common in the human motor control literature: the random reach task, suited to the dominant system, a model with better coordination, and the hold position task, suited to the non-dominant system, a model with more stable movement. Each system out-performed the non-favoured system in its preferred task. For both tasks, a bilateral model outperforms the 'non-preferred' hand, and is as good or better than the 'preferred' hand. The Corpus Callosum tends to improve performance, but not always for the specialised models.",
        "comments": "ACM Class:          I.2.6; I.2.9",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14057"
    },
    {
        "doc_id": 405,
        "title": "Radical Realism",
        "authors": [
            "Nicol\u00e1s Hinrichs",
            "Noah Guzm\u00e1n"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The ontogeny of cognitive neuroscience has emerged within the hegemony of substance ontology. Persistent physicalist influences are described through three developmental hallmarks that yielded epistemic attractors - promoters and perpetuators of material-discursive practices oriented toward reification and self-vindication across the interdisciplinary spectrum which, as a whole, has been driven away from its pretensions to scientific realism. In virtue of a desire for a radical return thereto, we adopt a metaphysic stance akin to pragmatism, and briefly make the case that such concerns have sociopolitical implications extending far beyond the realm of mere philosophical interest.",
        "comments": "19 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14049"
    },
    {
        "doc_id": 406,
        "title": "DNA Sequence Classification with Compressors",
        "authors": [
            "\u015e\u00fckr\u00fc Ozan"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "Recent studies in DNA sequence classification have leveraged sophisticated machine learning techniques, achieving notable accuracy in categorizing complex genomic data. Among these, methods such as k-mer counting have proven effective in distinguishing sequences from varied species like chimpanzees, dogs, and humans, becoming a staple in contemporary genomic research. However, these approaches often demand extensive computational resources, posing a challenge in terms of scalability and efficiency. Addressing this issue, our study introduces a novel adaptation of Jiang et al.'s compressor-based, parameter-free classification method, specifically tailored for DNA sequence analysis. This innovative approach utilizes a variety of compression algorithms, such as Gzip, Brotli, and LZMA, to efficiently process and classify genomic sequences. Not only does this method align with the current state-of-the-art in terms of accuracy, but it also offers a more resource-efficient alternative to traditional machine learning methods. Our comprehensive evaluation demonstrates the proposed method's effectiveness in accurately classifying DNA sequences from multiple species. We present a detailed analysis of the performance of each algorithm used, highlighting the strengths and limitations of our approach in various genomic contexts. Furthermore, we discuss the broader implications of our findings for bioinformatics, particularly in genomic data processing and analysis. The results of our study pave the way for more efficient and scalable DNA sequence classification methods, offering significant potential for advancements in genomic research and applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14025"
    },
    {
        "doc_id": 407,
        "title": "Temperature Compensation through Kinetic Regulation in Biochemical Oscillators",
        "authors": [
            "Haochen Fu",
            "Chenyi Fei",
            "Qi Ouyang",
            "Yuhai Tu"
        ],
        "subjects": [
            "Molecular Networks",
            "Biological Physics"
        ],
        "abstract": "Nearly all circadian clocks maintain a period that is insensitive to temperature changes, a phenomenon known as temperature compensation (TC). Yet, it is unclear whether there is any common feature among different systems that exhibit TC. From a general timescale invariance, we show that TC relies on existence of certain period-lengthening reactions wherein the period of the system increases strongly with the rates in these reactions. By studying several generic oscillator models, we show that this counter-intuitive dependence is nonetheless a common feature of oscillators in the nonlinear (far-from-onset) regime where the oscillation can be separated into fast and slow phases. The increase of the period with the period-lengthening reaction rates occurs when the amplitude of the slow phase in the oscillation increases with these rates while the progression-speed in the slow phase is controlled by other rates of the system. The positive dependence of the period on the period-lengthening rates balances its inverse dependence on other kinetic rates in the system, which gives rise to robust TC in a wide range of parameters. We demonstrate the existence of such period-lengthening reactions and their relevance for TC in all four model systems we considered. Theoretical results for a model of the Kai system are supported by experimental data. A study of the energy dissipation also shows that better TC performance requires higher energy consumption. Our study unveils a general mechanism by which a biochemical oscillator achieves TC by operating at regimes far from the onset where period-lengthening reactions exist.",
        "comments": "19 pages, 11 figures (main text + supplementary information)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13960"
    },
    {
        "doc_id": 408,
        "title": "Towards 3D Molecule-Text Interpretation in Language Models",
        "authors": [
            "Sihang Li",
            "Zhiyuan Liu",
            "Yanchen Luo",
            "Xiang Wang",
            "Xiangnan He",
            "Kenji Kawaguchi",
            "Tat-Seng Chua",
            "Qi Tian"
        ],
        "subjects": [
            "Machine Learning",
            "Information Retrieval",
            "Biomolecules"
        ],
        "abstract": "Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder's representation space and the LM's input space. Moreover, to enhance 3D-MoLM's ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks, including molecule-text retrieval, molecule captioning, and more challenging open-text molecular QA tasks, especially focusing on 3D-dependent properties.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13923"
    },
    {
        "doc_id": 409,
        "title": "Inverse Molecular Design with Multi-Conditional Diffusion Guidance",
        "authors": [
            "Gang Liu",
            "Jiaxin Xu",
            "Tengfei Luo",
            "Meng Jiang"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We introduce multi-conditional diffusion guidance. The proposed Transformer-based denoising model has a condition encoder that learns the representations of numerical and categorical conditions. The denoising model, consisting of a structure encoder-decoder, is trained for denoising under the representation of conditions. The diffusion process becomes graph-dependent to accurately estimate graph-related noise in molecules, unlike the previous models that focus solely on the marginal distributions of atoms or bonds. We extensively validate our model for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution learning to condition control for molecular properties. An inverse polymer design task for gas separation with feedback from domain experts further demonstrates its practical utility.",
        "comments": "20 pages, 8 figures, 7 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13858"
    },
    {
        "doc_id": 410,
        "title": "Engineering Yeast Cells to Facilitate Information Exchange",
        "authors": [
            "Nikolaos Ntetsikas",
            "Styliana Kyriakoudi",
            "Antonis Kirmizis",
            "Bige Deniz Unluturk",
            "Andreas Pitsillides",
            "Ian F. Akyildiz",
            "Marios Lestas"
        ],
        "subjects": [
            "Emerging Technologies",
            "Information Theory",
            "Molecular Networks"
        ],
        "abstract": "Although continuous advances in theoretical modelling of Molecular Communications (MC) are observed, there is still an insuperable gap between theory and experimental testbeds, especially at the microscale. In this paper, the development of the first testbed incorporating engineered yeast cells is reported. Different from the existing literature, eukaryotic yeast cells are considered for both the sender and the receiver, with \u03b1-factor molecules facilitating the information transfer. The use of such cells is motivated mainly by the well understood biological mechanism of yeast mating, together with their genetic amenability. In addition, recent advances in yeast biosensing establish yeast as a suitable detector and a neat interface to in-body sensor networks. The system under consideration is presented first, and the mathematical models of the underlying biological processes leading to an end-to-end (E2E) system are given. The experimental setup is then described and used to obtain experimental results which validate the developed mathematical models. Beyond that, the ability of the system to effectively generate output pulses in response to repeated stimuli is demonstrated, reporting one event per two hours. However, fast RNA fluctuations indicate cell responses in less than three minutes, demonstrating the potential for much higher rates in the future.",
        "comments": "18 pages, 9 figures (2 of which are not colored) all .png, recently accepted for publication at TMBMC",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13712"
    },
    {
        "doc_id": 411,
        "title": "Accelerating hyperbolic t-SNE",
        "authors": [
            "Martin Skrodzki",
            "Hunter van Geffen",
            "Nicolas F. Chaves-de-Plaza",
            "Thomas H\u00f6llt",
            "Elmar Eisemann",
            "Klaus Hildebrandt"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods",
            "Machine Learning"
        ],
        "abstract": "The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13708"
    },
    {
        "doc_id": 412,
        "title": "A generic model of consciousness",
        "authors": [
            "Mark J. Hadley"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "This is a model of consciousness. The hard problem of consciousness, what it feels like, is answered. The work builds on medical research analyzing the source and mechanisms associated with our feelings. It goes further by describing a generic model with wide applicability. The model is fully consistent with medical pathways in humans, but easily extends to animals and AI. The essence of the model is the interplay between associative memory and physiology. The model is a clear and concrete counterexample to the famous philosophical objections to a scientific explanation.",
        "comments": "Journal ref:        Journal of Artificial Intelligence and Consciousness 10 (2):291--308 (2023)",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13690"
    },
    {
        "doc_id": 413,
        "title": "Detecting local perturbations of networks in a latent hyperbolic space",
        "authors": [
            "Alice Longhena",
            "Martin Guillemaud",
            "Mario Chavez"
        ],
        "subjects": [
            "Quantitative Methods",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Graph theoretical approaches have been proven to be effective in the characterization of connected systems, as well as in quantifying their dysfunction due to perturbation. In this paper, we show the advantage of a non-Euclidean (hyperbolic) representation of networks to identify local connectivity perturbations and to characterize the induced effects on a large scale. We propose two perturbation scores based on representations of the networks in a latent geometric space, obtained through an embedding onto the hyperbolic Poincar\u00e9 disk. We numerically demonstrate that these methods are able to localize perturbations in networks with homogeneous or heterogeneous degree connectivity. We apply this framework to identify the most perturbed brain areas in epileptic patients following surgery. This study is conceived in the effort of developing more powerful tools to represent and analyze brain networks, and it is the first to apply geometric network embedding techniques to the case of epilepsy.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13495"
    },
    {
        "doc_id": 414,
        "title": "Unified neural field theory of brain dynamics underlying oscillations in Parkinson's disease and generalized epilepsies",
        "authors": [
            "Eli J M\u00fcller",
            "Sacha J van Albada",
            "Jong-Won Kim",
            "Peter A Robinson"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The mechanisms underlying pathologically synchronized neural oscillations in Parkinson's disease (PD) and generalized epilepsies are jointly explored via a neural field model of the corticothalamic-basal ganglia (CTBG) system. The basal ganglia (BG) are approximated as a single effective population and their roles in modulating oscillatory corticothalamic (CT) dynamics and vice versa are analyzed. Besides normal EEG rhythms, enhanced activity around 4 Hz and 20 Hz exists in the model, consistent with characteristic frequencies in PD. These rhythms result from resonances in loops between the BG and CT populations, analogous to those underlying epileptic oscillations in a previous CT model. Dopamine depletion is argued to weaken the dampening of these resonances in PD, and network connections explain the significant coherence between BG, thalamic, and cortical activity around 4-8 Hz and 20 Hz. Parallels between the afferent and efferent connection sites of the thalamic reticular nucleus (TRN) and BG predict low dopamine to correspond to a reduced likelihood of tonic-clonic (grand mal) seizures, agreeing with experimental findings. Further, the model predicts an increased likelihood of absence (petit mal) seizure resulting from low dopamine levels matching experimental findings. Suppression of absence seizure activity is shown when afferent and efferent BG connections to the CT system are strengthened, consistent with other CTBG modeling studies. The BG are demonstrated to suppress activity of the CTBG system near tonic-clonic seizure states, providing insight into the reported efficacy of current treatments in BG circuits. Sleep states of the TRN are also found to suppress pathological PD activity matching observations. Overall, the findings demonstrate strong parallels between coherent oscillations in generalized epilepsies and PD, and provide insights into possible comorbidities.",
        "comments": "Journal ref:        Journal of Theoretical Biology (2017) 428, 132-146",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13467"
    },
    {
        "doc_id": 415,
        "title": "TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification",
        "authors": [
            "Sathyanarayanan Aakur",
            "Vishalini R. Laguduva",
            "Priyadharsini Ramamurthy",
            "Akhilesh Ramachandran"
        ],
        "subjects": [
            "Genomics",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "A species' genetic code or genome encodes valuable evolutionary, biological, and phylogenetic information that aids in species recognition, taxonomic classification, and understanding genetic predispositions like drug resistance and virulence. However, the vast number of potential species poses significant challenges in developing a general-purpose whole genome classification tool. Traditional bioinformatics tools have made notable progress but lack scalability and are computationally expensive. Machine learning-based frameworks show promise but must address the issue of large classification vocabularies with long-tail distributions. In this study, we propose addressing this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a taxonomy-aware embedding space for reasoning and classification. This embedding space captures compositional and phylogenetic relationships of species, enabling predictions in extensive search spaces. We evaluate TEPI using two rigorous zero-shot settings and demonstrate its generalization capabilities qualitatively on curated, large-scale, publicly sourced data.",
        "comments": "Accepted to IEEE JBHI",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13219"
    },
    {
        "doc_id": 416,
        "title": "Single NV in nanodiamond for quantum sensing of protein dynamics in an ABEL trap",
        "authors": [
            "Ivan Perez",
            "Anke Krueger",
            "Joerg Wrachtrup",
            "Fedor Jelezko",
            "Michael B\u00f6rsch"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Enzymes are cellular protein machines using a variety of conformational changes to power fast biochemical catalysis. Our goal is to exploit the single-spin properties of the luminescent NV (nitrogen-vacancy) center in nanodiamonds to reveal the dynamics of an active enzyme complex at physiological conditions with the highest spatio-temporal resolution. Specifically attached to the membrane enzyme FoF1-ATP synthase, the NV sensor will report the adenosine triphosphate (ATP)-driven full rotation of Fo motor subunits in ten consecutive 36\u00b0 steps. Conformational dynamics are monitored using either a double electron-electron resonance scheme or NV- magnetometry with optical readout or using NV- relaxometry with a superparamagnetic nanoparticle as the second marker attached to the same enzyme. First, we show how all photophysical parameters like individual size, charge, brightness, spectral range of fluorescence and fluorescence lifetime can be determined for the NV- center in a single nanodiamond held in aqueous solution by a confocal anti-Brownian electrokinetic trap (ABEL trap). Stable photon count rates of individual nanodiamonds and the absence of blinking allow for observation times of single nanodiamonds in solution exceeding hundreds of seconds. For the proposed quantum sensing of nanometer-sized distance changes within an active enzyme, we show that local magnetic field fluctuations can be detected all-optically by analyzing fluorescence lifetime changes of the NV- center in each nanodiamond in solution.",
        "comments": "14 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13180"
    },
    {
        "doc_id": 417,
        "title": "Enabling Global Image Data Sharing in the Life Sciences",
        "authors": [
            "Peter Bajcsy",
            "Sreenivas Bhattiprolu",
            "Katy Borner",
            "Beth Cimini",
            "Lucy Collinson",
            "Jan Ellenberg",
            "Reto Fiolka",
            "Maryellen Giger",
            "Wojtek Goscinski",
            "Matthew Hartley",
            "Nathan Hotaling",
            "Rick Horwitz",
            "Florian Jug",
            "Anna Kreshuk",
            "Emma Lundberg",
            "Aastha Mathur",
            "Kedar Narayan",
            "Shuichi Onami",
            "Anne L. Plant",
            "Fred Prior",
            "Jason Swedlow",
            "Adam Taylor",
            "Antje Keppler"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Coordinated collaboration is essential to realize the added value of and infrastructure requirements for global image data sharing in the life sciences. In this White Paper, we take a first step at presenting some of the most common use cases as well as critical/emerging use cases of (including the use of artificial intelligence for) biological and medical image data, which would benefit tremendously from better frameworks for sharing (including technical, resourcing, legal, and ethical aspects). In the second half of this paper, we paint an ideal world scenario for how global image data sharing could work and benefit all life sciences and beyond. As this is still a long way off, we conclude by suggesting several concrete measures directed toward our institutions, existing imaging communities and data initiatives, and national funders, as well as publishers. Our vision is that within the next ten years, most researchers in the world will be able to make their datasets openly available and use quality image data of interest to them for their research and benefit. This paper is published in parallel with a companion White Paper entitled Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data, which addresses challenges and opportunities related to producing well-documented and high-quality image data that is ready to be shared. The driving goal is to address remaining challenges and democratize access to everyday practices and tools for a spectrum of biomedical researchers, regardless of their expertise, access to resources, and geographical location.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13023"
    },
    {
        "doc_id": 418,
        "title": "Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data",
        "authors": [
            "Nikki Bialy",
            "Frank Alber",
            "Brenda Andrews",
            "Michael Angelo",
            "Brian Beliveau",
            "Lacramioara Bintu",
            "Alistair Boettiger",
            "Ulrike Boehm",
            "Claire M. Brown",
            "Mahmoud Bukar Maina",
            "James J. Chambers",
            "Beth Cimini",
            "Kevin Eliceiri",
            "Rachel Errington",
            "Orestis Faklaris",
            "Nathalie Gaudreault",
            "Ronald N. Germain",
            "Wojtek Goscinski",
            "David Grunwald",
            "Michael Halter",
            "Dorit Hanein",
            "John W. Hickey",
            "Judith Lacoste",
            "Alex Laude",
            "Emma Lundberg",
            "et al. (22 additional authors not shown)"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Together with the molecular knowledge of genes and proteins, biological images promise to significantly enhance the scientific understanding of complex cellular systems and to advance predictive and personalized therapeutic products for human health. For this potential to be realized, quality-assured image data must be shared among labs at a global scale to be compared, pooled, and reanalyzed, thus unleashing untold potential beyond the original purpose for which the data was generated. There are two broad sets of requirements to enable image data sharing in the life sciences. One set of requirements is articulated in the companion White Paper entitled Enabling Global Image Data Sharing in the Life Sciences, which is published in parallel and addresses the need to build the cyberinfrastructure for sharing the digital array data. In this White Paper, we detail a broad set of requirements, which involves collecting, managing, presenting, and propagating contextual information essential to assess the quality, understand the content, interpret the scientific implications, and reuse image data in the context of the experimental details. We start by providing an overview of the main lessons learned to date through international community activities, which have recently made considerable progress toward generating community standard practices for imaging Quality Control (QC) and metadata. We then provide a clear set of recommendations for amplifying this work. The driving goal is to address remaining challenges and democratize access to everyday practices and tools for a spectrum of biomedical researchers, regardless of their expertise, access to resources, and geographical location.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13022"
    },
    {
        "doc_id": 419,
        "title": "How norms shape the evolution of prosocial behavior. Compassion, Universalizability, Reciprocity, Equity: A C.U.R.E for social dilemmas",
        "authors": [
            "Brian Mintz",
            "Feng Fu"
        ],
        "subjects": [
            "Physics and Society",
            "Populations and Evolution"
        ],
        "abstract": "How cooperation evolves and particularly maintains at a large scale remains an open problem for improving humanity across domains ranging from climate change to pandemic response. To shed light on how behavioral norms can resolve the social dilemma of cooperation, here we present a formal mathematical model of individuals' decision making under general social norms, encompassing a variety of concerns and motivations an individual may have beyond simply maximizing their own payoffs. Using the canonical game of the Prisoner's Dilemma, we compare four different norms: compassion, universalizability, reciprocity, and equity, to determine which social forces can facilitate the evolution of cooperation, if any. We analyze our model through a variety of limiting cases, including weak selection, low mutation, and large population sizes. This is complemented by computer simulations of population dynamics via a Fisher process, which confirm our theoretical results. We find that the first two norms lead to the emergence of cooperation in a wide range of games, but the latter two do not on their own. Due to its generality, our framework can be used to investigate many more norms, as well as how norms themselves emerge and evolve. Our work complements recent work on fair-minded learning dynamics and provides a useful bottom-up perspective into understanding the impact of top-down social norms on collective cooperative intelligence.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13015"
    },
    {
        "doc_id": 420,
        "title": "Ready for climate change? The importance of adaptive thermoregulatory flexibility for the Malagasy bat species Triaenops menamena",
        "authors": [
            "Sina Remmers"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "The balance between energy intake and expenditure is essential and crucial for survival for all organisms. The energy management is closely linked to the ecology. Thus, changes in environmental conditions can be challenging, especially for the animals physiology. Different strategies of thermoregulation have evolved and heterothermy seems to be the most efficient way for saving energy. Daily torpor, a temporally controlled reduction of the metabolic rate and body temperature, is one form of heterothermy and recent studies revealed that this physiological strategy is used by many tropical and subtropical species. Yet, little is known about torpor in bats and their intraspecific thermoregulatory flexibility. Therefore, three populations of the Malagasy bat species Triaenops menamena were investigated, to examine their metabolic rate, skin temperature and related energy expenditure during normothermic and torpid states in context of different microclimatic conditions. This study exposed significant physiological differences among these three populations along a gradient of fluctuation in environmental conditions. The greater the fluctuations in ambient temperature and humidity, the higher was the general resting metabolic rate and the rate of its reduction, but the lower was the torpid metabolic rate. This species shows a highly adaptive flexibility in their physiology and are able to cope with unfavorable environmental conditions by using different strategies of thermoregulation and hypometabolism, which is beneficial regarding ongoing climatic changes.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13012"
    },
    {
        "doc_id": 421,
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "authors": [
            "Hanxue Gu",
            "Roy Colglazier",
            "Haoyu Dong",
            "Jikai Zhang",
            "Yaqian Chen",
            "Zafer Yildiz",
            "Yuwen Chen",
            "Lin Li",
            "Jichen Yang",
            "Jay Willhite",
            "Alex M. Meyer",
            "Brian Guo",
            "Yashvi Atul Shah",
            "Emily Luo",
            "Shipra Rajput",
            "Sally Kuehn",
            "Clark Bulleit",
            "Kevin A. Wu",
            "Jisoo Lee",
            "Brandon Ramirez",
            "Darui Lu",
            "Jay M. Levin",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "comments": "15 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12974"
    },
    {
        "doc_id": 422,
        "title": "Analysis of a detailed multi-stage model of stochastic gene expression using queueing theory and model reduction",
        "authors": [
            "Muhan Ma",
            "Juraj Szavits-Nossan",
            "Abhyudai Singh",
            "Ramon Grima"
        ],
        "subjects": [
            "Molecular Networks",
            "Quantitative Methods",
            "Subcellular Processes"
        ],
        "abstract": "We introduce a biologically detailed, stochastic model of gene expression describing the multiple rate-limiting steps of transcription, nuclear pre-mRNA processing, nuclear mRNA export, cytoplasmic mRNA degradation and translation of mRNA into protein. The processes in sub-cellular compartments are described by an arbitrary number of processing stages, thus accounting for a significantly finer molecular description of gene expression than conventional models such as the telegraph, two-stage and three-stage models of gene expression. We use two distinct tools, queueing theory and model reduction using the slow-scale linear-noise approximation, to derive exact or approximate analytic expressions for the moments or distributions of nuclear mRNA, cytoplasmic mRNA and protein fluctuations, as well as lower bounds for their Fano factors in steady-state conditions. We use these to study the phase diagram of the stochastic model; in particular we derive parametric conditions determining three types of transitions in the properties of mRNA fluctuations: from sub-Poissonian to super-Poissonian noise, from high noise in the nucleus to high noise in the cytoplasm, and from a monotonic increase to a monotonic decrease of the Fano factor with the number of processing stages. In contrast, protein fluctuations are always super-Poissonian and show weak dependence on the number of mRNA processing stages. Our results delineate the region of parameter space where conventional models give qualitatively incorrect results and provide insight into how the number of processing stages, e.g. the number of rate-limiting steps in initiation, splicing and mRNA degradation, shape stochastic gene expression by modulation of molecular memory.",
        "comments": "49 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12661"
    },
    {
        "doc_id": 423,
        "title": "The stability and instability of the language control network: a longitudinal resting-state functional magnetic resonance imaging study",
        "authors": [
            "Zilong Li",
            "Cong Liu",
            "Xin Pan",
            "Guosheng Ding",
            "Ruiming Wanga"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The language control network is vital among language-related networks responsible for solving the problem of multiple language switching. Researchers have expressed concerns about the instability of the language control network when exposed to external influences (e.g., Long-term second language learning). However, some studies have suggested that the language control network is stable. Therefore, whether the language control network is stable or not remains unclear. In the present study, we directly evaluated the stability and instability of the language control network using resting-state functional magnetic resonance imaging (rs-fMRI). We employed cohorts of Chinese first-year college students majoring in English who underwent second language (L2) acquisition courses at a university and those who did not. Two resting-state fMRI scans were acquired approximately 1 year apart. We found that the language control network was both moderately stable and unstable. We further investigated the morphological coexistence patterns of stability and instability within the language control network. First, we extracted connections representing stability and plasticity from the entire network. We then evaluated whether the coexistence patterns were modular (stability and instability involve different brain regions) or non-modular (stability and plasticity involve the same brain regions but have unique connectivity patterns). We found that both stability and instability coexisted in a non-modular pattern. Compared with the non-English major group, the English major group has a more non-modular coexistence pattern.. These findings provide preliminary evidence of the coexistence of stability and instability in the language control network.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12616"
    },
    {
        "doc_id": 424,
        "title": "Experiencing an elongated limb in virtual reality modifies the tactile distance perception of the corresponding real limb",
        "authors": [
            "Fran\u00e7ois Le Jeune",
            "Marco D'Alonzo",
            "Valeria Piombino",
            "Alessia Noccaro",
            "Domenico Formica",
            "Giovanni Di Pino"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In measurement, a reference frame is needed to compare the measured object to something already known. This raises the neuroscientific question of which reference frame is used by humans when exploring the environment. Previous studies suggested that, in touch, the body employed as measuring tool also serves as reference frame. Indeed, an artificial modification of the perceived dimensions of the body changes the tactile perception of external object dimensions. However, it is unknown if such a change in tactile perception would occur when the body schema is modified through the illusion of owning an limb altered in size. Therefore, employing a virtual hand illusion paradigm with an elongated forearm of different lengths, we systematically tested the subjective perception of distance between two points (tactile distance perception task, TDP task) on the corresponding real forearm following the illusion. Thus, TDP task is used as a proxy to gauge changes in the body schema. Embodiment of the virtual arm was found significantly greater after the synchronous visuo-tactile stimulation condition compared to the asynchronous one, and the forearm elongation significantly increased the TDP. However, we did not find any link between the visuo-tactile induced ownership over the elongated arm and TDP variation, suggesting that vision plays the main role in the modification of the body schema. Additionally, significant effect of elongation found on TDP but not on proprioception suggests that these are affected differently by body schema modifications. These findings confirm the body schema malleability and its role as reference frame in touch.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12601"
    },
    {
        "doc_id": 425,
        "title": "A robust balancing mechanism for spiking neural networks",
        "authors": [
            "Antonio Politi",
            "Alessandro Torcini"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Neurons and Cognition"
        ],
        "abstract": "Dynamical balance of excitation and inhibition is usually invoked to explain the irregular low firing activity observed in the cortex. We propose a robust nonlinear balancing mechanism for a random network of spiking neurons, which works also in absence of strong external currents. Biologically, the mechanism exploits the plasticity of excitatory-excitatory synapses induced by short-term depression. Mathematically, the nonlinear response of the synaptic activity is the key ingredient responsible for the emergence of a stable balanced regime. Our claim is supported by a simple self-consistent analysis accompanied by extensive simulations performed for increasing network sizes. The observed regime is essentially fluctuation driven and characterized by highly irregular spiking dynamics of all neurons.",
        "comments": "9 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12559"
    },
    {
        "doc_id": 426,
        "title": "Understanding Cellular Noise with Optical Perturbation and Deep Learning",
        "authors": [
            "Chuanbo Liu",
            "Yu Fu",
            "Lu Lin",
            "Elliot L. Elson",
            "Jin Wang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Noise plays a crucial role in the regulation of cellular and organismal function and behavior.\n  Exploring noise's impact is key to understanding fundamental biological processes, such as gene expression, signal transduction, and the mechanisms of development and evolution.\n  Currently, a comprehensive method to quantify dynamical behavior of cellular noise within these biochemical systems is lacking.\n  In this study, we introduce an optically-controlled perturbation system utilizing the light-sensitive Phytochrome B (PhyB) from \\textit{Arabidopsis thaliana}, which enables precise noise modulation with high spatial-temporal resolution.\n  Our system exhibits exceptional sensitivity to light, reacting consistently to pulsed light signals, distinguishing it from other photoreceptor-based promoter systems that respond to a single light wavelength.\n  To characterize our system, we developed a stochastic model for phytochromes that accounts for photoactivation/deactivation, thermal reversion, and the dynamics of the light-activated gene promoter system.\n  To precisely control our system, we determined the rate constants for this model using an omniscient deep neural network that can directly map rate constant combinations to time-dependent state joint distributions.\n  By adjusting the activation rates through light intensity and degradation rates via N-terminal mutagenesis, we illustrate that out optical-controlled perturbation can effectively modulate molecular expression level as well as noise.\n  Our results highlight the potential of employing an optically-controlled gene perturbation system as a noise-controlled stimulus source.\n  This approach, when combined with the analytical capabilities of a sophisticated deep neural network, enables the accurate estimation of rate constants from observational data in a broad range of biochemical reaction networks.",
        "comments": "33 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12498"
    },
    {
        "doc_id": 427,
        "title": "Modular Control of Biological Networks",
        "authors": [
            "David Murrugarra",
            "Alan Veliz-Cuba",
            "Elena Dimitrova",
            "Claus Kadelka",
            "Matthew Wheeler",
            "Reinhard Laubenbacher"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "The concept of control is central to understanding and applications of biological network models. Some of their key structural features relate to control functions, through gene regulation, signaling, or metabolic mechanisms, and computational models need to encode these. Applications of models often focus on model-based control, such as in biomedicine or metabolic engineering. This paper presents an approach to model-based control that exploits two common features of biological networks, namely their modular structure and canalizing features of their regulatory mechanisms. The paper focuses on intracellular regulatory networks, represented by Boolean network models. A main result of this paper is that control strategies can be identified by focusing on one module at a time. This paper also presents a criterion based on canalizing features of the regulatory rules to identify modules that do not contribute to network control and can be excluded. For even moderately sized networks, finding global control inputs is computationally very challenging. The modular approach presented here leads to a highly efficient approach to solving this problem. This approach is applied to a published Boolean network model of blood cancer large granular lymphocyte (T-LGL) leukemia to identify a minimal control set that achieves a desired control objective.",
        "comments": "15 pages, 5 figures. arXiv admin note: text overlap with arXiv:2206.04217",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12477"
    },
    {
        "doc_id": 428,
        "title": "A dynamic model to study the potential TB infections and assessment of control strategies in China",
        "authors": [
            "Chuanqing Xu",
            "Kedeng Cheng",
            "Songbai Guo",
            "Dehui Yuan",
            "Xiaoyu Zhao"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "China is one of the countries with a high burden of tuberculosis, and although the number of new cases of tuberculosis has been decreasing year by year, the number of new infections per year has remained high and the diagnosis rate of tuberculosis-infected patients has remained low. Based on the analysis of TB infection data, we develop a model of TB transmission dynamics that include potentially infected individuals and BCG vaccination, fit the model parameters to the data on new TB cases, calculate the basic reproduction number \\mathcal{R}_v= 0.4442. A parametric sensitivity analysis of \\mathcal{R}_v is performed, and we obtained the correlation coefficients of BCG vaccination rate and effectiveness rate with \\mathcal{R}_v as -0.810, -0.825. According to the model, we estimate that there are 614,186 (95% CI [562,631,665,741]) potentially infected TB cases in China, accounting for about 39.5% of the total number of TB cases. We assess the feasibility of achieving the goals of the WHO strategy to end tuberculosis in China and find that reducing the number of new cases by 90 per cent by 2035 is very difficult with the current tuberculosis control measures. However, with an effective combination of control measures such as increased detection of potentially infected persons, improved drug treatment, and reduction of overall exposure to tuberculosis patients, it is feasible to reach the WHO strategic goal of ending tuberculosis by 2035.",
        "comments": "20 pages, 10 figures, 33 conference",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12462"
    },
    {
        "doc_id": 429,
        "title": "Hypochaos prevents tragedy of the commons in discrete-time eco-evolutionary game dynamics",
        "authors": [
            "Samrat Sohel Mondal",
            "Avishuman Ray",
            "Sagar Chakraborty"
        ],
        "subjects": [
            "Populations and Evolution",
            "Adaptation and Self-Organizing Systems"
        ],
        "abstract": "While quite a few recent papers have explored game-resource feedback using the framework of evolutionary game theory, almost all the studies are confined to using time-continuous dynamical equations. Moreover, in such literature, the effect of ubiquitous chaos in the resulting eco-evolutionary dynamics is rather missing. Here, we present a deterministic eco-evolutionary discrete-time dynamics in generation-wise non-overlapping population of two types of harvesters, one harvesting at a faster rate than the other, consuming a self-renewing resource capable of showing chaotic dynamics. In the light of our finding that sometimes chaos is confined exclusively to either the dynamics of the resource or that of the consumer fractions, an interesting scenario is realized: The resource state can keep oscillating chaotically, and hence, it does not vanish to result in the tragedy of the commons, extinction of the resource due to selfish indiscriminate exploitation, and yet the consumer population, whose dynamics depends directly on the state of the resource, may end up being composed exclusively of defectors, i.e., high harvesters. This appears non-intuitive because it is well known that prevention of tragedy of the commons usually requires substantial cooperation to be present.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12245"
    },
    {
        "doc_id": 430,
        "title": "A distribution-guided Mapper algorithm",
        "authors": [
            "Yuyang Tao",
            "Shufei Ge"
        ],
        "subjects": [
            "Algebraic Topology",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Motivation: The Mapper algorithm is an essential tool to explore shape of data in topology data analysis. With a dataset as an input, the Mapper algorithm outputs a graph representing the topological features of the whole dataset. This graph is often regarded as an approximation of a reeb graph of data. The classic Mapper algorithm uses fixed interval lengths and overlapping ratios, which might fail to reveal subtle features of data, especially when the underlying structure is complex.\n  Results: In this work, we introduce a distribution guided Mapper algorithm named D-Mapper, that utilizes the property of the probability model and data intrinsic characteristics to generate density guided covers and provides enhanced topological features. Our proposed algorithm is a probabilistic model-based approach, which could serve as an alternative to non-prababilistic ones. Moreover, we introduce a metric accounting for both the quality of overlap clustering and extended persistence homology to measure the performance of Mapper type algorithm. Our numerical experiments indicate that the D-Mapper outperforms the classical Mapper algorithm in various scenarios. We also apply the D-Mapper to a SARS-COV-2 coronavirus RNA sequences dataset to explore the topological structure of different virus variants. The results indicate that the D-Mapper algorithm can reveal both vertical and horizontal evolution processes of the viruses.\n  Availability: Our package is available at https://github.com/ShufeiGe/D-Mapper.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12237"
    },
    {
        "doc_id": 431,
        "title": "Machine Learning Modeling Of SiRNA Structure-Potency Relationship With Applications Against Sars-Cov-2 Spike Gene",
        "authors": [
            "Damilola Oshunyinka"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "The pharmaceutical Research and development (R&D) process is lengthy and costly, taking nearly a decade to bring a new drug to the market. However, advancements in biotechnology, computational methods, and machine learning algorithms have the potential to revolutionize drug discovery, speeding up the process and improving patient outcomes. The COVID-19 pandemic has further accelerated and deepened the recognition of the potential of these techniques, especially in the areas of drug repurposing and efficacy predictions. Meanwhile, non-small molecule therapeutic modalities such as cell therapies, monoclonal antibodies, and RNA interference (RNAi) technology have gained importance due to their ability to target specific disease pathways and/or patient populations. In the field of RNAi, many experiments have been carried out to design and select highly efficient siRNAs. However, the established patterns for efficient siRNAs are sometimes contradictory and unable to consistently determine the most potent siRNA molecules against a target mRNA. Thus, this paper focuses on developing machine learning models based on the cheminformatics representation of the nucleotide composition (i.e. AUTGC) of siRNA to predict their potency and aid the selection of the most efficient siRNAs for further development. The PLS (Partial Least Square) and SVR (Support Vector Regression) machine learning models built in this work outperformed previously published models. These models can help in predicting siRNA potency and aid in selecting the best siRNA molecules for experimental validation and further clinical development. The study has demonstrated the potential of AI/machine learning models to help expedite siRNA-based drug discovery including the discovery of potent siRNAs against SARS-CoV-2.",
        "comments": "Master's thesis",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12232"
    },
    {
        "doc_id": 432,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 433,
        "title": "Matching biomolecular structures by registration of point clouds",
        "authors": [
            "Michael Habeck",
            "Andreas Kr\u00f6pelin",
            "Nima Vakili"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Motivation: Assessing the match between two biomolecular structures is at the heart of structural analyses such as superposition, alignment and docking. These tasks are typically solved with specialized structure-matching techniques implemented in software for protein structural alignment, rigid-body docking, or rigid fitting into cryo-EM maps. Results: We present a unifying framework to compare biomolecular structures by applying ideas from computer vision. The structures are represented as three-dimensional point clouds and compared by quantifying their overlap. We use the kernel correlation to measure point cloud overlap, and discuss local and global optimization strategies for maximizing the kernel correlation over the space of rigid transformations. We derive a majorization-minimization procedure that can be used to register two point clouds without establishing a point-to-point correspondence. We demonstrate that the majorization-minimization algorithms outperform the commonly used Iterative Closest Point registration algorithm. Furthermore, we discuss and benchmark a randomization strategy for globally optimizing the kernel correlation. We illustrate the approach on various 3D fitting problems such as the comparison of circularly permuted structures and rigid fitting of cryo-EM maps or bead models from small-angle scattering.",
        "comments": "18 pages (main text), 7 figures (main text)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12082"
    },
    {
        "doc_id": 434,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Maria de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 435,
        "title": "Approximating a linear dynamical system from non-sequential data",
        "authors": [
            "Cliff Stein",
            "Pratik Worah"
        ],
        "subjects": [
            "Genomics"
        ],
        "abstract": "Given non-sequential snapshots from instances of a dynamical system, we design a compressed sensing based algorithm that reconstructs the dynamical system. We formally prove that successful reconstruction is possible under the assumption that we can construct an approximate clock from a subset of the coordinates of the underlying system.\n  As an application, we argue that our assumption is likely true for genomic datasets, and we recover the underlying nuclear receptor networks and predict pathways, as opposed to genes, that may differentiate phenotypes in some publicly available datasets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11858"
    },
    {
        "doc_id": 436,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 437,
        "title": "Full-dimensional characterisation of time-warped spike-time stimulus-response distribution geometries",
        "authors": [
            "James B Isbister"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Characterising the representation of sensory stimuli in the brain is a fundamental scientific endeavor, which can illuminate principles of information coding. Most characterizations reduce the dimensionality of neural data by converting spike trains to firing rates or binned spike counts, applying explicitly named methods of ``dimensionality reduction'', or collapsing trial-to-trial variability. Characterisation of the full-dimensional geometry of timing-based representations may provide unexpected insights into how complex high-dimensional information is encoded. Recent research shows that the distribution of representations elicited over trials of a single stimulus can be geometrically characterized without the application of dimensionality reduction, maintaining the temporal spiking information of individual neurons in a cell assembly and illuminating rich geometric structure. We extend these results, showing that precise spike time patterns for larger cell assemblies are time-warped (i.e. stretched or compressed) on each trial. Moreover, by geometrically characterizing distributions of large spike time patterns, our analysis supports the hypothesis that the degree to which a spike time pattern is time-warped depends on the cortical area's background activity level on a single trial. Finally, we suggest that the proliferation of large electrophysiology datasets and the increasing concentration of ``neural geometrists'', creates ideal conditions for characterization of full-dimensional spike time representations, in complement to dimensionality reduction approaches.",
        "comments": "Accepted as an extended abstract at the NeurReps workshop at NeurIPS 2023. The workshop doesn't publish extended abstracts so submitting here",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11784"
    },
    {
        "doc_id": 438,
        "title": "Impact of temporal interaction on the evolution of cooperation",
        "authors": [
            "Yujie He",
            "Tianyu Ren",
            "Junjun Zheng",
            "Huawen Liang"
        ],
        "subjects": [
            "Physics and Society",
            "Social and Information Networks",
            "Populations and Evolution"
        ],
        "abstract": "This research investigates the impact of dynamic interactions with time-varying topologies on the evolution of cooperative behaviours in social dilemmas. Traditional research has focused on deterministic rules governing pairwise interactions, yet the impact of interaction frequency and synchronicity on cooperation remains underexplored. Addressing this gap, our work introduces two temporal interaction mechanisms to model the stochastic or periodic participation of individuals in these games, acknowledging real-life variances due to exogenous temporal factors and geographical time differences. We consider that the interaction state significantly influences both game payoff calculations and the strategy updating process, offering new insights into the emergence and sustainability of cooperation. Our results indicate that maximum game participation frequency is suboptimal under a stochastic interaction mechanism. Instead, an intermediate region of activation probability yields the highest cooperation level, especially under strong dilemma conditions. This suggests that a balance between inactivity security and interaction frequency is crucial. Furthermore, local synchronization of interactions within specific areas is shown to be beneficial, as time differences hinder the spread of cross-structures but promote the formation of dense cooperative clusters with smoother boundaries. Our findings provide an intuitive understanding of node-based temporality and probabilistic interactions, contributing to the broader discourse on resolving social dilemmas.",
        "comments": "7 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11782"
    },
    {
        "doc_id": 439,
        "title": "Combining oligo pools and Golden Gate cloning to create protein variant libraries or guide RNA libraries for CRISPR applications",
        "authors": [
            "Alicia Maci\u00e1 Valero",
            "Rianne C. Prins",
            "Thijs de Vroet",
            "Sonja Billerbeck"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biomolecules"
        ],
        "abstract": "Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 350 bases), a higher error rate compared to alternative synthesis methods, and the presence of truncated molecules in the pool due to incomplete synthesis. Here, we provide users with a comprehensive protocol that details how oligo pools can be used in combination with Golden Gate cloning to create user-defined protein mutant libraries, as well as single guide RNA libraries for CRISPR applications. Our methods are optimized to work within the Yeast Toolkit Golden Gate scheme, but are in principle compatible with any other Golden Gate-based modular cloning toolkit and extendable to other restriction enzyme-based cloning methods beyond Golden Gate. Our methods yield high-quality, affordable, in-house variant libraries.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11746"
    },
    {
        "doc_id": 440,
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "authors": [
            "Chaoqian Wang",
            "Matja\u017e Perc",
            "Attila Szolnoki"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Statistical Mechanics",
            "Computational Complexity",
            "Cellular Automata and Lattice Gases",
            "Populations and Evolution"
        ],
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Ball-and-Box problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11686"
    },
    {
        "doc_id": 441,
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "authors": [
            "Courtney Golden",
            "Dan Ilan",
            "Nicholas Cebry",
            "Christopher Batten"
        ],
        "subjects": [
            "Hardware Architecture",
            "Genomics"
        ],
        "abstract": "DNA sequence alignment is an important workload in computational genomics. Reference-guided DNA assembly involves aligning many read sequences against candidate locations in a long reference genome. To reduce the computational load of this alignment, candidate locations can be pre-filtered using simpler alignment algorithms like edit distance. Prior work has explored accelerating filtering on simulated compute-in-DRAM, due to the massive parallelism of compute-in-memory architectures. In this paper, we present work-in-progress on accelerating filtering using a commercial compute-in-SRAM accelerator. We leverage the recently released Gemini accelerator platform from GSI Technology, which is the first, to our knowledge, commercial-scale compute-in-SRAM system. We accelerate the Myers' bit-parallel edit distance algorithm, producing average speedups of 14.1x over single-core CPU performance. Individual query/candidate alignments produce speedups of up to 24.1x. These early results suggest this novel architecture is well-suited to accelerating the filtering step of sequence-to-sequence DNA alignment.",
        "comments": "Journal ref:        5th Workshop on Accelerator Architecture in Computational Biology and Bioinformatics (AACBB), June 2023",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11685"
    },
    {
        "doc_id": 442,
        "title": "Modern approaches to improving phase contrast electron microscopy",
        "authors": [
            "Jeremy J. Axelrod",
            "Jessie T. Zhang",
            "Petar N. Petrov",
            "Robert M. Glaeser",
            "Holger Mueller"
        ],
        "subjects": [
            "Quantitative Methods",
            "Optics",
            "Biomolecules"
        ],
        "abstract": "Although defocus can be used to generate partial phase contrast in transmission electron microscope images, cryo-electron microscopy (cryo-EM) can be further improved by the development of phase plates which increase contrast by applying a phase shift to the unscattered part of the electron beam. Many approaches have been investigated, including the ponderomotive interaction between light and electrons. We review the recent successes achieved with this method in high-resolution, single-particle cryo-EM. We also review the status of using pulsed or near-field enhanced laser light as alternatives, along with approaches that use scanning transmission electron microscopy (STEM) with a segmented detector rather than a phase plate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11678"
    },
    {
        "doc_id": 443,
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "authors": [
            "Pratik Worah"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.\n  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11562"
    },
    {
        "doc_id": 444,
        "title": "Understanding Hepatitis B Virus Infection through Hepatocyte Proliferation and Capsid Recycling",
        "authors": [
            "Rupchand Sutradhar",
            "D C Dalal"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "Proliferation of uninfected as well as infected hepatocytes and recycling of DNA-containing\n  capsids are two major mechanisms playing significant roles in the clearance of hepatitis B\n  virus (HBV) infection. In this study, the temporal dynamics of this infection are investigated\n  through two in silico bio-mathematical models considering both proliferation of hepatocytes\n  and the recycling of capsids. Both models are formulated on the basis of a key finding in the existing literature: mitosis of infected yields in two uninfected progenies. In the first model,\n  we examine regular proliferation (occurs continuously), while the second model deals with the\n  irregular proliferation (happens when the total number of liver cells decreases to less than 70%\n  of its initial volume). The models are calibrated with the experimental data obtained from\n  an adult chimpanzee. Results of this study suggest that when both hepatocytes proliferate\n  with equal rate, proliferation aids the individual in a rapid recovery from the acute infection\n  whereas in the case of chronic infection, the severity of the infection increases if the proliferation\n  occurs frequently. On the other hand, if the infected cells proliferate at a slower rate than uninfected cells, the proliferation of uninfected hepatocytes contributes to increase the infection,\n  but the proliferation of infected hepatocytes acts to reduce the infection from the long-term\n  perspective. Furthermore, it is also observed that the differences between the outcomes of\n  regular and irregular proliferations are substantial and noteworthy.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11481"
    },
    {
        "doc_id": 445,
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "authors": [
            "Yin Li",
            "Yu Xiong",
            "Wenxin Fan",
            "Kai Wang",
            "Qingqing Yu",
            "Liping Si",
            "Patrick van der Smagt",
            "Jun Tang",
            "Nutan Chen"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.\n  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM models, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these RMSEs are significantly lower than the random prediction error of $4.55$.\n  Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11447"
    },
    {
        "doc_id": 446,
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "authors": [
            "Haoqiang Guo",
            "Sendong Zhao",
            "Haochun Wang",
            "Yanrui Du",
            "Bing Qin"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Biomolecules"
        ],
        "abstract": "Deep learning is now widely used in drug discovery, providing significant acceleration and cost reduction. As the most fundamental building block, molecular representation is essential for predicting molecular properties to enable various downstream applications. Most existing methods attempt to incorporate more information to learn better representations. However, not all features are equally important for a specific task. Ignoring this would potentially compromise the training efficiency and predictive accuracy. To address this issue, we propose a novel approach, which treats language models as an agent and molecular pretraining models as a knowledge base. The agent accentuates task-relevant features in the molecular representation by understanding the natural language description of the task, just as a tailor customizes clothes for clients. Thus, we call this approach MolTailor. Evaluations demonstrate MolTailor's superior performance over baselines, validating the efficacy of enhancing relevance for molecular representation learning. This illustrates the potential of language model guided optimization to better exploit and unleash the capabilities of existing powerful molecular representation methods. Our codes and appendix are available at https://github.com/SCIR-HI/MolTailor.",
        "comments": "Accepted by AAAI 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11403"
    },
    {
        "doc_id": 447,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 448,
        "title": "Sensory adaptation in a continuum model of bacterial chemotaxis -- working range, cost-accuracy relation, and coupled systems",
        "authors": [
            "Vansh Kharbanda",
            "Benedikt Sabass"
        ],
        "subjects": [
            "Cell Behavior",
            "Soft Condensed Matter"
        ],
        "abstract": "Sensory adaptation enables organisms to adjust their perception in a changing environment. A paradigm is bacterial chemotaxis, where the output activity of chemoreceptors is adapted to different baseline concentrations via receptor methylation. The range of internal receptor states limits the stimulus magnitude to which these systems can adapt. Here, we employ a highly idealized, Langevin-equation based model to study how the finite range of state variables affects the adaptation accuracy and the energy dissipation in individual and coupled systems. Maintaining an adaptive state requires constant energy dissipation. We show that the steady-state dissipation rate increases approximately linearly with the adaptation accuracy for varying stimulus magnitudes in the so-called perfect adaptation limit. This result complements the well-known logarithmic cost-accuracy relationship for varying chemical driving. Next, we study linearly coupled pairs of sensory units. We find that the interaction reduces the dissipation rate per unit and affects the overall cost-accuracy relationship. A coupling of the slow methylation variables results in a better accuracy than a coupling of activities. Overall, the findings highlight the significance of both the working range and collective operation mode as crucial design factors that impact the accuracy and energy expenditure of molecular adaptation networks.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11341"
    },
    {
        "doc_id": 449,
        "title": "Uncertainty quantification of receptor ligand binding sites prediction",
        "authors": [
            "Nanjie Chen",
            "Dongliang Yu",
            "Dmitri Beglov",
            "Mark Kon",
            "Julio Enrique Castrillon-Candas"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Recent advancements in protein docking site prediction have highlighted the limitations of traditional rigid docking algorithms, like PIPER, which often neglect critical stochastic elements such as solvent-induced fluctuations. These oversights can lead to inaccuracies in identifying viable docking sites due to the complexity of high-dimensional, stochastic energy manifolds with low regularity. To address this issue, our research introduces a novel model where the molecular shapes of ligands and receptors are represented using multi-variate Karhunen-Lo `eve (KL) expansions. This method effectively captures the stochastic nature of energy manifolds, allowing for a more accurate representation of molecular interactions.Developed as a plugin for PIPER, our scientific computing software enhances the platform, delivering robust uncertainty measures for the energy manifolds of ranked binding sites. Our results demonstrate that top-ranked binding sites, characterized by lower uncertainty in the stochastic energy manifold, align closely with actual docking sites. Conversely, sites with higher uncertainty correlate with less optimal docking positions. This distinction not only validates our approach but also sets a new standard in protein docking predictions, offering substantial implications for future molecular interaction research and drug development.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11312"
    },
    {
        "doc_id": 450,
        "title": "Seasonality of primary productivity affects coastal species more than its magnitude",
        "authors": [
            "Carlota Muniz",
            "Christopher McQuaid",
            "Nicolas Weidberg"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "While the importance of extreme conditions is recognised, patterns in species abundances are often interpreted through average environmental conditions within their distributional range. For marine species with pelagic larvae, temperature and phytoplankton concentration are key variables. Along the south coast of South Africa, conspicuous spatial patterns in recruitment rates and the abundances of different mussel species exist, with focal areas characterized by large populations. We studied 15 years of sea surface temperature (SST) and chlorophyll-a (chl-a) satellite data, using spectral analyses to partition their temporal variability over ecologically relevant time periods, including seasonal (101 to 365 days) and intra-seasonal cycles (20 to 100 days). Adult cover and mussel recruitment were measured at 10 sites along the south coast and regression models showed that about 70 percent of the variability in recruitment and adult cover was explained by seasonal variability in chl-a, while mean annual chl-a and SST only explained 30 percent of the recruitment, with no significant effect for adult cover. SST and chl-a at two upwelling centres showed less predictable seasonal cycles during the second half of the study period with a significant cooling trend during austral autumn, coinciding with one of the mussel reproductive peaks. This likely reflects recent changes in the Agulhas Current, the world largest western boundary current, which affects coastal ecosystems by driving upwelling.",
        "comments": "Journal ref:        Science of the Total Environment, 757:143740, 2021",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11289"
    },
    {
        "doc_id": 451,
        "title": "Smart Drug-Delivery Systems for Cancer Nanotherapy",
        "authors": [
            "Paola Sanchez-Moreno",
            "Juan Luis Ortega-Vinuesa",
            "Jose Manuel Peula-Garcia",
            "Juan Antonio Marchal",
            "Houria Boulaiz"
        ],
        "subjects": [
            "Tissues and Organs",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics",
            "Biological Physics"
        ],
        "abstract": "Despite all the advances achieved in the field of tumor-biology research, in most cases conventional therapies including chemotherapy are still the leading choices. The main disadvantage of these treatments, in addition to the low solubility of many antitumor drugs, is their lack of specificity, which explains the frequent occurrence of serious side effects due to nonspecific drug uptake by healthy cells. Progress in nanotechnology and its application in medicine have provided new opportunities and different smart systems. Such systems can improve the intracellular delivery of the drugs due to their multifunctionality and targeting potential. The purpose of this manuscript is to review and analyze the recent progress made in nanotherapy applied to cancer treatment. First, we provide a global overview of cancer and different smart nanoparticles currently used in oncology. Then, we analyze in detail the development of drug-delivery strategies in cancer therapy, focusing mainly on the intravenously administered smart nanoparticles with protein corona to avoid immune-system clearance. Finally, we discuss the challenges, clinical trials, and future directions of the nanoparticle-based therapy in cancer.",
        "comments": "Preprint version, 25 pages, 7 figures, 3 tables. Authors thank to Bentham Science the posibility of deposit the ACCEPTED VERSION of the peer-reviewed article after 12 months of publication on journal web site on arXiv repository. The published manuscript is available at EurekaSelect via https://www.eurekaselect.com/openurl/content.php?genre=article&doi=10.2174/1389450117666160527142544",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11192"
    },
    {
        "doc_id": 452,
        "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge",
        "authors": [
            "Chih-Hsuan Wei",
            "Alexis Allot",
            "Po-Ting Lai",
            "Robert Leaman",
            "Shubo Tian",
            "Ling Luo",
            "Qiao Jin",
            "Zhizheng Wang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "subjects": [
            "Computation and Language",
            "Quantitative Methods"
        ],
        "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves the factuality and verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive set of features and tools that allow researchers to navigate the ever-expanding wealth of biomedical literature, expediting research and unlocking valuable insights for scientific discovery.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11048"
    },
    {
        "doc_id": 453,
        "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
        "authors": [
            "Minkai Xu",
            "Jiaqi Han",
            "Aaron Lou",
            "Jean Kossaifi",
            "Arvind Ramanathan",
            "Kamyar Azizzadenesheli",
            "Jure Leskovec",
            "Stefano Ermon",
            "Anima Anandkumar"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis",
            "Quantitative Methods"
        ],
        "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11037"
    },
    {
        "doc_id": 454,
        "title": "Clustering Molecular Energy Landscapes by Adaptive Network Embedding",
        "authors": [
            "Paula Mercurio",
            "Di Liu"
        ],
        "subjects": [
            "Biomolecules",
            "Statistical Mechanics",
            "Machine Learning"
        ],
        "abstract": "In order to efficiently explore the chemical space of all possible small molecules, a common approach is to compress the dimension of the system to facilitate downstream machine learning tasks. Towards this end, we present a data driven approach for clustering potential energy landscapes of molecular structures by applying recently developed Network Embedding techniques, to obtain latent variables defined through the embedding function. To scale up the method, we also incorporate an entropy sensitive adaptive scheme for hierarchical sampling of the energy landscape, based on Metadynamics and Transition Path Theory. By taking into account the kinetic information implied by a system's energy landscape, we are able to interpret dynamical node-node relationships in reduced dimensions. We demonstrate the framework through Lennard-Jones (LJ) clusters and a human DNA sequence.",
        "comments": "19 pages, 10 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10972"
    },
    {
        "doc_id": 455,
        "title": "Homogenisation of nonlinear blood flow in periodic networks: the limit of small haematocrit heterogeneity",
        "authors": [
            "Y. Ben-Ami",
            "B. D. Wood",
            "J. M. Pitt-Francis",
            "P. K. Maini",
            "H. M. Byrne"
        ],
        "subjects": [
            "Tissues and Organs",
            "Soft Condensed Matter",
            "Biological Physics"
        ],
        "abstract": "In this work we develop a homogenisation methodology to upscale mathematical descriptions of microcirculatory blood flow from the microscale (where individual vessels are resolved) to the macroscopic (or tissue) scale. Due to the assumed two-phase nature of blood and specific features of red blood cells (RBCs), mathematical models for blood flow in the microcirculation are highly nonlinear, coupling the flow and RBC concentrations (haematocrit). In contrast to previous works which accomplished blood-flow homogenisation by assuming that the haematocrit level remains constant, here we allow for spatial heterogeneity in the haematocrit concentration and thus begin with a nonlinear microscale model. We simplify the analysis by considering the limit of small haematocrit heterogeneity which prevails when variations in haematocrit concentration between neighbouring vessels are small. Homogenisation results in a system of coupled, nonlinear partial differential equations describing the flow and haematocrit transport at the macroscale, in which a nonlinear Darcy-type model relates the flow and pressure gradient via a haematocrit-dependent permeability tensor. During the analysis we obtain further that haematocrit transport at the macroscale is governed by a purely advective equation. Applying the theory to particular examples of two- and three-dimensional geometries of periodic networks, we calculate the effective permeability tensor associated with blood flow in these vascular networks. We demonstrate how the statistical distribution of vessel lengths and diameters, together with the average haematocrit level, affect the statistical properties of the macroscopic permeability tensor. These data can be used to simulate blood flow and haematocrit transport at the macroscale.",
        "comments": "34 pages, 8 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10932"
    },
    {
        "doc_id": 456,
        "title": "A Chaotic Associative Memory",
        "authors": [
            "Nurani Rajagopal Rohan",
            "Sayan Gupta",
            "V. Srinivasa Chakravarthy"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Chaotic Dynamics"
        ],
        "abstract": "We propose a novel Chaotic Associative Memory model using a network of chaotic Rossler systems and investigate the storage capacity and retrieval capabilities of this model as a function of increasing periodicity and chaos. In early models of associate memory networks, memories were modeled as fixed points, which may be mathematically convenient but has poor neurobiological plausibility. Since brain dynamics is inherently oscillatory, attempts have been made to construct associative memories using nonlinear oscillatory networks. However, oscillatory associative memories are plagued by the problem of poor storage capacity, though efforts have been made to improve capacity by adding higher order oscillatory modes. The chaotic associative memory proposed here exploits the continuous spectrum of chaotic elements and has higher storage capacity than previously described oscillatory associate memories.",
        "comments": "10 pages, 8 Figures, Submitted to \"Chaos: An Interdisciplinary Journal of Nonlinear Science\"",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10922"
    },
    {
        "doc_id": 457,
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "authors": [
            "Jason Toy",
            "Josh MacAdam",
            "Phil Tabor"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
        "comments": "9 pages, 4 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10910"
    },
    {
        "doc_id": 458,
        "title": "Novel community data in ecology -- properties and prospects",
        "authors": [
            "Florian Hartig",
            "Nerea Abrego",
            "Alex Bush",
            "Jonathan M. Chase",
            "Gurutzeta Guillera-Arroita",
            "Mathew A. Leibold",
            "Otso Ovaskainen",
            "Lo\u00efc Pellissier",
            "Maximilian Pichler",
            "Giovanni Poggiato",
            "Laura Pollock",
            "Sara Si-Moussi",
            "Wilfried Thuiller",
            "Duarte S. Viana",
            "David I. Warton",
            "Damaris Zurell",
            "Douglas W. Yu"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "New technologies for acquiring biological information such as eDNA, acoustic or optical sensors, make it possible to generate spatial community observations at unprecedented scales. The potential of these novel community data to standardize community observations at high spatial, temporal, and taxonomic resolution and at large spatial scale ('many rows and many columns') has been widely discussed, but so far, there has been little integration of these data with ecological models and theory. Here, we review these developments and highlight emerging solutions, focusing on statistical methods for analyzing novel community data, in particular joint species distribution models; the new ecological questions that can be answered with these data; and the potential implications of these developments for policy and conservation.",
        "comments": "Journal ref:        Trends in Ecology & Evolution, 2024",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10860"
    },
    {
        "doc_id": 459,
        "title": "Exploring the role of structure in a time constrained decision task",
        "authors": [
            "Naomi Chaix-Eichel",
            "Gautham Venugopal",
            "Thomas Boraud",
            "Nicolas P. Rougier"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "The structure of the basal ganglia is remarkably similar across a number of species (often described in terms of direct, indirect and hyperdirect pathways) and is deeply involved in decision making and action selection. In this article, we are interested in exploring the role of structure when solving a decision task while avoiding to make any strong assumption regarding the actual structure. To do so, we exploit the echo state network paradigm that allows to solve complex task based on a random architecture. Considering a temporal decision task, the question is whether a specific structure allows for better performance and if so, whether this structure shares some similarity with the basal ganglia. Our results highlight the advantage of having a slow (direct) and a fast (hyperdirect) pathway that allows to deal with late information during a decision making task.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10849"
    },
    {
        "doc_id": 460,
        "title": "Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer Subtype Diagnosis",
        "authors": [
            "Charles Theodore Kent",
            "Leila Bagheriye",
            "Johan Kwisthout"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Machine Learning",
            "Genomics",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Recent strides in the field of neural computation has seen the adoption of Winner Take All (WTA) circuits to facilitate the unification of hierarchical Bayesian inference and spiking neural networks as a neurobiologically plausible model of information processing. Current research commonly validates the performance of these networks via classification tasks, particularly of the MNIST dataset. However, researchers have not yet reached consensus about how best to translate the stochastic responses from these networks into discrete decisions, a process known as population decoding. Despite being an often underexamined part of SNNs, in this work we show that population decoding has a significanct impact on the classification performance of WTA networks. For this purpose, we apply a WTA network to the problem of cancer subtype diagnosis from multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing so we utilise a novel implementation of gene similarity networks, a feature encoding technique based on Kohoens self organising map algorithm. We further show that the impact of selecting certain population decoding methods is amplified when facing imbalanced datasets.",
        "comments": "This paper has been accepted in BIOINFORMATICS 2024 (BIOSTEC 2024)",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10844"
    },
    {
        "doc_id": 461,
        "title": "DeepRLI: A Multi-objective Framework for Universal Protein--Ligand Interaction Prediction",
        "authors": [
            "Haoyu Lin",
            "Shiwei Wang",
            "Jintao Zhu",
            "Yibo Li",
            "Jianfeng Pei",
            "Luhua Lai"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Protein (receptor)--ligand interaction prediction is a critical component in computer-aided drug design, significantly influencing molecular docking and virtual screening processes. Despite the development of numerous scoring functions in recent years, particularly those employing machine learning, accurately and efficiently predicting binding affinities for protein--ligand complexes remains a formidable challenge. Most contemporary methods are tailored for specific tasks, such as binding affinity prediction, binding pose prediction, or virtual screening, often failing to encompass all aspects. In this study, we put forward DeepRLI, a novel protein--ligand interaction prediction architecture. It encodes each protein--ligand complex into a fully connected graph, retaining the integrity of the topological and spatial structure, and leverages the improved graph transformer layers with cosine envelope as the central module of the neural network, thus exhibiting superior scoring power. In order to equip the model to generalize to conformations beyond the confines of crystal structures and to adapt to molecular docking and virtual screening tasks, we propose a multi-objective strategy, that is, the model outputs three scores for scoring and ranking, docking, and screening, and the training process optimizes these three objectives simultaneously. For the latter two objectives, we augment the dataset through a docking procedure, incorporate suitable physics-informed blocks and employ an effective contrastive learning approach. Eventually, our model manifests a balanced performance across scoring, ranking, docking, and screening, thereby demonstrating its ability to handle a range of tasks. Overall, this research contributes a multi-objective framework for universal protein--ligand interaction prediction, augmenting the landscape of structure-based drug design.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10806"
    },
    {
        "doc_id": 462,
        "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks",
        "authors": [
            "Heorhii Skovorodnikov",
            "Hoda Alkhzaimi"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Genomics"
        ],
        "abstract": "With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples via spectral analysis yielding conclusions for countermeasures against such attacks.",
        "comments": "15 pages, core code available at: https://github.com/HeorhiiS/fimba-attack",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10657"
    },
    {
        "doc_id": 463,
        "title": "Exact analytical algorithm for solvent accessible surface area and derivatives in implicit solvent molecular simulations on GPUs",
        "authors": [
            "Xin Cao",
            "Michelle H. Hummel",
            "Yuzhang Wang",
            "Carlos Simmerling",
            "Evangelos A. Coutsias"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "In this paper, we present dSASA (differentiable SASA), an exact geometric method to calculate solvent accessible surface area (SASA) analytically along with atomic derivatives on GPUs. The atoms in a molecule are first assigned to tetrahedra in groups of four atoms by Delaunay tetrahedrization adapted for efficient GPU implementation and the SASA values for atoms and molecules are calculated based on the tetrahedrization information and inclusion-exclusion method. The SASA values from the numerical icosahedral-based method can be reproduced with more than 98% accuracy for both proteins and RNAs. Having been implemented on GPUs and incorporated into the software Amber, we can apply dSASA to implicit solvent molecular dynamics simulations with inclusion of this nonpolar term. The current GPU version of GB/SA simulations has been accelerated up to nearly 20-fold compared to the CPU version and it outperforms LCPO as the system size increases. The performance and importance of the nonpolar part in implicit solvent modeling are demonstrated in GB/SA simulations of proteins and accurate SASA calculation of nucleic acids.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10462"
    },
    {
        "doc_id": 464,
        "title": "Ecosystem models cannot predict the consequences of conservation decisions",
        "authors": [
            "Larissa Lubiana Botelho",
            "Cailan Jeynes-Smith",
            "Sarah Vollert",
            "Michael Bode"
        ],
        "subjects": [
            "Populations and Evolution",
            "Quantitative Methods"
        ],
        "abstract": "Ecosystem models are often used to predict the consequences of management decisions in applied ecology, including fisheries management and threatened species conservation. These models are high-dimensional, parameter-rich, and nonlinear, yet limited data is available to calibrate them, and they are rarely tested or validated. Consequently, the accuracy of their forecasts, and their utility as decision-support tools is a matter of debate. In this paper, we calibrate ecosystem models to time-series data from 110 different experimental microcosm ecosystems, each containing between three and five interacting species. We then assess how often these calibrated models offer accurate and useful predictions about how the ecosystem will respond to a set of standard management interventions. Our results show that for each timeseries dataset, a large number of very different parameter sets offer equivalent, good fits. However, these calibrated ecosystem models have poor predictive accuracy when forecasting future dynamics and offer ambiguous predictions about how species in the ecosystem will respond to management interventions. Closer inspection reveals that the ecosystem models fail because calibration cannot determine the types of interactions that occur within the ecosystem. Our findings call into question claims that ecosystem modelling can support applied ecological decision-making when they are calibrated against real-world datasets.",
        "comments": "23 pages (main text + supplementary material) 9 figures (main text + supplementary material)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10439"
    },
    {
        "doc_id": 465,
        "title": "Diffusion of intrinsically disordered proteins within viscoelastic membraneless droplets",
        "authors": [
            "Fuga Watanabe",
            "Takuma Akimoto",
            "Robert B. Best",
            "Kresten Lindorff-Larsen",
            "Ralf Metzler",
            "Eiji Yamamoto"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Biological Physics",
            "Computational Physics",
            "Biomolecules"
        ],
        "abstract": "In living cells, intrinsically disordered proteins (IDPs), such as FUS and DDX4, undergo phase separation, forming biomolecular condensates. Using molecular dynamics simulations, we investigate their behavior in their respective homogenous droplets. We find that the proteins exhibit transient subdiffusion due to the viscoelastic nature and confinement effects in the droplets. The conformation and the instantaneous diffusivity of the proteins significantly vary between the interior and the interface of the droplet, resulting in non-Gaussianity in the displacement distributions. This study highlights key aspects of IDP behavior in biomolecular condensates.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10438"
    },
    {
        "doc_id": 466,
        "title": "Exploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies",
        "authors": [
            "Gang Qu",
            "Anton Orlichenko",
            "Junqi Wang",
            "Gemeng Zhang",
            "Li Xiao",
            "Aiying Zhang",
            "Zhengming Ding",
            "Yu-Ping Wang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined graph structure to depict associations between brain regions, a detail not solely provided by FCs. To bridge this gap, we introduce the Gated Graph Transformer (GGT) framework, designed to predict cognitive metrics based on FCs. Empirical validation on the Philadelphia Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of our model, further accentuating its potential in identifying pivotal neural connectivities that correlate with human cognitive processes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10348"
    },
    {
        "doc_id": 467,
        "title": "DrugAssist: A Large Language Model for Molecule Optimization",
        "authors": [
            "Geyan Ye",
            "Xibao Cai",
            "Houtim Lai",
            "Xing Wang",
            "Junhong Huang",
            "Longyue Wang",
            "Wei Liu",
            "Xiangxiang Zeng"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called MolOpt-Instructions for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.",
        "comments": "Geyan Ye and Xibao Cai are equal contributors; Longyue Wang is corresponding author",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10334"
    },
    {
        "doc_id": 468,
        "title": "Fine scale depth regulation of invertebrate larvae around coastal fronts",
        "authors": [
            "Nicolas Weidberg",
            "Wayne Goschen",
            "Jennifer M. Jackson",
            "Paula Pattrick",
            "Christopher D. McQuaid",
            "Francesca Porri"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Vertical migrations of zooplankters have been widely described, but their active movements through shallow, highly dynamic water columns within the inner shelf may be more complex and difficult to characterize. In this study, invertebrate larvae, currents, and hydrographic variables were sampled at different depths during and after the presence of fronts on three different cruises off the southern coast of South Africa. Internal wave dynamics were observed in the hydrographic data set but also through satellite imagery, although strong surface convergent currents were absent and thermal stratification was weak. During the first two cruises, fronts were more conspicuous and they preceded strong onshore currents at depth which developed with the rising tide. Vertical distributions of larvae changed accordingly, with higher abundances at these deep layers once the front disappeared. The third cruise was carried out during slack tides, the front was not conspicuous, deep strong onshore currents did not occur afterward and larval distributions did not change consistently through time. Overall, the vertical distributions of many larval taxa matched the vertical profiles of shoreward currents and multivariate analyses revealed that these flows structured the larval community, which was neither influenced by temperature nor chlorophyll. Thus, the ability to regulate active vertical positioning may enhance shoreward advection and determine nearshore larval distributions.",
        "comments": "Journal ref:        Limnology and Oceanography. 64 - 2, pp. 785 - 802, 2019",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10303"
    },
    {
        "doc_id": 469,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 470,
        "title": "Mechanisms of nearshore retention and offshore export of mussel larvae over the Agulhas Bank",
        "authors": [
            "Nicolas Weidberg",
            "Francesca Porri",
            "Charles von der Meden",
            "Jennifer M. Jackson",
            "Wayne Goschen",
            "Christopher McQuaid"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Ecological connectivity is critical for population dynamics but in many benthic species it is complicated by a planktonic larval phase, whose dispersal remains poorly understood. Using a plankton pump, we examine the distribution of intertidal mussel larvae along three axes: alongshore, cross-shelf and by depth during a large scale (600 km) cruise over the Agulhas Bank off southern Africa in August/September 2010. As a general pattern, higher veliger abundances were found close to the coast. Our analyses of the nearshore flow, estimated from ADCP data and the vertical distribution of larvae, show that onshore larval retention may be mediated by active vertical swimming through the water column guided by light and wind-induced turbulence. A massive offshore export of larvae off St Francis Bay was, however, observed during an Agulhas Current meander which influenced inner shelf waters. We hypothesize that, by increasing and homogenizing flow, the Agulhas Current may erase the effects of larval vertical positioning on onshore retention and transport larvae offshore. Our study highlights the need to integrate the effects of complex, region-specific physical dynamics with the swimming behaviour of larvae in order to explain their spatial distribution, population connectivity and the consequences for population dynamics.",
        "comments": "Journal ref:        Journal of Plankton Research. 37 - 6, pp. 1166 - 1180. Oxford Journals, 11/2015",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10292"
    },
    {
        "doc_id": 471,
        "title": "Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning",
        "authors": [
            "Ryan Cho",
            "Mobasshira Zaman",
            "Kyu Taek Cho",
            "Jaejin Hwang"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Neurons and Cognition"
        ],
        "abstract": "This study aimed to analyze brain activity during various STEM activities, exploring the feasibility of classifying between different tasks. EEG brain data from twenty subjects engaged in five cognitive tasks were collected and segmented into 4-second clips. Power spectral densities of brain frequency waves were then analyzed. Testing different k-intervals with XGBoost, Random Forest, and Bagging Classifier revealed that Random Forest performed best, achieving a testing accuracy of 91.07% at an interval size of two. When utilizing all four EEG channels, cognitive flexibility was most recognizable. Task-specific classification accuracy showed the right frontal lobe excelled in mathematical processing and planning, the left frontal lobe in cognitive flexibility and mental flexibility, and the left temporoparietal lobe in connections. Notably, numerous connections between frontal and temporoparietal lobes were observed during STEM activities. This study contributes to a deeper understanding of implementing machine learning in analyzing brain activity and sheds light on the brain's mechanisms.",
        "comments": "20 pages, 7 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10285"
    },
    {
        "doc_id": 472,
        "title": "EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model",
        "authors": [
            "Yuqi Chen",
            "Kan Ren",
            "Kaitao Song",
            "Yansen Wang",
            "Yifan Wang",
            "Dongsheng Li",
            "Lili Qiu"
        ],
        "subjects": [
            "Signal Processing",
            "Artificial Intelligence",
            "Machine Learning",
            "Multimedia",
            "Neurons and Cognition"
        ],
        "abstract": "Self-supervised learning has emerged as a highly effective approach in the fields of natural language processing and computer vision. It is also applicable to brain signals such as electroencephalography (EEG) data, given the abundance of available unlabeled data that exist in a wide spectrum of real-world medical applications ranging from seizure detection to wave analysis. The existing works leveraging self-supervised learning on EEG modeling mainly focus on pretraining upon each individual dataset corresponding to a single downstream task, which cannot leverage the power of abundant data, and they may derive sub-optimal solutions with a lack of generalization. Moreover, these methods rely on end-to-end model learning which is not easy for humans to understand. In this paper, we present a novel EEG foundation model, namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained model cannot only learn universal representations on EEG signals with adaptable performance on various downstream tasks but also provide interpretable outcomes of the useful patterns within the data. To validate the effectiveness of our model, we extensively evaluate it on various downstream tasks and assess the performance under different transfer settings. Furthermore, we demonstrate how the learned model exhibits transferable anomaly detection performance and provides valuable interpretability of the acquired patterns via self-supervised learning.",
        "comments": "A preprint version of an ongoing work",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10278"
    },
    {
        "doc_id": 473,
        "title": "Evolving Diploid Boolean and Multi-Valued Gene Networks",
        "authors": [
            "Larry Bull"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Boolean networks have been widely used to explore aspects of gene regulation, traditionally with a single network. A modified form of the model to explore the effects of increasing the number of gene states has also recently been introduced. In this paper, these discrete dynamical networks are evolved as diploids within rugged fitness landscapes to explore their behaviour. Results suggest the general properties of haploid networks in similar circumstances remain for diploids. The previously proposed inherent fitness landscape smoothing properties of eukaryotic sex are shown to be exhibited in these dynamical systems, as is their propensity to change in size based upon the characteristics of the network and fitness landscape.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.01694",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10237"
    },
    {
        "doc_id": 474,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 475,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 476,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 477,
        "title": "Correlating fluorescence microscopy, optical and magnetic tweezers to study single chiral biopolymers, tested on DNA plectoneme formation dynamics",
        "authors": [
            "Jack W Shepherd",
            "Sebastien Guilbaud",
            "Zhaokun Zhou",
            "Jamieson Howard",
            "Matthew Burman",
            "Charley Schaefer",
            "Adam Kerrigan",
            "Clare Steele-King",
            "Agnes Noy",
            "Mark C Leake"
        ],
        "subjects": [
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Biopolymer topology is critical for determining interactions inside cell environments, exemplified by DNA where its response to mechanical perturbation is as important as biochemical properties to its cellular roles. The dynamic structures of chiral biopolymers exhibit complex dependence with extension and torsion, however the physical mechanisms underpinning the emergence of structural motifs upon physiological twisting and stretching are poorly understood due to technological limitations in correlating force, torque and spatial localization information. We present COMBI-Tweez (Combined Optical and Magnetic BIomolecule TWEEZers), a transformative tool that overcomes these challenges by integrating optical trapping, time-resolved electromagnetic tweezers, and fluorescence microscopy, demonstrated on single DNA molecules, that can controllably form and visualise higher order structural motifs including plectonemes. This technology combined with cutting-edge MD simulations provides quantitative insight into complex dynamic structures relevant to DNA cellular processes and can be adapted to study a range of filamentous biopolymers.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10087"
    },
    {
        "doc_id": 478,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 479,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 480,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 481,
        "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
        "authors": [
            "Zofia Rudnicka",
            "Janusz Szczepanski",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in the medical image scan segmentation, and intelligent visual-content generation, i.e. computer-generated three-dimensional (3D) images in the context of Extended Reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes also with possible developments and open challenges in AI application in Extended Reality-based solutions. Finally, the future lines of research and development directions of Artificial Intelligence applications both in medical image segmentation and Extended Reality-based medical solutions are discussed",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09857"
    },
    {
        "doc_id": 482,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 483,
        "title": "The impact of Covid-19 vaccination in Aotearoa New Zealand: a modelling study",
        "authors": [
            "Samik Datta",
            "Giorgia Vattiato",
            "Oliver J Maclaren",
            "Ning Hua",
            "Andrew Sporle",
            "Michael J Plank"
        ],
        "subjects": [
            "Populations and Evolution",
            "Physics and Society"
        ],
        "abstract": "Aotearoa New Zealand implemented a Covid-19 elimination strategy in 2020 and 2021, which enabled a large majority of the population to be vaccinated before being exposed to the virus. This strategy delivered one of the lowest pandemic mortality rates in the world. However, quantitative estimates of the population-level health benefits of vaccination are lacking. Here, we use a validated mathematical model to investigate counterfactual scenarios with differing levels of vaccine coverage in different age and ethnicity groups. The model builds on earlier research by adding age- and time-dependent case ascertainment, the effect of antiviral medications, improved hospitalisation rate estimates, and the impact of relaxing control measures. The model was used for scenario analysis and policy advice for the New Zealand Government in 2022 and 2023. We compare the number of Covid-19 hospitalisations, deaths, and years of life lost in each counterfactual scenario to a baseline scenario that is fitted to epidemiological data between January 2022 and June 2023. Our results estimate that vaccines saved 6650 (95% credible interval [4424, 10180]) lives, and prevented 74500 [51000, 115400] years of life lost and 45100 [34400, 55600] hospitalisations during this 18-month period. Making the same comparison before the benefit of antiviral medications is accounted for, the estimated number of lives saved by vaccines increases to 7604 [5080, 11942]. Due to inequities in the vaccine rollout, vaccination rates among M\u0101ori were lower than in people of European ethnicity. Our results show that, if vaccination rates had been equitable, an estimated 11-26% of the 292 M\u0101ori Covid-19 deaths that were recorded in this time period could have been prevented. We conclude that Covid-19 vaccination greatly reduced health burden in New Zealand and that equity needs to be a key focus of future vaccination programmes.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09679"
    },
    {
        "doc_id": 484,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 485,
        "title": "Molecular causality in the advent of foundation models",
        "authors": [
            "Sebastian Lobentanzer",
            "Pablo Rodriguez-Mier",
            "Stefan Bauer",
            "Julio Saez-Rodriguez"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Correlation is not causation. As simple as this widely agreed-upon statement may seem, scientifically defining causality and using it to drive our modern biomedical research is immensely challenging. In this perspective, we attempt to synergise the partly disparate fields of systems biology, causal reasoning, and machine learning, to inform future approaches in the field of systems biology and molecular networks.",
        "comments": "22 pages, 0 figures, 87 references; submitted to MSB",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09558"
    },
    {
        "doc_id": 486,
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "Junhao Wen",
            "Mathilde Antoniades",
            "Zhijian Yang",
            "Gyujoon Hwang",
            "Ioanna Skampardoni",
            "Rongguang Wang",
            "Christos Davatzikos"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing",
            "Quantitative Methods"
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09517"
    },
    {
        "doc_id": 487,
        "title": "Is the Emergence of Life an Expected Phase Transition in the Evolving Universe?",
        "authors": [
            "Stuart Kauffman",
            "Andrea Roli"
        ],
        "subjects": [
            "Populations and Evolution",
            "Biological Physics"
        ],
        "abstract": "We propose a novel definition of life in terms of which its emergence in the universe is expected, and its ever-creative open-ended evolution is entailed by no law. Living organisms are Kantian Wholes that achieve Catalytic Closure, Constraint Closure, and Spatial Closure. We here unite for the first time two established mathematical theories, namely Collectively Autocatalytic Sets and the Theory of the Adjacent Possible. The former establishes that a first-order phase transition to molecular reproduction is expected in the chemical evolution of the universe where the diversity and complexity of molecules increases; the latter posits that, under loose hypotheses, if the system starts with a small number of beginning molecules, each of which can combine with copies of itself or other molecules to make new molecules, over time the number of kinds of molecules increases slowly but then explodes upward hyperbolically. Together these theories imply that life is expected as a phase transition in the evolving universe. The familiar distinction between software and hardware loses its meaning in living cells. We propose new ways to study the phylogeny of metabolisms, new astronomical ways to search for life on exoplanets, new experiments to seek the emergence of the most rudimentary life, and the hint of a coherent testable pathway to prokaryotes with template replication and coding.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09514"
    },
    {
        "doc_id": 488,
        "title": "Role of Upwelling on Larval Dispersal and Productivity of Gooseneck Barnacle Populations in the Cantabrian Sea: Management Implications",
        "authors": [
            "Antonella Rivera",
            "Nicolas Weidberg",
            "Antonio F. Pardi\u00f1as",
            "Ricardo Gonzalez-Gil",
            "Luc\u0131a Garc\u0131a- Florez",
            "Jose Luis Acu\u00f1a"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "The effect of coastal upwelling on the recruitment and connectivity of coastal marine populations has rarely been characterized to a level of detail to be included into sound fishery management strategies. The gooseneck barnacle (Pollicipes pollicipes) fishery at the Cantabrian Coast (Northern Spain) is located at the fringes of the NW Spanish Upwelling system. This fishery is being co-managed through a fine-scale, interspersed set of protected rocks where each rock receives a distinct level of protection. Such interspersion is potentially beneficial, but the extent to which such spacing is consistent with mean larval dispersal distances is as yet unknown. We have simulated the spread of gooseneck barnacle larvae in the Central Cantabrian Coast using a high-resolution time-series of current profiles measured at a nearshore location. During a year of high upwelling activity (2009), theoretical recruitment success was 94% with peak recruitment predicted 56 km west of the emission point. However, for a year of low upwelling activity (2011) theoretical recruitment success dropped to 15.4% and peak recruitment was expected 13 km east of the emission point. This is consistent with a positive correlation between catch rates and the Integrated Upwelling Index, using a 4-year lag to allow recruits to reach commercial size. Furthermore, a net long-term westward larval transport was estimated by means of mitochondrial cytochrome c oxidase subunit I (COI) sequences for five populations in the Cantabrian Sea. Our results call into question the role of long distance dispersal, driven by the mesoscale processes in the area, in gooseneck barnacle populations and point to the prevalent role of small-scale, asymmetric connectivity more consistent with the typical scale of the co-management process in this fishery.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09513"
    },
    {
        "doc_id": 489,
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Haotian Lu",
            "Yexin Wu",
            "Zexin Yuan",
            "Shengdian Jiang",
            "Jiaxiang Wu",
            "Yimin Wang",
            "Junchi Yan"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09500"
    },
    {
        "doc_id": 490,
        "title": "Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "Jiayu Chang",
            "Shiyu Wang",
            "Chen Ling",
            "Zhaohui Qin",
            "Liang Zhao"
        ],
        "subjects": [
            "Quantitative Methods",
            "Information Retrieval"
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations.",
        "comments": "This is the official paper accepted by AAAI 2024 Workshop on Large Language Models for Biological Discoveries",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09490"
    },
    {
        "doc_id": 491,
        "title": "The Interplay Between Logical Phenomena and the Cognitive System of the Mind",
        "authors": [
            "Kazem Haghnejad Azar"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In this article, we employ mathematical concepts as a tool to examine the phenomenon of consciousness experience and logical phenomena. Through our investigation, we aim to demonstrate that our experiences, while not confined to limitations, cannot be neatly encapsulated within a singular collection. Our conscious experience emerges as a result of the developmental and augmentative trajectory of our cognitive system. As our cognitive abilities undergo refinement and advancement, our capacity for logical thinking likewise evolves, thereby manifesting a heightened level of conscious experience. The primary objective of this article is to embark upon a profound exploration of the concept of logical experience, delving into the intricate process by which these experiences are derived from our mind.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09465"
    },
    {
        "doc_id": 492,
        "title": "Diffusion-Driven Generative Framework for Molecular Conformation Prediction",
        "authors": [
            "Bobin Yang",
            "Jie Deng",
            "Zhenghan Chen",
            "Ruoxue Wu"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "The task of deducing three-dimensional molecular configurations from their two-dimensional graph representations holds paramount importance in the fields of computational chemistry and pharmaceutical development. The rapid advancement of machine learning, particularly within the domain of deep generative networks, has revolutionized the precision of predictive modeling in this context. Traditional approaches often adopt a two-step strategy: initially estimating interatomic distances and subsequently refining the spatial molecular structure by solving a distance geometry problem. However, this sequential approach occasionally falls short in accurately capturing the intricacies of local atomic arrangements, thereby compromising the fidelity of the resulting structural models. Addressing these limitations, this research introduces a cutting-edge generative framework named \\method{}. This framework is grounded in the principles of diffusion observed in classical non-equilibrium thermodynamics. \\method{} views atoms as discrete entities and excels in guiding the reversal of diffusion, transforming a distribution of stochastic noise back into coherent molecular structures through a process akin to a Markov chain. This transformation commences with the initial representation of a molecular graph in an abstract latent space, culminating in the realization of three-dimensional structures via a sophisticated bilevel optimization scheme meticulously tailored to meet the specific requirements of the task. One of the formidable challenges in this modeling endeavor involves preserving roto-translational invariance to ensure that the generated molecular conformations adhere to the laws of physics. Extensive experimental evaluations confirm the efficacy of the proposed \\method{} in comparison to state-of-the-art methods.",
        "comments": "arXiv admin note: text overlap with arXiv:2105.07246 by other authors",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09451"
    },
    {
        "doc_id": 493,
        "title": "Regenerative Medicine for Tendon/Ligament Injuries: De Novo Equine Tendon/Ligament Neotissue Generation and Application",
        "authors": [
            "Takashi Taguchi"
        ],
        "subjects": [
            "Tissues and Organs"
        ],
        "abstract": "Tendon and ligament injuries are debilitating conditions across species. Poor regenerative capacities of these tissues limit restoration of original functions. The first study of this dissertation evaluated the effect of cellular administration on tendon/ligament injuries in horses using meta-analysis. The findings led to the second study that engineered implantable de novo tendon neotissue using equine adipose-derived multipotent stromal cells and collagen type I. The neotendon was evaluated for its biocompatibility and therapeutic potential in the third study using immunocompetent and immunocompromised rat bilateral calcaneal tendon elongation model. The fourth study investigated the therapeutic effects of neotendon in surgically-induced non-terminal equine accessory ligament of deep digital flexor tendon injury model.",
        "comments": " ",
        "date": "24 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09423"
    },
    {
        "doc_id": 494,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 495,
        "title": "Graph-based vulnerability assessment of resting-state functional brain networks in full-term neonates",
        "authors": [
            "Mahshid Fouladivanda",
            "Kamran Kazemi",
            "Habibollah Danyali",
            "Ardalan Aarabi"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Quantitative Methods"
        ],
        "abstract": "Network disruption during early brain development can result in long-term cognitive impairments. In this study, we investigated rich-club organization in resting-state functional brain networks in full-term neonates using a multiscale connectivity analysis. We further identified the most influential nodes, also called spreaders, having higher impacts on the flow of information throughout the network. The network vulnerability to damage to rich-club (RC) connectivity within and between resting-state networks was also assessed using a graph-based vulnerability analysis. Our results revealed a rich club organization and small-world topology for resting-state functional brain networks in full term neonates, regardless of the network size. Interconnected mostly through short-range connections, functional rich-club hubs were confined to sensory-motor, cognitive-attention-salience (CAS), default mode, and language-auditory networks with an average cross-scale overlap of 36%, 20%, 15% and 12%, respectively. The majority of the functional hubs also showed high spreading potential, except for several non-RC spreaders within CAS and temporal networks. The functional networks exhibited high vulnerability to loss of RC nodes within sensorimotor cortices, resulting in a significant increase and decrease in network segregation and integration, respectively. The network vulnerability to damage to RC nodes within the language-auditory, cognitive-attention-salience, and default mode networks was also significant but relatively less prominent. Our findings suggest that the network integration in neonates can be highly compromised by damage to RC connectivity due to brain immaturity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09255"
    },
    {
        "doc_id": 496,
        "title": "Reproducibility via neural fields of visual illusions induced by localized stimuli",
        "authors": [
            "Cyprien Tamekue",
            "Dario Prandi",
            "Yacine Chitour"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Pattern Formation and Solitons"
        ],
        "abstract": "This paper investigates the replication of experiments by Billock and Tsou [PNAS, 2007] using the controllability of neural fields of Amari-type modelling the cortical activity in the primary visual cortex (V1), focusing on a regular funnel pattern localised in the fovea or the peripheral visual field. The aim is to understand and model the visual phenomena observed in these experiments, emphasising their nonlinear nature. The study involves designing sensory inputs simulating the visual stimuli from Billock and Tsou's experiments. The after-images induced by these inputs are then theoretically and numerically studied to determine their capacity to replicate the experimentally observed visual effects. A key aspect of this research is investigating the effects induced by the nonlinear nature of neural responses. In particular, by highlighting the importance of both excitatory and inhibitory neurons in the emergence of certain visual phenomena, this study suggests that an interplay of both types of neuronal activities plays an essential role in visual processes, challenging the assumption that the latter is mainly driven by excitatory activities alone.",
        "comments": "MSC Class:          92C20; 35B36; 45A05; 45G15; 45K05; 65R20",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09108"
    },
    {
        "doc_id": 497,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 498,
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "authors": [
            "Ziyang Yu",
            "Wenbing Huang",
            "Yang Liu"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08986"
    },
    {
        "doc_id": 499,
        "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
        "authors": [
            "Zahra Sheikhbahaee",
            "Adam Safron",
            "Casper Hesp",
            "Guillaume Dumas"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08873"
    }
]