[
    {
        "doc_id": 0,
        "title": "Clustering-based spatial interpolation of parametric post-processing models",
        "authors": [
            "S\u00e1ndor Baran",
            "M\u00e1ria Lakatos"
        ],
        "subjects": [
            "Applications",
            "Methodology"
        ],
        "abstract": "Since the start of the operational use of ensemble prediction systems, ensemble-based probabilistic forecasting has become the most advanced approach in weather prediction. However, despite the persistent development of the last three decades, ensemble forecasts still often suffer from the lack of calibration and might exhibit systematic bias, which calls for some form of statistical post-processing. Nowadays, one can choose from a large variety of post-processing approaches, where parametric methods provide full predictive distributions of the investigated weather quantity. Parameter estimation in these models is based on training data consisting of past forecast-observation pairs, thus post-processed forecasts are usually available only at those locations where training data are accessible. We propose a general clustering-based interpolation technique of extending calibrated predictive distributions from observation stations to any location in the ensemble domain where there are ensemble forecasts at hand. Focusing on the ensemble model output statistics (EMOS) post-processing technique, in a case study based on wind speed ensemble forecasts of the European Centre for Medium-Range Weather Forecasts, we demonstrate the predictive performance of various versions of the suggested method and show its superiority over the regionally estimated and interpolated EMOS models and the raw ensemble forecasts as well.",
        "comments": "19 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14393"
    },
    {
        "doc_id": 1,
        "title": "Single-file dynamics with general charge measures",
        "authors": [
            "\u017diga Krajnik"
        ],
        "subjects": [
            "Statistical Mechanics"
        ],
        "abstract": "We study charge fluctuations in single-file dynamics with general charge measures. The exact finite-time distribution of charge fluctuations is obtained in terms of a dressing transformation acting on the finite-time distribution of particle fluctuations. The transformation is mapped to a simple substitution rule for corresponding full-counting statistics. By taking the asymptotics of the dressing transformation we analyze typical and large scale charge fluctuations. Typical charge fluctuations in equilibrium states with vanishing mean charge are anomalous while large charge fluctuations undergo first and second order dynamical phase transitions out of equilibrium.",
        "comments": "18+9 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14378"
    },
    {
        "doc_id": 2,
        "title": "Modeling Global Surface Dust Deposition Using Physics-Informed Neural Networks",
        "authors": [
            "Constanza A. Molina Catricheo",
            "Fabrice Lambert",
            "Julien Salomon",
            "Elwin van 't Wout"
        ],
        "subjects": [
            "Geophysics"
        ],
        "abstract": "Paleoclimatic measurements serve to understand geophysical processes and evaluate climate model performances. However, their spatial coverage is generally sparse and unevenly distributed across the globe. Statistical interpolation methods are the prevalent techniques to grid such data, but these purely data-driven approaches sometimes produce results that are incoherent with our knowledge of the physical world. Physics-Informed Neural Networks (PINNs) follow an innovative approach to data analysis and physical modeling through machine learning, as they incorporate physical principles into the data-driven learning process. Here, we develop PINNs to reconstruct global maps of atmospheric dust surface deposition fluxes from measurement data in paleoclimatic archives, for the Holocene and Last Glacial Maximum periods. We design an advection-diffusion equation to consider dominant wind directions at various latitudes, which prevents dust particles from flowing upwind. Our PINN improves on standard kriging interpolation by allowing variable asymmetry around data points. The reconstructions display realistic dust plumes from continental sources towards ocean basins following prevailing winds.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14372"
    },
    {
        "doc_id": 3,
        "title": "Minimum Covariance Determinant: Spectral Embedding and Subset Size Determination",
        "authors": [
            "Qiang Heng",
            "Kenneth Lange"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "This paper introduces several ideas to the minimum covariance determinant problem for outlier detection and robust estimation of means and covariances. We leverage the principal component transform to achieve dimension reduction, paving the way for improved analyses. Our best subset selection algorithm strategically combines statistical depth and concentration steps. To ascertain the appropriate subset size and number of principal components, we introduce a novel bootstrap procedure that estimates the instability of the best subset algorithm. The parameter combination exhibiting minimal instability proves ideal for the purposes of outlier detection and robust estimation. Rigorous benchmarking against prominent MCD variants showcases our approach's superior capability in outlier detection and computational speed in high dimensions. Application to a fruit spectra data set and a cancer genomics data set illustrates our claims.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14359"
    },
    {
        "doc_id": 4,
        "title": "Multiply Robust Estimation of Causal Effect Curves for Difference-in-Differences Designs",
        "authors": [
            "Gary Hettinger",
            "Youjin Lee",
            "Nandita Mitra"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Researchers commonly use difference-in-differences (DiD) designs to evaluate public policy interventions. While established methodologies exist for estimating effects in the context of binary interventions, policies often result in varied exposures across regions implementing the policy. Yet, existing approaches for incorporating continuous exposures face substantial limitations in addressing confounding variables associated with intervention status, exposure levels, and outcome trends. These limitations significantly constrain policymakers' ability to fully comprehend policy impacts and design future interventions. In this study, we propose innovative estimators for causal effect curves within the DiD framework, accounting for multiple sources of confounding. Our approach accommodates misspecification of a subset of treatment, exposure, and outcome models while avoiding any parametric assumptions on the effect curve. We present the statistical properties of the proposed methods and illustrate their application through simulations and a study investigating the diverse effects of a nutritional excise tax.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14355"
    },
    {
        "doc_id": 5,
        "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
        "authors": [
            "Thomas F. Varley",
            "Joshua Bongard"
        ],
        "subjects": [
            "Information Theory",
            "Dynamical Systems",
            "Chaotic Dynamics",
            "Cellular Automata and Lattice Gases"
        ],
        "abstract": "There has recently been an explosion of interest in how \"higher-order\" structures emerge in complex systems. This \"emergent\" organization has been found in a variety of natural and artificial systems, although at present the field lacks a unified understanding of what the consequences of higher-order synergies and redundancies are for systems. Typical research treat the presence (or absence) of synergistic information as a dependent variable and report changes in the level of synergy in response to some change in the system. Here, we attempt to flip the script: rather than treating higher-order information as a dependent variable, we use evolutionary optimization to evolve boolean networks with significant higher-order redundancies, synergies, or statistical complexity. We then analyse these evolved populations of networks using established tools for characterizing discrete dynamics: the number of attractors, average transient length, and Derrida coefficient. We also assess the capacity of the systems to integrate information. We find that high-synergy systems are unstable and chaotic, but with a high capacity to integrate information. In contrast, evolved redundant systems are extremely stable, but have negligible capacity to integrate information. Finally, the complex systems that balance integration and segregation (known as Tononi-Sporns-Edelman complexity) show features of both chaosticity and stability, with a greater capacity to integrate information than the redundant systems while being more stable than the random and synergistic systems. We conclude that there may be a fundamental trade-off between the robustness of a systems dynamics and its capacity to integrate information (which inherently requires flexibility and sensitivity), and that certain kinds of complexity naturally balance this trade-off.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14347"
    },
    {
        "doc_id": 6,
        "title": "Uncovering Heterogeneity of Solar Flare Mechanism With Mixture Models",
        "authors": [
            "Bach Viet Do",
            "Yang Chen",
            "XuanLong Nguyen",
            "Ward Manchester"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Applications",
            "Methodology"
        ],
        "abstract": "The physics of solar flares occurring on the Sun is highly complex and far from fully understood. However, observations show that solar eruptions are associated with the intense kilogauss fields of active regions, where free energies are stored with field-aligned electric currents. With the advent of high-quality data sources such as the Geostationary Operational Environmental Satellites (GOES) and Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI), recent works on solar flare forecasting have been focusing on data-driven methods. In particular, black box machine learning and deep learning models are increasingly adopted in which underlying data structures are not modeled explicitly. If the active regions indeed follow the same laws of physics, there should be similar patterns shared among them, reflected by the observations. Yet, these black box models currently used in the literature do not explicitly characterize the heterogeneous nature of the solar flare data, within and between active regions. In this paper, we propose two finite mixture models designed to capture the heterogeneous patterns of active regions and their associated solar flare events. With extensive numerical studies, we demonstrate the usefulness of our proposed method for both resolving the sample imbalance issue and modeling the heterogeneity for rare energetic solar flare events.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14345"
    },
    {
        "doc_id": 7,
        "title": "Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective",
        "authors": [
            "Xuechen Zhang",
            "Mingchen Li",
            "Jiasi Chen",
            "Christos Thrampoulidis",
            "Samet Oymak"
        ],
        "subjects": [
            "Machine Learning",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CAP is competitive with prior art and its flexibility unlocks clear benefits for fairness objectives beyond balanced accuracy. Finally, we evaluate CAP on problems with label noise as well as weighted test objectives to showcase how CAP can jointly adapt to different heterogeneities.",
        "comments": "15 pages, 8 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14343"
    },
    {
        "doc_id": 8,
        "title": "Estimation of partially known Gaussian graphical models with score-based structural priors",
        "authors": [
            "Mart\u00edn Sevilla",
            "Antonio Garc\u00eda Marques",
            "Santiago Segarra"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.",
        "comments": "15 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14340"
    },
    {
        "doc_id": 9,
        "title": "Case-crossover designs and overdispersion with application in air pollution epidemiology",
        "authors": [
            "Samuel Perreault",
            "Gracia Y. Dong",
            "Alex Stringer",
            "Hwashin Shin",
            "Patrick Brown"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Over the last three decades, case-crossover designs have found many applications in health sciences, especially in air pollution epidemiology. They are typically used, in combination with partial likelihood techniques, to define a conditional logistic model for the responses, usually health outcomes, conditional on the exposures. Despite the fact that conditional logistic models have been shown equivalent, in typical air pollution epidemiology setups, to specific instances of the well-known Poisson time series model, it is often claimed that they cannot allow for overdispersion. This paper clarifies the relationship between case-crossover designs, the models that ensue from their use, and overdispersion. In particular, we propose to relax the assumption of independence between individuals traditionally made in case-crossover analyses, in order to explicitly introduce overdispersion in the conditional logistic model. As we show, the resulting overdispersed conditional logistic model coincides with the overdispersed, conditional Poisson model, in the sense that their likelihoods are simple re-expressions of one another. We further provide the technical details of a Bayesian implementation of the proposed case-crossover model, which we use to demonstrate, by means of a large simulation study, that standard case-crossover models can lead to dramatically underestimated coverage probabilities, while the proposed models do not. We also perform an illustrative analysis of the association between air pollution and morbidity in Toronto, Canada, which shows that the proposed models are more robust than standard ones to outliers such as those associated with public holidays.",
        "comments": "MSC Class:          62J12; 62F15; 62P10                          ACM Class:          G.3",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14338"
    },
    {
        "doc_id": 10,
        "title": "Common Randomness Generation from Finite Compound Sources",
        "authors": [
            "Rami Ezzine",
            "Moritz Wiese",
            "Christian Deppe",
            "Holger Boche"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "We investigate the problem of generating common randomness (CR) from finite compound sources aided by unidirectional communication over rate-limited perfect channels. The two communicating parties, often referred to as terminals, observe independent and identically distributed (i.i.d.) samples of a finite compound source and aim to agree on a common random variable with a high probability for every possible realization of the source state. Both parties know the set of source states as well as their statistics. However, they are unaware of the actual realization of the source state. We establish a single-letter lower and upper bound on the compound CR capacity for the specified model. Furthermore, we present two special scenarios where the established bounds coincide.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.05524",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14323"
    },
    {
        "doc_id": 11,
        "title": "Using Geographically Weighted Models to Explore Temporal and Spatial Varying Impacts on Commute Trip Change Due to Covid-19",
        "authors": [
            "Saeed Saleh Namadi",
            "Behnam Tahmasbi",
            "Asal Mehditabrizi",
            "Aref Darzi",
            "Deb Niemeier"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "COVID-19 has deeply affected daily life and travel behaviors. Understanding these changes is crucial, prompting an investigation into socio-demographic and socio-economic factors. This study used large-scale mobile device location data in Washington, D.C., Maryland, and Virginia (DMV area) to unveil the impacts of these variables on commute trip changes. It reflected short and long-term impacts through linear regression and geographically weighted regression models. Findings indicated that counties with a higher percentage of people using walking and biking during the initial phase of COVID-19 experienced greater reductions in commute trips. For the long-term effect in November, the impact of active modes became insignificant, and individuals using public modes showed more significant trip reductions. Positive correlations were observed between median income levels and reduced commute trips. Sectors requiring ongoing outdoor operations during the pandemic showed substantial negative correlations. In the DMV area, counties with a higher proportion of Democratic voters experienced less trip reduction. Applying Geographically Weighted Regression models captured local spatial relationships, showing the emergence of local correlations as the pandemic evolved, suggesting a geographical impact pattern. Initially global, the pandemic's impact on commuting behaviors became more influenced by spatial factors over time, showing localized effects.",
        "comments": "28 pages, 8 figures, accepted at TRR 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14306"
    },
    {
        "doc_id": 12,
        "title": "The overlooked significance of the unbiased exponential phasefactor in the determination of the finite-density lattice QCD equation of state",
        "authors": [
            "Sabarnya Mitra"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology",
            "Nuclear Experiment",
            "Nuclear Theory"
        ],
        "abstract": "Within the framework of (2+1)-flavor QCD at finite temperature and chemical potential, we present results using high statistics data and demonstrate how the phasefactor of low order unbiased exponential resummation offers excellent prediction, proving to be an alternative reliable estimator of the radius of convergence of the eighth order QCD Taylor series at finite baryon density measured using the ratio and the Merci-Roberts estimators. We construct a new non-trivial unbiased phasefactor for complex isospin chemical potentials $\\muI$ and highlight its novelty. We find that this new unbiased phasefactor is very much capable of indicating the onset of non-monotonicity in finite $\\muI$ thermodynamics, which we illustrate by comparing the phasefactor results with that of low order cumulants of $\\muI$ fluctuations for non-vanishing $\\muI$. We also furnish results establishing that this unbiased phasefactor is reliable in manifesting the beginning of the overlap problem for finite, real $\\muI$. The errorbars increase drastically across the indications provided by the phasefactor which becomes very apparent from the coincidence between the phasefactor and the maximum of the errorbar slopes.",
        "comments": "9 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14299"
    },
    {
        "doc_id": 13,
        "title": "\"All of Me\": Mining Users' Attributes from their Public Spotify Playlists",
        "authors": [
            "Pier Paolo Tricomi",
            "Luca Pajola",
            "Luca Pasa",
            "Mauro Conti"
        ],
        "subjects": [
            "Cryptography and Security",
            "Machine Learning",
            "Social and Information Networks"
        ],
        "abstract": "In the age of digital music streaming, playlists on platforms like Spotify have become an integral part of individuals' musical experiences. People create and publicly share their own playlists to express their musical tastes, promote the discovery of their favorite artists, and foster social connections. These publicly accessible playlists transcend the boundaries of mere musical preferences: they serve as sources of rich insights into users' attributes and identities. For example, the musical preferences of elderly individuals may lean more towards Frank Sinatra, while Billie Eilish remains a favored choice among teenagers. These playlists thus become windows into the diverse and evolving facets of one's musical identity.\n  In this work, we investigate the relationship between Spotify users' attributes and their public playlists. In particular, we focus on identifying recurring musical characteristics associated with users' individual attributes, such as demographics, habits, or personality traits. To this end, we conducted an online survey involving 739 Spotify users, yielding a dataset of 10,286 publicly shared playlists encompassing over 200,000 unique songs and 55,000 artists. Through extensive statistical analyses, we first assess a deep connection between a user's Spotify playlists and their real-life attributes. For instance, we found individuals high in openness often create playlists featuring a diverse array of artists, while female users prefer Pop and K-pop music genres. Building upon these observed associations, we create accurate predictive models for users' attributes, presenting a novel DeepSet application that outperforms baselines in most of these users' attributes.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14296"
    },
    {
        "doc_id": 14,
        "title": "Heteroscedasticity-aware stratified sampling to improve uplift modeling",
        "authors": [
            "Bj\u00f6rn Bokelmann",
            "Stefan Lessmann"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In many business applications, including online marketing and customer churn prevention, randomized controlled trials (RCT's) are conducted to investigate on the effect of specific treatment (coupon offers, advertisement mailings,...). Such RCT's allow for the estimation of average treatment effects as well as the training of (uplift) models for the heterogeneity of treatment effects between individuals. The problem with these RCT's is that they are costly and this cost increases with the number of individuals included into the RCT. For this reason, there is research how to conduct experiments involving a small number of individuals while still obtaining precise treatment effect estimates. We contribute to this literature a heteroskedasticity-aware stratified sampling (HS) scheme, which leverages the fact that different individuals have different noise levels in their outcome and precise treatment effect estimation requires more observations from the \"high-noise\" individuals than from the \"low-noise\" individuals. By theory as well as by empirical experiments, we demonstrate that our HS-sampling yields significantly more precise estimates of the ATE, improves uplift models and makes their evaluation more reliable compared to RCT data sampled completely randomly. Due to the relative ease of application and the significant benefits, we expect HS-sampling to be valuable in many real-world applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14294"
    },
    {
        "doc_id": 15,
        "title": "Speech foundation models on intelligibility prediction for hearing-impaired listeners",
        "authors": [
            "Santiago Cuervo",
            "Ricard Marxer"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech foundation models (SFMs) have been benchmarked on many speech processing tasks, often achieving state-of-the-art performance with minimal adaptation. However, the SFM paradigm has been significantly less explored for applications of interest to the speech perception community. In this paper we present a systematic evaluation of 10 SFMs on one such application: Speech intelligibility prediction. We focus on the non-intrusive setup of the Clarity Prediction Challenge 2 (CPC2), where the task is to predict the percentage of words correctly perceived by hearing-impaired listeners from speech-in-noise recordings. We propose a simple method that learns a lightweight specialized prediction head on top of frozen SFMs to approach the problem. Our results reveal statistically significant differences in performance across SFMs. Our method resulted in the winning submission in the CPC2, demonstrating its promise for speech perception applications.",
        "comments": "To be presented in ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14289"
    },
    {
        "doc_id": 16,
        "title": "Information Leakage Detection through Approximate Bayes-optimal Prediction",
        "authors": [
            "Pritha Gupta",
            "Marcel Wever",
            "Eyke H\u00fcllermeier"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predictor. As the Bayes predictor is typically unknown in practice, we propose to approximate it with the help of automated machine learning (AutoML). First, we compare our MI estimation approaches against current baselines, using synthetic data sets generated using the multivariate normal (MVN) distribution with known MI. Second, we introduce a cut-off technique using one-sided statistical tests to detect IL, employing the Holm-Bonferroni correction to increase confidence in detection decisions. Our study evaluates IL detection performance on real-world data sets, highlighting the effectiveness of the Bayes predictor's log-loss estimation, and finds our proposed method to effectively estimate MI on synthetic data sets and thus detect ILs accurately.",
        "comments": "Under submission in JMLR",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14283"
    },
    {
        "doc_id": 17,
        "title": "How far can we see back in time in high-energy collisions using charm quarks?",
        "authors": [
            "Laszlo Gyulai",
            "Gabor Biro",
            "Robert Vertesi",
            "Gergely Gabor Barnafoldi"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We use open charm production to estimate how far we can see back in time in high-energy hadron-hadron collisions. We analyze the transverse momentum distributions of the identified D mesons from pp, p-Pb and A-A collisions at the ALICE and STAR experiments covering the energy range from $\\sqrt{s_{\\rm NN}} = 200$ GeV up to 7 TeV. Within a non-extensive statistical framework, the common Tsallis parameters for D mesons represent higher temperature and more degrees of freedom than that of light-flavour hadrons. The production of D mesons corresponds to a significantly earlier proper time, $\u03c4_{\\rm D} = (0.18 \\pm 0.06) \u03c4_{\\rm LF}$.",
        "comments": "18 pages, 6 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14282"
    },
    {
        "doc_id": 18,
        "title": "An Instance-Based Approach to the Trace Reconstruction Problem",
        "authors": [
            "Kayvon Mazooji",
            "Ilan Shomorony"
        ],
        "subjects": [
            "Information Theory",
            "Data Structures and Algorithms",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\" Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.",
        "comments": "7 pages, accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14277"
    },
    {
        "doc_id": 19,
        "title": "Conservation laws and the foundations of quantum mechanics",
        "authors": [
            "Yakir Aharonov",
            "Sandu Popescu",
            "Daniel Rohrlich"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "In a recent paper, PNAS, 118, e1921529118 (2021), it was argued that while the standard definition of conservation laws in quantum mechanics, which is of a statistical character, is perfectly valid, it misses essential features of nature and it can and must be revisited to address the issue of conservation/non-conservation in individual cases. Specifically, in the above paper an experiment was presented in which it can be proven that in some individual cases energy is not conserved, despite being conserved statistically. It was felt however that this is worrisome, and that something must be wrong if there are individual instances in which conservation doesn't hold, even though this is not required by the standard conservation law. Here we revisit that experiment and show that although its results are correct, there is a way to circumvent them and ensure individual case conservation in that situation. The solution is however quite unusual, challenging one of the basic assumptions of quantum mechanics, namely that any quantum state can be prepared, and it involves a time-holistic, double non-conservation effect. Our results bring new light on the role of the preparation stage of the initial state of a particle and on the interplay of conservation laws and frames of reference. We also conjecture that when such a full analysis of any conservation experiment is performed, conservation is obeyed in every individual case.",
        "comments": "Journal ref:        PNAS, 120 (41) e2220810120 (2023)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14261"
    },
    {
        "doc_id": 20,
        "title": "spINAR: An R Package for Semiparametric and Parametric Estimation and Bootstrapping of Integer-Valued Autoregressive (INAR) Models",
        "authors": [
            "Maxime Faymonville",
            "Javiera Riffo",
            "Jonas Rieger",
            "Carsten Jentsch"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "Although the statistical literature extensively covers continuous-valued time series processes and their parametric, non-parametric and semiparametric estimation, the literature on count data time series is considerably less advanced. Among the count data time series models, the integer-valued autoregressive (INAR) model is arguably the most popular one finding applications in a wide variety of fields such as medical sciences, environmentology and economics. While many contributions have been made during the last decades, the majority of the literature focuses on parametric INAR models and estimation techniques. Our emphasis is on the complex but efficient and non-restrictive semiparametric estimation of INAR models. The appeal of this approach lies in the absence of a commitment to a parametric family of innovation distributions. In this paper, we describe the need and the features of our R package spINAR which combines semiparametric simulation, estimation and bootstrapping of INAR models also covering its parametric versions.",
        "comments": "3 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14239"
    },
    {
        "doc_id": 21,
        "title": "At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition",
        "authors": [
            "Ashok Dahal",
            "Rapha\u00ebl Huser",
            "Luigi Lombardo"
        ],
        "subjects": [
            "Machine Learning",
            "Geophysics",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple return periods. We also use our model to further explore landslide hazard for the same return periods under different climate change scenarios up to the end of the century. Our results show that the proposed model performs excellently and can be used to model landslide hazard in a unified manner. Geomorphologically, we find that under both climate change scenarios (SSP245 and SSP885), landslide hazard is likely to increase up to two times on average in the lower Himalayan regions while remaining the same in the middle Himalayan region whilst decreasing slightly in the upper Himalayan region areas.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14210"
    },
    {
        "doc_id": 22,
        "title": "Statistical Characterization of RIS-assisted UAV Communications in Terrestrial and Non-Terrestrial Networks Under Channel Aging",
        "authors": [
            "Thanh Luan Nguyen",
            "Georges Kaddoum",
            "Tri Nhu Do",
            "Zygmunt J. Haas"
        ],
        "subjects": [
            "Signal Processing",
            "Information Theory"
        ],
        "abstract": "This paper studies the statistical characterization of ground-to-UAV (G2A) and reconfigurable intelligent surface (RIS)-assisted UAV-to-ground (A2G) communications in terrestrial and non-terrestrial networks under the impact of channel aging. We first model the G2A and A2G signal-to-noise ratios as non-central complex Gaussian quadratic random variables (RVs) and derive their exact probability density functions, offering a unique characterization for the A2G SNR as the product of two scaled non-central chi-square RVs. Moreover, we also find that, for a large number of RIS elements, the RIS-assisted A2G channel can be characterized as a single Rician fading channel. Our results reveal the presence of channel hardening in A2G communication under low UAV speeds, where we derive the maximum target spectral efficiency (SE) for a system to maintain a consistent required outage level. Meanwhile, high UAV speeds, exceeding 50 m/s, lead to a significant performance degradation, which cannot be mitigated by increasing the number of RIS elements.",
        "comments": "6 pages, 3 figures and 7 subfigures, IEEE ICC'24 (Revision),",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14203"
    },
    {
        "doc_id": 23,
        "title": "Clinical Melanoma Diagnosis with Artificial Intelligence: Insights from a Prospective Multicenter Study",
        "authors": [
            "Lukas Heinlein",
            "Roman C. Maron",
            "Achim Hekler",
            "Sarah Haggenm\u00fcller",
            "Christoph Wies",
            "Jochen S. Utikal",
            "Friedegund Meier",
            "Sarah Hobelsberger",
            "Frank F. Gellrich",
            "Mildred Sergon",
            "Axel Hauschild",
            "Lars E. French",
            "Lucie Heinzerling",
            "Justin G. Schlager",
            "Kamran Ghoreschi",
            "Max Schlaak",
            "Franz J. Hilke",
            "Gabriela Poch",
            "S\u00f6ren Korsing",
            "Carola Berking",
            "Markus V. Heppt",
            "Michael Erdmann",
            "Sebastian Haferkamp",
            "Konstantin Drexler",
            "Dirk Schadendorf",
            "et al. (5 additional authors not shown)"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Applications"
        ],
        "abstract": "Early detection of melanoma, a potentially lethal type of skin cancer with high prevalence worldwide, improves patient prognosis. In retrospective studies, artificial intelligence (AI) has proven to be helpful for enhancing melanoma detection. However, there are few prospective studies confirming these promising results. Existing studies are limited by low sample sizes, too homogenous datasets, or lack of inclusion of rare melanoma subtypes, preventing a fair and thorough evaluation of AI and its generalizability, a crucial aspect for its application in the clinical setting. Therefore, we assessed 'All Data are Ext' (ADAE), an established open-source ensemble algorithm for detecting melanomas, by comparing its diagnostic accuracy to that of dermatologists on a prospectively collected, external, heterogeneous test set comprising eight distinct hospitals, four different camera setups, rare melanoma subtypes, and special anatomical sites. We advanced the algorithm with real test-time augmentation (R-TTA, i.e. providing real photographs of lesions taken from multiple angles and averaging the predictions), and evaluated its generalization capabilities. Overall, the AI showed higher balanced accuracy than dermatologists (0.798, 95% confidence interval (CI) 0.779-0.814 vs. 0.781, 95% CI 0.760-0.802; p<0.001), obtaining a higher sensitivity (0.921, 95% CI 0.900- 0.942 vs. 0.734, 95% CI 0.701-0.770; p<0.001) at the cost of a lower specificity (0.673, 95% CI 0.641-0.702 vs. 0.828, 95% CI 0.804-0.852; p<0.001). As the algorithm exhibited a significant performance advantage on our heterogeneous dataset exclusively comprising melanoma-suspicious lesions, AI may offer the potential to support dermatologists particularly in diagnosing challenging cases.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14193"
    },
    {
        "doc_id": 24,
        "title": "Graph-accelerated Markov Chain Monte Carlo using Approximate Samples",
        "authors": [
            "Leo L. Duan",
            "Anirban Bhattacharya"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "In recent years, it has become increasingly easy to obtain approximate posterior samples via efficient computation algorithms, such as those in variational Bayes. On the other hand, concerns exist on the accuracy of uncertainty estimates, which make it tempting to consider exploiting the approximate samples in canonical Markov chain Monte Carlo algorithms. A major technical barrier is that the approximate sample, when used as a proposal in Metropolis-Hastings steps, tends to have a low acceptance rate as the dimension increases. In this article, we propose a simple yet general solution named ''graph-accelerated Markov Chain Monte Carlo''. We first build a graph with each node location assigned to an approximate sample, then we run Markov chain Monte Carlo with random walks over the graph. In the first stage, we optimize the choice of graph edges to enforce small differences in posterior density/probability between neighboring nodes, while encouraging edges to correspond to large distances in the parameter space. This optimized graph allows us to accelerate a canonical Markov transition kernel through mixing with a large-jump Metropolis-Hastings step, when collecting Markov chain samples at the second stage. Due to its simplicity, this acceleration can be applied to most of the existing Markov chain Monte Carlo algorithms. We theoretically quantify the rate of acceptance as dimension increases, and show the effects on improved mixing time. We demonstrate our approach through improved mixing performances for challenging sampling problems, such as those involving multiple modes, non-convex density contour, or large-dimension latent variables.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14186"
    },
    {
        "doc_id": 25,
        "title": "Adapting tree-based multiple imputation methods for multi-level data? A simulation study",
        "authors": [
            "Ketevan Gurtskaia",
            "Jakob Schwerter",
            "Philipp Doebler"
        ],
        "subjects": [
            "Applications",
            "Machine Learning"
        ],
        "abstract": "This simulation study evaluates the effectiveness of multiple imputation (MI) techniques for multilevel data. It compares the performance of traditional Multiple Imputation by Chained Equations (MICE) with tree-based methods such as Chained Random Forests with Predictive Mean Matching and Extreme Gradient Boosting. Adapted versions that include dummy variables for cluster membership are also included for the tree-based methods. Methods are evaluated for coefficient estimation bias, statistical power, and type I error rates on simulated hierarchical data with different cluster sizes (25 and 50) and levels of missingness (10\\% and 50\\%). Coefficients are estimated using random intercept and random slope models. The results show that while MICE is preferred for accurate rejection rates, Extreme Gradient Boosting is advantageous for reducing bias. Furthermore, the study finds that bias levels are similar across different cluster sizes, but rejection rates tend to be less favorable with fewer clusters (lower power, higher type I error). In addition, the inclusion of cluster dummies in tree-based methods improves estimation for Level 1 variables, but is less effective for Level 2 variables. When data become too complex and MICE is too slow, extreme gradient boosting is a good alternative for hierarchical data.\n  Keywords: Multiple imputation; multi-level data; MICE; missRanger; mixgb",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14161"
    },
    {
        "doc_id": 26,
        "title": "Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations",
        "authors": [
            "Xinyue Xu",
            "Yi Qin",
            "Lu Mi",
            "Hao Wang",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., \"yellow breast\") does not help correct highly correlated concepts (e.g., \"yellow belly\"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label \"Kentucky Warbler\" and a concept \"black bill\", what is the probability that the model correctly predicts another concept \"black crown\"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bottleneck Models (ECBMs). Our ECBMs use a set of neural networks to define the joint energy of candidate (input, concept, class) tuples. With such a unified interface, prediction, concept correction, and conditional dependency quantification are then represented as conditional probabilities, which are generated by composing different energy functions. Our ECBMs address both limitations of existing CBMs, providing higher accuracy and richer concept interpretations. Empirical results show that our approach outperforms the state-of-the-art on real-world datasets.",
        "comments": "Accepted by ICLR 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14142"
    },
    {
        "doc_id": 27,
        "title": "Performance Analysis for Near-Field ISAC: A Holographic MIMO Design",
        "authors": [
            "Boqun Zhao",
            "Chongjun Ouyang",
            "Xingqi Zhang",
            "Yuanwei Liu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "A near-field holographic multiple-input multiple-output (MIMO) based integrated sensing and communications (ISAC) framework is proposed for both downlink and uplink scenarios, where spherical wave-based model is considered to capture the characteristics of the near field. The coupling effect introduced by the densely spaced antennas of the holographic MIMO are characterized by spatially correlated Rayleigh fading. Based on the proposed framework, by considering both instantaneous channel state information (CSI) and statistical CSI, closed-form expressions are derived for sensing rates (SRs), communication rates (CRs), and outage probabilities under different ISAC designs. Further insights are gained by examining high signal-to-noise ratio slopes and diversity orders. Specifically, 1) for the downlink case, a sensing-centric (S-C) design and a communications-centric (C-C) design are investigated based on different beamforming strategies, and a Pareto optimal design is proposed to characterize the attainable SR-CR region; and 2) for the uplink case, the S-C design and the C-C design are distinguished by the interference cancellation order of the communication signal and the sensing signal, and the rate region is obtained through a time-sharing strategy. Numerical results reveal that the proposed ISAC system achieves more extensive rate regions than the conventional frequency-division sensing and communications system, highlighting its superior performance.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14129"
    },
    {
        "doc_id": 28,
        "title": "On a Novel Skewed Generalized t Distribution: Properties, Estimations and its Applications",
        "authors": [
            "Chengdi Lian",
            "Yaohua Rong",
            "Weihu Cheng"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "With the progress of information technology, large amounts of asymmetric, leptokurtic and heavy-tailed data are arising in various fields, such as finance, engineering, genetics and medicine. It is very challenging to model those kinds of data, especially for extremely skewed data, accompanied by very high kurtosis or heavy tails. In this paper, we propose a class of novel skewed generalized t distribution (SkeGTD) as a scale mixture of skewed generalized normal. The proposed SkeGTD has excellent adaptiveness to various data, because of its capability of allowing for a large range of skewness and kurtosis and its compatibility of the separated location, scale, skewness and shape parameters. We investigate some important properties of this family of distributions. The maximum likelihood estimation, L-moments estimation and two-step estimation for the SkeGTD are explored. To illustrate the usefulness of the proposed methodology, we present simulation studies and analyze two real datasets.",
        "comments": "34 pages, 4 figures; Communications in Statistics - Theory and Methods, accepted, January 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14122"
    },
    {
        "doc_id": 29,
        "title": "ODC and ROC curves, comparison curves, and stochastic dominance",
        "authors": [
            "Teresa Ledwina",
            "Adam Zagda\u0144ski"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "We discuss two novel approaches to the classical two-sample problem. Our starting point are properly standardized and combined, very popular in several areas of statistics and data analysis, ordinal dominance and receiver characteristic curves, denoted by ODC and ROC, respectively. The proposed new curves are termed the comparison curves. Their estimates, being weighted rank processes on (0,1), form the basis of inference. These weighted processes are intuitive, well-suited for visual inspection of data at hand, and are also useful for constructing some formal inferential procedures. They can be applied to several variants of two-sample problem. Their use can help to improve some existing procedures both in terms of power and the ability to identify the sources of departures from the postulated model. To simplify interpretation of finite sample results we restrict attention to values of the processes on a finite grid of points. This results in the so-called bar plots (B-plots) which readably summarize the information contained in the data. What is more, we show that B-plots along with adjusted simultaneous acceptance regions provide principled information about where the model departs from the data. This leads to a framework which facilitates identification of regions with locally significant differences.\n  We show an implementation of the considered techniques to a standard stochastic dominance testing problem. Some min-type statistics are introduced and investigated. A simulation study compares two tests pertinent to the comparison curves to well-established tests in the literature and demonstrates the strong and competitive performance of the former in many typical situations. Some real data applications illustrate simplicity and practical usefulness of the proposed approaches. A range of other applications of considered weighted processes is briefly discussed too.",
        "comments": "45 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14094"
    },
    {
        "doc_id": 30,
        "title": "LongMemory.jl: Generating, Estimating, and Forecasting Long Memory Models in Julia",
        "authors": [
            "J. Eduardo Vera-Vald\u00e9s"
        ],
        "subjects": [
            "Mathematical Software",
            "Computation"
        ],
        "abstract": "LongMemory.jl is a package for time series long memory modelling in Julia. The package provides functions to generate long memory, estimate model parameters, and forecast. Generating methods include fractional differencing, stochastic error duration, and cross-sectional aggregation. Estimators include the classic ones used to estimate the Hurst effect, those inspired by log-periodogram regression, and parametric ones. Forecasting is provided for all parametric estimators. Moreover, the package adds plotting capabilities to illustrate long memory dynamics and forecasting. This article presents the theoretical developments for long memory modelling, show examples using the data included with the package, and compares the properties of LongMemory.jl with current alternatives, including benchmarks. For some of the theoretical developments, LongMemory.jl provides the first publicly available implementation in any programming language. A notable feature of this package is that all functions are implemented in the same programming language, taking advantage of the ease of use and speed provided by Julia. Therefore, all code is accessible to the user. Multiple dispatch, a novel feature of the language, is used to speed computations and provide consistent calls to related methods. The package is related to the R packages LongMemoryTS and fracdiff.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14077"
    },
    {
        "doc_id": 31,
        "title": "Influence of climate variability on the potential forage production of a mown permanent grassland in the French Massif Central",
        "authors": [
            "I\u00f1igo G\u00f3mara",
            "Gianni Bellocchi",
            "Rapha\u00ebl Martin",
            "Bel\u00e9n Rodr\u00edguez-Fonseca",
            "Margarita Ruiz-Ramos"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Climate Services (CS) provide support to decision makers across socio-economic sectors. In the agricultural sector, one of the most important CS applications is to provide timely and accurate yield forecasts based on climate prediction. In this study, the Pasture Simulation model (PaSim) was used to simulate, for the period 1959-2015, the forage production of a mown grassland system (Laqueuille, Massif Central of France) under different management conditions, with meteorological inputs extracted from the SAFRAN atmospheric database. The aim was to generate purely climate-dependent timeseries of optimal forage production, a variable that was maximized by brighter and warmer weather conditions at the grassland. A long-term increase was observed in simulated forage yield, with the 1995-2015 average being 29% higher than the 1959-1979 average. Such increase seems consistent with observed rising trends in temperature and CO2, and multi-decadal changes in incident solar radiation. At interannual timescales, sea surface temperature anomalies of the Mediterranean (MED), Tropical North Atlantic (TNA), equatorial Pacific (El Ni\u00f1o Southern Oscillation) and the North Atlantic Oscillation (NAO) index were found robustly correlated with annual forage yield values. Relying only on climatic predictors, we developed a stepwise statistical multi-regression model with leave-one-out cross-validation. Under specific management conditions (e.g., three annual cuts) and from one to five months in advance, the generated model successfully provided a p-value<0.01 in correlation (t-test), a root mean square error percentage (%RMSE) of 14.6% and a 71.43% hit rate predicting above/below average years in terms of forage yield collection.",
        "comments": "Journal ref:        Gomara I, Bellocchi G, Martin R, Rodriguez-Fonseca B, Ruiz-Ramos M (2020) Agricultural and Forest Meteorology, 280, 107768",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14053"
    },
    {
        "doc_id": 32,
        "title": "Testing Alpha in High Dimensional Linear Factor Pricing Models with Dependent Observations",
        "authors": [
            "Huifang Ma",
            "Long Feng",
            "Zhaojun Wang",
            "Jigang Bao"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In this study, we introduce three distinct testing methods for testing alpha in high dimensional linear factor pricing model that deals with dependent data. The first method is a sum-type test procedure, which exhibits high performance when dealing with dense alternatives. The second method is a max-type test procedure, which is particularly effective for sparse alternatives. For a broader range of alternatives, we suggest a Cauchy combination test procedure. This is predicated on the asymptotic independence of the sum-type and max-type test statistics. Both simulation studies and practical data application demonstrate the effectiveness of our proposed methods when handling dependent observations.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14052"
    },
    {
        "doc_id": 33,
        "title": "Diverse and Lifespan Facial Age Transformation Synthesis with Identity Variation Rationality Metric",
        "authors": [
            "Jiu-Cheng Xie",
            "Jun Yang",
            "Wenqing Wang",
            "Feng Xu",
            "Hao Gao"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Face aging has received continuous research attention over the past two decades. Although previous works on this topic have achieved impressive success, two longstanding problems remain unsettled: 1) generating diverse and plausible facial aging patterns at the target age stage; 2) measuring the rationality of identity variation between the original portrait and its syntheses with age progression or regression. In this paper, we introduce DLAT + , the first algorithm that can realize Diverse and Lifespan Age Transformation on human faces, where the diversity jointly manifests in the transformation of facial textures and shapes. Apart from the diversity mechanism embedded in the model, multiple consistency restrictions are leveraged to keep it away from counterfactual aging syntheses. Moreover, we propose a new metric to assess the rationality of Identity Deviation under Age Gaps (IDAG) between the input face and its series of age-transformed generations, which is based on statistical laws summarized from plenty of genuine face-aging data. Extensive experimental results demonstrate the uniqueness and effectiveness of our method in synthesizing diverse and perceptually reasonable faces across the whole lifetime.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14036"
    },
    {
        "doc_id": 34,
        "title": "Comparison of modularity-based approaches for nodes clustering in binary hypergraphs",
        "authors": [
            "Veronica Poda",
            "Catherine Matias"
        ],
        "subjects": [
            "Social and Information Networks",
            "Combinatorics",
            "Data Analysis, Statistics and Probability",
            "Applications"
        ],
        "abstract": "We conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14028"
    },
    {
        "doc_id": 35,
        "title": "Semantic Ensemble Loss and Latent Refinement for High-Fidelity Neural Image Compression",
        "authors": [
            "Daxin Li",
            "Yuanchao Bai",
            "Kai Wang",
            "Junjun Jiang",
            "Xianming Liu"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Recent advancements in neural compression have surpassed traditional codecs in PSNR and MS-SSIM measurements. However, at low bit-rates, these methods can introduce visually displeasing artifacts, such as blurring, color shifting, and texture loss, thereby compromising perceptual quality of images. To address these issues, this study presents an enhanced neural compression method designed for optimal visual fidelity. We have trained our model with a sophisticated semantic ensemble loss, integrating Charbonnier loss, perceptual loss, style loss, and a non-binary adversarial loss, to enhance the perceptual quality of image reconstructions. Additionally, we have implemented a latent refinement process to generate content-aware latent codes. These codes adhere to bit-rate constraints, balance the trade-off between distortion and fidelity, and prioritize bit allocation to regions of greater importance. Our empirical findings demonstrate that this approach significantly improves the statistical fidelity of neural image compression. On CLIC2024 validation set, our approach achieves a 62% bitrate saving compared to MS-ILLM under FID metric.",
        "comments": "7 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14007"
    },
    {
        "doc_id": 36,
        "title": "Localization of Lindbladian Fermions",
        "authors": [
            "Foster Thompson",
            "Yi Huang",
            "Alex Kamenev"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks"
        ],
        "abstract": "We study a Lindbladian generalization of the Anderson model of localization that describes disordered free fermions coupled to a disordered environment. From finite size scaling of both eigenvalue statistics and participation ratio, we identify localization transitions in both the non-Hermitian Lindbladian spectrum, which governs transient relaxation dynamics, and in the Hermitian stationary state density matrix. These localization transitions occur at different critical values of Hamiltonian and dissipative disorder strength, implying the existence of atypical phases with a mixture of localized and delocalized features. We find this phenomenon is robust to changes to the value of the dissipative spectral gap.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14006"
    },
    {
        "doc_id": 37,
        "title": "Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru",
        "authors": [
            "Tanmay Ghosh",
            "Nithin Nagaraj"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics"
        ],
        "abstract": "The decision making involved behind the mode choice is critical for transportation planning. While statistical learning techniques like discrete choice models have been used traditionally, machine learning (ML) models have gained traction recently among the transportation planners due to their higher predictive performance. However, the black box nature of ML models pose significant interpretability challenges, limiting their practical application in decision and policy making. This study utilised a dataset of $1350$ households belonging to low and low-middle income bracket in the city of Bengaluru to investigate mode choice decision making behaviour using Multinomial logit model and ML classifiers like decision trees, random forests, extreme gradient boosting and support vector machines. In terms of accuracy, random forest model performed the best ($0.788$ on training data and $0.605$ on testing data) compared to all the other models. This research has adopted modern interpretability techniques like feature importance and individual conditional expectation plots to explain the decision making behaviour using ML models. A higher travel costs significantly reduce the predicted probability of bus usage compared to other modes (a $0.66\\%$ and $0.34\\%$ reduction using Random Forests and XGBoost model for $10\\%$ increase in travel cost). However, reducing travel time by $10\\%$ increases the preference for the metro ($0.16\\%$ in Random Forests and 0.42% in XGBoost). This research augments the ongoing research on mode choice analysis using machine learning techniques, which would help in improving the understanding of the performance of these models with real-world data in terms of both accuracy and interpretability.",
        "comments": "65 pages, 26 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13977"
    },
    {
        "doc_id": 38,
        "title": "Sparse signal recovery and source localization via covariance learning",
        "authors": [
            "Esa Ollila"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "In the Multiple Measurements Vector (MMV) model, measurement vectors are connected to unknown, jointly sparse signal vectors through a linear regression model employing a single known measurement matrix (or dictionary). Typically, the number of atoms (columns of the dictionary) is greater than the number measurements and the sparse signal recovery problem is generally ill-posed. In this paper, we treat the signals and measurement noise as independent Gaussian random vectors with unknown signal covariance matrix and noise variance, respectively, and derive fixed point (FP) equation for solving the likelihood equation for signal powers, thereby enabling the recovery of the sparse signal support (sources with non-zero variances). Two practical algorithms, a block coordinate descent (BCD) and a cyclic coordinate descent (CCD) algorithms, that leverage on the FP characterization of the likelihood equation are then proposed. Additionally, a greedy pursuit method, analogous to popular simultaneous orthogonal matching pursuit (OMP), is introduced. Our numerical examples demonstrate effectiveness of the proposed covariance learning (CL) algorithms both in classic sparse signal recovery as well as in direction-of-arrival (DOA) estimation problems where they perform favourably compared to the state-of-the-art algorithms under a broad variety of settings.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13975"
    },
    {
        "doc_id": 39,
        "title": "Z-estimation system: a modular approach to asymptotic analysis",
        "authors": [
            "Jie Kate Hu"
        ],
        "subjects": [
            "Statistics Theory"
        ],
        "abstract": "Asymptotic analysis for related inference problems often involves similar steps and proofs. These intermediate results could be shared across problems if each of them is made self-contained and easily identified. However, asymptotic analysis using Taylor expansions is limited for result borrowing because it is a step-to-step procedural approach. This article introduces EEsy, a modular system for estimating finite and infinitely dimensional parameters in related inference problems. It is based on the infinite-dimensional Z-estimation theorem, Donsker and Glivenko-Cantelli preservation theorems, and weight calibration techniques. This article identifies the systematic nature of these tools and consolidates them into one system containing several modules, which can be built, shared, and extended in a modular manner. This change to the structure of method development allows related methods to be developed in parallel and complex problems to be solved collaboratively, expediting the development of new analytical methods. This article considers four related inference problems -- estimating parameters with random sampling, two-phase sampling, auxiliary information incorporation, and model misspecification. We illustrate this modular approach by systematically developing 9 parameter estimators and 18 variance estimators for the four related inference problems regarding semi-parametric additive hazards models. Simulation studies show the obtained asymptotic results for these 27 estimators are valid. In the end, I describe how this system can simplify the use of empirical process theory, a powerful but challenging tool to be adopted by the broad community of methods developers. I discuss challenges and the extension of this system to other inference problems.",
        "comments": "MSC Class:          62",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13948"
    },
    {
        "doc_id": 40,
        "title": "Is the age pension in Australia sustainable and fair? Evidence from forecasting the old-age dependency ratio using the Hamilton-Perry model",
        "authors": [
            "Sizhe Chen",
            "Han Lin Shang",
            "Yang Yang"
        ],
        "subjects": [
            "Applications",
            "Methodology"
        ],
        "abstract": "The age pension aims to assist eligible elderly Australians meet specific age and residency criteria in maintaining basic living standards. In designing efficient pension systems, government policymakers seek to satisfy the expectations of the overall aging population in Australia. However, the population's unique demographic characteristics at the state and territory level are often overlooked due to the lack of available data. We use the Hamilton-Perry model, which requires minimum input, to model and forecast the evolution of age-specific populations at the state level. We also integrate the obtained sub-national demographic information to determine sustainable pension ages up to 2051. We also investigate pension welfare distribution in all states and territories to identify disadvantaged residents under the current pension system. Using the sub-national mortality data for Australia from 1971 to 2021 obtained from AHMD (2023), we implement the Hamilton-Perry model with the help of functional time series forecasting techniques. With forecasts of age-specific population sizes for each state and territory, we compute the old age dependency ratio to determine the nationwide sustainable pension age.",
        "comments": "31 pages, 14 figures, 1 table",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13943"
    },
    {
        "doc_id": 41,
        "title": "A New Paradigm for Counterfactual Reasoning in Fairness and Recourse",
        "authors": [
            "Lucius E. J. Bynum",
            "Joshua R. Loftus",
            "Julia Stoyanovich"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Counterfactuals and counterfactual reasoning underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems. The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated. For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc. We ask, for example, what would have happened had your race been different? An inherent limitation of this paradigm is that some demographic interventions -- like interventions on race -- may not translate into the formalisms of interventional counterfactuals. In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine alternate initial conditions while holding these characteristics fixed. We ask instead, what would explain a counterfactual outcome for you as you actually are or could be? This alternate framework allows us to address many of the same social concerns, but to do so while asking fundamentally different questions that do not rely on demographic interventions.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13935"
    },
    {
        "doc_id": 42,
        "title": "Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics",
        "authors": [
            "Xingche Guo",
            "Donglin Zeng",
            "Yuanjia Wang"
        ],
        "subjects": [
            "Machine Learning",
            "Applications",
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "Major depressive disorder (MDD) presents challenges in diagnosis and treatment due to its complex and heterogeneous nature. Emerging evidence indicates that reward processing abnormalities may serve as a behavioral marker for MDD. To measure reward processing, patients perform computer-based behavioral tasks that involve making choices or responding to stimulants that are associated with different outcomes. Reinforcement learning (RL) models are fitted to extract parameters that measure various aspects of reward processing to characterize how patients make decisions in behavioral tasks. Recent findings suggest the inadequacy of characterizing reward learning solely based on a single RL model; instead, there may be a switching of decision-making processes between multiple strategies. An important scientific question is how the dynamics of learning strategies in decision-making affect the reward learning ability of individuals with MDD. Motivated by the probabilistic reward task (PRT) within the EMBARC study, we propose a novel RL-HMM framework for analyzing reward-based decision-making. Our model accommodates learning strategy switching between two distinct approaches under a hidden Markov model (HMM): subjects making decisions based on the RL model or opting for random choices. We account for continuous RL state space and allow time-varying transition probabilities in the HMM. We introduce a computationally efficient EM algorithm for parameter estimation and employ a nonparametric bootstrap for inference. We apply our approach to the EMBARC study to show that MDD patients are less engaged in RL compared to the healthy controls, and engagement is associated with brain activities in the negative affect circuitry during an emotional conflict task.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13929"
    },
    {
        "doc_id": 43,
        "title": "Scale-invariant Phenomena in Repeating Fast Radio Bursts and Glitching Pulsars",
        "authors": [
            "Chong-Yu Gao",
            "Jun-Jie Wei"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "The recent discoveries of a remarkable glitch/antiglitch accompanied by fast radio burst (FRB)-like bursts from the Galactic magnetar SGR J1935+2154 have revealed the physical connection between the two. In this work, we study the statistical properties of radio bursts from the hyperactive repeating source FRB 20201124A and of glitches from the pulsar PSR B1737--30. For FRB 20201124A, we confirm that the probability density functions of fluctuations of energy, peak flux, duration, and waiting time well follow the Tsallis q-Gaussian distribution. The derived q values from q-Gaussian distribution keep approximately steady for different temporal interval scales, which indicate that there is a common scale-invariant structure in repeating FRBs. Similar scale-invariant property can be found in PSR B1737--30's glitches, implying an underlying association between the origins of repeating FRBs and pulsar glitches. These statistical features can be well understood within the same physical framework of self-organized criticality systems.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13916"
    },
    {
        "doc_id": 44,
        "title": "Spectral Clustering for Discrete Distributions",
        "authors": [
            "Zixiao Wang",
            "Dong Qiao",
            "Jicong Fan"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13913"
    },
    {
        "doc_id": 45,
        "title": "A Survey of Deep Learning and Foundation Models for Time Series Forecasting",
        "authors": [
            "John A. Miller",
            "Mohammed Aldosari",
            "Farah Saeed",
            "Nasid Habib Barna",
            "Subas Rana",
            "I. Budak Arpinar",
            "Ninghao Liu"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Deep Learning has been successfully applied to many application domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known Makridakis (M) Competitions, hybrids of traditional statistical or machine learning techniques have only recently become the top performers. With the recent architectural advances in deep learning being applied to time series forecasting (e.g., encoder-decoders with attention, transformers, and graph neural networks), deep learning has begun to show significant advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, unawareness of accumulated scientific knowledge, and interpretability of the model. To this end, the development of foundation models (large deep learning models with extensive pre-training) allows models to understand patterns and acquire knowledge that can be applied to new related problems before extensive training data becomes available. Furthermore, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject such knowledge into deep learning models. In this survey, several state-of-the-art modeling techniques are reviewed, and suggestions for further work are provided.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13912"
    },
    {
        "doc_id": 46,
        "title": "Empowering Machines to Think Like Chemists: Unveiling Molecular Structure-Polarity Relationships with Hierarchical Symbolic Regression",
        "authors": [
            "Siyu Lou",
            "Chengchun Liu",
            "Yuntian Chen",
            "Fanyang Mo"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Databases",
            "Applications"
        ],
        "abstract": "Thin-layer chromatography (TLC) is a crucial technique in molecular polarity analysis. Despite its importance, the interpretability of predictive models for TLC, especially those driven by artificial intelligence, remains a challenge. Current approaches, utilizing either high-dimensional molecular fingerprints or domain-knowledge-driven feature engineering, often face a dilemma between expressiveness and interpretability. To bridge this gap, we introduce Unsupervised Hierarchical Symbolic Regression (UHiSR), combining hierarchical neural networks and symbolic regression. UHiSR automatically distills chemical-intuitive polarity indices, and discovers interpretable equations that link molecular structure to chromatographic behavior.",
        "comments": "33 pages, 6 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13904"
    },
    {
        "doc_id": 47,
        "title": "Discrete Hawkes process with flexible residual distribution and filtered historical simulation",
        "authors": [
            "Kyungsub Lee"
        ],
        "subjects": [
            "Statistical Finance",
            "Methodology"
        ],
        "abstract": "We introduce a new model which can be considered as a extended version of the Hawkes process in a discrete sense. This model enables the integration of various residual distributions while preserving the fundamental properties of the original Hawkes process. The rich nature of this model enables a filtered historical simulation which incorporate the properties of original time series more accurately. The process naturally extends to multi-variate models with easy implementations of estimation and simulation. We investigate the effect of flexible residual distribution on estimation of high frequency financial data compared with the Hawkes process.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13890"
    },
    {
        "doc_id": 48,
        "title": "Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation",
        "authors": [
            "Yixuan Zhang",
            "Qiaomin Xie"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "Stochastic Approximation (SA) is a widely used algorithmic approach in various fields, including optimization and reinforcement learning (RL). Among RL algorithms, Q-learning is particularly popular due to its empirical success. In this paper, we study asynchronous Q-learning with constant stepsize, which is commonly used in practice for its fast convergence. By connecting the constant stepsize Q-learning to a time-homogeneous Markov chain, we show the distributional convergence of the iterates in Wasserstein distance and establish its exponential convergence rate. We also establish a Central Limit Theory for Q-learning iterates, demonstrating the asymptotic normality of the averaged iterates. Moreover, we provide an explicit expansion of the asymptotic bias of the averaged iterate in stepsize. Specifically, the bias is proportional to the stepsize up to higher-order terms and we provide an explicit expression for the linear coefficient. This precise characterization of the bias allows the application of Richardson-Romberg (RR) extrapolation technique to construct a new estimate that is provably closer to the optimal Q function. Numerical results corroborate our theoretical finding on the improvement of the RR extrapolation method.",
        "comments": "41 pages, 3 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13884"
    },
    {
        "doc_id": 49,
        "title": "Spontaneous stochasticity amplifies even thermal noise to the largest scales of turbulence in a few eddy turnover times",
        "authors": [
            "Dmytro Bandak",
            "Alexei Mailybaev",
            "Gregory L. Eyink",
            "Nigel Goldenfeld"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "How predictable are turbulent flows? Here we use theoretical estimates and shell model simulations to argue that Eulerian spontaneous stochasticity, a manifestation of the non-uniqueness of the solutions to the Euler equation that is conjectured to occur in Navier-Stokes turbulence at high Reynolds numbers, leads to universal statistics at finite times, not just at infinite time as for standard chaos. These universal statistics are predictable, even though individual flow realizations are not. Any small-scale noise vanishing slowly enough with increasing Reynolds number can trigger spontaneous stochasticity and here we show that thermal noise alone, in the absence of any larger disturbances, would suffice. If confirmed for Navier-Stokes turbulence, our findings would imply that intrinsic stochasticity of turbulent fluid motions at all scales can be triggered even by unavoidable molecular noise, with implications for modeling in engineering, climate, astrophysics and cosmology.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13881"
    },
    {
        "doc_id": 50,
        "title": "Principal Component Regression to Study the Impact of Economic Factors on Disadvantaged Communities",
        "authors": [
            "Narmadha M. Mohankumar",
            "Milan Jain",
            "Heng Wan",
            "Sumitrra Ganguli",
            "Kyle D. Wilson",
            "David M. Anderson"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "The Council on Environmental Quality's Climate and Economic Justice Screening Tool defines \"disadvantaged communities\" (DAC) in the USA, highlighting census tracts where benefits of climate and energy investments are not accruing. We use a principal component generalized linear model, which addresses the intertwined nature of economic factors, income and employment and model their relationship to DAC status. Our study 1) identifies the most significant income groups and employment industries that impact DAC status, 2) provides the probability of DAC status across census tracts and compares the predictive accuracy with widely used machine learning approaches, 3) obtains historical predictions of the probability of DAC status, 4) obtains spatial downscaling of DAC status across block groups. Our study provides valuable insights for policymakers and stakeholders to develop strategies that promote sustainable development and address inequities in climate and energy investments in the USA.",
        "comments": "13 pages, 9 figures, 2 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13880"
    },
    {
        "doc_id": 51,
        "title": "Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?",
        "authors": [
            "Huy Nguyen",
            "Pedram Akbarian",
            "Nhat Ho"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Dense-to-sparse gating mixture of experts (MoE) has recently become an effective alternative to a well-known sparse MoE. Rather than fixing the number of activated experts as in the latter model, which could limit the investigation of potential experts, the former model utilizes the temperature to control the softmax weight distribution and the sparsity of the MoE during training in order to stabilize the expert specialization. Nevertheless, while there are previous attempts to theoretically comprehend the sparse MoE, a comprehensive analysis of the dense-to-sparse gating MoE has remained elusive. Therefore, we aim to explore the impacts of the dense-to-sparse gate on the maximum likelihood estimation under the Gaussian MoE in this paper. We demonstrate that due to interactions between the temperature and other model parameters via some partial differential equations, the convergence rates of parameter estimations are slower than any polynomial rates, and could be as slow as $\\mathcal{O}(1/\\log(n))$, where $n$ denotes the sample size. To address this issue, we propose using a novel activation dense-to-sparse gate, which routes the output of a linear layer to an activation function before delivering them to the softmax function. By imposing linearly independence conditions on the activation function and its derivatives, we show that the parameter estimation rates are significantly improved to polynomial rates.",
        "comments": "53 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13875"
    },
    {
        "doc_id": 52,
        "title": "A V2X-based Privacy Preserving Federated Measuring and Learning System",
        "authors": [
            "Levente Alekszejenk\u00f3",
            "Tadeusz Dobrowiecki"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data. Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making. Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies. Moreover, predicting the state of the road network might be beneficial too. With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow. That would decrease transportation costs as well as reduce its environmental impact.\n  In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network. As we are yet to have real-world AV data, we model it with a non-IID (independent and identically distributed) dataset to evaluate the capabilities of the proposed system in terms of performance and privacy. Results indicate that the proposed FL scheme improves learning performance and prevents eavesdropping at the aggregator server side.",
        "comments": "8 pages, 5 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13848"
    },
    {
        "doc_id": 53,
        "title": "Machine learning for industrial sensing and control: A survey and practical perspective",
        "authors": [
            "Nathan P. Lawrence",
            "Seshu Kumar Damarla",
            "Jong Woo Kim",
            "Aditya Tulsyan",
            "Faraz Amjad",
            "Kai Wang",
            "Benoit Chachuat",
            "Jong Min Lee",
            "Biao Huang",
            "R. Bhushan Gopaluni"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning"
        ],
        "abstract": "With the rise of deep learning, there has been renewed interest within the process industries to utilize data on large-scale nonlinear sensing and control problems. We identify key statistical and machine learning techniques that have seen practical success in the process industries. To do so, we start with hybrid modeling to provide a methodological framework underlying core application areas: soft sensing, process optimization, and control. Soft sensing contains a wealth of industrial applications of statistical and machine learning methods. We quantitatively identify research trends, allowing insight into the most successful techniques in practice.\n  We consider two distinct flavors for data-driven optimization and control: hybrid modeling in conjunction with mathematical programming techniques and reinforcement learning. Throughout these application areas, we discuss their respective industrial requirements and challenges.\n  A common challenge is the interpretability and efficiency of purely data-driven methods. This suggests a need to carefully balance deep learning techniques with domain knowledge. As a result, we highlight ways prior knowledge may be integrated into industrial machine learning applications. The treatment of methods, problems, and applications presented here is poised to inform and inspire practitioners and researchers to develop impactful data-driven sensing, optimization, and control solutions in the process industries.",
        "comments": "48 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13836"
    },
    {
        "doc_id": 54,
        "title": "Generalized Free Cumulants for Quantum Chaotic Systems",
        "authors": [
            "Siddharth Jindal",
            "Pavan Hosur"
        ],
        "subjects": [
            "Statistical Mechanics",
            "High Energy Physics - Theory",
            "Quantum Physics"
        ],
        "abstract": "The eigenstate thermalization hypothesis (ETH) is the leading conjecture for the emergence of statistical mechanics in generic isolated quantum systems and is formulated in terms of the matrix elements of operators. An analog known as the ergodic bipartition (EB) describes entanglement and locality and is formulated in terms of the components of eigenstates. In this paper, we significantly generalize the EB and unify it with the ETH, extending the EB to study higher correlations and systems out of equilibrium. Our main result is a diagrammatic formalism that computes arbitrary correlations between eigenstates and operators based on a recently uncovered connection between the ETH and free probability theory. We refer to the connected components of our diagrams as generalized free cumulants. We apply our formalism in several ways. First, we focus on chaotic eigenstates and establish the so-called subsystem ETH and the Page curve as consequences of our construction. We also improve known calculations for thermal reduced density matrices and comment on an inherently free probabilistic aspect of the replica approach to entanglement entropy previously noticed in a calculation for the Page curve of an evaporating black hole. Next, we turn to chaotic quantum dynamics and demonstrate the ETH as a sufficient mechanism for thermalization, in general. In particular, we show that reduced density matrices relax to their equilibrium form and that systems obey the Page curve at late times. We also demonstrate that entanglement velocities, which govern the spreading of entanglement, are encoded in higher correlations of the EB. Lastly, we examine the chaotic structure of eigenstates and operators together and reveal previously overlooked correlations between them. Crucially, these correlations encode butterfly velocities, a well-known dynamical property of interacting quantum systems.",
        "comments": "44+14 pages, 19 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13829"
    },
    {
        "doc_id": 55,
        "title": "A Bayesian hierarchical mixture cure modelling framework to utilize multiple survival datasets for long-term survivorship estimates: A case study from previously untreated metastatic melanoma",
        "authors": [
            "Nathan Green",
            "Murat Kurt",
            "Andriy Moshyk",
            "James Larkin",
            "Gianluca Baio"
        ],
        "subjects": [
            "Applications",
            "Methodology"
        ],
        "abstract": "Time to an event of interest over a lifetime is a central measure of the clinical benefit of an intervention used in a health technology assessment (HTA). Within the same trial multiple end-points may also be considered. For example, overall and progression-free survival time for different drugs in oncology studies. A common challenge is when an intervention is only effective for some proportion of the population who are not clinically identifiable. Therefore, latent group membership as well as separate survival models for groups identified need to be estimated. However, follow-up in trials may be relatively short leading to substantial censoring. We present a general Bayesian hierarchical framework that can handle this complexity by exploiting the similarity of cure fractions between end-points; accounting for the correlation between them and improving the extrapolation beyond the observed data. Assuming exchangeability between cure fractions facilitates the borrowing of information between end-points. We show the benefits of using our approach with a motivating example, the CheckMate 067 phase 3 trial consisting of patients with metastatic melanoma treated with first line therapy.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13820"
    },
    {
        "doc_id": 56,
        "title": "Bayesian Analysis of the Beta Regression Model Subject to Linear Inequality Restrictions with Application",
        "authors": [
            "Solmaz Seifollahi",
            "Hossein Bevrani",
            "Kristofer Mansson"
        ],
        "subjects": [
            "Methodology",
            "Computation"
        ],
        "abstract": "ReRecent studies in machine learning are based on models in which parameters or state variables are bounded restricted. These restrictions are from prior information to ensure the validity of scientific theories or structural consistency based on physical phenomena. The valuable information contained in the restrictions must be considered during the estimation process to improve estimation accuracy. Many researchers have focused on linear regression models subject to linear inequality restrictions, but generalized linear models have received little attention. In this paper, the parameters of beta Bayesian regression models subjected to linear inequality restrictions are estimated. The proposed Bayesian restricted estimator, which is demonstrated by simulated studies, outperforms ordinary estimators. Even in the presence of multicollinearity, it outperforms the ridge estimator in terms of the standard deviation and the mean squared error. The results confirm that the proposed Bayesian restricted estimator makes sparsity in parameter estimating without using the regularization penalty. Finally, a real data set is analyzed by the new proposed Bayesian estimation method.",
        "comments": "16 pages, 7 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13787"
    },
    {
        "doc_id": 57,
        "title": "Revisiting the memoryless property -- testing for the Pareto type I distribution",
        "authors": [
            "Lethani Ndwandwe",
            "James Allison",
            "Leonard Santana",
            "Jaco Visagie"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "We propose new goodness-of-fit tests for the Pareto type I distribution. These tests are based on a multiplicative version of the memoryless property which characterises this distribution. We present the results of a Monte Carlo power study demonstrating that the proposed tests are powerful compared to existing tests. As a result of independent interest, we demonstrate that tests specifically developed for the Pareto type I distribution substantially outperform tests for exponentiality applied to log-transformed data (since Pareto type I distributed values can be transformed to exponentiality via a simple log-transformation). Specifically, the newly proposed tests based on the multiplicative memoryless property of the Pareto distribution substantially outperform a test based on the memoryless property of the exponential distribution. The practical use of tests is illustrated by testing the hypothesis that two sets of observed golfers' earnings (those of the PGA and LIV tours) are realised from Pareto distributions.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13777"
    },
    {
        "doc_id": 58,
        "title": "Early Detection of Treatments Side Effect: A Sequential Approach",
        "authors": [
            "Jiayue Wang",
            "Ben Boukai"
        ],
        "subjects": [
            "Applications",
            "Statistics Theory"
        ],
        "abstract": "With the emergence and spread of infectious diseases with pandemic potential, such as COVID- 19, the urgency for vaccine development have led to unprecedented compressed and accelerated schedules that shortened the standard development timeline. In a relatively short time, the leading pharmaceutical companies1, received an Emergency Use Authorization (EUA) for vaccine\\prime s en-mass deployment To monitor the potential side effect(s) of the vaccine during the (initial) vaccination campaign, we developed an optimal sequential test that allows for the early detection of potential side effect(s). This test employs a rule to stop the vaccination process once the observed number of side effect incidents exceeds a certain (pre-determined) threshold. The optimality of the proposed sequential test is justified when compared with the (\u03b1, \u03b2) optimality of the non-randomized fixed-sample Uniformly Most Powerful (UMP) test. In the case of a single side effect, we study the properties of the sequential test and derive the exact expressions of the Average Sample Number (ASN) curve of the stopping time (and its variance) via the regularized incomplete beta function. Additionally, we derive the asymptotic distribution of the relative savings in ASN as compared to maximal sample size. Moreover, we construct the post-test parameter estimate and studied its sampling properties, including its asymptotic behavior under local-type alternatives. These limiting behavior results are the consistency and asymptotic normality of the post-test parameter estimator. We conclude the paper with a small simulation study illustrating the asymptotic performance of the point and interval estimation and provide a detailed example, based on COVID-19 side effect data (see Beatty et al. (2021)) of our suggested testing procedure.",
        "comments": "There are 21 pages, 8 pictures and 4 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13760"
    },
    {
        "doc_id": 59,
        "title": "Assumptions and Bounds in the Instrumental Variable Model",
        "authors": [
            "Thomas S. Richardson",
            "James M. Robins"
        ],
        "subjects": [
            "Statistics Theory",
            "Artificial Intelligence"
        ],
        "abstract": "In this note we give proofs for results relating to the Instrumental Variable (IV) model with binary response $Y$ and binary treatment $X$, but with an instrument $Z$ that takes $K$ states that were originally stated in Richardson & Robins (2014), \"ACE Bounds; SEMS with Equilibrium Conditions,\" arXiv:1410.0470.",
        "comments": "27 pages, 1 figure, 1 table. Proofs of Theorems 1 and 2 stated in Richardson and Robins (2014), arXiv:1410.0470",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13758"
    },
    {
        "doc_id": 60,
        "title": "A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks",
        "authors": [
            "Charles Meyers",
            "Mohammad Reza Saleh Sedghpour",
            "Tommy L\u00f6fstedt",
            "Erik Elmroth"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Convolutional neural networks have shown to be widely applicable to a large number of fields when large amounts of labelled data are available. The recent trend has been to use models with increasingly larger sets of tunable parameters to increase model accuracy, reduce model loss, or create more adversarially robust models -- goals that are often at odds with one another. In particular, recent theoretical work raises questions about the ability for even larger models to generalize to data outside of the controlled train and test sets. As such, we examine the role of the number of hidden layers in the ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test a variety of parameters including the size of the model, the floating point precision, and the noise level of both the training data and the model output. To encapsulate the model's predictive power and computational cost, we provide a method that uses induced failures to model the probability of failure as a function of time and relate that to a novel metric that allows us to quickly determine whether or not the cost of training a model outweighs the cost of attacking it. Using this approach, we are able to approximate the expected failure rate using a small number of specially crafted samples rather than increasingly larger benchmark datasets. We demonstrate the efficacy of this technique on both the MNIST and CIFAR10 datasets using 8-, 16-, 32-, and 64-bit floating-point numbers, various data pre-processing techniques, and several attacks on five configurations of the ResNet model. Then, using empirical measurements, we examine the various trade-offs between cost, robustness, latency, and reliability to find that larger models do not significantly aid in adversarial robustness despite costing significantly more to train.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13751"
    },
    {
        "doc_id": 61,
        "title": "Conformal Prediction Sets Improve Human Decision Making",
        "authors": [
            "Jesse C. Cresswell",
            "Yi Sui",
            "Bhargava Kumar",
            "No\u00ebl Vouitsis"
        ],
        "subjects": [
            "Machine Learning",
            "Human-Computer Interaction",
            "Machine Learning"
        ],
        "abstract": "In response to everyday queries, humans explicitly signal uncertainty and offer alternative answers when they are unsure. Machine learning models that output calibrated prediction sets through conformal prediction mimic this human behaviour; larger sets signal greater uncertainty while providing alternatives. In this work, we study the usefulness of conformal prediction sets as an aid for human decision making by conducting a pre-registered randomized controlled trial with conformal prediction sets provided to human subjects. With statistical significance, we find that when humans are given conformal prediction sets their accuracy on tasks improves compared to fixed-size prediction sets with the same coverage guarantee. The results show that quantifying model uncertainty with conformal prediction is helpful for human-in-the-loop decision making and human-AI teams.",
        "comments": "Code available at https://github.com/layer6ai-labs/hitl-conformal-prediction",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13744"
    },
    {
        "doc_id": 62,
        "title": "The $M_{\\rm BH}-M_*$ relation up to $z\\sim2$ through decomposition of COSMOS-Web NIRCam images",
        "authors": [
            "Takumi S. Tanaka",
            "John D. Silverman",
            "Xuheng Ding",
            "Knud Jahnke",
            "Benny Trakhtenbrot",
            "Erini Lambrides",
            "Masafusa Onoue",
            "Irham Taufik Andika",
            "Angela Bongiorno",
            "Andreas L. Faisst",
            "Steven Gillman",
            "Christopher C. Hayward",
            "Michaela Hirschmann",
            "Anton Koekemoer",
            "Vasily Kokorev",
            "Zhaoxuan Liu",
            "Georgios E. Magdis",
            "Alvio Renzini",
            "Caitlin Casey",
            "Nicole E. Drakos",
            "Maximilien Franco",
            "Ghassem Gozaliasl",
            "Jeyhan Kartaltepe",
            "Daizhong Liu",
            "Henry Joy McCracken",
            "et al. (3 additional authors not shown)"
        ],
        "subjects": [
            "Astrophysics of Galaxies"
        ],
        "abstract": "Our knowledge of relations between supermassive black holes and their host galaxies at $z\\gtrsim1$ is still limited, even though being actively sought out to $z\\sim6$. Here, we use the high resolution and sensitivity of JWST to measure the host galaxy properties for 61 X-ray-selected type-I AGNs at $0.7<z<2.5$ with rest-frame optical/near-infrared imaging from COSMOS-Web and PRIMER. Black hole masses ($\\log\\left(M_{\\rm BH}/M_\\odot\\right)\\sim7.5-9.5$) are available from previous spectroscopic campaigns. We extract the host galaxy components from four NIRCam broadband images and the HST/ACS F814W image by applying a 2D image decomposition technique. We detect the host galaxy for $\\sim90\\%$ of the sample after subtracting the unresolved AGN emission. With host photometry free of AGN emission, we determine the stellar mass of the host galaxies to be $\\log\\left(M_*/M_\\odot\\right)\\sim10-11.5$ through SED fitting and measure the evolution of the mass relation between SMBHs and their host galaxies. Considering selection biases and measurement uncertainties, we find that the $M_\\mathrm{ BH}/M_*$ ratio evolves as $\\left(1+z\\right)^{0.37_{-0.60}^{+0.35}}$ thus remains essentially constant or exhibits mild evolution up to $z\\sim2.5$. We also see an amount of scatter ($\u03c3_\u03bc=0.28\\pm0.13$) is similar to the local relation and consistent with low-$z$ studies; this appears to not rule out non-causal cosmic assembly where mergers contribute to the statistical averaging towards the local relation. We highlight improvements to come with larger samples from JWST and, particularly, Euclid, which will exceed the statistical power of wide and deep surveys such as Subaru Hyper Suprime-Cam.",
        "comments": "31 pages, 19 figures, submitted to ApJ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13742"
    },
    {
        "doc_id": 63,
        "title": "Restoration of the Tully-Fisher Relation by Statistical Rectification",
        "authors": [
            "Hai Fu"
        ],
        "subjects": [
            "Astrophysics of Galaxies",
            "Instrumentation and Methods for Astrophysics"
        ],
        "abstract": "I employ the Lucy rectification algorithm to recover the inclination-corrected distribution of local disk galaxies in the plane of absolute magnitude ($M_i$) and \\HI\\ velocity width ($W_{20}$). By considering the inclination angle as a random variable with a known probability distribution, the novel approach eliminates one major source of uncertainty in studies of the Tully-Fisher relation: inclination angle estimation from axial ratio. Leveraging the statistical strength derived from the entire sample of 28,264 \\HI-selected disk galaxies at $z < 0.06$ from the Arecibo Legacy Fast ALFA (ALFALFA) survey, I show that the restored distribution follows a sharp correlation that is approximately a power law between $-16 > M_i > -22$: $M_i = M_0 - 2.5\u03b2\\ [\\log(W_{\\rm 20}/250 {\\rm km/s})]$, with $M_0 = -19.77\\pm0.04$ and $\u03b2= 4.39\\pm0.06$. At the brighter end ($M_i < -22$), the slope of the correlation decreases to $\u03b2\\approx 3.3$, confirming previous results. Because the method accounts for measurement errors, the intrinsic dispersion of the correlation is directly measured: $\u03c3(\\log W_{20}) \\approx 0.06$\\,dex between $-17 > M_i > -23$, while $\u03c3(M_i)$ decreases from $\\sim$0.8 in slow rotators to $\\sim$0.4 in fast rotators. The statistical rectification method holds significant potential, especially in the studies of intermediate-to-high-redshift samples, where limited spatial resolution hinders precise measurements of inclination angles.",
        "comments": "Resubmitted to ApJ Letters. Python notebook and data files are available at https://github.com/fuhaiastro/TFR_Lucy",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13738"
    },
    {
        "doc_id": 64,
        "title": "Is GN-z11 powered by a super-Eddington massive black hole?",
        "authors": [
            "Maulik Bhatt",
            "Simona Gallerani",
            "Andrea Ferrara",
            "Chiara Mazzucchelli",
            "Valentina D'Odorico",
            "Milena Valentini",
            "Tommaso Zana",
            "Emanuele Paolo Farina",
            "Srija Chakraborty"
        ],
        "subjects": [
            "Astrophysics of Galaxies",
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "Observations of $z \\sim 6$ quasars powered by super-massive black holes (SMBHs, $M_{\\rm BH} \\sim 10^{8-10}\\, M_\\odot$) challenge our current understanding of early black hole formation and evolution. The advent of the James Webb Space Telescope (JWST) has enabled the study of massive black holes (MBHs, $M_{\\rm BH}\\sim 10^{6-7} \\ \\mathrm{M}_\\odot$) up to $z\\sim 11$, thus bridging the properties of $z\\sim 6$ quasars to their ancestors. JWST spectroscopic observations of GN-z11, a well-known $z=10.6$ star forming galaxy, have been interpreted with the presence of a super-Eddington (Eddington ratio $\\equiv \\,\u03bb_{\\rm Edd}\\sim 5.5$) accreting MBH. To test this hypothesis we use a zoom-in cosmological simulation of galaxy formation and BH co-evolution. We first test the simulation results against the observed probability distribution function (PDF) of $\u03bb_{\\rm Edd}$ found in $z\\sim 6$ quasars. Then, we select in the simulation those BHs that satisfy the following criteria: (a) $10 < z < 11 $, (b) $M_{\\rm BH} > 10^6 \\ \\mathrm{M}_\\odot$. Finally we apply the Extreme Value Statistics to the PDF of $\u03bb_{\\rm Edd}$ resulting from the simulation and find that the probability of observing a $z\\sim 10-11$ MBH, accreting with $\u03bb_{\\rm Edd} \\sim 5.5$, in the volume surveyed by JWST, is very low ($<0.5\\%$). We compare our predictions with those in the literature and further discuss the main limitations of our work. Our simulation cannot explain the JWST observations of GN-z11. This might be due to (i) missing physics in simulations, or (ii) uncertainties in the data analysis.",
        "comments": "8 pages, 2 figures; Submitted to A&A",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13733"
    },
    {
        "doc_id": 65,
        "title": "Origin of the Stochastic Gravitational Wave Background: First-Order Phase Transition vs. Black Hole Mergers",
        "authors": [
            "Martin Wolfgang Winkler",
            "Katherine Freese"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics",
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The NANOGrav, Parkes and European Pulsar Timing Array (PTA) experiments have collected strong evidence for a stochastic gravitational wave background in the nHz-frequency band. In this work we perform a detailed statistical analysis of the signal in order to elucidate its physical origin. Specifically, we test the standard explanation in terms of supermassive black hole mergers against the prominent alternative explanation in terms of a first-order phase transition. By means of a frequentist hypothesis test we find that the observed gravitational wave spectrum prefers a first-order phase transition at $2-3\u03c3$ significance compared to black hole mergers (depending on the underlying black hole model). This mild preference is linked to the relatively large amplitude of the observed gravitational wave signal (above the typical expectation of black hole models) and to its spectral shape (which slightly favors the phase-transition spectrum over the predominantly single power-law spectrum predicted in black hole models). The best fit to the combined PTA data set is obtained for a phase transition which dominantly produces the gravitational wave signal by bubble collisions (rather than by sound waves). The best-fit (energy-density) spectrum features, within the frequency band of the PTA experiments, a crossover from a steeply rising power law (causality tail) to a softly rising power law; the peak frequency then falls slightly above the PTA-measured range. Such a spectrum can be obtained for a strong first-order phase transition in the thick-wall regime of vacuum tunneling which reheats the Universe to a temperature of $T_*\\sim \\text{GeV}$. A dark sector phase transition at the GeV-scale provides a comparably good fit.",
        "comments": "26 pages, 8 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13729"
    },
    {
        "doc_id": 66,
        "title": "Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare",
        "authors": [
            "Vibeke Binz Vallevik",
            "Aleksandar Babic",
            "Serena Elizabeth Marshall",
            "Severin Elvatun",
            "Helga Br\u00f8gger",
            "Sharmini Alagaratnam",
            "Bj\u00f8rn Edwin",
            "Narasimha Raghavan Veeraragavan",
            "Anne Kjersti Befring",
            "Jan Franz Nyg\u00e5rd"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Ensuring safe adoption of AI tools in healthcare hinges on access to sufficient data for training, testing and validation. In response to privacy concerns and regulatory requirements, using synthetic data has been suggested. Synthetic data is created by training a generator on real data to produce a dataset with similar statistical properties. Competing metrics with differing taxonomies for quality evaluation have been suggested, resulting in a complex landscape. Optimising quality entails balancing considerations that make the data fit for use, yet relevant dimensions are left out of existing frameworks. We performed a comprehensive literature review on the use of quality evaluation metrics on SD within the scope of tabular healthcare data and SD made using deep generative methods. Based on this and the collective team experiences, we developed a conceptual framework for quality assurance. The applicability was benchmarked against a practical case from the Dutch National Cancer Registry. We present a conceptual framework for quality assurance of SD for AI applications in healthcare that aligns diverging taxonomies, expands on common quality dimensions to include the dimensions of Fairness and Carbon footprint, and proposes stages necessary to support real-life applications. Building trust in synthetic data by increasing transparency and reducing the safety risk will accelerate the development and uptake of trustworthy AI tools for the benefit of patients. Despite the growing emphasis on algorithmic fairness and carbon footprint, these metrics were scarce in the literature review. The overwhelming focus was on statistical similarity using distance metrics while sequential logic detection was scarce. A consensus-backed framework that includes all relevant quality dimensions can provide assurance for safe and responsible real-life applications of SD.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13716"
    },
    {
        "doc_id": 67,
        "title": "Accelerating hyperbolic t-SNE",
        "authors": [
            "Martin Skrodzki",
            "Hunter van Geffen",
            "Nicolas F. Chaves-de-Plaza",
            "Thomas H\u00f6llt",
            "Elmar Eisemann",
            "Klaus Hildebrandt"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods",
            "Machine Learning"
        ],
        "abstract": "The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13708"
    },
    {
        "doc_id": 68,
        "title": "Determinants of the Propensity for Innovation among Entrepreneurs in the Tourism Industry",
        "authors": [
            "Miguel Angel Montanes-Del-Rio",
            "Jose Aurelio Medina-Garrido"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Tourism's increasing share of Gross Domestic Product throughout the world, its impact on employment and its continuous growth justifies the interest it raises amongst entrepreneurs and public authorities. However, this growth coexists with intense competition; as a result of which, tourism companies must continuously innovate in order to survive and grow. This is evident in the diversification of tourism products and destinations, the improvement of business processes and the incorporation of new technologies for intermediation, amongst other examples. This paper expounds on the factors that explain the propensity for innovation amongst tourism entrepreneurs and it may help governments to promote innovation that is based on those determining factors. The hypotheses are tested using a logistic regression on 699 international tourism entrepreneurs, taken from the 2014 Global Adult Population Survey of the Global Entrepreneurship Monitor project. The propensity for innovation amongst tourism entrepreneurs has a statistically significant relationship to gender, age, level of education and informal investments in previous businesses.",
        "comments": "Journal ref:        Sustainability 12:5003 (2020)",
        "date": "5 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13679"
    },
    {
        "doc_id": 69,
        "title": "Analisis de la incidencia de la inversion extranjera directa y la inversion nacional, en el crecimiento economico de Chile",
        "authors": [
            "Alvear Guzman Katherine",
            "Campozano Buele Jenner",
            "Duran Canarte Paulette",
            "Holguin Cedeno Roger",
            "Mejia Crespin Fernando"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The research aims to assess the impact of foreign direct investment (FDI) and domestic investment on Chile's economic growth. By elucidating the relationship between FDI and domestic investment, the study contributes valuable insights for economic policy formulation and future investments. The findings hold significance in shaping Chile's international perception as an investment destination, potentially influencing its standing in the global economic landscape. Demonstrating that FDI is a significant driver of economic growth could enhance confidence among foreign investors. The project's importance lies in contributing to economic knowledge and guiding strategic decisions for sustainable economic growth in Chile. Understanding the interplay of FDI and domestic investment allows for a balanced approach, promoting stable economic development and mitigating issues like excessive reliance on foreign investment. The study highlights the theory of internationalization as a conceptual framework for understanding the motives and strategies of multinational companies investing abroad. Leveraging data from sources like the Central Bank of Chile, the research analyzes variables such as Chile's economic growth (GDP), FDI, and domestic investment. The hypothesis posits a significant long-term causal relationship between FDI, National Investment (NI), and Chile's Economic Growth (GDP). Statistical analysis using the Eviews 6 software tool confirms that attracting foreign investments and promoting internal investment are imperative for sustainable economic growth in Chile.",
        "comments": "in Spanish language",
        "date": "13 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13674"
    },
    {
        "doc_id": 70,
        "title": "Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach",
        "authors": [
            "Yuling Yan",
            "Martin J. Wainwright"
        ],
        "subjects": [
            "Statistics Theory",
            "Econometrics",
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\u00e9r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13665"
    },
    {
        "doc_id": 71,
        "title": "Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity",
        "authors": [
            "Ernesto Colacrai",
            "Federico Cinus",
            "Gianmarco De Francisci Morales",
            "Michele Starnini"
        ],
        "subjects": [
            "Social and Information Networks",
            "Computers and Society",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy. While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies. In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass. We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022. By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes. In addition, we characterize users by their demographic attributes (age, gender, and affluence).\n  We find significant homophily for interactions along the social axis of the political compass and demographic attributes. Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%. In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%. Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology. Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions. By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13656"
    },
    {
        "doc_id": 72,
        "title": "The limitations (and potential) of non-parametric morphology statistics for post-merger identification",
        "authors": [
            "Scott Wilkinson",
            "Sara L. Ellison",
            "Connor Bottrell",
            "Robert W. Bickley",
            "Shoshannah Byrne-Mamahit",
            "Leonardo Ferreira",
            "David R. Patton"
        ],
        "subjects": [
            "Astrophysics of Galaxies"
        ],
        "abstract": "Non-parametric morphology statistics have been used for decades to classify galaxies into morphological types and identify mergers in an automated way. In this work, we assess how reliably we can identify galaxy post-mergers with non-parametric morphology statistics. Low-redshift (z<0.2), recent (t_post-merger < 200 Myr), and isolated (r > 100 kpc) post-merger galaxies are drawn from the IllustrisTNG100-1 cosmological simulation. Synthetic r-band images of the mergers are generated with SKIRT9 and degraded to various image qualities, adding observational effects such as sky noise and atmospheric blurring. We find that even in perfect quality imaging, the individual non-parametric morphology statistics fail to recover more than 55% of the post-mergers, and that this number decreases precipitously with worsening image qualities. The realistic distributions of galaxy properties in IllustrisTNG allow us to show that merger samples assembled using individual morphology statistics are biased towards low mass, high gas fraction, and high mass ratio. However, combining all of the morphology statistics together using either a linear discriminant analysis or random forest algorithm increases the completeness and purity of the identified merger samples and mitigates bias with various galaxy properties. For example, we show that in imaging similar to that of the 10-year depth of the Legacy Survey of Space and Time (LSST), a random forest can identify 89% of mergers with a false positive rate of 17%. Finally, we conduct a detailed study of the effect of viewing angle on merger observability and find that there may be an upper limit to merger recovery due to the orientation of merger features with respect to the observer.",
        "comments": "32 pages, 21 figures Accepted for publication by MNRAS",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13654"
    },
    {
        "doc_id": 73,
        "title": "Unveiling homophily beyond the pool of opportunities",
        "authors": [
            "Sina Sajjadi",
            "Samuel Martin-Gutierrez",
            "Fariba Karimi"
        ],
        "subjects": [
            "Physics and Society"
        ],
        "abstract": "Unveiling individuals' preferences for connecting with similar others (choice homophily) beyond the structural factors determining the pool of opportunities, is a challenging task. Here, we introduce a robust methodology for quantifying and inferring choice homophily in a variety of social networks. Our approach employs statistical network ensembles to estimate and standardize homophily measurements. We control for group size imbalances and activity disparities by counting the number of possible network configurations with a given number of inter-group links using combinatorics. This method provides a principled measure of connection preferences and their confidence intervals. Our framework is versatile, suitable for undirected and directed networks, and applicable in scenarios involving multiple groups. To validate our inference method, we test it on synthetic networks and show that it outperforms traditional metrics. Our approach accurately captures the generative homophily used to build the networks, even when we include additional tie-formation mechanisms, such as preferential attachment and triadic closure. Results show that while triadic closure has some influence on the inference, its impact is small in homophilic networks. On the other hand, preferential attachment does not perturb the results of the inference method. We apply our method to real-world networks, demonstrating its effectiveness in unveiling underlying gender homophily. Our method aligns with traditional metrics in networks with balanced populations, but we obtain different results when the group sizes or degrees are imbalanced. This finding highlights the importance of considering structural factors when measuring choice homophily in social networks.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13642"
    },
    {
        "doc_id": 74,
        "title": "Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint",
        "authors": [
            "Zhongjie Shi",
            "Fanghui Liu",
            "Yuan Cao",
            "Johan A. K. Suykens"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \\textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear over-parameterization (meaning that the number of parameters is only slightly larger than the sample size) is enough to ensure such existence if the target function is smooth enough. iii) For regression, our results demonstrate that there also exist infinitely many overfitted DNNs with linear over-parameterization in adversarial training that can achieve almost optimal rates of convergence for the standard generalization error. Overall, our analysis points out that robust overfitting can be avoided but the required model capacity will depend on the smoothness of the target function, while a robust generalization gap is inevitable. We hope our analysis will give a better understanding of the mathematical foundations of robustness in DNNs from an approximation view.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13624"
    },
    {
        "doc_id": 75,
        "title": "The assessment of replicability using the sum of p-values",
        "authors": [
            "Leonhard Held",
            "Samuel Pawel",
            "Charlotte Micheloud"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Statistical significance of both the original and the replication study is a commonly used criterion to assess replication attempts, also known as the two-trials rule in drug development. However, replication studies are sometimes conducted although the original study is non-significant, in which case Type-I error rate control across both studies is no longer guaranteed. We propose an alternative method to assess replicability using the sum of p-values from the two studies. The approach provides a combined p-value and can be calibrated to control the overall Type-I error rate at the same level as the two-trials rule but allows for replication success even if the original study is non-significant. The unweighted version requires a less restrictive level of significance at replication if the original study is already convincing which facilitates sample size reductions of up to 10%. Downweighting the original study accounts for possible bias and requires a more stringent significance level and larger samples sizes at replication. Data from four large-scale replication projects are used to illustrate and compare the proposed method with the two-trials rule, meta-analysis and Fisher's combination method.",
        "comments": "6 figures, 0 tables, 1 box",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13615"
    },
    {
        "doc_id": 76,
        "title": "The Doob transform and the tree behind the forest, with application to near-critical dimers",
        "authors": [
            "Lucas Rey"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "The Doob transform technique enables the study of a killed random walk (KRW) via a random walk (RW) with transition probabilities tilted by a discrete massive harmonic function. The main contribution of this paper is to transfer this powerful technique to statistical mechanics by relating two models, namely random rooted spanning forests (RSF) and random spanning trees (RST), and provide applications. More precisely, our first main theorem explicitly relates models on the level of partition functions, and probability measures, in the case of finite and infinite graphs. Then, in the planar case, we also rely on the dimer model: we introduce a killed and a drifted dimer model, extending to this general framework the models introduced in [Chh12,dT20]. Using Temperley's bijection between RST and dimers, this allows us to relate RSF to dimers and thus extend partially this bijection to RSF. As immediate applications, we give a short and transparent proof of Kenyon's result stating that the spectral curve of RSF is a Harnack curve, and provide a general setting to relate discrete massive holomorphic and harmonic functions. The other important application consists in proving universality of the convergence of the near-critical loop-erased RW, RST and dimer models by extending the results of [Chh12,CW21,HSB22] from the square lattice to any isoradial graphs: we introduce a loop erased RW, RST and dimer model on isoradial discretizations of any simply connected domain and prove convergence in the massive scaling limit towards continuous objects described by a massive version of SLE2.",
        "comments": "50 pages, 8 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13599"
    },
    {
        "doc_id": 77,
        "title": "WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition",
        "authors": [
            "Zhengyao Song",
            "Yongqiang Li",
            "Danni Yuan",
            "Li Liu",
            "Shaokui Wei",
            "Baoyuan Wu"
        ],
        "subjects": [
            "Cryptography and Security"
        ],
        "abstract": "This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack. In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference. Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods. In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings. We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions. Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods. Besides, we also provide visualization analyses to explain why our method works.",
        "comments": "13 pages, 21 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13578"
    },
    {
        "doc_id": 78,
        "title": "Rare event probability estimation for groundwater inverse problems with a two-stage Sequential Monte Carlo approach",
        "authors": [
            "Lea Friedli",
            "Niklas Linde"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "Bayesian inversions followed by estimations of rare event probabilities are often needed to analyse groundwater hazards. Instead of focusing on the posterior distribution of model parameters, the main interest lies then in the distribution of a specific quantity of interest contingent upon these parameters. To address the associated methodological challenges, we introduce a two-stage Sequential Monte Carlo approach. In the first stage, it generates particles that approximate the posterior distribution; in the second stage, it employs subset sampling techniques to assess the probability of the rare event of interest. By considering two hydrogeological problems of increasing complexity, we showcase the efficiency and accuracy of the resulting PostRisk-SMC method for rare event probability estimation related to groundwater hazards. We compare the performance of the PostRisk-SMC method with a traditional Monte Carlo approach that relies on Markov chain Monte Carlo samples. We showcase that our estimates align with those of the traditional method, but the coefficients of variation are notably lower for the same computational budget when targeting more rare events. Furthermore, we highlight that the PostRisk-SMC method allows estimating rare event probabilities approaching one in a billion using less than one hundred thousand forward simulations. Even if the presented examples are related to groundwater hazards, the methodology is well-suited for addressing a wide range of topics in the geosciences and beyond.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13572"
    },
    {
        "doc_id": 79,
        "title": "Benchmarking the Fairness of Image Upsampling Methods",
        "authors": [
            "Mike Laszkiewicz",
            "Imant Daunhawer",
            "Julia E. Vogt",
            "Asja Fischer",
            "Johannes Lederer"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\\unicode{x2013}$inspired by their supervised fairness counterparts$\\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to dataset imbalances. Alarmingly, we find that none of the considered methods produces statistically fair and diverse results.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13555"
    },
    {
        "doc_id": 80,
        "title": "Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?",
        "authors": [
            "Ri\u010dards Marcinkevi\u010ds",
            "Sonia Laguna",
            "Moritz Vandenhirtz",
            "Julia E. Vogt"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the practical utility of the proposed techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes can be as intervenable and more performant than CBMs.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13544"
    },
    {
        "doc_id": 81,
        "title": "Functional weak convergence of stochastic integrals for moving averages and continuous-time random walks",
        "authors": [
            "Andreas S\u00f8jmark",
            "Fabrice Wunderlich"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "There is by now an extensive and well-developed theory of weak convergence for moving averages and continuous-time random walks (CTRWs) with respect to Skorokhod's M1 and J1 topologies. Here we address the fundamental question of how this translates into functional limit theorems, in the M1 or J1 topology, for stochastic integrals driven by these processes. As a key application, we provide weak approximation results for a general class of SDEs driven by time-changed L\u00e9vy processes. Such SDEs and their associated fractional Fokker--Planck--Kolmogorov equations are central to models of anomalous diffusion in statistical physics, and our results provide a rigorous functional characterisation of these as continuum limits of the corresponding models driven by CTRWs. In regard to strictly M1 convergent moving averages and so-called correlated CTRWs, it turns out that the convergence of stochastic integrals can fail markedly. Nevertheless, we are able to identify natural classes of integrand processes for which the convergence holds. We end by showing that these results are general enough to yield functional limit theorems, in the M1 topology, for certain stochastic delay differential equations driven by moving averages.",
        "comments": "43 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13543"
    },
    {
        "doc_id": 82,
        "title": "Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models",
        "authors": [
            "Lukas Heinrich",
            "Tobias Golling",
            "Michael Kagan",
            "Samuel Klein",
            "Matthew Leigh",
            "Margarita Osadchy",
            "John Andrew Raine"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Machine Learning",
            "High Energy Physics - Experiment",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "We propose masked particle modeling (MPM) as a self-supervised method for learning generic, transferable, and reusable representations on unordered sets of inputs for use in high energy physics (HEP) scientific data. This work provides a novel scheme to perform masked modeling based pre-training to learn permutation invariant functions on sets. More generally, this work provides a step towards building large foundation models for HEP that can be generically pre-trained with self-supervised learning and later fine-tuned for a variety of down-stream tasks. In MPM, particles in a set are masked and the training objective is to recover their identity, as defined by a discretized token representation of a pre-trained vector quantized variational autoencoder. We study the efficacy of the method in samples of high energy jets at collider physics experiments, including studies on the impact of discretization, permutation invariance, and ordering. We also study the fine-tuning capability of the model, showing that it can be adapted to tasks such as supervised and weakly supervised jet classification, and that the model can transfer efficiently with small fine-tuning data sets to new classes and new data domains.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13537"
    },
    {
        "doc_id": 83,
        "title": "Finetuning Foundation Models for Joint Analysis Optimization",
        "authors": [
            "Matthias Vigl",
            "Nicole Hartman",
            "Lukas Heinrich"
        ],
        "subjects": [
            "High Energy Physics - Experiment",
            "Machine Learning",
            "High Energy Physics - Phenomenology",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "In this work we demonstrate that significant gains in performance and data efficiency can be achieved in High Energy Physics (HEP) by moving beyond the standard paradigm of sequential optimization or reconstruction and analysis components. We conceptually connect HEP reconstruction and analysis to modern machine learning workflows such as pretraining, finetuning, domain adaptation and high-dimensional embedding spaces and quantify the gains in the example usecase of searches of heavy resonances decaying via an intermediate di-Higgs system to four $b$-jets.",
        "comments": "13 pages, 12 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13536"
    },
    {
        "doc_id": 84,
        "title": "Depth Patterns",
        "authors": [
            "Annika Betken",
            "Alexander Schnurr"
        ],
        "subjects": [
            "Statistics Theory",
            "Probability"
        ],
        "abstract": "We establish a definition of ordinal patterns for multivariate time series data based on the concept of Tukey's halfspace depth. Given the definition of these \\emph{depth patterns}, we are interested in the probabilities of observing specific patterns in a time series. For this, we consider the relative frequency of depth patterns as natural estimators for their occurrence probabilities. Depending on the choice of reference distribution and the relation between reference and data distribution, we distinguish different settings that are considered separately. Within these settings we study statistical properties of ordinal pattern probabilities, establishing consistency and asymptotic normality under the assumption of weakly dependent time series data. Since our concept only depends on ordinal depth information, the resulting values are robust under small perturbations and measurement errors.",
        "comments": "MSC Class:          62M10; 62H10; 62H12; 60F05",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13532"
    },
    {
        "doc_id": 85,
        "title": "Detecting local perturbations of networks in a latent hyperbolic space",
        "authors": [
            "Alice Longhena",
            "Martin Guillemaud",
            "Mario Chavez"
        ],
        "subjects": [
            "Quantitative Methods",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Graph theoretical approaches have been proven to be effective in the characterization of connected systems, as well as in quantifying their dysfunction due to perturbation. In this paper, we show the advantage of a non-Euclidean (hyperbolic) representation of networks to identify local connectivity perturbations and to characterize the induced effects on a large scale. We propose two perturbation scores based on representations of the networks in a latent geometric space, obtained through an embedding onto the hyperbolic Poincar\u00e9 disk. We numerically demonstrate that these methods are able to localize perturbations in networks with homogeneous or heterogeneous degree connectivity. We apply this framework to identify the most perturbed brain areas in epileptic patients following surgery. This study is conceived in the effort of developing more powerful tools to represent and analyze brain networks, and it is the first to apply geometric network embedding techniques to the case of epilepsy.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13495"
    },
    {
        "doc_id": 86,
        "title": "Detection of Correlated Random Vectors",
        "authors": [
            "Dor Elimelech",
            "Wasim Huleihel"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning",
            "Statistics Theory"
        ],
        "abstract": "In this paper, we investigate the problem of deciding whether two standard normal random vectors $\\mathsf{X}\\in\\mathbb{R}^{n}$ and $\\mathsf{Y}\\in\\mathbb{R}^{n}$ are correlated or not. This is formulated as a hypothesis testing problem, where under the null hypothesis, these vectors are statistically independent, while under the alternative, $\\mathsf{X}$ and a randomly and uniformly permuted version of $\\mathsf{Y}$, are correlated with correlation $\u03c1$. We analyze the thresholds at which optimal testing is information-theoretically impossible and possible, as a function of $n$ and $\u03c1$. To derive our information-theoretic lower bounds, we develop a novel technique for evaluating the second moment of the likelihood ratio using an orthogonal polynomials expansion, which among other things, reveals a surprising connection to integer partition functions. We also study a multi-dimensional generalization of the above setting, where rather than two vectors we observe two databases/matrices, and furthermore allow for partial correlations between these two.",
        "comments": "34 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13429"
    },
    {
        "doc_id": 87,
        "title": "Text Categorization Can Enhance Domain-Agnostic Stopword Extraction",
        "authors": [
            "Houcemeddine Turki",
            "Naome A. Etori",
            "Mohamed Ali Hadj Taieb",
            "Abdul-Hakeem Omotayo",
            "Chris Chinenye Emezue",
            "Mohamed Ben Aouicha",
            "Ayodele Awokoya",
            "Falalu Ibrahim Lawan",
            "Doreen Nixdorf"
        ],
        "subjects": [
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "This paper investigates the role of text categorization in streamlining stopword extraction in natural language processing (NLP), specifically focusing on nine African languages alongside French. By leveraging the MasakhaNEWS, African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that text categorization effectively identifies domain-agnostic stopwords with over 80% detection success rate for most examined languages. Nevertheless, linguistic variances result in lower detection rates for certain languages. Interestingly, we find that while over 40% of stopwords are common across news categories, less than 15% are unique to a single category. Uncommon stopwords add depth to text but their classification as stopwords depends on context. Therefore combining statistical and linguistic approaches creates comprehensive stopword lists, highlighting the value of our hybrid method. This research enhances NLP for African languages and underscores the importance of text categorization in stopword extraction.",
        "comments": "A Project Report for the Masakhane Research Community",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13398"
    },
    {
        "doc_id": 88,
        "title": "An Ising Similarity Regression Model for Modeling Multivariate Binary Data",
        "authors": [
            "Zhi Yang Tho",
            "Francis K. C. Hui",
            "Tao Zou"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory",
            "Applications"
        ],
        "abstract": "Understanding the dependence structure between response variables is an important component in the analysis of correlated multivariate data. This article focuses on modeling dependence structures in multivariate binary data, motivated by a study aiming to understand how patterns in different U.S. senators' votes are determined by similarities (or lack thereof) in their attributes, e.g., political parties and social network profiles. To address such a research question, we propose a new Ising similarity regression model which regresses pairwise interaction coefficients in the Ising model against a set of similarity measures available/constructed from covariates. Model selection approaches are further developed through regularizing the pseudo-likelihood function with an adaptive lasso penalty to enable the selection of relevant similarity measures. We establish estimation and selection consistency of the proposed estimator under a general setting where the number of similarity measures and responses tend to infinity. Simulation study demonstrates the strong finite sample performance of the proposed estimator in terms of parameter estimation and similarity selection. Applying the Ising similarity regression model to a dataset of roll call voting records of 100 U.S. senators, we are able to quantify how similarities in senators' parties, businessman occupations and social network profiles drive their voting associations.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13379"
    },
    {
        "doc_id": 89,
        "title": "Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems",
        "authors": [
            "Jikun Gao",
            "Ioannis Mavromatis",
            "Peizheng Li",
            "Pietro Carnelli",
            "Aftab Khan"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Federated learning (FL) systems face performance challenges in dealing with heterogeneous devices and non-identically distributed data across clients. We propose a dynamic global model aggregation method within Asynchronous Federated Learning (AFL) deployments to address these issues. Our aggregation method scores and adjusts the weighting of client model updates based on their upload frequency to accommodate differences in device capabilities. Additionally, we also immediately provide an updated global model to clients after they upload their local models to reduce idle time and improve training efficiency. We evaluate our approach within an AFL deployment consisting of 10 simulated clients with heterogeneous compute constraints and non-IID data. The simulation results, using the FashionMNIST dataset, demonstrate over 10% and 19% improvement in global model accuracy compared to state-of-the-art methods PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows reliable global model training despite limiting client resources and statistical data heterogeneity. This improves robustness and scalability for real-world FL deployments.",
        "comments": "6 pages, 5 figures. This work has been accepted by PerCom PerconAI workshop 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13366"
    },
    {
        "doc_id": 90,
        "title": "Full Bayesian Significance Testing for Neural Networks",
        "authors": [
            "Zehua Liu",
            "Zimeng Li",
            "Jingyuan Wang",
            "Yue He"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \\textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \\textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \\textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\\textit{n}FBST, LRP-\\textit{n}FBST, DeepLIFT-\\textit{n}FBST, LIME-\\textit{n}FBST. A range of experiments on both simulated and real data are conducted to show the advantages of our method.",
        "comments": "Published as a conference paper at AAAI 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13335"
    },
    {
        "doc_id": 91,
        "title": "An Explicit Scheme for Pathwise XVA Computations",
        "authors": [
            "Lokman Abbas-Turki",
            "St\u00e9phane Cr\u00e9pey",
            "Botao Li",
            "Bouazza Saadeddine"
        ],
        "subjects": [
            "Risk Management",
            "Numerical Analysis",
            "Computational Finance",
            "Machine Learning"
        ],
        "abstract": "Motivated by the equations of cross valuation adjustments (XVAs) in the realistic case where capital is deemed fungible as a source of funding for variation margin, we introduce a simulation/regression scheme for a class of anticipated BSDEs, where the coefficient entails a conditional expected shortfall of the martingale part of the solution. The scheme is explicit in time and uses neural network least-squares and quantile regressions for the embedded conditional expectations and expected shortfall computations. An a posteriori Monte Carlo validation procedure allows assessing the regression error of the scheme at each time step. The superiority of this scheme with respect to Picard iterations is illustrated in a high-dimensional and hybrid market/default risks XVA use-case.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13314"
    },
    {
        "doc_id": 92,
        "title": "On distributional limit laws for recurrence",
        "authors": [
            "Mark Holland",
            "Mike Todd"
        ],
        "subjects": [
            "Dynamical Systems",
            "Probability"
        ],
        "abstract": "For a probability measure preserving dynamical system $(\\mathcal{X},f,\u03bc)$, the Poincar\u00e9 Recurrence Theorem asserts that $\u03bc$-almost every orbit is recurrent with respect to its initial condition. This motivates study of the statistics of the process $X_n(x)=\\text{dist}(f^n(x),x))$, and real-valued functions thereof. For a wide class of non-uniformly expanding dynamical systems, we show that the time-$n$ counting process $R_n(x)$ associated to the number recurrences below a certain radii sequence $r_n(\u03c4)$ follows an \\emph{averaged} Poisson distribution $G(\u03c4)$. Furthermore, we obtain quantitative results on almost sure rates for the recurrence statistics of the process $X_n$.",
        "comments": "MSC Class:          37A50; 37B20; 60G55; 37E05; 60G70",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13300"
    },
    {
        "doc_id": 93,
        "title": "Transport and information in open quantum systems",
        "authors": [
            "Kasper Poulsen"
        ],
        "subjects": [
            "Quantum Physics",
            "Mesoscale and Nanoscale Physics",
            "Statistical Mechanics"
        ],
        "abstract": "With the approaching second quantum revolution, the study of quantum thermodynamics, particularly heat flow, has become even more relevant for two main reasons. First, understanding heat and other types of noise is essential for protecting quantum information and preventing decoherence. Second, the ability to manufacture and control quantum systems developed for the quantum computer allows for experimental study of quantum thermodynamics in entirely new settings.\n  In this thesis, several systems involving quantum systems in contact with baths are studied theoretically in experimentally available settings. First, two rectification or diode setups for heat currents are proposed using a dark-state mechanism. In one system, the dark-state mechanism is imperfect but very robust. In the other system, the dark-state mechanism relies on quantum entanglement and is much better but more fragile towards decoherence. Next, a quantum version of the Wheatstone bridge is built using the same entanglement-powered dark state mechanism. After having studied several boundary-driven quantum systems, the lessons learned are generalized into resonance conditions using a general linear chain of weakly interacting chains of strongly interacting spins.\n  The final two chapters focus on the ability to study statistical physics in realizable quantum systems. First, a Maxwell's demon setup is proposed. A demon-controlled qutrit is coupled to two non-Markovian baths. The information back-flow from the non-Markovian baths allows the demon to more effectively transfer heat from the cold bath to the hot bath. Second, the Mott insulator to superfluid phase transition in a lattice of transmons is examined. The ground state has a variable particle number and is prepared using adiabatic state preparation. This allows for the exploration of the entire phase diagram.",
        "comments": "PhD thesis",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13292"
    },
    {
        "doc_id": 94,
        "title": "Diverse Science from VLT imagery and spectroscopy of PNe in the Galactic Bulge",
        "authors": [
            "Quentin Parker",
            "Shuyu Tan",
            "Andreas Ritter",
            "Albert Zijlstra"
        ],
        "subjects": [
            "Astrophysics of Galaxies",
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "We have undertaken a deep investigation of a well defined sample of 136 PNe located in a 10x10 degree central region of the Galactic Bulge observed with the ESO VLT and supplemented by archival HST imagery. These studies have provided precise morphologies, major axes position angles and the most robust sample of consistently derived chemical abundances available to date. Using these data we have statistically confirmed, at 5-sigma, the precise PNe population that provides the PNe alignment of major axes previously suggested in the Galactic Bulge, revealed a partial solution to the sulfur anomaly and uncovered interesting morphological, abundance and kinematic features. We summarise the most significant findings here with detailed results appearing in a series of related publications.",
        "comments": "6 pages, 5 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13257"
    },
    {
        "doc_id": 95,
        "title": "Quantum natural gradient without monotonicity",
        "authors": [
            "Toi Sasaki",
            "Hideyuki Miyahara"
        ],
        "subjects": [
            "Quantum Physics",
            "Statistical Mechanics",
            "Information Theory",
            "Computational Physics",
            "Machine Learning"
        ],
        "abstract": "Natural gradient (NG) is an information-geometric optimization method that plays a crucial role, especially in the estimation of parameters for machine learning models like neural networks. To apply NG to quantum systems, the quantum natural gradient (QNG) was introduced and utilized for noisy intermediate-scale devices. Additionally, a mathematically equivalent approach to QNG, known as the stochastic reconfiguration method, has been implemented to enhance the performance of quantum Monte Carlo methods. It is worth noting that these methods are based on the symmetric logarithmic derivative (SLD) metric, which is one of the monotone metrics. So far, monotonicity has been believed to be a guiding principle to construct a geometry in physics. In this paper, we propose generalized QNG by removing the condition of monotonicity. Initially, we demonstrate that monotonicity is a crucial condition for conventional QNG to be optimal. Subsequently, we provide analytical and numerical evidence showing that non-monotone QNG outperforms conventional QNG based on the SLD metric in terms of convergence speed.",
        "comments": "6 pages, 3 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13237"
    },
    {
        "doc_id": 96,
        "title": "The role of carbon in red giant spectro-seismology",
        "authors": [
            "Kirsten A. Banks",
            "Sarah L. Martell",
            "C. G. Tinney",
            "Dennis Stello",
            "Marc Hon",
            "Claudia Reyes",
            "James Priest",
            "Sven Buder",
            "Benjamin T. Montet"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "Although red clump stars function as reliable standard candles, their surface characteristics (i.e. T$_{\\text{eff}}$, log~$g$, and [Fe/H]) overlap with those of red giant branch stars, which are not standard candles. Recent results have revealed that spectral features containing carbon (e.g. CN molecular bands) carry information correlating with the ''gold-standard'' asteroseismic classifiers that distinguish red clump from red giant branch stars. However, the underlying astrophysical processes driving the correlation between these spectroscopic and asteroseismic quantities in red giants remain inadequately explored. This study aims to enhance our understanding of this ''spectro-seismic'' effect, by refining the list of key spectral features predicting red giant evolutionary state. In addition, we conduct further investigation into those key spectral features to probe the astrophysical processes driving this connection. We employ the data-driven The Cannon algorithm to analyse high-resolution ($R\\sim80,000$) Veloce spectra from the Anglo-Australian Telescope for 301 red giant stars (where asteroseismic classifications from the TESS mission are known for 123 of the stars). The results highlight molecular spectroscopic features, particularly those containing carbon (e.g. CN), as the primary indicators of the evolutionary states of red giant stars. Furthermore, by investigating CN isotopic pairs (that is, $^{12}$C$^{14}$N and $^{13}$C$^{14}$N) we find statistically significant differences in the reduced equivalent widths of such lines, suggesting that physical processes that change the surface abundances and isotopic ratios in red giant stars, such as deep mixing, are the driving forces of the ''spectro-seismic'' connection of red giants.",
        "comments": "13 pages, 9 figures, submitted to MNRAS",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13235"
    },
    {
        "doc_id": 97,
        "title": "On the Statistical Mechanics of Mass Accommodation at Liquid-Vapor Interfaces",
        "authors": [
            "Kritanjan Polley",
            "Kevin R. Wilson",
            "David T. Limmer"
        ],
        "subjects": [
            "Chemical Physics",
            "Statistical Mechanics"
        ],
        "abstract": "We propose a framework for describing the dynamics associated with the adsorption of small molecules to liquid-vapor interfaces, using an intermediate resolution between traditional continuum theories that are bereft of molecular detail and molecular dynamics simulations that are replete with them. In particular, we develop an effective single particle equation of motion capable of describing the physical processes that determine thermal and mass accommodation probabilities. The effective equation is parameterized with quantities that vary through space away from the liquid-vapor interface. Of particular importance in describing the early time dynamics is the spatially dependent friction, for which we propose a numerical scheme to evaluate from molecular simulation. Taken together with potentials of mean force computable with importance sampling methods, we illustrate how to compute the mass accommodation coefficient and residence time distribution. Throughout, we highlight the case of ozone adsorption in aqueous solutions and its dependence on electrolyte composition.",
        "comments": "9 pages, 7 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13234"
    },
    {
        "doc_id": 98,
        "title": "On Principled Local Optimization Methods for Federated Learning",
        "authors": [
            "Honglin Yuan"
        ],
        "subjects": [
            "Machine Learning",
            "Distributed, Parallel, and Cluster Computing",
            "Optimization and Control",
            "Machine Learning"
        ],
        "abstract": "Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions.\n  First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective.\n  Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled acceleration of FedAvg, which provably improves the convergence rate and communication efficiency. Our technique uses on a potential-based perturbed iterate analysis, a novel stability analysis of generalized accelerated SGD, and a strategic tradeoff between acceleration and stability.\n  Third, we study the Federated Composite Optimization problem, which extends the classic smooth setting by incorporating a shared non-smooth regularizer. We show that direct extensions of FedAvg may suffer from the \"curse of primal averaging,\" resulting in slow convergence. As a solution, we propose a new primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of primal averaging by employing a novel inter-client dual averaging procedure.",
        "comments": "Stanford University Doctoral Dissertation",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13216"
    },
    {
        "doc_id": 99,
        "title": "Assessing Influential Observations in Pain Prediction using fMRI Data",
        "authors": [
            "Dongliang Zhang",
            "Masoud Asgharian",
            "Martin A. Lindquist"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Influential diagnosis is an integral part of data analysis, of which most existing methodological frameworks presume a deterministic submodel and are designed for low-dimensional data (i.e., the number of predictors p smaller than the sample size n). However, the stochastic selection of a submodel from high-dimensional data where p exceeds n has become ubiquitous. Thus, methods for identifying observations that could exert undue influence on the choice of a submodel can play an important role in this setting. To date, discussion of this topic has been limited, falling short in two domains: (i) constrained ability to detect multiple influential points, and (ii) applicability only in restrictive settings. After describing the problem, we characterize and formalize the concept of influential observations on variable selection. Then, we propose a generalized diagnostic measure, extended from an available metric accommodating different model selectors and multiple influential observations, the asymptotic distribution of which is subsequently establish large p, thus providing guidelines to ascertain influential observations. A high-dimensional clustering procedure is further incorporated into our proposed scheme to detect multiple influential points. Simulation is conducted to assess the performances of various diagnostic approaches. The proposed procedure further demonstrates its value in improving predictive power when analyzing thermal-stimulated pain based on fMRI data.",
        "comments": "21 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13208"
    },
    {
        "doc_id": 100,
        "title": "Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities",
        "authors": [
            "Yiyuan Zhang",
            "Xiaohan Ding",
            "Kaixiong Gong",
            "Yixiao Ge",
            "Ying Shan",
            "Xiangyu Yue"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "We propose to improve transformers of a specific modality with irrelevant data from other modalities, e.g., improve an ImageNet model with audio or point cloud datasets. We would like to highlight that the data samples of the target modality are irrelevant to the other modalities, which distinguishes our method from other works utilizing paired (e.g., CLIP) or interleaved data of different modalities. We propose a methodology named Multimodal Pathway - given a target modality and a transformer designed for it, we use an auxiliary transformer trained with data of another modality and construct pathways to connect components of the two models so that data of the target modality can be processed by both models. In this way, we utilize the universal sequence-to-sequence modeling abilities of transformers obtained from two modalities. As a concrete implementation, we use a modality-specific tokenizer and task-specific head as usual but utilize the transformer blocks of the auxiliary model via a proposed method named Cross-Modal Re-parameterization, which exploits the auxiliary weights without any inference costs. On the image, point cloud, video, and audio recognition tasks, we observe significant and consistent performance improvements with irrelevant data from other modalities. The code and models are available at https://github.com/AILab-CVC/M2PT.",
        "comments": "The code and models are available at https://github.com/AILab-CVC/M2PT",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14405"
    },
    {
        "doc_id": 101,
        "title": "Deconstructing Denoising Diffusion Models for Self-Supervised Learning",
        "authors": [
            "Xinlei Chen",
            "Zhuang Liu",
            "Saining Xie",
            "Kaiming He"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "In this study, we examine the representation learning abilities of Denoising Diffusion Models (DDM) that were originally purposed for image generation. Our philosophy is to deconstruct a DDM, gradually transforming it into a classical Denoising Autoencoder (DAE). This deconstructive procedure allows us to explore how various components of modern DDMs influence self-supervised representation learning. We observe that only a very few modern components are critical for learning good representations, while many others are nonessential. Our study ultimately arrives at an approach that is highly simplified and to a large extent resembles a classical DAE. We hope our study will rekindle interest in a family of classical methods within the realm of modern self-supervised learning.",
        "comments": "Technical report, 10 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14404"
    },
    {
        "doc_id": 102,
        "title": "Adaptive Mobile Manipulation for Articulated Objects In the Open World",
        "authors": [
            "Haoyu Xiong",
            "Russell Mendonca",
            "Kenneth Shaw",
            "Deepak Pathak"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Deploying robots in open-ended unstructured environments such as homes has been a long-standing research problem. However, robots are often studied only in closed-off lab settings, and prior mobile manipulation work is restricted to pick-move-place, which is arguably just the tip of the iceberg in this area. In this paper, we introduce Open-World Mobile Manipulation System, a full-stack approach to tackle realistic articulated object operation, e.g. real-world doors, cabinets, drawers, and refrigerators in open-ended unstructured environments. The robot utilizes an adaptive learning framework to initially learns from a small set of data through behavior cloning, followed by learning from online practice on novel objects that fall outside the training distribution. We also develop a low-cost mobile manipulation hardware platform capable of safe and autonomous online adaptation in unstructured environments with a cost of around 20,000 USD. In our experiments we utilize 20 articulate objects across 4 buildings in the CMU campus. With less than an hour of online learning for each object, the system is able to increase success rate from 50% of BC pre-training to 95% using online adaptation. Video results at https://open-world-mobilemanip.github.io/",
        "comments": "Website at https://open-world-mobilemanip.github.io/",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14403"
    },
    {
        "doc_id": 103,
        "title": "Range-Agnostic Multi-View Depth Estimation With Keyframe Selection",
        "authors": [
            "Andrea Conti",
            "Matteo Poggi",
            "Valerio Cambareri",
            "Stefano Mattoccia"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Methods for 3D reconstruction from posed frames require prior knowledge about the scene metric range, usually to recover matching cues along the epipolar lines and narrow the search range. However, such prior might not be directly available or estimated inaccurately in real scenarios -- e.g., outdoor 3D reconstruction from video sequences -- therefore heavily hampering performance. In this paper, we focus on multi-view depth estimation without requiring prior knowledge about the metric range of the scene by proposing RAMDepth, an efficient and purely 2D framework that reverses the depth estimation and matching steps order. Moreover, we demonstrate the capability of our framework to provide rich insights about the quality of the views used for prediction. Additional material can be found on our project page https://andreaconti.github.io/projects/range_agnostic_multi_view_depth.",
        "comments": "3DV 2024 Project Page https://andreaconti.github.io/projects/range_agnostic_multi_view_depth GitHub Page https://github.com/andreaconti/ramdepth.git",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14401"
    },
    {
        "doc_id": 104,
        "title": "Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect",
        "authors": [
            "Jannis Vamvas",
            "No\u00ebmi Aepli",
            "Rico Sennrich"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Creating neural text encoders for written Swiss German is challenging due to a dearth of training data combined with dialectal variation. In this paper, we build on several existing multilingual encoders and adapt them to Swiss German using continued pre-training. Evaluation on three diverse downstream tasks shows that simply adding a Swiss German adapter to a modular encoder achieves 97.5% of fully monolithic adaptation performance. We further find that for the task of retrieving Swiss German sentences given Standard German queries, adapting a character-level model is more effective than the other adaptation strategies. We release our code and the models trained for our experiments at https://github.com/ZurichNLP/swiss-german-text-encoders",
        "comments": "First Workshop on Modular and Open Multilingual NLP (MOOMIN 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14400"
    },
    {
        "doc_id": 105,
        "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes",
        "authors": [
            "Ege Ozguroglu",
            "Ruoshi Liu",
            "D\u00eddac Sur\u00eds",
            "Dian Chen",
            "Achal Dave",
            "Pavel Tokmakov",
            "Carl Vondrick"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.",
        "comments": "Website: https://gestalt.cs.columbia.edu/",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14398"
    },
    {
        "doc_id": 106,
        "title": "O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold",
        "authors": [
            "Tolson Bell",
            "Alan Frieze"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Combinatorics"
        ],
        "abstract": "The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler. Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time. In this paper, we give a theoretical insertion time bound for this algorithm. More precisely, for every $d\\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists. We show that for any $d\\ge 4$ hashes and load factor $c<c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$.",
        "comments": "19 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14394"
    },
    {
        "doc_id": 107,
        "title": "Rethinking Patch Dependence for Masked Autoencoders",
        "authors": [
            "Letian Fu",
            "Long Lian",
            "Renhao Wang",
            "Baifeng Shi",
            "Xudong Wang",
            "Adam Yala",
            "Trevor Darrell",
            "Alexei A. Efros",
            "Ken Goldberg"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In this work, we re-examine inter-patch dependencies in the decoding mechanism of masked autoencoders (MAE). We decompose this decoding mechanism for masked patch reconstruction in MAE into self-attention and cross-attention. Our investigations suggest that self-attention between mask patches is not essential for learning good representations. To this end, we propose a novel pretraining framework: Cross-Attention Masked Autoencoders (CrossMAE). CrossMAE's decoder leverages only cross-attention between masked and visible tokens, with no degradation in downstream performance. This design also enables decoding only a small subset of mask tokens, boosting efficiency. Furthermore, each decoder block can now leverage different encoder features, resulting in improved representation learning. CrossMAE matches MAE in performance with 2.5 to 3.7$\\times$ less decoding compute. It also surpasses MAE on ImageNet classification and COCO instance segmentation under the same compute. Code and models: https://crossmae.github.io",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14391"
    },
    {
        "doc_id": 108,
        "title": "Smooth Ranking SVM via Cutting-Plane Method",
        "authors": [
            "Erhan Can Ozcan",
            "Berk G\u00f6rg\u00fcl\u00fc",
            "Mustafa G. Baydogan",
            "Ioannis Ch. Paschalidis"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "The most popular classification algorithms are designed to maximize classification accuracy during training. However, this strategy may fail in the presence of class imbalance since it is possible to train models with high accuracy by overfitting to the majority class. On the other hand, the Area Under the Curve (AUC) is a widely used metric to compare classification performance of different algorithms when there is a class imbalance, and various approaches focusing on the direct optimization of this metric during training have been proposed. Among them, SVM-based formulations are especially popular as this formulation allows incorporating different regularization strategies easily. In this work, we develop a prototype learning approach that relies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Our algorithm learns simpler models by iteratively introducing cutting planes, thus overfitting is prevented in an unconventional way. Furthermore, it penalizes the changes in the weights at each iteration to avoid large jumps that might be observed in the test performance, thus facilitating a smooth learning process. Based on the experiments conducted on 73 binary classification datasets, our method yields the best test AUC in 25 datasets among its relevant competitors.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14388"
    },
    {
        "doc_id": 109,
        "title": "Inconsistency Masks: Removing the Uncertainty from Input-Pseudo-Label Pairs",
        "authors": [
            "Michael R. H. Vorndran",
            "Bernhard F. Roeck"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Generating sufficient labeled data is a significant hurdle in the efficient execution of deep learning projects, especially in uncharted territories of image segmentation where labeling demands extensive time, unlike classification tasks. Our study confronts this challenge, operating in an environment constrained by limited hardware resources and the lack of extensive datasets or pre-trained models. We introduce the novel use of Inconsistency Masks (IM) to effectively filter uncertainty in image-pseudo-label pairs, substantially elevating segmentation quality beyond traditional semi-supervised learning techniques. By integrating IM with other methods, we demonstrate remarkable binary segmentation performance on the ISIC 2018 dataset, starting with just 10% labeled data. Notably, three of our hybrid models outperform those trained on the fully labeled dataset. Our approach consistently achieves exceptional results across three additional datasets and shows further improvement when combined with other techniques. For comprehensive and robust evaluation, this paper includes an extensive analysis of prevalent semi-supervised learning strategies, all trained under identical starting conditions. The full code is available at: https://github.com/MichaelVorndran/InconsistencyMasks",
        "comments": "18 pages, 22 figures, 3 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14387"
    },
    {
        "doc_id": 110,
        "title": "Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem",
        "authors": [
            "Kaifeng Bu",
            "Weichen Gu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We establish an entropic, quantum central limit theorem and quantum inverse sumset theorem in discrete-variable quantum systems describing qudits or qubits. Both results are enabled by using our recently-discovered quantum convolution. We show that the exponential rate of convergence of the entropic central limit theorem is bounded by the magic gap. We also establish an ``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose a conjecture called ``convolutional strong subaddivity,'' which leads to the triangle inequality for the quantum Ruzsa divergence. A byproduct of this work is a magic measure to quantify the nonstabilizer nature of a state, based on the quantum Ruzsa divergence.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14385"
    },
    {
        "doc_id": 111,
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "subjects": [
            "Computational Complexity",
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We devise a parameterized family of distributions, the high-entropy step distributions (HES), which are expressive enough to capture near-optima of spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime and yet permit low-degree Sum-of-Squares (SoS) certificates that no such distribution can achieve value slightly larger than the true optimum. This yields a SoS optimization program and rounding scheme that attains near-optimal solutions for spherical spin glasses in the fRSB regime. In other regimes, the same results occur at the ALG value, which is a conjectured best-value attainable by any polynomial time algorithm. These SoS programs optimize over families of distributions of possible solutions, and circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure by instead proving the same bounds only in expectation on solution distributions that can be produced by the chosen rounding algorithm. The new SoS hierarchy does not make any specific reference to the spherical spin glass problem, and we conjecture that it can be applied to a broad range of average-case problems to obtain value that is optimal among polynomial-time algorithms. We give evidence for this with examples of ensembles that provably fool certain local iterative algorithms but for which there is either proof or evidence that the SoS program is better. This opens the door to addressing a question posed by Barak about the possible optimality of SoS on average-case optimization problems, and by Schramm about reductions between different families of algorithms for average-case problems. In this paper, we give low-degree SoS proofs certifying key properties about HES distributions as well as the ALG threshold for spherical spin glasses. The rounding algorithm is introduced and analyzed in a companion paper.",
        "comments": "130 pages, 0 figures. First of two companion papers",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14383"
    },
    {
        "doc_id": 112,
        "title": "An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Numerical Analysis",
            "Machine Learning"
        ],
        "abstract": "The recent introduction of the Least-Squares Support Vector Regression (LS-SVR) algorithm for solving differential and integral equations has sparked interest. In this study, we expand the application of this algorithm to address systems of differential-algebraic equations (DAEs). Our work presents a novel approach to solving general DAEs in an operator format by establishing connections between the LS-SVR machine learning model, weighted residual methods, and Legendre orthogonal polynomials. To assess the effectiveness of our proposed method, we conduct simulations involving various DAE scenarios, such as nonlinear systems, fractional-order derivatives, integro-differential, and partial DAEs. Finally, we carry out comparisons between our proposed method and currently established state-of-the-art approaches, demonstrating its reliability and effectiveness.",
        "comments": "17 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14382"
    },
    {
        "doc_id": 113,
        "title": "Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs",
        "authors": [
            "Martin Hanik",
            "Gabriele Steidl",
            "Christoph von Tycowicz"
        ],
        "subjects": [
            "Machine Learning",
            "Differential Geometry"
        ],
        "abstract": "We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.",
        "comments": "MSC Class:          53Z50                          ACM Class:          I.2.4",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14381"
    },
    {
        "doc_id": 114,
        "title": "UrbanGenAI: Reconstructing Urban Landscapes using Panoptic Segmentation and Diffusion Models",
        "authors": [
            "Timo Kapsalis"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "In contemporary design practices, the integration of computer vision and generative artificial intelligence (genAI) represents a transformative shift towards more interactive and inclusive processes. These technologies offer new dimensions of image analysis and generation, which are particularly relevant in the context of urban landscape reconstruction. This paper presents a novel workflow encapsulated within a prototype application, designed to leverage the synergies between advanced image segmentation and diffusion models for a comprehensive approach to urban design. Our methodology encompasses the OneFormer model for detailed image segmentation and the Stable Diffusion XL (SDXL) diffusion model, implemented through ControlNet, for generating images from textual descriptions. Validation results indicated a high degree of performance by the prototype application, showcasing significant accuracy in both object detection and text-to-image generation. This was evidenced by superior Intersection over Union (IoU) and CLIP scores across iterative evaluations for various categories of urban landscape features. Preliminary testing included utilising UrbanGenAI as an educational tool enhancing the learning experience in design pedagogy, and as a participatory instrument facilitating community-driven urban planning. Early results suggested that UrbanGenAI not only advances the technical frontiers of urban landscape reconstruction but also provides significant pedagogical and participatory planning benefits. The ongoing development of UrbanGenAI aims to further validate its effectiveness across broader contexts and integrate additional features such as real-time feedback mechanisms and 3D modelling capabilities. Keywords: generative AI; panoptic image segmentation; diffusion models; urban landscape design; design pedagogy; co-design",
        "comments": "19 pages, 4 figures, 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14379"
    },
    {
        "doc_id": 115,
        "title": "Bonding Grammars",
        "authors": [
            "Tikhon Pshenitsyn"
        ],
        "subjects": [
            "Formal Languages and Automata Theory"
        ],
        "abstract": "We introduce bonding grammars, a graph grammar formalism developed to model DNA computation by means of graph transformations. It is a modification of fusion grammars introduced by Kreowski, Kuske and Lye in 2017. Bonding is a graph transformation that consists of merging two hyperedges into a single larger one. We show why bonding better reflects interaction between DNA molecules than fusion. We prove that bonding grammars naturally generalise regular sticker systems. We also study the relation between bonding grammars and hyperedge replacement grammars proving that each of these kinds of grammars generates a language the other one cannot generate. Finally, we prove that the membership problem for bonding grammars is NP-complete and, moreover, that some bonding grammar generates an NP-complete set.",
        "comments": "Submitted to UCNC 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14377"
    },
    {
        "doc_id": 116,
        "title": "The GraphTempo Framework for Exploring the Evolution of a Graph through Pattern Aggregation",
        "authors": [
            "Evangelia Tsoukanara",
            "Georgia Koloniari",
            "Evaggelia Pitoura"
        ],
        "subjects": [
            "Social and Information Networks"
        ],
        "abstract": "When the focus is on the relationships or interactions between entities, graphs offer an intuitive model for many real-world data. Such graphs are usually large and change over time, thus, requiring models and strategies that explore their evolution. We study the evolution of aggregated graphs and introduce the GraphTempo model that allows temporal and attribute aggregation not only on node level by grouping individual nodes, but on a pattern level as well, where subgraphs are grouped together. Furthermore, We propose an efficient strategy for exploring the evolution of the graph based on identifying time intervals of significant growth, shrinkage or stability. Finally, we evaluate the efficiency and effectiveness of the proposed approach using three real graphs.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14375"
    },
    {
        "doc_id": 117,
        "title": "TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation",
        "authors": [
            "G\u00f6k\u00e7e Uludo\u011fan",
            "Zeynep Yirmibe\u015fo\u011flu Balal",
            "Furkan Akkurt",
            "Melik\u015fah T\u00fcrker",
            "Onur G\u00fcng\u00f6r",
            "Susan \u00dcsk\u00fcdarl\u0131"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The recent advances in natural language processing have predominantly favored well-resourced English-centric models, resulting in a significant gap with low-resource languages. In this work, we introduce the language model TURNA, which is developed for the low-resource language Turkish and is capable of both natural language understanding and generation tasks. TURNA is pretrained with an encoder-decoder architecture based on the unified framework UL2 with a diverse corpus that we specifically curated for this purpose. We evaluated TURNA with three generation tasks and five understanding tasks for Turkish. The results show that TURNA outperforms several multilingual models in both understanding and generation tasks, and competes with monolingual Turkish models in understanding tasks. TURNA is made available at https://huggingface.co/boun-tabi-LMG/TURNA .",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14373"
    },
    {
        "doc_id": 118,
        "title": "Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input",
        "authors": [
            "Enrico Picco",
            "Lina Jaurigue",
            "Kathy L\u00fcdge",
            "Serge Massar"
        ],
        "subjects": [
            "Emerging Technologies",
            "Artificial Intelligence",
            "Neural and Evolutionary Computing",
            "Optics"
        ],
        "abstract": "We present an experimental validation of a recently proposed optimization technique for reservoir computing, using an optoelectronic setup. Reservoir computing is a robust framework for signal processing applications, and the development of efficient optimization approaches remains a key challenge. The technique we address leverages solely a delayed version of the input signal to identify the optimal operational region of the reservoir, simplifying the traditionally time-consuming task of hyperparameter tuning. We verify the effectiveness of this approach on different benchmark tasks and reservoir operating conditions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14371"
    },
    {
        "doc_id": 119,
        "title": "Genie: Achieving Human Parity in Content-Grounded Datasets Generation",
        "authors": [
            "Asaf Yehudai",
            "Boaz Carmeli",
            "Yosi Mass",
            "Ofir Arviv",
            "Nathaniel Mills",
            "Assaf Toledo",
            "Eyal Shnarch",
            "Leshem Choshen"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The lack of high-quality data for content-grounded generation tasks has been identified as a major obstacle to advancing these tasks. To address this gap, we propose Genie, a novel method for automatically generating high-quality content-grounded data. It consists of three stages: (a) Content Preparation, (b) Generation: creating task-specific examples from the content (e.g., question-answer pairs or summaries). (c) Filtering mechanism aiming to ensure the quality and faithfulness of the generated data. We showcase this methodology by generating three large-scale synthetic data, making wishes, for Long-Form Question-Answering (LFQA), summarization, and information extraction. In a human evaluation, our generated data was found to be natural and of high quality. Furthermore, we compare models trained on our data with models trained on human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail for Summarization. We show that our models are on par with or outperforming models trained on human-generated data and consistently outperforming them in faithfulness. Finally, we applied our method to create LFQA data within the medical domain and compared a model trained on it with models trained on other domains.",
        "comments": "Accepted to ICLR24",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14367"
    },
    {
        "doc_id": 120,
        "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support",
        "authors": [
            "Inhwa Song",
            "Sachin R. Pendse",
            "Neha Kumar",
            "Munmun De Choudhury"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Artificial Intelligence",
            "Computers and Society"
        ],
        "abstract": "People experiencing severe distress increasingly use Large Language Model (LLM) chatbots as mental health support tools. Discussions on social media have described how engagements were lifesaving for some, but evidence suggests that general-purpose LLM chatbots also have notable risks that could endanger the welfare of users if not designed responsibly. In this study, we investigate the lived experiences of people who have used LLM chatbots for mental health support. We build on interviews with 21 individuals from globally diverse backgrounds to analyze how users create unique support roles for their chatbots, fill in gaps in everyday care, and navigate associated cultural limitations when seeking support from chatbots. We ground our analysis in psychotherapy literature around effective support, and introduce the concept of therapeutic alignment, or aligning AI with therapeutic values for mental health contexts. Our study offers recommendations for how designers can approach the ethical and effective use of LLM chatbots and other AI mental health support tools in mental health care.",
        "comments": "The first two authors contributed equally to this work",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14362"
    },
    {
        "doc_id": 121,
        "title": "MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving",
        "authors": [
            "Leyang Xue",
            "Yao Fu",
            "Zhan Lu",
            "Luo Mai",
            "Mahesh Marina"
        ],
        "subjects": [
            "Machine Learning",
            "Performance"
        ],
        "abstract": "This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE) serving system that realizes activation-aware expert offloading. MoE-Infinity features sequence-level expert activation tracing, a new approach adept at identifying sparse activations and capturing the temporal locality of MoE inference. By analyzing these traces, MoE-Infinity performs novel activation-aware expert prefetching and caching, substantially reducing the latency overheads usually associated with offloading experts for improved cost performance. Extensive experiments in a cluster show that MoE-Infinity outperforms numerous existing systems and approaches, reducing latency by 4 - 20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity's source code is publicly available at https://github.com/TorchMoE/MoE-Infinity",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14361"
    },
    {
        "doc_id": 122,
        "title": "A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts",
        "authors": [
            "Kazi Toufique Elahi",
            "Tasnuva Binte Rahman",
            "Shakil Shahriar",
            "Samir Sarker",
            "Md. Tanvir Rouf Shawon",
            "G. M. Shahariar"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "While Bengali is considered a language with limited resources, sentiment analysis has been a subject of extensive research in the literature. Nevertheless, there is a scarcity of exploration into sentiment analysis specifically in the realm of noisy Bengali texts. In this paper, we introduce a dataset (NC-SentNoB) that we annotated manually to identify ten different types of noise found in a pre-existing sentiment analysis dataset comprising of around 15K noisy Bengali texts. At first, given an input noisy text, we identify the noise type, addressing this as a multi-label classification task. Then, we introduce baseline noise reduction methods to alleviate noise prior to conducting sentiment analysis. Finally, we assess the performance of fine-tuned sentiment analysis models with both noisy and noise-reduced texts to make comparisons. The experimental findings indicate that the noise reduction methods utilized are not satisfactory, highlighting the need for more suitable noise reduction methods in future research endeavors. We have made the implementation and dataset presented in this paper publicly available at https://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts",
        "comments": "Accepted in The 9th Workshop on Noisy and User-generated Text (W-NUT), 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14360"
    },
    {
        "doc_id": 123,
        "title": "Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation",
        "authors": [
            "Jiaxu Wang",
            "Ziyi Zhang",
            "Renjing Xu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "This paper introduces a novel paradigm for the generalizable neural radiance field (NeRF). Previous generic NeRF methods combine multiview stereo techniques with image-based neural rendering for generalization, yielding impressive results, while suffering from three issues. First, occlusions often result in inconsistent feature matching. Then, they deliver distortions and artifacts in geometric discontinuities and locally sharp shapes due to their individual process of sampled points and rough feature aggregation. Third, their image-based representations experience severe degradations when source views are not near enough to the target view. To address challenges, we propose the first paradigm that constructs the generalizable neural field based on point-based rather than image-based rendering, which we call the Generalizable neural Point Field (GPF). Our approach explicitly models visibilities by geometric priors and augments them with neural features. We propose a novel nonuniform log sampling strategy to improve both rendering speed and reconstruction quality. Moreover, we present a learnable kernel spatially augmented with features for feature aggregations, mitigating distortions at places with drastically varying geometries. Besides, our representation can be easily manipulated. Experiments show that our model can deliver better geometries, view consistencies, and rendering quality than all counterparts and benchmarks on three datasets in both generalization and finetuning settings, preliminarily proving the potential of the new paradigm for generalizable NeRF.",
        "comments": "International Conference on Learning Representations 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14354"
    },
    {
        "doc_id": 124,
        "title": "Skyline-based exploration of temporal property graphs",
        "authors": [
            "Evangelia Tsoukanara",
            "Georgia Koloniari",
            "Evaggelia Pitoura"
        ],
        "subjects": [
            "Social and Information Networks"
        ],
        "abstract": "In this paper, we focus on temporal property graphs, that is, property graphs whose labeled nodes and edges as well as the values of the properties associated with them may change with time. For instance, consider a bibliographic network, with nodes representing authors and conferences with properties such as gender and location respectively, and edges representing collaboration between authors and publications in conferences. A key challenge in studying temporal graphs lies in detecting interesting events in their evolution, defined as time intervals of significant stability, growth, or shrinkage. To address this challenge, we build aggregated graphs, where nodes are grouped based on the values of their properties, and seek events at the aggregated level, for example, time intervals of significant growth in the collaborations between authors of the same gender. To locate such events, we propose a novel approach based on unified evolution skylines. A unified evolution skyline assesses the significance of an event in conjunction with the duration of the interval in which the event occurs. Significance is measured by a set of counts, where each count refers to the number of graph elements that remain stable, are created, or deleted, for a specific property value. For example, for property gender, we measure the number of female-female, female-male, and male-male collaborations. Lastly, we share experimental findings that highlight the efficiency and effectiveness of our approach.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14352"
    },
    {
        "doc_id": 125,
        "title": "ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models",
        "authors": [
            "Yao Fu",
            "Leyang Xue",
            "Yeqi Huang",
            "Andrei-Octavian Brabete",
            "Dmitrii Ustiugov",
            "Yuvraj Patel",
            "Luo Mai"
        ],
        "subjects": [
            "Machine Learning",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "This paper presents ServerlessLLM, a locality-enhanced serverless inference system for Large Language Models (LLMs). ServerlessLLM exploits the substantial capacity and bandwidth of storage and memory devices available on GPU servers, thereby reducing costly remote checkpoint downloads and achieving efficient checkpoint loading. ServerlessLLM achieves this through three main contributions: (i) fast LLM checkpoint loading via a novel loading-optimized checkpoint format design, coupled with an efficient multi-tier checkpoint loading system; (ii) locality-driven LLM inference with live migration, which allows ServerlessLLM to effectively achieve locality-driven server allocation while preserving the low latency of ongoing LLM inference; and (iii) locality-aware server allocation, enabling ServerlessLLM to evaluate the status of each server in a cluster and effectively schedule model startup time to capitalize on local checkpoint placement. Our comprehensive experiments, which include microbenchmarks and real-world traces, show that ServerlessLLM surpasses state-of-the-art systems by 10 - 200X in latency performance when running various LLM inference workloads.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14351"
    },
    {
        "doc_id": 126,
        "title": "5G Network Security Practices: An Overview and Survey",
        "authors": [
            "Fatema Bannat Wala",
            "Mariam Kiran"
        ],
        "subjects": [
            "Networking and Internet Architecture",
            "Cryptography and Security"
        ],
        "abstract": "This document provides an overview of 5G network security, describing various components of the 5G core network architecture and what kind of security services are offered by these 5G components. It also explores the potential security risks and vulnerabilities presented by the security architecture in 5G and recommends some of the best practices for the 5G network admins to consider while deploying a secure 5G network, based on the surveyed documents from the European government's efforts in commercializing the IoT devices and securing supply chain over 5G networks.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14350"
    },
    {
        "doc_id": 127,
        "title": "Learning to navigate efficiently and precisely in real environments",
        "authors": [
            "Guillaume Bono",
            "Herv\u00e9 Poirier",
            "Leonid Antsfeld",
            "Gianluca Monaci",
            "Boris Chidlovskii",
            "Christian Wolf"
        ],
        "subjects": [
            "Robotics",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In the context of autonomous navigation of terrestrial robots, the creation of realistic models for agent dynamics and sensing is a widespread habit in the robotics literature and in commercial applications, where they are used for model based control and/or for localization and mapping. The more recent Embodied AI literature, on the other hand, focuses on modular or end-to-end agents trained in simulators like Habitat or AI-Thor, where the emphasis is put on photo-realistic rendering and scene diversity, but high-fidelity robot motion is assigned a less privileged role. The resulting sim2real gap significantly impacts transfer of the trained models to real robotic platforms. In this work we explore end-to-end training of agents in simulation in settings which minimize the sim2real gap both, in sensing and in actuation. Our agent directly predicts (discretized) velocity commands, which are maintained through closed-loop control in the real robot. The behavior of the real robot (including the underlying low-level controller) is identified and simulated in a modified Habitat simulator. Noise models for odometry and localization further contribute in lowering the sim2real gap. We evaluate on real navigation scenarios, explore different localization and point goal calculation methods and report significant gains in performance and robustness compared to prior work.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14349"
    },
    {
        "doc_id": 128,
        "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
        "authors": [
            "Thomas F. Varley",
            "Joshua Bongard"
        ],
        "subjects": [
            "Information Theory",
            "Dynamical Systems",
            "Chaotic Dynamics",
            "Cellular Automata and Lattice Gases"
        ],
        "abstract": "There has recently been an explosion of interest in how \"higher-order\" structures emerge in complex systems. This \"emergent\" organization has been found in a variety of natural and artificial systems, although at present the field lacks a unified understanding of what the consequences of higher-order synergies and redundancies are for systems. Typical research treat the presence (or absence) of synergistic information as a dependent variable and report changes in the level of synergy in response to some change in the system. Here, we attempt to flip the script: rather than treating higher-order information as a dependent variable, we use evolutionary optimization to evolve boolean networks with significant higher-order redundancies, synergies, or statistical complexity. We then analyse these evolved populations of networks using established tools for characterizing discrete dynamics: the number of attractors, average transient length, and Derrida coefficient. We also assess the capacity of the systems to integrate information. We find that high-synergy systems are unstable and chaotic, but with a high capacity to integrate information. In contrast, evolved redundant systems are extremely stable, but have negligible capacity to integrate information. Finally, the complex systems that balance integration and segregation (known as Tononi-Sporns-Edelman complexity) show features of both chaosticity and stability, with a greater capacity to integrate information than the redundant systems while being more stable than the random and synergistic systems. We conclude that there may be a fundamental trade-off between the robustness of a systems dynamics and its capacity to integrate information (which inherently requires flexibility and sensitivity), and that certain kinds of complexity naturally balance this trade-off.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14347"
    },
    {
        "doc_id": 129,
        "title": "Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective",
        "authors": [
            "Xuechen Zhang",
            "Mingchen Li",
            "Jiasi Chen",
            "Christos Thrampoulidis",
            "Samet Oymak"
        ],
        "subjects": [
            "Machine Learning",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CAP is competitive with prior art and its flexibility unlocks clear benefits for fairness objectives beyond balanced accuracy. Finally, we evaluate CAP on problems with label noise as well as weighted test objectives to showcase how CAP can jointly adapt to different heterogeneities.",
        "comments": "15 pages, 8 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14343"
    },
    {
        "doc_id": 130,
        "title": "Efficient Construction of Long Orientable Sequences",
        "authors": [
            "Daniel Gabric",
            "Joe Sawada"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Information Theory",
            "Combinatorics"
        ],
        "abstract": "An orientable sequence of order $n$ is a cyclic binary sequence such that each length-$n$ substring appears at most once \\emph{in either direction}. Maximal length orientable sequences are known only for $n\\leq 7$, and a trivial upper bound on their length is $2^{n-1} - 2^{\\lfloor(n-1)/2\\rfloor}$. This paper presents the first efficient algorithm to construct orientable sequences with asymptotically optimal length; more specifically, our algorithm constructs orientable sequences via cycle-joining and a successor-rule approach requiring $O(n)$ time per symbol and $O(n)$ space. This answers a longstanding open question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)]. Our sequences are applied to find new longest-known orientable sequences for $n\\leq 20$.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14341"
    },
    {
        "doc_id": 131,
        "title": "Estimation of partially known Gaussian graphical models with score-based structural priors",
        "authors": [
            "Mart\u00edn Sevilla",
            "Antonio Garc\u00eda Marques",
            "Santiago Segarra"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.",
        "comments": "15 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14340"
    },
    {
        "doc_id": 132,
        "title": "Progressive Multi-task Anti-Noise Learning and Distilling Frameworks for Fine-grained Vehicle Recognition",
        "authors": [
            "Dichao Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Fine-grained vehicle recognition (FGVR) is an essential fundamental technology for intelligent transportation systems, but very difficult because of its inherent intra-class variation. Most previous FGVR studies only focus on the intra-class variation caused by different shooting angles, positions, etc., while the intra-class variation caused by image noise has received little attention. This paper proposes a progressive multi-task anti-noise learning (PMAL) framework and a progressive multi-task distilling (PMD) framework to solve the intra-class variation problem in FGVR due to image noise. The PMAL framework achieves high recognition accuracy by treating image denoising as an additional task in image recognition and progressively forcing a model to learn noise invariance. The PMD framework transfers the knowledge of the PMAL-trained model into the original backbone network, which produces a model with about the same recognition accuracy as the PMAL-trained model, but without any additional overheads over the original backbone network. Combining the two frameworks, we obtain models that significantly exceed previous state-of-the-art methods in recognition accuracy on two widely-used, standard FGVR datasets, namely Stanford Cars, and CompCars, as well as three additional surveillance image-based vehicle-type classification datasets, namely Beijing Institute of Technology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle Images Dataset for Make Model Recognition (VIDMMR), without any additional overheads over the original backbone networks. The source code is available at https://github.com/Dichao-Liu/Anti-noise_FGVR",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14336"
    },
    {
        "doc_id": 133,
        "title": "SunBlock: Cloudless Protection for IoT Systems",
        "authors": [
            "Vadim Safronov",
            "Anna Maria Mandalari",
            "Daniel J. Dubois",
            "David Choffnes",
            "Hamed Haddadi"
        ],
        "subjects": [
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "With an increasing number of Internet of Things (IoT) devices present in homes, there is a rise in the number of potential information leakage channels and their associated security threats and privacy risks. Despite a long history of attacks on IoT devices in unprotected home networks, the problem of accurate, rapid detection and prevention of such attacks remains open. Many existing IoT protection solutions are cloud-based, sometimes ineffective, and might share consumer data with unknown third parties. This paper investigates the potential for effective IoT threat detection locally, on a home router, using AI tools combined with classic rule-based traffic-filtering algorithms. Our results show that with a slight rise of router hardware resources caused by machine learning and traffic filtering logic, a typical home router instrumented with our solution is able to effectively detect risks and protect a typical home IoT network, equaling or outperforming existing popular solutions, without any effects on benign IoT functionality, and without relying on cloud services and third parties.",
        "comments": "This paper is accepted at Passive and Active Measurement (PAM) conference 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14332"
    },
    {
        "doc_id": 134,
        "title": "Unlocking Past Information: Temporal Embeddings in Cooperative Bird's Eye View Prediction",
        "authors": [
            "Dominik R\u00f6\u00dfle",
            "Jeremias Gerner",
            "Klaus Bogenberger",
            "Daniel Cremers",
            "Stefanie Schmidtner",
            "Torsten Sch\u00f6n"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Accurate and comprehensive semantic segmentation of Bird's Eye View (BEV) is essential for ensuring safe and proactive navigation in autonomous driving. Although cooperative perception has exceeded the detection capabilities of single-agent systems, prevalent camera-based algorithms in cooperative perception neglect valuable information derived from historical observations. This limitation becomes critical during sensor failures or communication issues as cooperative perception reverts to single-agent perception, leading to degraded performance and incomplete BEV segmentation maps. This paper introduces TempCoBEV, a temporal module designed to incorporate historical cues into current observations, thereby improving the quality and reliability of BEV map segmentations. We propose an importance-guided attention architecture to effectively integrate temporal information that prioritizes relevant properties for BEV map segmentation. TempCoBEV is an independent temporal module that seamlessly integrates into state-of-the-art camera-based cooperative perception models. We demonstrate through extensive experiments on the OPV2V dataset that TempCoBEV performs better than non-temporal models in predicting current and future BEV map segmentations, particularly in scenarios involving communication failures. We show the efficacy of TempCoBEV and its capability to integrate historical cues into the current BEV map, improving predictions under optimal communication conditions by up to 2% and under communication failures by up to 19%. The code will be published on GitHub.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14325"
    },
    {
        "doc_id": 135,
        "title": "Scalable Tree-based Register Automata Learning",
        "authors": [
            "Simon Dierl",
            "Paul Fiterau-Brostean",
            "Falk Howar",
            "Bengt Jonsson",
            "Konstantinos Sagonas",
            "Fredrik T\u00e5quist"
        ],
        "subjects": [
            "Formal Languages and Automata Theory"
        ],
        "abstract": "Existing active automata learning (AAL) algorithms have demonstrated their potential in capturing the behavior of complex systems (e.g., in analyzing network protocol implementations). The most widely used AAL algorithms generate finite state machine models, such as Mealy machines. For many analysis tasks, however, it is crucial to generate richer classes of models that also show how relations between data parameters affect system behavior. Such models have shown potential to uncover critical bugs, but their learning algorithms do not scale beyond small and well curated experiments. In this paper, we present $SL^\u03bb$, an effective and scalable register automata (RA) learning algorithm that significantly reduces the number of tests required for inferring models. It achieves this by combining a tree-based cost-efficient data structure with mechanisms for computing short and restricted tests. We have implemented $SL^\u03bb$ as a new algorithm in RALib. We evaluate its performance by comparing it against $SL^*$, the current state-of-the-art RA learning algorithm, in a series of experiments, and show superior performance and substantial asymptotic improvements in bigger systems.",
        "comments": "26 pages, 8 figures, to appear in TACAS 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14324"
    },
    {
        "doc_id": 136,
        "title": "Common Randomness Generation from Finite Compound Sources",
        "authors": [
            "Rami Ezzine",
            "Moritz Wiese",
            "Christian Deppe",
            "Holger Boche"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "We investigate the problem of generating common randomness (CR) from finite compound sources aided by unidirectional communication over rate-limited perfect channels. The two communicating parties, often referred to as terminals, observe independent and identically distributed (i.i.d.) samples of a finite compound source and aim to agree on a common random variable with a high probability for every possible realization of the source state. Both parties know the set of source states as well as their statistics. However, they are unaware of the actual realization of the source state. We establish a single-letter lower and upper bound on the compound CR capacity for the specified model. Furthermore, we present two special scenarios where the established bounds coincide.",
        "comments": "arXiv admin note: text overlap with arXiv:2305.05524",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14323"
    },
    {
        "doc_id": 137,
        "title": "Generalized People Diversity: Learning a Human Perception-Aligned Diversity Representation for People Images",
        "authors": [
            "Hansa Srinivasan",
            "Candice Schumann",
            "Aradhana Sinha",
            "David Madras",
            "Gbolahan Oluwafemi Olanubi",
            "Alex Beutel",
            "Susanna Ricco",
            "Jilin Chen"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Computers and Society"
        ],
        "abstract": "Capturing the diversity of people in images is challenging: recent literature tends to focus on diversifying one or two attributes, requiring expensive attribute labels or building classifiers. We introduce a diverse people image ranking method which more flexibly aligns with human notions of people diversity in a less prescriptive, label-free manner. The Perception-Aligned Text-derived Human representation Space (PATHS) aims to capture all or many relevant features of people-related diversity, and, when used as the representation space in the standard Maximal Marginal Relevance (MMR) ranking algorithm, is better able to surface a range of types of people-related diversity (e.g. disability, cultural attire). PATHS is created in two stages. First, a text-guided approach is used to extract a person-diversity representation from a pre-trained image-text model. Then this representation is fine-tuned on perception judgments from human annotators so that it captures the aspects of people-related similarity that humans find most salient. Empirical results show that the PATHS method achieves diversity better than baseline methods, according to side-by-side ratings from human annotators.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14322"
    },
    {
        "doc_id": 138,
        "title": "VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech",
        "authors": [
            "Chenpeng Du",
            "Yiwei Guo",
            "Hankun Wang",
            "Yifan Yang",
            "Zhikang Niu",
            "Shuai Wang",
            "Hui Zhang",
            "Xie Chen",
            "Kai Yu"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Recent TTS models with decoder-only Transformer architecture, such as SPEAR-TTS and VALL-E, achieve impressive naturalness and demonstrate the ability for zero-shot adaptation given a speech prompt. However, such decoder-only TTS models lack monotonic alignment constraints, sometimes leading to hallucination issues such as mispronunciation, word skipping and difficulty in stopping. To address this limitation, we propose VALL-T, a generative Transducer model that introduces shifting relative position embeddings for input phoneme sequence, explicitly indicating the monotonic generation process while maintaining the architecture of decoder-only Transformer. Consequently, VALL-T retains the capability of prompt-based zero-shot adaptation and demonstrates better robustness against hallucinations with a relative reduction of 28.3\\% in the word error rate. Furthermore, the controllability of alignment in VALL-T during decoding facilitates the use of untranscribed speech prompts, even in unknown languages. It also enables the synthesis of lengthy speech by utilizing an aligned context window.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14321"
    },
    {
        "doc_id": 139,
        "title": "Quantifying Software Correctness by Combining Architecture Modeling and Formal Program Analysis",
        "authors": [
            "Florian Lanzinger",
            "Christian Martin",
            "Frederik Reiche",
            "Samuel Teuber",
            "Robert Heinrich",
            "Alexander Weigl"
        ],
        "subjects": [
            "Software Engineering",
            "Logic in Computer Science"
        ],
        "abstract": "Most formal methods see the correctness of a software system as a binary decision. However, proving the correctness of complex systems completely is difficult because they are composed of multiple components, usage scenarios, and environments. We present QuAC, a modular approach for quantifying the correctness of service-oriented software systems by combining software architecture modeling with deductive verification. Our approach is based on a model of the service-oriented architecture and the probabilistic usage scenarios of the system. The correctness of a single service is approximated by a coverage region, which is a formula describing which inputs for that service are proven to not lead to an erroneous execution. The coverage regions can be determined by a combination of various analyses, e.g., formal verification, expert estimations, or testing. The coverage regions and the software model are then combined into a probabilistic program. From this, we can compute the probability that under a given usage profile no service is called outside its coverage region. If the coverage region is large enough, then instead of attempting to get 100% coverage, which may be prohibitively expensive, run-time verification or testing approaches may be used to deal with inputs outside the coverage region. We also present an implementation of QuAC for Java using the modeling tool Palladio and the deductive verification tool KeY. We demonstrate its usability by applying it to a software simulation of an energy system.",
        "comments": "10 pages; to appear at the 39th ACM/SIGAPP Symposium on Applied Computing (SAC '24)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14320"
    },
    {
        "doc_id": 140,
        "title": "A Quantum \"Lifting Theorem\" for Constructions of Pseudorandom Generators from Random Oracles",
        "authors": [
            "Benjamin Sela",
            "Jonathan Katz"
        ],
        "subjects": [
            "Cryptography and Security"
        ],
        "abstract": "We study the (quantum) security of pseudorandom generators (PRGs) constructed from random oracles. We prove a ``lifting theorem'' showing, roughly, that if such a PRG is unconditionally secure against classical adversaries making polynomially many queries to the random oracle, then it is also (unconditionally) secure against quantum adversaries in the same sense. As a result of independent interest, we also show that any pseudo-deterministic quantum-oracle algorithm (i.e., a quantum algorithm that with high probability returns the same value on repeated executions) can be simulated by a computationally unbounded but query bounded classical-oracle algorithm with only a polynomial blowup in the number of queries. This implies as a corollary that our lifting theorem holds even for PRGs that themselves make quantum queries to the random oracle.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14319"
    },
    {
        "doc_id": 141,
        "title": "Maximizing the Minimum Eigenvalue in Constant Dimension",
        "authors": [
            "Adam Brown",
            "Aditi Laddha",
            "Mohit Singh"
        ],
        "subjects": [
            "Data Structures and Algorithms"
        ],
        "abstract": "In an instance of the minimum eigenvalue problem, we are given a collection of $n$ vectors $v_1,\\ldots, v_n \\subset {\\mathbb{R}^d}$, and the goal is to pick a subset $B\\subseteq [n]$ of given vectors to maximize the minimum eigenvalue of the matrix $\\sum_{i\\in B} v_i v_i^{\\top} $. Often, additional combinatorial constraints such as cardinality constraint $\\left(|B|\\leq k\\right)$ or matroid constraint ($B$ is a basis of a matroid defined on $[n]$) must be satisfied by the chosen set of vectors. The minimum eigenvalue problem with matroid constraints models a wide variety of problems including the Santa Clause problem, the E-design problem, and the constructive Kadison-Singer problem.\n  In this paper, we give a randomized algorithm that finds a set $B\\subseteq [n]$ subject to any matroid constraint whose minimum eigenvalue is at least $(1-\u03b5)$ times the optimum, with high probability. The running time of the algorithm is $O\\left( n^{O(d\\log(d)/\u03b5^2)}\\right)$. In particular, our results give a polynomial time asymptotic scheme when the dimension of the vectors is constant. Our algorithm uses a convex programming relaxation of the problem after guessing a rescaling which allows us to apply pipage rounding and matrix Chernoff inequalities to round to a good solution. The key new component is a structural lemma which enables us to \"guess'' the appropriate rescaling, which could be of independent interest. Our approach generalizes the approximation guarantee to monotone, homogeneous functions and as such we can maximize $\\det(\\sum_{i\\in B} v_i v_i^\\top)^{1/d}$, or minimize any norm of the eigenvalues of the matrix $\\left(\\sum_{i\\in B} v_i v_i^\\top\\right)^{-1} $, with the same running time under some mild assumptions. As a byproduct, we also get a simple algorithm for an algorithmic version of Kadison-Singer problem.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14317"
    },
    {
        "doc_id": 142,
        "title": "MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems",
        "authors": [
            "Xinyu Gao",
            "Zhijie Wang",
            "Yang Feng",
            "Lei Ma",
            "Zhenyu Chen",
            "Baowen Xu"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms. With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems. Similar to traditional software, adequate testing is also required for AI-enabled MSF systems. Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-/point cloud-based object detection systems). There remains a lack of emphasis on generating multi-modal test cases for MSF systems. To address these limitations, we design and implement MultiTest, a fitness-guided metamorphic testing method for complex MSF perception systems. MultiTest employs a physical-aware approach to synthesize realistic multi-modal object instances and insert them into critical positions of background images and point clouds. A fitness metric is designed to guide and boost the test generation process. We conduct extensive experiments with five SOTA perception systems to evaluate MultiTest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement. The results show that MultiTest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test. Moreover, retraining an MSF system on the test cases generated by MultiTest can improve the system's robustness.",
        "comments": "The first two authors contributed equally. To appear in the proceedings of the 46th International Conference on Software Engineering (ICSE 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14314"
    },
    {
        "doc_id": 143,
        "title": "On Some Complexity Results for Even Linear Languages",
        "authors": [
            "Liliana Cojocaru"
        ],
        "subjects": [
            "Formal Languages and Automata Theory",
            "Computational Complexity",
            "Logic in Computer Science"
        ],
        "abstract": "We deal with a normal form for context-free grammars, called Dyck normal form. This normal form is a syntactical restriction of the Chomsky normal form, in which the two nonterminals occurring on the right-hand side of a rule are paired nonterminals. This pairwise property, along with several other terminal rewriting conditions, makes it possible to define a homomorphism from Dyck words to words generated by a grammar in Dyck normal form. We prove that for each context-free language L, there exist an integer K and a homomorphism phi such that L=phi(D'_K), where D'_K is a subset of D_K and D_K is the one-sided Dyck language over K letters. As an application we give an alternative proof of the inclusion of the class of even linear languages in AC1.",
        "comments": "16 pages, no figure. arXiv admin note: substantial text overlap with arXiv:1512.09207",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14303"
    },
    {
        "doc_id": 144,
        "title": "\"All of Me\": Mining Users' Attributes from their Public Spotify Playlists",
        "authors": [
            "Pier Paolo Tricomi",
            "Luca Pajola",
            "Luca Pasa",
            "Mauro Conti"
        ],
        "subjects": [
            "Cryptography and Security",
            "Machine Learning",
            "Social and Information Networks"
        ],
        "abstract": "In the age of digital music streaming, playlists on platforms like Spotify have become an integral part of individuals' musical experiences. People create and publicly share their own playlists to express their musical tastes, promote the discovery of their favorite artists, and foster social connections. These publicly accessible playlists transcend the boundaries of mere musical preferences: they serve as sources of rich insights into users' attributes and identities. For example, the musical preferences of elderly individuals may lean more towards Frank Sinatra, while Billie Eilish remains a favored choice among teenagers. These playlists thus become windows into the diverse and evolving facets of one's musical identity.\n  In this work, we investigate the relationship between Spotify users' attributes and their public playlists. In particular, we focus on identifying recurring musical characteristics associated with users' individual attributes, such as demographics, habits, or personality traits. To this end, we conducted an online survey involving 739 Spotify users, yielding a dataset of 10,286 publicly shared playlists encompassing over 200,000 unique songs and 55,000 artists. Through extensive statistical analyses, we first assess a deep connection between a user's Spotify playlists and their real-life attributes. For instance, we found individuals high in openness often create playlists featuring a diverse array of artists, while female users prefer Pop and K-pop music genres. Building upon these observed associations, we create accurate predictive models for users' attributes, presenting a novel DeepSet application that outperforms baselines in most of these users' attributes.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14296"
    },
    {
        "doc_id": 145,
        "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts",
        "authors": [
            "Maciej Besta",
            "Florim Memedi",
            "Zhenyu Zhang",
            "Robert Gerstenberger",
            "Nils Blach",
            "Piotr Nyczyk",
            "Marcin Copik",
            "Grzegorz Kwa\u015bniewski",
            "J\u00fcrgen M\u00fcller",
            "Lukas Gianinazzi",
            "Ales Kubicek",
            "Hubert Niewiadomski",
            "Onur Mutlu",
            "Torsten Hoefler"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models' (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxonomy of structure-enhanced LLM reasoning schemes. We focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. We refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the LLM context. Our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. We also outline theoretical underpinnings, relationships between prompting and others parts of the LLM ecosystem such as knowledge bases, and the associated research challenges. Our work will help to advance future prompt engineering techniques.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14295"
    },
    {
        "doc_id": 146,
        "title": "AST-2: Single and bi-layered 2-D acoustic soft tactile skin",
        "authors": [
            "Vishnu Rajendran",
            "Simon Parsons",
            "Amir Ghalamzan E"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence"
        ],
        "abstract": "This paper aims to present an innovative and cost-effective design for Acoustic Soft Tactile (AST) Skin, with the primary goal of significantly enhancing the accuracy of 2-D tactile feature estimation. The existing challenge lies in achieving precise tactile feature estimation, especially concerning contact geometry characteristics, using cost-effective solutions. We hypothesise that by harnessing acoustic energy through dedicated acoustic channels in 2 layers beneath the sensing surface and analysing amplitude modulation, we can effectively decode interactions on the sensory surface, thereby improving tactile feature estimation. Our approach involves the distinct separation of hardware components responsible for emitting and receiving acoustic signals, resulting in a modular and highly customizable skin design. Practical tests demonstrate the effectiveness of this novel design, achieving remarkable precision in estimating contact normal forces (MAE < 0.8 N), 2D contact localisation (MAE < 0.7 mm), and contact surface diameter (MAE < 0.3 mm). In conclusion, the AST skin, with its innovative design and modular architecture, successfully addresses the challenge of tactile feature estimation. The presented results showcase its ability to precisely estimate various tactile features, making it a practical and cost-effective solution for robotic applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14292"
    },
    {
        "doc_id": 147,
        "title": "Speech foundation models on intelligibility prediction for hearing-impaired listeners",
        "authors": [
            "Santiago Cuervo",
            "Ricard Marxer"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech foundation models (SFMs) have been benchmarked on many speech processing tasks, often achieving state-of-the-art performance with minimal adaptation. However, the SFM paradigm has been significantly less explored for applications of interest to the speech perception community. In this paper we present a systematic evaluation of 10 SFMs on one such application: Speech intelligibility prediction. We focus on the non-intrusive setup of the Clarity Prediction Challenge 2 (CPC2), where the task is to predict the percentage of words correctly perceived by hearing-impaired listeners from speech-in-noise recordings. We propose a simple method that learns a lightweight specialized prediction head on top of frozen SFMs to approach the problem. Our results reveal statistically significant differences in performance across SFMs. Our method resulted in the winning submission in the CPC2, demonstrating its promise for speech perception applications.",
        "comments": "To be presented in ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14289"
    },
    {
        "doc_id": 148,
        "title": "Equivalence of Applicative Functors and Multifunctors",
        "authors": [
            "Andreas Abel"
        ],
        "subjects": [
            "Programming Languages",
            "Logic in Computer Science"
        ],
        "abstract": "McBride and Paterson introduced Applicative functors to Haskell, which are equivalent to the lax monoidal functors (with strength) of category theory. Applicative functors F are presented via idiomatic application $\\_\\circledast\\_ : F (A \\to B) \\to F A \\to F B$ and laws that are a bit hard to remember. Capriotti and Kaposi observed that applicative functors can be conceived as multifunctors, i.e., by a family liftA$_n$ : $(A_1 \\to ... \\to A_n \\to C) \\to F A_1 \\to ... \\to F A_n \\to F C$ of zipWith-like functions that generalize pure $(n=0)$, fmap $(n=1)$ and liftA2 $(n=2)$. This reduces the associated laws to just the first functor law and a uniform scheme of second (multi)functor laws, i.e., a composition law for liftA. In this note, we rigorously prove that applicative functors are in fact equivalent to multifunctors, by interderiving their laws.",
        "comments": "6 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14286"
    },
    {
        "doc_id": 149,
        "title": "POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation",
        "authors": [
            "Bo Zhou",
            "Jun Hou",
            "Tianqi Chen",
            "Yinchi Zhou",
            "Xiongchao Chen",
            "Huidong Xie",
            "Qiong Liu",
            "Xueqi Guo",
            "Yu-Jung Tsai",
            "Vladimir Y. Panin",
            "Takuya Toyonaga",
            "James S. Duncan",
            "Chi Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Image and Video Processing"
        ],
        "abstract": "Low-dose PET offers a valuable means of minimizing radiation exposure in PET imaging. However, the prevalent practice of employing additional CT scans for generating attenuation maps (u-map) for PET attenuation correction significantly elevates radiation doses. To address this concern and further mitigate radiation exposure in low-dose PET exams, we propose POUR-Net - an innovative population-prior-aided over-under-representation network that aims for high-quality attenuation map generation from low-dose PET. First, POUR-Net incorporates an over-under-representation network (OUR-Net) to facilitate efficient feature extraction, encompassing both low-resolution abstracted and fine-detail features, for assisting deep generation on the full-resolution level. Second, complementing OUR-Net, a population prior generation machine (PPGM) utilizing a comprehensive CT-derived u-map dataset, provides additional prior information to aid OUR-Net generation. The integration of OUR-Net and PPGM within a cascade framework enables iterative refinement of $\u03bc$-map generation, resulting in the production of high-quality $\u03bc$-maps. Experimental results underscore the effectiveness of POUR-Net, showing it as a promising solution for accurate CT-free low-count PET attenuation correction, which also surpasses the performance of previous baseline methods.",
        "comments": "10 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14285"
    },
    {
        "doc_id": 150,
        "title": "Bridging Education and Development: IDEs as Interactive Learning Platforms",
        "authors": [
            "Anastasiia Birillo",
            "Maria Tigina",
            "Zarina Kurbatova",
            "Anna Potriasaeva",
            "Ilya Vlasov",
            "Valerii Ovchinnikov",
            "Igor Gerasimov"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "In this work, we introduce a novel approach to programming education - in-IDE courses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin. The primary objective of this approach is to address the challenge of familiarizing students with industrial technologies by moving all theory and practical materials to a professional IDE. This approach allows students to immediately use modern industrial tools as they are fully integrated into the learning process. We have already applied this approach in over 40 courses, and it successfully educates students across diverse topics such as Plugin Development, Algorithms, Data Analysis, and Language mastery in various programming languages, including Kotlin, Java, C++, and Python. Along with the paper, we are providing the community not only with a new way of learning and a set of ready-made courses but also a collection of helpful resources to assist educators in getting started with the plugin. Finally, we describe in detail an IDE plugin development course that demonstrates how the in-IDE approach covers complex topics easily.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14284"
    },
    {
        "doc_id": 151,
        "title": "Information Leakage Detection through Approximate Bayes-optimal Prediction",
        "authors": [
            "Pritha Gupta",
            "Marcel Wever",
            "Eyke H\u00fcllermeier"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predictor. As the Bayes predictor is typically unknown in practice, we propose to approximate it with the help of automated machine learning (AutoML). First, we compare our MI estimation approaches against current baselines, using synthetic data sets generated using the multivariate normal (MVN) distribution with known MI. Second, we introduce a cut-off technique using one-sided statistical tests to detect IL, employing the Holm-Bonferroni correction to increase confidence in detection decisions. Our study evaluates IL detection performance on real-world data sets, highlighting the effectiveness of the Bayes predictor's log-loss estimation, and finds our proposed method to effectively estimate MI on synthetic data sets and thus detect ILs accurately.",
        "comments": "Under submission in JMLR",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14283"
    },
    {
        "doc_id": 152,
        "title": "RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization",
        "authors": [
            "Jaavid Aktar Husain",
            "Raj Dabre",
            "Aswanth Kumar",
            "Ratish Puduppully",
            "Anoop Kunchukuttan"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Latin scripts. We propose an innovative approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens with English enhance cross-lingual alignment. Focusing on Hindi, we demonstrate through Hindi-to-English translation and sentiment analysis tasks that romanized text not only significantly improves inference efficiency due to its lower fertility compared to native text but also achieves competitive performance with limited pre-training. Additionally, our novel multi-script prompting approach, which combines romanized and native texts, shows promise in further enhancing task performance. These findings suggest the potential of romanization in bridging the language gap for LLM applications, with future work aimed at expanding this approach to more languages and tasks.",
        "comments": "Work in progress",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14280"
    },
    {
        "doc_id": 153,
        "title": "ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code Snippets using ChatGPT",
        "authors": [
            "Azmain Kabir",
            "Shaowei Wang",
            "Yuan Tian",
            "Tse-Hsun",
            "Chen",
            "Muhammad Asaduzzaman",
            "Wenbin Zhang"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Technical question and answering (Q&A) sites such as Stack Overflow have become an important source for software developers to seek knowledge. However, code snippets on Q&A sites are usually uncompilable and semantically incomplete for compilation due to unresolved types and missing dependent libraries, which raises the obstacle for users to reuse or analyze Q&A code snippets. Prior approaches either are not designed for synthesizing compilable code or suffer from a low compilation success rate. To address this problem, we propose ZS4C, a lightweight approach to perform zero-shot synthesis of compilable code from incomplete code snippets using Large Language Model (LLM). ZS4C operates in two stages. In the first stage, ZS4C utilizes an LLM, i.e., ChatGPT, to identify missing import statements for a given code snippet, leveraging our designed task-specific prompt template. In the second stage, ZS4C fixes compilation errors caused by incorrect import statements and syntax errors through collaborative work between ChatGPT and a compiler. We thoroughly evaluated ZS4C on a widely used benchmark called StatType-SO against the SOTA approach SnR. Compared with SnR, ZS4C improves the compilation rate from 63% to 87.6%, with a 39.3% improvement. On average, ZS4C can infer more accurate import statements than SnR, with an improvement of 6.6% in the F1.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14279"
    },
    {
        "doc_id": 154,
        "title": "CHIRON: Accelerating Node Synchronization without Security Trade-offs in Distributed Ledgers",
        "authors": [
            "Ray Neiheiser",
            "Arman Babaei",
            "Giannis Alexopoulos",
            "Marios Kogias",
            "Eleftherios Kokoris Kogias"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Blockchain performance has historically faced challenges posed by the throughput limitations of consensus algorithms. Recent breakthroughs in research have successfully alleviated these constraints by introducing a modular architecture that decouples consensus from execution. The move toward independent optimization of the consensus layer has shifted attention to the execution layer.\n  While concurrent transaction execution is a promising solution for increasing throughput, practical challenges persist. Its effectiveness varies based on the workloads, and the associated increased hardware requirements raise concerns about undesirable centralization. This increased requirement results in full nodes and stragglers synchronizing from signed checkpoints, decreasing the trustless nature of blockchain systems.\n  In response to these challenges, this paper introduces Chiron, a system designed to extract execution hints for the acceleration of straggling and full nodes. Notably, Chiron achieves this without compromising the security of the system or introducing overhead on the critical path of consensus. Evaluation results demonstrate a notable speedup of up to 30%, effectively addressing the gap between theoretical research and practical deployment. The quantification of this speedup is achieved through realistic blockchain benchmarks derived from a comprehensive analysis of Ethereum and Solana workloads, constituting an independent contribution.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14278"
    },
    {
        "doc_id": 155,
        "title": "An Instance-Based Approach to the Trace Reconstruction Problem",
        "authors": [
            "Kayvon Mazooji",
            "Ilan Shomorony"
        ],
        "subjects": [
            "Information Theory",
            "Data Structures and Algorithms",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\" Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.",
        "comments": "7 pages, accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14277"
    },
    {
        "doc_id": 156,
        "title": "Optimization-based motion primitive automata for autonomous driving",
        "authors": [
            "Matheus V. A. Pedrosa",
            "Patrick Scheffe",
            "Bassam Alrifaee",
            "Kathrin Fla\u00dfkamp"
        ],
        "subjects": [
            "Systems and Control",
            "Robotics"
        ],
        "abstract": "Trajectory planning for autonomous cars can be addressed by primitive-based methods, which encode nonlinear dynamical system behavior into automata. In this paper, we focus on optimal trajectory planning. Since, typically, multiple criteria have to be taken into account, multiobjective optimization problems have to be solved. For the resulting Pareto-optimal motion primitives, we introduce a universal automaton, which can be reduced or reconfigured according to prioritized criteria during planning. We evaluate a corresponding multi-vehicle planning scenario with both simulations and laboratory experiments.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14276"
    },
    {
        "doc_id": 157,
        "title": "libcdict: fast dictionaries in C",
        "authors": [
            "Robert G. Izzard",
            "David D. Hendriks",
            "Daniel P. Nemergut"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Astrophysics of Galaxies",
            "High Energy Astrophysical Phenomena",
            "Instrumentation and Methods for Astrophysics",
            "Solar and Stellar Astrophysics"
        ],
        "abstract": "A common requirement in science is to store and share large sets of simulation data in an efficient, nested, flexible and human-readable way. Such datasets contain number counts and distributions, i.e. histograms and maps, of arbitrary dimension and variable type, e.g. floating-point number, integer or character string. Modern high-level programming languages like Perl and Python have associated arrays, knowns as dictionaries or hashes, respectively, to fulfil this storage need. Low-level languages used more commonly for fast computational simulations, such as C and Fortran, lack this functionality. We present libcdict, a C dictionary library, to solve this problem. Libcdict provides C and Fortran application programming interfaces (APIs) to native dictionaries, called cdicts, and functions for cdicts to load and save these as JSON and hence for easy interpretation in other software and languages like Perl, Python and R.",
        "comments": "Accepted for publication in JOSS (The Journal of Open-Source Software)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14272"
    },
    {
        "doc_id": 158,
        "title": "Improving Design of Input Condition Invariant Speech Enhancement",
        "authors": [
            "Wangyou Zhang",
            "Jee-weon Jung",
            "Shinji Watanabe",
            "Yanmin Qian"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Building a single universal speech enhancement (SE) system that can handle arbitrary input is a demanded but underexplored research topic. Towards this ultimate goal, one direction is to build a single model that handles diverse audio duration, sampling frequencies, and microphone variations in noisy and reverberant scenarios, which we define here as \"input condition invariant SE\". Such a model was recently proposed showing promising performance; however, its multi-channel performance degraded severely in real conditions. In this paper we propose novel architectures to improve the input condition invariant SE model so that performance in simulated conditions remains competitive while real condition degradation is much mitigated. For this purpose, we redesign the key components that comprise such a system. First, we identify that the channel-modeling module's generalization to unseen scenarios can be sub-optimal and redesign this module. We further introduce a two-stage training strategy to enhance training efficiency. Second, we propose two novel dual-path time-frequency blocks, demonstrating superior performance with fewer parameters and computational costs compared to the existing method. All proposals combined, experiments on various public datasets validate the efficacy of the proposed model, with significantly improved performance on real conditions. Recipe with full model details is released at https://github.com/espnet/espnet.",
        "comments": "Accepted by ICASSP 2024, 5 pages, 2 figures, 3 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14271"
    },
    {
        "doc_id": 159,
        "title": "Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables",
        "authors": [
            "Max Rosenkranz",
            "Karl A. Kalina",
            "J\u00f6rg Brummund",
            "WaiChing Sun",
            "Markus K\u00e4stner"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "We present an approach for the data-driven modeling of nonlinear viscoelastic materials at small strains which is based on physics-augmented neural networks (NNs) and requires only stress and strain paths for training. The model is built on the concept of generalized standard materials and is therefore thermodynamically consistent by construction. It consists of a free energy and a dissipation potential, which can be either expressed by the components of their tensor arguments or by a suitable set of invariants. The two potentials are described by fully/partially input convex neural networks. For training of the NN model by paths of stress and strain, an efficient and flexible training method based on a recurrent cell, particularly a long short-term memory cell, is developed to automatically generate the internal variable(s) during the training process. The proposed method is benchmarked and thoroughly compared with existing approaches. These include a method that obtains the internal variable by integrating the evolution equation over the entire sequence, while the other method uses an an auxiliary feedforward neural network for the internal variable(s). Databases for training are generated by using a conventional nonlinear viscoelastic reference model, where 3D and 2D plane strain data with either ideal or noisy stresses are generated. The coordinate-based and the invariant-based formulation are compared and the advantages of the latter are demonstrated. Afterwards, the invariant-based model is calibrated by applying the three training methods using ideal or noisy stress data. All methods yield good results, but differ in computation time and usability for large data sets. The presented training method based on a recurrent cell turns out to be particularly robust and widely applicable and thus represents a promising approach for the calibration of other types of models as well.",
        "comments": "21 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14270"
    },
    {
        "doc_id": 160,
        "title": "Combined Generative and Predictive Modeling for Speech Super-resolution",
        "authors": [
            "Heming Wang",
            "Eric W. Healy",
            "DeLiang Wang"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Speech super-resolution (SR) is the task that restores high-resolution speech from low-resolution input. Existing models employ simulated data and constrained experimental settings, which limit generalization to real-world SR. Predictive models are known to perform well in fixed experimental settings, but can introduce artifacts in adverse conditions. On the other hand, generative models learn the distribution of target data and have a better capacity to perform well on unseen conditions. In this study, we propose a novel two-stage approach that combines the strengths of predictive and generative models. Specifically, we employ a diffusion-based model that is conditioned on the output of a predictive model. Our experiments demonstrate that the model significantly outperforms single-stage counterparts and existing strong baselines on benchmark SR datasets. Furthermore, we introduce a repainting technique during the inference of the diffusion process, enabling the proposed model to regenerate high-frequency components even in mismatched conditions. An additional contribution is the collection of and evaluation on real SR recordings, using the same microphone at different native sampling rates. We make this dataset freely accessible, to accelerate progress towards real-world speech super-resolution.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14269"
    },
    {
        "doc_id": 161,
        "title": "GPTVoiceTasker: LLM-Powered Virtual Assistant for Smartphone",
        "authors": [
            "Minh Duc Vu",
            "Han Wang",
            "Zhuang Li",
            "Jieshan Chen",
            "Shengdong Zhao",
            "Zhenchang Xing",
            "Chunyang Chen"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "Virtual assistants have the potential to play an important role in helping users achieves different tasks. However, these systems face challenges in their real-world usability, characterized by inefficiency and struggles in grasping user intentions. Leveraging recent advances in Large Language Models (LLMs), we introduce GptVoiceTasker, a virtual assistant poised to enhance user experiences and task efficiency on mobile devices. GptVoiceTasker excels at intelligently deciphering user commands and executing relevant device interactions to streamline task completion. The system continually learns from historical user commands to automate subsequent usages, further enhancing execution efficiency. Our experiments affirm GptVoiceTasker's exceptional command interpretation abilities and the precision of its task automation module. In our user study, GptVoiceTasker boosted task efficiency in real-world scenarios by 34.85%, accompanied by positive participant feedback. We made GptVoiceTasker open-source, inviting further research into LLMs utilization for diverse tasks through prompt engineering and leveraging user usage data to improve efficiency.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14268"
    },
    {
        "doc_id": 162,
        "title": "Transformers and Cortical Waves: Encoders for Pulling In Context Across Time",
        "authors": [
            "Lyle Muller",
            "Patricia S. Churchland",
            "Terrence J. Sejnowski"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "The capabilities of transformer networks such as ChatGPT and other Large Language Models (LLMs) have captured the world's attention. The crucial computational mechanism underlying their performance relies on transforming a complete input sequence - for example, all the words in a sentence into a long \"encoding vector\" - that allows transformers to learn long-range temporal dependencies in naturalistic sequences. Specifically, \"self-attention\" applied to this encoding vector enhances temporal context in transformers by computing associations between pairs of words in the input sequence. We suggest that waves of neural activity, traveling across single cortical regions or across multiple regions at the whole-brain scale, could implement a similar encoding principle. By encapsulating recent input history into a single spatial pattern at each moment in time, cortical waves may enable temporal context to be extracted from sequences of sensory inputs, the same computational principle used in transformers.",
        "comments": "25 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14267"
    },
    {
        "doc_id": 163,
        "title": "Worst-Case Per-User Error Bound for Asynchronous Unsourced Multiple Access",
        "authors": [
            "Jyun-Sian Wu",
            "Pin-Hsun Lin",
            "Marcel A. Mross",
            "Eduard A. Jorswieck"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "This work considers an asynchronous $\\textsf{K}_a$-active-user unsourced multiple access channel (AUMAC) with the worst-case asynchronicity. The transmitted messages must be decoded within $n$ channel uses, while some codewords are not completely received due to asynchronicities. We consider a constraint of the largest allowed delay of the transmission. The AUMAC lacks the permutation-invariant property of the synchronous UMAC since different permutations of the same codewords with a fixed asynchronicity are distinguishable. Hence, the analyses require calculating all $2^{\\textsf{K}_a}-1$ combinations of erroneously decoded messages. Moreover, transmitters cannot adapt the corresponding codebooks according to asynchronicity due to a lack of information on asynchronicities. To overcome this challenge, a uniform bound of the per-user probability of error (PUPE) is derived by investigating the worst-case of the asynchronous patterns with the delay constraint. Numerical results show the trade-off between the energy-per-bit and the number of active users for different delay constraints. In addition, although the asynchronous transmission reduces interference, the required energy-per-bit increases as the receiver decodes with incompletely received codewords, compared to the synchronous case.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14265"
    },
    {
        "doc_id": 164,
        "title": "Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation",
        "authors": [
            "Minglin Chen",
            "Longguang Wang",
            "Weihao Yuan",
            "Yukun Wang",
            "Zhe Sheng",
            "Yisheng He",
            "Zilong Dong",
            "Liefeng Bo",
            "Yulan Guo"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recently, text-to-3D approaches have achieved high-fidelity 3D content generation using text description. However, the generated objects are stochastic and lack fine-grained control. Sketches provide a cheap approach to introduce such fine-grained control. Nevertheless, it is challenging to achieve flexible control from these sketches due to their abstraction and ambiguity. In this paper, we present a multi-view sketch-guided text-to-3D generation framework (namely, Sketch2NeRF) to add sketch control to 3D generation. Specifically, our method leverages pretrained 2D diffusion models (e.g., Stable Diffusion and ControlNet) to supervise the optimization of a 3D scene represented by a neural radiance field (NeRF). We propose a novel synchronized generation and reconstruction method to effectively optimize the NeRF. In the experiments, we collected two kinds of multi-view sketch datasets to evaluate the proposed method. We demonstrate that our method can synthesize 3D consistent contents with fine-grained sketch control while being high-fidelity to text prompts. Extensive results show that our method achieves state-of-the-art performance in terms of sketch similarity and text alignment.",
        "comments": "11 pages, 9 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14257"
    },
    {
        "doc_id": 165,
        "title": "Producing Plankton Classifiers that are Robust to Dataset Shift",
        "authors": [
            "Cheng Chen",
            "Sreenath Kyathanahally",
            "Marta Reyes",
            "Stefanie Merkli",
            "Ewa Merz",
            "Emanuele Francazi",
            "Marvin Hoege",
            "Francesco Pomati",
            "Marco Baity-Jesi"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Modern plankton high-throughput monitoring relies on deep learning classifiers for species recognition in water ecosystems. Despite satisfactory nominal performances, a significant challenge arises from Dataset Shift, which causes performances to drop during deployment. In our study, we integrate the ZooLake dataset with manually-annotated images from 10 independent days of deployment, serving as test cells to benchmark Out-Of-Dataset (OOD) performances. Our analysis reveals instances where classifiers, initially performing well in In-Dataset conditions, encounter notable failures in practical scenarios. For example, a MobileNet with a 92% nominal test accuracy shows a 77% OOD accuracy. We systematically investigate conditions leading to OOD performance drops and propose a preemptive assessment method to identify potential pitfalls when classifying new data, and pinpoint features in OOD images that adversely impact classification. We present a three-step pipeline: (i) identifying OOD degradation compared to nominal test performance, (ii) conducting a diagnostic analysis of degradation causes, and (iii) providing solutions. We find that ensembles of BEiT vision transformers, with targeted augmentations addressing OOD robustness, geometric ensembling, and rotation-based test-time augmentation, constitute the most robust model, which we call BEsT model. It achieves an 83% OOD accuracy, with errors concentrated on container classes. Moreover, it exhibits lower sensitivity to dataset shift, and reproduces well the plankton abundances. Our proposed pipeline is applicable to generic plankton classifiers, contingent on the availability of suitable test cells. By identifying critical shortcomings and offering practical procedures to fortify models against dataset shift, our study contributes to the development of more reliable plankton classification technologies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14256"
    },
    {
        "doc_id": 166,
        "title": "Interpretable Solutions for Breast Cancer Diagnosis with Grammatical Evolution and Data Augmentation",
        "authors": [
            "Yumnah Hasan",
            "Allan de Lima",
            "Fatemeh Amerehi",
            "Darian Reyes Fernandez de Bulnes",
            "Patrick Healy",
            "Conor Ryan"
        ],
        "subjects": [
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Medical imaging diagnosis increasingly relies on Machine Learning (ML) models. This is a task that is often hampered by severely imbalanced datasets, where positive cases can be quite rare. Their use is further compromised by their limited interpretability, which is becoming increasingly important. While post-hoc interpretability techniques such as SHAP and LIME have been used with some success on so-called black box models, the use of inherently understandable models makes such endeavors more fruitful. This paper addresses these issues by demonstrating how a relatively new synthetic data generation technique, STEM, can be used to produce data to train models produced by Grammatical Evolution (GE) that are inherently understandable. STEM is a recently introduced combination of the Synthetic Minority Oversampling Technique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previously been successfully used to tackle both between class and within class imbalance issues. We test our technique on the Digital Database for Screening Mammography (DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Under the Curve (AUC) results with an ensemble of the top three performing classifiers from a set of eight standard ML classifiers with varying degrees of interpretability. We demonstrate that the GE-derived models present the best AUC while still maintaining interpretable solutions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14255"
    },
    {
        "doc_id": 167,
        "title": "On mission Twitter Profiles: A Study of Selective Toxic Behavior",
        "authors": [
            "Hina Qayyum",
            "Muhammad Ikram",
            "Benjamin Zi Hao Zhao",
            "an D. Wood",
            "Nicolas Kourtellis",
            "Mohamed Ali Kaafar"
        ],
        "subjects": [
            "Computers and Society"
        ],
        "abstract": "The argument for persistent social media influence campaigns, often funded by malicious entities, is gaining traction. These entities utilize instrumented profiles to disseminate divisive content and disinformation, shaping public perception. Despite ample evidence of these instrumented profiles, few identification methods exist to locate them in the wild. To evade detection and appear genuine, small clusters of instrumented profiles engage in unrelated discussions, diverting attention from their true goals. This strategic thematic diversity conceals their selective polarity towards certain topics and fosters public trust.\n  This study aims to characterize profiles potentially used for influence operations, termed 'on-mission profiles,' relying solely on thematic content diversity within unlabeled data. Distinguishing this work is its focus on content volume and toxicity towards specific themes. Longitudinal data from 138K Twitter or X, profiles and 293M tweets enables profiling based on theme diversity. High thematic diversity groups predominantly produce toxic content concerning specific themes, like politics, health, and news classifying them as 'on-mission' profiles.\n  Using the identified ``on-mission\" profiles, we design a classifier for unseen, unlabeled data. Employing a linear SVM model, we train and test it on an 80/20% split of the most diverse profiles. The classifier achieves a flawless 100% accuracy, facilitating the discovery of previously unknown ``on-mission\" profiles in the wild.",
        "comments": "Journal ref:        2023 IEEE International Conference on Big Data (BigData)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14252"
    },
    {
        "doc_id": 168,
        "title": "JUMP: A joint multimodal registration pipeline for neuroimaging with minimal preprocessing",
        "authors": [
            "Adria Casamitjana",
            "Juan Eugenio Iglesias",
            "Raul Tudela",
            "Aida Ninerola-Baizan",
            "Roser Sala-Llonch"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "We present a pipeline for unbiased and robust multimodal registration of neuroimaging modalities with minimal pre-processing. While typical multimodal studies need to use multiple independent processing pipelines, with diverse options and hyperparameters, we propose a single and structured framework to jointly process different image modalities. The use of state-of-the-art learning-based techniques enables fast inferences, which makes the presented method suitable for large-scale and/or multi-cohort datasets with a diverse number of modalities per session. The pipeline currently works with structural MRI, resting state fMRI and amyloid PET images. We show the predictive power of the derived biomarkers using in a case-control study and study the cross-modal relationship between different image modalities. The code can be found in https: //github.com/acasamitjana/JUMP.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14250"
    },
    {
        "doc_id": 169,
        "title": "On generalisability of segment anything model for nuclear instance segmentation in histology images",
        "authors": [
            "Kesi Xu",
            "Lea Goetz",
            "Nasir Rajpoot"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Pre-trained on a large and diverse dataset, the segment anything model (SAM) is the first promptable foundation model in computer vision aiming at object segmentation tasks. In this work, we evaluate SAM for the task of nuclear instance segmentation performance with zero-shot learning and finetuning. We compare SAM with other representative methods in nuclear instance segmentation, especially in the context of model generalisability. To achieve automatic nuclear instance segmentation, we propose using a nuclei detection model to provide bounding boxes or central points of nu-clei as visual prompts for SAM in generating nuclear instance masks from histology images.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14248"
    },
    {
        "doc_id": 170,
        "title": "Contract Usage and Evolution in Android Mobile Applications",
        "authors": [
            "David R. Ferreira",
            "Alexandra Mendes",
            "Jo\u00e3o F. Ferreira"
        ],
        "subjects": [
            "Software Engineering",
            "Logic in Computer Science",
            "Programming Languages"
        ],
        "abstract": "Formal contracts and assertions are effective methods to enhance software quality by enforcing preconditions, postconditions, and invariants. Previous research has demonstrated the value of contracts in traditional software development contexts. However, the adoption and impact of contracts in the context of mobile application development, particularly of Android applications, remain unexplored.\n  To address this, we present the first large-scale empirical study on the presence and use of contracts in Android applications, written in Java or Kotlin. We consider different types of contract elements divided into five categories: conditional runtime exceptions, APIs, annotations, assertions, and other. We analyzed 2,390 Android applications from the F-Droid repository and processed more than 51,749 KLOC to determine 1) how and to what extent contracts are used, 2) how contract usage evolves, and 3) whether contracts are used safely in the context of program evolution and inheritance. Our findings include: 1) although most applications do not specify contracts, annotation-based approaches are the most popular among practitioners; 2) applications that use contracts continue to use them in later versions, but the number of methods increases at a higher rate than the number of contracts; and 3) there are many potentially unsafe specification changes when applications evolve and in subtyping relationships, which indicates a lack of specification stability. Our findings show that it would be desirable to have libraries that standardize contract specifications in Java and Kotlin, and tools that aid practitioners in writing stronger contracts and in detecting contract violations in the context of program evolution and inheritance.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14244"
    },
    {
        "doc_id": 171,
        "title": "Improving Natural Language Capability of Code Large Language Model",
        "authors": [
            "Wei Li",
            "Daoguang Zan",
            "Bei Guan",
            "Ailun Yu",
            "Xiaolin Chen",
            "Yongji Wang"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Code large language models (Code LLMs) have demonstrated remarkable performance in code generation. Nonetheless, most existing works focus on boosting code LLMs from the perspective of programming capabilities, while their natural language capabilities receive less attention. To fill this gap, we thus propose a novel framework, comprising two modules: AttentionExtractor, which is responsible for extracting key phrases from the user's natural language requirements, and AttentionCoder, which leverages these extracted phrases to generate target code to solve the requirement. This framework pioneers an innovative idea by seamlessly integrating code LLMs with traditional natural language processing tools. To validate the effectiveness of the framework, we craft a new code generation benchmark, called MultiNL-H, covering five natural languages. Extensive experimental results demonstrate the effectiveness of our proposed framework.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14242"
    },
    {
        "doc_id": 172,
        "title": "New Algorithms for Computing Sibson Capacity and Arimoto Capacity",
        "authors": [
            "Akira Kamatsuka",
            "Yuki Ishikawa",
            "Koki Kazama",
            "Takahiro Yoshida"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "The Arimoto capacity and Sibson capacity, which are based on the Arimoto and Sibson mutual information (MI) of order \u03b1, respectively, are well-known generalizations of the channel capacity C. In this study, we derive novel alternating optimization algorithms for computing these capacities by providing new max characterizations of the Arimoto MI and Sibson MI. Moreover, we prove that all iterative algorithms for computing these capacities are equivalent under appropriate conditions imposed on their initial distributions",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14241"
    },
    {
        "doc_id": 173,
        "title": "Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda",
        "authors": [
            "Richard Kimera",
            "Daniela N. Rim",
            "Joseph Kirabira",
            "Ubong Godwin Udomah",
            "Heeyoul Choi"
        ],
        "subjects": [
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Depression is a global burden and one of the most challenging mental health conditions to control. Experts can detect its severity early using the Beck Depression Inventory (BDI) questionnaire, administer appropriate medication to patients, and impede its progression. Due to the fear of potential stigmatization, many patients turn to social media platforms like Reddit for advice and assistance at various stages of their journey. This research extracts text from Reddit to facilitate the diagnostic process. It employs a proposed labeling approach to categorize the text and subsequently fine-tunes the Longformer model. The model's performance is compared against baseline models, including Naive Bayes, Random Forest, Support Vector Machines, and Gradient Boosting. Our findings reveal that the Longformer model outperforms the baseline models in both English (48%) and Luganda (45%) languages on a custom-made dataset.",
        "comments": "In IEEE Proceedings of the 14th International Conference on ICT Convergence (ICTC), Jeju, Korea, October 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14240"
    },
    {
        "doc_id": 174,
        "title": "Exploring the Unexplored: Understanding the Impact of Layer Adjustments on Image Classification",
        "authors": [
            "Haixia Liu",
            "Tim Brailsford",
            "James Goulding",
            "Gavin Smith",
            "Larry Bull"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "This paper investigates how adjustments to deep learning architectures impact model performance in image classification. Small-scale experiments generate initial insights although the trends observed are not consistent with the entire dataset. Filtering operations in the image processing pipeline are crucial, with image filtering before pre-processing yielding better results. The choice and order of layers as well as filter placement significantly impact model performance. This study provides valuable insights into optimizing deep learning models, with potential avenues for future research including collaborative platforms.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14236"
    },
    {
        "doc_id": 175,
        "title": "AR-GAN: Generative Adversarial Network-Based Defense Method Against Adversarial Attacks on the Traffic Sign Classification System of Autonomous Vehicles",
        "authors": [
            "M Sabbir Salek",
            "Abdullah Al Mamun",
            "Mashrur Chowdhury"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This study developed a generative adversarial network (GAN)-based defense method for traffic sign classification in an autonomous vehicle (AV), referred to as the attack-resilient GAN (AR-GAN). The novelty of the AR-GAN lies in (i) assuming zero knowledge of adversarial attack models and samples and (ii) providing consistently high traffic sign classification performance under various adversarial attack types. The AR-GAN classification system consists of a generator that denoises an image by reconstruction, and a classifier that classifies the reconstructed image. The authors have tested the AR-GAN under no-attack and under various adversarial attacks, such as Fast Gradient Sign Method (FGSM), DeepFool, Carlini and Wagner (C&W), and Projected Gradient Descent (PGD). The authors considered two forms of these attacks, i.e., (i) black-box attacks (assuming the attackers possess no prior knowledge of the classifier), and (ii) white-box attacks (assuming the attackers possess full knowledge of the classifier). The classification performance of the AR-GAN was compared with several benchmark adversarial defense methods. The results showed that both the AR-GAN and the benchmark defense methods are resilient against black-box attacks and could achieve similar classification performance to that of the unperturbed images. However, for all the white-box attacks considered in this study, the AR-GAN method outperformed the benchmark defense methods. In addition, the AR-GAN was able to maintain its high classification performance under varied white-box adversarial perturbation magnitudes, whereas the performance of the other defense methods dropped abruptly at increased perturbation magnitudes.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.14232"
    },
    {
        "doc_id": 176,
        "title": "Strongly k-recursive sequences",
        "authors": [
            "Daniel Krenn",
            "Jeffrey Shallit"
        ],
        "subjects": [
            "Formal Languages and Automata Theory",
            "Discrete Mathematics",
            "Combinatorics"
        ],
        "abstract": "Drawing inspiration from a recent paper of Heuberger, Krenn, and Lipnik, we define the class of strongly k-recursive sequences. We show that every k-automatic sequence is strongly $k$-recursive, therefore k-recursive, and discuss that the converse is not true.\n  We also show that the class of strongly k-recursive sequences is a proper subclass of the class of k-regular sequences, and we present some explicit examples. We then extend the proof techniques to answer the same question for the class of k-recursive sequences.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14231"
    },
    {
        "doc_id": 177,
        "title": "Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods",
        "authors": [
            "Mohammed Sabry",
            "Anya Belz"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "As the cost of training ever larger language models has grown, so has the interest in reusing previously learnt knowledge. Transfer learning methods have shown how reusing non-task-specific knowledge can help in subsequent task-specific learning. In this paper, we investigate the inverse: porting whole functional modules that encode task-specific knowledge from one model to another. We designed a study comprising 1,440 training/testing runs to test the portability of modules trained by parameter-efficient finetuning (PEFT) techniques, using sentiment analysis as an example task. We test portability in a wide range of scenarios, involving different PEFT techniques and different pretrained host models, among other dimensions. We compare the performance of ported modules with that of equivalent modules trained (i) from scratch, and (ii) from parameters sampled from the same distribution as the ported module. We find that the ported modules far outperform the two alternatives tested, but that there are interesting performance differences between the four PEFT techniques. We conclude that task-specific knowledge in the form of structurally modular sets of parameters as produced by PEFT techniques is highly portable, but that degree of success depends on type of PEFT and on differences between originating and receiving pretrained models.",
        "comments": "Accepted to Findings of EACL 2024. Camera ready version",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14228"
    },
    {
        "doc_id": 178,
        "title": "Sample Efficient Reinforcement Learning by Automatically Learning to Compose Subtasks",
        "authors": [
            "Shuai Han",
            "Mehdi Dastani",
            "Shihan Wang"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Improving sample efficiency is central to Reinforcement Learning (RL), especially in environments where the rewards are sparse. Some recent approaches have proposed to specify reward functions as manually designed or learned reward structures whose integrations in the RL algorithms are claimed to significantly improve the learning efficiency. Manually designed reward structures can suffer from inaccuracy and existing automatically learning methods are often computationally intractable for complex tasks. The integration of inaccurate or partial reward structures in RL algorithms fail to learn optimal policies. In this work, we propose an RL algorithm that can automatically structure the reward function for sample efficiency, given a set of labels that signify subtasks. Given such minimal knowledge about the task, we train a high-level policy that selects optimal sub-tasks in each state together with a low-level policy that efficiently learns to complete each sub-task. We evaluate our algorithm in a variety of sparse-reward environments. The experiment results show that our approach significantly outperforms the state-of-art baselines as the difficulty of the task increases.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14226"
    },
    {
        "doc_id": 179,
        "title": "InfiniteEn: A Multi-Source Energy Harvesting System with Load Monitoring Module for Batteryless Internet of Things",
        "authors": [
            "Priyesh Pappinisseri Puluckul",
            "Maarten Weyn"
        ],
        "subjects": [
            "Signal Processing",
            "Hardware Architecture"
        ],
        "abstract": "This paper presents InfiniteEn, a multi-source energy harvesting platform designed for the Internet of Batteryless Things (IoBT). InfiniteEn incorporates an efficient energy combiner to combine energy from different harvesting sources. The energy combiner uses capacitor-to-capacitor energy transfer to combine energy from multiple sources and achieves a nominal efficiency of 88\\%. In addition to multiplexing different sources, the energy combiner facilitates the estimation of the harvesting rate and the calibration of the capacity of the energy buffer. The energy storage architecture of InfiniteEn employs an array of storage buffers that can be configured on demand to cope with varying energy harvesting rates and load's energy requirements. To address the challenge of tracking the energy state of batteryless devices with minimum energy overhead, this work introduces the concept of a Load Monitoring Module (LMM). InfiniteEn is a load-agnostic platform, meaning that it does not require any prior knowledge of the energy profile of the load to track its energy states. The LMM assists InfiniteEn in tracking the energy state of the load and dynamically modifying the storage buffers to meet the load's energy requirements. Furthermore, the module can detect and signal any abnormalities in the energy consumption pattern of the load caused by a hardware or software defect. Experiments demonstrate that LMM has a response time of less than 11 ms to energy state changes.",
        "comments": "Accepted and presented at \"2023 IEEE World Forum on Internet of Things (WF-IoT)\" and to be published in IEEE Conference Proceedings",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14216"
    },
    {
        "doc_id": 180,
        "title": "Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement",
        "authors": [
            "Hana Kim",
            "Kai Tzu-iunn Ong",
            "Seoyeon Kim",
            "Dongha Lee",
            "Jinyoung Yeo"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Memorizing and utilizing speakers' personas is a common practice for response generation in long-term conversations. Yet, human-authored datasets often provide uninformative persona sentences that hinder response quality. This paper presents a novel framework that leverages commonsense-based persona expansion to address such issues in long-term conversation. While prior work focuses on not producing personas that contradict others, we focus on transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies. As the pioneer of persona expansion in multi-session settings, our framework facilitates better response generation via human-like persona refinement. The supplementary video of our work is available at https://caffeine-15bbf.web.app/.",
        "comments": "Accepted to EACL 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14215"
    },
    {
        "doc_id": 181,
        "title": "A Quantitative Version of More Capable Channel Comparison",
        "authors": [
            "Donald Kougang-Yombi",
            "Jan H\u0105z\u0142a"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "This paper introduces a quantitative generalization of the ``more capable'' comparison of broadcast channels, which is termed ``more capable with advantage''. Some basic properties are demonstrated (including tensorization on product channels), and a characterisation is given for the cases of Binary Symmetric Channel (BSC) and Binary Erasure Channel (BEC).\n  It is then applied to two problems. First, a list decoding bound on the BSC is given that applies to transitive codes that achieve capacity on the BEC. Second, new lower bounds on entropy rates of binary hidden Markov processes are derived.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14214"
    },
    {
        "doc_id": 182,
        "title": "Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations",
        "authors": [
            "Wolf Nuyts",
            "Ruben Cartuyvels",
            "Marie-Francine Moens"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Recognizing visual entities in a natural language sentence and arranging them in a 2D spatial layout require a compositional understanding of language and space. This task of layout prediction is valuable in text-to-image synthesis as it allows localized and controlled in-painting of the image. In this comparative study it is shown that we can predict layouts from language representations that implicitly or explicitly encode sentence syntax, if the sentences mention similar entity-relationships to the ones seen during training. To test compositional understanding, we collect a test set of grammatically correct sentences and layouts describing compositions of entities and relations that unlikely have been seen during training. Performance on this test set substantially drops, showing that current models rely on correlations in the training data and have difficulties in understanding the structure of the input sentences. We propose a novel structural loss function that better enforces the syntactic structure of the input sentence and show large performance gains in the task of 2D spatial layout prediction conditioned on text. The loss has the potential to be used in other generation tasks where a tree-like structure underlies the conditioning modality. Code, trained models and the USCOCO evaluation set will be made available via github.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14212"
    },
    {
        "doc_id": 183,
        "title": "Communication-Efficient Federated Learning through Adaptive Weight Clustering and Server-Side Distillation",
        "authors": [
            "Vasileios Tsouvalas. Aaqib Saeed",
            "Tanir Ozcelebi",
            "Nirvana Meratnia"
        ],
        "subjects": [
            "Machine Learning",
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Federated Learning (FL) is a promising technique for the collaborative training of deep neural networks across multiple devices while preserving data privacy. Despite its potential benefits, FL is hindered by excessive communication costs due to repeated server-client communication during training. To address this challenge, model compression techniques, such as sparsification and weight clustering are applied, which often require modifying the underlying model aggregation schemes or involve cumbersome hyperparameter tuning, with the latter not only adjusts the model's compression rate but also limits model's potential for continuous improvement over growing data. In this paper, we propose FedCompress, a novel approach that combines dynamic weight clustering and server-side knowledge distillation to reduce communication costs while learning highly generalizable models. Through a comprehensive evaluation on diverse public datasets, we demonstrate the efficacy of our approach compared to baselines in terms of communication costs and inference speed. We will make our implementation public upon acceptance.",
        "comments": "9 pages, 2 figures, Accepted on ICASSP 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14211"
    },
    {
        "doc_id": 184,
        "title": "At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition",
        "authors": [
            "Ashok Dahal",
            "Rapha\u00ebl Huser",
            "Luigi Lombardo"
        ],
        "subjects": [
            "Machine Learning",
            "Geophysics",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple return periods. We also use our model to further explore landslide hazard for the same return periods under different climate change scenarios up to the end of the century. Our results show that the proposed model performs excellently and can be used to model landslide hazard in a unified manner. Geomorphologically, we find that under both climate change scenarios (SSP245 and SSP885), landslide hazard is likely to increase up to two times on average in the lower Himalayan regions while remaining the same in the middle Himalayan region whilst decreasing slightly in the upper Himalayan region areas.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14210"
    },
    {
        "doc_id": 185,
        "title": "Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation classification",
        "authors": [
            "Daniele Perlo",
            "Luca Berton",
            "Alessia Delpiano",
            "Francesca Menchini",
            "Stefano Tibaldi",
            "Marco Grosso",
            "Paolo Fonio"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence"
        ],
        "abstract": "The liver is the most involved organ by distant metastasis in colon-rectal cancer (CRC) patients and it comes necessary to be aware of the mutational status of the lesions to correctly design the best individual treatment. So far, efforts have been made in order to develop non-invasive and real-time methods that permit the analysis of the whole tumor, using new artificial intelligence tools to analyze the tumor's image obtained by Computed Tomography (CT) scan. In order to address the current medical workflow, that is biopsy analysis-based, we propose the first DeepLearning-based exploration, to our knowledge, of such classification approach from the patient medical imaging. We propose i) a solid pipeline for managing undersized datasets of available CT scans and ii) a baseline study for genomics mutation diagnosis support for preemptive patient follow-up. Our method is able to identify CRC RAS mutation family from CT images with 0.73 F1 score.",
        "comments": "ACM Class:          J.3; I.1.2",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14206"
    },
    {
        "doc_id": 186,
        "title": "Statistical Characterization of RIS-assisted UAV Communications in Terrestrial and Non-Terrestrial Networks Under Channel Aging",
        "authors": [
            "Thanh Luan Nguyen",
            "Georges Kaddoum",
            "Tri Nhu Do",
            "Zygmunt J. Haas"
        ],
        "subjects": [
            "Signal Processing",
            "Information Theory"
        ],
        "abstract": "This paper studies the statistical characterization of ground-to-UAV (G2A) and reconfigurable intelligent surface (RIS)-assisted UAV-to-ground (A2G) communications in terrestrial and non-terrestrial networks under the impact of channel aging. We first model the G2A and A2G signal-to-noise ratios as non-central complex Gaussian quadratic random variables (RVs) and derive their exact probability density functions, offering a unique characterization for the A2G SNR as the product of two scaled non-central chi-square RVs. Moreover, we also find that, for a large number of RIS elements, the RIS-assisted A2G channel can be characterized as a single Rician fading channel. Our results reveal the presence of channel hardening in A2G communication under low UAV speeds, where we derive the maximum target spectral efficiency (SE) for a system to maintain a consistent required outage level. Meanwhile, high UAV speeds, exceeding 50 m/s, lead to a significant performance degradation, which cannot be mitigated by increasing the number of RIS elements.",
        "comments": "6 pages, 3 figures and 7 subfigures, IEEE ICC'24 (Revision),",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14203"
    },
    {
        "doc_id": 187,
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics",
            "Trading and Market Microstructure"
        ],
        "abstract": "In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14199"
    },
    {
        "doc_id": 188,
        "title": "DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence",
        "authors": [
            "Daya Guo",
            "Qihao Zhu",
            "Dejian Yang",
            "Zhenda Xie",
            "Kai Dong",
            "Wentao Zhang",
            "Guanting Chen",
            "Xiao Bi",
            "Y. Wu",
            "Y. K. Li",
            "Fuli Luo",
            "Yingfei Xiong",
            "Wenfeng Liang"
        ],
        "subjects": [
            "Software Engineering",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "The rapid development of large language models has revolutionized code intelligence in software development. However, the predominance of closed-source models has restricted extensive research and development. To address this, we introduce the DeepSeek-Coder series, a range of open-source code models with sizes from 1.3B to 33B, trained from scratch on 2 trillion tokens. These models are pre-trained on a high-quality project-level code corpus and employ a fill-in-the-blank task with a 16K window to enhance code generation and infilling. Our extensive evaluations demonstrate that DeepSeek-Coder not only achieves state-of-the-art performance among open-source code models across multiple benchmarks but also surpasses existing closed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder models are under a permissive license that allows for both research and unrestricted commercial use.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14196"
    },
    {
        "doc_id": 189,
        "title": "Parameter-Efficient Conversational Recommender System as a Language Processing Task",
        "authors": [
            "Mathieu Ravaut",
            "Hao Zhang",
            "Lu Xu",
            "Aixin Sun",
            "Yong Liu"
        ],
        "subjects": [
            "Computation and Language"
        ],
        "abstract": "Conversational recommender systems (CRS) aim to recommend relevant items to users by eliciting user preference through natural language conversation. Prior work often utilizes external knowledge graphs for items' semantic information, a language model for dialogue generation, and a recommendation module for ranking relevant items. This combination of multiple components suffers from a cumbersome training process, and leads to semantic misalignment issues between dialogue generation and item recommendation. In this paper, we represent items in natural language and formulate CRS as a natural language processing task. Accordingly, we leverage the power of pre-trained language models to encode items, understand user intent via conversation, perform item recommendation through semantic matching, and generate dialogues. As a unified model, our PECRS (Parameter-Efficient CRS), can be optimized in a single stage, without relying on non-textual metadata such as a knowledge graph. Experiments on two benchmark CRS datasets, ReDial and INSPIRED, demonstrate the effectiveness of PECRS on recommendation and conversation. Our code is available at: https://github.com/Ravoxsg/efficient_unified_crs.",
        "comments": "9 pages, 4 figures, 7 tables, EACL 2024 conference",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14194"
    },
    {
        "doc_id": 190,
        "title": "Clinical Melanoma Diagnosis with Artificial Intelligence: Insights from a Prospective Multicenter Study",
        "authors": [
            "Lukas Heinlein",
            "Roman C. Maron",
            "Achim Hekler",
            "Sarah Haggenm\u00fcller",
            "Christoph Wies",
            "Jochen S. Utikal",
            "Friedegund Meier",
            "Sarah Hobelsberger",
            "Frank F. Gellrich",
            "Mildred Sergon",
            "Axel Hauschild",
            "Lars E. French",
            "Lucie Heinzerling",
            "Justin G. Schlager",
            "Kamran Ghoreschi",
            "Max Schlaak",
            "Franz J. Hilke",
            "Gabriela Poch",
            "S\u00f6ren Korsing",
            "Carola Berking",
            "Markus V. Heppt",
            "Michael Erdmann",
            "Sebastian Haferkamp",
            "Konstantin Drexler",
            "Dirk Schadendorf",
            "et al. (5 additional authors not shown)"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Applications"
        ],
        "abstract": "Early detection of melanoma, a potentially lethal type of skin cancer with high prevalence worldwide, improves patient prognosis. In retrospective studies, artificial intelligence (AI) has proven to be helpful for enhancing melanoma detection. However, there are few prospective studies confirming these promising results. Existing studies are limited by low sample sizes, too homogenous datasets, or lack of inclusion of rare melanoma subtypes, preventing a fair and thorough evaluation of AI and its generalizability, a crucial aspect for its application in the clinical setting. Therefore, we assessed 'All Data are Ext' (ADAE), an established open-source ensemble algorithm for detecting melanomas, by comparing its diagnostic accuracy to that of dermatologists on a prospectively collected, external, heterogeneous test set comprising eight distinct hospitals, four different camera setups, rare melanoma subtypes, and special anatomical sites. We advanced the algorithm with real test-time augmentation (R-TTA, i.e. providing real photographs of lesions taken from multiple angles and averaging the predictions), and evaluated its generalization capabilities. Overall, the AI showed higher balanced accuracy than dermatologists (0.798, 95% confidence interval (CI) 0.779-0.814 vs. 0.781, 95% CI 0.760-0.802; p<0.001), obtaining a higher sensitivity (0.921, 95% CI 0.900- 0.942 vs. 0.734, 95% CI 0.701-0.770; p<0.001) at the cost of a lower specificity (0.673, 95% CI 0.641-0.702 vs. 0.828, 95% CI 0.804-0.852; p<0.001). As the algorithm exhibited a significant performance advantage on our heterogeneous dataset exclusively comprising melanoma-suspicious lesions, AI may offer the potential to support dermatologists particularly in diagnosing challenging cases.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14193"
    },
    {
        "doc_id": 191,
        "title": "How Can Large Language Models Understand Spatial-Temporal Data?",
        "authors": [
            "Lei Liu",
            "Shuo Yu",
            "Runze Wang",
            "Zhenxun Ma",
            "Yanming Shen"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language"
        ],
        "abstract": "While Large Language Models (LLMs) dominate tasks like natural language processing and computer vision, harnessing their power for spatial-temporal forecasting remains challenging. The disparity between sequential text and complex spatial-temporal data hinders this application. To address this issue, this paper introduces STG-LLM, an innovative approach empowering LLMs for spatial-temporal forecasting. We tackle the data mismatch by proposing: 1) STG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph data into concise tokens capturing both spatial and temporal relationships; 2) STG-Adapter: This minimalistic adapter, consisting of linear encoding and decoding layers, bridges the gap between tokenized data and LLM comprehension. By fine-tuning only a small set of parameters, it can effectively grasp the semantics of tokens generated by STG-Tokenizer, while preserving the original natural language understanding capabilities of LLMs. Extensive experiments on diverse spatial-temporal benchmark datasets show that STG-LLM successfully unlocks LLM potential for spatial-temporal forecasting. Remarkably, our approach achieves competitive performance on par with dedicated SOTA methods.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14192"
    },
    {
        "doc_id": 192,
        "title": "TDFNet: An Efficient Audio-Visual Speech Separation Model with Top-down Fusion",
        "authors": [
            "Samuel Pegg",
            "Kai Li",
            "Xiaolin Hu"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Audio and Speech Processing"
        ],
        "abstract": "Audio-visual speech separation has gained significant traction in recent years due to its potential applications in various fields such as speech recognition, diarization, scene analysis and assistive technologies. Designing a lightweight audio-visual speech separation network is important for low-latency applications, but existing methods often require higher computational costs and more parameters to achieve better separation performance. In this paper, we present an audio-visual speech separation model called Top-Down-Fusion Net (TDFNet), a state-of-the-art (SOTA) model for audio-visual speech separation, which builds upon the architecture of TDANet, an audio-only speech separation method. TDANet serves as the architectural foundation for the auditory and visual networks within TDFNet, offering an efficient model with fewer parameters. On the LRS2-2Mix dataset, TDFNet achieves a performance increase of up to 10\\% across all performance metrics compared with the previous SOTA method CTCNet. Remarkably, these results are achieved using fewer parameters and only 28\\% of the multiply-accumulate operations (MACs) of CTCNet. In essence, our method presents a highly effective and efficient solution to the challenges of speech separation within the audio-visual domain, making significant strides in harnessing visual information optimally.",
        "comments": "Journal ref:        2023 13th International Conference on Information Science and Technology (ICIST), Cairo, Egypt, 2023, pp. 243-252",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14185"
    },
    {
        "doc_id": 193,
        "title": "Friendly Attacks to Improve Channel Coding Reliability",
        "authors": [
            "Anastasiia Kurmukova",
            "Deniz Gunduz"
        ],
        "subjects": [
            "Information Theory",
            "Machine Learning"
        ],
        "abstract": "This paper introduces a novel approach called \"friendly attack\" aimed at enhancing the performance of error correction channel codes. Inspired by the concept of adversarial attacks, our method leverages the idea of introducing slight perturbations to the neural network input, resulting in a substantial impact on the network's performance. By introducing small perturbations to fixed-point modulated codewords before transmission, we effectively improve the decoder's performance without violating the input power constraint. The perturbation design is accomplished by a modified iterative fast gradient method. This study investigates various decoder architectures suitable for computing gradients to obtain the desired perturbations. Specifically, we consider belief propagation (BP) for LDPC codes; the error correcting code transformer, BP and neural BP (NBP) for polar codes, and neural BCJR for convolutional codes. We demonstrate that the proposed friendly attack method can improve the reliability across different channels, modulations, codes, and decoders. This method allows us to increase the reliability of communication with a legacy receiver by simply modifying the transmitted codeword appropriately.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14184"
    },
    {
        "doc_id": 194,
        "title": "Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Yaniv Proselkov",
            "Alexandra Brintrup"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Multiagent Systems",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Recent global disruptions, such as the pandemic and geopolitical conflicts, have profoundly exposed vulnerabilities in traditional supply chains, requiring exploration of more resilient alternatives. Autonomous supply chains (ASCs) have emerged as a potential solution, offering increased visibility, flexibility, and resilience in turbulent trade environments. Despite discussions in industry and academia over several years, ASCs lack well-established theoretical foundations. This paper addresses this research gap by presenting a formal definition of ASC along with its defining characteristics and auxiliary concepts. We propose a layered conceptual framework called the MIISI model. An illustrative case study focusing on the meat supply chain demonstrates an initial ASC implementation based on this conceptual model. Additionally, we introduce a seven-level supply chain autonomy reference model, delineating a trajectory towards achieving a full supply chain autonomy. Recognising that this work represents an initial endeavour, we emphasise the need for continued exploration in this emerging domain. We anticipate that this work will stimulate further research, both theoretical and technical, and contribute to the continual evolution of ASCs.",
        "comments": "This paper includes 20 pages and 8 figures",
        "date": "13 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.14183"
    },
    {
        "doc_id": 195,
        "title": "Copilot Refinement: Addressing Code Smells in Copilot-Generated Python Code",
        "authors": [
            "Beiqi Zhang",
            "Peng Liang",
            "Qiong Feng",
            "Yujia Fu",
            "Zengyang Li"
        ],
        "subjects": [
            "Software Engineering",
            "Artificial Intelligence"
        ],
        "abstract": "As one of the most popular dynamic languages, Python experiences a decrease in readability and maintainability when code smells are present. Recent advancements in Large Language Models have sparked growing interest in AI-enabled tools for both code generation and refactoring. GitHub Copilot is one such tool that has gained widespread usage. Copilot Chat, released on September 2023, functions as an interactive tool aims at facilitating natural language-powered coding. However, limited attention has been given to understanding code smells in Copilot-generated Python code and Copilot's ability to fix the code smells it generates. To this end, we built a dataset comprising 102 code smells in Copilot-generated Python code. Our aim is to first explore the occurrence of code smells in Copilot-generated Python code and then evaluate the effectiveness of Copilot in fixing these code smells employing different prompts. The results show that 8 out of 10 types of Python smells can be detected in Copilot-generated Python code, among which Multiply-Nested Container is the most common one. For these code smells, Copilot Chat achieves a highest fixing rate of 87.1%, showing promise in fixing Python code smells generated by Copilot itself. Besides, the effectiveness of Copilot Chat in fixing these smells can be improved with the provision of more detailed prompts. However, using Copilot Chat to fix these smells might introduce new code smells.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14176"
    },
    {
        "doc_id": 196,
        "title": "The Boundaries of Tractability in Hierarchical Task Network Planning",
        "authors": [
            "Cornelius Brand",
            "Robert Ganian",
            "Fionn Mc Inerney",
            "Simon Wietheger"
        ],
        "subjects": [
            "Computational Complexity",
            "Artificial Intelligence"
        ],
        "abstract": "We study the complexity-theoretic boundaries of tractability for three classical problems in the context of Hierarchical Task Network Planning: the validation of a provided plan, whether an executable plan exists, and whether a given state can be reached by some plan. We show that all three problems can be solved in polynomial time on primitive task networks of constant partial order width (and a generalization thereof), whereas for the latter two problems this holds only under a provably necessary restriction to the state space. Next, we obtain an algorithmic meta-theorem along with corresponding lower bounds to identify tight conditions under which general polynomial-time solvability results can be lifted from primitive to general task networks. Finally, we enrich our investigation by analyzing the parameterized complexity of the three considered problems, and show that (1) fixed-parameter tractability for all three problems can be achieved by replacing the partial order width with the vertex cover number of the network as the parameter, and (2) other classical graph-theoretic parameters of the network (including treewidth, treedepth, and the aforementioned partial order width) do not yield fixed-parameter tractability for any of the three problems.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14174"
    },
    {
        "doc_id": 197,
        "title": "Multicasting Optical Reconfigurable Switch",
        "authors": [
            "Niyazi Ulas Dinc",
            "Mustafa Yildirim",
            "Christophe Moser",
            "Demetri Psaltis"
        ],
        "subjects": [
            "Optics",
            "Networking and Internet Architecture"
        ],
        "abstract": "Artificial Intelligence (AI) demands large data flows within datacenters, heavily relying on multicasting data transfers. As AI models scale, the requirement for high-bandwidth and low-latency networking compounds. The common use of electrical packet switching faces limitations due to its optical-electrical-optical conversion bottleneck. Optical switches, while bandwidth-agnostic and low-latency, suffer from having only unicast or non-scalable multicasting capability. This paper introduces an optical switching technique addressing the scalable multicasting challenge. Our approach enables arbitrarily programmable simultaneous unicast and multicast connectivity, eliminating the need for optical splitters that hinder scalability due to optical power loss. We use phase modulation in multiple planes, tailored to implement any multicast connectivity map. Using phase modulation enables wavelength selectivity on top of spatial selectivity, resulting in an optical switch that implements space-wavelength routing. We conducted simulations and experiments to validate our approach. Our results affirm the concept's feasibility and effectiveness, as a multicasting switch.",
        "comments": "12 pages, 3 figures, article",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14173"
    },
    {
        "doc_id": 198,
        "title": "Predicting Hypoxia in Brain Tumors from Multiparametric MRI",
        "authors": [
            "Daniele Perlo",
            "Georgia Kanli",
            "Selma Boudissa",
            "Olivier Keunen"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence"
        ],
        "abstract": "This research paper presents a novel approach to the prediction of hypoxia in brain tumors, using multi-parametric Magnetic Resonance Imaging (MRI). Hypoxia, a condition characterized by low oxygen levels, is a common feature of malignant brain tumors associated with poor prognosis. Fluoromisonidazole Positron Emission Tomography (FMISO PET) is a well-established method for detecting hypoxia in vivo, but it is expensive and not widely available. Our study proposes the use of MRI, a more accessible and cost-effective imaging modality, to predict FMISO PET signals. We investigate deep learning models (DL) trained on the ACRIN 6684 dataset, a resource that contains paired MRI and FMISO PET images from patients with brain tumors. Our trained models effectively learn the complex relationships between the MRI features and the corresponding FMISO PET signals, thereby enabling the prediction of hypoxia from MRI scans alone. The results show a strong correlation between the predicted and actual FMISO PET signals, with an overall PSNR score above 29.6 and a SSIM score greater than 0.94, confirming MRI as a promising option for hypoxia prediction in brain tumors. This approach could significantly improve the accessibility of hypoxia detection in clinical settings, with the potential for more timely and targeted treatments.",
        "comments": "7 pages, 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14171"
    },
    {
        "doc_id": 199,
        "title": "Vivim: a Video Vision Mamba for Medical Video Object Segmentation",
        "authors": [
            "Yijun Yang",
            "Zhaohu Xing",
            "Lei Zhu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Traditional convolutional neural networks have a limited receptive field while transformer-based networks are mediocre in constructing long-term dependency from the perspective of computational complexity. Such the bottleneck poses a significant challenge when processing long video sequences in video analysis tasks. Very recently, the state space models (SSMs) with efficient hardware-aware designs, famous by Mamba, have exhibited impressive achievements in long sequence modeling, which facilitates the development of deep neural networks on many vision tasks. To better capture available cues in video frames, this paper presents a generic Video Vision Mamba-based framework for medical video object segmentation tasks, named Vivim. Our Vivim can effectively compress the long-term spatiotemporal representation into sequences at varying scales by our designed Temporal Mamba Block. Compared to existing video-level Transformer-based methods, our model maintains excellent segmentation results with better speed performance. Extensive experiments on the breast US dataset demonstrate the effectiveness and efficiency of our Vivim. The code for Vivim is available at: https://github.com/scott-yjyang/Vivim.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14168"
    },
    {
        "doc_id": 200,
        "title": "Identification of Nonseparable Models with Endogenous Control Variables",
        "authors": [
            "Kaicheng Chen",
            "Kyoo il Kim"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "We study identification of the treatment effects in a class of nonseparable models with the presence of potentially endogenous control variables. We show that given the treatment variable and the controls are measurably separated, the usual conditional independence condition or availability of excluded instrument suffices for identification.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14395"
    },
    {
        "doc_id": 201,
        "title": "Using Geographically Weighted Models to Explore Temporal and Spatial Varying Impacts on Commute Trip Change Due to Covid-19",
        "authors": [
            "Saeed Saleh Namadi",
            "Behnam Tahmasbi",
            "Asal Mehditabrizi",
            "Aref Darzi",
            "Deb Niemeier"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "COVID-19 has deeply affected daily life and travel behaviors. Understanding these changes is crucial, prompting an investigation into socio-demographic and socio-economic factors. This study used large-scale mobile device location data in Washington, D.C., Maryland, and Virginia (DMV area) to unveil the impacts of these variables on commute trip changes. It reflected short and long-term impacts through linear regression and geographically weighted regression models. Findings indicated that counties with a higher percentage of people using walking and biking during the initial phase of COVID-19 experienced greater reductions in commute trips. For the long-term effect in November, the impact of active modes became insignificant, and individuals using public modes showed more significant trip reductions. Positive correlations were observed between median income levels and reduced commute trips. Sectors requiring ongoing outdoor operations during the pandemic showed substantial negative correlations. In the DMV area, counties with a higher proportion of Democratic voters experienced less trip reduction. Applying Geographically Weighted Regression models captured local spatial relationships, showing the emergence of local correlations as the pandemic evolved, suggesting a geographical impact pattern. Initially global, the pandemic's impact on commuting behaviors became more influenced by spatial factors over time, showing localized effects.",
        "comments": "28 pages, 8 figures, accepted at TRR 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14306"
    },
    {
        "doc_id": 202,
        "title": "spINAR: An R Package for Semiparametric and Parametric Estimation and Bootstrapping of Integer-Valued Autoregressive (INAR) Models",
        "authors": [
            "Maxime Faymonville",
            "Javiera Riffo",
            "Jonas Rieger",
            "Carsten Jentsch"
        ],
        "subjects": [
            "Computation"
        ],
        "abstract": "Although the statistical literature extensively covers continuous-valued time series processes and their parametric, non-parametric and semiparametric estimation, the literature on count data time series is considerably less advanced. Among the count data time series models, the integer-valued autoregressive (INAR) model is arguably the most popular one finding applications in a wide variety of fields such as medical sciences, environmentology and economics. While many contributions have been made during the last decades, the majority of the literature focuses on parametric INAR models and estimation techniques. Our emphasis is on the complex but efficient and non-restrictive semiparametric estimation of INAR models. The appeal of this approach lies in the absence of a commitment to a parametric family of innovation distributions. In this paper, we describe the need and the features of our R package spINAR which combines semiparametric simulation, estimation and bootstrapping of INAR models also covering its parametric versions.",
        "comments": "3 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14239"
    },
    {
        "doc_id": 203,
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics",
            "Trading and Market Microstructure"
        ],
        "abstract": "In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14199"
    },
    {
        "doc_id": 204,
        "title": "Costly Persuasion by a Partially Informed Sender",
        "authors": [
            "Shaofei Jiang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "I study a model of costly Bayesian persuasion by a privately and partially informed sender who conducts a public experiment. The cost of running an experiment is the expected reduction of a weighted log-likelihood ratio function of the sender's belief. This is microfounded by a Wald's sequential sampling problem where good news and bad news cost differently. I focus on equilibria that satisfy the D1 criterion. The equilibrium outcome depends on the relative costs of drawing good and bad news in the experiment. If bad news is more costly, there exists a unique separating equilibrium, and the receiver unambiguously benefits from the sender's private information. If good news is more costly, the single-crossing property fails. There may exist pooling and partial pooling equilibria, and in some equilibria, the receiver strictly suffers from sender private information.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14087"
    },
    {
        "doc_id": 205,
        "title": "Influence of climate variability on the potential forage production of a mown permanent grassland in the French Massif Central",
        "authors": [
            "I\u00f1igo G\u00f3mara",
            "Gianni Bellocchi",
            "Rapha\u00ebl Martin",
            "Bel\u00e9n Rodr\u00edguez-Fonseca",
            "Margarita Ruiz-Ramos"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Climate Services (CS) provide support to decision makers across socio-economic sectors. In the agricultural sector, one of the most important CS applications is to provide timely and accurate yield forecasts based on climate prediction. In this study, the Pasture Simulation model (PaSim) was used to simulate, for the period 1959-2015, the forage production of a mown grassland system (Laqueuille, Massif Central of France) under different management conditions, with meteorological inputs extracted from the SAFRAN atmospheric database. The aim was to generate purely climate-dependent timeseries of optimal forage production, a variable that was maximized by brighter and warmer weather conditions at the grassland. A long-term increase was observed in simulated forage yield, with the 1995-2015 average being 29% higher than the 1959-1979 average. Such increase seems consistent with observed rising trends in temperature and CO2, and multi-decadal changes in incident solar radiation. At interannual timescales, sea surface temperature anomalies of the Mediterranean (MED), Tropical North Atlantic (TNA), equatorial Pacific (El Ni\u00f1o Southern Oscillation) and the North Atlantic Oscillation (NAO) index were found robustly correlated with annual forage yield values. Relying only on climatic predictors, we developed a stepwise statistical multi-regression model with leave-one-out cross-validation. Under specific management conditions (e.g., three annual cuts) and from one to five months in advance, the generated model successfully provided a p-value<0.01 in correlation (t-test), a root mean square error percentage (%RMSE) of 14.6% and a 71.43% hit rate predicting above/below average years in terms of forage yield collection.",
        "comments": "Journal ref:        Gomara I, Bellocchi G, Martin R, Rodriguez-Fonseca B, Ruiz-Ramos M (2020) Agricultural and Forest Meteorology, 280, 107768",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14053"
    },
    {
        "doc_id": 206,
        "title": "Engineering a sustainable world by enhancing the scope of systems of systems engineering and mastering dynamics",
        "authors": [
            "Rasmus Adler",
            "Frank Elberzhager",
            "Florian Baldauf"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Engineering a sustainable world requires to consider various systems that interact with each other. These systems include ecological systems, economical systems, social systems and tech-nical systems. They are loosely coupled, geographically distributed, evolve permanently and generate emergent behavior. As these are characteristics of systems of systems (SoS), we discuss the engi-neering of a sustainable world from a SoS engineering perspective. We studied SoS engineering in context of a research project, which aims at political recommendations and a research roadmap for engineering dynamic SoS. The project included an exhaustive literature review, interviews and work-shops with representatives from industry and academia from different application domains. Based on these results and observations, we will discuss how suitable the current state-of-the-art in SoS engi-neering is in order to engineer sustainability. Sustainability was a major driver for SoS engineering in all domains, but we argue that the current scope of SoS engineering is too limited in order to engineer sustainability. Further, we argue that mastering dynamics in this larger scope is essential to engineer sustainability and that this is accompanied by dynamic adaptation of technological SoS.",
        "comments": "Accepted at the INCOSE EMEA WSEC Workshop and Conference, Sevilla, Spain - 24-26 April, 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14047"
    },
    {
        "doc_id": 207,
        "title": "Measuring multidimensional inequality: a new proposal based on the Fourier transform",
        "authors": [
            "Paolo Giudici",
            "Emanuela Raffinetti",
            "Giuseppe Toscani"
        ],
        "subjects": [
            "Physics and Society",
            "Information Theory",
            "Probability"
        ],
        "abstract": "Inequality measures are quantitative measures that take values in the unit interval, with a zero value characterizing perfect equality. Although originally proposed to measure economic inequalities, they can be applied to several other situations, in which one is interested in the mutual variability between a set of observations, rather than in their deviations from the mean. While unidimensional measures of inequality, such as the Gini index, are widely known and employed, multidimensional measures, such as Lorenz Zonoids, are difficult to interpret and computationally expensive and, for these reasons, are not much well known. To overcome the problem, in this paper we propose a new scaling invariant multidimensional inequality index, based on the Fourier transform, which exhibits a number of interesting properties, and whose application to the multidimensional case is rather straightforward to calculate and interpret.",
        "comments": "arXiv admin note: text overlap with arXiv:2310.20483",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14012"
    },
    {
        "doc_id": 208,
        "title": "Evaluating the Determinants of Mode Choice Using Statistical and Machine Learning Techniques in the Indian Megacity of Bengaluru",
        "authors": [
            "Tanmay Ghosh",
            "Nithin Nagaraj"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics"
        ],
        "abstract": "The decision making involved behind the mode choice is critical for transportation planning. While statistical learning techniques like discrete choice models have been used traditionally, machine learning (ML) models have gained traction recently among the transportation planners due to their higher predictive performance. However, the black box nature of ML models pose significant interpretability challenges, limiting their practical application in decision and policy making. This study utilised a dataset of $1350$ households belonging to low and low-middle income bracket in the city of Bengaluru to investigate mode choice decision making behaviour using Multinomial logit model and ML classifiers like decision trees, random forests, extreme gradient boosting and support vector machines. In terms of accuracy, random forest model performed the best ($0.788$ on training data and $0.605$ on testing data) compared to all the other models. This research has adopted modern interpretability techniques like feature importance and individual conditional expectation plots to explain the decision making behaviour using ML models. A higher travel costs significantly reduce the predicted probability of bus usage compared to other modes (a $0.66\\%$ and $0.34\\%$ reduction using Random Forests and XGBoost model for $10\\%$ increase in travel cost). However, reducing travel time by $10\\%$ increases the preference for the metro ($0.16\\%$ in Random Forests and 0.42% in XGBoost). This research augments the ongoing research on mode choice analysis using machine learning techniques, which would help in improving the understanding of the performance of these models with real-world data in terms of both accuracy and interpretability.",
        "comments": "65 pages, 26 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13977"
    },
    {
        "doc_id": 209,
        "title": "Principal Component Regression to Study the Impact of Economic Factors on Disadvantaged Communities",
        "authors": [
            "Narmadha M. Mohankumar",
            "Milan Jain",
            "Heng Wan",
            "Sumitrra Ganguli",
            "Kyle D. Wilson",
            "David M. Anderson"
        ],
        "subjects": [
            "Applications"
        ],
        "abstract": "The Council on Environmental Quality's Climate and Economic Justice Screening Tool defines \"disadvantaged communities\" (DAC) in the USA, highlighting census tracts where benefits of climate and energy investments are not accruing. We use a principal component generalized linear model, which addresses the intertwined nature of economic factors, income and employment and model their relationship to DAC status. Our study 1) identifies the most significant income groups and employment industries that impact DAC status, 2) provides the probability of DAC status across census tracts and compares the predictive accuracy with widely used machine learning approaches, 3) obtains historical predictions of the probability of DAC status, 4) obtains spatial downscaling of DAC status across block groups. Our study provides valuable insights for policymakers and stakeholders to develop strategies that promote sustainable development and address inequities in climate and energy investments in the USA.",
        "comments": "13 pages, 9 figures, 2 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13880"
    },
    {
        "doc_id": 210,
        "title": "SoK: Game-Theoretic Cybersecurity: Assumptions, Models, Gaps, and Bridges",
        "authors": [
            "Brandon Collins",
            "Shouhuai Xu",
            "Philip N. Brown"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security"
        ],
        "abstract": "The discipline of game theory was introduced in the context of economics, and has been applied to study cyber attacker and defender behaviors. While adaptions have been made to accommodate features in the cyber domain, these studies are inherently limited by the root of game theory in economic systems where players (i.e., agents) may be selfish but not malicious. In this SoK, we systematize the major cybersecurity problems that have been studied with the game-theoretic approach, the assumptions that have been made, the models and solution concepts that have been proposed. The systematization leads to a characterization of the technical gaps that must be addressed in order to make game-theoretic cybersecurity models truly useful. We explore bridges to address them.",
        "comments": "21 pages, Finished October 17th, 2023",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13815"
    },
    {
        "doc_id": 211,
        "title": "Optimal Queueing Regimes",
        "authors": [
            "Marco Scarsini",
            "Eran Shmaya"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory",
            "Probability"
        ],
        "abstract": "We consider an M/M/1 queueing model where customers can strategically decide whether to join the queue or balk and when to renege. We characterize the class of queueing regimes such that, for any parameters of the model, the socially efficient behavior is an equilibrium outcome.",
        "comments": "MSC Class:          91A40; 60J28",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13812"
    },
    {
        "doc_id": 212,
        "title": "The Arrival of Fast Internet and Employment in Africa: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Hjort and Poulsen (2019) frames the staggered arrival of submarine Internet cables on the shores of Africa circa 2010 as a difference-in-differences natural experiment in broadband access. The paper finds positive impacts on individual- and firm-level employment and nighttime light emissions. These results are largely ascribable to geocoding errors; to discontinuities from a satellite changeover at end-2009; and to a definition of the treated zone that has unclear technological basis, is narrower than the spatial resolution of nearly all the data sources, and is weakly representative of the geography of broadband availability.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13694"
    },
    {
        "doc_id": 213,
        "title": "Trusting AI in High-stake Decision Making",
        "authors": [
            "Ali Saffarini"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "The use of artificial intelligence models has recently grown common; we may use them to write lines of code for us, summarize readings, draft emails, or even illustrate images. But when it comes to important decisions we need to make, such as choosing between job offers or implementing certain economic policies, our level of confidence and trust in AI falls. This raises an intriguing point of exploration which I tackle in this paper - What would need to happen for people to trust artificial intelligence for important decisions? In this paper, I elaborate on how trust in AI for high-stake decisions would be accomplished if the technology was anthropomorphized because its anthropomorphism would overcome psychological barriers that are necessary to overcome for us to trust AI for important decisions.",
        "comments": "14 Pages, 0 Figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13689"
    },
    {
        "doc_id": 214,
        "title": "In the Aftermath of Oil Prices Fall of 2014/2015-Socioeconomic Facts and Changes in the Public Policies in the Sultanate of Oman",
        "authors": [
            "Osama A. Marzouk"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Since the start of its national renaissance in 1970, the Sultanate of Oman (Oman) has gone over a major development in several areas, such as education, infrastructure, and urbanization. This has been powered by the revenues from exporting crude oil and natural gas, which together form the skeleton of the country's economy. In the second half of 2014, the oil prices declined strongly to about 50% of its price. This was followed by another moderate decline in the second half of 2015 and the beginning of 2016, leaving the barrel price at a low level below 30 US$ in January 2016 (as compared to above 110 US$ in June 2014). This drop had direct impacts on the economy of Oman, manifested in a large budget deficit, reduced governmental expenditure, reduced or cancelled subsidy of fuels and electricity, increase in the water tariff, and decline in deposits in banks. The country is coping with this through its 9th five-year plan (2016-2020), which adopts a strategy of diversifying the income and relying less on the traditional oil and gas sector. The country has also taken measures to facilitate private businesses. This article sheds light on these topics as well as miscellaneous data about Oman.",
        "comments": "17 pages, 16 figures, 5 tables, 44 references",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13688"
    },
    {
        "doc_id": 215,
        "title": "Econometric Approach to Analyzing Determinants of Sustained Prosperity",
        "authors": [
            "Anika Dixit"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Every year, substantial resources are allocated to foreign aid with the aim of catalyzing prosperity and development in recipient countries. The diverse body of research on the relationship between aid and gross domestic product (GDP) has yielded varying results, finding evidence of both positive, negative, and negligible associations between the two. This study employs econometric techniques, namely Fully Modified Ordinary Least Squares Regression (FMOLS) and the Generalized Method of Moments (GMM), to explore the intricate links between innovation and different types of official development assistance (ODA) with the overarching construct of prosperity. The paper also reviews the linkages between foundational metrics, such as the rule of law, education, and economic infrastructure and services, in enabling self-sustaining prosperity. Drawing upon panel data of relevant determinants for 74 countries across the years 2013 to 2021, the study found that there was a negligible relationship between both ODA and innovation indices with prosperity. Notably, foreign aid targeted specifically toward education was observed to have a positive impact on prosperity, as was the presence of rule of law in a state. The results of the study are then examined through the lens of a case-study on Reliance Jio, exemplifying how the company engineered an ecosystem that harnessed resources and facilitated infrastructure development, thereby contributing to self-sustaining economic growth and prosperity in India.",
        "comments": "15 pages including 7 tables, and references",
        "date": "22 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13687"
    },
    {
        "doc_id": 216,
        "title": "Capturing the Tax-Revenue Bracketing System via a predator-prey model: Evidence from South Africa",
        "authors": [
            "Leonard Mushunje"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Revenues obtained from the corporate tax heads play significant roles in any economy as they can be prioritized for producing public goods and employment creations, among others. As such, corporate tax revenue should be paid enough attention. This study, therefore, explores the tax-revenue harvesting system of an economy where we focused on the corporate tax head. The system comprises three players; the government and formal and informal firms. We applied the predator-prey model to model the effect of the government-gazetted tax rate on corporate survivability. It is a new approach to modeling economic system relations and games. Critical combinatory points are derived, with stability analysis provided after that. Dynamics associated with the tax-revenue system are established and critically analyzed. Lastly, we provide the mathematical way the system can be optimized for the government to harvest as much Revenue as possible, including optimal conditions.",
        "comments": "18 Pages",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13686"
    },
    {
        "doc_id": 217,
        "title": "Determinants of Hotels and Restaurants entrepreneurship: A study using GEM data",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The objective of this work is to assess the influence of certain factors on the likelihood of being a Hotels and Restaurants (H&R) entrepreneur. The factors evaluated are demographic and economic variables, variables related to perceptions of the environment and personal traits, and variables measuring the individual's intellectual and social capital. The work uses logistic regression techniques to analyze a sample of 33,711 individuals in the countries participating in the GEM project in 2008. The findings show that age, gender, income, perception of opportunities, fear of failure, entrepreneurial ability, knowing other entrepreneurs and being a business angel are explanatory factors of the probability of being an H&R entrepreneur.",
        "comments": "Journal ref:        International Journal of Hospitality Management, 31(2), 579-587 (2012)",
        "date": "18 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13685"
    },
    {
        "doc_id": 218,
        "title": "Global Entrepreneurship Monitor versus Panel Study of Entrepreneurial Dynamics: comparing their intellectual structures",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Salustiano Martinez-Fierro",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "In the past 15 years, two international observatories have been intensively studying entrepreneurship using empirical studies with different methodologies: GEM and PSED. Both projects have generated a considerable volume of scientific production, and their intellectual structures are worth analyzing. The current work is an exploratory study of the knowledge base of the articles generated by each of these two observatories and published in prestigious journals. The value added of this work lies in its novel characterization of the intellectual structure of entrepreneurship according to the academic production of these two initiatives. The results may be of interest to the managers and members of these observatories, as well as to academics, researchers, sponsors and policymakers interested in entrepreneurship.",
        "comments": "Journal ref:        (2015). Global entrepreneurship monitor versus panel study of entrepreneurial dynamics: comparing their intellectual structures. International Entrepreneurship and Management Journal, 11(3), 571-597",
        "date": "18 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13684"
    },
    {
        "doc_id": 219,
        "title": "Relationship between work-family balance, employee well-being and job performance",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Antonio Rafael Ramos-Rodriguez"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Purpose: To assess the impact of the existence of and access to different work-family policies on employee well-being and job performance.\n  Design-methodology-approach: Hypothesis testing was performed using a structural equation model based on a PLS-SEM approach applied to a sample of 1,511 employees of the Spanish banking sector.\n  Findings: The results obtained demonstrate that the existence and true access to different types of work-family policies such as flexible working hours (flexi-time), long leaves, and flexible work location (flexi-place) are not directly related to job performance, but indirectly so, when mediated by the well-being of employees generated by work-family policies. In a similar vein, true access to employee and family support services also has an indirect positive impact on job performance mediated by the well-being produced. In contrast, the mere existence of employee and family support services does not have any direct or indirect effect on job performance.\n  Originality-value: This study makes a theoretical and empirical contribution to better understand the impact that of the existence of and access to work-family policies on job performance mediated by employee well-being. In this sense, we posited and tested an unpublished theoretical model where the concept of employee well-being gains special relevance at academic and organizational level due to its implications for human resource management.",
        "comments": "Journal ref:        Academia Revista Latinoamericana de Administracion, 30(1), pp. 40-58 (2017)",
        "date": "15 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13683"
    },
    {
        "doc_id": 220,
        "title": "Why not now? Intended timing in entrepreneurial intentions",
        "authors": [
            "Antonio Rafael Ramos-Rodriguez",
            "Jose Aurelio Medina-Garrido",
            "Jose Ruiz-Navarro"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Purpose: Understanding the formation of entrepreneurial intentions is critical, given that it is the first step in the entrepreneurial process. Although entrepreneurial intention has been extensively studied, little attention has been paid on the intended timing of future entrepreneurial projects. This paper analyses entrepreneurial intentions among final-year university students after graduation in terms of the timeframe to start a business. Potentially rapid entrepreneurs and entrepreneurs-in-waiting were compared using the Theory of Planned Behaviour (TPB). Methodology: A variance-based structural equation modelling approach was used for the sample of 851 final-year university students with entrepreneurial intentions who participated in GUESSS project. Findings: The results obtained contribute to the understanding of how entrepreneurial intentions are formed, particularly, how intended timing plays a moderating role in the relationships of the variables of the theoretical model of TPB. This study provides empirical evidence that significant differences exist between potential rapid entrepreneurs and entrepreneurs-in-waiting. Practical implications: The findings of this study have practical implications for entrepreneurship education, and they can help policy makers develop more effective policies and programs to promote entrepreneurship. Originality: Intention-based models have traditionally examined the intent -- but not the timing -- of new venture creation. However, the time elapsed between the formation of the entrepreneurial intent and the identification of a business opportunity can vary considerably. Therefore, analysing the moderating role of intended timing could be relevant to entrepreneurial intention research.",
        "comments": "Journal ref:        International Entrepreneurship and Management Journal, 15:1221-1246 (2019)",
        "date": "15 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13682"
    },
    {
        "doc_id": 221,
        "title": "Moderating effects of gender and family responsibilities on the relations between work-family policies and job performance",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Antonio Rafael Ramos-Rodriguez"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This study analyzes the impact of work-family policies (WFP) on job performance, and the possible moderating role of gender and family responsibilities. Hypothesis testing was performed using a structural equation model based on a PLS-SEM approach applied to a sample of 1,511 employees of the Spanish banking sector. The results show that neither the existence nor the accessibility of the WFP has a direct, positive impact on performance, unlike what we expected, but both have an indirect effect via the well-being generated by these policies. We also find that neither gender nor family responsibilities have a significant moderating role on these relations, contrary to what we initially expected.",
        "comments": "Journal ref:        International Journal of Human Resource Management, 32 (2021)",
        "date": "12 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13681"
    },
    {
        "doc_id": 222,
        "title": "Determinants of the Propensity for Innovation among Entrepreneurs in the Tourism Industry",
        "authors": [
            "Miguel Angel Montanes-Del-Rio",
            "Jose Aurelio Medina-Garrido"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Tourism's increasing share of Gross Domestic Product throughout the world, its impact on employment and its continuous growth justifies the interest it raises amongst entrepreneurs and public authorities. However, this growth coexists with intense competition; as a result of which, tourism companies must continuously innovate in order to survive and grow. This is evident in the diversification of tourism products and destinations, the improvement of business processes and the incorporation of new technologies for intermediation, amongst other examples. This paper expounds on the factors that explain the propensity for innovation amongst tourism entrepreneurs and it may help governments to promote innovation that is based on those determining factors. The hypotheses are tested using a logistic regression on 699 international tourism entrepreneurs, taken from the 2014 Global Adult Population Survey of the Global Entrepreneurship Monitor project. The propensity for innovation amongst tourism entrepreneurs has a statistically significant relationship to gender, age, level of education and informal investments in previous businesses.",
        "comments": "Journal ref:        Sustainability 12:5003 (2020)",
        "date": "5 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13679"
    },
    {
        "doc_id": 223,
        "title": "I Can't Go to Work Tomorrow! Work-Family Policies, Well-Being and Absenteeism",
        "authors": [
            "Jose Aurelio Medina-Garrido",
            "Jose Maria Biedma-Ferrer",
            "Jaime Sanchez-Ortiz"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Among the main causes of absenteeism are health problems, emotional problems, and inadequate work-family policies (WFP). This paper analyses the impact of the existence and accessibility of WFP on work absenteeism, by considering the mediating role of the well-being, which includes emotional as well as physical or health problems, that is generated by these policies. We differentiate between the existence of the WFP and its accessibility, as the mere existence of the WFP in an organisation is not enough. Additionally, workers must be able to access these policies easily and without retaliation of any kind. The model includes the hierarchy and the gender as moderating variables. To test the proposed hypotheses, a structural equation model based on the partial least squares structural equation modelling (PLS-SEM) approach is applied to a sample of employees in the service sector in Spain. On the one hand, the findings show that the existence of WFP has no direct effect on absenteeism; however, accessibility to these policies does have a direct effect on absenteeism. On the other hand, both the existence and accessibility of WFP have positive direct effects on emotional well-being. In addition, emotional well-being is positively related to physical well-being which, in turn, promotes a reduction in absenteeism. Finally, significant differences in the relationship between the existence of WFP and emotional well-being confirm the special difficulty of female managers in reconciling family life and work life.",
        "comments": "Journal ref:        Sustainability 12:5519 (2020)",
        "date": "5 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13678"
    },
    {
        "doc_id": 224,
        "title": "The impact of Hong Kong's anti-ELAB movement on political related firms",
        "authors": [
            "Ziqi Wang"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "Hong Kong's anti-ELAB movement had a significant impact on the stock market the stock price of listed companies. Using the number of protestors as the measurement of daily protesting intensity from 2019/6/6 to 2020/1/17, this paper documents that the stock price of listed companies associated with the pan-democratic parties were more negatively affected by protesting than other companies. Furthermore, this paper finds that after the implementation of the anti-mask law, protesting had a positive impact on red chips but a negative impact on companies related to pan-democracy parties. Therefore, this paper believes that after the central government and the HKSAR government adopted strict measures to stop violence and chaos, the value of the political connection of red chips became positive while the value of the connection with pan-democracy parties became negative.",
        "comments": "34 pages, 13 tables",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13676"
    },
    {
        "doc_id": 225,
        "title": "Social costs of curcular economy in European Union",
        "authors": [
            "Shteryo Nozharov"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Two fundamental issues are incorporated in the present monograph: the issue related to the quantification of the social costs and the issue, related to the defining of the circular economy concept as a theoretical model. The analysis is based on the methodology of the new institutional economics, which fact distinguishes it from the many other circular economy analysis based on the neo-classical methodological apparatus.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13675"
    },
    {
        "doc_id": 226,
        "title": "Analisis de la incidencia de la inversion extranjera directa y la inversion nacional, en el crecimiento economico de Chile",
        "authors": [
            "Alvear Guzman Katherine",
            "Campozano Buele Jenner",
            "Duran Canarte Paulette",
            "Holguin Cedeno Roger",
            "Mejia Crespin Fernando"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The research aims to assess the impact of foreign direct investment (FDI) and domestic investment on Chile's economic growth. By elucidating the relationship between FDI and domestic investment, the study contributes valuable insights for economic policy formulation and future investments. The findings hold significance in shaping Chile's international perception as an investment destination, potentially influencing its standing in the global economic landscape. Demonstrating that FDI is a significant driver of economic growth could enhance confidence among foreign investors. The project's importance lies in contributing to economic knowledge and guiding strategic decisions for sustainable economic growth in Chile. Understanding the interplay of FDI and domestic investment allows for a balanced approach, promoting stable economic development and mitigating issues like excessive reliance on foreign investment. The study highlights the theory of internationalization as a conceptual framework for understanding the motives and strategies of multinational companies investing abroad. Leveraging data from sources like the Central Bank of Chile, the research analyzes variables such as Chile's economic growth (GDP), FDI, and domestic investment. The hypothesis posits a significant long-term causal relationship between FDI, National Investment (NI), and Chile's Economic Growth (GDP). Statistical analysis using the Eviews 6 software tool confirms that attracting foreign investments and promoting internal investment are imperative for sustainable economic growth in Chile.",
        "comments": "in Spanish language",
        "date": "13 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13674"
    },
    {
        "doc_id": 227,
        "title": "Sacred Ecology: The Environmental Impact of African Traditional Religions",
        "authors": [
            "Neha Deopa",
            "Daniele Rinaldo"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Do religions codify ecological principles? This paper explores theoretically and empirically the role religious beliefs play in shaping environmental interactions. We study African Traditional Religions (ATR) which place forests within a sacred sphere. We build a model of non-market interactions of the mean-field type where the actions of agents with heterogeneous religious beliefs continuously affect the spatial density of forest cover. The equilibrium extraction policy shows how individual beliefs and their distribution among the population can be a key driver of forest conservation. The model also characterizes the role of resource scarcity in both individual and population extraction decisions. We test the model predictions empirically relying on the unique case of Benin, where ATR adherence is freely reported. Using an instrumental variable strategy that exploits the variation in proximity to the Benin-Nigerian border, we find that a 1 standard deviation increase in ATR adherence has a 0.4 standard deviation positive impact on forest cover change. We study the impact of historically belonging to the ancient Kingdom of Dahomey, birthplace of the Vodun religion. Using the original boundaries as a spatial discontinuity, we find positive evidence of Dahomey affiliation on contemporary forest change. Lastly, we compare observed forest cover to counterfactual outcomes by simulating the absence of ATR beliefs across the population.",
        "comments": " ",
        "date": "9 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13673"
    },
    {
        "doc_id": 228,
        "title": "Determinants of renewable energy consumption in Madagascar: Evidence from feature selection algorithms",
        "authors": [
            "Franck Ramaharo",
            "Fitiavana Randriamifidy"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "The aim of this note is to identify the factors influencing renewable energy consumption in Madagascar. We tested 12 features covering macroeconomic, financial, social, and environmental aspects, including economic growth, domestic investment, foreign direct investment, financial development, industrial development, inflation, income distribution, trade openness, exchange rate, tourism development, environmental quality, and urbanization. To assess their significance, we assumed a linear relationship between renewable energy consumption and these features over the 1990-2021 period. Next, we applied different machine learning feature selection algorithms classified as filter-based (relative importance for linear regression, correlation method), embedded (LASSO), and wrapper-based (best subset regression, stepwise regression, recursive feature elimination, iterative predictor weighting partial least squares, Boruta, simulated annealing, and genetic algorithms) methods. Our analysis revealed that the five most influential drivers stem from macroeconomic aspects. We found that domestic investment, foreign direct investment, and inflation positively contribute to the adoption of renewable energy sources. On the other hand, industrial development and trade openness negatively affect renewable energy consumption in Madagascar.",
        "comments": "21 pages, 4 tables, 1 figure",
        "date": "27 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13671"
    },
    {
        "doc_id": 229,
        "title": "\"The Roller Conduction Effect\" from the A-share Data Evidence",
        "authors": [
            "Wenbo Lyu"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "In the post-epidemic era, consumption recovery has obvious time and space transmission laws, and there are different valuation criteria for consumption segments. Using the A-share data of the consumption recovery stage from January to April 2022, this paper quantitatively compares the rotation effect between different consumption sectors when the valuation returns to the reasonable range. According to the new classification of \"sensory-based consumption\", it interprets the internal logic of digital consumption as A consumption upgrade tool and a higher valuation target, and expounds the \"the roller conduction effect\". The law of consumption recovery and valuation return period is explained from the perspective of time and space conduction. The study found that in the early stage of consumption recovery, the recovery of consumer confidence was slow. In this period, A-shares were mainly dominated by the stock capital game, and there was an obvious plate rotation law in the game. Being familiar with this law has strong significance, which not only helps policy makers to adjust the direction of policy guidance, but also helps financial investors to make better investment strategies. The disadvantage of this paper is that it has not yet studied the roller conduction effect of the global financial market, and more rigorous mathematical models are still needed to support the definition of stock funds, which is also the main direction of the author's future research.",
        "comments": "11 pages",
        "date": "15 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13670"
    },
    {
        "doc_id": 230,
        "title": "Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach",
        "authors": [
            "Yuling Yan",
            "Martin J. Wainwright"
        ],
        "subjects": [
            "Statistics Theory",
            "Econometrics",
            "Methodology",
            "Machine Learning"
        ],
        "abstract": "In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\u00e9r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13665"
    },
    {
        "doc_id": 231,
        "title": "Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity",
        "authors": [
            "Ernesto Colacrai",
            "Federico Cinus",
            "Gianmarco De Francisci Morales",
            "Michele Starnini"
        ],
        "subjects": [
            "Social and Information Networks",
            "Computers and Society",
            "Physics and Society",
            "Applications"
        ],
        "abstract": "The prevalent perspective in quantitative research on opinion dynamics flattens the landscape of the online political discourse into a traditional left--right dichotomy. While this approach helps simplify the analysis and modeling effort, it also neglects the intrinsic multidimensional richness of ideologies. In this study, we analyze social interactions on Reddit, under the lens of a multi-dimensional ideological framework: the political compass. We examine over 8 million comments posted on the subreddits /r/PoliticalCompass and /r/PoliticalCompassMemes during 2020--2022. By leveraging their self-declarations, we disentangle the ideological dimensions of users into economic (left--right) and social (libertarian--authoritarian) axes. In addition, we characterize users by their demographic attributes (age, gender, and affluence).\n  We find significant homophily for interactions along the social axis of the political compass and demographic attributes. Compared to a null model, interactions among individuals of similar ideology surpass expectations by 6%. In contrast, we uncover a significant heterophily along the economic axis: left/right interactions exceed expectations by 10%. Furthermore, heterophilic interactions are characterized by a higher language toxicity than homophilic interactions, which hints at a conflictual discourse between every opposite ideology. Our results help reconcile apparent contradictions in recent literature, which found a superposition of homophilic and heterophilic interactions in online political discussions. By disentangling such interactions into the economic and social axes we pave the way for a deeper understanding of opinion dynamics on social media.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13656"
    },
    {
        "doc_id": 232,
        "title": "Dynamic Risk Management in Cyber Physical Systems",
        "authors": [
            "Daniel Schneider",
            "Jan Reich",
            "Rasmus Adler",
            "Peter Liggesmeyer"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Cyber Physical Systems (CPS) enable new kinds of applications as well as significant improvements of existing ones in numerous different application domains. A major trait of upcoming CPS is an increasing degree of automation up to the point of autonomy, as there is a huge potential for economic success as well as for ecologic and societal improvements. However, to unlock the full potential of such (cooperative and automated) CPS, we first need to overcome several significant engineering challenges, where safety assurance is a particularly important one. Unfortunately, established safety assurance methods and standards do not live up to this task, as they have been designed with closed and less complex systems in mind. This paper structures safety assurance challenges of cooperative automated CPS, provides an overview on our vision of dynamic risk management and describes already existing building blocks.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13539"
    },
    {
        "doc_id": 233,
        "title": "Symbolic Equation Solving via Reinforcement Learning",
        "authors": [
            "Lennart Dabelow",
            "Masahito Ueda"
        ],
        "subjects": [
            "Machine Learning",
            "Symbolic Computation"
        ],
        "abstract": "Machine-learning methods are gradually being adopted in a great variety of social, economic, and scientific contexts, yet they are notorious for struggling with exact mathematics. A typical example is computer algebra, which includes tasks like simplifying mathematical terms, calculating formal derivatives, or finding exact solutions of algebraic equations. Traditional software packages for these purposes are commonly based on a huge database of rules for how a specific operation (e.g., differentiation) transforms a certain term (e.g., sine function) into another one (e.g., cosine function). Thus far, these rules have usually needed to be discovered and subsequently programmed by humans. Focusing on the paradigmatic example of solving linear equations in symbolic form, we demonstrate how the process of finding elementary transformation rules and step-by-step solutions can be automated using reinforcement learning with deep neural networks.",
        "comments": "12 pages, 4 figures + appendices 17 pages, 1 figure, 16 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13447"
    },
    {
        "doc_id": 234,
        "title": "New accessibility measures based on unconventional big data sources",
        "authors": [
            "G. Arbia",
            "V. Nardelli",
            "N. Salvini",
            "I. Valentini"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "In health econometric studies we are often interested in quantifying aspects related to the accessibility to medical infrastructures. The increasing availability of data automatically collected through unconventional sources (such as webscraping, crowdsourcing or internet of things) recently opened previously unconceivable opportunities to researchers interested in measuring accessibility and to use it as a tool for real-time monitoring, surveillance and health policies definition. This paper contributes to this strand of literature proposing new accessibility measures that can be continuously feeded by automatic data collection. We present new measures of accessibility and we illustrate their use to study the territorial impact of supply-side shocks of health facilities. We also illustrate the potential of our proposal with a case study based on a huge set of data (related to the Emergency Departments in Milan, Italy) that have been webscraped for the purpose of this paper every 5 minutes since November 2021 to March 2022, amounting to approximately 5 million observations.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13370"
    },
    {
        "doc_id": 235,
        "title": "Organizing Scientific Knowledge From Energy System Research Using the Open Research Knowledge Graph",
        "authors": [
            "Oliver Karras",
            "Jan G\u00f6pfert",
            "Patrick Kuckertz",
            "Tristan Pelser",
            "S\u00f6ren Auer"
        ],
        "subjects": [
            "Digital Libraries"
        ],
        "abstract": "Engineering sciences, such as energy system research, play an important role in developing solutions to technical, environmental, economic, and social challenges of our modern society. In this context, the transformation of energy systems into climate-neutral systems is one of the key strategies for mitigating climate change. For the transformation of energy systems, engineers model, simulate and analyze scenarios and transformation pathways to initiate debates about possible transformation strategies. For these debates and research in general, all steps of the research process must be traceable to guarantee the trustworthiness of published results, avoid redundancies, and ensure their social acceptance. However, the analysis of energy systems is an interdisciplinary field as the investigations of large, complex energy systems often require the use of different software applications and large amounts of heterogeneous data. Engineers must therefore communicate, understand, and (re)use heterogeneous scientific knowledge and data. Although the importance of FAIR scientific knowledge and data in the engineering sciences and energy system research is increasing, little research has been conducted on this topic. When it comes to publishing scientific knowledge and data from publications, software, and datasets (such as models, scenarios, and simulations) openly available and transparent, energy system research lags behind other research domains. According to Schmitt et al. and Nie\u00dfe et al., engineers need technical support in the form of infrastructures, services, and terminologies to improve communication, understanding, and (re)use of scientific knowledge and data.",
        "comments": "1. NFDI4Energy Conference",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13365"
    },
    {
        "doc_id": 236,
        "title": "Realized Stochastic Volatility Model with Skew-t Distributions for Improved Volatility and Quantile Forecasting",
        "authors": [
            "Makoto Takahashi",
            "Yuta Yamauchi",
            "Toshiaki Watanabe",
            "Yasuhiro Omori"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Forecasting volatility and quantiles of financial returns is essential for accurately measuring financial tail risks, such as value-at-risk and expected shortfall. The critical elements in these forecasts involve understanding the distribution of financial returns and accurately estimating volatility. This paper introduces an advancement to the traditional stochastic volatility model, termed the realized stochastic volatility model, which integrates realized volatility as a precise estimator of volatility. To capture the well-known characteristics of return distribution, namely skewness and heavy tails, we incorporate three types of skew-t distributions. Among these, two distributions include the skew-normal feature, offering enhanced flexibility in modeling the return distribution. We employ a Bayesian estimation approach using the Markov chain Monte Carlo method and apply it to major stock indices. Our empirical analysis, utilizing data from US and Japanese stock indices, indicates that the inclusion of both skewness and heavy tails in daily returns significantly improves the accuracy of volatility and quantile forecasts.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13179"
    },
    {
        "doc_id": 237,
        "title": "Boundary Technology Costs for Economic Viability of Long-Duration Energy Storage Systems",
        "authors": [
            "Patricia Silva",
            "Alexandre Moreira",
            "Miguel Heleno",
            "Andre Luis Marcato"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "The urgent need for decarbonization in the energy sector has led to an increased emphasis on the integration of renewable energy sources, such as wind and solar, into power grids. While these resources offer significant environmental benefits, they also introduce challenges related to intermittency and variability. Long-duration energy storage (LDES) technologies have emerged as a very promising solution to address these challenges by storing excess energy during periods of high generation and delivering it when demand is high or renewable resources are scarce for a sustained amount of time. This paper introduces a novel methodology for estimating the boundary technology cost of LDES systems for economic viability in decarbonized energy systems. Our methodology is applied to estimate the boundary costs in 2050 for the state of California to achieve full retirement of gas power plants. California's ambitious decarbonization goals and transition to a renewable energy-based power system present an ideal context for examining the role of LDES. The results also offer insights into the needed capacity expansion planning and the operational contribution of LDES in the California's energy landscape, taking into account the unique energy demand profiles and renewable resource availability of the region. Our findings are intended to provide complementary information to guide decision-makers, energy planners, and any other stakeholders in making informed choices about LDES investment in the context of a decarbonized energy future.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13163"
    },
    {
        "doc_id": 238,
        "title": "Environmental impacts, nutritional profiles, and retail prices of commonly sold retail food items in 181 countries: an observational study",
        "authors": [
            "Elena M. Martinez",
            "Nicole Tichenor Blackstone",
            "Parke E. Wilde",
            "Anna W. Herforth",
            "William A. Masters"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Affordability is often seen as a barrier to consuming sustainable diets. This study provides the first worldwide test of how retail food prices relate to empirically estimated environmental impacts and nutritional profile scores between and within food groups. We use prices for 811 retail food items commonly sold in 181 countries during 2011 and 2017, matched to estimated carbon and water footprints and nutritional profiles, to test whether healthier and more environmentally sustainable foods are more expensive between and within food groups. We find that within almost all groups, less expensive items have significantly lower carbon and water footprints. Associations are strongest for animal source foods, where each 10% lower price is associated with 20 grams lower CO2-equivalent carbon and 5 liters lower water footprint per 100kcal. Gradients between price and nutritional profile vary by food group, price range, and nutritional attribute. In contrast, lower-priced items have lower nutritional value in only some groups over some price ranges, and that relationship is sometimes reversed. These findings reveal opportunities to reduce financial and environmental costs of diets, contributing to transitions towards healthier, more environmentally sustainable food systems.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13159"
    },
    {
        "doc_id": 239,
        "title": "Three Variations on Money Pump, Common Prior, and Trade",
        "authors": [
            "Ziv Hellman",
            "Miklos Pinter"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We consider finite information structures, and quest for the answer of the question: What is the proper definition of prior?\n  In the single player setting we conclude that a probability distribution is a prior if it is disintegrable, because this definition excludes money pump.\n  In the multiplayer setting our analysis does not boil down to one proper notion of common prior (the multiplayer version of prior). The appropriate notion is a choice of the modeller in this setting. We consider three variants of money pump, each \"defines\" a notion of common prior.\n  Furthermore, we also consider three variants of trade, each correspond to one of the money pump variants, hence to one of the common prior variants.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13132"
    },
    {
        "doc_id": 240,
        "title": "Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge",
        "authors": [
            "Ruixin Song",
            "Gabriel Spadon",
            "Sarah Bailey",
            "Ronald Pelot",
            "Stan Matwin",
            "Amilcar Soares"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Social and Information Networks",
            "Applications"
        ],
        "abstract": "Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive species risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape.",
        "comments": "26 pages, 7 figures, under review",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13098"
    },
    {
        "doc_id": 241,
        "title": "Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in Deep Learning Systems",
        "authors": [
            "Michelle R. Greene",
            "Mariam Josyula",
            "Wentao Si",
            "Jennifer A. Hart"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., \"ruin\", \"slum\"), especially in images from homes with lower socioeconomic status (SES). This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States. This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets. By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems. There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.",
        "comments": "20 pages, 3 figures, 3 tables",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13097"
    },
    {
        "doc_id": 242,
        "title": "Importance of the spectral emissivity measurements at working temperature to determine the efficiency of a solar selective coating",
        "authors": [
            "Telmo Ech\u00e1niz",
            "I\u00f1igo Seti\u00e9n-Fern\u00e1ndez",
            "Ra\u00fal Benjam\u00edn P\u00e9rez-S\u00e1ez",
            "Carlos Prieto",
            "Ram\u00f3n Escobar Galindo",
            "Manuel Jos\u00e9 Tello"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "The total emissivity of the absorbing surfaces is a critical parameter in the calculation of the radiative thermal losses in solar thermal collectors. This is because the radiative heat losses have a significant economic impact on the final cost of the electricity produced in a solar thermal plant. This paper demonstrates the need to calculate the total emissivity from spectral emissivity measurements at the working temperature of the solar thermal collector, instead of using extrapolated values from spectral emissivities measured at room temperature. Usual uncertainties produced by the estimation of the total emissivity, in which its temperature dependence is only introduced by the Planck function, are analyzed.",
        "comments": "4 pages, 6 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13095"
    },
    {
        "doc_id": 243,
        "title": "Towards Trustable Language Models: Investigating Information Quality of Large Language Models",
        "authors": [
            "Rick Rejeleene",
            "Xiaowei Xu",
            "John Talburt"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.",
        "comments": "31 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13086"
    },
    {
        "doc_id": 244,
        "title": "Inference under partial identification with minimax test statistics",
        "authors": [
            "Isaac Loh"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "We provide a means of computing and estimating the asymptotic distributions of test statistics based on an outer minimization of an inner maximization. Such test statistics, which arise frequently in moment models, are of special interest in providing hypothesis tests under partial identification. Under general conditions, we provide an asymptotic characterization of such test statistics using the minimax theorem, and a means of computing critical values using the bootstrap. Making some light regularity assumptions, our results provide a basis for several asymptotic approximations that have been provided for partially identified hypothesis tests, and extend them by mitigating their dependence on local linear approximations of the parameter space. These asymptotic results are generally simple to state and straightforward to compute (e.g. adversarially).",
        "comments": "MSC Class:          Primary 62G10; Secondary 62G20",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13057"
    },
    {
        "doc_id": 245,
        "title": "Distributed Empirical Likelihood Inference With or Without Byzantine Failures",
        "authors": [
            "Qihua Wang",
            "Jinye Du",
            "Ying Sheng"
        ],
        "subjects": [
            "Methodology"
        ],
        "abstract": "Empirical likelihood is a very important nonparametric approach which is of wide application. However, it is hard and even infeasible to calculate the empirical log-likelihood ratio statistic with massive data. The main challenge is the calculation of the Lagrange multiplier. This motivates us to develop a distributed empirical likelihood method by calculating the Lagrange multiplier in a multi-round distributed manner. It is shown that the distributed empirical log-likelihood ratio statistic is asymptotically standard chi-squared under some mild conditions. The proposed algorithm is communication-efficient and achieves the desired accuracy in a few rounds. Further, the distributed empirical likelihood method is extended to the case of Byzantine failures. A machine selection algorithm is developed to identify the worker machines without Byzantine failures such that the distributed empirical likelihood method can be applied. The proposed methods are evaluated by numerical simulations and illustrated with an analysis of airline on-time performance study and a surface climate analysis of Yangtze River Economic Belt.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12827"
    },
    {
        "doc_id": 246,
        "title": "Generative AI Triggers Welfare-Reducing Decisions in Humans",
        "authors": [
            "Fabian Dvorak",
            "Regina Stumpf",
            "Sebastian Fehrler",
            "Urs Fischbacher"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Generative artificial intelligence (AI) is poised to reshape the way individuals communicate and interact. While this form of AI has the potential to efficiently make numerous human decisions, there is limited understanding of how individuals respond to its use in social interaction. In particular, it remains unclear how individuals engage with algorithms when the interaction entails consequences for other people. Here, we report the results of a large-scale pre-registered online experiment (N = 3,552) indicating diminished fairness, trust, trustworthiness, cooperation, and coordination by human players in economic twoplayer games, when the decision of the interaction partner is taken over by ChatGPT. On the contrary, we observe no adverse welfare effects when individuals are uncertain about whether they are interacting with a human or generative AI. Therefore, the promotion of AI transparency, often suggested as a solution to mitigate the negative impacts of generative AI on society, shows a detrimental effect on welfare in our study. Concurrently, participants frequently delegate decisions to ChatGPT, particularly when the AI's involvement is undisclosed, and individuals struggle to discern between AI and human decisions.",
        "comments": "19 pages, 2 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12773"
    },
    {
        "doc_id": 247,
        "title": "Improving single-molecule conductance measurements with change point detection from the econometrics toolbox",
        "authors": [
            "Joseph M. Hamill",
            "William Bro-J\u00f8rgensen",
            "Zolt\u00e1n Balogh",
            "Haixing Li",
            "Susanne Leitherer",
            "David Solomon",
            "Andr\u00e1s Halbritter",
            "Gemma Solomon"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Soft Condensed Matter"
        ],
        "abstract": "Structural breaks occur in timeseries data across a broad range of fields, from economics to nanosciences. For measurements of single-molecule break junctions, structural breaks in conductance versus displacement data occur when the molecular junction ruptures. This moment is significant because the molecule is likely in its most extended geometry, and therefore resembles most closely the geometry used in theoretical predictions. Conventional single-molecule break junction data analysis, on the other hand, typically uses the entire molecular plateau to estimate the single-molecule conductance, which skews the estimate when the plateau is sloped. Borrowing from econometrics, where the study of structural breaks is well established, we present change point detection (CPD) as a tool to search for junction rupture in single-molecule break junction data, and improve estimates in single-molecule conductance. We demonstrate that using CPD instead of the conventional 1D conductance histogram to determine the mean molecular conductance yields a standard deviation in the estimate of typically half that of the conventional approach, greatly improving accuracy. We apply CPD to three separate data sets, two on 4,4'-bipyridine and one on a silane, two at room temperature and one at 4 K, two in one lab, one in another, to show the wide applicability of even the simplest of CPD algorithms: the Chow test. This versatility and better accuracy will propagate into more accurate theoretical simulations. These improved metrics, in turn, will further improve any downstream analyses, including all emerging machine learning approaches.",
        "comments": "33 pages and 11 figures and supporting material of 8 pages and 3 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12769"
    },
    {
        "doc_id": 248,
        "title": "Optimal design of a local renewable electricity supply system for power-intensive production processes with demand response",
        "authors": [
            "Sonja H. M. Germscheid",
            "Benedikt Nilges",
            "Niklas von der Assen",
            "Alexander Mitsos",
            "Manuel Dahmen"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "This work studies synergies arising from combining industrial demand response and local renewable electricity supply. To this end, we optimize the design of a local electricity generation and storage system with an integrated demand response scheduling of a continuous power-intensive production process in a multi-stage problem. We optimize both total annualized cost and global warming impact and consider local photovoltaic and wind electricity generation, an electric battery, and electricity trading on day-ahead and intraday market. We find that installing a battery can reduce emissions and enable large trading volumes on the electricity markets, but significantly increases cost. Economic and ecologic process and battery operation are driven primarily by the electricity price and grid emission factor, respectively, rather than locally generated electricity. A parameter study reveals that economic savings from the local system and flexibilizing the process behave almost additive.",
        "comments": "manuscript (32 pages, 9 figures, 6 tables), supporting materials (11 pages, 9 figures, 2 tables)",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12759"
    },
    {
        "doc_id": 249,
        "title": "Multicausal transport: barycenters and dynamic matching",
        "authors": [
            "Beatrice Acciaio",
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "We introduce a multivariate version of adapted transport, which we name multicausal transport, involving several filtered processes among which causality constraints are imposed. Subsequently, we consider the barycenter problem for stochastic processes with respect to causal and bicausal optimal transport, and study its connection to specific multicausal transport problems. Attainment and duality of the aforementioned problems are provided. As an application, we study a matching problem in a dynamic setting where agents' types evolve over time. We link this to a causal barycenter problem and thereby show existence of equilibria.",
        "comments": "26 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12748"
    },
    {
        "doc_id": 250,
        "title": "Arrow's single peaked domains, richness, and domains for plurality and the Borda count",
        "authors": [
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "In this paper we extend the study of Arrow's generalisation of Black's single-peaked domain and connect this to domains where voting rules satisfy different versions of independence of irrelevant alternatives.\n  First we report on a computational generation of all non-isomorphic Arrow's single-peaked domains on $n\\leq 9$ alternatives. Next, we introduce a quantitative measure of richness for domains, as the largest number $r$ such that every alternative is given every rank between 1 and $r$ by the orders in the domain. We investigate the richness of Arrow's single-peaked domains and prove that Black's single-peaked domain has the highest possible richness, but it is not the only domain which attains the maximum.\n  After this we connect Arrow's single-peaked domains to the discussion by Dasgupta, Maskin and others of domains on which plurality and the Borda count satisfy different versions of Independence of Irrelevant alternatives (IIA). For Nash's version of IIA and plurality, it turns out the domains are exactly the duals of Arrow's single-peaked domains. As a consequence there can be at most two alternatives which are ranked first in any such domain.\n  For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum domain size which is exponentially smaller than $2^{n-1}$, the size of Black's single-peaked domain.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12547"
    },
    {
        "doc_id": 251,
        "title": "Moen Meets Rotemberg: An Earthly Model of the Divine Coincidence",
        "authors": [
            "Pascal Michaillat",
            "Emmanuel Saez"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "This paper proposes a model of the divine coincidence, explaining its recent appearance in US data. The divine coincidence matters because it helps explain the behavior of inflation after the pandemic, and it guarantees that the full-employment and price-stability mandates of the Federal Reserve coincide. In the model, a Phillips curve relating unemployment to inflation arises from Moen's (1997) directed search. The Phillips curve is nonvertical thanks to Rotemberg's (1982) price-adjustment costs. The model's Phillips curve guarantees that the rate of inflation is on target whenever the rate of unemployment is efficient, generating the divine coincidence. If we assume that wage decreases -- which reduce workers' morale -- are more costly to producers than price increases -- which upset customers -- the Phillips curve also displays a kink at the point of divine coincidence.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12475"
    },
    {
        "doc_id": 252,
        "title": "Convex-Concave Zero-sum Markov Stackelberg Games",
        "authors": [
            "Denizalp Goktas",
            "Arjun Prakash",
            "Amy Greenwald"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "Zero-sum Markov Stackelberg games can be used to model myriad problems, in domains ranging from economics to human robot interaction. In this paper, we develop policy gradient methods that solve these games in continuous state and action settings using noisy gradient estimates computed from observed trajectories of play. When the games are convex-concave, we prove that our algorithms converge to Stackelberg equilibrium in polynomial time. We also show that reach-avoid problems are naturally modeled as convex-concave zero-sum Markov Stackelberg games, and that Stackelberg equilibrium policies are more effective than their Nash counterparts in these problems.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12437"
    },
    {
        "doc_id": 253,
        "title": "A Unified Approach to Second and Third Degree Price Discrimination",
        "authors": [
            "Dirk Bergemann",
            "Tibor Heumann",
            "Michael C. Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Computer Science and Game Theory"
        ],
        "abstract": "We analyze the welfare impact of a monopolist able to segment a multiproduct market and offer differentiated price menus within each segment. We characterize a family of extremal distributions such that all achievable welfare outcomes can be reached by selecting segments from within these distributions. This family of distributions arises as the solution to the consumer maximizing distribution of values for multigood markets. With these results, we analyze the effect of segmentation on consumer surplus and prices in both interior and extremal markets, including conditions under which there exists a segmentation benefiting all consumers. Finally, we present an efficient algorithm for computing segmentations.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12366"
    },
    {
        "doc_id": 254,
        "title": "Business Model Contributions to Bank Profit Performance: A Machine Learning Approach",
        "authors": [
            "F. Bolivar",
            "Miguel A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the relation between bank profit performance and business models. Using a machine learning-based approach, we propose a methodological strategy in which balance sheet components' contributions to profitability are the identification instruments of business models. We apply this strategy to the European Union banking system from 1997 to 2021. Our main findings indicate that the standard retail-oriented business model is the profile that performs best in terms of profitability, whereas adopting a non-specialized business profile is a strategic decision that leads to poor profitability. Additionally, our findings suggest that the effect of high capital ratios on profitability depends on the business profile. The contributions of business models to profitability decreased during the Great Recession. Although the situation showed signs of improvement afterward, the European Union banking system's ability to yield returns is still problematic in the post-crisis period, even for the best-performing group.",
        "comments": "46 pages, 10 tables, 3 figures, submitted version of a paper published in Research in International Business and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12334"
    },
    {
        "doc_id": 255,
        "title": "Bank Business Models, Size, and Profitability",
        "authors": [
            "F. Bolivar",
            "M. A. Duran",
            "A. Lozano-Vivas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "To examine the relation between profitability and business models (BMs) across bank sizes, the paper proposes a research strategy based on machine learning techniques. This strategy allows for analyzing whether size and profit performance underlie BM heterogeneity, with BM identification being based on how the components of the bank portfolio contribute to profitability. The empirical exercise focuses on the European Union banking system. Our results suggest that banks with analogous levels of performance and different sizes share strategic features. Additionally, high capital ratios seem compatible with high profitability if banks, relative to their size peers, adopt a standard retail BM.",
        "comments": "14 pages, 1 figure, 3 tables, accepted version of an article published in Finance Research Letters",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12323"
    },
    {
        "doc_id": 256,
        "title": "The outcomes of generative AI are exactly the Nash equilibria of a non-potential game",
        "authors": [
            "Boualem Djehiche",
            "Hamidou Tembine"
        ],
        "subjects": [
            "Computer Science and Game Theory"
        ],
        "abstract": "In this article we show that the asymptotic outcomes of both shallow and deep neural networks such as those used in BloombergGPT to generate economic time series are exactly the Nash equilibria of a non-potential game. We then design and analyze deep neural network algorithms that converge to these equilibria. The methodology is extended to federated deep neural networks between clusters of regional servers and on-device clients. Finally, the variational inequalities behind large language models including encoder-decoder related transformers are established.",
        "comments": "24 pages. Accepted and to appear in: International Econometric Conference of Vietnam",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12321"
    },
    {
        "doc_id": 257,
        "title": "The Risk-Return Relation in the Corporate Loan Market",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "This paper analyzes the hypothesis that returns play a risk-compensating role in the market for corporate revolving lines of credit. Specifically, we test whether borrower risk and the expected return on these debt instruments are positively related. Our main findings support this prediction, in contrast to the only previous work that examined this problem two decades ago. Nevertheless, we find evidence of mispricing regarding the risk of deteriorating firms using their facilities more intensively and during the subprime crisis.",
        "comments": "56 pages, 3 figurees, 7 tables, accepted version of a paper published in the North American Journal of Economics and Finance",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12315"
    },
    {
        "doc_id": 258,
        "title": "Interpreting Event-Studies from Recent Difference-in-Differences Methods",
        "authors": [
            "Jonathan Roth"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This note discusses the interpretation of event-study plots produced by recent difference-in-differences methods. I show that even when specialized to the case of non-staggered treatment timing, the default plots produced by software for three of the most popular recent methods (de Chaisemartin and D'Haultfoeuille, 2020; Callaway and SantAnna, 2021; Borusyak, Jaravel and Spiess, 2024) do not match those of traditional two-way fixed effects (TWFE) event-studies: the new methods may show a kink or jump at the time of treatment even when the TWFE event-study shows a straight line. This difference stems from the fact that the new methods construct the pre-treatment coefficients asymmetrically from the post-treatment coefficients. As a result, visual heuristics for analyzing TWFE event-study plots should not be immediately applied to those from these methods. I conclude with practical recommendations for constructing and interpreting event-study plots when using these methods.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12309"
    },
    {
        "doc_id": 259,
        "title": "Pricing and Usage: An Empirical Analysis of Lines of Credit",
        "authors": [
            "Miguel A. Duran"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The hypothesis that committed revolving credit lines with fixed spreads can provide firms with interest rate insurance is a standard feature of models on these credit facilities' interest rate structure. Nevertheless, this hypothesis has not been tested. Its empirical examination is the main contribution of this paper. To perform this analysis, and given the unavailability of data, we hand-collect data on usage at the credit line level itself. The resulting dataset enables us also to take into account characteristics of credit lines that have been ignored by previous research. One of them is that credit lines can have simultaneously fixed and performance-based spreads.",
        "comments": "32 pages, 7 tables, accepted version of a paper published in the Journal of International Financial Markets, Institutions and Money",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12301"
    },
    {
        "doc_id": 260,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 261,
        "title": "The Global Impact of AI-Artificial Intelligence: Recent Advances and Future Directions, A Review",
        "authors": [
            "Chandregowda Pachegowda"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence"
        ],
        "abstract": "Artificial intelligence (AI) is an emerging technology that has the potential to transform many aspects of society, including the economy, healthcare, and transportation. This article synthesizes recent research literature on the global impact of AI, exploring its potential benefits and risks. The article highlights the implications of AI, including its impact on economic, ethical, social, security & privacy, and job displacement aspects. It discusses the ethical concerns surrounding AI development, including issues of bias, security, and privacy violations. To ensure the responsible development and deployment of AI, collaboration between government, industry, and academia is essential. The article concludes by emphasizing the importance of public engagement and education to promote awareness and understanding of AI's impact on society at large.",
        "comments": "4 pages",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.12223"
    },
    {
        "doc_id": 262,
        "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
        "authors": [
            "Tahereh Zarrat Ehsan",
            "Seyed Mehdi Mohtavipour"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal chicken health conditions, minimizing economic losses and bolstering profitability. This paper presents a novel real-time framework for analyzing chicken behavior in cage-free poultry houses to detect abnormal behaviors. Specifically, two significant abnormalities, namely inactive broiler and huddling behavior, are investigated in this study. The proposed framework comprises three key steps: (1) chicken detection utilizing a state-of-the-art deep learning model, (2) tracking individual chickens across consecutive frames with a fast tracker module, and (3) detecting abnormal behaviors within the video stream. Experimental studies are conducted to evaluate the efficacy of the proposed algorithm in accurately assessing chicken behavior. The results illustrate that our framework provides a precise and efficient solution for real-time anomaly detection, facilitating timely interventions to maintain chicken health and enhance overall productivity on poultry farms. Github: https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
        "comments": "11 pages, 7 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12176"
    },
    {
        "doc_id": 263,
        "title": "Centralization in Block Building and Proposer-Builder Separation",
        "authors": [
            "Maryam Bahrani",
            "Pranav Garimidi",
            "Tim Roughgarden"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Cryptography and Security",
            "Distributed, Parallel, and Cluster Computing",
            "Theoretical Economics"
        ],
        "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about centralization in block-building (due to, e.g., MEV and private order flow) and the outsourcing of block-building by validators to specialists (i.e., proposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers inevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve decentralization among proposers?\n  This paper develops mathematical models and results that offer answers to these questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block producer rewards, and staking costs, we quantify the extent to which heterogeneous rewards lead to concentration in the equilibrium staking distribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly reinvest rewards into staking, we quantify, as a function of the block producer heterogeneity, the rate at which stake concentrates on the most sophisticated block producers.\n  3. In a model with heterogeneous proposers and specialized builders, we quantify, as a function of the competitiveness of the builder ecosystem, the extent to which proposer-builder separation reduces the heterogeneity in rewards across different proposers.\n  Our models and results take advantage of connections to contest design, P\u00f3lya urn processes, and auction theory.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12120"
    },
    {
        "doc_id": 264,
        "title": "Measures of the Capital Network of the U.S. Economy",
        "authors": [
            "Ben Klemens"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "About two million U.S. corporations and partnerships are linked to each other and human investors by about 15 million owner-subsidiary links. Comparable social networks such as corporate board memberships and socially-built systems such as the network of Internet links are \"small worlds,\" meaning a network with a small diameter and link densities with a power-law distribution, but these properties had not yet been measured for the business entity network. This article shows that both inbound links and outbound links display a power-law distribution with a coefficient of concentration estimable to within a generally narrow confidence interval, overall, for subnetworks including only business entities, only for the great connected component of the network, and in subnetworks with edges associated with certain industries, for all years 2009-2021. In contrast to other networks with power-law distributed link densities, the network is mostly a tree, and has a diameter an order of magnitude larger than a small-world network with the same link distribution. The regularity of the power-law distribution indicates that its coefficient can be used as a new, well-defined macroeconomic metric for the concentration of capital flows in an economy. Economists might use it as a new measure of market concentration which is more comprehensive than measures based only on the few biggest firms. Comparing capital link concentrations across countries would facilitate modeling the relationship between business network characteristics and other macroeconomic indicators.",
        "comments": "18 pages. JEL classifications: L14; C81; M42; G34",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12118"
    },
    {
        "doc_id": 265,
        "title": "Metrics matter, a Formal comment on Ward et al Plos-One 2016 paper : Is decoupling GDP growth from environmental impact possible?",
        "authors": [
            "Herv\u00e9 Bercegol",
            "Paul E. Brockway"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The Ward et al. (2016) Plos-One paper is an important, heavily-cited paper in the decoupling literature. The authors present evidence of 1990-2015 growth in material and energy consumption and GDP at a world level, and for selected countries. They find only relative decoupling has occurred, leading to their central claim that future absolute decoupling is implausible. However, the authors have made two key errors in their collected data: GDP data is in current prices which includes inflation, and their global material use data is the total mass of fossil energy materials. Strictly, GDP data should be in constant prices to allow for its comparison over time, and material inputs to an economy should be the sum of mineral raw materials. Amending for these errors, we find much smaller levels of energy-GDP relative decoupling, and no materials-GDP decoupling at all at a global level. We check these new results by adding data for 1900-1990 to provide a longer time series, and find consistently low (and even no) levels of global relative decoupling of material use. The central claim for materials over the implausibility of future absolute decoupling therefore not only remains valid but is reinforced by the corrected datasets.",
        "comments": "6 pages, 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12100"
    },
    {
        "doc_id": 266,
        "title": "Temporal Aggregation for the Synthetic Control Method",
        "authors": [
            "Liyang Sun",
            "Eli Ben-Michael",
            "Avi Feller"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "The synthetic control method (SCM) is a popular approach for estimating the impact of a treatment on a single unit with panel data. Two challenges arise with higher frequency data (e.g., monthly versus yearly): (1) achieving excellent pre-treatment fit is typically more challenging; and (2) overfitting to noise is more likely. Aggregating data over time can mitigate these problems but can also destroy important signal. In this paper, we bound the bias for SCM with disaggregated and aggregated outcomes and give conditions under which aggregating tightens the bounds. We then propose finding weights that balance both disaggregated and aggregated series.",
        "comments": "9 pages, 3 figures, Prepared for 2024 AEA Papers and Proceedings \"Treatment Effects: Theory and Implementation\"",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12084"
    },
    {
        "doc_id": 267,
        "title": "Market Responses to Genuine Versus Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers",
        "authors": [
            "Chen Liang",
            "Murat Tunc",
            "Gordon Burtch"
        ],
        "subjects": [
            "General Economics",
            "Computers and Society",
            "Human-Computer Interaction"
        ],
        "abstract": "Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about the motivations of donors in these charity fundraisers, resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity, based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of strategic generosity), and based on an individual's degree of social exposure within the NFT marketplace. We show that charity-NFT \"relisters\" experience significant penalties in the market, in terms of the prices they are able to command on other NFT listings, particularly among those who relist quickly and those who are more socially exposed. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12064"
    },
    {
        "doc_id": 268,
        "title": "A Bracketing Relationship for Long-Term Policy Evaluation with Combined Experimental and Observational Data",
        "authors": [
            "Yechan Park",
            "Yuya Sasaki"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Combining short-term experimental data with observational data enables credible long-term policy evaluation. The literature offers two key but non-nested assumptions, namely the latent unconfoundedness (LU; Athey et al., 2020) and equi-confounding bias (ECB; Ghassami et al., 2022) conditions, to correct observational selection. Committing to the wrong assumption leads to biased estimation. To mitigate such risks, we provide a novel bracketing relationship (cf. Angrist and Pischke, 2009) repurposed for the setting with data combination: the LU-based estimand and the ECB-based estimand serve as the lower and upper bounds, respectively, with the true causal effect lying in between if either assumption holds. For researchers further seeking point estimates, our Lalonde-style exercise suggests the conservatively more robust LU-based lower bounds align closely with the hold-out experimental estimates for educational policy evaluation. We investigate the economic substantives of these findings through the lens of a nonparametric class of selection mechanisms and sensitivity analysis. We uncover as key the sub-martingale property and sufficient-statistics role (Chetty, 2009) of the potential outcomes of student test scores (Chetty et al., 2011, 2014).",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12050"
    },
    {
        "doc_id": 269,
        "title": "Local Diversity of Condorcet Domains",
        "authors": [
            "Alexander Karpov",
            "Klas Markstr\u00f6m",
            "S\u00f8ren Riis",
            "Bei Zhou"
        ],
        "subjects": [
            "Theoretical Economics",
            "Discrete Mathematics"
        ],
        "abstract": "Several of the classical results in social choice theory demonstrate that in order for many voting systems to be well-behaved the set domain of individual preferences must satisfy some kind of restriction, such as being single-peaked on a political axis. As a consequence it becomes interesting to measure how diverse the preferences in a well-behaved domain can be.\n  In this paper we introduce an egalitarian approach to measuring preference diversity, focusing on the abundance of distinct suborders one subsets of the alternative. We provide a common generalisation of the frequently used concepts of ampleness and copiousness.\n  We give a detailed investigation of the abundance for Condorcet domains. Our theorems imply a ceiling for the local diversity in domains on large sets of alternatives, which show that in this measure Black's single-peaked domain is in fact optimal. We also demonstrate that for some numbers of alternatives, there are Condorcet domains which have largest local diversity without having maximum order.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11912"
    },
    {
        "doc_id": 270,
        "title": "Efficiency in random allocation with ordinal rules",
        "authors": [
            "Samson Alva",
            "Eun Jeong Heo",
            "Vikram Manjunath"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "We study ordinal rules for allocating indivisible goods via lottery. Ordinality requires a rule to consider only how agents rank degenerate lotteries and may be necessitated by cognitive, informational, or as we show, incentive constraints. The limited responsiveness of ordinal rules to agents' preferences means that they can only satisfy welfare properties based on first order stochastic dominance, which is incomplete.\n  We define a new efficiency concept for ordinal rules. While ordinality and efficiency together are incompatible with the usual notions of fairness and somewhat limit randomization, they do leave room for a rich class of rules. We demonstrate this through a characterization of all ordinal, efficient, strategy-proof, non-bossy, boundedly invariant, and neutral rules.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11899"
    },
    {
        "doc_id": 271,
        "title": "Finite horizon optimal control of reaction-diffusion SIV epidemic system with stochastic environment",
        "authors": [
            "Zong Wang"
        ],
        "subjects": [
            "Optimization and Control",
            "Dynamical Systems"
        ],
        "abstract": "This contribution mainly focuses on the finite horizon optimal control problems of a susceptible-infected-vaccinated(SIV) epidemic system governed by reaction-diffusion equations and Markov switching. Stochastic dynamic programming is employed to find the optimal vaccination effort and economic return for a stochastic reaction diffusion SIV epidemic model. To achieve this, a key step is to show the existence and uniqueness of invariant measure for the model. Then, we obtained the necessary and sufficient conditions for the near-optimal control. Furthermore, we give an algorithm to approximate the Hamilton-Jacobi Bellman (HJB) equation. Finally, some numerical simulations are presented to confirm our analytic results.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11744"
    },
    {
        "doc_id": 272,
        "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
        "authors": [
            "Yu Zhu",
            "Kang Li",
            "Lequan Yu",
            "Pheng-Ann Heng"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.",
        "comments": "Accepted by AAAI 2024",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11674"
    },
    {
        "doc_id": 273,
        "title": "Analyzing the Impact of Financial Inclusion on Economic Growth in Bangladesh",
        "authors": [
            "Ganapati Kumar Biswas"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Financial inclusion is touted one of the principal drivers for economic growth for an economy. The study aims to explore the impact of financial inclusion on economic growth in Bangladesh. In my study, I used the number of loan accounts as the proxy for financial inclusion. Using time series data from spans from 2004-2021, the study revealed that there exists a long-run relationship between GDP, financial inclusion, and other macroeconomic variables in Bangladesh. The study also found that financial inclusion had a positive impact on economic growth of Bangladesh during the study period. Therefore, the policymakers and the central bank of Bangladesh as the apex authority of financial system should promote financial inclusion activities to achieve sustainable economic growth.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11585"
    },
    {
        "doc_id": 274,
        "title": "A note on the stability of Monotone Markov Chains",
        "authors": [
            "Bar Light"
        ],
        "subjects": [
            "Probability",
            "Theoretical Economics"
        ],
        "abstract": "This note studies monotone Markov chains a subclass of Markov chains with extensive applications in operations research and economics. While the properties that ensure the global stability of these chains are well studied, their establishment often relies on the fulfillment of a certain splitting condition. We address the challenges of verifying the splitting condition, by introducing simple, applicable conditions that ensure global stability. The simplicity of these conditions is demonstrated through various examples including autoregressive processes and portfolio allocation problems.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11568"
    },
    {
        "doc_id": 275,
        "title": "Taxi dispatching strategies with compensations",
        "authors": [
            "Holger Billhardt",
            "Alberto Fern\u00e1ndez",
            "Sascha Ossowski",
            "Javier Palanca",
            "Javier Bajo"
        ],
        "subjects": [
            "Artificial Intelligence"
        ],
        "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi vehicles are key elements in daily traffic activity. The advance of ICT and geo-positioning systems has given rise to new opportunities for improving the efficiency of taxi fleets in terms of waiting times of passengers, cost and time for drivers, traffic density, CO2 emissions, etc., by using more informed, intelligent dispatching. Still, the explicit spatial and temporal components, as well as the scale and, in particular, the dynamicity of the problem of pairing passengers and taxis in big towns, render traditional approaches for solving standard assignment problem useless for this purpose, and call for intelligent approximation strategies based on domain-specific heuristics. Furthermore, taxi drivers are often autonomous actors and may not agree to participate in assignments that, though globally efficient, may not be sufficently beneficial for them individually. This paper presents a new heuristic algorithm for taxi assignment to customers that considers taxi reassignments if this may lead to globally better solutions. In addition, as such new assignments may reduce the expected revenues of individual drivers, we propose an economic compensation scheme to make individually rational drivers agree to proposed modifications in their assigned clients. We carried out a set of experiments, where several commonly used assignment strategies are compared to three different instantiations of our heuristic algorithm. The results indicate that our proposal has the potential to reduce customer waiting times in fleets of autonomous taxis, while being also beneficial from an economic point of view.",
        "comments": "ACM Class:          I.2.1",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11553"
    },
    {
        "doc_id": 276,
        "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload Control",
        "authors": [
            "Zhigang Wang",
            "Xu Zhang",
            "Ning Wang",
            "Chuanfei Xu",
            "Jie Nie",
            "Zhiqiang Wei",
            "Yu Gu",
            "Ge Yu"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing"
        ],
        "abstract": "Transformer-based models are becoming deeper and larger recently. For better scalability, an underlying training solution in industry is to split billions of parameters (tensors) into many tasks and then run them across homogeneous accelerators (e.g., GPUs). However, such dedicated compute cluster is prohibitively expensive in academia and moderate companies. An economic replacement is to aggregate existing heterogeneous devices and share resources among multi-tenants. Nevertheless, static hardware configurations and dynamic resource contention definitely cause straggling tasks, which heavily slows down the overall training efficiency. Existing works feature contributions mainly tailored for traditional data parallelism. They cannot work well for the new tensor parallelism due to strict communication and correctness constraints.\n  In this paper we first present ZERO-resizing, a novel dynamic workload balancing technique without any data migration. We tune workloads in real-time by temporarily resizing matrices involved in core tensor-related computations. We particularly design data imputation and priority selection policies to respectively satisfy consistency constraint required by normal training and reduce the accuracy loss. We also give a lightweight data migration technique without loss of accuracy, to cope with heavy heterogeneity. Our final SEMI-migration solution is built on top of these two techniques and can adaptively distinguish their respective balancing missions, to achieve an overall success in efficiency and accuracy. Extensive experiments on the representative Colossal-AI platform validate the effectiveness of our proposals.",
        "comments": "13 pages",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11469"
    },
    {
        "doc_id": 277,
        "title": "Local Identification in the Instrumental Variable Multivariate Quantile Regression Model",
        "authors": [
            "Haruki Kono"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The instrumental variable (IV) quantile regression model introduced by Chernozhukov and Hansen (2005) is a useful tool for analyzing quantile treatment effects in the presence of endogeneity, but when outcome variables are multidimensional, it is silent on the joint distribution of different dimensions of each variable. To overcome this limitation, we propose an IV model built on the optimal-transport-based multivariate quantile that takes into account the correlation between the entries of the outcome variable. We then provide a local identification result for the model. Surprisingly, we find that the support size of the IV required for the identification is independent of the dimension of the outcome vector, as long as the IV is sufficiently informative. Our result follows from a general identification theorem that we establish, which has independent theoretical significance.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11422"
    },
    {
        "doc_id": 278,
        "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
        "authors": [
            "Md Zubair",
            "Md. Shahidul Salim",
            "Mehrab Mustafy Rahman",
            "Mohammad Jahid Ibna Basher",
            "Shahin Imran",
            "Iqbal H. Sarker"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence"
        ],
        "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with higher accuracy. These predictions guide our system to assist the farmers in making feasible decisions about planting, irrigation, harvesting, and so on. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.",
        "comments": "16 pages, 14 figures and 12 tables. Submitted to Engineering Application of Artificial Intelligence (Elsevier)",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11410"
    },
    {
        "doc_id": 279,
        "title": "Fake Google restaurant reviews and the implications for consumers and restaurants",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The use of online reviews to aid with purchase decisions is popular among consumers as it is a simple heuristic tool based on the reported experiences of other consumers. However, not all online reviews are written by real consumers or reflect actual experiences, and present implications for consumers and businesses. This study examines the effects of fake online reviews written by artificial intelligence (AI) on consumer decision making. Respondents were surveyed about their attitudes and habits concerning online reviews using an online questionnaire (n=351), and participated in a restaurant choice experiment using varying proportions of fake and real reviews. While the findings confirm prior studies, new insights are gained about the confusion for consumers and consequences for businesses when reviews written by AI are believed rather than real reviews. The study presents a fake review detection model using logistic regression modeling to score and flag reviews as a solution.",
        "comments": "pp.1-158, 41 tables, 11 figures. Doctor of Business Administration Dissertation",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11345"
    },
    {
        "doc_id": 280,
        "title": "An income-based approach to modeling commuting distance in the Toronto area",
        "authors": [
            "Shawn Berry"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "The purpose of this article is to propose a novel model of the effects of changes in shelter and driving costs on car commuting distances in the overheated Toronto housing market from 2011 to 2016. The model borrows from theoretical concepts of microeconomics and urban geography to examine the Toronto housing market. Using 2011 and 2016 Census data for census metropolitan areas (CMAs) and census agglomerations (CAs) in Southern Ontario and computed driving costs, the model of car commuting distance is based on variables of allocation of monthly household income to monthly shelter costs and driving costs as a function of the car driving distance to Toronto. Using this model, we can predict the effect on car commuting distance due to changes in any of the variables. The model also offers an explanation for communities of Toronto car commuters beyond a driving radius that we might expect for daily commuting. The model confirms that increases in shelter costs in the Toronto housing market from 2011 to 2016 have forced the boundaries of feasible housing locations outward, and forced households to move farther away, thus increasing car commuting distance.",
        "comments": "pp.1-40, 8 tables, 5 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11343"
    },
    {
        "doc_id": 281,
        "title": "Coevolution of Resource and Strategies in Common-Pool Resource Dilemmas: A Coupled Human-Environmental System Model",
        "authors": [
            "Chengyi Tu",
            "Renfei Chen",
            "Ying Fan",
            "Yongliang Yang"
        ],
        "subjects": [
            "Theoretical Economics"
        ],
        "abstract": "Common-pool resource governance requires users to cooperate and avoid overexploitation, but defection and free-riding often undermine cooperation. We model a human-environmental system that integrates dynamics of resource and users' strategies. The resource follows a logistic function that depends on natural growth rate, carrying capacity, and extraction rates of cooperators and defectors. The users' strategies evolve according to different processes that capture effects of payoff, resource, and noise. We analyze the feedback between resource availability and strategic adaptation, and explores the conditions for the emergence and maintenance of cooperation. We find different processes lead to different regimes of equilibrium solutions and resource levels depending on the parameter configuration and initial conditions. We also show that some processes can enhance the sustainability of the resource by making the users more responsive to the resource scarcity. The paper advances the understanding of human-environmental system and offers insights for resource governance policies and interventions.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11269"
    },
    {
        "doc_id": 282,
        "title": "Estimation with Pairwise Observations",
        "authors": [
            "Felix Chan",
            "Laszlo Matyas"
        ],
        "subjects": [
            "Econometrics",
            "Statistics Theory"
        ],
        "abstract": "The paper introduces a new estimation method for the standard linear regression model. The procedure is not driven by the optimisation of any objective function rather, it is a simple weighted average of slopes from observation pairs. The paper shows that such estimator is consistent for carefully selected weights. Other properties, such as asymptotic distributions, have also been derived to facilitate valid statistical inference. Unlike traditional methods, such as Least Squares and Maximum Likelihood, among others, the estimated residual of this estimator is not by construction orthogonal to the explanatory variables of the model. This property allows a wide range of practical applications, such as the testing of endogeneity, i.e.,the correlation between the explanatory variables and the disturbance terms, and potentially several others.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11229"
    },
    {
        "doc_id": 283,
        "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
        "authors": [
            "Xuechen Liu",
            "Md Sahidullah",
            "Kong Aik Lee",
            "Tomi Kinnunen"
        ],
        "subjects": [
            "Cryptography and Security",
            "Artificial Intelligence",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.",
        "comments": "To appear in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11156"
    },
    {
        "doc_id": 284,
        "title": "Long-term Effects of India's Childhood Immunization Program on Earnings and Consumption Expenditure: Comment",
        "authors": [
            "David Roodman"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Summan, Nandi, and Bloom (2023; SNB) finds that exposure of babies to India's Universal Immunization Programme (UIP) in the late 1980s increased their weekly wages in early adulthood by 0.138 log points and per-capita household consumption 0.028 points. But the results are attained by regressing on age, in years, while controlling for year of birth--two variables that, as constructed, are nearly collinear. The results are therefore attributable to trends during the one-year survey period, such as inflation. A randomization exercise shows that when the true impacts are zero, the SNB estimator averages 0.088 points for wages and 0.039 points for consumption.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11100"
    },
    {
        "doc_id": 285,
        "title": "Information Based Inference in Models with Set-Valued Predictions and Misspecification",
        "authors": [
            "Hiroaki Kaido",
            "Francesca Molinari"
        ],
        "subjects": [
            "Econometrics",
            "Methodology"
        ],
        "abstract": "This paper proposes an information-based inference method for partially identified parameters in incomplete models that is valid both when the model is correctly specified and when it is misspecified. Key features of the method are: (i) it is based on minimizing a suitably defined Kullback-Leibler information criterion that accounts for incompleteness of the model and delivers a non-empty pseudo-true set; (ii) it is computationally tractable; (iii) its implementation is the same for both correctly and incorrectly specified models; (iv) it exploits all information provided by variation in discrete and continuous covariates; (v) it relies on Rao's score statistic, which is shown to be asymptotically pivotal.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11046"
    },
    {
        "doc_id": 286,
        "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking Models",
        "authors": [
            "Ben Aoki-Sherwood",
            "Catherine Bregou",
            "David Liben-Nowell",
            "Kiran Tomlinson",
            "Thomas Zeng"
        ],
        "subjects": [
            "Machine Learning",
            "Multiagent Systems",
            "Econometrics"
        ],
        "abstract": "A common theory of choice posits that individuals make choices in a two-step process, first selecting some subset of the alternatives to consider before making a selection from the resulting consideration set. However, inferring unobserved consideration sets (or item consideration probabilities) in this \"consider then choose\" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We consider a natural extension of consider-then-choose models to a top-$k$ ranking setting, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that knowledge of item utilities allows us to infer bounds on the relative sizes of consideration probabilities. Additionally, given a condition on the expected consideration set size, we derive absolute upper and lower bounds on item consideration probabilities. We also provide algorithms to tighten those bounds on consideration probabilities by propagating inferred constraints. Thus, we show that we can learn useful information about consideration probabilities despite not being able to identify them precisely. We demonstrate our methods on a ranking dataset from a psychology experiment with two different ranking tasks (one with fixed consideration sets and one with unknown consideration sets). This combination of data allows us to estimate utilities and then learn about unknown consideration probabilities using our bounds.",
        "comments": "11 pages; accepted as an extended abstract to AAMAS '24",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11016"
    },
    {
        "doc_id": 287,
        "title": "Subjective Causality",
        "authors": [
            "Joseph Y. Halpern",
            "Evan Piermont"
        ],
        "subjects": [
            "Theoretical Economics",
            "Artificial Intelligence",
            "Logic in Computer Science"
        ],
        "abstract": "We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are consistent with some causal model and to identify causal judgements from observed behavior.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10937"
    },
    {
        "doc_id": 288,
        "title": "An Experimental Study of Decentralized Matching",
        "authors": [
            "Federico Echenique",
            "Alejandro Robinson-Cort\u00e9s",
            "Leeat Yariv"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "We present an experimental study of decentralized two-sided matching markets with no transfers. Experimental participants are informed of everyone's preferences and can make arbitrary non-binding match offers that get finalized when a period of market inactivity has elapsed. Several insights emerge. First, stable outcomes are prevalent. Second, while centralized clearinghouses commonly aim at implementing extremal stable matchings, our decentralized markets most frequently culminate in the median stable matching. Third, preferences' cardinal representations impact the stable partners participants match with. Last, the dynamics underlying our results exhibit strategic sophistication, with agents successfully avoiding cycles of blocking pairs.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10872"
    },
    {
        "doc_id": 289,
        "title": "Aberration compensation for the anamorphic triplet",
        "authors": [
            "Dmitry Zhuridov"
        ],
        "subjects": [
            "Optics",
            "Applied Physics",
            "Instrumentation and Detectors"
        ],
        "abstract": "Compensation of the generalized spherical aberrations is discussed for the plane-symmetric and anamorphic optical systems. The compensation rules are derived for an economical three-component double-plane symmetric telescopic system containing two cylindrical mirrors and one toroidal lens. Anamorphic systems, which provide large magnifications in the two orthogonal directions, are presented.",
        "comments": "4 pages, 4 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10762"
    },
    {
        "doc_id": 290,
        "title": "Methodology to assess prosumer participation in European electricity markets",
        "authors": [
            "Rub\u00e9n Rodr\u00edguez-Vilches",
            "Francisco Mart\u00edn-Mart\u00ednez",
            "\u00c1lvaro S\u00e1nchez-Miralles",
            "Javier Rodrigo Guti\u00e9rrez de la C\u00e1mara",
            "Sergio Mu\u00f1oz Delgado"
        ],
        "subjects": [
            "Physics and Society",
            "Systems and Control"
        ],
        "abstract": "The emergence of distributed generation and the electrification of demand have opened the possibility for prosumers to participate in electricity markets, receiving economic benefits on their bills and contributing to the reduction of carbon emissions, aligning with United Nations Sustainable Development Goal 7. Consumers and prosumers can participate through implicit and explicit demand flexibility and (collective) self-consumption. This study analyses the potential markets in which prosumers can participate and indicates whether these are currently open. The markets studied include day-ahead, intraday, ancillary services, adequacy services, constraint management, and local flexibility markets. Additionally, collective self-consumption is analysed as a service through which prosumers can participate in the electricity market. Previous studies are usually focused on a single market or in a single country, making impossible a complete comparison. This analysis has been done in Spain, Italy, Croatia, and the United Kingdom as representative countries to obtain a methodology to assess countries' openness to prosumer participation in electricity markets, comparing regulatory frameworks and assigning scores based on their prosumer inclusion across various markets. This work updates current literature reviews with the changes and a new description of local market designs in Spain. This methodology can be used to compare other countries' grade of openness. The results of this study show that the analysed countries can be categorised into three groups: almost open, partially open, and closed markets. Analysing the differences, recommendations on the following steps to foster user participation are suggested for each group.",
        "comments": "Journal ref:        Renewable and Sustainable Energy Reviews Volume 191, March 2024, 114179",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10696"
    },
    {
        "doc_id": 291,
        "title": "Quantum Computing Enhanced Service Ecosystem for Simulation in Manufacturing",
        "authors": [
            "Wolfgang Maass",
            "Ankit Agrawal",
            "Alessandro Ciani",
            "Sven Danz",
            "Alejandro Delgadillo",
            "Philipp Ganser",
            "Pascal Kienast",
            "Marco Kulig",
            "Valentina K\u00f6nig",
            "Nil Rodellas-Gr\u00e0cia",
            "Rivan Rughubar",
            "Stefan Schr\u00f6der",
            "Marc Stautner",
            "Hannah Stein",
            "Tobias Stollenwerk",
            "Daniel Zeuch",
            "Frank K. Wilhelm"
        ],
        "subjects": [
            "Quantum Physics",
            "Systems and Control"
        ],
        "abstract": "Quantum computing (QC) and machine learning (ML), taken individually or combined into quantum-assisted ML (QML), are ascending computing paradigms whose calculations come with huge potential for speedup, increase in precision, and resource reductions. Likely improvements for numerical simulations in engineering imply the possibility of a strong economic impact on the manufacturing industry. In this project report, we propose a framework for a quantum computing-enhanced service ecosystem for simulation in manufacturing, consisting of various layers ranging from hardware to algorithms to service and organizational layers. In addition, we give insight into the current state of the art of applications research based on QC and QML, both from a scientific and an industrial point of view. We further analyse two high-value use cases with the aim of a quantitative evaluation of these new computing paradigms for industrially-relevant settings.",
        "comments": "10 pages, 3 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10623"
    },
    {
        "doc_id": 292,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 293,
        "title": "Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest Machine Learning",
        "authors": [
            "Zaina Abu Hweij",
            "Florence Liang",
            "Sophie Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing",
            "Medical Physics"
        ],
        "abstract": "Acute compartment syndrome (ACS) is an orthopedic emergency, caused by elevated pressure within a muscle compartment, that leads to permanent tissue damage and eventually death. Diagnosis of ACS relies heavily on patient-reported symptoms, a method that is clinically unreliable and often supplemented with invasive intracompartmental pressure measurements. This study proposes a continuous, objective, noninvasive diagnostic for ACS. The device detects ACS through a random forest machine learning model that uses pressure readings from force-sensitive resistors (FSRs) placed on the skin. The final diagnosis is exported real-time to a web application via Bluetooth. To validate the diagnostic, a data set containing FSR measurements and the corresponding simulated intracompartmental pressure was created. The diagnostic achieved an accuracy, on par to the invasive gold standard, of 97%. The device excelled in key performance metrics including precision, sensitivity, and F1 score. Manufactured for 73 USD, our device may be an economic alternative to needle-based diagnostics. These results demonstrate the potential of noninvasive ACS diagnostics to meet clinical standards and enhance patient care.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10386"
    },
    {
        "doc_id": 294,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 295,
        "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms",
        "authors": [
            "Iris Yan"
        ],
        "subjects": [
            "Machine Learning"
        ],
        "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere. GS can cause severe damages to satellites, power grids, and communication infrastructures. Estimate of direct economic impacts of a large scale GS exceeds $40 billion a day in the US. Early prediction is critical in preventing and minimizing the hazards. However, current methods either predict several hours ahead but fail to identify all types of GS, or make predictions within short time, e.g., one hour ahead of the occurrence. This work aims to predict all types of geomagnetic storms reliably and as early as possible using big data and machine learning algorithms. By fusing big data collected from multiple ground stations in the world on different aspects of solar measurements and using Random Forests regression with feature selection and downsampling on minor geomagnetic storm instances (which carry majority of the data), we are able to achieve an accuracy of 82.55% on data collected in 2021 when making early predictions three hours in advance. Given that important predictive features such as historic Kp indices are measured every 3 hours and their importance decay quickly with the amount of time in advance, an early prediction of 3 hours ahead of time is believed to be close to the practical limit.",
        "comments": "14 pages, 7 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10290"
    },
    {
        "doc_id": 296,
        "title": "How industrial clusters influence the growth of the regional GDP: A spatial-approach",
        "authors": [
            "Vahidin Jeleskovic",
            "Steffen Loeber"
        ],
        "subjects": [
            "General Economics",
            "Econometrics"
        ],
        "abstract": "In this paper, we employ spatial econometric methods to analyze panel data from German NUTS 3 regions. Our goal is to gain a deeper understanding of the significance and interdependence of industry clusters in shaping the dynamics of GDP. To achieve a more nuanced spatial differentiation, we introduce indicator matrices for each industry sector which allows for extending the spatial Durbin model to a new version of it. This approach is essential due to both the economic importance of these sectors and the potential issue of omitted variables. Failing to account for industry sectors can lead to omitted variable bias and estimation problems. To assess the effects of the major industry sectors, we incorporate eight distinct branches of industry into our analysis. According to prevailing economic theory, these clusters should have a positive impact on the regions they are associated with. Our findings indeed reveal highly significant impacts, which can be either positive or negative, of specific sectors on local GDP growth. Spatially, we observe that direct and indirect effects can exhibit opposite signs, indicative of heightened competitiveness within and between industry sectors. Therefore, we recommend that industry sectors should be taken into consideration when conducting spatial analysis of GDP. Doing so allows for a more comprehensive understanding of the economic dynamics at play.",
        "comments": " ",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10261"
    },
    {
        "doc_id": 297,
        "title": "Nowcasting Madagascar's real GDP using machine learning algorithms",
        "authors": [
            "Franck Ramaharo",
            "Gerzhino Rasolofomanana"
        ],
        "subjects": [
            "General Economics",
            "Machine Learning"
        ],
        "abstract": "We investigate the predictive power of different machine learning algorithms to nowcast Madagascar's gross domestic product (GDP). We trained popular regression models, including linear regularized regression (Ridge, Lasso, Elastic-net), dimensionality reduction model (principal component regression), k-nearest neighbors algorithm (k-NN regression), support vector regression (linear SVR), and tree-based ensemble models (Random forest and XGBoost regressions), on 10 Malagasy quarterly macroeconomic leading indicators over the period 2007Q1--2022Q4, and we used simple econometric models as a benchmark. We measured the nowcast accuracy of each model by calculating the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by aggregating individual predictions, consistently outperforms traditional econometric models. We conclude that machine learning models can deliver more accurate and timely nowcasts of Malagasy economic performance and provide policymakers with additional guidance for data-driven decision making.",
        "comments": "13 pages, 6 figures, 5 tables",
        "date": "24 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10255"
    },
    {
        "doc_id": 298,
        "title": "Equilibrium Multiplicity: A Systematic Approach using Homotopies, with an Application to Chicago",
        "authors": [
            "Amine C-L. Ouazad"
        ],
        "subjects": [
            "General Economics"
        ],
        "abstract": "Discrete choice models with social interactions or spillovers may exhibit multiple equilibria. This paper provides a systematic approach to enumerating them for a quantitative spatial model with discrete locations, social interactions, and elastic housing supply. The approach relies on two homotopies. A homotopy is a smooth function that transforms the solutions of a simpler city where solutions are known, to a city with heterogeneous locations and finite supply elasticity. The first homotopy is that, in the set of cities with perfectly elastic floor surface supply, an economy with heterogeneous locations is homotopic to an economy with homogeneous locations, whose solutions can be comprehensively enumerated. Such an economy is epsilon close to an economy whose equilibria are the zeros of a system of polynomials. This is a well-studied area of mathematics where the enumeration of equilibria can be guaranteed. The second homotopy is that a city with perfectly elastic housing supply is homotopic to a city with an arbitrary supply elasticity. In a small number of cases, the path may bifurcate and a single path yields two or more equilibria. By running the method on thousands of cities, we obtain a large number of equilibria. Each equilibrium has different population distributions. We provide a method that is computationally feasible for economies with a large number of locations choices, with an empirical application to the City of Chicago. There exist multiple ``counterfactual Chicagos'' consistent with the estimated parameters. Population distribution, prices, and welfare are not uniquely pinned down by amenities. The paper's method can be applied to models in trade and IO. Further applications of algebraic geometry are suggested.",
        "comments": "MSC Class:          91; 90; 65                          ACM Class:          G.3; J.4; I.6",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10181"
    },
    {
        "doc_id": 299,
        "title": "Nowcasting economic activity in European regions using a mixed-frequency dynamic factor model",
        "authors": [
            "Luca Barbaglia",
            "Lorenzo Frattarolo",
            "Niko Hauzenberger",
            "Dominik Hirschbuehl",
            "Florian Huber",
            "Luca Onorante",
            "Michael Pfarrhofer",
            "Luca Tiozzo Pezzoli"
        ],
        "subjects": [
            "Econometrics"
        ],
        "abstract": "Timely information about the state of regional economies can be essential for planning, implementing and evaluating locally targeted economic policies. However, European regional accounts for output are published at an annual frequency and with a two-year delay. To obtain robust and more timely measures in a computationally efficient manner, we propose a mixed-frequency dynamic factor model that accounts for national information to produce high-frequency estimates of the regional gross value added (GVA). We show that our model produces reliable nowcasts of GVA in 162 regions across 12 European countries.",
        "comments": "JEL: C22, C53, R11; keywords: factor models, mixed-frequency, nowcasting, regional data",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10054"
    },
    {
        "doc_id": 300,
        "title": "Adaptive Mobile Manipulation for Articulated Objects In the Open World",
        "authors": [
            "Haoyu Xiong",
            "Russell Mendonca",
            "Kenneth Shaw",
            "Deepak Pathak"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Deploying robots in open-ended unstructured environments such as homes has been a long-standing research problem. However, robots are often studied only in closed-off lab settings, and prior mobile manipulation work is restricted to pick-move-place, which is arguably just the tip of the iceberg in this area. In this paper, we introduce Open-World Mobile Manipulation System, a full-stack approach to tackle realistic articulated object operation, e.g. real-world doors, cabinets, drawers, and refrigerators in open-ended unstructured environments. The robot utilizes an adaptive learning framework to initially learns from a small set of data through behavior cloning, followed by learning from online practice on novel objects that fall outside the training distribution. We also develop a low-cost mobile manipulation hardware platform capable of safe and autonomous online adaptation in unstructured environments with a cost of around 20,000 USD. In our experiments we utilize 20 articulate objects across 4 buildings in the CMU campus. With less than an hour of online learning for each object, the system is able to increase success rate from 50% of BC pre-training to 95% using online adaptation. Video results at https://open-world-mobilemanip.github.io/",
        "comments": "Website at https://open-world-mobilemanip.github.io/",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14403"
    },
    {
        "doc_id": 301,
        "title": "VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech",
        "authors": [
            "Chenpeng Du",
            "Yiwei Guo",
            "Hankun Wang",
            "Yifan Yang",
            "Zhikang Niu",
            "Shuai Wang",
            "Hui Zhang",
            "Xie Chen",
            "Kai Yu"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Recent TTS models with decoder-only Transformer architecture, such as SPEAR-TTS and VALL-E, achieve impressive naturalness and demonstrate the ability for zero-shot adaptation given a speech prompt. However, such decoder-only TTS models lack monotonic alignment constraints, sometimes leading to hallucination issues such as mispronunciation, word skipping and difficulty in stopping. To address this limitation, we propose VALL-T, a generative Transducer model that introduces shifting relative position embeddings for input phoneme sequence, explicitly indicating the monotonic generation process while maintaining the architecture of decoder-only Transformer. Consequently, VALL-T retains the capability of prompt-based zero-shot adaptation and demonstrates better robustness against hallucinations with a relative reduction of 28.3\\% in the word error rate. Furthermore, the controllability of alignment in VALL-T during decoding facilitates the use of untranscribed speech prompts, even in unknown languages. It also enables the synthesis of lengthy speech by utilizing an aligned context window.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14321"
    },
    {
        "doc_id": 302,
        "title": "Pilot Distributions for Phase Noise Estimation in Electro-Optic Frequency Comb Systems",
        "authors": [
            "Mohammad Farsi",
            "Magnus Karlsson",
            "Erik Agrell"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "We explore the optimal pilot positioning for phase tracking in electro-optic frequency comb setups. We show that, in contrast to previous results for regular multichannel systems, allocating the first and the last channels for pilots is optimal given a fixed pilot overhead",
        "comments": "Presented at European Conference on Optical Communications (ECOC) 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14308"
    },
    {
        "doc_id": 303,
        "title": "Constraint-Aware Mesh Refinement Method by Reachability Set Envelope of Curvature Bounded Paths",
        "authors": [
            "Juho Bae",
            "Ji Hoon Bai",
            "Byung-Yoon Lee",
            "Jun-Yong Lee"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper presents an enhanced direct-method-based approach for the real-time solution of optimal control problems to handle path constraints, such as obstacles. The principal contributions of this work are twofold: first, the existing methods for constructing reachability sets in the literature are extended to derive the envelope of these sets, which determines the region swept by all feasible trajectories between adjacent sample points. Second, we propose a novel method to guarantee constraint violation-free between discrete states in two dimensions through mesh refinement approach. To illustrate the effectiveness of the proposed methodology, numerical simulations are conducted on real-time path planning for fixed-wing unmanned aerial vehicles.",
        "comments": "Preprint submitted to Automatica",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14304"
    },
    {
        "doc_id": 304,
        "title": "PWM strategy with harmonics injection and modulated frequency triangular carrier. A review",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Francisco Perez- Hidalgo",
            "Francisco Vargas-Merino",
            "JuanR Heredia-Larrubia"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "A new, programmed pulse width modulation (PWM) technique to control power inverters, which uses a harmonic injection modulator and a frequency modulated triangular carrier, synchronized with the modulating signal is presented in this paper. The instantaneous carrier frequency is adjusted according to a periodic function synchronized with the fundamental term of the modulating signal, in order to maintain the average value of the instantaneous frequency as an odd positive integer multiple of 3, for each period of the modulating signal which is known as the average modulation order. The advantages of using the proposed technique over the conventional PWM techniques are the reduction in the total harmonic distortion and shift the frequency up of the temporal harmonics for any average modulation order. The experimental results show the viability of optimizing the time harmonics generated to minimize the vibrations in an induction motor or avoid the resonant frequencies.The mathematical formulation for the output modulated voltage is defined and the results are also checked experimentally and compared to a sinusoidal PWM technique",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14297"
    },
    {
        "doc_id": 305,
        "title": "Speech foundation models on intelligibility prediction for hearing-impaired listeners",
        "authors": [
            "Santiago Cuervo",
            "Ricard Marxer"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "Speech foundation models (SFMs) have been benchmarked on many speech processing tasks, often achieving state-of-the-art performance with minimal adaptation. However, the SFM paradigm has been significantly less explored for applications of interest to the speech perception community. In this paper we present a systematic evaluation of 10 SFMs on one such application: Speech intelligibility prediction. We focus on the non-intrusive setup of the Clarity Prediction Challenge 2 (CPC2), where the task is to predict the percentage of words correctly perceived by hearing-impaired listeners from speech-in-noise recordings. We propose a simple method that learns a lightweight specialized prediction head on top of frozen SFMs to approach the problem. Our results reveal statistically significant differences in performance across SFMs. Our method resulted in the winning submission in the CPC2, demonstrating its promise for speech perception applications.",
        "comments": "To be presented in ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14289"
    },
    {
        "doc_id": 306,
        "title": "Modelling Micro-Doppler Signature of Drone Propellers in Distributed ISAC",
        "authors": [
            "Heraldo Cesar Alves Costa",
            "Saw James Myint",
            "Carsten Andrich",
            "Sebastian W. Giehl",
            "Christian Schneider",
            "Reiner S. Thom\u00e4"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Integrated Sensing and Communication (ISAC) comprises detection and analysis of non-cooperative targets by exploiting the resources of the mobile radio system. In this context, micro-Doppler is of great importance for target classification, in order to distinguish objects with local movements. For developing algorithms for target classification, it is necessary to have a large amount of target signatures. Aiming to generate these data, this paper proposes a mathematical model for the micro-Doppler of drone rotating propellers, and validate the proposed model by comparing it to measured micro-Doppler. Results show that the proposed mathematical model can generate micro-Doppler data very similar to those from measurement data.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14287"
    },
    {
        "doc_id": 307,
        "title": "POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation",
        "authors": [
            "Bo Zhou",
            "Jun Hou",
            "Tianqi Chen",
            "Yinchi Zhou",
            "Xiongchao Chen",
            "Huidong Xie",
            "Qiong Liu",
            "Xueqi Guo",
            "Yu-Jung Tsai",
            "Vladimir Y. Panin",
            "Takuya Toyonaga",
            "James S. Duncan",
            "Chi Liu"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Artificial Intelligence",
            "Image and Video Processing"
        ],
        "abstract": "Low-dose PET offers a valuable means of minimizing radiation exposure in PET imaging. However, the prevalent practice of employing additional CT scans for generating attenuation maps (u-map) for PET attenuation correction significantly elevates radiation doses. To address this concern and further mitigate radiation exposure in low-dose PET exams, we propose POUR-Net - an innovative population-prior-aided over-under-representation network that aims for high-quality attenuation map generation from low-dose PET. First, POUR-Net incorporates an over-under-representation network (OUR-Net) to facilitate efficient feature extraction, encompassing both low-resolution abstracted and fine-detail features, for assisting deep generation on the full-resolution level. Second, complementing OUR-Net, a population prior generation machine (PPGM) utilizing a comprehensive CT-derived u-map dataset, provides additional prior information to aid OUR-Net generation. The integration of OUR-Net and PPGM within a cascade framework enables iterative refinement of $\u03bc$-map generation, resulting in the production of high-quality $\u03bc$-maps. Experimental results underscore the effectiveness of POUR-Net, showing it as a promising solution for accurate CT-free low-count PET attenuation correction, which also surpasses the performance of previous baseline methods.",
        "comments": "10 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14285"
    },
    {
        "doc_id": 308,
        "title": "Energy-Efficient Power Allocation in Cell-Free Massive MIMO via Graph Neural Networks",
        "authors": [
            "Ramprasad Raghunath",
            "Bile Peng",
            "Eduard A. Jorswieck"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "CF-mMIMO systems are a promising solution to enhance the performance in 6G wireless networks. Its distributed nature of the architecture makes it highly reliable, provides sufficient coverage and allows higher performance than cellular networks. EE is an important metric that reduces the operating costs and also better for the environment. In this work, we optimize the downlink EE performance with MRT precoding and power allocation. Our aim is to achieve a less complex, distributed and scalable solution. To achieve this, we apply unsupervised ML with permutation equivariant architecture and use a non-convex objective function with multiple local optima. We compare the performance with the centralized and computationally expensive SCA. The results indicate that the proposed approach can outperform the baseline with significantly less computation time.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14281"
    },
    {
        "doc_id": 309,
        "title": "Optimization-based motion primitive automata for autonomous driving",
        "authors": [
            "Matheus V. A. Pedrosa",
            "Patrick Scheffe",
            "Bassam Alrifaee",
            "Kathrin Fla\u00dfkamp"
        ],
        "subjects": [
            "Systems and Control",
            "Robotics"
        ],
        "abstract": "Trajectory planning for autonomous cars can be addressed by primitive-based methods, which encode nonlinear dynamical system behavior into automata. In this paper, we focus on optimal trajectory planning. Since, typically, multiple criteria have to be taken into account, multiobjective optimization problems have to be solved. For the resulting Pareto-optimal motion primitives, we introduce a universal automaton, which can be reduced or reconfigured according to prioritized criteria during planning. We evaluate a corresponding multi-vehicle planning scenario with both simulations and laboratory experiments.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14276"
    },
    {
        "doc_id": 310,
        "title": "Improving Design of Input Condition Invariant Speech Enhancement",
        "authors": [
            "Wangyou Zhang",
            "Jee-weon Jung",
            "Shinji Watanabe",
            "Yanmin Qian"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Building a single universal speech enhancement (SE) system that can handle arbitrary input is a demanded but underexplored research topic. Towards this ultimate goal, one direction is to build a single model that handles diverse audio duration, sampling frequencies, and microphone variations in noisy and reverberant scenarios, which we define here as \"input condition invariant SE\". Such a model was recently proposed showing promising performance; however, its multi-channel performance degraded severely in real conditions. In this paper we propose novel architectures to improve the input condition invariant SE model so that performance in simulated conditions remains competitive while real condition degradation is much mitigated. For this purpose, we redesign the key components that comprise such a system. First, we identify that the channel-modeling module's generalization to unseen scenarios can be sub-optimal and redesign this module. We further introduce a two-stage training strategy to enhance training efficiency. Second, we propose two novel dual-path time-frequency blocks, demonstrating superior performance with fewer parameters and computational costs compared to the existing method. All proposals combined, experiments on various public datasets validate the efficacy of the proposed model, with significantly improved performance on real conditions. Recipe with full model details is released at https://github.com/espnet/espnet.",
        "comments": "Accepted by ICASSP 2024, 5 pages, 2 figures, 3 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14271"
    },
    {
        "doc_id": 311,
        "title": "Combined Generative and Predictive Modeling for Speech Super-resolution",
        "authors": [
            "Heming Wang",
            "Eric W. Healy",
            "DeLiang Wang"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Speech super-resolution (SR) is the task that restores high-resolution speech from low-resolution input. Existing models employ simulated data and constrained experimental settings, which limit generalization to real-world SR. Predictive models are known to perform well in fixed experimental settings, but can introduce artifacts in adverse conditions. On the other hand, generative models learn the distribution of target data and have a better capacity to perform well on unseen conditions. In this study, we propose a novel two-stage approach that combines the strengths of predictive and generative models. Specifically, we employ a diffusion-based model that is conditioned on the output of a predictive model. Our experiments demonstrate that the model significantly outperforms single-stage counterparts and existing strong baselines on benchmark SR datasets. Furthermore, we introduce a repainting technique during the inference of the diffusion process, enabling the proposed model to regenerate high-frequency components even in mismatched conditions. An additional contribution is the collection of and evaluation on real SR recordings, using the same microphone at different native sampling rates. We make this dataset freely accessible, to accelerate progress towards real-world speech super-resolution.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14269"
    },
    {
        "doc_id": 312,
        "title": "Pulse width modulation technique with harmonic injection in the modulating wave and discontinuous frequency modulation for the carrier wave to reduce vibrations in asynchronous machines",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Juan-Ramon Heredia-Larrubia",
            "Francisco Perez-Hidalgo",
            "Francisco Vargas-Merino"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "A new carrier-based pulse-width modulation (PWM) technique to control power inverters is presented in this paper. To generate the output waveform, this technique compares a harmonic-injection modulating wave and a frequency-modulated triangular carrier wave. The instantaneous frequency for the carrier wave is adjusted according to a periodic function synchronized with the fundamental term of the modulating wave. The main motivation for using this technique compared to a classic PWM sinusoidal technique revolves around the reduction of total harmonic distortion, the reduction of the distortion factor and the shift of temporal harmonics to higher frequencies for any modulation frequency order. Experimental results show that it is possible to optimize the time harmonics generated to minimize vibrations produced by an induction motor when it is fed with a DC/AC converter controlled by the proposed control strategy. This is made possible by using a control parameter that modifies the instantaneous frequency of the carrier wave without modifying the number of pulses per period of the modulating wave, i. e. the mean value of the carrier wave frequency. The proposed technique is applied to an open loop-controlled inverter that operates an induction motor, helping to reduce the vibration levels produced.",
        "comments": "Journal ref:        : WILEY -The Institution of Engineering and Technology, England",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14263"
    },
    {
        "doc_id": 313,
        "title": "On generalisability of segment anything model for nuclear instance segmentation in histology images",
        "authors": [
            "Kesi Xu",
            "Lea Goetz",
            "Nasir Rajpoot"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Pre-trained on a large and diverse dataset, the segment anything model (SAM) is the first promptable foundation model in computer vision aiming at object segmentation tasks. In this work, we evaluate SAM for the task of nuclear instance segmentation performance with zero-shot learning and finetuning. We compare SAM with other representative methods in nuclear instance segmentation, especially in the context of model generalisability. To achieve automatic nuclear instance segmentation, we propose using a nuclei detection model to provide bounding boxes or central points of nu-clei as visual prompts for SAM in generating nuclear instance masks from histology images.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14248"
    },
    {
        "doc_id": 314,
        "title": "Efficient stripe artefact removal by a variational method: application to light-sheet microscopy, FIB-SEM and remote sensing images",
        "authors": [
            "Niklas Rottmayer",
            "Claudia Redenbach",
            "Florian Fahrbach"
        ],
        "subjects": [
            "Image and Video Processing"
        ],
        "abstract": "Light-sheet fluorescence microscopy (LSFM) is used to capture volume images of biological specimens. It offers high contrast deep inside densely fluorescence labelled samples, fast acquisition speed and minimal harmful effects on the sample. However, the resulting images often show strong stripe artifacts originating from light-matter interactions. We propose a robust variational method suitable for removing stripes which outperforms existing methods and offers flexibility through two adjustable parameters. This tool is widely applicable to improve visual quality as well as facilitate downstream processing and analysis of images acquired on systems that do not provide hardware-based destriping methods. An evaluation of methods is performed on LSFM, FIB-SEM and remote sensing data, supplemented by synthetic LSFM images. The latter is obtained by simulating the imaging process on virtual samples.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14220"
    },
    {
        "doc_id": 315,
        "title": "Active Simultaneously Transmitting and Reflecting Surface Assisted NOMA Networks",
        "authors": [
            "Xinwei Yue",
            "Jin Xie",
            "Chongjun Ouyang",
            "Yuanwei Liu",
            "Xia Shen",
            "Zhiguo Ding"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The novel active simultaneously transmitting and reflecting surface (ASTARS) has recently received a lot of attention due to its capability to conquer the multiplicative fading loss and achieve full-space smart radio environments. This paper introduces the ASTARS to assist non-orthogonal multiple access (NOMA) communications, where the stochastic geometry theory is used to model the spatial positions of pairing users. We design the independent reflection/transmission phase-shift controllers of ASTARS to align the phases of cascaded channels at pairing users. We derive new closed-form and asymptotic expressions of the outage probability and ergodic data rate for ASTARS-NOMA networks in the presence of perfect/imperfect successive interference cancellation (pSIC). The diversity orders and multiplexing gains for ASTARS-NOMA are derived to provide more insights. Furthermore, the system throughputs of ASTARS-NOMA are investigated in both delay-tolerant and delay-limited transmission modes. The numerical results are presented and show that: 1) ASTARS-NOMA with pSIC outperforms ASTARS assisted-orthogonal multiple access (ASTARS-OMA) in terms of outage probability and ergodic data rate; 2) The outage probability of ASTARS-NOMA can be further reduced within a certain range by increasing the power amplification factors; 3) The system throughputs of ASTARS-NOMA are superior to that of ASTARS-OMA in both delay-limited and delay-tolerant transmission modes.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14219"
    },
    {
        "doc_id": 316,
        "title": "InfiniteEn: A Multi-Source Energy Harvesting System with Load Monitoring Module for Batteryless Internet of Things",
        "authors": [
            "Priyesh Pappinisseri Puluckul",
            "Maarten Weyn"
        ],
        "subjects": [
            "Signal Processing",
            "Hardware Architecture"
        ],
        "abstract": "This paper presents InfiniteEn, a multi-source energy harvesting platform designed for the Internet of Batteryless Things (IoBT). InfiniteEn incorporates an efficient energy combiner to combine energy from different harvesting sources. The energy combiner uses capacitor-to-capacitor energy transfer to combine energy from multiple sources and achieves a nominal efficiency of 88\\%. In addition to multiplexing different sources, the energy combiner facilitates the estimation of the harvesting rate and the calibration of the capacity of the energy buffer. The energy storage architecture of InfiniteEn employs an array of storage buffers that can be configured on demand to cope with varying energy harvesting rates and load's energy requirements. To address the challenge of tracking the energy state of batteryless devices with minimum energy overhead, this work introduces the concept of a Load Monitoring Module (LMM). InfiniteEn is a load-agnostic platform, meaning that it does not require any prior knowledge of the energy profile of the load to track its energy states. The LMM assists InfiniteEn in tracking the energy state of the load and dynamically modifying the storage buffers to meet the load's energy requirements. Furthermore, the module can detect and signal any abnormalities in the energy consumption pattern of the load caused by a hardware or software defect. Experiments demonstrate that LMM has a response time of less than 11 ms to energy state changes.",
        "comments": "Accepted and presented at \"2023 IEEE World Forum on Internet of Things (WF-IoT)\" and to be published in IEEE Conference Proceedings",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14216"
    },
    {
        "doc_id": 317,
        "title": "Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation classification",
        "authors": [
            "Daniele Perlo",
            "Luca Berton",
            "Alessia Delpiano",
            "Francesca Menchini",
            "Stefano Tibaldi",
            "Marco Grosso",
            "Paolo Fonio"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence"
        ],
        "abstract": "The liver is the most involved organ by distant metastasis in colon-rectal cancer (CRC) patients and it comes necessary to be aware of the mutational status of the lesions to correctly design the best individual treatment. So far, efforts have been made in order to develop non-invasive and real-time methods that permit the analysis of the whole tumor, using new artificial intelligence tools to analyze the tumor's image obtained by Computed Tomography (CT) scan. In order to address the current medical workflow, that is biopsy analysis-based, we propose the first DeepLearning-based exploration, to our knowledge, of such classification approach from the patient medical imaging. We propose i) a solid pipeline for managing undersized datasets of available CT scans and ii) a baseline study for genomics mutation diagnosis support for preemptive patient follow-up. Our method is able to identify CRC RAS mutation family from CT images with 0.73 F1 score.",
        "comments": "ACM Class:          J.3; I.1.2",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14206"
    },
    {
        "doc_id": 318,
        "title": "Statistical Characterization of RIS-assisted UAV Communications in Terrestrial and Non-Terrestrial Networks Under Channel Aging",
        "authors": [
            "Thanh Luan Nguyen",
            "Georges Kaddoum",
            "Tri Nhu Do",
            "Zygmunt J. Haas"
        ],
        "subjects": [
            "Signal Processing",
            "Information Theory"
        ],
        "abstract": "This paper studies the statistical characterization of ground-to-UAV (G2A) and reconfigurable intelligent surface (RIS)-assisted UAV-to-ground (A2G) communications in terrestrial and non-terrestrial networks under the impact of channel aging. We first model the G2A and A2G signal-to-noise ratios as non-central complex Gaussian quadratic random variables (RVs) and derive their exact probability density functions, offering a unique characterization for the A2G SNR as the product of two scaled non-central chi-square RVs. Moreover, we also find that, for a large number of RIS elements, the RIS-assisted A2G channel can be characterized as a single Rician fading channel. Our results reveal the presence of channel hardening in A2G communication under low UAV speeds, where we derive the maximum target spectral efficiency (SE) for a system to maintain a consistent required outage level. Meanwhile, high UAV speeds, exceeding 50 m/s, lead to a significant performance degradation, which cannot be mitigated by increasing the number of RIS elements.",
        "comments": "6 pages, 3 figures and 7 subfigures, IEEE ICC'24 (Revision),",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14203"
    },
    {
        "doc_id": 319,
        "title": "Clinical Melanoma Diagnosis with Artificial Intelligence: Insights from a Prospective Multicenter Study",
        "authors": [
            "Lukas Heinlein",
            "Roman C. Maron",
            "Achim Hekler",
            "Sarah Haggenm\u00fcller",
            "Christoph Wies",
            "Jochen S. Utikal",
            "Friedegund Meier",
            "Sarah Hobelsberger",
            "Frank F. Gellrich",
            "Mildred Sergon",
            "Axel Hauschild",
            "Lars E. French",
            "Lucie Heinzerling",
            "Justin G. Schlager",
            "Kamran Ghoreschi",
            "Max Schlaak",
            "Franz J. Hilke",
            "Gabriela Poch",
            "S\u00f6ren Korsing",
            "Carola Berking",
            "Markus V. Heppt",
            "Michael Erdmann",
            "Sebastian Haferkamp",
            "Konstantin Drexler",
            "Dirk Schadendorf",
            "et al. (5 additional authors not shown)"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Applications"
        ],
        "abstract": "Early detection of melanoma, a potentially lethal type of skin cancer with high prevalence worldwide, improves patient prognosis. In retrospective studies, artificial intelligence (AI) has proven to be helpful for enhancing melanoma detection. However, there are few prospective studies confirming these promising results. Existing studies are limited by low sample sizes, too homogenous datasets, or lack of inclusion of rare melanoma subtypes, preventing a fair and thorough evaluation of AI and its generalizability, a crucial aspect for its application in the clinical setting. Therefore, we assessed 'All Data are Ext' (ADAE), an established open-source ensemble algorithm for detecting melanomas, by comparing its diagnostic accuracy to that of dermatologists on a prospectively collected, external, heterogeneous test set comprising eight distinct hospitals, four different camera setups, rare melanoma subtypes, and special anatomical sites. We advanced the algorithm with real test-time augmentation (R-TTA, i.e. providing real photographs of lesions taken from multiple angles and averaging the predictions), and evaluated its generalization capabilities. Overall, the AI showed higher balanced accuracy than dermatologists (0.798, 95% confidence interval (CI) 0.779-0.814 vs. 0.781, 95% CI 0.760-0.802; p<0.001), obtaining a higher sensitivity (0.921, 95% CI 0.900- 0.942 vs. 0.734, 95% CI 0.701-0.770; p<0.001) at the cost of a lower specificity (0.673, 95% CI 0.641-0.702 vs. 0.828, 95% CI 0.804-0.852; p<0.001). As the algorithm exhibited a significant performance advantage on our heterogeneous dataset exclusively comprising melanoma-suspicious lesions, AI may offer the potential to support dermatologists particularly in diagnosing challenging cases.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14193"
    },
    {
        "doc_id": 320,
        "title": "TDFNet: An Efficient Audio-Visual Speech Separation Model with Top-down Fusion",
        "authors": [
            "Samuel Pegg",
            "Kai Li",
            "Xiaolin Hu"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Audio and Speech Processing"
        ],
        "abstract": "Audio-visual speech separation has gained significant traction in recent years due to its potential applications in various fields such as speech recognition, diarization, scene analysis and assistive technologies. Designing a lightweight audio-visual speech separation network is important for low-latency applications, but existing methods often require higher computational costs and more parameters to achieve better separation performance. In this paper, we present an audio-visual speech separation model called Top-Down-Fusion Net (TDFNet), a state-of-the-art (SOTA) model for audio-visual speech separation, which builds upon the architecture of TDANet, an audio-only speech separation method. TDANet serves as the architectural foundation for the auditory and visual networks within TDFNet, offering an efficient model with fewer parameters. On the LRS2-2Mix dataset, TDFNet achieves a performance increase of up to 10\\% across all performance metrics compared with the previous SOTA method CTCNet. Remarkably, these results are achieved using fewer parameters and only 28\\% of the multiply-accumulate operations (MACs) of CTCNet. In essence, our method presents a highly effective and efficient solution to the challenges of speech separation within the audio-visual domain, making significant strides in harnessing visual information optimally.",
        "comments": "Journal ref:        2023 13th International Conference on Information Science and Technology (ICIST), Cairo, Egypt, 2023, pp. 243-252",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14185"
    },
    {
        "doc_id": 321,
        "title": "Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Yaniv Proselkov",
            "Alexandra Brintrup"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Multiagent Systems",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Recent global disruptions, such as the pandemic and geopolitical conflicts, have profoundly exposed vulnerabilities in traditional supply chains, requiring exploration of more resilient alternatives. Autonomous supply chains (ASCs) have emerged as a potential solution, offering increased visibility, flexibility, and resilience in turbulent trade environments. Despite discussions in industry and academia over several years, ASCs lack well-established theoretical foundations. This paper addresses this research gap by presenting a formal definition of ASC along with its defining characteristics and auxiliary concepts. We propose a layered conceptual framework called the MIISI model. An illustrative case study focusing on the meat supply chain demonstrates an initial ASC implementation based on this conceptual model. Additionally, we introduce a seven-level supply chain autonomy reference model, delineating a trajectory towards achieving a full supply chain autonomy. Recognising that this work represents an initial endeavour, we emphasise the need for continued exploration in this emerging domain. We anticipate that this work will stimulate further research, both theoretical and technical, and contribute to the continual evolution of ASCs.",
        "comments": "This paper includes 20 pages and 8 figures",
        "date": "13 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.14183"
    },
    {
        "doc_id": 322,
        "title": "Predicting Hypoxia in Brain Tumors from Multiparametric MRI",
        "authors": [
            "Daniele Perlo",
            "Georgia Kanli",
            "Selma Boudissa",
            "Olivier Keunen"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence"
        ],
        "abstract": "This research paper presents a novel approach to the prediction of hypoxia in brain tumors, using multi-parametric Magnetic Resonance Imaging (MRI). Hypoxia, a condition characterized by low oxygen levels, is a common feature of malignant brain tumors associated with poor prognosis. Fluoromisonidazole Positron Emission Tomography (FMISO PET) is a well-established method for detecting hypoxia in vivo, but it is expensive and not widely available. Our study proposes the use of MRI, a more accessible and cost-effective imaging modality, to predict FMISO PET signals. We investigate deep learning models (DL) trained on the ACRIN 6684 dataset, a resource that contains paired MRI and FMISO PET images from patients with brain tumors. Our trained models effectively learn the complex relationships between the MRI features and the corresponding FMISO PET signals, thereby enabling the prediction of hypoxia from MRI scans alone. The results show a strong correlation between the predicted and actual FMISO PET signals, with an overall PSNR score above 29.6 and a SSIM score greater than 0.94, confirming MRI as a promising option for hypoxia prediction in brain tumors. This approach could significantly improve the accessibility of hypoxia detection in clinical settings, with the potential for more timely and targeted treatments.",
        "comments": "7 pages, 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14171"
    },
    {
        "doc_id": 323,
        "title": "Attention-based Efficient Classification for 3D MRI Image of Alzheimer's Disease",
        "authors": [
            "Yihao Lin",
            "Ximeng Li",
            "Yan Zhang",
            "Jinshan Tang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Early diagnosis of Alzheimer Diagnostics (AD) is a challenging task due to its subtle and complex clinical symptoms. Deep learning-assisted medical diagnosis using image recognition techniques has become an important research topic in this field. The features have to accurately capture main variations of anatomical brain structures. However, time-consuming is expensive for feature extraction by deep learning training. This study proposes a novel Alzheimer's disease detection model based on Convolutional Neural Networks. The model utilizes a pre-trained ResNet network as the backbone, incorporating post-fusion algorithm for 3D medical images and attention mechanisms. The experimental results indicate that the employed 2D fusion algorithm effectively improves the model's training expense. And the introduced attention mechanism accurately weights important regions in images, further enhancing the model's diagnostic accuracy.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14130"
    },
    {
        "doc_id": 324,
        "title": "Performance Analysis for Near-Field ISAC: A Holographic MIMO Design",
        "authors": [
            "Boqun Zhao",
            "Chongjun Ouyang",
            "Xingqi Zhang",
            "Yuanwei Liu"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "A near-field holographic multiple-input multiple-output (MIMO) based integrated sensing and communications (ISAC) framework is proposed for both downlink and uplink scenarios, where spherical wave-based model is considered to capture the characteristics of the near field. The coupling effect introduced by the densely spaced antennas of the holographic MIMO are characterized by spatially correlated Rayleigh fading. Based on the proposed framework, by considering both instantaneous channel state information (CSI) and statistical CSI, closed-form expressions are derived for sensing rates (SRs), communication rates (CRs), and outage probabilities under different ISAC designs. Further insights are gained by examining high signal-to-noise ratio slopes and diversity orders. Specifically, 1) for the downlink case, a sensing-centric (S-C) design and a communications-centric (C-C) design are investigated based on different beamforming strategies, and a Pareto optimal design is proposed to characterize the attainable SR-CR region; and 2) for the uplink case, the S-C design and the C-C design are distinguished by the interference cancellation order of the communication signal and the sensing signal, and the rate region is obtained through a time-sharing strategy. Numerical results reveal that the proposed ISAC system achieves more extensive rate regions than the conventional frequency-division sensing and communications system, highlighting its superior performance.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14129"
    },
    {
        "doc_id": 325,
        "title": "Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement",
        "authors": [
            "Aaqib Saeed",
            "Dimitris Spathis",
            "Jungwoo Oh",
            "Edward Choi",
            "Ali Etemad"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Wearable technologies enable continuous monitoring of various health metrics, such as physical activity, heart rate, sleep, and stress levels. A key challenge with wearable data is obtaining quality labels. Unlike modalities like video where the videos themselves can be effectively used to label objects or events, wearable data do not contain obvious cues about the physical manifestation of the users and usually require rich metadata. As a result, label noise can become an increasingly thorny issue when labeling such data. In this paper, we propose a novel solution to address noisy label learning, entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initially learns a seed model using weak labels. Next, it fine-tunes the seed model using a handful of expert corrections. Finally, it achieves better generalizability and robustness by merging the seed and fine-tuned models via weighted parameter averaging. We evaluate our approach on four challenging tasks and datasets, and compare it against eight competitive baselines designed to deal with noisy labels. We show that FHLR achieves significantly better performance when learning from noisy labels and achieves state-of-the-art by a large margin, with up to 19% accuracy improvement under symmetric and asymmetric noise. Notably, we find that FHLR is particularly robust to increased label noise, unlike prior works that suffer from severe performance degradation. Our work not only achieves better generalization in high-stakes health sensing benchmarks but also sheds light on how noise affects commonly-used models.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14107"
    },
    {
        "doc_id": 326,
        "title": "Enhanced Multi-Target Tracking in Dynamic Environments: Distributed Control Methods Within the Random Finite Set Framework",
        "authors": [
            "Aidan Blair",
            "Amirali Khodadadian Gostar",
            "Alireza Bab-Hadiashar",
            "Xiaodong Li",
            "Reza Hoseinnezhad"
        ],
        "subjects": [
            "Systems and Control",
            "Signal Processing"
        ],
        "abstract": "Tracking multiple targets in dynamic environments using distributed sensor networks is a challenging problem that has received significant attention in recent years. In such scenarios, the network of sensors must coordinate their actions to estimate the locations and trajectories of multiple targets accurately. Multi-sensor control methods can improve the performance of these networks by enabling efficient utilization of resources and enhancing the accuracy of the estimated target states. This paper proposes two novel multi-sensor control methods that utilize the Random Finite Set (RFS) framework to address this problem. Our methods improve computational tractability and enable fully distributed control, making them suitable for real-time applications.",
        "comments": "22 pages, 9 figures, submitted to Signal Processing",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14085"
    },
    {
        "doc_id": 327,
        "title": "Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India",
        "authors": [
            "Hasmat Malik",
            "Amit Kumar Yadav",
            "Fausto Pedro Garc\u00eda M\u00e1rquez",
            "Jes\u00fas Mar\u00eda Pinar-P\u00e9rez"
        ],
        "subjects": [
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Wind power generated by wind has non-schedule nature due to stochastic nature of meteorological variable. Hence energy business and control of wind power generation requires prediction of wind speed (WS) from few seconds to different time steps in advance. To deal with prediction shortcomings, various WS prediction methods have been used. Predictive data mining offers variety of methods for WS predictions where artificial neural network (ANN) is one of the reliable and accurate methods. It is observed from the result of this study that ANN gives better accuracy in comparison conventional model. The accuracy of WS prediction models is found to be dependent on input parameters and architecture type algorithms utilized. So the selection of most relevant input parameters is important research area in WS predicton field. The objective of the paper is twofold: first extensive review of ANN for wind power and WS prediction is carried out. Discussion and analysis of feature selection using Relief Algorithm (RA) in WS prediction are considered for different Indian sites. RA identify atmospheric pressure, solar radiation and relative humidity are relevant input variables. Based on relevant input variables Cascade ANN model is developed and prediction accuracy is evaluated. It is found that root mean square error (RMSE) for comparison between predicted and measured WS for training and testing wind speed are found to be 1.44 m/s and 1.49 m/s respectively. The developed cascade ANN model can be used to predict wind speed for sites where there are not WS measuring instruments are installed in India.",
        "comments": "Malik, H., Yadav, A. K., M\u00e1rquez, F. P. G., & Pinar-P\u00e9rez, J. M. (2022). Novel application of Relief Algorithm in cascaded artificial neural network to predict wind speed for wind power resource assessment in India. Energy Strategy Reviews, 41, 100864",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14065"
    },
    {
        "doc_id": 328,
        "title": "Towards a Systems Theory of Algorithms",
        "authors": [
            "Florian D\u00f6rfler",
            "Zhiyu He",
            "Giuseppe Belgioioso",
            "Saverio Bolognani",
            "John Lygeros",
            "Michael Muehlebach"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Traditionally, numerical algorithms are seen as isolated pieces of code confined to an {\\em in silico} existence. However, this perspective is not appropriate for many modern computational approaches in control, learning, or optimization, wherein {\\em in vivo} algorithms interact with their environment. Examples of such {\\em open} include various real-time optimization-based control strategies, reinforcement learning, decision-making architectures, online optimization, and many more. Further, even {\\em closed} algorithms in learning or optimization are increasingly abstracted in block diagrams with interacting dynamic modules and pipelines. In this opinion paper, we state our vision on a to-be-cultivated {\\em systems theory of algorithms} and argue in favour of viewing algorithms as open dynamical systems interacting with other algorithms, physical systems, humans, or databases. Remarkably, the manifold tools developed under the umbrella of systems theory also provide valuable insights into this burgeoning paradigm shift and its accompanying challenges in the algorithmic world. We survey various instances where the principles of algorithmic systems theory are being developed and outline pertinent modeling, analysis, and design challenges.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14029"
    },
    {
        "doc_id": 329,
        "title": "Massive Unsourced Random Access for Near-Field Communications",
        "authors": [
            "Xinyu Xie",
            "Yongpeng Wu",
            "Jianping An",
            "Derrick Wing Kwan Ng",
            "Chengwen Xing",
            "Wenjun Zhang"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper investigates the unsourced random access (URA) problem with a massive multiple-input multiple-output receiver that serves wireless devices in the near-field of radiation. We employ an uncoupled transmission protocol without appending redundancies to the slot-wise encoded messages. To exploit the channel sparsity for block length reduction while facing the collapsed sparse structure in the angular domain of near-field channels, we propose a sparse channel sampling method that divides the angle-distance (polar) domain based on the maximum permissible coherence. Decoding starts with retrieving active codewords and channels from each slot. We address the issue by leveraging the structured channel sparsity in the spatial and polar domains and propose a novel turbo-based recovery algorithm. Furthermore, we investigate an off-grid compressed sensing method to refine discretely estimated channel parameters over the continuum that improves the detection performance. Afterward, without the assistance of redundancies, we recouple the separated messages according to the similarity of the users' channel information and propose a modified K-medoids method to handle the constraints and collisions involved in channel clustering. Simulations reveal that via exploiting the channel sparsity, the proposed URA scheme achieves high spectral efficiency and surpasses existing multi-slot-based schemes. Moreover, with more measurements provided by the overcomplete channel sampling, the near-field-suited scheme outperforms its counterpart of the far-field.",
        "comments": "Accepted by IEEE Transactions on Communications",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14008"
    },
    {
        "doc_id": 330,
        "title": "Semantic Ensemble Loss and Latent Refinement for High-Fidelity Neural Image Compression",
        "authors": [
            "Daxin Li",
            "Yuanchao Bai",
            "Kai Wang",
            "Junjun Jiang",
            "Xianming Liu"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Recent advancements in neural compression have surpassed traditional codecs in PSNR and MS-SSIM measurements. However, at low bit-rates, these methods can introduce visually displeasing artifacts, such as blurring, color shifting, and texture loss, thereby compromising perceptual quality of images. To address these issues, this study presents an enhanced neural compression method designed for optimal visual fidelity. We have trained our model with a sophisticated semantic ensemble loss, integrating Charbonnier loss, perceptual loss, style loss, and a non-binary adversarial loss, to enhance the perceptual quality of image reconstructions. Additionally, we have implemented a latent refinement process to generate content-aware latent codes. These codes adhere to bit-rate constraints, balance the trade-off between distortion and fidelity, and prioritize bit allocation to regions of greater importance. Our empirical findings demonstrate that this approach significantly improves the statistical fidelity of neural image compression. On CLIC2024 validation set, our approach achieves a 62% bitrate saving compared to MS-ILLM under FID metric.",
        "comments": "7 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14007"
    },
    {
        "doc_id": 331,
        "title": "WAL-Net: Weakly supervised auxiliary task learning network for carotid plaques classification",
        "authors": [
            "Haitao Gan",
            "Lingchao Fu",
            "Ran Zhou",
            "Weiyan Gan",
            "Furong Wang",
            "Xiaoyan Wu",
            "Zhi Yang",
            "Zhongwei Huang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "The classification of carotid artery ultrasound images is a crucial means for diagnosing carotid plaques, holding significant clinical relevance for predicting the risk of stroke. Recent research suggests that utilizing plaque segmentation as an auxiliary task for classification can enhance performance by leveraging the correlation between segmentation and classification tasks. However, this approach relies on obtaining a substantial amount of challenging-to-acquire segmentation annotations. This paper proposes a novel weakly supervised auxiliary task learning network model (WAL-Net) to explore the interdependence between carotid plaque classification and segmentation tasks. The plaque classification task is primary task, while the plaque segmentation task serves as an auxiliary task, providing valuable information to enhance the performance of the primary task. Weakly supervised learning is adopted in the auxiliary task to completely break away from the dependence on segmentation annotations. Experiments and evaluations are conducted on a dataset comprising 1270 carotid plaque ultrasound images from Wuhan University Zhongnan Hospital. Results indicate that the proposed method achieved an approximately 1.3% improvement in carotid plaque classification accuracy compared to the baseline network. Specifically, the accuracy of mixed-echoic plaques classification increased by approximately 3.3%, demonstrating the effectiveness of our approach.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13998"
    },
    {
        "doc_id": 332,
        "title": "Knowledge Graph Driven UAV Cognitive Semantic Communication Systems for Efficient Object Detection",
        "authors": [
            "Xi Song",
            "Lu Yuan",
            "Zhibo Qu",
            "Fuhui Zhou",
            "Qihui Wu",
            "Tony Q. S. Quek",
            "Rose Qingyang Hu"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) are widely used for object detection. However, the existing UAV-based object detection systems are subject to the serious challenge, namely, the finite computation, energy and communication resources, which limits the achievable detection performance. In order to overcome this challenge, a UAV cognitive semantic communication system is proposed by exploiting knowledge graph. Moreover, a multi-scale compression network is designed for semantic compression to reduce data transmission volume while guaranteeing the detection performance. Furthermore, an object detection scheme is proposed by using the knowledge graph to overcome channel noise interference and compression distortion. Simulation results conducted on the practical aerial image dataset demonstrate that compared to the benchmark systems, our proposed system has superior detection accuracy, communication robustness and computation efficiency even under high compression rates and low signal-to-noise ratio (SNR) conditions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13995"
    },
    {
        "doc_id": 333,
        "title": "Deep Learning Innovations in Diagnosing Diabetic Retinopathy: The Potential of Transfer Learning and the DiaCNN Model",
        "authors": [
            "Mohamed R. Shoaib",
            "Heba M. Emara",
            "Jun Zhao",
            "Walid El-Shafai",
            "Naglaa F. Soliman",
            "Ahmed S. Mubarak",
            "Osama A. Omer",
            "Fathi E. Abd El-Samie",
            "Hamada Esmaiel"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Diabetic retinopathy (DR) is a significant cause of vision impairment, emphasizing the critical need for early detection and timely intervention to avert visual deterioration. Diagnosing DR is inherently complex, as it necessitates the meticulous examination of intricate retinal images by experienced specialists. This makes the early diagnosis of DR essential for effective treatment and the prevention of eventual blindness. Traditional diagnostic methods, relying on human interpretation of these medical images, face challenges in terms of accuracy and efficiency. In the present research, we introduce a novel method that offers superior precision in DR diagnosis, compared to these traditional methods, by employing advanced deep learning techniques. Central to this approach is the concept of transfer learning. This entails using pre-existing, well-established models, specifically InceptionResNetv2 and Inceptionv3, to extract features and fine-tune select layers to cater to the unique requirements of this specific diagnostic task. Concurrently, we also present a newly devised model, DiaCNN, which is tailored for the classification of eye diseases. To validate the efficacy of the proposed methodology, we leveraged the Ocular Disease Intelligent Recognition (ODIR) dataset, which comprises eight different eye disease categories. The results were promising. The InceptionResNetv2 model, incorporating transfer learning, registered an impressive 97.5% accuracy in both the training and testing phases. Its counterpart, the Inceptionv3 model, achieved an even more commendable 99.7% accuracy during training, and 97.5% during testing. Remarkably, the DiaCNN model showcased unparalleled precision, achieving 100% accuracy in training and 98.3\\% in testing.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13990"
    },
    {
        "doc_id": 334,
        "title": "A Nearly Information Theoretically Secure Approach for Semantic Communications over Wiretap Channel",
        "authors": [
            "Weixuan Chen",
            "Shuo Shao",
            "Qianqian Yang",
            "Zhaoyang Zhang",
            "Ping Zhang"
        ],
        "subjects": [
            "Information Theory",
            "Image and Video Processing"
        ],
        "abstract": "This paper addresses the challenge of achieving information-theoretic security in semantic communication (SeCom) over a wiretap channel, where a legitimate receiver coexists with an eavesdropper experiencing a poorer channel condition. Despite previous efforts to secure SeCom against eavesdroppers, achieving information-theoretic security in such schemes remains an open issue. In this work, we propose a secure digital SeCom approach based on superposition codes, aiming to attain nearly information-theoretic security. Our proposed method involves associating semantic information with satellite constellation points within a double-layered constellation map, where cloud center constellation points are randomly selected. By carefully allocating power between these two layers of constellation, we ensure that the symbol error probability (SEP) of the eavesdropper decoding satellite constellation points is nearly equivalent to random guessing, while maintaining a low SEP for the legitimate receiver to successfully decode the semantic information. Simulation results showcase that the Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) for the eavesdropper's reconstructed data, using our proposed method, can range from decoding Gaussian-distributed random noise to approaching the variance of the data. This validates the ability of our method to achieve nearly information-theoretic security, demonstrating superior data security compared to benchmark methods.",
        "comments": "13 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13980"
    },
    {
        "doc_id": 335,
        "title": "Conditional Neural Video Coding with Spatial-Temporal Super-Resolution",
        "authors": [
            "Henan Wang",
            "Xiaohan Pan",
            "Runsen Feng",
            "Zongyu Guo",
            "Zhibo Chen"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "This document is an expanded version of a one-page abstract originally presented at the 2024 Data Compression Conference. It describes our proposed method for the video track of the Challenge on Learned Image Compression (CLIC) 2024. Our scheme follows the typical hybrid coding framework with some novel techniques. Firstly, we adopt Spynet network to produce accurate motion vectors for motion estimation. Secondly, we introduce the context mining scheme with conditional frame coding to fully exploit the spatial-temporal information. As for the low target bitrates given by CLIC, we integrate spatial-temporal super-resolution modules to improve rate-distortion performance. Our team name is IMCLVC.",
        "comments": "Accepted by the 2024 Data Compression Conference (DCC) for presentation as a poster",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13959"
    },
    {
        "doc_id": 336,
        "title": "Automatic Tissue Traction with Haptics-Enabled Forceps for Minimally Invasive Surgery",
        "authors": [
            "Tangyou Liu",
            "Xiaoyi Wang",
            "Jay Katupitiya",
            "Jiaole Wang",
            "Liao Wu"
        ],
        "subjects": [
            "Robotics",
            "Human-Computer Interaction",
            "Systems and Control"
        ],
        "abstract": "A common limitation of autonomous tissue manipulation in robotic minimally invasive surgery (MIS) is the absence of force sensing and control at the tool level. Recently, our team has developed haptics-enabled forceps that can simultaneously measure the grasping and pulling forces during tissue manipulation. Based on this design, here we further present a method to automate tissue traction with controlled grasping and pulling forces. Specifically, the grasping stage relies on a controlled grasping force, while the pulling stage is under the guidance of a controlled pulling force. Notably, during the pulling process, the simultaneous control of both grasping and pulling forces is also enabled for more precise tissue traction, achieved through force decoupling. The force controller is built upon a static model of tissue manipulation, considering the interaction between the haptics-enabled forceps and soft tissue. The efficacy of this force control approach is validated through a series of experiments comparing targeted, estimated, and actual reference forces. To verify the feasibility of the proposed method in surgical applications, various tissue resections are conducted on ex vivo tissues employing a dual-arm robotic setup. Finally, we discuss the benefits of multi-force control in tissue traction, evidenced through comparative analyses of various ex vivo tissue resections. The results affirm the feasibility of implementing automatic tissue traction using micro-sized forceps with multi-force control, suggesting its potential to promote autonomous MIS. A video demonstrating the experiments can be found at https://youtu.be/8fe8o8IFrjE.",
        "comments": "12 pages, 12 figures, submitted to T-RO",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13957"
    },
    {
        "doc_id": 337,
        "title": "Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy Trading",
        "authors": [
            "Chen Feng",
            "Andrew L. Liu"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning",
            "Multiagent Systems"
        ],
        "abstract": "Utilizing distributed renewable and energy storage resources in local distribution networks via peer-to-peer (P2P) energy trading has long been touted as a solution to improve energy systems' resilience and sustainability. Consumers and prosumers (those who have energy generation resources), however, do not have the expertise to engage in repeated P2P trading, and the zero-marginal costs of renewables present challenges in determining fair market prices. To address these issues, we propose multi-agent reinforcement learning (MARL) frameworks to help automate consumers' bidding and management of their solar PV and energy storage resources, under a specific P2P clearing mechanism that utilizes the so-called supply-demand ratio. In addition, we show how the MARL frameworks can integrate physical network constraints to realize voltage control, hence ensuring physical feasibility of the P2P energy trading and paving way for real-world implementations.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13947"
    },
    {
        "doc_id": 338,
        "title": "Learning-based sensing and computing decision for data freshness in edge computing-enabled networks",
        "authors": [
            "Sinwoong Yun",
            "Dongsun Kim",
            "Chanwon Park",
            "Jemin Lee"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "As the demand on artificial intelligence (AI)-based applications increases, the freshness of sensed data becomes crucial in the wireless sensor networks. Since those applications require a large amount of computation for processing the sensed data, it is essential to offload the computation load to the edge computing (EC) server. In this paper, we propose the sensing and computing decision (SCD) algorithms for data freshness in the EC-enabled wireless sensor networks. We define the \u03b7-coverage probability to show the probability of maintaining fresh data for more than \u03b7 ratio of the network, where the spatial-temporal correlation of information is considered. We then propose the probability-based SCD for the single pre-charged sensor case with providing the optimal point after deriving the \u03b7-coverage probability. We also propose the reinforcement learning (RL)- based SCD by training the SCD policy of sensors for both the single pre-charged and multiple energy harvesting (EH) sensor cases, to make a real-time decision based on its observation. Our simulation results verify the performance of the proposed algorithms under various environment settings, and show that the RL-based SCD algorithm achieves higher performance compared to baseline algorithms for both the single pre-charged sensor and multiple EH sensor cases.",
        "comments": "15 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13936"
    },
    {
        "doc_id": 339,
        "title": "Iterative Methods in GPU-Resident Linear Solvers for Nonlinear Constrained Optimization",
        "authors": [
            "Kasia \u015awirydowicz",
            "Nicholson Koukpaizan",
            "Maksudul Alam",
            "Shaked Regev",
            "Michael Saunders",
            "Slaven Pele\u0161"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Systems and Control",
            "Numerical Analysis"
        ],
        "abstract": "Linear solvers are major computational bottlenecks in a wide range of decision support and optimization computations. The challenges become even more pronounced on heterogeneous hardware, where traditional sparse numerical linear algebra methods are often inefficient. For example, methods for solving ill-conditioned linear systems have relied on conditional branching, which degrades performance on hardware accelerators such as graphical processing units (GPUs). To improve the efficiency of solving ill-conditioned systems, our computational strategy separates computations that are efficient on GPUs from those that need to run on traditional central processing units (CPUs). Our strategy maximizes the reuse of expensive CPU computations. Iterative methods, which thus far have not been broadly used for ill-conditioned linear systems, play an important role in our approach. In particular, we extend ideas from [1] to implement iterative refinement using inexact LU factors and flexible generalized minimal residual (FGMRES), with the aim of efficient performance on GPUs. We focus on solutions that are effective within broader application contexts, and discuss how early performance tests could be improved to be more predictive of the performance in a realistic environment",
        "comments": "15 pages, 8 figures, 5 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13926"
    },
    {
        "doc_id": 340,
        "title": "Intelli-Z: Toward Intelligible Zero-Shot TTS",
        "authors": [
            "Sunghee Jung",
            "Won Jang",
            "Jaesam Yoon",
            "Bongwan Kim"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "Although numerous recent studies have suggested new frameworks for zero-shot TTS using large-scale, real-world data, studies that focus on the intelligibility of zero-shot TTS are relatively scarce. Zero-shot TTS demands additional efforts to ensure clear pronunciation and speech quality due to its inherent requirement of replacing a core parameter (speaker embedding or acoustic prompt) with a new one at the inference stage. In this study, we propose a zero-shot TTS model focused on intelligibility, which we refer to as Intelli-Z. Intelli-Z learns speaker embeddings by using multi-speaker TTS as its teacher and is trained with a cycle-consistency loss to include mismatched text-speech pairs for training. Additionally, it selectively aggregates speaker embeddings along the temporal dimension to minimize the interference of the text content of reference speech at the inference stage. We substantiate the effectiveness of the proposed methods with an ablation study. The Mean Opinion Score (MOS) increases by 9% for unseen speakers when the first two methods are ap- plied, and it further improves by 16% when selective temporal aggregation is applied.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13921"
    },
    {
        "doc_id": 341,
        "title": "Analog Beamforming for In-Band Full-Duplex Phased Arrays with Quantized Phase Shifters under a Per-Antenna Received Power Constraint",
        "authors": [
            "Ao Liu",
            "Ian P. Roberts",
            "Taneli Riihonen",
            "Weixing Sheng"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This letter develops a novel transmit beamforming (BF) design for canceling self-interference (SI) in analog in-band full-duplex phased arrays. Our design maximizes transmit BF gain in a desired direction while simultaneously reducing SI power to below a specified threshold on per-antenna basis to avoid saturating receive-chain components, such as LNAs. Core to our approach is that it accounts for real-world phase shifters used in analog phased array systems, whose limited resolution imposes non-convex constraints on BF design. We overcome this by transforming these non-convex constraints into convex polygon constraints, which we then solve through semidefinite relaxation and a rank refinement procedure. Numerical results show that our proposed BF scheme reliably cancels SI to the target power threshold at each receive antenna while sacrificing little in transmit BF gain, even with modest phase shifter resolution.",
        "comments": "This paper has been submitted to the IEEE for review; copyright may change without notice",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13914"
    },
    {
        "doc_id": 342,
        "title": "Computationally-Efficient Linear Periodically Time-Variant Digital PLL Modeling Using Conversion Matrices and Uncorrelated Upsampling",
        "authors": [
            "Hongyu Lu",
            "Patrick P. Mercier"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper introduces a conversion matrix method for linear periodically time-variant (LPTV) digital phase-locked loop (DPLL) phase noise modeling that offers precise and computationally efficient results to enable rapid design iteration and optimization. Unlike many previous studies, which either assume linear time-invariance (LTI) and therefore overlook phase noise aliasing effects, or solve LPTV systems with noise folding and multiple sampling rate conversions that heightens modeling and computational complexity, the proposed conversion matrix method allows the designer to represent the LPTV systems using intuitive LTI-like transfer functions with excellent accuracy. Additionally, computational efficiency is improved through the uncorrelated upsampling method, which eliminates the need to consider beat frequency of noise sources with different sampling rates. The proposed algorithm is applied to modeling a DPLL with time-varying proportional loop gain, and the modeling accuracy is validated with Simulink transient simulations.",
        "comments": "10 pages, 16 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13897"
    },
    {
        "doc_id": 343,
        "title": "A Survey on Indoor Visible Light Positioning Systems: Fundamentals, Applications, and Challenges",
        "authors": [
            "Zhiyu Zhu",
            "Yang Yang",
            "Mingzhe Chen",
            "Caili Guo",
            "Julian Cheng",
            "Shuguang Cui"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "The growing demand for location-based services in areas like virtual reality, robot control, and navigation has intensified the focus on indoor localization. Visible light positioning (VLP), leveraging visible light communications (VLC), becomes a promising indoor positioning technology due to its high accuracy and low cost. This paper provides a comprehensive survey of VLP systems. In particular, since VLC lays the foundation for VLP, we first present a detailed overview of the principles of VLC. The performance of each positioning algorithm is also compared in terms of various metrics such as accuracy, coverage, and orientation limitation. Beyond the physical layer studies, the network design for a VLP system is also investigated, including multi-access technologies resource allocation, and light-emitting diode (LED) placements. Next, the applications of the VLP systems are overviewed. Finally, this paper outlines open issues, challenges, and future research directions for the research field. In a nutshell, this paper constitutes the first holistic survey on VLP from state-of-the-art studies to practical uses.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13893"
    },
    {
        "doc_id": 344,
        "title": "Robust Transmission Design for RIS-Assisted Integrated Sensing and Communication Systems",
        "authors": [
            "Yongqing Xu",
            "Yong Li",
            "Tony Q. S. Quek"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "As a critical technology for next-generation communication networks, integrated sensing and communication (ISAC) aims to achieve the harmonious coexistence of communication and sensing. The degrees-of-freedom (DoF) of ISAC is limited due to multiple performance metrics used for communication and sensing. Reconfigurable Intelligent Surfaces (RIS) composed of metamaterials can enhance the DoF in the spatial domain of ISAC systems. However, the availability of perfect Channel State Information (CSI) is a prerequisite for the gain brought by RIS, which is not realistic in practical environments. Therefore, under the imperfect CSI condition, we propose a decomposition-based large deviation inequality approach to eliminate the impact of CSI error on communication rate and sensing Cram\u00e9r-Rao bound (CRB). Then, an alternating optimization (AO) algorithm based on semi-definite relaxation (SDR) and gradient extrapolated majorization-maximization (GEMM) is proposed to solve the transmit beamforming and discrete RIS beamforming problems. We also analyze the complexity and convergence of the proposed algorithm. Simulation results show that the proposed algorithms can effectively eliminate the influence of CSI error and have good convergence performance. Notably, when CSI error exists, the gain brought by RIS will decrease with the increase of the number of RIS elements. Finally, we summarize and outline future research directions.",
        "comments": "This paper has been submitted to a IEEE journal. arXiv admin note: text overlap with arXiv:2303.01771",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13882"
    },
    {
        "doc_id": 345,
        "title": "Scaling NVIDIA's multi-speaker multi-lingual TTS systems with voice cloning to Indic Languages",
        "authors": [
            "Akshit Arora",
            "Rohan Badlani",
            "Sungwon Kim",
            "Rafael Valle",
            "Bryan Catanzaro"
        ],
        "subjects": [
            "Sound",
            "Machine Learning",
            "Audio and Speech Processing"
        ],
        "abstract": "In this paper, we describe the TTS models developed by NVIDIA for the MMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024 Challenge. In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS by training additionally on 5 minutes of target speaker data. In Track 3, we utilize P-Flow to perform zero-shot TTS by training on the challenge dataset as well as external datasets. We use HiFi-GAN vocoders for all submissions. RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first on Track 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS) of 3.62.",
        "comments": "Presentation accepted at ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13851"
    },
    {
        "doc_id": 346,
        "title": "Machine learning for industrial sensing and control: A survey and practical perspective",
        "authors": [
            "Nathan P. Lawrence",
            "Seshu Kumar Damarla",
            "Jong Woo Kim",
            "Aditya Tulsyan",
            "Faraz Amjad",
            "Kai Wang",
            "Benoit Chachuat",
            "Jong Min Lee",
            "Biao Huang",
            "R. Bhushan Gopaluni"
        ],
        "subjects": [
            "Systems and Control",
            "Machine Learning"
        ],
        "abstract": "With the rise of deep learning, there has been renewed interest within the process industries to utilize data on large-scale nonlinear sensing and control problems. We identify key statistical and machine learning techniques that have seen practical success in the process industries. To do so, we start with hybrid modeling to provide a methodological framework underlying core application areas: soft sensing, process optimization, and control. Soft sensing contains a wealth of industrial applications of statistical and machine learning methods. We quantitatively identify research trends, allowing insight into the most successful techniques in practice.\n  We consider two distinct flavors for data-driven optimization and control: hybrid modeling in conjunction with mathematical programming techniques and reinforcement learning. Throughout these application areas, we discuss their respective industrial requirements and challenges.\n  A common challenge is the interpretability and efficiency of purely data-driven methods. This suggests a need to carefully balance deep learning techniques with domain knowledge. As a result, we highlight ways prior knowledge may be integrated into industrial machine learning applications. The treatment of methods, problems, and applications presented here is poised to inform and inspire practitioners and researchers to develop impactful data-driven sensing, optimization, and control solutions in the process industries.",
        "comments": "48 pages",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13836"
    },
    {
        "doc_id": 347,
        "title": "Exploring Adversarial Threat Models in Cyber Physical Battery Systems",
        "authors": [
            "Shanthan Kumar Padisala",
            "Shashank Dhananjay Vyas",
            "Satadru Dey"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Technological advancements like the Internet of Things (IoT) have facilitated data exchange across various platforms. This data exchange across various platforms has transformed the traditional battery system into a cyber physical system. Such connectivity makes modern cyber physical battery systems vulnerable to cyber threats where a cyber attacker can manipulate sensing and actuation signals to bring the battery system into an unsafe operating condition. Hence, it is essential to build resilience in modern cyber physical battery systems (CPBS) under cyber attacks. The first step of building such resilience is to analyze potential adversarial behavior, that is, how the adversaries can inject attacks into the battery systems. However, it has been found that in this under-explored area of battery cyber physical security, such an adversarial threat model has not been studied in a systematic manner. In this study, we address this gap and explore adversarial attack generation policies based on optimal control framework. The framework is developed by performing theoretical analysis, which is subsequently supported by evaluation with experimental data generated from a commercial battery cell.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13801"
    },
    {
        "doc_id": 348,
        "title": "Synthetic Waveform Generation for Satellite, HAPS, and 5G Base Station Positioning Reference Signal Using QuaDRiGa",
        "authors": [
            "Hongzhao Zheng",
            "Mohamed Atia",
            "Halim Yanikomeroglu",
            "Paulo S. R. Diniz"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Waveform generation is essential for studying signal propagation and channel characteristics, particularly for objects that are conceptualized but still need to be operational. We introduce a comprehensive guide on creating synthetic signals using channel and delay coefficients derived from the Quasi-Deterministic Radio Channel Generator (QuaDRiGa), which is recognized as a 3GPP-3D and 3GPP 38.901 reference implementation. The effectiveness of the proposed synthetic waveform generation method is validated through accurate estimation of code delay and Doppler shift. This validation is achieved using both the parallel code phase search technique and the conventional tracking method applied to satellites. As the method of integrating channel and delay coefficients to create synthetic waveforms is the same for satellite, HAPS, and gNB PRS, validating this method on synthetic satellite signals could potentially be extended to HAPS and gNB PRS as well. This study could significantly contribute to the field of heterogeneous navigation systems.",
        "comments": "6 pages, 31 figures, conference",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13791"
    },
    {
        "doc_id": 349,
        "title": "Orthogonal Time-Frequency-Space (OTFS) and Related Signaling",
        "authors": [
            "Lie-Liang Yang"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "The principle of orthogonal time-frequency-space (OTFS) signaling is firstly analyzed, followed by explaining that OTFS embeds another signaling scheme referred to as orthogonal short-time Fourier (OSTF). Then, the relationship among OTFS, OSTF, orthogonal frequency-division multiplexing (OFDM) and single-carrier frequency-division multiple-access (SC-FDMA) is explored, demonstrating that OSTF/OTFS are fundamentally the extensions of OFDM/SC-FDMA from one-dimensional (1D) signaling to two-dimensional (2D) signaling. Hence, the characteristics and performance of OSTF/OTFS schemes can be perceived from the well-understood OFDM/SC-FDMA schemes. Accordingly, the advantages and disadvantages of OSTF/OTFS are discussed. Furthermore, from the principles of OFDM/SC-FDMA, the multiuser multiplexing in OSTF/OTFS systems is analyzed with respect to uplink and downlink, respectively. Added on this, a range of generalized multiplexing schemes are presented, whose characteristics are briefly analyzed.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13790"
    },
    {
        "doc_id": 350,
        "title": "On the Predictive Capability of Dynamic Mode Decomposition for Nonlinear Periodic Systems with Focus on Orbital Mechanics",
        "authors": [
            "Sriram Narayanan",
            "Mohamed Naveed Gul Mohamed",
            "Indranil Nayak",
            "Suman Chakravorty",
            "Mrinal Kumar"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "This paper discusses the predictive capability of Dynamic Mode Decomposition (DMD) in the context of orbital mechanics. The focus is specifically on the Hankel variant of DMD which uses a stacked set of time-delayed observations for system identification and subsequent prediction. A theory on the minimum number of time delays required for accurate reconstruction of periodic trajectories of nonlinear systems is presented and corroborated using experimental analysis. In addition, the window size for training and prediction regions, respectively, is presented. The need for a meticulous approach while using DMD is emphasized by drawing comparisons between its performance on two candidate satellites, the ISS and MOLNIYA-3-50.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13784"
    },
    {
        "doc_id": 351,
        "title": "Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks",
        "authors": [
            "Daniel P\u00e9rez Herrera",
            "Zheng Chen",
            "Erik G. Larsson"
        ],
        "subjects": [
            "Information Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely adopted algorithm for decentralized training of machine learning models across networked agents. A crucial part of D-SGD is the consensus-based model averaging, which heavily relies on information exchange and fusion among the nodes. Specifically, for consensus averaging over wireless networks, communication coordination is necessary to determine when and how a node can access the channel and transmit (or receive) information to (or from) its neighbors. In this work, we propose $\\texttt{BASS}$, a broadcast-based subgraph sampling method designed to accelerate the convergence of D-SGD while considering the actual communication cost per iteration. $\\texttt{BASS}$ creates a set of mixing matrix candidates that represent sparser subgraphs of the base topology. In each consensus iteration, one mixing matrix is sampled, leading to a specific scheduling decision that activates multiple collision-free subsets of nodes. The sampling occurs in a probabilistic manner, and the elements of the mixing matrices, along with their sampling probabilities, are jointly optimized. Simulation results demonstrate that $\\texttt{BASS}$ enables faster convergence with fewer transmission slots compared to existing link-based scheduling methods. In conclusion, the inherent broadcasting nature of wireless channels offers intrinsic advantages in accelerating the convergence of decentralized optimization and learning.",
        "comments": "11 pages, 5 figures, submitted for possible journal publication. arXiv admin note: text overlap with arXiv:2310.16106",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13779"
    },
    {
        "doc_id": 352,
        "title": "Multiview Graph Learning with Consensus Graph",
        "authors": [
            "Abdullah Karaaslanli",
            "Selin Aviyente"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning"
        ],
        "abstract": "Graph topology inference, i.e., learning graphs from a given set of nodal observations, is a significant task in many application domains. Existing approaches are mostly limited to learning a single graph assuming that the observed data is homogeneous. This is problematic because many modern datasets are heterogeneous or mixed and involve multiple related graphs, i.e., multiview graphs. Recent work proposing to learn multiview graphs ensures the similarity of learned view graphs through pairwise regularization, where each pair of views is encouraged to have similar structures. However, this approach cannot infer the shared structure across views. In this work, we propose an alternative method based on consensus regularization, where views are ensured to be similar through a learned consensus graph representing the common structure of the views. In particular, we propose an optimization problem, where graph data is assumed to be smooth over the multiview graph and the topology of the individual views and that of the consensus graph are learned, simultaneously. Our optimization problem is designed to be general in the sense that different regularization functions can be used depending on what the shared structure across views is. Moreover, we propose two regularization functions that extend fused and group graphical lasso to consensus based regularization. Proposed multiview graph learning is evaluated on simulated data and shown to have better performance than existing methods. It is also employed to infer the functional brain connectivity networks of multiple subjects from their electroencephalogram (EEG) recordings. The proposed method reveals the structure shared by subjects as well as the characteristics unique to each subject.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13769"
    },
    {
        "doc_id": 353,
        "title": "Bayesian adaptive learning to latent variables via Variational Bayes and Maximum a Posteriori",
        "authors": [
            "Hu Hu",
            "Sabato Marco Siniscalchi",
            "Chin-Hui Lee"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Sound"
        ],
        "abstract": "In this work, we aim to establish a Bayesian adaptive learning framework by focusing on estimating latent variables in deep neural network (DNN) models. Latent variables indeed encode both transferable distributional information and structural relationships. Thus the distributions of the source latent variables (prior) can be combined with the knowledge learned from the target data (likelihood) to yield the distributions of the target latent variables (posterior) with the goal of addressing acoustic mismatches between training and testing conditions. The prior knowledge transfer is accomplished through Variational Bayes (VB). In addition, we also investigate Maximum a Posteriori (MAP) based Bayesian adaptation. Experimental results on device adaptation in acoustic scene classification show that our proposed approaches can obtain good improvements on target devices, and consistently outperforms other cut-edging algorithms.",
        "comments": "ASRU2023 Bayesian Symposium. arXiv admin note: text overlap with arXiv:2110.08598",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13766"
    },
    {
        "doc_id": 354,
        "title": "Fast System Level Synthesis: Robust Model Predictive Control using Riccati Recursions",
        "authors": [
            "Antoine P. Leeman",
            "Johannes K\u00f6hler",
            "Florian Messerer",
            "Amon Lahr",
            "Moritz Diehl",
            "Melanie N. Zeilinger"
        ],
        "subjects": [
            "Optimization and Control",
            "Systems and Control"
        ],
        "abstract": "System Level Synthesis (SLS) enables improved robust MPC formulations by allowing for joint optimization of the nominal trajectory and controller. This paper introduces a tailored algorithm for solving the corresponding disturbance feedback optimization problem. The proposed algorithm builds on a recently proposed joint optimization scheme and iterates between optimizing the controller and the nominal trajectory while converging q-linearly to an optimal solution. We show that the controller optimization can be solved through Riccati recursions leading to a horizon-length, state, and input scalability of $\\mathcal{O}(N^2 ( n_x^3 + n_u ^3 ) )$ for each iterate. On a numerical example, the proposed algorithm exhibits computational speedups of order $10$ to $10^3$ compared to general-purpose commercial solvers.",
        "comments": "Submitted to IFAC Conference on Nonlinear Model Predictive Control (NMPC) 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13762"
    },
    {
        "doc_id": 355,
        "title": "Experimental validation of ultra-shortened 3D finite element electromagnetic modeling of three-core armored cables at power frequency",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Due to recent advances, the numerical analysis of submarine three-core armored cables can nowadays be developed through the finite element method (FEM) in a small slice of the cable. This strongly reduces the computational burden and simulation time. However, the performance of this ultra-shortened 3D-FEM model is still to be fully assessed with experimental measurements. This paper focuses on this validation for an extensive variety of situations through the experimental measurements available in the specialized literature for up to 10 actual cables. In particular, it deals not only with relevant calculations at power frequency, like the series resistance and inductive reactance or the induced sheath current, but also with other aspects never analyzed before through 3D-FEM simulations, such as the zero sequence impedance, the magnetic field distribution around the power cable, as well as side effects due to the nonlinear properties of the armor wires. All this considering different armoring and sheath bonding configurations. Results show a very good agreement between measured and computed values, presenting the ultra-shortened 3D-FEM model as a suitable tool for the analysis and design of three-core armored cables, and opening the possibility to reduce the need of extensive experimental tests in the design stage of new cables.",
        "comments": "Journal ref:        Electric Power Systems Research, vol. 203, 107665, feb. 2022",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13761"
    },
    {
        "doc_id": 356,
        "title": "Intermittency versus Path Loss in RIS-aided THz Communication: A Data Significance Approach",
        "authors": [
            "Yasemin Karacora",
            "Adam Umra",
            "Aydin Sezgin"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "The transition to Terahertz (THz) frequencies, providing an ultra-wide bandwidth, is a key driver for future wireless communication networks. However, the specific properties of the THz channel, such as severe path loss and vulnerability to blockage, pose a significant challenge in balancing data rate and reliability. This work considers reconfigurable intelligent surface (RIS)-aided THz communication, where the effective exploitation of a strong, but intermittent line-of-sight (LOS) path versus a reliable, yet weaker RIS-path is studied. We introduce a mixed-criticality superposition coding scheme that addresses this tradeoff from a data significance perspective. The results show that the proposed scheme enables reliable transmission for a portion of high-criticality data without significantly impacting the overall achievable sum rate and queuing delay. Additionally, we gain insights into how the LOS blockage probability and the channel gain of the RIS-link influence the rate performance of our scheme.",
        "comments": "6 pages, 5 figures (accepted for publication at IEEE ICC 2024)",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13743"
    },
    {
        "doc_id": 357,
        "title": "HetDAPAC: Distributed Attribute-Based Private Access Control with Heterogeneous Attributes",
        "authors": [
            "Shreya Meel",
            "Sennur Ulukus"
        ],
        "subjects": [
            "Information Theory",
            "Cryptography and Security",
            "Networking and Internet Architecture",
            "Signal Processing"
        ],
        "abstract": "Verifying user attributes to provide fine-grained access control to databases is fundamental to an attribute-based authentication system. In such systems, either a single (central) authority verifies all attributes, or multiple independent authorities verify individual attributes distributedly to allow a user to access records stored on the servers. While a \\emph{central} setup is more communication cost efficient, it causes privacy breach of \\emph{all} user attributes to a central authority. Recently, Jafarpisheh et al. studied an information theoretic formulation of the \\emph{distributed} multi-authority setup with $N$ non-colluding authorities, $N$ attributes and $K$ possible values for each attribute, called an $(N,K)$ distributed attribute-based private access control (DAPAC) system, where each server learns only one attribute value that it verifies, and remains oblivious to the remaining $N-1$ attributes. We show that off-loading a subset of attributes to a central server for verification improves the achievable rate from $\\frac{1}{2K}$ in Jafarpisheh et al. to $\\frac{1}{K+1}$ in this paper, thus \\emph{almost doubling the rate} for relatively large $K$, while sacrificing the privacy of a few possibly non-sensitive attributes.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13653"
    },
    {
        "doc_id": 358,
        "title": "Tyche: Stochastic In-Context Learning for Medical Image Segmentation",
        "authors": [
            "Marianne Rakic",
            "Hallee E. Wong",
            "Jose Javier Gonzalez Ortiz",
            "Beth Cimini",
            "John Guttag",
            "Adrian V. Dalca"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Existing learning-based solutions to medical image segmentation have two important shortcomings. First, for most new segmentation task, a new model has to be trained or fine-tuned. This requires extensive resources and machine learning expertise, and is therefore often infeasible for medical researchers and clinicians. Second, most existing segmentation methods produce a single deterministic segmentation mask for a given image. In practice however, there is often considerable uncertainty about what constitutes the correct segmentation, and different expert annotators will often segment the same image differently. We tackle both of these problems with Tyche, a model that uses a context set to generate stochastic predictions for previously unseen tasks without the need to retrain. Tyche differs from other in-context segmentation methods in two important ways. (1) We introduce a novel convolution block architecture that enables interactions among predictions. (2) We introduce in-context test-time augmentation, a new mechanism to provide prediction stochasticity. When combined with appropriate model design and loss functions, Tyche can predict a set of plausible diverse segmentation candidates for new or unseen medical images and segmentation tasks without the need to retrain.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13650"
    },
    {
        "doc_id": 359,
        "title": "Cooperative Periodic Coverage With Collision Avoidance",
        "authors": [
            "Jos\u00e9 Manuel Palacios-Gas\u00f3s",
            "Eduardo Montijano",
            "Carlos Sag\u00fc\u00e9s",
            "Sergio Llorente"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "In this paper we propose a periodic solution to the problem of persistently covering a finite set of interest points with a group of autonomous mobile agents. These agents visit periodically the points and spend some time carrying out the coverage task, which we call coverage time. Since this periodic persistent coverage problem is NP-hard, we split it into three subproblems to counteract its complexity. In the first place, we plan individual closed paths for the agents to cover all the points. Second, we formulate a quadratically constrained linear program to find the optimal coverage times and actions that satisfy the coverage objective. Finally, we join together the individual plans of the agents in a periodic team plan by obtaining a schedule that guarantees collision avoidance. To this end, we solve a mixed integer linear program that minimizes the time in which two or more agents move at the same time. Eventually, we apply the proposed solution to an induction hob with mobile inductors for a domestic heating application and show its performance with experiments on a real prototype.",
        "comments": "This is the accepted version an already published manuscript. See journal reference for details",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13622"
    },
    {
        "doc_id": 360,
        "title": "FLLIC: Functionally Lossless Image Compression",
        "authors": [
            "Xi Zhang",
            "Xiaolin Wu"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Recently, DNN models for lossless image coding have surpassed their traditional counterparts in compression performance, reducing the bit rate by about ten percent for natural color images. But even with these advances, mathematically lossless image compression (MLLIC) ratios for natural images still fall short of the bandwidth and cost-effectiveness requirements of most practical imaging and vision systems at present and beyond. To break the bottleneck of MLLIC in compression performance, we question the necessity of MLLIC, as almost all digital sensors inherently introduce acquisition noises, making mathematically lossless compression counterproductive. Therefore, in contrast to MLLIC, we propose a new paradigm of joint denoising and compression called functionally lossless image compression (FLLIC), which performs lossless compression of optimally denoised images (the optimality may be task-specific). Although not literally lossless with respect to the noisy input, FLLIC aims to achieve the best possible reconstruction of the latent noise-free original image. Extensive experiments show that FLLIC achieves state-of-the-art performance in joint denoising and compression of noisy images and does so at a lower computational cost.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13616"
    },
    {
        "doc_id": 361,
        "title": "Intermittent Connectivity Maintenance With Heterogeneous Robots",
        "authors": [
            "Rosario Aragues",
            "Dimos V. Dimarogonas",
            "Pablo Guallar",
            "Carlos Sagues"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "We consider a scenario of cooperative task servicing, with a team of heterogeneous robots with different maximum speeds and communication radii, in charge of keeping the network intermittently connected. We abstract the task locations into a $1D$ cycle graph that is traversed by the communicating robots, and we discuss intermittent communication strategies so that each task location is periodically visited, with a worst--case revisiting time. Robots move forward and backward along the cycle graph, exchanging data with their previous and next neighbors when they meet, and updating their region boundaries. Asymptotically, each robot is in charge of a region of the cycle graph, depending on its capabilities. The method is distributed, and robots only exchange data when they meet.",
        "comments": "Journal ref:        in IEEE Transactions on Robotics, vol. 37, no. 1, pp. 225-245, Feb. 2021",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13612"
    },
    {
        "doc_id": 362,
        "title": "Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models",
        "authors": [
            "Rhiannon Mogridge",
            "George Close",
            "Robert Sutherland",
            "Thomas Hain",
            "Jon Barker",
            "Stefan Goetze",
            "Anton Ragni"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Audio and Speech Processing"
        ],
        "abstract": "Neural networks have been successfully used for non-intrusive speech intelligibility prediction. Recently, the use of feature representations sourced from intermediate layers of pre-trained self-supervised and weakly-supervised models has been found to be particularly useful for this task. This work combines the use of Whisper ASR decoder layer representations as neural network input features with an exemplar-based, psychologically motivated model of human memory to predict human intelligibility ratings for hearing-aid users. Substantial performance improvement over an established intrusive HASPI baseline system is found, including on enhancement systems and listeners unseen in the training data, with a root mean squared error of 25.3 compared with the baseline of 28.7.",
        "comments": "Accepted paper. IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), Seoul, Korea, April 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13611"
    },
    {
        "doc_id": 363,
        "title": "Scale-free vision-based aerial control of a ground formation with hybrid topology",
        "authors": [
            "Miguel Aranda",
            "Youcef Mezouar",
            "Gonzalo L\u00f3pez-Nicol\u00e1s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "We present a novel vision-based control method to make a group of ground mobile robots achieve a specified formation shape with unspecified size. Our approach uses multiple aerial control units equipped with downward-facing cameras, each observing a partial subset of the multirobot team. The units compute the control commands from the ground robots' image projections, using neither calibration nor scene scale information, and transmit them to the robots. The control strategy relies on the calculation of image similarity transformations, and we show it to be asymptotically stable if the overlaps between the subsets of controlled robots satisfy certain conditions. The presence of the supervisory units, which coordinate their motions to guarantee a correct control performance, gives rise to a hybrid system topology. All in all, the proposed system provides relevant practical advantages in simplicity and flexibility. Within the problem of controlling a team shape, our contribution lies in addressing several simultaneous challenges: the controller needs only partial information of the robotic group, does not use distance measurements or global reference frames, is designed for unicycle agents, and can accommodate topology changes. We present illustrative simulation results.",
        "comments": "This is the accepted version an already published manuscript. See journal reference for details",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13610"
    },
    {
        "doc_id": 364,
        "title": "Run-to-Run Control With Bayesian Optimization for Soft Landing of Short-Stroke Reluctance Actuators",
        "authors": [
            "Eduardo Moya-Lasheras",
            "Carlos Sagues"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "There is great interest in minimizing the impact forces of reluctance actuators during commutations, in order to reduce contact bouncing, acoustic noise and mechanical wear. In this regard, a run-to-run control algorithm is proposed to decrease the contact velocity, by exploiting the repetitive operations of these devices. The complete control is presented, with special focus on the optimization method and the input definition. The search method is based on Bayesian optimization, and several additions are introduced for its application in run-to-run control, e.g. the removal of stored points and the definition of a new acquisition function. Additionally, methods for the input parametrization and dimension reduction are presented. For analysis, Monte Carlo simulations are performed using a dynamic model of a commercial solenoid valve, comparing the proposed search method with two alternatives. Furthermore, the control strategy is validated through experimental testing, using several devices from the same ensemble of solenoid valves.",
        "comments": "This is the accepted version an already published manuscript. See journal reference for details",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13606"
    },
    {
        "doc_id": 365,
        "title": "Perception-latency aware distributed target tracking",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "This work is devoted to the problem of distributed target tracking when a team of robots detect the target through a variable perception-latency mechanism. A reference for the robots to track is constructed in terms of a desired formation around the estimation of the target position. However, it is noted that due to the perception-latency, classical estimation techniques have smoothness issues which prevent asymptotic stability for the formation control. We propose a near-optimal smooth-output estimator which circumvents this issue. Moreover, local estimations are fused using novel dynamic consensus techniques. The advantages of the proposal as well as a comparison with a non-smooth optimal alternative are discussed through simulation examples.",
        "comments": "This is the accepted version an already published manuscript. See journal reference for details",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13602"
    },
    {
        "doc_id": 366,
        "title": "PLATE: A perception-latency aware estimator,",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "subjects": [
            "Systems and Control",
            "Computer Vision and Pattern Recognition",
            "Optimization and Control"
        ],
        "abstract": "Target tracking is a popular problem with many potential applications. There has been a lot of effort on improving the quality of the detection of targets using cameras through different techniques. In general, with higher computational effort applied, i.e., a longer perception-latency, a better detection accuracy is obtained. However, it is not always useful to apply the longest perception-latency allowed, particularly when the environment doesn't require to and when the computational resources are shared between other tasks. In this work, we propose a new Perception-LATency aware Estimator (PLATE), which uses different perception configurations in different moments of time in order to optimize a certain performance measure. This measure takes into account a perception-latency and accuracy trade-off aiming for a good compromise between quality and resource usage. Compared to other heuristic frame-skipping techniques, PLATE comes with a formal complexity and optimality analysis. The advantages of PLATE are verified by several experiments including an evaluation over a standard benchmark with real data and using state of the art deep learning object detection methods for the perception stage.",
        "comments": "This is the accepted version an already published manuscript. See journal reference for details",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13596"
    },
    {
        "doc_id": 367,
        "title": "Deep Learning Based Adaptive Joint mmWave Beam Alignment",
        "authors": [
            "Daniel Tandler",
            "Marc Gauger",
            "Ahmet Serdar Tan",
            "Sebastian D\u00f6rner",
            "Stephan ten Brink"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "The challenging propagation environment, combined with the hardware limitations of mmWave systems, gives rise to the need for accurate initial access beam alignment strategies with low latency and high achievable beamforming gain. Much of the recent work in this area either focuses on one-sided beam alignment, or, joint beam alignment methods where both sides of the link perform a sequence of fixed channel probing steps. Codebook-based non-adaptive beam alignment schemes have the potential to allow multiple user equipment (UE) to perform initial access beam alignment in parallel whereas adaptive schemes are favourable in achievable beamforming gain. This work introduces a novel deep learning based joint beam alignment scheme that aims to combine the benefits of adaptive, codebook-free beam alignment at the UE side with the advantages of a codebook-sweep based scheme at the base station. The proposed end-to-end trainable scheme is compatible with current cellular standard signaling and can be readily integrated into the standard without requiring significant changes to it. Extensive simulations demonstrate superior performance of the proposed approach over purely codebook-based ones.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13587"
    },
    {
        "doc_id": 368,
        "title": "Latency vs precision: Stability preserving perception scheduling",
        "authors": [
            "Rodrigo Aldana-L\u00f3pez",
            "Rosario Arag\u00fc\u00e9s",
            "Carlos Sag\u00fc\u00e9s"
        ],
        "subjects": [
            "Systems and Control",
            "Robotics",
            "Optimization and Control"
        ],
        "abstract": "In robotic systems, perception latency is a term that refers to the computing time measured from the data acquisition to the moment in which perception output is ready to be used to compute control commands. There is a compromise between perception latency, precision for the overall robotic system, and computational resource usage referred to here as the latency-precision trade-off. In this work, we analyze a robot model given by a linear system, a zero-order hold controller, and measurements taken by several perception mode possibilities with different noise levels. We show that the analysis of this system is reduced to studying an equivalent switching system. Our goal is to schedule perception modes such that stability is attained while optimizing a cost function that models the latency-precision trade-off. Our solution framework comprises three main tools: the construction of perception scheduling policy candidates, admissibility verification for policy candidates, and optimal strategies based on admissible policies.",
        "comments": "This is the accepted version of an already published manuscript. See journal reference",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13585"
    },
    {
        "doc_id": 369,
        "title": "RIS Empowered Near-Field Covert Communications",
        "authors": [
            "Jun Liu",
            "Gang Yang",
            "Yuanwei Liu",
            "Xiangyun Zhou"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "This paper studies an extremely large-scale reconfigurable intelligent surface (XL-RIS) empowered covert communication system in the near-field region. Alice covertly transmits messages to Bob with the assistance of the XL-RIS, while evading detection by Willie. To enhance the covert communication performance, we maximize the achievable covert rate by jointly optimizing the hybrid analog and digital beamformers at Alice, as well as the reflection coefficient matrix at the XL-RIS. An alternating optimization algorithm is proposed to solve the joint beamforming design problem. For the hybrid beamformer design, a semi-closed-form solution for fully digital beamformer is first obtained by a weighted minimum mean-square error based algorithm, then the baseband digital and analog beamformers at Alice are designed by approximating the fully digital beamformer via manifold optimization. For the XL-RIS's reflection coefficient matrix design, a low-complexity alternating direction method of multipliers based algorithm is proposed to address the challenge of large-scale variables and unit-modulus constraints. Numerical results unveil that i) the near-field communications can achieve a higher covert rate than the far-field covert communications in general, and still realize covert transmission even if Willie is located at the same direction as Bob and closer to the XL-RIS; ii) the proposed algorithm can enhance the covert rate significantly compared to the benchmark schemes; iii) the proposed algorithm leads to a beam diffraction pattern that can bypass Willie and achieve high-rate covert transmission to Bob.",
        "comments": "15 pages, 8 figures, submitted to IEEE journal",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13564"
    },
    {
        "doc_id": 370,
        "title": "Pricing of Short Circuit Current in High IBR-Penetrated System",
        "authors": [
            "Zhongda Chu",
            "Jingyi Wu",
            "Fei Teng"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "With the growing penetration of Inverter-Based Resources (IBRs) in power systems, stability service markets have emerged to incentivize technologies that ensure power system stability and reliability. Among the various challenges faced in power system operation and stability, a prominent issue raised from the increasing integration of large-scale IBRs is the significant reduction of the Short-Circuit Current (SCC) level in the system, which poses a considerable threat to system voltage stability and protection. Thus, a proper market mechanism to incentivize the provision of SCC as a stability service is desired. However, the pricing of this service within the future stability market has not yet been fully developed, due to the nonconvex nature of SCC constraints and the locational property of SCC. To address these problems, this work aims to explore, for the first time, a pricing model for SCC service by incorporating a linearized SCC constraint into the Unit Commitment (UC) problem, to achieve the desired SCC level and extract the shadow price for SCC through different pricing methods.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13561"
    },
    {
        "doc_id": 371,
        "title": "Extension of the Injected-Absorbed-Current Method applied to DC-DC Converters with Input Filter, Output Post-filter and Feedforward Compensations",
        "authors": [
            "Diego Ochoa",
            "Antonio Lazaro",
            "Pablo Zumel",
            "Cristina Fernandez",
            "Marina Sanz",
            "Jorge Rodriguez",
            "Andres Barrado"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "In railway applications, it is common to use an LC filter connected between the catenary and the input port of the main converter of the auxiliary and traction systems. In addition, in the auxiliary systems, there is a converter operating as a battery charger, which requires a very low ripple in the output current and output voltage, so a postfilter may be placed at the output port of the converter. This article proposes a step-by-step methodology to extend the injected-absorbed-current (IAC) method in order to obtain transfer functions that consider the effects of the input filter, output postfilter, and some feedforward compensations. The proposed methodology allows reusing the characteristic coefficients of the DC-DC converter model derived from the existing IAC method. One of the advantages of the proposed methodology is that the transfer functions obtained in this article are valid for cases where both, one or none of the filters, are implemented. Finally, for the experimental validation of the proposed methodology, the phase-shifted full-bridge converter was selected as a convenient example. Furthermore, the experimental measurements have been performed on two prototypes.",
        "comments": "This work was supported in part by the European Regional Development Fund (FEDER), in part by the Ministry of Science, Innovation and Universities, and in part by the State Research Agency through the Research Project: Modeling and Control Strategies for the Stabilization of the Interconnection of Power Electronic Converters CONEXPOT-2 under Grant DPI2017-84572-C2-2-R (AEI/FEDER, UE)",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13556"
    },
    {
        "doc_id": 372,
        "title": "On the Constrained CAV Platoon Control Problem",
        "authors": [
            "MirSaleh Bahavarnia",
            "Junyi Ji",
            "Ahmad F. Taha",
            "and Daniel B. Work"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "The main objective of the connected and automated vehicle (CAV) platoon control problem is to regulate CAVs' position while ensuring stability and accounting for vehicle dynamics. Although this problem has been studied in the literature, existing research has some limitations. This paper presents two new theoretical results that address these limitations: (i) the synthesis of unrealistic high-gain control parameters due to the lack of a systematic way to incorporate the lower and upper bounds on the control parameters, and (ii) the performance sensitivity to the communication delay due to inaccurate Taylor series approximation. To be more precise, taking advantage of the wellknown Pade approximation, this paper proposes a constrained CAV platoon controller synthesis that (i) systematically incorporates the lower and upper bounds on the control parameters, and (ii) significantly improves the performance sensitivity to the communication delay. The effectiveness of the presented results is verified through conducting extensive numerical simulations. The proposed controller effectively attenuates the stop-and-go disturbance -- a single cycle of deceleration followed by acceleration -- amplification throughout the mixed platoon (consisting of CAVs and human-driven vehicles). Modern transportation systems will benefit from the proposed CAV controls in terms of effective disturbance attenuation as it will potentially reduce collisions.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13552"
    },
    {
        "doc_id": 373,
        "title": "A Phoneme-Scale Assessment of Multichannel Speech Enhancement Algorithms",
        "authors": [
            "Nasser-Eddine Monir",
            "Paul Magron",
            "Romain Serizel"
        ],
        "subjects": [
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "In the intricate acoustic landscapes where speech intelligibility is challenged by noise and reverberation, multichannel speech enhancement emerges as a promising solution for individuals with hearing loss. Such algorithms are commonly evaluated at the utterance level. However, this approach overlooks the granular acoustic nuances revealed by phoneme-specific analysis, potentially obscuring key insights into their performance. This paper presents an in-depth phoneme-scale evaluation of 3 state-of-the-art multichannel speech enhancement algorithms. These algorithms -- FasNet, MVDR, and Tango -- are extensively evaluated across different noise conditions and spatial setups, employing realistic acoustic simulations with measured room impulse responses, and leveraging diversity offered by multiple microphones in a binaural hearing setup. The study emphasizes the fine-grained phoneme-level analysis, revealing that while some phonemes like plosives are heavily impacted by environmental acoustics and challenging to deal with by the algorithms, others like nasals and sibilants see substantial improvements after enhancement. These investigations demonstrate important improvements in phoneme clarity in noisy conditions, with insights that could drive the development of more personalized and phoneme-aware hearing aid technologies.",
        "comments": "This is the preprint of the paper that we submitted to the Trends in Hearing Journal",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13548"
    },
    {
        "doc_id": 374,
        "title": "Analysis, design, and implementation of the AFZ converter applied to photovoltaic systems",
        "authors": [
            "David Lopez del Moral",
            "Andres Barrado",
            "Marina Sanz",
            "Antonio Lazaro",
            "Pablo Zumel"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Grid-tied photovoltaic (PV) installations with Distributed Maximum Power Point Tracking (DMPPT) architectures include a DC-DC Module Integrated Converter (MIC) for managing each PV panel, isolating it from the others, reducing the mismatching effect and maximizing the harvested power. In this paper, the Autotransformer Forward converter with type-Zeta resonant reset (AFZ) is proposed as a DMPPT architecture MIC candidate. The main characteristics of the AFZ converter are the high versatility due to its voltage step-up and step-down capability; the use of an optimized autotransformer with only two windings, reducing the complexity and power losses of this component; the good dynamic performances, like the Forward converter ones; the low number of components and the simplicity and high feasibility associated to the use of just one active switch. Besides, soft switching transitions are achieved thanks to the autotransformer type-Zeta resonant reset. The steady-state theoretical analysis, considering the effect of the autotransformer leakage inductance, is presented. The converter is also studied in the frequency domain, obtaining the small-signal transfer functions. A design procedure based on the requirements of a 100 kW grid-tied photovoltaic installation is described, yielding in a 225 W prototype with efficiencies up to 95.6 %. Experimental results validate the theoretical analysis.",
        "comments": "This work was supported in part by the Spanish Ministry of Economy and Competitiveness and FEDER funds through the research project: Modeling and Control Strategies for the Stabilization of the Interconnection of Power Electronic Converters CONEXPOT under Grant DPI2017-84572-C2-2-R. copyright: 2020 IEEE",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13546"
    },
    {
        "doc_id": 375,
        "title": "SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation",
        "authors": [
            "Dong Zhang",
            "Xin Zhang",
            "Jun Zhan",
            "Shimin Li",
            "Yaqian Zhou",
            "Xipeng Qiu"
        ],
        "subjects": [
            "Computation and Language",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate that SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable proficiency in capturing and modeling speech's semantic and perceptual dimensions. Code and models are available at https://github.com/0nutation/SpeechGPT.",
        "comments": "work in progress",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13527"
    },
    {
        "doc_id": 376,
        "title": "Tissue Cross-Section and Pen Marking Segmentation in Whole Slide Images",
        "authors": [
            "Ruben T. Lucassen",
            "Willeke A. M. Blokx",
            "Mitko Veta"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "Tissue segmentation is a routine preprocessing step to reduce the computational cost of whole slide image (WSI) analysis by excluding background regions. Traditional image processing techniques are commonly used for tissue segmentation, but often require manual adjustments to parameter values for atypical cases, fail to exclude all slide and scanning artifacts from the background, and are unable to segment adipose tissue. Pen marking artifacts in particular can be a potential source of bias for subsequent analyses if not removed. In addition, several applications require the separation of individual cross-sections, which can be challenging due to tissue fragmentation and adjacent positioning. To address these problems, we develop a convolutional neural network for tissue and pen marking segmentation using a dataset of 200 H&E stained WSIs. For separating tissue cross-sections, we propose a novel post-processing method based on clustering predicted centroid locations of the cross-sections in a 2D histogram. On an independent test set, the model achieved a mean Dice score of 0.981$\\pm$0.033 for tissue segmentation and a mean Dice score of 0.912$\\pm$0.090 for pen marking segmentation. The mean absolute difference between the number of annotated and separated cross-sections was 0.075$\\pm$0.350. Our results demonstrate that the proposed model can accurately segment H&E stained tissue cross-sections and pen markings in WSIs while being robust to many common slide and scanning artifacts. The model with trained model parameters and post-processing method are made publicly available as a Python package called SlideSegmenter.",
        "comments": "6 pages, 3 figures",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13511"
    },
    {
        "doc_id": 377,
        "title": "Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting",
        "authors": [
            "Hounsu Kim",
            "Soonbeom Choi",
            "Juhan Nam"
        ],
        "subjects": [
            "Sound",
            "Artificial Intelligence",
            "Machine Learning",
            "Audio and Speech Processing",
            "Signal Processing"
        ],
        "abstract": "Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression. Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input. In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll. We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency. To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer. Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work.",
        "comments": "Accepted to ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13498"
    },
    {
        "doc_id": 378,
        "title": "Towards an Autonomous Compost Turner: Current State of Research",
        "authors": [
            "Max Cichocki",
            "Eva Reitbauer",
            "Fabian Theurl",
            "Christoph Schmied"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "This preprint presents the current status of research into the development and application of an autonomous, self-driving compost turner. The aim is to overcome challenges in the composting industry, such as adverse working conditions, by automating the composting process. The preprint provides a comprehensive overview of the overall concept of the self-driving compost turner, including the hardware architecture with sensors, navigation module and control module. In addition, the methodical development of the architecture of concepts, models and their subsequent software integration in ROS using model-based systems engineering is described. The validation and verification of the overall system is carried out in an industrial environment using three scenarios. The capabilities of the compost turner are demonstrated by autonomously following predefined trajectories in the composting plant and performing the required composting tasks. The results show that the autonomous compost turner is capable of performing the required activities. In addition, the compost turner has intelligent processing capabilities for compost data as well as its transmission, visualization and storage in a cloud server. It is important to note that this work is a preprint that represents the current state of research. The authors aim to publish the full paper in a peer-reviewed journal in the near future.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13493"
    },
    {
        "doc_id": 379,
        "title": "Segmenting Cardiac Muscle Z-disks with Deep Neural Networks",
        "authors": [
            "Mihaela Croitor Ibrahim",
            "Nishant Ravikumar",
            "Alistair Curd",
            "Joanna Leng",
            "Oliver Umney",
            "Michelle Peckham"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Z-disks are complex structures that delineate repeating sarcomeres in striated muscle. They play significant roles in cardiomyocytes such as providing mechanical stability for the contracting sarcomere, cell signalling and autophagy. Changes in Z-disk architecture have been associated with impaired cardiac function. Hence, there is a strong need to create tools to segment Z-disks from microscopy images, that overcome traditional limitations such as variability in image brightness and staining technique. In this study, we apply deep learning based segmentation models to extract Z-disks in images of striated muscle tissue. We leverage a novel Airyscan confocal dataset, which comprises high resolution images of Z-disks of healthy heart tissue, stained with Affimers for specific Z-disk proteins. We employed an interactive labelling tool, Ilastik to obtain ground truth segmentation masks and use the resulting data set to train and evaluate the performance of several state-of-the-art segmentation networks. On the test set, UNet++ achieves best segmentation performance for Z-disks in cardiomyocytes, with an average Dice score of 0.91 and outperforms other established segmentation methods including UNet, FPN, DeepLabv3+ and pix2pix. However, pix2pix demonstrates improved generalisation, when tested on an additional dataset of cardiomyocytes with a titin mutation. This is the first study to demonstrate that automated machine learning-based segmentation approaches may be used effectively to segment Z-disks in confocal microscopy images. Automated segmentation approaches and predicted segmentation masks could be used to derive morphological features of Z-disks (e.g. width and orientation), and subsequently, to quantify disease-related changes to cardiac microstructure.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13472"
    },
    {
        "doc_id": 380,
        "title": "Analysis and implementation of the Buck-Boost Modified Series Forward converter applied to photovoltaic systems",
        "authors": [
            "David Lopez del Moral",
            "Andres Barrado",
            "Marina Sanz",
            "Antonio Lazaro",
            "Pablo Zumel"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The mismatching phenomenon is one of the main issues in photovoltaic (PV) applications. It could reduce the generated power of a string when a PV panel has different performances from the other PV panels connected to the same string. Distributed Maximum Power Point Tracking (DMPPT) architectures are one of the most promising solutions to overcome the drawbacks associated with mismatching phenomena in PV applications. In this kind of architectures, a DC-DC module integrated converter (MIC) manages each PV panel, isolating it from the rest of the PV panels, for harvesting the maximum available power from the Sun. Due to the high number of DCDC converters used in a grid-tied PV installation, the most desired MIC requirements are high efficiency, low cost and the capability of voltage step-up and step-down. This paper proposes the Buck-Boost Modified Forward (BBMSF) converter as a good candidate to be applied in DMPPT architectures. A complete analysis of the BBMSF converter is carried out, including the steady-state analysis as well as the small signal analysis in continuous conduction mode. The main advantages of the BBMSF converter are its step-up and step-down voltage transfer function; a higher simplicity, since it only includes a single controlled switch; the soft switching characteristics in all the diodes and MOSFET, reaching in some cases ZVS and ZCS, and yielding high efficiencies; the use of an autotransformer, with better performances than a typical Forward transformer; and the good dynamic performance, like the Forward converter ones. The theoretical analyses are validated through the experimental results in a 225 W BBMSF prototype designed and built under the requirements of a 100 kW grid-tied PV installation, achieving an efficiency up to 93.6%.",
        "comments": "This work has been supported by the Ministry of Economy and Competitiveness and FEDER funds through the research project \"Storage and Energy Management for Hybrid Electric Vehicles based on Fuel Cell, Battery and Supercapacitors\" - ELECTRICAR-AG- (DPI2014-53685-C2-1-R)",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13464"
    },
    {
        "doc_id": 381,
        "title": "SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering",
        "authors": [
            "Chyi-Jiunn Lin",
            "Guan-Ting Lin",
            "Yung-Sung Chuang",
            "Wei-Lun Wu",
            "Shang-Wen Li",
            "Abdelrahman Mohamed",
            "Hung-yi Lee",
            "Lin-shan Lee"
        ],
        "subjects": [
            "Computation and Language",
            "Information Retrieval",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage. SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems. However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered. This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem. SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR). No manually transcribed speech data is needed. Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robust to speech recognition errors.",
        "comments": "Accepted at ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13463"
    },
    {
        "doc_id": 382,
        "title": "Experimental validation of ultra-shortened 3D finite element models for frequency-domain analyses of three-core armored cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Recently, large offshore wind power plants have been installed far from the shore, using long HVAC three-core armored cables to export power. Its high capacitance may contribute to the appearance of unwanted phenomena, such as overvoltages or resonances at low frequencies. To adequately assess these problems, detailed and reliable cable models are required to develop time-domain/frequency-domain analyses on this type of cables. This paper presents, for the first time in the literature, an assessment on the performance of 3D finite element method-based (3D-FEM) models for developing frequency-domain analyses on three-core armored cables, confronting simulation results with experimental measurements found in the literature for three real cables. To this aim, a simplified ultra-shortened 3D-FEM model is proposed to reduce the simulation time during frequency sweeps, through which relevant aspects never analyzed before with frequency-domain 3D-FEM simulations are addressed, such as total losses, induced sheath current, magnetic field around the power cable, positive and zero sequence harmonic impedances, as well as resonant frequencies. Also, a time-domain example derived from the frequency-domain analysis is provided. Remarkable results are obtained when comparing computed values and measurements, presenting the simplified ultra-shortened 3DFEM model as a valuable tool for the frequency-domain analysis of these cables.",
        "comments": "Journal ref:        IEEE Trans. on Power Delivery, Vol. 37, no. 6, dec. 2022",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13451"
    },
    {
        "doc_id": 383,
        "title": "Finite-Precision Arithmetic Transceiver for Massive MIMO Systems",
        "authors": [
            "Yiming Fang",
            "Li Chen",
            "Yunfei Chen",
            "Huarui Yin"
        ],
        "subjects": [
            "Information Theory",
            "Signal Processing"
        ],
        "abstract": "Efficient implementation of massive multiple-input-multiple-output (MIMO) transceivers is essential for the next-generation wireless networks. To reduce the high computational complexity of the massive MIMO transceiver, in this paper, we propose a new massive MIMO architecture using finite-precision arithmetic. First, we conduct the rounding error analysis and derive the lower bound of the achievable rate for single-input-multiple-output (SIMO) using maximal ratio combining (MRC) and multiple-input-single-output (MISO) systems using maximal ratio transmission (MRT) with finite-precision arithmetic. Then, considering the multi-user scenario, the rounding error analysis of zero-forcing (ZF) detection and precoding is derived by using the normal equations (NE) method. The corresponding lower bounds of the achievable sum rate are also derived and asymptotic analyses are presented. Built upon insights from these analyses and lower bounds, we propose a mixed-precision architecture for massive MIMO systems to offset performance gaps due to finite-precision arithmetic. The corresponding analysis of rounding errors and computational costs is obtained. Simulation results validate the derived bounds and underscore the superiority of the proposed mixed-precision architecture to the conventional structure.",
        "comments": "16 pages, 8 figures. Submitted to IEEE JSAC for possible publication",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13442"
    },
    {
        "doc_id": 384,
        "title": "Guiding Soft Robots with Motor-Imagery Brain Signals and Impedance Control",
        "authors": [
            "Maximilian St\u00f6lzle",
            "Sonal Santosh Baberwal",
            "Daniela Rus",
            "Shirley Coyle",
            "Cosimo Della Santina"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Integrating Brain-Machine Interfaces into non-clinical applications like robot motion control remains difficult - despite remarkable advancements in clinical settings. Specifically, EEG-based motor imagery systems are still error-prone, posing safety risks when rigid robots operate near humans. This work presents an alternative pathway towards safe and effective operation by combining wearable EEG with physically embodied safety in soft robots. We introduce and test a pipeline that allows a user to move a soft robot's end effector in real time via brain waves that are measured by as few as three EEG channels. A robust motor imagery algorithm interprets the user's intentions to move the position of a virtual attractor to which the end effector is attracted, thanks to a new Cartesian impedance controller. We specifically focus here on planar soft robot-based architected metamaterials, which require the development of a novel control architecture to deal with the peculiar nonlinearities - e.g., non-affinity in control. We preliminarily but quantitatively evaluate the approach on the task of setpoint regulation. We observe that the user reaches the proximity of the setpoint in 66% of steps and that for successful steps, the average response time is 21.5s. We also demonstrate the execution of simple real-world tasks involving interaction with the environment, which would be extremely hard to perform if it were not for the robot's softness.",
        "comments": "8 pages, presented at 7th IEEE-RAS International Conference on Soft Robotics (2024)",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13441"
    },
    {
        "doc_id": 385,
        "title": "Model Predictive Wave Disturbance Rejection for Underwater Soft Robotic Manipulators",
        "authors": [
            "Kyle L. Walker",
            "Cosimo Della Santina",
            "Francesco Giorgio-Serchi"
        ],
        "subjects": [
            "Robotics",
            "Systems and Control"
        ],
        "abstract": "Inspired by the octopus and other animals living in water, soft robots should naturally lend themselves to underwater operations, as supported by encouraging validations in deep water scenarios. This work deals with equipping soft arms with the intelligence necessary to move precisely in wave-dominated environments, such as shallow waters where marine renewable devices are located. This scenario is substantially more challenging than calm deep water since, at low operational depths, hydrodynamic wave disturbances can represent a significant impediment. We propose a control strategy based on Nonlinear Model Predictive Control that can account for wave disturbances explicitly, optimising control actions by considering an estimate of oncoming hydrodynamic loads. The proposed strategy is validated through a set of tasks covering set-point regulation, trajectory tracking and mechanical failure compensation, all under a broad range of varying significant wave heights and peak spectral periods. The proposed control methodology displays positional error reductions as large as 84% with respect to a baseline controller, proving the effectiveness of the method. These initial findings present a first step in the development and deployment of soft manipulators for performing tasks in hazardous water environments.",
        "comments": "To be presented at RoboSoft 2024, San Diego",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13439"
    },
    {
        "doc_id": 386,
        "title": "Keeping Energy-Neutral Devices Operational: a Coherent Massive Beamforming Approach",
        "authors": [
            "Jarne Van Mulders",
            "Bert Cox",
            "Benjamin J. B. Deutschmann",
            "Gilles Callebaut",
            "Lieven de Strycker",
            "Liesbet Van der Perre"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Keeping the batteries on the shelf: this is the holy grail for low-cost Internet of Things (IoT) nodes. In this paper we study the potential of radio frequency (RF)-based wireless power transfer implementing coherent beamforming with many antennas to realize this ambitious target. We optimize the deployment of the antennas to charge electronic shelf labels (ESLs), considering actual regulatory constraints. The results confirm the feasibility to create power spots that are sufficient to keep the high density of battery-less devices operational.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13438"
    },
    {
        "doc_id": 387,
        "title": "SEDNet: Shallow Encoder-Decoder Network for Brain Tumor Segmentation",
        "authors": [
            "Chollette C. Olisah"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Despite the advancement in computational modeling towards brain tumor segmentation, of which several models have been developed, it is evident from the computational complexity of existing models which are still at an all-time high, that performance and efficiency under clinical application scenarios are limited. Therefore, this paper proposes a shallow encoder and decoder network named SEDNet for brain tumor segmentation. The proposed network is adapted from the U-Net structure. Though brain tumors do not assume complex structures like the task the traditional U-Net was designed for, their variance in appearance, shape, and ambiguity of boundaries makes it a compelling complex task to solve. SEDNet architecture design is inspired by the localized nature of brain tumors in brain images, thus consists of sufficient hierarchical convolutional blocks in the encoding pathway capable of learning the intrinsic features of brain tumors in brain slices, and a decoding pathway with selective skip path sufficient for capturing miniature local-level spatial features alongside the global-level features of brain tumor. SEDNet with the integration of the proposed preprocessing algorithm and optimization function on the BraTS2020 set reserved for testing achieves impressive dice and Hausdorff scores of 0.9308, 0.9451, 0.9026, and 0.7040, 1.2866, 0.7762 for non-enhancing tumor core (NTC), peritumoral edema (ED), and enhancing tumor (ET), respectively. Furthermore, through transfer learning with initialized SEDNet pre-trained weights, termed SEDNetX, a performance increase is observed. The dice and Hausdorff scores recorded are 0.9336, 0.9478, 0.9061, 0.6983, 1.2691, and 0.7711 for NTC, ED, and ET, respectively. With about 1.3 million parameters and impressive performance in comparison to the state-of-the-art, SEDNet(X) is shown to be computationally efficient for real-time clinical diagnosis.",
        "comments": "8 pages, 7 figures, 3 Tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13403"
    },
    {
        "doc_id": 388,
        "title": "Perceptually-motivated Spatial Audio Codec for Higher-Order Ambisonics Compression",
        "authors": [
            "Christoph Hold",
            "Leo McCormack",
            "Archontis Politis",
            "Ville Pulkki"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Signal Processing"
        ],
        "abstract": "Scene-based spatial audio formats, such as Ambisonics, are playback system agnostic and may therefore be favoured for delivering immersive audio experiences to a wide range of (potentially unknown) devices. The number of channels required to deliver high spatial resolution Ambisonic audio, however, can be prohibitive for low-bandwidth applications. Therefore, this paper proposes a compression codec, which is based upon the parametric higher-order Directional Audio Coding (HO-DirAC) model. The encoder downmixes the higher-order Ambisonic (HOA) input audio into a reduced number of signals, which are accompanied by perceptually-motivated scene parameters. The downmixed audio is coded using a perceptual audio coder, whereas the parameters are grouped into perceptual bands, quantized, and downsampled. On the decoder side, low Ambisonic orders are fully recovered. Not fully recoverable HOA components are synthesized according to the parameters. The results of a listening test indicate that the proposed parametric spatial audio codec can improve the adopted perceptual audio coder, especially at low to medium-high bitrates, when applied to fifth-order HOA signals.",
        "comments": "Accepted for publication in Proceedings of the 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13401"
    },
    {
        "doc_id": 389,
        "title": "Towards Optimal Pilot Spacing and Power Control in Multi-Antenna Systems Operating Over Non-Stationary Rician Aging Channels",
        "authors": [
            "Sajad Daei",
            "Gabor Fodor",
            "Mikael Skoglund",
            "Miklos Telek"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Several previous works have addressed the inherent trade-off between allocating resources in the power and time domains to pilot and data signals in multiple input multiple output systems over block-fading channels. In particular, when the channel changes rapidly in time, channel aging degrades the performance in terms of spectral efficiency without proper pilot spacing and power control. Despite recognizing non-stationary stochastic processes as more accurate models for time-varying wireless channels, the problem of pilot spacing and power control in multi-antenna systems operating over non-stationary channels is not addressed in the literature. In this paper, we address this gap by introducing a refined first-order autoregressive model that exploits the inherent temporal correlations over non-stationary Rician aging channels. We design a multi-frame structure for data transmission that better reflects the non-stationary fading environment than previously developed single-frame structures. Subsequently, to determine optimal pilot spacing and power control within this multi-frame structure, we develop an optimization framework and an efficient algorithm based on maximizing a deterministic equivalent expression for the spectral efficiency, demonstrating its generality by encompassing previous channel aging results. Our numerical results indicate the efficacy of the proposed method in terms of spectral efficiency gains over the single frame structure.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13368"
    },
    {
        "doc_id": 390,
        "title": "Intelligent Traffic Light Controller using Verilog and Xilinx Spartan-3e",
        "authors": [
            "Apoorva Banerjee"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Traffic lights also known as stop-lights are signaling devices placed at road crossings which control the competing flow of traffic and avoid collisions. The traffic light controller uses a worldwide color code (red, yellow and green). A traffic light controller can be implemented by using a microcontroller, Field Programmable Gate Array or Application Specific Integrated Circuits. Use of Field Programmable Gate Array is beneficial for a number of reasons viz number of Input/Output ports, performance compared to that of a microcontroller and also it is less expensive as compared to Application Specific Integrated Circuits. In this paper, an efficient Traffic Light controller is designed using Moore finite state machine. The circuit description is done in Verilog and the design is tested and simulated on FPGA board Spartan-3e.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13345"
    },
    {
        "doc_id": 391,
        "title": "Deep Learning for Improved Polyp Detection from Synthetic Narrow-Band Imaging",
        "authors": [
            "Mathias Ramm Haugland",
            "Hemin Ali Qadir",
            "Ilangko Balasingham"
        ],
        "subjects": [
            "Image and Video Processing",
            "Artificial Intelligence",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "To cope with the growing prevalence of colorectal cancer (CRC), screening programs for polyp detection and removal have proven their usefulness. Colonoscopy is considered the best-performing procedure for CRC screening. To ease the examination, deep learning based methods for automatic polyp detection have been developed for conventional white-light imaging (WLI). Compared with WLI, narrow-band imaging (NBI) can improve polyp classification during colonoscopy but requires special equipment. We propose a CycleGAN-based framework to convert images captured with regular WLI to synthetic NBI (SNBI) as a pre-processing method for improving object detection on WLI when NBI is unavailable. This paper first shows that better results for polyp detection can be achieved on NBI compared to a relatively similar dataset of WLI. Secondly, experimental results demonstrate that our proposed modality translation can achieve improved polyp detection on SNBI images generated from WLI compared to the original WLI. This is because our WLI-to-SNBI translation model can enhance the observation of polyp surface patterns in the generated SNBI images.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13315"
    },
    {
        "doc_id": 392,
        "title": "Evaluation of the power frequency magnetic field generated by three-core armored cables through 3D finite element simulations",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero",
            "Juan Carlos Bravo-Rodr\u00edguez"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "The great expansion in offshore power plants is raising the concern regarding the cumulative effect of the electromagnetic field emissions caused by submarine power cables. In this sense, owners are required to predict these emissions during the permitting and consenting process of new power plants. This is a challenging task, especially in the case of HVAC three-core armored cables due to their complex geometry. Customarily, 2D approaches based on the finite element method (FEM) have been employed for evaluating the magnetic field emissions caused by these cables. However, inaccurate results are obtained since the phase conductors and armor twisting is omitted. This work develops, for the first time in the literature, an in-depth analysis of the magnetic field caused by this type of cable through an ultra-shortened 3D-FEM model, which is also faced to experimental measurements taken on an actual 132 kV, 800 mm2 three-core armored cable. Relevant conclusions are derived regarding the impact of the cable design on the magnetic field emissions, including material properties, as well as single and double-layer armors, presenting the proposed model not only as a valuable tool for predicting purposes, but also for optimizing cable design in terms of magnetic field emissions.",
        "comments": "Journal ref:        Electric Power Systems Research, Volume 213, 108701, december 2022",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13312"
    },
    {
        "doc_id": 393,
        "title": "SCNet: Sparse Compression Network for Music Source Separation",
        "authors": [
            "Weinan Tong",
            "Jiaxu Zhu",
            "Jun Chen",
            "Shiyin Kang",
            "Tao Jiang",
            "Yang Li",
            "Zhiyong Wu",
            "Helen Meng"
        ],
        "subjects": [
            "Audio and Speech Processing"
        ],
        "abstract": "Deep learning-based methods have made significant achievements in music source separation. However, obtaining good results while maintaining a low model complexity remains challenging in super wide-band music source separation. Previous works either overlook the differences in subbands or inadequately address the problem of information loss when generating subband features. In this paper, we propose SCNet, a novel frequency-domain network to explicitly split the spectrogram of the mixture into several subbands and introduce a sparsity-based encoder to model different frequency bands. We use a higher compression ratio on subbands with less information to improve the information density and focus on modeling subbands with more information. In this way, the separation performance can be significantly improved using lower computational consumption. Experiment results show that the proposed model achieves a signal to distortion ratio (SDR) of 9.0 dB on the MUSDB18-HQ dataset without using extra data, which outperforms state-of-the-art methods. Specifically, SCNet's CPU inference time is only 48% of HT Demucs, one of the previous state-of-the-art models.",
        "comments": "Accepted by ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13276"
    },
    {
        "doc_id": 394,
        "title": "Loss Allocation in Submarine Armored Three-core HVAC Power Cables",
        "authors": [
            "Juan Carlos del-Pino-L\u00f3pez",
            "Pedro Cruz-Romero",
            "Luis Carlos S\u00e1nchez-D\u00edaz"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "Loss allocation of the three different components (conductor, sheaths and armor) of solidly bonded three-core separated lead-sheathed armored cables, frequently employed in offshore wind farms, is challenging due to the lack of accurate enough analytical expressions in the IEC standard. Also, loss allocation through experimental tests leads to inaccurate results since it is based on questionable assumptions. This paper improves both the IEC formulae and experimental methods by means of different analytical corrections in the conductor and sheath loss expressions. To this aim, an ad hoc application interface (Virtual Lab) based on 3D numerical simulations (finite element method) has been developed. This tool virtualizes and automates different test setups to emulate, in few seconds, the most employed experimental procedures in this type of cable. The analytical corrections have been derived from an in-depth analysis of a first set of 368 cables, ranging from 30 to 275 kV. The new loss expressions were successfully applied to a second set of 645 armored cables of quite diverse features (voltages from 10 to 275 kV, sections and dimensional parameters), hence bringing a general framework for any kind of three-core armored cable.",
        "comments": "Journal ref:        IEEE Transactions on Industry Applications, vol. 57, no. 6, pp. 5706-5715, Nov.-Dec. 2021",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13268"
    },
    {
        "doc_id": 395,
        "title": "MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction",
        "authors": [
            "Jiajun He",
            "Xiaohan Shi",
            "Xingfeng Li",
            "Tomoki Toda"
        ],
        "subjects": [
            "Computation and Language",
            "Multimedia",
            "Sound",
            "Audio and Speech Processing"
        ],
        "abstract": "The prevalent approach in speech emotion recognition (SER) involves integrating both audio and textual information to comprehensively identify the speaker's emotion, with the text generally obtained through automatic speech recognition (ASR). An essential issue of this approach is that ASR errors from the text modality can worsen the performance of SER. Previous studies have proposed using an auxiliary ASR error detection task to adaptively assign weights of each word in ASR hypotheses. However, this approach has limited improvement potential because it does not address the coherence of semantic information in the text. Additionally, the inherent heterogeneity of different modalities leads to distribution gaps between their representations, making their fusion challenging. Therefore, in this paper, we incorporate two auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to enhance the semantic coherence of ASR text, and further introduce a novel multi-modal fusion (MF) method to learn shared representations across modalities. We refer to our method as MF-AED-AEC. Experimental results indicate that MF-AED-AEC significantly outperforms the baseline model by a margin of 4.1\\%.",
        "comments": "Accepted by ICASSP 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13260"
    },
    {
        "doc_id": 396,
        "title": "MOS-FAD: Improving Fake Audio Detection Via Automatic Mean Opinion Score Prediction",
        "authors": [
            "Wangjin Zhou",
            "Zhengdong Yang",
            "Chenhui Chu",
            "Sheng Li",
            "Raj Dabre",
            "Yi Zhao",
            "Tatsuya Kawahara"
        ],
        "subjects": [
            "Audio and Speech Processing",
            "Multimedia"
        ],
        "abstract": "Automatic Mean Opinion Score (MOS) prediction is employed to evaluate the quality of synthetic speech. This study extends the application of predicted MOS to the task of Fake Audio Detection (FAD), as we expect that MOS can be used to assess how close synthesized speech is to the natural human voice. We propose MOS-FAD, where MOS can be leveraged at two key points in FAD: training data selection and model fusion. In training data selection, we demonstrate that MOS enables effective filtering of samples from unbalanced datasets. In the model fusion, our results demonstrate that incorporating MOS as a gating mechanism in FAD model fusion enhances overall performance.",
        "comments": "Accepted in ICASSP2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13249"
    },
    {
        "doc_id": 397,
        "title": "Segment Any Cell: A SAM-based Auto-prompting Fine-tuning Framework for Nuclei Segmentation",
        "authors": [
            "Saiyang Na",
            "Yuzhi Guo",
            "Feng Jiang",
            "Hehuan Ma",
            "Junzhou Huang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "In the rapidly evolving field of AI research, foundational models like BERT and GPT have significantly advanced language and vision tasks. The advent of pretrain-prompting models such as ChatGPT and Segmentation Anything Model (SAM) has further revolutionized image segmentation. However, their applications in specialized areas, particularly in nuclei segmentation within medical imaging, reveal a key challenge: the generation of high-quality, informative prompts is as crucial as applying state-of-the-art (SOTA) fine-tuning techniques on foundation models. To address this, we introduce Segment Any Cell (SAC), an innovative framework that enhances SAM specifically for nuclei segmentation. SAC integrates a Low-Rank Adaptation (LoRA) within the attention layer of the Transformer to improve the fine-tuning process, outperforming existing SOTA methods. It also introduces an innovative auto-prompt generator that produces effective prompts to guide segmentation, a critical factor in handling the complexities of nuclei segmentation in biomedical imaging. Our extensive experiments demonstrate the superiority of SAC in nuclei segmentation tasks, proving its effectiveness as a tool for pathologists and researchers. Our contributions include a novel prompt generation strategy, automated adaptability for diverse segmentation tasks, the innovative application of Low-Rank Attention Adaptation in SAM, and a versatile framework for semantic segmentation challenges.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13220"
    },
    {
        "doc_id": 398,
        "title": "Predicting Mitral Valve mTEER Surgery Outcomes Using Machine Learning and Deep Learning Techniques",
        "authors": [
            "Tejas Vyas",
            "Mohsena Chowdhury",
            "Xiaojiao Xiao",
            "Mathias Claeys",
            "G\u00e9raldine Ong",
            "Guanghui Wang"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition"
        ],
        "abstract": "Mitral Transcatheter Edge-to-Edge Repair (mTEER) is a medical procedure utilized for the treatment of mitral valve disorders. However, predicting the outcome of the procedure poses a significant challenge. This paper makes the first attempt to harness classical machine learning (ML) and deep learning (DL) techniques for predicting mitral valve mTEER surgery outcomes. To achieve this, we compiled a dataset from 467 patients, encompassing labeled echocardiogram videos and patient reports containing Transesophageal Echocardiography (TEE) measurements detailing Mitral Valve Repair (MVR) treatment outcomes. Leveraging this dataset, we conducted a benchmark evaluation of six ML algorithms and two DL models. The results underscore the potential of ML and DL in predicting mTEER surgery outcomes, providing insight for future investigation and advancements in this domain.",
        "comments": "5 pages, 1 figure",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13197"
    },
    {
        "doc_id": 399,
        "title": "LightSleepNet: Design of a Personalized Portable Sleep Staging System Based on Single-Channel EEG",
        "authors": [
            "Yiqiao Liao",
            "Chao Zhang",
            "Milin Zhang",
            "Zhihua Wang",
            "Xiang Xie"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "This paper proposed LightSleepNet - a light-weight, 1-d Convolutional Neural Network (CNN) based personalized architecture for real-time sleep staging, which can be implemented on various mobile platforms with limited hardware resources. The proposed architecture only requires an input of 30s single-channel EEG signal for the classification. Two residual blocks consisting of group 1-d convolution are used instead of the traditional convolution layers to remove the redundancy in the CNN. Channel shuffles are inserted into each convolution layer to improve the accuracy. In order to avoid over-fitting to the training set, a Global Average Pooling (GAP) layer is used to replace the fully connected layer, which further reduces the total number of the model parameters significantly. A personalized algorithm combining Adaptive Batch Normalization (AdaBN) and gradient re-weighting is proposed for unsupervised domain adaptation. A higher priority is given to examples that are easy to transfer to the new subject, and the algorithm could be personalized for new subjects without re-training. Experimental results show a state-of-the-art overall accuracy of 83.8% with only 45.76 Million Floating-point Operations per Second (MFLOPs) computation and 43.08 K parameters.",
        "comments": "5 pages, 3 figures, published by IEEE TCAS-II",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13194"
    },
    {
        "doc_id": 400,
        "title": "Nucleosynthesis in magnetorotational supernovae: impact of the magnetic field configuration",
        "authors": [
            "M. Reichert",
            "M. Bugli",
            "J. Guilet",
            "M. Obergaulinger",
            "M. \u00c1. Aloy",
            "A. Arcones"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "The production of heavy elements is one of the main by-products of the explosive end of massive stars. A long sought goal is finding differentiated patterns in the nucleosynthesis yields, which could permit identifying a number of properties of the explosive core. Among them, the traces of the magnetic field topology are particularly important for \\emph{extreme} supernova explosions, most likely hosted by magnetorotational effects. We investigate the nucleosynthesis of five state-of-the-art magnetohydrodynamic models with fast rotation that have been previously calculated in full 3D and that involve an accurate neutrino transport (M1). One of the models does not contain any magnetic field and synthesizes elements around the iron group, in agreement with other CC-SNe models in literature. All other models host a strong magnetic field of the same intensity, but with different topology. For the first time, we investigate the nucleosynthesis of MR-SNe models with a quadrupolar magnetic field and a 90 degree tilted dipole. We obtain a large variety of ejecta compositions reaching from iron nuclei to nuclei up to the third r-process peak. We assess the robustness of our results by considering the impact of different nuclear physics uncertainties such as different nuclear masses, $\u03b2^{-}$-decays and $\u03b2^{-}$-delayed neutron emission probabilities, neutrino reactions, fission, and a feedback of nuclear energy on the temperature. We find that the qualitative results do not change with different nuclear physics input. The properties of the explosion dynamics and the magnetic field configuration are the dominant factors determining the ejecta composition.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14402"
    },
    {
        "doc_id": 401,
        "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes",
        "authors": [
            "Ege Ozguroglu",
            "Ruoshi Liu",
            "D\u00eddac Sur\u00eds",
            "Dian Chen",
            "Achal Dave",
            "Pavel Tokmakov",
            "Carl Vondrick"
        ],
        "subjects": [
            "Computer Vision and Pattern Recognition",
            "Machine Learning"
        ],
        "abstract": "We introduce pix2gestalt, a framework for zero-shot amodal segmentation, which learns to estimate the shape and appearance of whole objects that are only partially visible behind occlusions. By capitalizing on large-scale diffusion models and transferring their representations to this task, we learn a conditional diffusion model for reconstructing whole objects in challenging zero-shot cases, including examples that break natural and physical priors, such as art. As training data, we use a synthetically curated dataset containing occluded objects paired with their whole counterparts. Experiments show that our approach outperforms supervised baselines on established benchmarks. Our model can furthermore be used to significantly improve the performance of existing object recognition and 3D reconstruction methods in the presence of occlusions.",
        "comments": "Website: https://gestalt.cs.columbia.edu/",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14398"
    },
    {
        "doc_id": 402,
        "title": "Entanglement entropy and deconfined criticality: emergent SO(5) symmetry and proper lattice bipartition",
        "authors": [
            "Jonathan D'Emidio",
            "Anders W. Sandvik"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "High Energy Physics - Lattice"
        ],
        "abstract": "We study the R\u00e9nyi entanglement entropy (EE) of the two-dimensional $J$-$Q$ model, the emblematic quantum spin model of deconfined criticality at the phase transition between antiferromagnetic and valence-bond-solid ground states. Quantum Monte Carlo simulations with an improved EE scheme reveal critical corner contributions that scale logarithmically with the system size, with a coefficient in remarkable agreement with the form expected from a large-$N$ conformal field theory with SO($N=5$) symmetry. However, details of the bipartition of the lattice are crucial in order to observe this behavior. If the subsystem for the reduced density matrix does not properly accommodate valence-bond fluctuations, logarithmic contributions appear even for corner-less bipartitions. We here use a $45^\\circ$ tilted cut on the square lattice. Beyond supporting an SO($5$) deconfined quantum critical point, our results for both the regular and tilted cuts demonstrate important microscopic aspects of the EE that are not captured by conformal field theory.",
        "comments": "5 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14396"
    },
    {
        "doc_id": 403,
        "title": "Summing up perturbation series around superintegrable point",
        "authors": [
            "A. Mironov",
            "A. Morozov",
            "A. Popolitov",
            "Sh. Shakirov"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "Mathematical Physics"
        ],
        "abstract": "We work out explicit formulas for correlators in the Gaussian matrix model perturbed by a logarithmic potential, i.e. by inserting Miwa variables. In this paper, we concentrate on the example of a single Miwa variable. The ordinary Gaussian model is superintegrable, i.e. the average of the Schur functions $S_Q$ is an explicit function of the Young diagram $Q$. The question is what happens to this property after perturbation. We show that the entire perturbation series can be nicely summed up into a kind of Borel transform of a universal exponential function, while the dependence on $R$ enters through a polynomial factor in front of this exponential. Moreover, these polynomials can be described explicitly through a single additional structure, which we call ``truncation'' of the Young diagram $Q$. It is unclear if one can call this an extended superintegrability, but at least it is a tremendously simple deformation of it. Moreover, the vanishing Gaussian correlators remain vanishing and, hence, are not deformed at all.",
        "comments": "15 pages + Appendix (7 pages)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14392"
    },
    {
        "doc_id": 404,
        "title": "Weakening of magnetic braking in cataclysmic variables explains the dearth of period bouncers",
        "authors": [
            "Arnab Sarkar",
            "Antonio C. Rodriguez",
            "Sivan Ginzburg",
            "Lev Yungelson",
            "Christopher A. Tout"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Period bouncers are cataclysmic variables (CVs) that have evolved past their orbital period minimum. The strong disagreement between theory and observations of the relative fraction of period bouncers is a severe shortcoming in the understanding of CV evolution. We test the implications of the hypothesis that magnetic braking (MB), which is suggested to be an additional angular momentum loss (AML) mechanism for CVs below the period gap ($P_\\mathrm{orb}\\lesssim 120$ min), weakens around their period minimum. We compute the evolution of CV donors below the period gap using the MESA code, assuming that the evolution of the system is driven by AML by gravitational wave radiation (GWR) and MB. We parametrize the MB strength as $\\mathrm{AML_{MB}}=\u03ba\\mathrm{AML_{GWR}}$. We compute two qualitatively different sets of models, one where $\u03ba$ is a constant and the other where $\u03ba$ depends on stellar parameters. We find that in the latter set of models, $\u03ba$ decreases as the CV approaches the period minimum ($P_\\mathrm{orb}\\approx80\\,$ min), beyond which $\u03ba\\approx0$. This stalls their evolution so that they spend a long time in the observed period minimum spike ($80\\lesssim P_\\mathrm{orb}/\\,\\mathrm{min}\\lesssim 86$). Here they become difficult to distinguish from pre-bounce systems in the spike. A strong decrease in mass-transfer rate makes them virtually undetectable as they evolve further. We also discuss the physical processes, such as dynamo action, white dwarf magnetism and dead zones, that may cause such a weakening of MB at short orbital periods. The weakening magnetic braking formalism solves the problem of the lack of period bouncers in CV observational surveys.",
        "comments": "Submitted to A&A Letters. Comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14389"
    },
    {
        "doc_id": 405,
        "title": "Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem",
        "authors": [
            "Kaifeng Bu",
            "Weichen Gu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We establish an entropic, quantum central limit theorem and quantum inverse sumset theorem in discrete-variable quantum systems describing qudits or qubits. Both results are enabled by using our recently-discovered quantum convolution. We show that the exponential rate of convergence of the entropic central limit theorem is bounded by the magic gap. We also establish an ``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose a conjecture called ``convolutional strong subaddivity,'' which leads to the triangle inequality for the quantum Ruzsa divergence. A byproduct of this work is a magic measure to quantify the nonstabilizer nature of a state, based on the quantum Ruzsa divergence.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14385"
    },
    {
        "doc_id": 406,
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "subjects": [
            "Computational Complexity",
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We devise a parameterized family of distributions, the high-entropy step distributions (HES), which are expressive enough to capture near-optima of spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime and yet permit low-degree Sum-of-Squares (SoS) certificates that no such distribution can achieve value slightly larger than the true optimum. This yields a SoS optimization program and rounding scheme that attains near-optimal solutions for spherical spin glasses in the fRSB regime. In other regimes, the same results occur at the ALG value, which is a conjectured best-value attainable by any polynomial time algorithm. These SoS programs optimize over families of distributions of possible solutions, and circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure by instead proving the same bounds only in expectation on solution distributions that can be produced by the chosen rounding algorithm. The new SoS hierarchy does not make any specific reference to the spherical spin glass problem, and we conjecture that it can be applied to a broad range of average-case problems to obtain value that is optimal among polynomial-time algorithms. We give evidence for this with examples of ensembles that provably fool certain local iterative algorithms but for which there is either proof or evidence that the SoS program is better. This opens the door to addressing a question posed by Barak about the possible optimality of SoS on average-case optimization problems, and by Schramm about reductions between different families of algorithms for average-case problems. In this paper, we give low-degree SoS proofs certifying key properties about HES distributions as well as the ALG threshold for spherical spin glasses. The rounding algorithm is introduced and analyzed in a companion paper.",
        "comments": "130 pages, 0 figures. First of two companion papers",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14383"
    },
    {
        "doc_id": 407,
        "title": "Electrotaxis of self-propelling artificial swimmers in microchannels",
        "authors": [
            "Carola M. Buness",
            "Avi Rana",
            "Corinna C. Maass",
            "Ranabir Dey"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Fluid Dynamics"
        ],
        "abstract": "Ciliated microswimmers and flagellated bacteria alter their swimming trajectories to follow the direction of an applied electric field exhibiting electrotaxis. Both for matters of application and physical modelling, it is instructive to study such behaviour in synthetic swimmers. We show here that under an external electric field, self-propelling active droplets autonomously modify their swimming trajectories in microchannels, even undergoing `U-turns', to exhibit robust electrotaxis. Depending on the relative initial orientations of the microswimmer and the external electric field, the active droplet can also navigate upstream of an external flow following a centre-line motion, instead of the oscillatory upstream trajectory observed in absence of electric field. Using a hydrodynamic theory model, we show that the electrically induced angular velocity and electrophoretic effects, along with the microswimmer motility and its hydrodynamic interactions with the microchannel walls, play crucial roles in dictating the electrotactic trajectories and dynamics. Specifically, the transformation in the trajectories during upstream swimming against an external flow under an electric field can be understood as a reverse Hopf bifurcation for a dynamical system. Our study provides a simple methodology and a systematic understanding of manoeuvring active droplets in microconfinements for micro-robotic applications especially in biotechnology.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14376"
    },
    {
        "doc_id": 408,
        "title": "Spatially Resolved Conductivity of Rectangular Interconnects considering Surface Scattering -- Part II: Circuit-Compatible Modeling",
        "authors": [
            "Xinkang Chen",
            "Sumeet Kumar Gupta"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Interconnect conductivity modeling is a critical aspect for modern chip design. Surface scattering -- an important scattering mechanism in scaled interconnects is usually captured using Fuchs-Sondheimer (FS) model which offers the average behavior of the interconnect. However, to support the modern interconnect structures (such as tapered geometries), modeling spatial dependency of conductivity becomes important. In Part I of this work, we presented a spatially resolved FS (SRFS) model for rectangular interconnects derived from the fundamental FS approach. While the proposed SRFS model offers both spatial-dependency of conductivity and its direct relationship with the physical parameters, its complex expression is not suitable for incorporation in circuit simulations. In this part, we build upon our SRFS model to propose a circuit-compatible conductivity model for rectangular interconnects accounting for 2D surface scattering. The proposed circuit-compatible model offers spatial resolution of conductivity as well as explicit dependence on the physical parameters such as electron mean free path ($\u03bb_0$), specularity ($p$) and interconnect geometry. We validate our circuit-compatible model over a range of interconnect width/height (and $\u03bb_0$) and p values and show a close match with the physical SRFS model proposed in Part I (with error < 0.7%). We also compare our circuit-compatible model with a previous spatially resolved analytical model (appropriately modified for a fair comparison) and show that our model captures the spatial resolution of conductivity and the dependence on physical parameters more accurately. Finally, we present a semi-analytical equation for the average conductivity based on our circuit-compatible model.",
        "comments": "10 pages, 8 figures in process to submit to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14374"
    },
    {
        "doc_id": 409,
        "title": "Modeling Global Surface Dust Deposition Using Physics-Informed Neural Networks",
        "authors": [
            "Constanza A. Molina Catricheo",
            "Fabrice Lambert",
            "Julien Salomon",
            "Elwin van 't Wout"
        ],
        "subjects": [
            "Geophysics"
        ],
        "abstract": "Paleoclimatic measurements serve to understand geophysical processes and evaluate climate model performances. However, their spatial coverage is generally sparse and unevenly distributed across the globe. Statistical interpolation methods are the prevalent techniques to grid such data, but these purely data-driven approaches sometimes produce results that are incoherent with our knowledge of the physical world. Physics-Informed Neural Networks (PINNs) follow an innovative approach to data analysis and physical modeling through machine learning, as they incorporate physical principles into the data-driven learning process. Here, we develop PINNs to reconstruct global maps of atmospheric dust surface deposition fluxes from measurement data in paleoclimatic archives, for the Holocene and Last Glacial Maximum periods. We design an advection-diffusion equation to consider dominant wind directions at various latitudes, which prevents dust particles from flowing upwind. Our PINN improves on standard kriging interpolation by allowing variable asymmetry around data points. The reconstructions display realistic dust plumes from continental sources towards ocean basins following prevailing winds.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14372"
    },
    {
        "doc_id": 410,
        "title": "Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input",
        "authors": [
            "Enrico Picco",
            "Lina Jaurigue",
            "Kathy L\u00fcdge",
            "Serge Massar"
        ],
        "subjects": [
            "Emerging Technologies",
            "Artificial Intelligence",
            "Neural and Evolutionary Computing",
            "Optics"
        ],
        "abstract": "We present an experimental validation of a recently proposed optimization technique for reservoir computing, using an optoelectronic setup. Reservoir computing is a robust framework for signal processing applications, and the development of efficient optimization approaches remains a key challenge. The technique we address leverages solely a delayed version of the input signal to identify the optimal operational region of the reservoir, simplifying the traditionally time-consuming task of hyperparameter tuning. We verify the effectiveness of this approach on different benchmark tasks and reservoir operating conditions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14371"
    },
    {
        "doc_id": 411,
        "title": "Anomalous localization in spin-chain with tilted interactions",
        "authors": [
            "Arindam Mallick",
            "Jakub Zakrzewski"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Quantum Gases",
            "Strongly Correlated Electrons",
            "High Energy Physics - Lattice",
            "Quantum Physics"
        ],
        "abstract": "The localization properties of a disorder-free spin chain with inhomogeneous interactions are studied. In particular, we consider interaction strength growing linearly along the chain for systems with different interaction ranges. Using exact diagonalization we find the participation ratio of all eigenstates which allows us to quantify the localization volume in the Hilbert space. Surprisingly the localization volume changes nonmonotonically with the interaction range. The model for the infinite interaction range resembles the Schwinger model of lattice gauge theory in staggered formalism. The model studied may be implemented in state-of-the-art cold atomic devices and could reveal hidden features in disorder-free confinement phenomena.",
        "comments": "11 pages, 9 figures. Comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14369"
    },
    {
        "doc_id": 412,
        "title": "Spectral Gaps of 2D and 3D Many-body Quantum Systems in the Thermodynamic Limit",
        "authors": [
            "Illya V. Lukin",
            "Andrii G. Sotnikov",
            "Jacob M. Leamer",
            "Alicia B. Magann",
            "Denys I. Bondar"
        ],
        "subjects": [
            "Quantum Physics",
            "Strongly Correlated Electrons"
        ],
        "abstract": "We present an expression for the spectral gap, opening up new possibilities for performing and accelerating spectral calculations of quantum many-body systems. We develop and demonstrate one such possibility in the context of tensor network simulations. Our approach requires only minor modifications of the widely used Simple Update method and is computationally lightweight relative to other approaches. We validate it by computing spectral gaps of the 2D and 3D transverse-field Ising models and find strong agreement with previously reported perturbation theory results.",
        "comments": "7 pages and 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14368"
    },
    {
        "doc_id": 413,
        "title": "Spatially Resolved Conductivity of Rectangular Interconnects considering Surface Scattering -- Part I: Physical Modeling",
        "authors": [
            "Xinkang Chen",
            "Sumeet Kumar Gupta"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Accurate modeling of interconnect conductivity is important for performance evaluation of chips in advanced technologies. Surface scattering in interconnects is usually treated by using Fuchs-Sondheimer (FS) approach. While the FS model offer explicit inclusion of the physical parameters, it lacks spatial dependence of conductivity across the interconnect cross-section. To capture the space-dependency of conductivity, an empirical modeling approach based on \"cosh\" function has been proposed, but it lacks physical insights. In this work, we present a 2D spatially resolved FS (SRFS) model for rectangular interconnects derived from the Boltzmann transport equations. The proposed SRFS model for surface scattering offers both spatial dependence and explicit relation of conductivity to physical parameters such as mean free path and specularity of electrons and interconnect geometry. We highlight the importance of physics-based spatially resolved conductivity model by showing the differences in the spatial profiles between the proposed physical approach and the previous empirical approach. In Part II of this work, we build upon the SRFS approach to propose a compact model for spatially-resolved conductivity accounting for surface scattering in rectangular interconnects.",
        "comments": "12 pages, 8 figures, in process to submit to IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14366"
    },
    {
        "doc_id": 414,
        "title": "Impact of dynamical regionalization on precipitation biases and teleconnections over West Africa",
        "authors": [
            "I\u00f1igo G\u00f3mara",
            "Elsa Mohino",
            "Teresa Losada",
            "Marta Dom\u00ednguez",
            "Roberto Su\u00e1rez-Moreno",
            "Bel\u00e9n Rodr\u00edguez-Fonseca"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics",
            "Geophysics"
        ],
        "abstract": "West African societies are highly dependent on the West African Monsoon (WAM).Thus, a correct representation of the WAM in climate models is of paramount importance. In this article, the ability of 8 CMIP5 historical General Circulation Models (GCMs) and 4 CORDEX-Africa Regional Climate Models (RCMs) to characterize the WAM dynamics and variability is assessed for the period July-August-September 1979-2004. Simulations are compared with observations. Uncertainties in RCM performance and lateral boundary conditions are assessed individually. Results show that both GCMs and RCMs have trouble to simulate the northward migration of the Intertropical Convergence Zone in boreal summer. The greatest bias improvements are obtained after regionalization of the most inaccurate GCM simulations. To assess WAM variability, a Maximum Covariance Analysis is performed between Sea Surface Temperature and precipitation anomalies in observations, GCM and RCM simulations. The assessed variability patterns are: El Nino-Southern Oscillation (ENSO); the eastern Mediterranean (MED); and the Atlantic Equatorial Mode (EM). Evidence is given that regionalization of the ENSO-WAM teleconnection does not provide any added value. Unlike GCMs, RCMs are unable to precisely represent the ENSO impact on air subsidence over West Africa. Contrastingly, the simulation of the MED-WAM teleconnection is improved after regionalization. Humidity advection and convergence over the Sahel area are better simulated by RCMs. Finally, no robust conclusions can be determined for the EM-WAM teleconnection, which cannot be isolated for the 1979-2004 period. The novel results in this article will help to select the most appropriate RCM simulations to study WAM teleconnections.",
        "comments": "Journal ref:        Clim Dyn 50, 4481-4506 (2018)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14364"
    },
    {
        "doc_id": 415,
        "title": "Universal collective Larmor-Silin mode emerging in magnetized correlated Dirac fermions",
        "authors": [
            "Chuang Chen",
            "Yuan Da Liao",
            "Chengkang Zhou",
            "Gaopei Pan",
            "Zi Yang Meng",
            "Yang Qi"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Mesoscale and Nanoscale Physics",
            "Materials Science"
        ],
        "abstract": "Employing large-scale quantum Monte Carlo simulations, we find in magnetized interacting Dirac fermion model, there emerges a new and universal collective Larmor-Silin spin wave mode in the transverse dynamical spin susceptibility. Such mode purely originates from the interaction among Dirac fermions and distinguishes itself from the usual particle-hole continuum with finite lifetime and clear dispersion. Our unbiased numerical results offer the dynamic signature of this new collective excitations in interacting Dirac fermion systems, and provide experimental guidance for inelastic neutron scattering, electron spin resonance and other spectroscopic approaches in the investigation of such universal collective modes in quantum Moire materials, topological insulators and quantum spin liquid materials under magnetic field, with quintessential interaction nature beyond the commonly assumed noninteracting Dirac fermion or spinon approximations.",
        "comments": "11 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14358"
    },
    {
        "doc_id": 416,
        "title": "Near-field radiative heat transfer between shifted graphene gratings",
        "authors": [
            "Minggang Luo",
            "Youssef Jeyar",
            "Brahim Guizal",
            "Mauro Antezza"
        ],
        "subjects": [
            "Optics",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics"
        ],
        "abstract": "We examine the near-field radiative heat transfer between finite-thickness planar fused silica slabs covered with graphene gratings, through the utilization of the exact Fourier modal method augmented with local basis functions (FMM-LBF), with focus on the lateral shift effect. To do so, we propose and validate a minor modification of the FMM-LBF theory to account for the lateral shift. This approach goes far beyond the effective medium approximation because this latter cannot account for the lateral shift. We show that the heat flux can exhibit significant oscillations with the lateral shift and, at short separation, it can experience up to a 60%-70% reduction compared to the aligned case. Such a lateral shift effect is found to be sensitive to the geometric factor $d/D$ (separation distance to grating period ratio). When $d/D>2$ (realized through large separation or small grating period), the two graphene gratings see each other as an effective whole rather than in detail, and thus the lateral shift effect on heat transfer becomes less important. Therefore, we can clearly distinguish two asymptotic regimes for radiative heat transfer: the LSE (Lateral Shift Effect) regime, where a significant lateral shift effect is observed, and the non-LSE regime, where this effect is negligible. Furthermore, regardless of the lateral shift, the radiative heat flux shows an obvious and non-monotonic dependence on the graphene chemical potential. That is, we can get an optimal radiative heat flux (peaking at about 0.3eV chemical potential) by $\\textit{in situ}$ modulating the chemical potential. This work has the potential to unveil new avenues for harnessing the lateral shift effect on radiative heat transfer in graphene-based nanodevices.",
        "comments": "13 pages, 13 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14357"
    },
    {
        "doc_id": 417,
        "title": "Exact surface energy of the Hubbard model with unparallel boundary magnetic fields",
        "authors": [
            "Pei Sun",
            "Yi Qiao",
            "Junpeng Cao",
            "Wen-Li Yang"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "In this paper, we study the exact physical quantities in the thermodynamic limit of the one-dimensional Hubbard model with unparallel boundary magnetic fields based on the off-diagonal Bethe ansatz solution. At the half-filling, we obtain the different patterns of Bethe roots of the reduced Bethe ansatz equations for the different boundary parameters. According to them, we obtain the densities of states, ground state energy density and surface energy. Our results show that the system has the stable boundary bound states when the boundary magnetic fields satisfy some constraints.",
        "comments": "13 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14356"
    },
    {
        "doc_id": 418,
        "title": "Initial data for Minkowski stability with arbitrary decay",
        "authors": [
            "Allen Juntao Fang",
            "J\u00e9r\u00e9mie Szeftel",
            "Arthur Touati"
        ],
        "subjects": [
            "Analysis of PDEs",
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "We construct and parametrize solutions to the constraint equations of general relativity in a neighborhood of Minkowski spacetime with arbitrary prescribed decay properties at infinity. We thus provide a large class of initial data for the results on stability of Minkowski which include a mass term in the asymptotics. Due to the symmetries of Minkowski, a naive linear perturbation fails. Our construction is based on a simplified conformal method, a reduction to transverse traceless perturbations and a nonlinear fixed point argument where we face linear obstructions coming from the cokernels of both the linearized constraint operator and the Laplace operator. To tackle these obstructions, we introduce a well-chosen truncated black hole around which to perturb. The control of the parameters of the truncated black hole is the most technical part of the proof, since its center of mass and angular momentum could be arbitrarily large.",
        "comments": "86 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14353"
    },
    {
        "doc_id": 419,
        "title": "Uncovering Heterogeneity of Solar Flare Mechanism With Mixture Models",
        "authors": [
            "Bach Viet Do",
            "Yang Chen",
            "XuanLong Nguyen",
            "Ward Manchester"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Applications",
            "Methodology"
        ],
        "abstract": "The physics of solar flares occurring on the Sun is highly complex and far from fully understood. However, observations show that solar eruptions are associated with the intense kilogauss fields of active regions, where free energies are stored with field-aligned electric currents. With the advent of high-quality data sources such as the Geostationary Operational Environmental Satellites (GOES) and Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI), recent works on solar flare forecasting have been focusing on data-driven methods. In particular, black box machine learning and deep learning models are increasingly adopted in which underlying data structures are not modeled explicitly. If the active regions indeed follow the same laws of physics, there should be similar patterns shared among them, reflected by the observations. Yet, these black box models currently used in the literature do not explicitly characterize the heterogeneous nature of the solar flare data, within and between active regions. In this paper, we propose two finite mixture models designed to capture the heterogeneous patterns of active regions and their associated solar flare events. With extensive numerical studies, we demonstrate the usefulness of our proposed method for both resolving the sample imbalance issue and modeling the heterogeneity for rare energetic solar flare events.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14345"
    },
    {
        "doc_id": 420,
        "title": "From the Choi Formalism in Infinite Dimensions to Unique Decompositions of Generators of Completely Positive Dynamical Semigroups",
        "authors": [
            "Frederik vom Ende"
        ],
        "subjects": [
            "Functional Analysis",
            "Mathematical Physics",
            "Quantum Physics"
        ],
        "abstract": "Given any separable complex Hilbert space, any trace-class operator $B$ which does not have purely imaginary trace, and any generator $L$ of a norm-continuous one-parameter semigroup of completely positive maps we prove that there exists a unique bounded operator $K$ and a unique completely positive map $\u03a6$ such that (i) $L=K(\\cdot)+(\\cdot)K^*+\u03a6$, (ii) the superoperator $\u03a6(B^*(\\cdot)B)$ is trace class and has vanishing trace, and (iii) ${\\rm tr}(B^*K)$ is a real number. Central to our proof is a modified version of the Choi formalism which relates completely positive maps to positive semi-definite operators. We characterize when this correspondence is injective and surjective, respectively, which in turn explains why the proof idea of our main result cannot extend to non-separable Hilbert spaces. In particular, we find examples of positive semi-definite operators which have empty pre-image under the Choi formalism as soon as the underlying Hilbert space is infinite-dimensional.",
        "comments": "25+3 pages. Generalizes arXiv:2310.04037 to infinite dimensions. To be submitted to J. Funct. Anal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14344"
    },
    {
        "doc_id": 421,
        "title": "Probing Quantum Entanglement from Quantum Correction to Newtonian Potential Energy",
        "authors": [
            "A. Belhaj",
            "S. E. Ennadifi",
            "L. Jebli"
        ],
        "subjects": [
            "Quantum Physics",
            "Mathematical Physics"
        ],
        "abstract": "Inspired by string theory ideas, we probe quantum entanglement from the gravitational potential energy. Concretely, we reconsider the study of quantum corrections to the Newtonian potential energy by treating a massive two-particle system $m_{1}$ and $m_{2}$ with size dimensions $r_{1}$ ad $% r_{2}$ where the two particles separated by a distance $d$ are under only their mutual classical gravitational interaction $V_{r}\\left( r_{1}\\text{, }% r_{2}\\right) $. Exploring such a size-dependent gravitational behavior and taking the limit $r_{1}$, $r_{2}\\ll d$, we investigate the associated quantum biparticle state and express its evolution after an interaction time $\u03c4$. Among others, we show that the two masses cannot be separable due to the induced gravitational entanglement in terms of the accumulated quantum phase $\u03b4\u03c6=\u03b4V_{g}\u03c4/\\hbar $. By analogy with the classical gravity, we derive the expression of the resulting extremely weak entanglement force from the corresponding gravitational entanglement energy. Then, we provide certain entanglement diagnostics.",
        "comments": "13 Pages, Latex, 0 Figure, 0 Table, Hand conducted work. To appear in Physica Scripta (2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14342"
    },
    {
        "doc_id": 422,
        "title": "Quantum Variational Algorithms for the Allocation of Resources in a Cloud/Edge Architecture",
        "authors": [
            "Carlo Mastroianni",
            "Francesco Plastina",
            "Jacopo Settino",
            "Andrea Vinci"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks",
            "Other Condensed Matter"
        ],
        "abstract": "Modern Cloud/Edge architectures need to orchestrate multiple layers of heterogeneous computing nodes, including pervasive sensors/actuators, distributed Edge/Fog nodes, centralized data centers and quantum devices. The optimal assignment and scheduling of computation on the different nodes is a very difficult problem, with NP-hard complexity. In this paper, we explore the possibility of solving this problem with variational quantum algorithms, which can become a viable alternative to classical algorithms in the near future. In particular, we compare the performances, in terms of success probability, of two algorithms, i.e., Quantum Approximate Optimization Algorithm (QAOA) and Variational Quantum Eigensolver (VQE). The simulation experiments, performed for a set of simple problems, show that the VQE algorithm ensures better performances when it is equipped with appropriate circuit ansatzes that are able to restrict the search space. Moreover, experiments executed on real quantum hardware show that the execution time, when increasing the size of the problem, grows much more slowly than the trend obtained with classical computation, which is known to be exponential.",
        "comments": "14 pages, 13 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14339"
    },
    {
        "doc_id": 423,
        "title": "Momentum, energy and vorticity balances in deep-water surface gravity waves",
        "authors": [
            "Aidan Blaser",
            "Rapha\u00ebl Benamran",
            "A. Bia Villas B\u00f4as",
            "Luc Lenain",
            "Nick Pizzo"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "The particle trajectories in irrotational, incompressible and inviscid deep-water surface gravity waves are open, leading to a net drift in the direction of wave propagation commonly referred to as the Stokes Drift, which is responsible for catalysing surface wave-induced mixing in the ocean and transporting marine debris. A balance between phase-averaged momentum density, kinetic energy density and vorticity for irrotational, monochromatic and periodic two-dimensional water waves is derived by working directly within the Lagrangian reference frame, which tracks particle trajectories as a function of their labels and time. This balance should be expected as all three of these quantities are conserved following particles in this system. Vorticity in particular is always conserved along particles in two-dimensional inviscid flow, and as such even in its absence it is the value of the vorticity which fundamentally sets the drift, which in the Lagrangian frame is identified as the phase-averaged momentum density of the system. A relationship between the drift and the geometric mean water level of particles is found at the surface and applications for potential new ways of inferring drift are discussed. Finally, an example of an initially quiescent fluid driven by a wavelike pressure disturbance is considered, showing how the net momentum and energy from the surface disturbance transfer to the wave field, recognizing the source of the mean Lagrangian drift as the net momentum required to generate an irrotational surface wave by any conservative force.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14334"
    },
    {
        "doc_id": 424,
        "title": "Rotating effects on the photoionization cross-section of a 2D quantum ring",
        "authors": [
            "Carlos Magno O. Pereira",
            "Frankbelson dos S. Azevedo",
            "Lu\u00eds Fernando C. Pereira",
            "Edilberto O. Silva"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics",
            "Quantum Physics"
        ],
        "abstract": "In this letter, we investigate the nonrelativistic quantum motion of a charged particle within a rotating frame, taking into account the Aharonov-Bohm (AB) effect and a uniform magnetic field. Our analysis entails the derivation of the equation of motion and the corresponding radial equation to describe the system. Solving the resulting radial equation enables us to determine the eigenvalues and eigenfunctions, providing a clear expression for the energy levels. Furthermore, our numerical analysis highlights the substantial influence of rotation on both energy levels and optical properties. Specifically, we evaluate the photoionization cross-section (PCS) with and without the effects of rotation. To elucidate the impact of rotation on the photoionization process of the system, we present graphics that offer an appealing visualization of the intrinsic nature of the physics involved.",
        "comments": "6 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14333"
    },
    {
        "doc_id": 425,
        "title": "Tripartite entanglement and tripartite steering in three-qubit pure states induced by vacuum-one-photon superpositions",
        "authors": [
            "Jian Wang",
            "Huan Liu",
            "Xue-feng Zhan",
            "Xue-xiang Xu"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Utilizing a tritter with variable parameter $T$ and induced by vacuum-one-photon superpositions $\\left\\vert 0\\right\\rangle +\u03b1\\left\\vert 1\\right\\rangle $ with $\u03b1=\\left\\vert \u03b1\\right\\vert e^{i\u03c6}$, we generate a class of three-qubit pure states. These states take the form of $\\left\\vert \u03c8\\right\\rangle _{123}=c_{0}\\left\\vert 000\\right\\rangle +c_{1}\\left\\vert 100\\right\\rangle +c_{2}\\left\\vert 010\\right\\rangle +c_{3}\\left\\vert 001\\right\\rangle $. The coefficients ($ c_{0}$, $c_{1}$, $c_{2}$, and $c_{3}$) can be manipulated through interaction parameters ($\\left\\vert \u03b1\\right\\vert $, $\u03c6$, and $T$). In line with Xie and Eberly's work[Phys. Rev. Lett. 127, 040403 (2021)], we investigate the genuine tripartite entanglement for $\\left\\vert \u03c8\\right\\rangle _{123}$ using the concurrence triangle measure. Drawing on Hao et al.'s research [Phys. Rev. Lett. 128, 120402 (2021)], we examine tripartite steering for $\\left\\vert \u03c8\\right\\rangle _{123}$ under certain measurements based on the uncertainty relations criterion. We identify nine potential configurations exhibiting varying steerability across different parameter spaces. It is important to highlight that while the state $% \\left\\vert \u03c8\\right\\rangle _{123}$ exhibits entanglement, steering remains unattainable in a substantial portion of the parameter space.",
        "comments": "10 pages, 8 figures, comments are welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14328"
    },
    {
        "doc_id": 426,
        "title": "Practical Phase-Space Electronic Hamiltonians for Ab Initio Dynamics",
        "authors": [
            "Zhen Tao",
            "Tian Qiu",
            "Mansi Bhati",
            "Xuezhi Bian",
            "Titouan Duston",
            "Jonathan Rawlinson",
            "Robert G. Littlejohn",
            "Joseph E. Subotnik"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Modern electronic structure theory is built around the Born-Oppenheimer approximation and the construction of an electronic Hamiltonian H_{el}(X) that depends on the nuclear position X (and not the nuclear momentum P). In this article, using the well-known theory of electron translation (Gamma') and rotational (Gamma'') factors to couple electronic transitions to nuclear motion, we construct a practical phase-space electronic Hamiltonian that depends on both nuclear position and momentum, H_{PS}(X,P). While classical Born-Oppenheimer dynamics that run along the eigensurfaces of the operator H_{el}(X) can recover many nuclear properties correctly, we present some evidence that motion along the eigensurfaces of H_{PS}(X,P) can better capture both nuclear and electronic properties (including the elusive electronic momentum studied by Nafie). Moreover, only the latter (as opposed to the former) conserves the total linear and angular momentum in general.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14327"
    },
    {
        "doc_id": 427,
        "title": "Radiative corrections to di-meson tau decays",
        "authors": [
            "Alejandro Miranda"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We review radiative corrections to tau decays into two mesons discussing their impact in new physics searches.",
        "comments": "5 pages, 1 figure. Accepted for publication in the proceedings of the HADRON 2023 Conference, Genova, Italy, 5-9 June 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14326"
    },
    {
        "doc_id": 428,
        "title": "Invisible neutrino decay at long-baseline neutrino oscillation experiments",
        "authors": [
            "Christoph A. Ternes",
            "Giulia Pagliaroli"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We perform an updated analysis of long-baseline accelerator data in the framework of neutrino oscillations in presence of invisible neutrino decay. We analyze data from T2K, NOvA and MINOS/MINOS+ and show that the combined analysis of all experiments improves the previous bound from long-baseline data by approximately one order of magnitude.",
        "comments": "v1: 7 pages, 2 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14316"
    },
    {
        "doc_id": 429,
        "title": "MultiTest: Physical-Aware Object Insertion for Testing Multi-sensor Fusion Perception Systems",
        "authors": [
            "Xinyu Gao",
            "Zhijie Wang",
            "Yang Feng",
            "Lei Ma",
            "Zhenyu Chen",
            "Baowen Xu"
        ],
        "subjects": [
            "Software Engineering"
        ],
        "abstract": "Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms. With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems. Similar to traditional software, adequate testing is also required for AI-enabled MSF systems. Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-/point cloud-based object detection systems). There remains a lack of emphasis on generating multi-modal test cases for MSF systems. To address these limitations, we design and implement MultiTest, a fitness-guided metamorphic testing method for complex MSF perception systems. MultiTest employs a physical-aware approach to synthesize realistic multi-modal object instances and insert them into critical positions of background images and point clouds. A fitness metric is designed to guide and boost the test generation process. We conduct extensive experiments with five SOTA perception systems to evaluate MultiTest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement. The results show that MultiTest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test. Moreover, retraining an MSF system on the test cases generated by MultiTest can improve the system's robustness.",
        "comments": "The first two authors contributed equally. To appear in the proceedings of the 46th International Conference on Software Engineering (ICSE 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14314"
    },
    {
        "doc_id": 430,
        "title": "Temperature Separation in a Vortex Tube and Solar Convection",
        "authors": [
            "Haibin Chen",
            "Rong Wu"
        ],
        "subjects": [
            "Fluid Dynamics",
            "Astrophysics of Galaxies"
        ],
        "abstract": "Why does the temperature gradient within a vortex tube deviate significantly from the adiabatic gradient is an important but unresolved issue. A new theory from solar physics suggests that the vorticity gradient, like the temperature gradient, can suppress or promote convection depending on the conditions, causing the temperature gradient to deviate significantly from or approach the adiabatic gradient. The gas near the wall has a very high vorticity, which can provide a large buoyancy force, driving some fluid parcels to undergo multiple collisions and reach near the axis, achieving temperature separation.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14313"
    },
    {
        "doc_id": 431,
        "title": "Theory of Acoustic Polarons in the Two-Dimensional SSH Model Applied to the Layered Superatomic Semiconductor Re6Se8Cl2",
        "authors": [
            "Petra Shih",
            "Timothy C. Berkelbach"
        ],
        "subjects": [
            "Materials Science",
            "Chemical Physics"
        ],
        "abstract": "Layered superatomic semiconductors, whose buildings blocks are atomically precise molecular clusters, exhibit interesting electronic and vibrational properties. In recent work [Science 382, 438 (2023)], transient reflection microscopy revealed quasi-ballistic exciton dynamics in Re6Se8Cl2, which was attributed to the formation of polarons due to coupling with acoustic phonons. Here, we characterize the electronic, excitonic, and phononic properties with periodic density functional theory. We further parameterize a polaron Hamiltonian with nonlocal [Su-Schrieffer-Heeger (SSH)] coupling to acoustic phonon to study the polaron ground state binding energy and dispersion relation with variational wavefunctions. We calculate a polaron binding energy of about 10 meV at room temperature, and the maximum group velocity of our polaron dispersion relation is 1.5 km/s, which is similar to the experimentally observed exciton transport velocity.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14312"
    },
    {
        "doc_id": 432,
        "title": "Higher categories",
        "authors": [
            "Rune Haugseng"
        ],
        "subjects": [
            "Category Theory",
            "Algebraic Topology"
        ],
        "abstract": "Invited contribution to the Encyclopedia of Mathematical Physics. We give an introduction to the homotopical theory of higher categories, focused on motivating the definitions of the basic objects, namely $\\infty$-categories and $(\\infty,n)$-categories.",
        "comments": "33 pages; contribution to Encyclopedia of Mathematical Physics, 2nd ed",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14311"
    },
    {
        "doc_id": 433,
        "title": "Andr\u00e9-Quillen cohomology in the context of curved algebras",
        "authors": [
            "Joan Bellier-Mill\u00e8s",
            "Sinan Yalin"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "K-Theory and Homology",
            "Symplectic Geometry"
        ],
        "abstract": "The Andr\u00e9-Quillen cohomology of an algebra with coefficients in a module is defined by deriving a functor based on K\u00e4hler differential forms. It can be computed using a cofibrant resolution of the algebra in a model category structure where weak equivalences are quasi-isomorphisms. This construction works for algebras over an operad, providing a cohomology theory tailored for each type of algebra. For curved algebras however, the notion of quasi-isomorphism is meaningless. The occurrence and importance of curved structures in various research topics (symplectic topology, deformation theory, derived geometry, mathematical physics) motivate the development of their homotopy theory and Andr\u00e9-Quillen cohomology theory. To get a homotopical context with an appropriate notion of weak equivalence, we consider filtered complete modules with a predifferential inducing a differential on the associated graded. Curved algebras in such modules are algebras over a curved operad. In this article, we consider curved operads which are not necessarily augmented. Bar and cobar constructions adapted to these curved operads are developed, as well as Koszul duality theory. Consequently, we obtain homotopy versions of our curved algebras and make it explicit for interesting cases. Two main examples are the curved operads encoding curved unital associative algebras and curved complex Lie algebras. In particular, homotopy curved unital associative algebras describe the structure of Floer complexes of lagrangian submanifolds and Fukaya categories in symplectic topology. Bar and cobar constructions for curved algebras are also developed, and we obtain resolutions from which we compute their Andr\u00e9-Quillen cohomology with module coefficients. Our computations in the case of curved complex Lie algebras reveal an interesting link between their Andr\u00e9-Quillen cohomology and derived complex analytic geometry.",
        "comments": "78 pages, comments welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14309"
    },
    {
        "doc_id": 434,
        "title": "The soaring kite: a tale of two punctured tori",
        "authors": [
            "Mathieu Giroux",
            "Andrzej Pokraka",
            "Franziska Porkert",
            "Yoann Sohnle"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "High Energy Physics - Phenomenology",
            "Mathematical Physics"
        ],
        "abstract": "We consider the 5-mass kite family of self-energy Feynman integrals and present a systematic approach for constructing an epsilon-form basis, along with its differential equation pulled back onto the moduli space of two tori. Each torus is associated with one of the two distinct elliptic curves this family depends on. We demonstrate how the locations of relevant punctures, which are required to parametrize the full image of the kinematic space onto this moduli space, can be extracted from integrals over maximal cuts. A boundary value is provided such that the differential equation is systematically solved in terms of iterated integrals over g-kernels and modular forms. Then, the numerical evaluation of the master integrals is discussed, and important challenges in that regard are emphasized. In an appendix, we introduce new relations between g-kernels.",
        "comments": "59 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14307"
    },
    {
        "doc_id": 435,
        "title": "$\u03bde\\to\u03bde$ scattering with massive Dirac or Majorana neutrinos and general interactions",
        "authors": [
            "Juan Manuel M\u00e1rquez",
            "Pablo Roig",
            "M\u00f3nica Salinas"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We calculate the neutrino-electron elastic scattering cross section, extending the results previously obtained in arXiv:1702.05721v2, in the presence of generic new interactions that take into account all the effects caused by finite neutrino masses. We address the potential significance of a heavy neutrino sector during precision measurements, particularly for tau neutrinos scattering with masses in the MeV range, for which the existing upper bounds on $|U_{\u03c44}|^2$ would result in conceivably measurable contributions. Finally, we comment on the possibility to distinguish between Dirac and Majorana neutrinos, including the analysis of the new emerging parameters and its application to illustrative model-dependent scenarios.",
        "comments": "22 pages, 1 figure",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14305"
    },
    {
        "doc_id": 436,
        "title": "Correlation function and the inverse problem in the $BD$ interaction",
        "authors": [
            "Hai-Peng Li",
            "Jing-Yu Yi",
            "Chu-Wen Xiao",
            "De-Liang Yao",
            "Wei-Hong Liang",
            "Eulogio Oset"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "We carry a study of the correlation functions of the $B^0 D^+, B^+ D^0$ system, which develops a bound state by about $40$ MeV, using input consistent with the $T_{cc}(3875)$ state. Then we face the inverse problem of starting from these correlation functions to determine scattering observables related to the system, including the existence of the bound state and its molecular nature. The important output of the approach is the uncertainty by which these observables can be obtained, assuming errors in the $B^0 D^+, B^+ D^0$ correlation functions typical of current ones in present correlation functions. We observe that it is possible to obtain scattering lengths and effective ranges with relative high precision and the existence of a bound state. While the pole position is obtained with errors of the order of $50 \\%$ of the binding energy, the molecular probability of the state is obtained with a very small error of the order of $6\\%$. All these findings can serve as motivation to perform such measurements in future runs of high energy hadron collisions.",
        "comments": "16 pages, 3 figures, 7 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14302"
    },
    {
        "doc_id": 437,
        "title": "Amorphous silicon detectors for proton beam monitoring in FLASH radiotherapy",
        "authors": [
            "Nicolas Wyrsch",
            "Luca Antognini",
            "Christophe Ballif",
            "Saverio Braccini",
            "Pierluigi Casolaro",
            "Sylvain Dunand",
            "Alexander Gottstein",
            "Matt Large",
            "Isidre Mateu",
            "Jonathan Thomet"
        ],
        "subjects": [
            "High Energy Physics - Experiment",
            "Materials Science"
        ],
        "abstract": "Ultra-high dose rate radiation therapy (FLASH) based on proton irradiation is of major interest for cancer treatments but creates new challenges for dose monitoring. Amorphous hydrogenated silicon is known to be one of the most radiation-hard semiconductors. In this study, detectors based on this material are investigated at proton dose rates similar to or exceeding those required for FLASH therapy. Tested detectors comprise two different types of contacts, two different thicknesses deposited either on glass or on polyimide substrates. All detectors exhibit excellent linear behaviour as a function of dose rate up to a value of 20 kGy/s. Linearity is achieved independently of the depletion condition of the device and remarkably in passive (unbiased) conditions. The degradation of the performance as a function of the dose rate and its recovery are also discussed.",
        "comments": "16 pages, 9 figures, presented at 29th Internation Conference on Solid-State Dosimetry, 2023",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14300"
    },
    {
        "doc_id": 438,
        "title": "The overlooked significance of the unbiased exponential phasefactor in the determination of the finite-density lattice QCD equation of state",
        "authors": [
            "Sabarnya Mitra"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "High Energy Physics - Phenomenology",
            "Nuclear Experiment",
            "Nuclear Theory"
        ],
        "abstract": "Within the framework of (2+1)-flavor QCD at finite temperature and chemical potential, we present results using high statistics data and demonstrate how the phasefactor of low order unbiased exponential resummation offers excellent prediction, proving to be an alternative reliable estimator of the radius of convergence of the eighth order QCD Taylor series at finite baryon density measured using the ratio and the Merci-Roberts estimators. We construct a new non-trivial unbiased phasefactor for complex isospin chemical potentials $\\muI$ and highlight its novelty. We find that this new unbiased phasefactor is very much capable of indicating the onset of non-monotonicity in finite $\\muI$ thermodynamics, which we illustrate by comparing the phasefactor results with that of low order cumulants of $\\muI$ fluctuations for non-vanishing $\\muI$. We also furnish results establishing that this unbiased phasefactor is reliable in manifesting the beginning of the overlap problem for finite, real $\\muI$. The errorbars increase drastically across the indications provided by the phasefactor which becomes very apparent from the coincidence between the phasefactor and the maximum of the errorbar slopes.",
        "comments": "9 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14299"
    },
    {
        "doc_id": 439,
        "title": "Characterising the Haar measure on the $p$-adic rotation groups via inverse limits of measure spaces",
        "authors": [
            "Paolo Aniello",
            "Sonia L'Innocente",
            "Stefano Mancini",
            "Vincenzo Parisi",
            "Ilaria Svampa",
            "Andreas Winter"
        ],
        "subjects": [
            "Mathematical Physics",
            "Functional Analysis",
            "Group Theory",
            "Number Theory"
        ],
        "abstract": "We determine the Haar measure on the compact $p$-adic special orthogonal groups of rotations $\\mathrm{SO}(d)_p$ in dimension $d=2,3$, by exploiting the machinery of inverse limits of measure spaces, for every prime $p>2$. We characterise $\\mathrm{SO}(d)_p$ as inverse limits of finite groups, of which we provide parametrisations and orders, together with an equivalent description through a multivariable Hensel lifting. Supplying these finite groups with their normalised counting measures, we get an inverse family of Haar measure spaces for each $\\mathrm{SO}(d)_p$. Finally, we constructively prove the existence of the so-called inverse limit measure of these inverse families, which is explicitly computable, and prove that it gives the Haar measure on $\\mathrm{SO}(d)_p$. Our results pave the way towards the study of the irreducible projective unitary representations of the $p$-adic rotation groups, with potential applications to the recently proposed $p$-adic quantum information theory.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14298"
    },
    {
        "doc_id": 440,
        "title": "The three-pion $K$-matrix at NLO in ChPT",
        "authors": [
            "Jorge Baeza-Ballesteros",
            "Johan Bijnens",
            "Tom\u00e1\u0161 Husek",
            "Fernando Romero-L\u00f3pez",
            "Stephen R. Sharpe",
            "Mattias Sj\u00f6"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Lattice",
            "Nuclear Theory"
        ],
        "abstract": "The three-particle $K$-matrix, $\\mathcal{K}_{\\mathrm{df},3}$, is a scheme-dependent quantity that parametrizes short-range three-particle interactions in the relativistic-field-theory three-particle finite-volume formalism. In this work, we compute its value for systems of three pions in all isospin channels through next-to-leading order in Chiral Perturbation Theory, generalizing previous work done at maximum isospin. We obtain analytic expressions through quadratic order (or cubic order, in the case of zero isospin) in the expansion about the three-pion threshold.",
        "comments": "44 pages, 8 figures, 10 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14293"
    },
    {
        "doc_id": 441,
        "title": "Quantum Electrometer for Time-Resolved Material Science at the Atomic Lattice Scale",
        "authors": [
            "Gregor Pieplow",
            "Cem G\u00fcney Torun",
            "Joseph H. D. Munns",
            "Franziska Marie Herrmann",
            "Andreas Thies",
            "Tommaso Pregnolato",
            "Tim Schr\u00f6der"
        ],
        "subjects": [
            "Applied Physics",
            "Materials Science",
            "Quantum Physics"
        ],
        "abstract": "The detection of individual charges plays a crucial role in fundamental material science and the advancement of classical and quantum high-performance technologies that operate with low noise. However, resolving charges at the lattice scale in a time-resolved manner has not been achieved so far. Here, we present the development of an electrometer, leveraging on the spectroscopy of an optically-active spin defect embedded in a solid-state material with a non-linear Stark response. By applying our approach to diamond, a widely used platform for quantum technology applications, we successfully localize charge traps, quantify their impact on transport dynamics and noise generation, analyze relevant material properties, and develop strategies for material optimization.",
        "comments": "Main: 9 pages, 5 figures; Supplement: 14 pages, 10 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14290"
    },
    {
        "doc_id": 442,
        "title": "How far can we see back in time in high-energy collisions using charm quarks?",
        "authors": [
            "Laszlo Gyulai",
            "Gabor Biro",
            "Robert Vertesi",
            "Gergely Gabor Barnafoldi"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We use open charm production to estimate how far we can see back in time in high-energy hadron-hadron collisions. We analyze the transverse momentum distributions of the identified D mesons from pp, p-Pb and A-A collisions at the ALICE and STAR experiments covering the energy range from $\\sqrt{s_{\\rm NN}} = 200$ GeV up to 7 TeV. Within a non-extensive statistical framework, the common Tsallis parameters for D mesons represent higher temperature and more degrees of freedom than that of light-flavour hadrons. The production of D mesons corresponds to a significantly earlier proper time, $\u03c4_{\\rm D} = (0.18 \\pm 0.06) \u03c4_{\\rm LF}$.",
        "comments": "18 pages, 6 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14282"
    },
    {
        "doc_id": 443,
        "title": "Bifurcation of Dividing Surfaces Constructed from Period-Doubling Bifurcations of Periodic Orbits in a Caldera Potential Energy Surface",
        "authors": [
            "Matthaios Katsanikas",
            "Makrina Agaoglou",
            "Stephen Wiggins"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Dynamical Systems",
            "Chemical Physics"
        ],
        "abstract": "In this work we analyze the bifurcation of dividing surfaces that occurs as a result of two period-doubling bifurcations in a 2D caldera-type potential. We study the structure, the range, the minimum and maximum extents of the periodic orbit dividing surfaces before and after a subcritical period-doubling bifurcation of the family of the central minimum of the potential energy surface. Furthermore, we repeat the same study for the case of a supercritical perioddoubling bifurcation of the family of the central minimum of the potential energy surface. We will discuss and compare the results for the two cases of bifurcations of dividing surfaces.",
        "comments": "15 pages. arXiv admin note: text overlap with arXiv:2107.09623",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14275"
    },
    {
        "doc_id": 444,
        "title": "Viscoelasticty with physics-augmented neural networks: Model formulation and training methods without prescribed internal variables",
        "authors": [
            "Max Rosenkranz",
            "Karl A. Kalina",
            "J\u00f6rg Brummund",
            "WaiChing Sun",
            "Markus K\u00e4stner"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science"
        ],
        "abstract": "We present an approach for the data-driven modeling of nonlinear viscoelastic materials at small strains which is based on physics-augmented neural networks (NNs) and requires only stress and strain paths for training. The model is built on the concept of generalized standard materials and is therefore thermodynamically consistent by construction. It consists of a free energy and a dissipation potential, which can be either expressed by the components of their tensor arguments or by a suitable set of invariants. The two potentials are described by fully/partially input convex neural networks. For training of the NN model by paths of stress and strain, an efficient and flexible training method based on a recurrent cell, particularly a long short-term memory cell, is developed to automatically generate the internal variable(s) during the training process. The proposed method is benchmarked and thoroughly compared with existing approaches. These include a method that obtains the internal variable by integrating the evolution equation over the entire sequence, while the other method uses an an auxiliary feedforward neural network for the internal variable(s). Databases for training are generated by using a conventional nonlinear viscoelastic reference model, where 3D and 2D plane strain data with either ideal or noisy stresses are generated. The coordinate-based and the invariant-based formulation are compared and the advantages of the latter are demonstrated. Afterwards, the invariant-based model is calibrated by applying the three training methods using ideal or noisy stress data. All methods yield good results, but differ in computation time and usability for large data sets. The presented training method based on a recurrent cell turns out to be particularly robust and widely applicable and thus represents a promising approach for the calibration of other types of models as well.",
        "comments": "21 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14270"
    },
    {
        "doc_id": 445,
        "title": "Phenomenology of TMD parton distributions in Drell-Yan and $Z^0$ boson production in a hadron structure oriented approach",
        "authors": [
            "F. Aslan",
            "M. Boglione",
            "J. O. Gonzalez-Hernandez",
            "T. Rainaldi",
            "T. C. Rogers",
            "A. Simonelli"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We present a first practical implementation of a recently proposed hadron structure oriented (HSO) approach to TMD phenomenology applied to Drell-Yan like processes, including lepton pair production at moderate $Q^2$ and $Z^0$ boson production. We compare and contrast general features of our methodology with other common practices and emphasize the improvements derived from our approach that we view as essential for applications where extracting details of nonperturbative transverse hadron structure is a major goal. These include the HSO's preservation of a basic TMD parton-model-like framework even while accounting for full TMD factorization and evolution, explicit preservation of the integral relationship between TMD and collinear pdfs, and the ability to meaningfully compare different theoretical models of nonperturbative TMD parton distributions. In our examples, we show that there is significant sensitivity at moderate $Q^2$ to both the form of the nonperturbative transverse momentum dependence and the parametrization of collinear parton densities. However, we also find that evolving to $Q^2 = M_Z^2$, without fitting, results in a satisfactory postdiction of existing data for $Z^0$ production, nearly independently of the modeling of nonperturbative transverse momentum behavior. We argue that this demonstrates that moderate $Q$ measurements should be given greater weight than high $Q$ measurements in extractions of nonperturbative transverse momentum dependence. We also obtain new extractions of the nonperturbative Collins-Soper kernel within the HSO approach. We discuss its features and compare with some earlier extractions.",
        "comments": "33 pages, 9 figures, 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14266"
    },
    {
        "doc_id": 446,
        "title": "Existence and characterization of edge states in an acoustic trimer Su-Schrieffer-Heeger model",
        "authors": [
            "I. Ioannou Sougleridis",
            "A. Anastasiadis",
            "O. Richoux",
            "V. Achilleos",
            "G. Theocharis",
            "V. Pagneux",
            "F. K. Diakonos"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "We report on a direct mapping of acoustic slender waveguides to the one dimensional trimer Su- Schrieffer-Heeger model, with neither chiral nor mirror symmetry. Importantly, we can choose to perform this mapping for either the acoustic velocity or pressure. We demonstrate that, for finite systems, this choice is necessarily linked to the boundary conditions. It allows for the unveiling of the edge states of the acoustic system through an edge state phase diagram. An experimental realization of our setup in the audible regime corroborates our theoretical predictions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14264"
    },
    {
        "doc_id": 447,
        "title": "Room temperature nonlocal detection of charge-spin interconversion in a topological insulator",
        "authors": [
            "Anamul Md. Hoque",
            "Lars Sj\u00f6str\u00f6m",
            "Dmitrii Khokhriakov",
            "Bing Zhao",
            "Saroj P. Dash"
        ],
        "subjects": [
            "Mesoscale and Nanoscale Physics"
        ],
        "abstract": "Topological insulators (TIs) are emerging materials for next-generation low-power nanoelectronic and spintronic device applications. TIs possess non-trivial spin-momentum locking features in the topological surface states in addition to the spin-Hall effect (SHE), and Rashba states due to high spin-orbit coupling (SOC) properties. These phenomena are vital for observing the charge-spin conversion (CSC) processes for spin-based memory, logic and quantum technologies. Although CSC has been observed in TIs by potentiometric measurements, reliable nonlocal detection has so far been limited to cryogenic temperatures up to T = 15 K. Here, we report nonlocal detection of CSC and its inverse effect in the TI compound Bi1.5Sb0.5Te1.7Se1.3 at room temperature using a van der Waals heterostructure with a graphene spin-valve device. The lateral nonlocal device design with graphene allows observation of both spin-switch and Hanle spin precession signals for generation, injection and detection of spin currents by the TI. Detailed bias- and gate-dependent measurements in different geometries prove the robustness of the CSC effects in the TI. These findings demonstrate the possibility of using topological materials to make all-electrical room-temperature spintronic devices.",
        "comments": "12 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14262"
    },
    {
        "doc_id": 448,
        "title": "Conservation laws and the foundations of quantum mechanics",
        "authors": [
            "Yakir Aharonov",
            "Sandu Popescu",
            "Daniel Rohrlich"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "In a recent paper, PNAS, 118, e1921529118 (2021), it was argued that while the standard definition of conservation laws in quantum mechanics, which is of a statistical character, is perfectly valid, it misses essential features of nature and it can and must be revisited to address the issue of conservation/non-conservation in individual cases. Specifically, in the above paper an experiment was presented in which it can be proven that in some individual cases energy is not conserved, despite being conserved statistically. It was felt however that this is worrisome, and that something must be wrong if there are individual instances in which conservation doesn't hold, even though this is not required by the standard conservation law. Here we revisit that experiment and show that although its results are correct, there is a way to circumvent them and ensure individual case conservation in that situation. The solution is however quite unusual, challenging one of the basic assumptions of quantum mechanics, namely that any quantum state can be prepared, and it involves a time-holistic, double non-conservation effect. Our results bring new light on the role of the preparation stage of the initial state of a particle and on the interplay of conservation laws and frames of reference. We also conjecture that when such a full analysis of any conservation experiment is performed, conservation is obeyed in every individual case.",
        "comments": "Journal ref:        PNAS, 120 (41) e2220810120 (2023)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14261"
    },
    {
        "doc_id": 449,
        "title": "Stability and Transport of Gyrokinetic Critical Pedestals",
        "authors": [
            "J. F. Parisi",
            "A. O. Nelson",
            "W. Guttenfelder",
            "R. Gaur",
            "J. W. Berkery",
            "S. M. Kaye",
            "K. Barada",
            "C. Clauser",
            "A. Diallo",
            "D. R. Hatch",
            "A. Kleiner",
            "M. Lampert",
            "T. Macwan",
            "J. E. Menard"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "A gyrokinetic threshold model for pedestal width-height scaling prediction is applied to multiple devices and to a shaping and aspect-ratio scan giving $\u0394_{\\mathrm{ped}} = 0.92 A^{1.04} \u03ba^{-1.24} 0.38^\u03b4 \u03b2_{\u03b8,\\mathrm{ped}}^{1.05}$ for pedestal width $\u0394_{\\mathrm{ped}}$, aspect-ratio $A$, elongation $\u03ba$, triangularity $\u03b4$, and normalized pedestal height $\u03b2_{\u03b8,\\mathrm{ped}}$. We also find a width-transport scaling $\u0394_{\\mathrm{ped} } = 0.028 \\left(q_e/\u0393_e - 1.7 \\right)^{1.5} \\sim \u03b7_e ^{1.5}$ where $q_e$ and $\u0393_e$ are turbulent electron heat and particle fluxes and $\u03b7_e = \\nabla \\ln T_e / \\nabla \\ln n_e$ for electron temperature $T_e$ and density $n_e$. Pedestals close to those limited by kinetic-ballooning-modes (KBMs) have modified turbulent transport properties compared to strongly driven KBMs. The role of flow shear is studied as a width-height scaling constraint and pedestal saturation mechanism for a standard and wide pedestal discharge.",
        "comments": "34 pages, 16 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14260"
    },
    {
        "doc_id": 450,
        "title": "Mpemba effects in nonequilibrium open quantum systems",
        "authors": [
            "Xuanhua Wang",
            "Jin Wang"
        ],
        "subjects": [
            "Quantum Physics",
            "Statistical Mechanics",
            "Chemical Physics"
        ],
        "abstract": "Originally, the Mpemba effect (MPE) is referred to the faster icing of a higher-temperature system than a system of a lower temperature. This concept was later generalized to anomalous decays of certain system quantities to the equilibrium states. In this study, we investigate the scenario when a system has no such equilibrium state to approach. Instead, the system is put in contact with two different baths, and only a nonequilibrium state exists, sustained by constant energy injection from the surrounding thermal baths. Firstly, we show that the nonequilibrium conditions can dramatically enlarge the parameter regimes where the MPE emerges. Secondly, we demonstrate that the anomalous MPEs and inverse MPEs emerge in the evolution of quantum correlations in the two-site fermionic system and that nonequilibrium conditions can expedite or delay the MPEs. Thirdly, we show that the nonequilibrium-induced quantum coherence can have considerable contributions to the emergence of the MPE which the conventional Lindbladian dynamics fails to capture.",
        "comments": "9 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14259"
    },
    {
        "doc_id": 451,
        "title": "On the vapour compression in cavitation bubbles",
        "authors": [
            "Davide Bernardo Preso",
            "Daniel Fuster",
            "Armand Baptiste Sieber",
            "Danail Obreschkow",
            "Mohamed Farhat"
        ],
        "subjects": [
            "Fluid Dynamics"
        ],
        "abstract": "The composition of the gaseous phase of cavitation bubbles and its role on the collapse remains to date poorly understood. In this work, experiments of single cavitation bubbles in aqueous ammonia serve as a novel approach to investigate the effect of the vapour contained in a bubble on its collapse. We find that the higher vapour pressure of more concentrated aqueous ammonia acts as a resistance to the collapse, reducing the total energy dissipation. In line with visual observation, acoustic measurements, and luminescence recordings, it is also observed that higher vapour pressures contribute to a more spherical collapse, likely hindering the growth of interface instabilities by decreasing the collapse velocities and accelerations. Remarkably, we evidence a strong difference between the effective damping and the energy of the shock emission, suggesting that the latter is not the dominant dissipation mechanism at collapse as predicted from classical correction models accounting for slightly compressible liquids. Furthermore, our results suggest that the vapour inside collapsing bubbles gets compressed, consistently with previous studies performed in the context of single bubble sonoluminescence, addressing the question about the ability of vapours to readily condense during a bubble collapse in similar regimes. These findings provide insights into the identification of the influence of the bubble content and the energy exchanges of the bubble with its surrounding media, eventually paving the way to a more efficient use of cavitation in engineering and biomedical applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14253"
    },
    {
        "doc_id": 452,
        "title": "Variational Neural and Tensor Network Approximations of Thermal States",
        "authors": [
            "Sirui Lu",
            "Giacomo Giudice",
            "J. Ignacio Cirac"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks",
            "Strongly Correlated Electrons"
        ],
        "abstract": "We introduce a variational Monte Carlo algorithm for approximating finite-temperature quantum many-body systems, based on the minimization of a modified free energy. We employ a variety of trial states -- both tensor networks as well as neural networks -- as variational ans\u00e4tze for our numerical optimization. We benchmark and compare different constructions in the above classes, both for one- and two-dimensional problems, with systems made of up to \\(N=100\\) spins. Despite excellent results in one dimension, our results suggest that the numerical ans\u00e4tze employed have certain expressive limitations for tackling more challenging two-dimensional systems.",
        "comments": "7+9 pages, 3+4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14243"
    },
    {
        "doc_id": 453,
        "title": "Short-Time Infrequent Metadynamics for Improved Kinetics Inference",
        "authors": [
            "Ofir Blumer",
            "Shlomi Reuveni",
            "Barak Hirshberg"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "Infrequent Metadynamics is a popular method to obtain the rate of long timescale processes from accelerated simulations. The inference procedure is based on rescaling the first-passage times of Metadynamics trajectories using a bias-dependent acceleration factor. While useful in many cases, it is limited to Poisson kinetics, and a reliable estimation of the unbiased rate requires slow bias deposition and prior knowledge of efficient collective variables. Here, we propose an improved inference scheme, which is based on two key observations: 1) The time-independent rate of Poisson processes can be estimated using short trajectories only. 2) Short trajectories experience minimal bias, and their rescaled first-passage times follow the unbiased distribution even for relatively high deposition rates and suboptimal collective variables. Therefore, by limiting the inference procedure to short timescales, we obtain an improved tradeoff between speedup and accuracy at no additional computational cost, especially when employing suboptimal collective variables. We demonstrate the improved inference scheme for a model system and two molecular systems.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14237"
    },
    {
        "doc_id": 454,
        "title": "Unraveling how winds and surface heat fluxes control the Atlantic Ocean's meridional heat transport",
        "authors": [
            "Dhruv Bhagtani",
            "Andrew McC. Hogg",
            "Ryan M. Holmes",
            "Navid C. Constantinou"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "The North Atlantic Ocean circulation, fueled by winds and surface buoyancy fluxes, carries 1.25$\\,$PettaWatts of heat poleward in the subtropics, and plays an important role in regulating global weather and climate patterns. Using a series of simulations with perturbed surface forcing, we study how winds and surface heat flux gradients affect the Atlantic meridional heat transport. We decompose the Atlantic meridional heat transport into contributions from circulation cells at warm and cold temperatures (resembling a subtropical gyre and the dense overturning circulation respectively), and a mixed circulation that contains water masses traversing both these cells. Variations in wind stress initially alter the amount of heat carried by the warm and mixed cells, but on long time scales ($>$10 years), changes in the temperature distribution restore the heat transport to equilibrium. Changes in surface buoyancy forcing control the cold cell's circulation, and its associated meridional heat flux, through high-latitude processes.",
        "comments": "13 pages, 3 figures, submitted to the Geophysical Research Letters",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14230"
    },
    {
        "doc_id": 455,
        "title": "Exploring the time axis within medium-modified jets",
        "authors": [
            "Liliana Apolin\u00e1rio",
            "Pablo Guerrero-Rodr\u00edguez",
            "Korinna Zapp"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "In this manuscript, we illustrate how to use the newly proposed $\u03c4$ re-clustering algorithm to select jets with different degrees of quenching without biasing their initial transverse momentum spectrum. Our study is based on Z+jet simulated events using the JEWEL Monte Carlo event generator to account for jet quenching effects. We apply the $\u03c4$ re-clustering algorithm to extract a proxy for a time axis (formation time) within the evolving medium. This information allows us to label jets according to their fragmentation pattern and select populations with enhanced sensitivity to quenching effects. Our results illustrate the potential of jets as precision tools for QGP tomography. Further, we show that the discussed method minimizes the biases stemming from $p_{T}$-, $dR$- or mass-based jet selection.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14229"
    },
    {
        "doc_id": 456,
        "title": "Periodically Forced Nonlinear Oscillatory Acoustic Vacuum",
        "authors": [
            "Makrina Agaoglou",
            "Michal Feckan",
            "Michal Pospisil",
            "Vassilis M. Rothos",
            "Alexander F. Vakakis"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "In this work, we study the in-plane oscillations of a finite lattice of particles coupled by linear springs under distributed harmonic excitation. Melnikov-type analysis is applied for the persistence of periodic oscillations of a reduced system.",
        "comments": "11 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14227"
    },
    {
        "doc_id": 457,
        "title": "On the well-posedness of inverse problems under information field theory: application to model-form error detection",
        "authors": [
            "Alex Alberts",
            "Ilias Bilionis"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "We derive properties of information field theory (IFT) as applied to inverse problems. The results here can be extended to methodologies which can be seen as limiting cases of IFT, such as Gaussian process regression and physics-informed machine learning. We first define the concept of a well-posed inverse problem within the context of IFT, and pose a few useful theorems for conditions in which an inverse problem becomes well-posed. Using the Gaussian random field interpretation of IFT, we show how identifying parameters of a covariance kernel becomes a well-posed inverse problem under certain conditions. An expression for the Hessian of the inverse problem log posterior is derived to construct the results. A specific focus is placed on the inverse problem of detecting model-form error. We provide an example where the physics are assumed to be the Poisson equation and prove conditions for which identifying model-form error in this case becomes a well-posed inverse problem under IFT.",
        "comments": "16 pages. Will be presented at SIAM Conference on Uncertainty Quantification 2024",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14224"
    },
    {
        "doc_id": 458,
        "title": "Application of performance portability solutions for GPUs and many-core CPUs to track reconstruction kernels",
        "authors": [
            "Ka Hei Martin Kwok",
            "Matti Kortelainen",
            "Giuseppe Cerati",
            "Alexei Strelchenko",
            "Oliver Gutsche",
            "Allison Reinsvold Hall",
            "Steve Lantz",
            "Michael Reid",
            "Daniel Riley",
            "Sophie Berkman",
            "Seyong Lee",
            "Hammad Ather",
            "Boyana Norris",
            "Cong Wang"
        ],
        "subjects": [
            "Accelerator Physics"
        ],
        "abstract": "Next generation High-Energy Physics (HEP) experiments are presented with significant computational challenges, both in terms of data volume and processing power. Using compute accelerators, such as GPUs, is one of the promising ways to provide the necessary computational power to meet the challenge. The current programming models for compute accelerators often involve using architecture-specific programming languages promoted by the hardware vendors and hence limit the set of platforms that the code can run on. Developing software with platform restrictions is especially unfeasible for HEP communities as it takes significant effort to convert typical HEP algorithms into ones that are efficient for compute accelerators. Multiple performance portability solutions have recently emerged and provide an alternative path for using compute accelerators, which allow the code to be executed on hardware from different vendors. We apply several portability solutions, such as Kokkos, SYCL, C++17 std::execution::par and Alpaka, on two mini-apps extracted from the mkFit project: p2z and p2r. These apps include basic kernels for a Kalman filter track fit, such as propagation and update of track parameters, for detectors at a fixed z or fixed r position, respectively. The two mini-apps explore different memory layout formats.\n  We report on the development experience with different portability solutions, as well as their performance on GPUs and many-core CPUs, measured as the throughput of the kernels from different GPU and CPU vendors such as NVIDIA, AMD and Intel.",
        "comments": "26th Intl Conf Computing High Energy & Nuclear Phys (CHEP 2023)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14221"
    },
    {
        "doc_id": 459,
        "title": "Shocks, clouds and atomic outflows in active galactic nuclei hosting relativistic jets",
        "authors": [
            "Manel Perucho"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Astrophysics of Galaxies"
        ],
        "abstract": "A number of observations have revealed atomic and/or molecular lines in active galaxies hosting jets and outflows. Line widths indicate outward motions of hundreds to few thousands of kilometers per second. They appear associated to the presence of radio emission in Gigahert-peaked spectrum (GPS) and compact steep spectrum (CSS) sources, with linear sizes < 10 kpc. Numerical simulations have shown that the bow shocks triggered by relativistic jets in their host galaxies drive ionisation and turbulence in the interstellar medium (ISM). However, the presence of atomic lines requires rapid recombination of ionised gas, which seems to be hard to explain from the physical conditions revealed so far by numerical simulations of powerful jets. The aim of this paper is to provide a global frame to explain the presence of lines in terms of jet and shock evolution, and fix the parameter space in which the atomic and molecular outflows might occur. This parameter space is inspired by numerical simulations and basic analytical models of jet evolution as a background. Our results show that a plausible, general explanation involves momentum transfer and heating to the interstellar medium gas by jet triggered shocks within the inner kiloparsecs. The presence of post-shock atomic gas is possible in the case of shocks interacting with dense clouds that remain relatively stable after the shock passage. According to our results, current numerical simulations cannot reproduce the physical conditions to explain the presence of atomic and molecular outflows in young radio-sources. However, I show that these outflows might occur in low-power jets at all scales, and predict a trend towards powerful jets showing lines at CSS scales, when clouds have cooled to recombination temperatures.",
        "comments": "Accepted for publication in Astronomy & Astrophysics",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14218"
    },
    {
        "doc_id": 460,
        "title": "The explicit form of the unitary representation of the Poincar\u00e9 group for vector-valued wave functions (massive and massless), with applications to photon's localization and position operators",
        "authors": [
            "Arkadiusz Jadczyk"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "We geometrically derive the explicit form of the Unitary representation of the Poincare group and use it to apply speed-of-light boosts to simple polarization basis to end up with Hawton-Baylis photon position operator with commuting components. We give explicit formulas for other photon boost eigenmodes. We investigate the underlying affine connections on the light cone in momentum space and find that while Pryce connection is metric semi-symmetric, the flat Hawton-Baylis connection is not semi-symmetric. Finally we discuss localizability of photon states localized on closed loops and show that photon states on the circle, both unnormalized improper states and finite norm wave packet smeared over washer-like regions are strictly localized with respect to Hawton-Baylis operators with commuting components and also with respect to the noncommutative Jauch-Piron-Amrein POV measure.",
        "comments": "30 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14217"
    },
    {
        "doc_id": 461,
        "title": "At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition",
        "authors": [
            "Ashok Dahal",
            "Rapha\u00ebl Huser",
            "Luigi Lombardo"
        ],
        "subjects": [
            "Machine Learning",
            "Geophysics",
            "Applications",
            "Machine Learning"
        ],
        "abstract": "The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple return periods. We also use our model to further explore landslide hazard for the same return periods under different climate change scenarios up to the end of the century. Our results show that the proposed model performs excellently and can be used to model landslide hazard in a unified manner. Geomorphologically, we find that under both climate change scenarios (SSP245 and SSP885), landslide hazard is likely to increase up to two times on average in the lower Himalayan regions while remaining the same in the middle Himalayan region whilst decreasing slightly in the upper Himalayan region areas.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14210"
    },
    {
        "doc_id": 462,
        "title": "Quantum information recovery from black hole with projective measurement",
        "authors": [
            "Ran Li",
            "Jin Wang"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Theory",
            "Quantum Physics"
        ],
        "abstract": "We studied the Hayden-Preskill thought experiment with the local projective measurement. Compared to the original model, the measurement is applied on the Hawking radiation that was emitted after throwing the quantum diary into the black hole. Within this setup, we explored various aspects of this model, including the information recovery from the black hole, the relation to the black hole final state proposal, the relation between the Yoshida-Kitaev protocol and Petz recovery map, the effects of the decoherence, and the quantum simulations of the decoding protocols. These aspects may provide us new insights into the non-perturbative nature of quantum black holes.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14207"
    },
    {
        "doc_id": 463,
        "title": "Experimental investigations of underwater and airborne noises produced by a large hovercraft in Ural River estuary",
        "authors": [
            "A. I. Vedenev",
            "O. Yu. Kochetov",
            "A. A. Lunkov",
            "A. S. Shurup",
            "S. S. Kassymbekova"
        ],
        "subjects": [
            "Atmospheric and Oceanic Physics"
        ],
        "abstract": "Simultaneous measurements of underwater and airborne noises produced by Griffon Hoverwork BHT130 hovercraft were carried out in environmentally sensitive area - wildlife preserve in the area of the Ural River estuary near the Caspian Sea shelf. Measurements were organized to assess the possible negative impact of noise from hovercraft on fish and birds in wildlife preserve. The particle velocity of underwater noise was estimated by using a gradient-type vector receiver. That was a distinctive aspect of the underwater noise studies since the majority of fish perceives the sound in terms of vibration of particles, and only a few as the pressure. Using synchronous recording of underwater and airborne noises, the mutual correlation of these data was investigated. The obtained correlation levels between underwater and airborne noises produced by hovercraft can be used for simplified estimation of the upper boundary of underwater noise level by measuring levels of airborne noise. The measured and estimated maximal levels of underwater noises of hovercraft are considerably lower than noises from conventional vessels with underwater engines, that makes hovercraft attractive alternative for use in locations with high underwater noise requirements, such as Ural River estuary and Caspian Sea shelf.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14204"
    },
    {
        "doc_id": 464,
        "title": "Investigating Organic Carbon and Thermal History of CM Carbonaceous Chondrites Using Spectroscopy and Laboratory Techniques",
        "authors": [
            "Safoura Tanbakouei",
            "Rui-Lin Cheng",
            "Binlong Ye",
            "Josep Ryan Michalski",
            "Ashley J. King"
        ],
        "subjects": [
            "Earth and Planetary Astrophysics",
            "Instrumentation and Methods for Astrophysics",
            "Geophysics"
        ],
        "abstract": "The CM chondrites are characterized as primary accretionary rocks which originate from primitive water-rich asteroids formed during the early Solar System. Here, we study the mineralogy and organic characteristics of right CM and one ungrouped chondrite to better understand their alteration history; Queen Alexandra Range 93005 (QUE 93005), Murchison, LaPaz Icefield 02333 (LAP 02333), Miller Range (MIL 13005), Mackay Glacier 05231 (MCY 05231), Northwest Africa 8534 (NWA 8534), Northwest Africa 3340 (NWA 3340), Yamato 86695 (Y-86695), and the ungrouped carbonaceous chondrite Belgica 7904 (B-7904). Raman spectroscopy has been employed to detect the presence of organic carbon in the samples, specifically through the G band at approximately 1580 cm-1 and D band at around 1350 cm-1. The properties of organic matter in meteorites serve as valuable indicators for characterizing the structure and crystallinity of carbonaceous materials and estimating their thermal metamorphism degree. The R1 parameter, defined as the peak height ratio of the D and G bands, provides a quantifiable measure of this structural organization. Raman spectra are used to show the general mineralogy, thermal history and heating stage of CM and ungrouped chondrites. X-ray diffraction patterns further indicate the mineralogical compositions of the samples. Visible to near-infrared (VNIR) and attenuated total reflection (ATR) reflectance spectra illustrate the trends related to their mineralogy and furthermore infer aqueous alteration, thermal history of CM carbonaceous chondrites, formation and evolution of their parent bodies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14201"
    },
    {
        "doc_id": 465,
        "title": "Speeding up Fermionic Lattice Calculations with Photonic Accelerated Inverters",
        "authors": [
            "Felipe Attanasio",
            "Marc Bauer",
            "Jelle Dijkstra",
            "Timoteo Lee",
            "Jan M. Pawlowski",
            "Wolfram Pernice"
        ],
        "subjects": [
            "High Energy Physics - Lattice",
            "Applied Physics",
            "Computational Physics"
        ],
        "abstract": "Lattice field theory (LFT) is the standard non-perturbative method to perform numerical calculations of quantum field theory. However, the typical bottleneck of fermionic lattice calculations is the inversion of the Dirac matrix. This inversion is solved by iterative methods, like the conjugate gradient algorithm, where matrix-vector multiplications (MVMs) are the main operation. Photonic integrated circuits excel in performing quick and energy-efficient MVMs, but at the same time, they are known to have low accuracy. This can be overcome by using mixed precision methods. In this paper, we explore the idea of using photonic technology to fulfil the demand for computational power of fermionic lattice calculations. These methods have the potential to reduce computation costs by one order of magnitude. Because of the hybrid nature of these methods, we call these 'photonic accelerated inverters (PAIs)'.",
        "comments": "10 pages, 8 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14200"
    },
    {
        "doc_id": 466,
        "title": "Deep Learning to Improve the Sensitivity of Di-Higgs Searches in the $4b$ Channel",
        "authors": [
            "Cheng-Wei Chiang",
            "Feng-Yang Hsieh",
            "Shih-Chieh Hsu",
            "Ian Low"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The study of di-Higgs events, both resonant and non-resonant, plays a crucial role in understanding the fundamental interactions of the Higgs boson. In this work we consider di-Higgs events decaying into four $b$-quarks and propose to improve the experimental sensitivity by utilizing a novel machine learning algorithm known as Symmetry Preserving Attention Network (\\textsc{Spa-Net}) -- a neural network structure whose architecture is designed to incorporate the inherent symmetries in particle reconstruction tasks. We demonstrate that the \\textsc{Spa-Net} can enhance the experimental reach over baseline methods such as the cut-based and the Deep Neural Networks (DNN)-based analyses. At the Large Hadron Collider, with a 14-TeV centre-of-mass energy and an integrated luminosity of 300 fb$^{-1}$, the \\textsc{Spa-Net} allows us to establish 95\\% C.L. upper limits in resonant production cross-sections that are 10\\% to 45\\% stronger than baseline methods. For non-resonant di-Higgs production, \\textsc{Spa-Net} enables us to constrain the self-coupling that is 9\\% more stringent than the baseline method.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14198"
    },
    {
        "doc_id": 467,
        "title": "Sensitivity of two-mode SRF cavity to generic electromagnetic interactions of ultralight dark matter",
        "authors": [
            "Chang-Jie Dai",
            "Tong Li",
            "Rui-Jia Zhang"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The ultralight dark matter (ULDM) such as axion or wavelike scalar plays as a plausible DM candidate. Recently, the possible non-standard ULDM couplings draw much attention. In this work we investigate the detection of electromagnetic couplings in a few benchmark models of ULDM. For illustration, we consider the generic axion electrodynamics including CP violating coupling as well as the newly proposed axion electromagnetodynamics. The superconducting radio frequency (SRF) cavity with two-mode has more advantages than the traditional cavity approach with static background field. We utilize the two-mode SRF cavity to probe the generic couplings of ULDM with frequency lower than GHz. The choices of the transverse electromagnetic modes are explicitly specified for the detection. We show the sensitivity of the SRF cavity to the axion couplings in the above frameworks.",
        "comments": "26 pages, 3 figures, 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14195"
    },
    {
        "doc_id": 468,
        "title": "Interactions of the Pseudoscalar Meson Octet and the Baryon Decuplet in the Continuum and a Finite Volume",
        "authors": [
            "Teng Ji",
            "Xiang-Kun Dong",
            "Ulf-G. Mei\u00dfner"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment",
            "High Energy Physics - Lattice",
            "Nuclear Theory"
        ],
        "abstract": "This study focuses on the interaction of the pseudoscalar meson octet and the baryon decuplet. In the continuum, it is observed that several $J^{P}=\\frac32^-$ baryon resonances can be produced by the Weinberg-Tomozawa interaction in unitarized chiral perturbation theory, including the $N(1875)$, $\u03a3(1670)$, $\u03a3(1910)$, $\u039e(1820)$ and $\u03a9(2012)$. Among them, the $\u039e(1820)$ and $\u03a3(1670)$ may exhibit a potential two-pole structures. The unitarized chiral perturbation approach is then applied as the underlying theory to predict the energy levels of these systems in a finite volume. These energy levels are well described by the $K$-matrix parameterization constrained by flavor SU(3) symmetry. With the parameters from the best fits, the poles extracted from the $K$-matrix parameterization closely correspond to those derived from the underlying chiral effective field theory, as long as they are close to physical region and not significantly higher than the lowest relevant threshold.",
        "comments": "11 pages, 6 figures and 2 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14188"
    },
    {
        "doc_id": 469,
        "title": "Non-symmetrical sparking may hint \"zits'' on a pulsar surface",
        "authors": [
            "Zhengli Wang",
            "Jiguang Lu",
            "Jingchen Jiang",
            "Shunshun Cao",
            "Weiyang Wang",
            "Enwei Liang",
            "Renxin Xu"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena"
        ],
        "abstract": "Pulsar electrodynamics could be relevant to the physics of stellar surface, which remains poorly understood for more than half a centenary and is difficult to probe due to the absence of direct and clear observational evidence. Nevertheless, highly-sensitive telescopes (e.g., China's Five-hundred-meter Aperture Spherical radio Telescope, FAST) may play an essential role in solving the problem since the predicted surface condition would have quite different characteristics in some models of pulsar structure, especially after the establishment of the standard model of particle physics. For instance, small hills (or ``zit'') may exist on solid strangeon star surface with rigidity, preferential discharge, i.e., gap sparking, may occur around the hills in the polar cap region. In this work, with the 110-min polarization observation of PSR B0950+08 targeted by FAST, we report that the gap sparking is significantly non-symmetrical to the meridian plane on which the rotational and magnetic axes lie. It is then speculated that this asymmetry could be the result of preferential sparking around zits which might rise randomly on pulsar surface. Some polarization features of both single pulses and the mean pulse, as well as the cross-correlation function of different emission regions, have also been presented.",
        "comments": "Accepted for publication in Astronomische Nachrichten",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14181"
    },
    {
        "doc_id": 470,
        "title": "Magnetic fields of protoplanetary disks",
        "authors": [
            "Sergey A. Khaibrakhmanov"
        ],
        "subjects": [
            "Solar and Stellar Astrophysics",
            "Earth and Planetary Astrophysics",
            "Plasma Physics"
        ],
        "abstract": "We review the current status of studies on accretion and protoplanetary disks of young stars with large-scale magnetic fields. Observational data on magnetic fields of the disks are compiled and analysed. Modern analytical and numerical MHD models of protoplanetary disks are discussed. The mechanisms of angular momentum transport via turbulence, magnetic tensions and outflows are outlined. We consider the influence of Ohmic dissipation, magnetic ambipolar diffusion, magnetic buoyancy, and the Hall effect on the evolution of the magnetic flux in disks. Modern MHD models of accretion disks show that the magnetic field can influence the structure of protoplanetary disks. We argue that the available observational data on the magnetic fields in protoplanetary disks can be interpreted within the framework of fossil magnetic field theory. We summarize the problems of the modern theory of accretion and protoplanetary disks with magnetic fields and also outline the prospects for further research.",
        "comments": "31 pages, 1 table, 2 figures, accepted to Astronomical and Astrophysical Transactions",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14180"
    },
    {
        "doc_id": 471,
        "title": "Deep Neural Networks as Variational Solutions for Correlated Open Quantum Systems",
        "authors": [
            "Johannes Mellak",
            "Enrico Arrigoni",
            "Wolfgang von der Linden"
        ],
        "subjects": [
            "Quantum Physics",
            "Disordered Systems and Neural Networks"
        ],
        "abstract": "In this work we apply deep neural networks to find the non-equilibrium steady state solution to correlated open quantum many-body systems. Motivated by the ongoing search to find more powerful representations of (mixed) quantum states, we design a simple prototypical convolutional neural network and show that parametrizing the density matrix directly with more powerful models can yield better variational ansatz functions and improve upon results reached by neural density operator based on the restricted Boltzmann machine. Hereby we give up the explicit restriction to positive semi-definite density matrices. However, this is fulfilled again to good approximation by optimizing the parameters. The great advantage of this approach is that it opens up the possibility of exploring more complex network architectures that can be tailored to specific physical properties. We show how translation invariance can be enforced effortlessly and reach better results with fewer parameters. We present results for the dissipative one-dimensional transverse-field Ising model and a two-dimensional dissipative Heisenberg model compared to exact values.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14179"
    },
    {
        "doc_id": 472,
        "title": "Multicasting Optical Reconfigurable Switch",
        "authors": [
            "Niyazi Ulas Dinc",
            "Mustafa Yildirim",
            "Christophe Moser",
            "Demetri Psaltis"
        ],
        "subjects": [
            "Optics",
            "Networking and Internet Architecture"
        ],
        "abstract": "Artificial Intelligence (AI) demands large data flows within datacenters, heavily relying on multicasting data transfers. As AI models scale, the requirement for high-bandwidth and low-latency networking compounds. The common use of electrical packet switching faces limitations due to its optical-electrical-optical conversion bottleneck. Optical switches, while bandwidth-agnostic and low-latency, suffer from having only unicast or non-scalable multicasting capability. This paper introduces an optical switching technique addressing the scalable multicasting challenge. Our approach enables arbitrarily programmable simultaneous unicast and multicast connectivity, eliminating the need for optical splitters that hinder scalability due to optical power loss. We use phase modulation in multiple planes, tailored to implement any multicast connectivity map. Using phase modulation enables wavelength selectivity on top of spatial selectivity, resulting in an optical switch that implements space-wavelength routing. We conducted simulations and experiments to validate our approach. Our results affirm the concept's feasibility and effectiveness, as a multicasting switch.",
        "comments": "12 pages, 3 figures, article",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14173"
    },
    {
        "doc_id": 473,
        "title": "No-go guide for the Hubble tension: late-time or local-scale new physics",
        "authors": [
            "Lu Huang",
            "Shao-Jiang Wang",
            "Wang-Wei Yu"
        ],
        "subjects": [
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "The standard model of modern cosmology might be cracked by the recent persistent hot debate on the Hubble-constant ($H_0$) tension, which manifests itself as the sound-horizon ($r_s$) tension or absolute-magnitude ($M_B$) tension if deeming the origin of the Hubble tension from modifying the early or late Universe, respectively. In this Letter, we achieve a fully model-independent constraint (fitting a model-independent global parameterization to a model-independent inverse distant ladder with a model-independent high-redshift calibration) on late-time models with strong evidence against homogeneous new physics over the $\u039b$-cold-dark ($\u039b$CDM) model. Further using this model-independent constraint to calibrate sufficiently local supernovae with corresponding late-time models extrapolated below the homogeneity scale, we find surprisingly that, although both $H_0$ tension and $M_B$ tension are absent in our local Universe, a combination of $H_0$ and $M_B$ as the intercept $a_B$ of the magnitude-redshift relation exhibits $3\\sim 7\u03c3$ tension even for the $\u039b$CDM model. This $a_B$ tension seems to call for local-scale inhomogeneous new physics disguised as local observational systematics.",
        "comments": "5 pages + references, 1 table and 3 figures, codes can be found at https://github.com/huanglu37/No-go-guide-for-the-Hubble-tension-late-time-or-local-scale-new-physics and chains can be found at https://zenodo.org/records/10559728",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14170"
    },
    {
        "doc_id": 474,
        "title": "Runaway Electron Dynamics in ITER Disruptions with Shattered Pellet Injections",
        "authors": [
            "Oskar Vallhagen",
            "Lise Hanebring",
            "Javier Artola",
            "Michael Lehnen",
            "Eric Nardon",
            "T\u00fcnde F\u00fcl\u00f6p",
            "Mathias Hoppe",
            "Sarah Newton",
            "Istvan Pusztai"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "This study systematically explores the parameter space of disruption mitigation through shattered pellet injection in ITER with a focus on runaway electron dynamics, using the disruption modelling tool DREAM. The physics fidelity is considerably increased compared to previous studies, by e.g., using realistic magnetic geometry, resistive wall configuration, thermal quench onset criteria, as well as including additional effects, such as ion transport and enhanced runaway electron transport during the thermal quench. The work aims to provide a fairly comprehensive coverage of experimentally feasible scenarios, considering plasmas representative of both non-activated and high-performance DT operation, different thermal quench onset criteria and transport levels, a wide range of hydrogen and neon quantities injected in one or two stages, and pellets with various characteristic shard sizes. Using a staggered injection scheme, with a pure hydrogen injection preceding a mixed hydrogen-neon injection, we find injection parameters leading to acceptable runaway electron currents in all investigated discharges without activated runaway sources. Dividing the injection into two stages is found to significantly enhance the assimilation and minimize runaway electron generation due to the hot-tail mechanism. However, while a staggered injection outperforms a single stage injection also in cases with radioactive runaway electron sources, no cases with acceptable runaway electron currents are found for a DT-plasma with a 15 MA plasma current.",
        "comments": "16 pages, 7 figures, submitted to Nuclear Fusion",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14167"
    },
    {
        "doc_id": 475,
        "title": "QCD analysis of the $P$-wave charmonium electromagnetic Dalitz decays $h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-}$",
        "authors": [
            "Chao-Jie Fan",
            "Jun-Kang He"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology"
        ],
        "abstract": "The $P$-wave charmonium electromagnetic Dalitz decays $h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-}$ $(\\ell=e, \u03bc)$ with large recoil momentum are investigated in the framework of perturbative QCD, and the soft contributions from the small recoil momentum region are described by the overlap of soft wave functions. The transition form factors $f_{h_{c}\u03b7^{(\\prime)}}(q^{2})$ and the normalized transition form factors $F_{h_{c} \u03b7^{(\\prime)}}(q^{2})$ in full kinematic region are derived for the first time. It is noticed that there are no extra IR divergences at the one-loop level and the tree level, and the transition form factors in which the relativistic corrections from the internal momentum of $h_{c}$ are taken into account are insensitive to both the shapes of $\u03b7^{(\\prime)}$ distribution amplitudes and the invariant mass of the lepton pair in the large recoil momentum region. Furthermore, we find that the contributions from the soft mechanism and those from hard mechanism are comparable with each other in the branching ratios $\\mathcal{B}(h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-})$. By employing the obtained $F_{h_{c} \u03b7^{(\\prime)}}(q^{2})$, we give the predictions of the branching ratios $\\mathcal{B}(h_{c}\\rightarrow\u03b7^{(\\prime)}\\ell^{+}\\ell^{-})$, which may come within the range of measurement of present or near-future experiments.",
        "comments": "32 pages, 6 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14152"
    },
    {
        "doc_id": 476,
        "title": "Polarized and bright telecom C-band single-photon source from InP-based quantum dots coupled to elliptical Bragg gratings",
        "authors": [
            "Zhenxuan Ge",
            "Tunghsun Chung",
            "Yu-Ming He",
            "Mohamed Benyoucef",
            "Yongheng Huo"
        ],
        "subjects": [
            "Quantum Physics"
        ],
        "abstract": "Bright, polarized, and high-purity single-photon sources in telecom wavelengths are crucial components in long-distance quantum communication, optical quantum computation and quantum networks. Semiconductor InAs/InP quantum dots (QDs) combined with photonic cavities provide a competitive path leading to optimal single-photon sources in this range. Here, we demonstrate a bright and polarized single-photon source operating in the telecom C-band based on an elliptical Bragg grating (EBG) cavity. With a significant Purcell enhancement of 5.25$\\pm$0.05, the device achieves a polarization ratio of 0.986, single-photon purity of g^2 (0)=0.078$\\pm$0.016 and single-polarized photon collection efficiency of ~ 24% at the first lens (NA=0.65) without blinking. These findings suggest that C-band QD-based single-photon sources are potential candidates for advancing quantum communication.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14150"
    },
    {
        "doc_id": 477,
        "title": "Mathematical Tri-State Model for Bee Shimmering Propagation Dynamics",
        "authors": [
            "Navin Patel",
            "Henri Huijberts",
            "Kaspar Althoefer",
            "Ketao Zhang"
        ],
        "subjects": [
            "Adaptation and Self-Organizing Systems",
            "Dynamical Systems",
            "Biological Physics"
        ],
        "abstract": "Bees undergo a self-organised process known as shimmering, where they form emergent patterns when they interact with each other on the nest surface as a defence mechanism in response to predator attacks. Many experimental studies have empirically investigated how the transfer of information to neighbouring bees propagates in various shimmering processes by measuring shimmering wave strength. However, there is no analytical modelling of the collective defence mechanism in nature. Here we introduce the first analytical tri-state Inactive-Active-Relapse (IAR) model to formulate the intrinsic process of bee shimmering. The major shimmering behaviour is shown to emerge under theoretical conditions which is demonstrated numerically and visually by simulating 1,000,000 bee agents, while the number of agents is scalable. Furthermore, we elaborate on these mathematical results to construct a wave strength function to demonstrate the accuracy of shimmering dynamics. The constructed wave strength function can be adapted to peak between 50-150ms which supports the experimental studies. Our results provide a foundation for further theoretical understanding of bee shimmering wave dynamics and could serve as inspiration for modelling other self-organised phenomena across scientific applications.",
        "comments": "20 pages, 7 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14145"
    },
    {
        "doc_id": 478,
        "title": "Efficient photon-pair generation empowered by dual quasi-bound states in the continuum",
        "authors": [
            "Tingting Liu",
            "Meibao Qin",
            "Siqi Feng",
            "Xu Tu",
            "Tianjing Guo",
            "Feng Wu",
            "Shuyuan Xiao"
        ],
        "subjects": [
            "Optics"
        ],
        "abstract": "Here we demonstrate the efficient photon-pair generation via spontaneous parametric down conversion from a semiconductor metasurface supporting dual quasi-bound states in the continuum (quasi-BICs). In a simple metasurface design composed of AlGaAs ellipse nano-cyclinders, the two high-$Q$ quasi-BIC resonances that coincide with the generated signal and idler frequencies significantly boost the local electric field. This leads to a substantial enhancement in the reverse classical nonlinear process of sum frequency generation and subsequently the remarkable high generation rate of photon pairs under the quantum-classical correspondence principle. Within a narrowband wavelength regime around the quasi-BIC resonances, the rate of pair production is enhanced up to $\\sim10^{4}$ Hz, two orders of magnitude larger than that in the Mie resonant AlGaAs nanoantennas. Moreover, the photon pair emission is mainly concentrated in the normal direction with respect to the metasurface, and shows tunable rate with the $Q$ factor by engineering the rotation angle of nano-cylinders. The presented work enables nanoscale sources of high-quality entangled photons which will find applications in advanced quantum imaging and communications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14140"
    },
    {
        "doc_id": 479,
        "title": "Micro and Nano 3D investigation of complex gut alterations-dementia interplay",
        "authors": [
            "F. Palermo",
            "N. Marrocco",
            "L. Dacom",
            "E. Grisafi",
            "M. Musella",
            "A. Sanna",
            "L. Massimi",
            "I. Bukreeva",
            "O. Junemann",
            "M. Eckermann",
            "P. Cloetens",
            "T. Weitkamp",
            "N. Kerlero de Rosbo",
            "C. Balducci",
            "A. Cedola"
        ],
        "subjects": [
            "Applied Physics"
        ],
        "abstract": "Alzheimer's disease (AD), a debilitating neurodegenerative disorder, remains one of the foremost public health challenges of our time. Despite decades of research, its etiology largely remains enigmatic. Recently, attention has turned to the gut-brain axis, a complex network of communication between the gastrointestinal tract and the brain, as a potential player in the pathogenesis of AD. Here we exploited X-ray Phase Contrast Tomography to provide an in-depth analysis of the link between the gut condition and AD, exploring gut anatomy and structure in murine models. We conducted a comprehensive analysis by comparing the outcomes in various mouse models of cognitive impairment, including AD, frail mice, and frontotemporal dementia (FTD) affected mice. We discovered an association between substantial changes in the gut structure and the presence of amyloid-beta (A\\b{eta}) in the brain. We found that the most important gut alterations are related to A\\b{eta} occurrence in the brain. In particular, we investigated the gut morphology, the distribution of enteric micro-processes and neurons in the ileum. Understanding the intricate interplay between gut condition and dementia may open new avenues for early AD diagnosis and treatment offering hope for a future where these diseases may be more effectively addressed.",
        "comments": "9 pages and 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14139"
    },
    {
        "doc_id": 480,
        "title": "Homoclinic chaos in a pair of parametrically-driven coupled SQUIDs",
        "authors": [
            "M. Agaoglou",
            "V. M. Rothos",
            "H. Susanto"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Mathematical Physics"
        ],
        "abstract": "An rf superconducting quantum interference device (SQUID) consists of a superconducting ring interrupted by a Josephson junction (JJ). When driven by an alternating magnetic field, the induced supercurrents around the ring are determined by the JJ through the celebrated Josephson relations. This system exhibits rich nonlinear behavior, including chaotic effects. We study the dynamics of a pair of parametrically-driven coupled SQUIDs arranged in series. We take advantage of the weak damping that characterizes these systems to perform a multiple-scales analysis and obtain amplitude equations, describing the slow dynamics of the system. This picture allows us to expose the existence of homoclinic orbits in the dynamics of the integrable part of the slow equations of motion. Using high-dimensional Melnikov theory, we are able to obtain explicit parameter values for which these orbits persist in the full system, consisting of both Hamiltonian and non-Hamiltonian perturbations, to form so-called Silnikov orbits, indicating a loss of integrability and the existence of chaos.",
        "comments": "4 pages. arXiv admin note: text overlap with arXiv:1007.3939 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14128"
    },
    {
        "doc_id": 481,
        "title": "Spatially Resolved High Voltage Kelvin Probe Force Microcopy: A Novel Avenue for Examining Electrical Phenomena at Nanoscale",
        "authors": [
            "Conor J. McCluskey",
            "Niyorjyoti Sharma",
            "Jesi R. Maguire",
            "Serene Pauly",
            "Andrew Rogers",
            "TJ Lindsay",
            "Kristina M. Holsgrove",
            "Brian J. Rodriguez",
            "Navneet Soin",
            "John Marty Gregg",
            "Raymond G. P. McQuaid",
            "Amit Kumar"
        ],
        "subjects": [
            "Materials Science",
            "Applied Physics"
        ],
        "abstract": "Kelvin probe microscopy (KPFM) is a well-established scanning probe technique, used to measure surface potential accurately; it has found extensive use in the study of a range of materials phenomena. In its conventional form, KPFM frustratingly precludes imaging samples or scenarios where large surface potential exists or large surface potential gradients are created outside the typical +/-10V window. If the potential regime measurable via KPFM could be expanded, to enable precise and reliable metrology, through a high voltage KPFM (HV-KPFM) adaptation, it could open up pathways towards a range of novel experiments, where the detection limit of regular KPFM has so far prevented the use of the technique. In this work, HV-KPFM has been realised and shown to be capable of measuring large surface potential and potential gradients with accuracy and precision. The technique has been employed to study a range of materials (positive temperature coefficient of resistivity ceramics, charge storage fluoropolymers and pyroelectrics) where accurate spatially resolved mapping of surface potential within high voltage regime facilitates novel physical insight. The results demonstrate that HV-KPFM can be used as an effective tool to fill in existing gaps in surface potential measurements while also opening routes for novel studies in materials physics.",
        "comments": "Main Text: 16 pages, 5 figures Supplementary information:4 pages, 2 tables and 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14124"
    },
    {
        "doc_id": 482,
        "title": "Heavy baryon decays into light meson and dark baryon within LCSR",
        "authors": [
            "Yu-Ji Shi",
            "Ye Xing",
            "Zhi-Peng Xing"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "High Energy Physics - Experiment"
        ],
        "abstract": "We studied the decays of Heavy baryon into a pseudoscalar meson and a dark baryon in the recently developed $B$-Mesogenesis scenario, where the two types of effective Lagrangians proposed by the scenario are both considered. The decay amplitudes of $\u039b_b^0$ are calculated by light-cone sum rules using its light-cone distribution amplitudes. The decay amplitudes of $\u039e_b^{0,\\pm}$ are related with those of $\u039b_b^0$ through a flavor SU(3) analysis. The uncertainties of threshold parameter and the Borel parameter are both considered in the numerical calculation. The values of effective coupling constants in the $B$-Mesogenesis are taken as their upper limits that obtained from our previous study on the inclusive decay. The upper limits of the decay branching fractions are presented as functions of the dark baryon mass.",
        "comments": "21 pages, 9 figures, 3 tables",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14120"
    },
    {
        "doc_id": 483,
        "title": "Pseudoscalar mesons from a PNJL model at zero temperature",
        "authors": [
            "R. M. Aguirre",
            "O. Louren\u00e7o"
        ],
        "subjects": [
            "High Energy Physics - Phenomenology",
            "Nuclear Theory"
        ],
        "abstract": "We study pseudoscalar $\u03c0$, $K$ and $\u03b7$ meson properties, such as masses and couplings, in dense matter at zero temperature. We use a recently proposed phenomenological quark model, known as the PNJL0, which takes into account the confinement/deconfinement phase transition by means of the traced Polyakov loop ($\u03a6$) which serves as an order parameter at zero temperature. We consider two different scenarios, namely, symmetric quark matter with equal chemical potentials for all the flavors, and the beta equilibrated matter. In the latter case the hadron-quark phase transition is implemented by a two model approach. For the hadron side we use a relativistic mean-field model with density dependent couplings. We show that $\u03a6$ induces abrupt changes in the mesons properties with gap sizes regulated by the phenomenological gluonic sector of the model.",
        "comments": "14 pages, 12 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14119"
    },
    {
        "doc_id": 484,
        "title": "Uniqueness of photon sphere for Reissner-Nordstr\u00f6m electric-magnetic system",
        "authors": [
            "Marek Rogatko"
        ],
        "subjects": [
            "General Relativity and Quantum Cosmology",
            "High Energy Physics - Theory"
        ],
        "abstract": "Uniqueness of static, asymptotically flat, non-extremal {\\it photon sphere} in Einstein-Maxwell spacetime with electric and magnetic charges has been proved. Using conformal positive energy theorem, as well as, the positive mass theorem and adequate conformal transformations, we envisage the two alternative ways of proving that the exterior region of a certain radius of the studied static {\\it photon sphere}, is characterized by ADM mass, electric and magnetic charges.",
        "comments": "22 pages, RevTex, to be published in Phys.Rev.D15",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14116"
    },
    {
        "doc_id": 485,
        "title": "Development of a Silicon Drift Detector Array to Search for keV-scale Sterile Neutrinos with the KATRIN Experiment",
        "authors": [
            "Daniel Siegmann",
            "Frank Edzards",
            "Christina Bruch",
            "Matteo Biassoni",
            "Marco Carminati",
            "Martin Descher",
            "Carlo Fiorini",
            "Christian Forstner",
            "Andrew Gavin",
            "Matteo Gugiatti",
            "Roman Hiller",
            "Dominic Hinz",
            "Thibaut Houdy",
            "Anton Huber",
            "Pietro King",
            "Peter Lechner",
            "Steffen Lichter",
            "Danilo Mie\u00dfner",
            "Andrea Nava",
            "Anthony Onillon",
            "David C. Radford",
            "Daniela Spreng",
            "Markus Steidl",
            "Paolo Trigilio",
            "Korbinian Urban",
            "et al. (3 additional authors not shown)"
        ],
        "subjects": [
            "Instrumentation and Detectors"
        ],
        "abstract": "Sterile neutrinos in the keV mass range present a viable candidate for dark matter. They can be detected through single $\u03b2$ decay, where they cause small spectral distortions. The Karlsruhe Tritium Neutrino (KATRIN) experiment aims to search for keV-scale sterile neutrinos with high sensitivity. To achieve this, the KATRIN beamline will be equipped with a novel multi-pixel silicon drift detector focal plane array named TRISTAN. In this study, we present the performance of a TRISTAN detector module, a component of the eventual 9-module system. Our investigation encompasses spectroscopic aspects such as noise performance, energy resolution, linearity, and stability.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14114"
    },
    {
        "doc_id": 486,
        "title": "CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks",
        "authors": [
            "Andrei Tomut",
            "Saeed S. Jahromi",
            "Sukhbinder Singh",
            "Faysal Ishtiaq",
            "Cesar Mu\u00f1oz",
            "Prabdeep Singh Bajaj",
            "Ali Elborady",
            "Gianni del Bimbo",
            "Mehrazin Alizadeh",
            "David Montero",
            "Pablo Martin-Ramiro",
            "Muhammad Ibrahim",
            "Oussama Tahiri Alaoui",
            "John Malcolm",
            "Samuel Mugel",
            "Roman Orus"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantum Physics"
        ],
        "abstract": "Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly in generative Artificial Intelligence (AI), but their immense size poses significant challenges, such as huge training and inference costs, substantial energy demands, and limitations for on-site deployment. Traditional compression methods such as pruning, distillation, and low-rank approximation focus on reducing the effective number of neurons in the network, while quantization focuses on reducing the numerical precision of individual weights to reduce the model size while keeping the number of neurons fixed. While these compression methods have been relatively successful in practice, there's no compelling reason to believe that truncating the number of neurons is an optimal strategy. In this context, this paper introduces CompactifAI, an innovative LLM compression approach using quantum-inspired Tensor Networks that focuses on the model's correlation space instead, allowing for a more controlled, refined and interpretable model compression. Our method is versatile and can be implemented with - or on top of - other compression techniques. As a benchmark, we demonstrate that CompactifAI alone enables compression of the LlaMA-2 7B model to only $30\\%$ of its original size while recovering over $90\\%$ of the original accuracy after a brief distributed retraining.",
        "comments": "4 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14109"
    },
    {
        "doc_id": 487,
        "title": "Travelling waves in nonlinear magneto-inductive lattices",
        "authors": [
            "M. Agaoglou",
            "M. Feckan",
            "M. Pospisil",
            "V. M. Rothos",
            "H. Susanto"
        ],
        "subjects": [
            "Mathematical Physics"
        ],
        "abstract": "We consider a lattice equation modelling one-dimensional metamaterials formed by a discrete array of nonlinear resonators. We focus on periodic travelling waves due to the presence of a periodic force. The existence and uniqueness results of periodic travelling waves of the system are presented. Our analytical results are found to be in good agreement with direct numerical computations",
        "comments": "21 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14108"
    },
    {
        "doc_id": 488,
        "title": "Learning under Label Noise through Few-Shot Human-in-the-Loop Refinement",
        "authors": [
            "Aaqib Saeed",
            "Dimitris Spathis",
            "Jungwoo Oh",
            "Edward Choi",
            "Ali Etemad"
        ],
        "subjects": [
            "Machine Learning",
            "Signal Processing"
        ],
        "abstract": "Wearable technologies enable continuous monitoring of various health metrics, such as physical activity, heart rate, sleep, and stress levels. A key challenge with wearable data is obtaining quality labels. Unlike modalities like video where the videos themselves can be effectively used to label objects or events, wearable data do not contain obvious cues about the physical manifestation of the users and usually require rich metadata. As a result, label noise can become an increasingly thorny issue when labeling such data. In this paper, we propose a novel solution to address noisy label learning, entitled Few-Shot Human-in-the-Loop Refinement (FHLR). Our method initially learns a seed model using weak labels. Next, it fine-tunes the seed model using a handful of expert corrections. Finally, it achieves better generalizability and robustness by merging the seed and fine-tuned models via weighted parameter averaging. We evaluate our approach on four challenging tasks and datasets, and compare it against eight competitive baselines designed to deal with noisy labels. We show that FHLR achieves significantly better performance when learning from noisy labels and achieves state-of-the-art by a large margin, with up to 19% accuracy improvement under symmetric and asymmetric noise. Notably, we find that FHLR is particularly robust to increased label noise, unlike prior works that suffer from severe performance degradation. Our work not only achieves better generalization in high-stakes health sensing benchmarks but also sheds light on how noise affects commonly-used models.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14107"
    },
    {
        "doc_id": 489,
        "title": "Inverse source problem for discrete Helmholtz equation",
        "authors": [
            "Roman Novikov",
            "Basant Lal Sharma"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "We consider multi-frequency inverse source problem for the discrete Helmholtz operator on the square lattice $\\mathbb{Z}^d$, $d \\ge 1$. We consider this problem for the cases with and without phase information. We prove uniqueness results and present examples of non-uniqueness for this problem for the case of compactly supported source function. Relations with inverse scattering problem for the discrete Schr\u00f6dinger operators in the Born approximation are also provided.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14103"
    },
    {
        "doc_id": 490,
        "title": "Few-magnon excitations in a frustrated spin-$S$ ferromagnetic chain",
        "authors": [
            "Jiawei Li",
            "Ye Cao",
            "Ning Wu"
        ],
        "subjects": [
            "Strongly Correlated Electrons",
            "Quantum Physics"
        ],
        "abstract": "We study few-magnon excitations in a finite-size spin-$S$ ferromagnetic nearest-neighbor (NN) XXZ chain with additional antiferromagnetic next-nearest-neighbor (NNN) interaction $J'$ and single-ion (SI) anisotropy $D$. Using a set of exact two-magnon Bloch states, the two-magnon problem is mapped to a single-particle one on an effective open chain with both NN and NNN hoppings. For the commensurate momentum $k=-\u03c0$, the effective chain is decoupled into two NN open chains that can be exactly solved via a plane-wave ansatz. Based on this, we identify in the $\u0394'-D/|J'|$ plane (with $\u0394'$ the anisotropy parameter for the NNN coupling) the regions supporting the SI or NNN exchange two-magnon bound states near the edge of the band. We prove that there always exists a lower-energy NN exchange two-magnon bound state near the band edge. For $S=1/2$, we numerically calculate the $n$-magnon spectra for $n\\leq5$ by using a spin-operator matrix element method. The corresponding $n$-magnon commensurate instability regions are determined for finite chains and consistent results with prior literature are observed.",
        "comments": "10 pages, 9 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14101"
    },
    {
        "doc_id": 491,
        "title": "Carry Your Fault: A Fault Propagation Attack on Side-Channel Protected LWE-based KEM",
        "authors": [
            "Suparna Kundu",
            "Siddhartha Chowdhury",
            "Sayandeep Saha",
            "Angshuman Karmakar",
            "Debdeep Mukhopadhyay",
            "Ingrid Verbauwhede"
        ],
        "subjects": [
            "Cryptography and Security"
        ],
        "abstract": "Post-quantum cryptographic (PQC) algorithms, especially those based on the learning with errors (LWE) problem, have been subjected to several physical attacks in the recent past. Although the attacks broadly belong to two classes - passive side-channel attacks and active fault attacks, the attack strategies vary significantly due to the inherent complexities of such algorithms. Exploring further attack surfaces is, therefore, an important step for eventually securing the deployment of these algorithms. Also, it is important to test the robustness of the already proposed countermeasures in this regard. In this work, we propose a new fault attack on side-channel secure masked implementation of LWE-based key-encapsulation mechanisms (KEMs) exploiting fault propagation. The attack typically originates due to an algorithmic modification widely used to enable masking, namely the Arithmetic-to-Boolean (A2B) conversion. We exploit the data dependency of the adder carry chain in A2B and extract sensitive information, albeit masking (of arbitrary order) being present. As a practical demonstration of the exploitability of this information leakage, we show key recovery attacks of Kyber, although the leakage also exists for other schemes like Saber. The attack on Kyber targets the decapsulation module and utilizes Belief Propagation (BP) for key recovery. To the best of our knowledge, it is the first attack exploiting an algorithmic component introduced to ease masking rather than only exploiting the randomness introduced by masking to obtain desired faults (as done by Delvaux). Finally, we performed both simulated and electromagnetic (EM) fault-based practical validation of the attack for an open-source first-order secure Kyber implementation running on an STM32 platform.",
        "comments": "ACM Class:          E.3.3",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14098"
    },
    {
        "doc_id": 492,
        "title": "Evaluating User Experience and Data Quality in a Gamified Data Collection for Appearance-Based Gaze Estimation",
        "authors": [
            "Mingtao Yue",
            "Tomomi Sayuda",
            "Miles Pennington",
            "Yusuke Sugano"
        ],
        "subjects": [
            "Human-Computer Interaction"
        ],
        "abstract": "Appearance-based gaze estimation, which uses only a regular camera to estimate human gaze, is important in various application fields. While the technique faces data bias issues, data collection protocol is often demanding, and collecting data from a wide range of participants is difficult. It is an important challenge to design opportunities that allow a diverse range of people to participate while ensuring the quality of the training data. To tackle this challenge, we introduce a novel gamified approach for collecting training data. In this game, two players communicate words via eye gaze through a transparent letter board. Images captured during gameplay serve as valuable training data for gaze estimation models. The game is designed as a physical installation that involves communication between players, and it is expected to attract the interest of diverse participants. We assess the game's significance on data quality and user experience through a comparative user study.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14095"
    },
    {
        "doc_id": 493,
        "title": "GQHAN: A Grover-inspired Quantum Hard Attention Network",
        "authors": [
            "Ren-Xin Zhao",
            "Jinjing Shi",
            "Xuelong Li"
        ],
        "subjects": [
            "Quantum Physics",
            "Artificial Intelligence"
        ],
        "abstract": "Numerous current Quantum Machine Learning (QML) models exhibit an inadequacy in discerning the significance of quantum data, resulting in diminished efficacy when handling extensive quantum datasets. Hard Attention Mechanism (HAM), anticipated to efficiently tackle the above QML bottlenecks, encounters the substantial challenge of non-differentiability, consequently constraining its extensive applicability. In response to the dilemma of HAM and QML, a Grover-inspired Quantum Hard Attention Mechanism (GQHAM) consisting of a Flexible Oracle (FO) and an Adaptive Diffusion Operator (ADO) is proposed. Notably, the FO is designed to surmount the non-differentiable issue by executing the activation or masking of Discrete Primitives (DPs) with Flexible Control (FC) to weave various discrete destinies. Based on this, such discrete choice can be visualized with a specially defined Quantum Hard Attention Score (QHAS). Furthermore, a trainable ADO is devised to boost the generality and flexibility of GQHAM. At last, a Grover-inspired Quantum Hard Attention Network (GQHAN) based on QGHAM is constructed on PennyLane platform for Fashion MNIST binary classification. Experimental findings demonstrate that GQHAN adeptly surmounts the non-differentiability hurdle, surpassing the efficacy of extant quantum soft self-attention mechanisms in accuracies and learning ability. In noise experiments, GQHAN is robuster to bit-flip noise in accuracy and amplitude damping noise in learning performance. Predictably, the proposal of GQHAN enriches the Quantum Attention Mechanism (QAM), lays the foundation for future quantum computers to process large-scale data, and promotes the development of quantum computer vision.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14089"
    },
    {
        "doc_id": 494,
        "title": "Spatially localized scalar structures on hyperscaling violating geometries",
        "authors": [
            "I. Andrade",
            "M. A. Marques",
            "R. Menezes",
            "D. C. Moreira"
        ],
        "subjects": [
            "High Energy Physics - Theory",
            "General Relativity and Quantum Cosmology",
            "Pattern Formation and Solitons"
        ],
        "abstract": "In this work, we investigate probe scalar field models preserving covariance on fixed, static background geometries that present hyperscaling violation properties. We develop a first-order framework that rises from restrictions on the dynamical and hyperscaling violating exponents. The results show that stable, analytical kink-like solutions and their respective energy densities can be obtained for a general class of models. In the canonical model, in particular, these solutions minimize the energy of the system.",
        "comments": "12 pages, 2 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14082"
    },
    {
        "doc_id": 495,
        "title": "Accelerating Fractional PINNs using Operational Matrices of Derivative",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis"
        ],
        "abstract": "This paper presents a novel operational matrix method to accelerate the training of fractional Physics-Informed Neural Networks (fPINNs). Our approach involves a non-uniform discretization of the fractional Caputo operator, facilitating swift computation of fractional derivatives within Caputo-type fractional differential problems with $0<\u03b1<1$. In this methodology, the operational matrix is precomputed, and during the training phase, automatic differentiation is replaced with a matrix-vector product. While our methodology is compatible with any network, we particularly highlight its successful implementation in PINNs, emphasizing the enhanced accuracy achieved when utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates Legendre polynomials into the PINN structure, providing a significant boost in accuracy. The effectiveness of our proposed method is validated across diverse differential equations, including Delay Differential Equations (DDEs) and Systems of Differential Algebraic Equations (DAEs). To demonstrate its versatility, we extend the application of the method to systems of differential equations, specifically addressing nonlinear Pantograph fractional-order DDEs/DAEs. The results are supported by a comprehensive analysis of numerical outcomes.",
        "comments": "19 pages, 11 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14081"
    },
    {
        "doc_id": 496,
        "title": "Light-induced photodissociation on the lowest three electronic states of NaH molecule",
        "authors": [
            "Otabek Umarov",
            "Andr\u00e1s Csehi",
            "P\u00e9ter Badank\u00f3",
            "G\u00e1bor J. Hal\u00e1sz",
            "\u00c1gnes Vib\u00f3k"
        ],
        "subjects": [
            "Chemical Physics"
        ],
        "abstract": "It has been known that electronic conical intersections in a molecular system can also be created by laser light even in diatomics. The direct consequence of these light-induced degeneracies is the appearance of a strong mixing between the electronic and vibrational motions, which has a strong fingerprint on the ultrafast nuclear dynamics. In the present work, pump and probe numerical simulations have been performed with the NaH molecule involving the first three singlet electronic states (X1\u03a3+(X), A1\u03a3+(A) and B1\u03a0(B)) and several light-induced degeneracies in the numerical description. To demonstrate the impact of the multiple light-induced non-adiabatic effects together with the molecular rotation on the dynamical properties of the molecule, the dissociation probabilities, kinetic energy release spectra (KER) and the angular distributions of the photofragments were calculated by discussing the role of the permanent dipole moment as well.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14080"
    },
    {
        "doc_id": 497,
        "title": "Generation of High-Brilliance Polarized $\u03b3$-Rays via Vacuum Birefringence",
        "authors": [
            "Chong Lv",
            "Feng Wan",
            "Yousef I. Salamin",
            "Qian Zhao",
            "Mamutjan Ababekri",
            "Ruirui Xu",
            "Jian-Xing Li"
        ],
        "subjects": [
            "Plasma Physics"
        ],
        "abstract": "High-brilliance circularly polarized $\u03b3$-photon beams are of great significance for a wide range of applications. However, their generation through nonlinear Compton scattering must require a high-density longitudinally-spin-polarized electron beam and consequently is still a great challenge. Here, we put forward a novel method to generate such $\u03b3$-photon beams via the vacuum dichroism (VD)-assisted vacuum birefringence (VB) effect, only utilizing a well-established unpolarized electron beam. We split a linearly polarized (LP) laser pulse into two subpulses with the first one colliding with a dense unpolarized electron beam to generate an LP $\u03b3$-photon beam (via nonlinear Compton scattering), which then further collides with the second subpulse and is transformed into a circularly polarized one via the VB effect. We find that by manipulating the relative polarization of two subpulses, one can ``purify'' the polarization of the $\u03b3$-photon beam via the VD effect, thereby significantly enhancing the circular polarization of the $\u03b3$-photon beam. Due to the VD assistance, the VB effect reaches optimal when the relative polarization is nearly $30^\\circ$, not the widely used $45^\\circ$ in the common VB detection methods. Our results show that one can obtain a circularly polarized $\u03b3$-photon beam with degree of about 30% (43%) for energies above 500 (1000) MeV and brilliance of about $10^{24}~(10^{23})~\\mathrm{photons / (s \\cdot mm^2 \\cdot mrad^{2} \\cdot 0.1\\%BW)}$ at $500~(1000)$ MeV by using a currently feasible laser with a peak intensity of about $10^{22}~\\mathrm{W/cm^2}$. And, it can be further improved to above 60% (75%) by increasing the laser pulse duration. Moreover, our method can also be used to efficiently confirm the well-known VB effect itself, which has been predicted a very long time ago but has not been directly observed in experiments yet.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14075"
    },
    {
        "doc_id": 498,
        "title": "Optical phase encoding in pulsed approach to reservoir computing",
        "authors": [
            "Johan Henaff",
            "Matthieu Ansquer",
            "Miguel C Soriano",
            "Roberta Zambrini",
            "Nicolas Treps",
            "Valentina Parigi"
        ],
        "subjects": [
            "Quantum Physics",
            "Optics"
        ],
        "abstract": "The exploitation of the full structure of multimode light fields enables compelling capabilities in many fields including classical and quantum information science. We exploit data-encoding on the optical phase of the pulses of a femtosecond laser source for a photonic implementation of a reservoir computing protocol. Rather than intensity detection, data-reading is done via homodyne detection that accesses combinations of amplitude and phase of the field. Numerical and experimental results on NARMA tasks and laser dynamic predictions are shown. We discuss perspectives for quantum enhanced protocols.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14073"
    },
    {
        "doc_id": 499,
        "title": "Gamma rays from dark matter spikes in EAGLE simulations",
        "authors": [
            "J. Aschersleben",
            "G. Bertone",
            "D. Horns",
            "E. Moulin",
            "R. F. Peletier",
            "M. Vecchi"
        ],
        "subjects": [
            "High Energy Astrophysical Phenomena",
            "Cosmology and Nongalactic Astrophysics"
        ],
        "abstract": "Intermediate Mass Black Holes (IMBHs) with a mass range between $100 \\, \\text{M}_\\odot$ and $10^6 \\, \\text{M}_\\odot$ are expected to be surrounded by high dark matter densities, so-called dark matter spikes. The high density of self-annihilating WIMPs in these spikes leads to copious gamma-ray production. Sufficiently nearby IMBHs could therefore appear as unidentified gamma-ray sources. However, the number of IMBHs and their distribution within our own Milky Way is currently unknown. In this work, we provide a mock catalogue of IMBHs and their dark matter spikes obtained from the EAGLE simulations, in which black holes with a mass of $10^5 \\, \\text{M}_\\odot/h$ are seeded into the centre of halos greater than $10^{10} \\, \\text{M}_\\odot/h$ to model black hole feedback influencing the formation of galaxies. The catalogue contains the coordinates and dark matter spike parameters for over 8700 IMBHs present in about 400 Milky Way-like galaxies. We expect about $19^{+13}_{-8}$ IMBHs within our own galaxy, mainly distributed in the Galactic Centre and the Galactic Plane. In the most optimistic scenario, we find that current and future gamma-ray observatories, such as Fermi-LAT, H.E.S.S. and CTA, would be sensitive enough to probe the cross section of dark matter self-annihilation around IMBHs down to many orders of magnitude below the thermal relic cross section for dark matter particles with masses from GeV to TeV. We have made the IMBH mock catalogue and the source code for our analysis publicly available, providing the resources to study dark matter self-annihilation around IMBHs with current and upcoming gamma-ray observatories.",
        "comments": "25 pages, 10 figures, submitted to Journal of Cosmology and Astroparticle Physics",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14072"
    },
    {
        "doc_id": 500,
        "title": "Higher order approximation of option prices in Barndorff-Nielsen and Shephard models",
        "authors": [
            "\u00c1lvaro Guinea Juli\u00e1",
            "Alet Roux"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We present an approximation method based on the mixing formula (Hull & White 1987, Romano & Touzi 1997) for pricing European options in Barndorff-Nielsen and Shephard models. This approximation is based on a Taylor expansion of the option price. It is implemented using a recursive algorithm that allows us to obtain closed form approximations of the option price of any order (subject to technical conditions on the background driving L\u00e9vy process). This method can be used for any type of Barndorff-Nielsen and Shephard stochastic volatility model. Explicit results are presented in the case where the stationary distribution of the background driving L\u00e9vy process is inverse Gaussian or gamma. In both of these cases, the approximation compares favorably to option prices produced by the characteristic function. In particular, we also perform an error analysis of the approximation, which is partially based on the results of Das & Langren\u00e9 (2022). We obtain asymptotic results for the error of the $N^{\\text{th}}$ order approximation and error bounds when the variance process satisfies an inverse Gaussian Ornstein-Uhlenbeck process or a gamma Ornstein-Uhlenbeck process.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14390"
    },
    {
        "doc_id": 501,
        "title": "MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning",
        "authors": [
            "Junwei Su",
            "Shan Wu",
            "Jinhui Li"
        ],
        "subjects": [
            "Machine Learning",
            "General Economics",
            "Trading and Market Microstructure"
        ],
        "abstract": "In this study, we explore the synergy of deep learning and financial market applications, focusing on pair trading. This market-neutral strategy is integral to quantitative finance and is apt for advanced deep-learning techniques. A pivotal challenge in pair trading is discerning temporal correlations among entities, necessitating the integration of diverse data modalities. Addressing this, we introduce a novel framework, Multi-modal Temporal Relation Graph Learning (MTRGL). MTRGL combines time series data and discrete features into a temporal graph and employs a memory-based temporal graph neural network. This approach reframes temporal correlation identification as a temporal graph link prediction task, which has shown empirical success. Our experiments on real-world datasets confirm the superior performance of MTRGL, emphasizing its promise in refining automated pair trading strategies.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14199"
    },
    {
        "doc_id": 502,
        "title": "Discrete Hawkes process with flexible residual distribution and filtered historical simulation",
        "authors": [
            "Kyungsub Lee"
        ],
        "subjects": [
            "Statistical Finance",
            "Methodology"
        ],
        "abstract": "We introduce a new model which can be considered as a extended version of the Hawkes process in a discrete sense. This model enables the integration of various residual distributions while preserving the fundamental properties of the original Hawkes process. The rich nature of this model enables a filtered historical simulation which incorporate the properties of original time series more accurately. The process naturally extends to multi-variate models with easy implementations of estimation and simulation. We investigate the effect of flexible residual distribution on estimation of high frequency financial data compared with the Hawkes process.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13890"
    },
    {
        "doc_id": 503,
        "title": "The impact of Hong Kong's anti-ELAB movement on political related firms",
        "authors": [
            "Ziqi Wang"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "Hong Kong's anti-ELAB movement had a significant impact on the stock market the stock price of listed companies. Using the number of protestors as the measurement of daily protesting intensity from 2019/6/6 to 2020/1/17, this paper documents that the stock price of listed companies associated with the pan-democratic parties were more negatively affected by protesting than other companies. Furthermore, this paper finds that after the implementation of the anti-mask law, protesting had a positive impact on red chips but a negative impact on companies related to pan-democracy parties. Therefore, this paper believes that after the central government and the HKSAR government adopted strict measures to stop violence and chaos, the value of the political connection of red chips became positive while the value of the connection with pan-democracy parties became negative.",
        "comments": "34 pages, 13 tables",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.13676"
    },
    {
        "doc_id": 504,
        "title": "Real-time Risk Metrics for Programmatic Stablecoin Crypto Asset-Liability Management (CALM)",
        "authors": [
            "Marcel Bluhm",
            "Adrian Cachinero Vasiljevi\u0107",
            "S\u00e9bastien Derivaux",
            "S\u00f8ren Terp H\u00f8rl\u00fcck Jessen"
        ],
        "subjects": [
            "Risk Management",
            "Cryptography and Security",
            "General Finance"
        ],
        "abstract": "Stablecoins have turned out to be the \"killer\" use case of the growing digital asset space. However, risk management frameworks, including regulatory ones, have been largely absent. In this paper, we address the critical question of measuring and managing risk in stablecoin protocols, which operate on public blockchain infrastructure. The on-chain environment makes it possible to monitor risk and automate its management via transparent smart-contracts in real-time. We propose two risk metrics covering capitalization and liquidity of stablecoin protocols. We then explore in a case-study type analysis how our risk management framework can be applied to DAI, the biggest decentralized stablecoin by market capitalisation to-date, governed by MakerDAO. Based on our findings, we recommend that the protocol explores implementing automatic capital buffer adjustments and dynamic maturity gap matching. Our analysis demonstrates the practical benefits for scalable (prudential) risk management stemming from real-time availability of high-quality, granular, tamper-resistant on-chain data in the digital asset space. We name this approach Crypto Asset-Liability Management (CALM).",
        "comments": "The authors would like to thank Professor Moorad Choudhry for review comments on an earlier draft. Submitted for the SNB-CIF Conference on Cryptoassets and Financial Innovation, 24 May 2024",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13399"
    },
    {
        "doc_id": 505,
        "title": "An Explicit Scheme for Pathwise XVA Computations",
        "authors": [
            "Lokman Abbas-Turki",
            "St\u00e9phane Cr\u00e9pey",
            "Botao Li",
            "Bouazza Saadeddine"
        ],
        "subjects": [
            "Risk Management",
            "Numerical Analysis",
            "Computational Finance",
            "Machine Learning"
        ],
        "abstract": "Motivated by the equations of cross valuation adjustments (XVAs) in the realistic case where capital is deemed fungible as a source of funding for variation margin, we introduce a simulation/regression scheme for a class of anticipated BSDEs, where the coefficient entails a conditional expected shortfall of the martingale part of the solution. The scheme is explicit in time and uses neural network least-squares and quantile regressions for the embedded conditional expectations and expected shortfall computations. An a posteriori Monte Carlo validation procedure allows assessing the regression error of the scheme at each time step. The superiority of this scheme with respect to Picard iterations is illustrated in a high-dimensional and hybrid market/default risks XVA use-case.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13314"
    },
    {
        "doc_id": 506,
        "title": "Optimizing Transition Strategies for Small to Medium Sized Portfolios",
        "authors": [
            "Nakul Upadhya",
            "Alexandre Granzer-Guay"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "This work discusses the benefits of constrained portfolio turnover strategies for small to medium-sized portfolios. We propose a dynamic multi-period model that aims to minimize transaction costs and maximize terminal wealth levels whilst adhering to strict portfolio turnover constraints. Our results demonstrate that using our framework in combination with a reasonable forecast, can lead to higher portfolio values and lower transaction costs on average when compared to a naive, single-period model. Such results were maintained given different problem cases, such as, trading horizon, assets under management, wealth levels, etc. In addition, the proposed model lends itself to a reformulation that makes use of the column generation algorithm which can be strategically leveraged to reduce complexity and solving times.",
        "comments": "All of the discussed experiments and presented results can be reproduced using our code at https://github.com/upadhyan/Portfolio-Changeover-Optimization",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13126"
    },
    {
        "doc_id": 507,
        "title": "Reference-dependent asset pricing with a stochastic consumption-dividend ratio",
        "authors": [
            "Luca De Gennaro Aquino",
            "Xuedong He",
            "Moris Simon Strub",
            "Yuting Yang"
        ],
        "subjects": [
            "Mathematical Finance",
            "General Finance"
        ],
        "abstract": "We study a discrete-time consumption-based capital asset pricing model under expectations-based reference-dependent preferences. More precisely, we consider an endowment economy populated by a representative agent who derives utility from current consumption and from gains and losses in consumption with respect to a forward-looking, stochastic reference point. First, we consider a general model in which the agent's preferences include both contemporaneous gain-loss utility, that is, utility from the difference between current consumption and previously held expectations about current consumption, and prospective gain-loss utility, that is, utility from the difference between intertemporal beliefs about future consumption. A semi-closed form solution for equilibrium asset prices is derived for this case. We then specialize to a model in which the agent derives contemporaneous gain-loss utility only, obtaining equilibrium asset prices in closed form. Extensive numerical experiments show that, with plausible values of risk aversion and loss aversion, our models can generate equity premia that match empirical estimates. Interestingly, the models turn out to be consistent with some well-known empirical facts, namely procyclical variation in the price-dividend ratio and countercyclical variation in the conditional expected equity premium and in the conditional volatility of the equity premium. Furthermore, we find that prospective gain-loss utility is necessary for the model to predict reasonable values of the price-dividend ratio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12856"
    },
    {
        "doc_id": 508,
        "title": "New approximate stochastic dominance approaches for Enhanced Indexation models",
        "authors": [
            "Francesco Cesarone",
            "Justo Puerto"
        ],
        "subjects": [
            "Portfolio Management",
            "Computational Finance",
            "General Finance"
        ],
        "abstract": "In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczynski (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12669"
    },
    {
        "doc_id": 509,
        "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL Dataset",
        "authors": [
            "Henri Arno",
            "Klaas Mulier",
            "Joke Baeck",
            "Thomas Demeester"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Computational Finance"
        ],
        "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.",
        "comments": "Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12652"
    },
    {
        "doc_id": 510,
        "title": "Are Charter Value and Supervision Aligned? A Segmentation Analysis",
        "authors": [
            "Juan Aparicio",
            "Miguel A. Duran",
            "Ana Lozano-Vivas",
            "Jesus T. Pastor"
        ],
        "subjects": [
            "Risk Management",
            "General Economics"
        ],
        "abstract": "Previous work suggests that the charter value hypothesis is theoretically grounded and empirically supported, but not universally. Accordingly, this paper aims to perform an analysis of the relations between charter value, risk taking, and supervision, taking into account the relations' complexity. Specifically, using the CAMELS rating system as a general framework for supervision, we study how charter value relates to risk and supervision by means of classification and regression tree analysis. The sample covers the period 2005-2016 and consists of listed banks in countries that were members of the Eurozone when it came into existence, along with Greece. To evaluate the crisis consequences, we also separately analyze four subperiods and countries that required financial aid from third parties and those that did not so, along with large and small banks. Our results reflect the complexity of the relations between charter value, supervision, and risk. Indeed, supervision and charter value seem aligned regarding only some types of risk",
        "comments": "46 pages, 4 tables, 5 figures, accepted version of a paper published in the Journal of Financial Stability",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12274"
    },
    {
        "doc_id": 511,
        "title": "General duality and dual attainment for adapted transport",
        "authors": [
            "Daniel Kr\u0161ek",
            "Gudmund Pammer"
        ],
        "subjects": [
            "Probability",
            "Optimization and Control",
            "Mathematical Finance"
        ],
        "abstract": "We investigate duality and existence of dual optimizers for several adapted optimal transport problems under minimal assumptions. This includes the causal and bicausal transport, the barycenter problem, and a general multimarginal problem incorporating causality constraints. Moreover, we discuss applications of our results in robust finance. We consider a non-dominated model of several financial markets where stocks are traded dynamically, but the joint stock dynamics are unknown. We show that a no-arbitrage assumption in a quasi-sure sense naturally leads to sets of multicausal couplings. Consequently, computing the robust superhedging price is equivalent to solving an adapted transport problem, and finding a superhedging strategy means solving the corresponding dual.",
        "comments": "32 pages",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11958"
    },
    {
        "doc_id": 512,
        "title": "Forecasting and Backtesting Gradient Allocations of Expected Shortfall",
        "authors": [
            "Takaaki Koike",
            "Cathy W. S. Chen",
            "Edward M. H. Lin"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Capital allocation is a procedure for quantifying the contribution of each source of risk to aggregated risk. The gradient allocation rule, also known as the Euler principle, is a prevalent rule of capital allocation under which the allocated capital captures the diversification benefit of the marginal risk as a component of overall risk. This research concentrates on Expected Shortfall (ES) as a regulatory standard and focuses on the gradient allocations of ES, also called ES contributions. We achieve the comprehensive treatment of backtesting the tuple of ES contributions in the framework of the traditional and comparative backtests based on the concepts of joint identifiability and multi-objective elicitability. For robust forecast evaluation against the choice of scoring function, we further develop Murphy diagrams for ES contributions as graphical tools to check whether one forecast dominates another under a class of scoring functions. Finally, leveraging the recent concept of multi-objective elicitability, we propose a novel semiparametric model for forecasting dynamic ES contributions based on a compositional regression model. In an empirical analysis of stock returns we evaluate and compare a variety of models for forecasting dynamic ES contributions and demonstrate the outstanding performance of the proposed model.",
        "comments": "MSC Class:          62F07; 62P05; 91B30",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11701"
    },
    {
        "doc_id": 513,
        "title": "A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting",
        "authors": [
            "Riaz Ud Din",
            "Salman Ahmed",
            "Saddam Hussain Khan"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.",
        "comments": "30 pages, 16 Figures, 4 Tables",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11621"
    },
    {
        "doc_id": 514,
        "title": "The geometry of multi-curve interest rate models",
        "authors": [
            "Claudio Fontana",
            "Giacomo Lanaro",
            "Agatha Murgoci"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We study the problems of consistency and of the existence of finite-dimensional realizations for multi-curve interest rate models of Heath-Jarrow-Morton type, generalizing the geometric approach developed by T. Bj\u00f6rk and co-authors in the classical single-curve setting. We characterize when a multi-curve interest rate model is consistent with a given parameterized family of forward curves and spreads and when a model can be realized by a finite-dimensional state process. We illustrate the general theory in a number of model classes and examples, providing explicit constructions of finite-dimensional realizations. Based on these theoretical results, we perform the calibration of a three-curve Hull-White model to market data and analyse the stability of the estimated parameters.",
        "comments": "28 pages, 2 figures",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11619"
    },
    {
        "doc_id": 515,
        "title": "Functional Limit Theorems for Hawkes Processes",
        "authors": [
            "Ulrich Horst",
            "Wei Xu"
        ],
        "subjects": [
            "Probability",
            "Statistics Theory",
            "Mathematical Finance"
        ],
        "abstract": "We prove that the long-run behavior of Hawkes processes is fully determined by the average number and the dispersion of child events. For subcritical processes we provide FLLNs and FCLTs under minimal conditions on the kernel of the process with the precise form of the limit theorems depending strongly on the dispersion of child events. For a critical Hawkes process with weakly dispersed child events, functional central limit theorems do not hold. Instead, we prove that the rescaled intensity processes and rescaled Hawkes processes behave like CIR-processes without mean-reversion, respectively integrated CIR-processes. We provide the rate of convergence by establishing an upper bound on the Wasserstein distance between the distributions of rescaled Hawkes process and the corresponding limit process. By contrast, critical Hawkes process with heavily dispersed child events share many properties of subcritical ones. In particular, functional limit theorems hold. However, unlike subcritical processes critical ones with heavily dispersed child events display long-range dependencies.",
        "comments": "59 pages; Keywords and phrases: Hawkes process, functional limit theorem, regular variation, convergence rate",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11495"
    },
    {
        "doc_id": 516,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 517,
        "title": "Data-driven Option Pricing",
        "authors": [
            "Min Dai",
            "Hanqing Jin",
            "Xi Yang"
        ],
        "subjects": [
            "Pricing of Securities"
        ],
        "abstract": "We propose an innovative data-driven option pricing methodology that relies exclusively on the dataset of historical underlying asset prices. While the dataset is rooted in the objective world, option prices are commonly expressed as discounted expectations of their terminal payoffs in a risk-neutral world. Bridging this gap motivates us to identify a pricing kernel process, transforming option pricing into evaluating expectations in the objective world. We recover the pricing kernel by solving a utility maximization problem, and evaluate the expectations in terms of a functional optimization problem. Leveraging the deep learning technique, we design data-driven algorithms to solve both optimization problems over the dataset. Numerical experiments are presented to demonstrate the efficiency of our methodology.",
        "comments": "15 pages, 3 figures",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11158"
    },
    {
        "doc_id": 518,
        "title": "BioFinBERT: Finetuning Large Language Models (LLMs) to Analyze Sentiment of Press Releases and Financial Text Around Inflection Points of Biotech Stocks",
        "authors": [
            "Valentina Aparicio",
            "Daniel Gordon",
            "Sebastian G. Huayamares",
            "Yuhuai Luo"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "Large language models (LLMs) are deep learning algorithms being used to perform natural language processing tasks in various fields, from social sciences to finance and biomedical sciences. Developing and training a new LLM can be very computationally expensive, so it is becoming a common practice to take existing LLMs and finetune them with carefully curated datasets for desired applications in different fields. Here, we present BioFinBERT, a finetuned LLM to perform financial sentiment analysis of public text associated with stocks of companies in the biotechnology sector. The stocks of biotech companies developing highly innovative and risky therapeutic drugs tend to respond very positively or negatively upon a successful or failed clinical readout or regulatory approval of their drug, respectively. These clinical or regulatory results are disclosed by the biotech companies via press releases, which are followed by a significant stock response in many cases. In our attempt to design a LLM capable of analyzing the sentiment of these press releases,we first finetuned BioBERT, a biomedical language representation model designed for biomedical text mining, using financial textual databases. Our finetuned model, termed BioFinBERT, was then used to perform financial sentiment analysis of various biotech-related press releases and financial text around inflection points that significantly affected the price of biotech stocks.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11011"
    },
    {
        "doc_id": 519,
        "title": "Forecasting Cryptocurrency Staking Rewards",
        "authors": [
            "Sauren Gupta",
            "Apoorva Hathi Katharaki",
            "Yifan Xu",
            "Bhaskar Krishnamachari",
            "Rajarshi Gupta"
        ],
        "subjects": [
            "Statistical Finance",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This research explores a relatively unexplored area of predicting cryptocurrency staking rewards, offering potential insights to researchers and investors. We investigate two predictive methodologies: a) a straightforward sliding-window average, and b) linear regression models predicated on historical data. The findings reveal that ETH staking rewards can be forecasted with an RMSE within 0.7% and 1.1% of the mean value for 1-day and 7-day look-aheads respectively, using a 7-day sliding-window average approach. Additionally, we discern diverse prediction accuracies across various cryptocurrencies, including SOL, XTZ, ATOM, and MATIC. Linear regression is identified as superior to the moving-window average for perdicting in the short term for XTZ and ATOM. The results underscore the generally stable and predictable nature of staking rewards for most assets, with MATIC presenting a noteworthy exception.",
        "comments": "9 pages, 18 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10931"
    },
    {
        "doc_id": 520,
        "title": "Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock",
        "authors": [
            "Dengxin Huang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Applications"
        ],
        "abstract": "This document presents a stock market analysis conducted on a dataset consisting of 750 instances and 16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section, feature engineering, data preparation, model selection, and insights from the analysis. The Fama French 3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear regression being the best-performing model.",
        "comments": "9 pages, 7 figures",
        "date": "31 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10903"
    },
    {
        "doc_id": 521,
        "title": "Stylized Facts and Market Microstructure: An In-Depth Exploration of German Bond Futures Market",
        "authors": [
            "Hamza Bodor",
            "Laurent Carlier"
        ],
        "subjects": [
            "Statistical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper presents an in-depth analysis of stylized facts in the context of futures on German bonds. The study examines four futures contracts on German bonds: Schatz, Bobl, Bund and Buxl, using tick-by-tick limit order book datasets. It uncovers a range of stylized facts and empirical observations, including the distribution of order sizes, patterns of order flow, and inter-arrival times of orders. The findings reveal both commonalities and unique characteristics across the different futures, thereby enriching our understanding of these markets. Furthermore, the paper introduces insightful realism metrics that can be used to benchmark market simulators. The study contributes to the literature on financial stylized facts by extending empirical observations to this class of assets, which has been relatively underexplored in existing research. This work provides valuable guidance for the development of more accurate and realistic market simulators.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10722"
    },
    {
        "doc_id": 522,
        "title": "Dynamic Programming: Finite States",
        "authors": [
            "Thomas J. Sargent",
            "John Stachurski"
        ],
        "subjects": [
            "General Economics",
            "Optimization and Control"
        ],
        "abstract": "This book is about dynamic programming and its applications in economics, finance, and adjacent fields. It brings together recent innovations in the theory of dynamic programming and provides applications and code that can help readers approach the research frontier. The book is aimed at graduate students and researchers, although most chapters are accessible to undergraduate students with solid quantitative backgrounds.",
        "comments": "MSC Class:          90C39",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10473"
    },
    {
        "doc_id": 523,
        "title": "Deep Generative Modeling for Financial Time Series with Application in VaR: A Comparative Review",
        "authors": [
            "Lars Ericson",
            "Xuejun Zhu",
            "Xusi Han",
            "Rao Fu",
            "Shuang Li",
            "Steve Guo",
            "Ping Hu"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "In the financial services industry, forecasting the risk factor distribution conditional on the history and the current market environment is the key to market risk modeling in general and value at risk (VaR) model in particular. As one of the most widely adopted VaR models in commercial banks, Historical simulation (HS) uses the empirical distribution of daily returns in a historical window as the forecast distribution of risk factor returns in the next day. The objectives for financial time series generation are to generate synthetic data paths with good variety, and similar distribution and dynamics to the original historical data. In this paper, we apply multiple existing deep generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for conditional time series generation, and propose and test two new methods for conditional multi-step time series generation, namely Encoder-Decoder CGAN and Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a set of KPIs to measure the quality of the generated time series for financial modeling. The KPIs cover distribution distance, autocorrelation and backtesting. All models (HS, parametric and neural networks) are tested on both historical USD yield curve data and additional data simulated from GARCH and CIR processes. The study shows that top performing models are HS, GARCH and CWGAN models. Future research directions in this area are also discussed.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10370"
    },
    {
        "doc_id": 524,
        "title": "Interplay between Cryptocurrency Transactions and Online Financial Forums",
        "authors": [
            "Ana Fern\u00e1ndez Vilas",
            "Rebeca P. D\u00edaz Redondo",
            "Daniel Couto Cancela",
            "Alejandro Torrado Pazos"
        ],
        "subjects": [
            "General Finance",
            "Computers and Society",
            "Machine Learning"
        ],
        "abstract": "Cryptocurrencies are a type of digital money meant to provide security and anonymity while using cryptography techniques. Although cryptocurrencies represent a breakthrough and provide some important benefits, their usage poses some risks that are a result of the lack of supervising institutions and transparency. Because disinformation and volatility is discouraging for personal investors, cryptocurrencies emerged hand-in-hand with the proliferation of online users' communities and forums as places to share information that can alleviate users' mistrust. This research focuses on the study of the interplay between these cryptocurrency forums and fluctuations in cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin (BTC) and a related active discussion community, Bitcointalk, are analyzed. This study shows that the activity of Bitcointalk forum keeps a direct relationship with the trend in the values of BTC, therefore analysis of this interaction would be a perfect base to support personal investments in a non-regulated market and, to confirm whether cryptocurrency forums show evidences to detect abnormal behaviors in BTC values as well as to predict or estimate these values. The experiment highlights that forum data can explain specific events in the financial field. It also underlines the relevance of quotes (regular mechanism to response a post) at periods: (1) when there is a high concentration of posts around certain topics; (2) when peaks in the BTC price are observed; and, (3) when the BTC price gradually shifts downwards and users intend to sell.",
        "comments": "Journal ref:        Mathematics 2021, 9(4), 411;",
        "date": "27 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10238"
    },
    {
        "doc_id": 525,
        "title": "An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)",
        "authors": [
            "Garvit Arora",
            "Shubhangi Shubhangi",
            "Ying Wu",
            "Xuan Mei"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10162"
    },
    {
        "doc_id": 526,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 527,
        "title": "Consistent asset modelling with random coefficients and switches between regimes",
        "authors": [
            "Felix L. Wolf",
            "Griselda Deelstra",
            "Lech A. Grzelak"
        ],
        "subjects": [
            "Pricing of Securities",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "We explore a stochastic model that enables capturing external influences in two specific ways. The model allows for the expression of uncertainty in the parametrisation of the stochastic dynamics and incorporates patterns to account for different behaviours across various times or regimes. To establish our framework, we initially construct a model with random parameters, where the switching between regimes can be dictated either by random variables or deterministically. Such a model is highly interpretable. We further ensure mathematical consistency by demonstrating that the framework can be elegantly expressed through local volatility models taking the form of standard jump diffusions. Additionally, we consider a Markov-modulated approach for the switching between regimes characterised by random parameters. For all considered models, we derive characteristic functions, providing a versatile tool with wide-ranging applications. In a numerical experiment, we apply the framework to the financial problem of option pricing. The impact of parameter uncertainty is analysed in a two-regime model, where the asset process switches between periods of high and low volatility imbued with high and low uncertainty, respectively.",
        "comments": "MSC Class:          91G20 91G30",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09955"
    },
    {
        "doc_id": 528,
        "title": "Cross-Domain Behavioral Credit Modeling: transferability from private to central data",
        "authors": [
            "O. Didkovskyi",
            "N. Jean",
            "G. Le Pera",
            "C. Nordio"
        ],
        "subjects": [
            "Risk Management",
            "Statistical Finance"
        ],
        "abstract": "This paper introduces a credit risk rating model for credit risk assessment in quantitative finance, aiming to categorize borrowers based on their behavioral data. The model is trained on data from Experian, a widely recognized credit bureau, to effectively identify instances of loan defaults among bank customers. Employing state-of-the-art statistical and machine learning techniques ensures the model's predictive accuracy. Furthermore, we assess the model's transferability by testing it on behavioral data from the Bank of Italy, demonstrating its potential applicability across diverse datasets during prediction. This study highlights the benefits of incorporating external behavioral data to improve credit risk assessment in financial institutions.",
        "comments": "25 pages, 15 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09778"
    },
    {
        "doc_id": 529,
        "title": "Neural Hawkes: Non-Parametric Estimation in High Dimension and Causality Analysis in Cryptocurrency Markets",
        "authors": [
            "Timoth\u00e9e Fabre",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Mathematical Finance"
        ],
        "abstract": "We propose a novel approach to marked Hawkes kernel inference which we name the moment-based neural Hawkes estimation method. Hawkes processes are fully characterized by their first and second order statistics through a Fredholm integral equation of the second kind. Using recent advances in solving partial differential equations with physics-informed neural networks, we provide a numerical procedure to solve this integral equation in high dimension. Together with an adapted training pipeline, we give a generic set of hyperparameters that produces robust results across a wide range of kernel shapes. We conduct an extensive numerical validation on simulated data. We finally propose two applications of the method to the analysis of the microstructure of cryptocurrency markets. In a first application we extract the influence of volume on the arrival rate of BTC-USD trades and in a second application we analyze the causality relationships and their directions amongst a universe of 15 cryptocurrency pairs in a centralized exchange.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09361"
    },
    {
        "doc_id": 530,
        "title": "A closer look at the chemical potential of an ideal agent system",
        "authors": [
            "Christoph J. B\u00f6rner",
            "Ingo Hoffmann",
            "John H. Stiebel"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Models for spin systems known from statistical physics are used in econometrics in the form of agent-based models. Econophysics research in econometrics is increasingly developing general market models that describe exchange phenomena and use the chemical potential $\u03bc$ known from physics in the context of particle number changes. In statistical physics, equations of state are known for the chemical potential, which take into account the respective model framework and the corresponding state variables. A simple transfer of these equations of state to problems in econophysics appears difficult. To the best of our knowledge, the equation of state for the chemical potential is currently missing even for the simplest conceivable model of an ideal agent system. In this paper, this research gap is closed and the equation of state for the chemical potential is derived from the econophysical model assumptions of the ideal agent system. An interpretation of the equation of state leads to fundamental relationships that could also have been guessed, but are shown here by the theory.",
        "comments": "11 Pages, 0 Figures, Working Paper, Theoretical Contribution",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09233"
    },
    {
        "doc_id": 531,
        "title": "Mean-Field SDEs driven by $G$-Brownian Motion",
        "authors": [
            "Karl-Wilhelm Georg Bollweg",
            "Thilo Meyer-Brandis"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We extend the notion of mean-field SDEs to SDEs driven by $G$-Brownian motion. More precisely, we consider a $G$-SDE where the coefficients depend not only on time and the current state but also on the solution as random variable.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09113"
    },
    {
        "doc_id": 532,
        "title": "AI Thrust: Ranking Emerging Powers for Tech Startup Investment in Latin America",
        "authors": [
            "Abraham Ramos Torres",
            "Laura N Montoya"
        ],
        "subjects": [
            "General Economics",
            "Risk Management"
        ],
        "abstract": "Artificial intelligence (AI) is rapidly transforming the global economy, and Latin America is no exception. In recent years, there has been a growing interest in AI development and implementation in the region. This paper presents a ranking of Latin American (LATAM) countries based on their potential to become emerging powers in AI. The ranking is based on three pillars: infrastructure, education, and finance. Infrastructure is measured by the availability of electricity, high-speed internet, the quality of telecommunications networks, and the availability of supercomputers. Education is measured by the quality of education and the research status. Finance is measured by the cost of investments, history of investments, economic metrics, and current implementation of AI.\n  While Brazil, Chile, and Mexico have established themselves as major players in the AI industry in Latin America, our ranking demonstrates the new emerging powers in the region. According to the results, Argentina, Colombia, Uruguay, Costa Rica, and Ecuador are leading as new emerging powers in AI in Latin America. These countries have strong education systems, well-developed infrastructure, and growing financial resources. The ranking provides a useful tool for policymakers, investors, and businesses interested in AI development in Latin America. It can help to identify emerging LATAM countries with the greatest potential for AI growth and success.",
        "comments": "9 pages, 4 tables, 9 figures",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09056"
    },
    {
        "doc_id": 533,
        "title": "On continuity of state-dependent utilities",
        "authors": [
            "Edoardo Berton",
            "Alessandro Doldi",
            "Marco Maggis"
        ],
        "subjects": [
            "Mathematical Finance",
            "Theoretical Economics"
        ],
        "abstract": "State-dependent preferences for a general Savage's state space were shown in Wakker and Zank (1999) to admit a numerical representation in the form of the integral of a state-dependent utility, as soon as pointwise continuity of the preference ordering is assumed. In this paper we prove that such a state-dependent function inherits pointwise continuity from the preference ordering, providing in this way a positive answer to a conjecture posed in the aforementioned seminal work. We further apply this result to obtain an explicit representation of conditional Chisini means in the form of a conditional certainty equivalent.",
        "comments": "MSC Class:          91B06; 91B08; 60A05",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09054"
    },
    {
        "doc_id": 534,
        "title": "Spurious Default Probability Projections in Credit Risk Stress Testing Models",
        "authors": [
            "Bernd Engelmann"
        ],
        "subjects": [
            "Risk Management"
        ],
        "abstract": "Credit risk stress testing has become an important risk management device which is used both by banks internally and by regulators. Stress testing is complex because it essentially means projecting a bank's full balance sheet conditional on a macroeconomic scenario over multiple years. Part of the complexity stems from using a wide range of model parameters for, e.g., rating transition, write-off rules, prepayment, or origination of new loans. A typical parameterization of a credit risk stress test model specifies parameters linked to an average economic, the through-the-cycle, state. These parameters are transformed to a stressed state by utilizing a macroeconomic model. It will be shown that the model parameterization implies a unique through-the-cycle portfolio which is unrelated to a bank's current portfolio. Independent of the stress imposed to the model, the current portfolio will have a tendency to propagate towards the through-the-cycle portfolio. This could create unwanted spurious effects on projected portfolio default rates especially when a stress test model's parameterization is inconsistent with a bank's current portfolio.",
        "comments": "15 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08892"
    },
    {
        "doc_id": 535,
        "title": "Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks",
        "authors": [
            "Xihan Xiong",
            "Zhipeng Wang",
            "Xi Chen",
            "William Knottenbelt",
            "Michael Huth"
        ],
        "subjects": [
            "General Finance",
            "Cryptography and Security"
        ],
        "abstract": "Lido, the leading Liquid Staking Derivative (LSD) provider on Ethereum, allows users to stake an arbitrary amount of ETH to receive stETH, which can be integrated with Decentralized Finance (DeFi) protocols such as Aave. The composability between Lido and Aave enables a novel strategy called \"leverage staking\", where users stake ETH on Lido to acquire stETH, utilize stETH as collateral on Aave to borrow ETH, and then restake the borrowed ETH on Lido. Users can iteratively execute this process to optimize potential returns based on their risk profile.\n  This paper systematically studies the opportunities and risks associated with leverage staking. We are the first to formalize the leverage staking strategy within the Lido-Aave ecosystem. Our empirical study identifies 262 leverage staking positions on Ethereum, with an aggregated staking amount of 295,243 ETH (482M USD). We discover that 90.13% of leverage staking positions have achieved higher returns than conventional staking. Furthermore, we perform stress tests to evaluate the risk introduced by leverage staking under extreme conditions. We find that leverage staking significantly amplifies the risk of cascading liquidations. We hope this paper can inform and encourage the development of robust risk management approaches to protect the Lido-Aave LSD ecosystem.",
        "comments": " ",
        "date": "28 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08610"
    },
    {
        "doc_id": 536,
        "title": "Forking paths in financial economics",
        "authors": [
            "Guillaume Coqueret"
        ],
        "subjects": [
            "General Finance",
            "Methodology"
        ],
        "abstract": "We argue that spanning large numbers of degrees of freedom in empirical analysis allows better characterizations of effects and thus improves the trustworthiness of conclusions. Our ideas are illustrated in three studies: equity premium prediction, asset pricing anomalies and risk premia estimation. In the first, we find that each additional degree of freedom in the protocol expands the average range of $t$-statistics by at least 30%. In the second, we show that resorting to forking paths instead of bootstrapping in multiple testing raises the bar of significance for anomalies: at the 5% confidence level, the threshold for bootstrapped statistics is 4.5, whereas with paths, it is at least 8.2, a bar much higher than those currently used in the literature. In our third application, we reveal the importance of particular steps in the estimation of premia. In addition, we use paths to corroborate prior findings in the three topics. We document heterogeneity in our ability to replicate prior studies: some conclusions seem robust, others do not align with the paths we were able to generate.",
        "comments": " ",
        "date": "25 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08606"
    },
    {
        "doc_id": 537,
        "title": "Reinforcement Learning and Deep Stochastic Optimal Control for Final Quadratic Hedging",
        "authors": [
            "Bernhard Hientzsch"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "We consider two data driven approaches, Reinforcement Learning (RL) and Deep Trajectory-based Stochastic Optimal Control (DTSOC) for hedging a European call option without and with transaction cost according to a quadratic hedging P&L objective at maturity (\"variance-optimal hedging\" or \"final quadratic hedging\"). We study the performance of the two approaches under various market environments (modeled via the Black-Scholes and/or the log-normal SABR model) to understand their advantages and limitations. Without transaction costs and in the Black-Scholes model, both approaches match the performance of the variance-optimal Delta hedge. In the log-normal SABR model without transaction costs, they match the performance of the variance-optimal Barlett's Delta hedge. Agents trained on Black-Scholes trajectories with matching initial volatility but used on SABR trajectories match the performance of Bartlett's Delta hedge in average cost, but show substantially wider variance. To apply RL approaches to these problems, P&L at maturity is written as sum of step-wise contributions and variants of RL algorithms are implemented and used that minimize expectation of second moments of such sums.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.07996",
        "date": "20 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.08600"
    },
    {
        "doc_id": 538,
        "title": "Fitting random cash management models to data",
        "authors": [
            "Francisco Salas-Molina"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Organizations use cash management models to control balances to both avoid overdrafts and obtain a profit from short-term investments. Most management models are based on control bounds which are derived from the assumption of a particular cash flow probability distribution. In this paper, we relax this strong assumption to fit cash management models to data by means of stochastic and linear programming. We also introduce ensembles of random cash management models which are built by randomly selecting a subsequence of the original cash flow data set. We illustrate our approach by means of a real case study showing that a small random sample of data is enough to fit sufficiently good bound-based models.",
        "comments": "19 pages,6 figures, 1 table",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08548"
    },
    {
        "doc_id": 539,
        "title": "Dynamic portfolio selection under generalized disappointment aversion",
        "authors": [
            "Zongxia Liang",
            "Sheng Wang",
            "Jianming Xia",
            "Fengyi Yuan"
        ],
        "subjects": [
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "This paper addresses the continuous-time portfolio selection problem under generalized disappointment aversion (GDA). The implicit definition of the certainty equivalent within GDA preferences introduces time inconsistency to this problem. We provide the sufficient and necessary conditions for a strategy to be an equilibrium by a fully nonlinear ordinary differential equation (ODE). Through an exploration of the existence and uniqueness of solution to the ODE, we establish the existence and uniqueness of the equilibrium. Our findings indicate that under disappointment aversion (DA) preferences, non-participation in the stock market is the unique equilibrium. The numerical analysis reveals that, under GDA preferences, the investment proportion in the stock market consistently remains smaller than the investment proportion under the classical Expected Utility (EU) theory.",
        "comments": "27 pages, 4 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08323"
    },
    {
        "doc_id": 540,
        "title": "Do backrun auctions protect traders?",
        "authors": [
            "Andrew W. Macpherson"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Distributed, Parallel, and Cluster Computing",
            "Computer Science and Game Theory"
        ],
        "abstract": "We study a new \"laminated\" queueing model for orders on batched trading venues such as decentralised exchanges. The model aims to capture and generalise transaction queueing infrastructure that has arisen to organise MEV activity on public blockchains such as Ethereum, providing convenient channels for sophisticated agents to extract value by acting on end-user order flow by performing arbitrage and related HFT activities. In our model, market orders are interspersed with orders created by arbitrageurs that under idealised conditions reset the marginal price to a global equilibrium between each trade, improving predictability of execution for liquidity traders.\n  If an arbitrageur has a chance to land multiple opportunities in a row, he may attempt to manipulate the execution price of the intervening market order by a probabilistic blind sandwiching strategy. To study how bad this manipulation can get, we introduce and bound a price manipulation coefficient that measures the deviation from global equilibrium of local pricing quoted by a rational arbitrageur. We exhibit cases in which this coefficient is well approximated by a \"zeta value' with interpretable and empirically measurable parameters.",
        "comments": "Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08302"
    },
    {
        "doc_id": 541,
        "title": "Optimal Insurance to Maximize Exponential Utility when Premium is Computed by a Convex Functional",
        "authors": [
            "Jingyi Cao",
            "Dongchen Li",
            "Virginia R. Young",
            "Bin Zou"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Risk Management"
        ],
        "abstract": "We find the optimal indemnity to maximize the expected utility of terminal wealth of a buyer of insurance whose preferences are modeled by an exponential utility. The insurance premium is computed by a convex functional. We obtain a necessary condition for the optimal indemnity; then, because the candidate optimal indemnity is given implicitly, we use that necessary condition to develop a numerical algorithm to compute it. We prove that the numerical algorithm converges to a unique indemnity that, indeed, equals the optimal policy. We also illustrate our results with numerical examples.",
        "comments": "12 pages, 3 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08094"
    },
    {
        "doc_id": 542,
        "title": "A Two-Step Longstaff Schwartz Monte Carlo Approach to Game Option Pricing",
        "authors": [
            "Ce Wang"
        ],
        "subjects": [
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "We proposed a two-step Longstaff Schwartz Monte Carlo (LSMC) method with two regression models fitted at each time step to price game options. Although the original LSMC can be used to price game options with an enlarged range of path in regression and a modified cashflow updating rule, we identified a drawback of such approach, which motivated us to propose our approach. We implemented numerical examples with benchmarks using binomial tree and numerical PDE, and it showed that our method produces more reliable results comparing to the original LSMC.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08093"
    },
    {
        "doc_id": 543,
        "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
        "authors": [
            "Shubham Singh",
            "Mayur Bhat"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Pricing of Securities"
        ],
        "abstract": "The research delves into the capabilities of a transformer-based neural network for Ethereum cryptocurrency price forecasting. The experiment runs around the hypothesis that cryptocurrency prices are strongly correlated with other cryptocurrencies and the sentiments around the cryptocurrency. The model employs a transformer architecture for several setups from single-feature scenarios to complex configurations incorporating volume, sentiment, and correlated cryptocurrency prices. Despite a smaller dataset and less complex architecture, the transformer model surpasses ANN and MLP counterparts on some parameters. The conclusion presents a hypothesis on the illusion of causality in cryptocurrency price movements driven by sentiments.",
        "comments": "12 pages",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08077"
    },
    {
        "doc_id": 544,
        "title": "Provisions and Economic Capital for Credit Losses",
        "authors": [
            "Dorinel Bastide",
            "St\u00e9phane Cr\u00e9pey"
        ],
        "subjects": [
            "Risk Management",
            "Probability",
            "General Finance"
        ],
        "abstract": "Based on supermodularity ordering properties, we show that convex risk measures of credit losses are nondecreasing  w.r.t. credit-credit and, in a wrong-way risk setup, credit-market, covariances of elliptically distributed latent factors. These results support the use of such setups for computing credit provisions and economic capital or for conducting stress test exercises and risk management analysis.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07728"
    },
    {
        "doc_id": 545,
        "title": "Cash and Card Acceptance in Retail Payments: Motivations and Factors",
        "authors": [
            "Samuel Vandak",
            "Geoffrey Goodell"
        ],
        "subjects": [
            "Computers and Society",
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The landscape of payment methods in retail is a complex and evolving area. Vendors are motivated to conduct an appropriate analysis to decide what payment methods to accept out of a vast range of options. Many factors are included in this decision process, some qualitative and some quantitative. The following research project investigates vendors' acceptance of cards and cash from various viewpoints, all chosen to represent a novel perspective, including the barriers and preferences for each and correlations with external demographic factors. We observe that lower interchange fees, limited in this instance by the regulatory framework, play a crucial role in facilitating merchants' acceptance of card payments. The regulatory constraints on interchange fees create a favorable cost structure for merchants, making card payment adoption financially feasible. However, additional factors like technological readiness and consumer preferences might also play a significant role in their decision-making process. We also note that aggregate Merchant Service Providers (MSPs) have positively impacted the payment landscape by offering more competitive fee rates, particularly beneficial for small merchants and entrepreneurs. However, associated risks, such as account freezes or abrupt terminations, pose challenges and often lack transparency. Last, the quantitative analysis of the relationship between demographic variables and acceptance of payment types is presented. This analysis combines the current landscape of payment acceptance in the UK with data from the most recent census from 2021. We show that the unemployment rates shape card and cash acceptance, age affects contactless preference, and work-from-home impacts credit card preference.",
        "comments": "34 pages, 19 figures, 5 tables",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07682"
    },
    {
        "doc_id": 546,
        "title": "Empirical Evidence for the Fragment level Understanding on Drug Molecular Structure of LLMs",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Machine Learning",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "AI for drug discovery has been a research hotspot in recent years, and SMILES-based language models has been increasingly applied in drug molecular design. However, no work has explored whether and how language models understand the chemical spatial structure from 1D sequences. In this work, we pre-train a transformer model on chemical language and fine-tune it toward drug design objectives, and investigate the correspondence between high-frequency SMILES substrings and molecular fragments. The results indicate that language models can understand chemical structures from the perspective of molecular fragments, and the structural knowledge learned through fine-tuning is reflected in the high-frequency SMILES substrings generated by the model.",
        "comments": "Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07657"
    },
    {
        "doc_id": 547,
        "title": "Graph database while computationally efficient filters out quickly the ESG integrated equities in investment management",
        "authors": [
            "Partha Sen",
            "Sumana Sen"
        ],
        "subjects": [
            "Computational Finance"
        ],
        "abstract": "Design/methodology/approach This research evaluated the databases of SQL, No-SQL and graph databases to compare and contrast efficiency and performance. To perform this experiment the data were collected from multiple sources including stock price and financial news. Python is used as an interface to connect and query databases (to create database structures according to the feed file structure, to load data into tables, objects, to read data , to connect PostgreSQL, ElasticSearch, Neo4j. Purpose Modern applications of LLM (Large language model) including RAG (Retrieval Augmented Generation) with Machine Learning, deep learning, NLP (natural language processing) or Decision Analytics are computationally expensive. Finding a better option to consume less resources and time to get the result. Findings The Graph database of ESG (Environmental, Social and Governance) is comparatively better and can be considered for extended analytics to integrate ESG in business and investment. Practical implications A graph ML with a RAG architecture model can be introduced as a new framework with less computationally expensive LLM application in the equity filtering process for portfolio management. Originality/value Filtering out selective stocks out of two thousand or more listed companies in any stock exchange for active investment, consuming less resource consumption especially memory and energy to integrate artificial intelligence and ESG in business and investment.",
        "comments": "10 pages, 17 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07483"
    },
    {
        "doc_id": 548,
        "title": "Herd Behavior in Optimal Investment: A Dual-Agent Approach with Investment Opinion and Rational Decision Decomposition",
        "authors": [
            "Huisheng Wang",
            "H. Vicky Zhao"
        ],
        "subjects": [
            "Systems and Control",
            "Optimization and Control",
            "Mathematical Finance",
            "Portfolio Management"
        ],
        "abstract": "In this paper, we study the optimal investment problem involving two agents, where the decision of one agent is influenced by the other. To measure the distance between two agents' decisions, we introduce the average deviation. We formulate the stochastic optimal control problem considering herd behavior and derive the analytical solution through the variational method. We theoretically analyze the impact of users' herd behavior on the optimal decision by decomposing it into their rational decisions, which is called the rational decision decomposition. Furthermore, to quantify the preference for their rational decision over that of the other agent, we introduce the agent's investment opinion. Our study is validated through simulations on real stock data.",
        "comments": " ",
        "date": "13 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.07183"
    },
    {
        "doc_id": 549,
        "title": "DocFinQA: A Long-Context Financial Reasoning Dataset",
        "authors": [
            "Varshini Reddy",
            "Rik Koncel-Kedziorski",
            "Viet Dac Lai",
            "Chris Tanner"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence"
        ],
        "abstract": "Research in quantitative reasoning within the financial domain indeed necessitates the use of realistic tasks and data, primarily because of the significant impact of decisions made in business and finance. Financial professionals often interact with documents hundreds of pages long, but most research datasets drastically reduce this context length. To address this, we introduce a long-document financial QA task. We augment 7,621 questions from the existing FinQA dataset with full-document context, extending the average context length for each question from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and long-context language models on the augmented data. Our results show that DocFinQA provides challenges for even the strongest, state-of-the-art systems.",
        "comments": "13 pages",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06915"
    },
    {
        "doc_id": 550,
        "title": "A deep implicit-explicit minimizing movement method for option pricing in jump-diffusion models",
        "authors": [
            "Emmanuil H. Georgoulis",
            "Antonis Papapantoleon",
            "Costas Smaragdakis"
        ],
        "subjects": [
            "Computational Finance",
            "Machine Learning",
            "Numerical Analysis",
            "Probability",
            "Machine Learning"
        ],
        "abstract": "We develop a novel deep learning approach for pricing European basket options written on assets that follow jump-diffusion dynamics. The option pricing problem is formulated as a partial integro-differential equation, which is approximated via a new implicit-explicit minimizing movement time-stepping approach, involving approximation by deep, residual-type Artificial Neural Networks (ANNs) for each time step. The integral operator is discretized via two different approaches: a) a sparse-grid Gauss--Hermite approximation following localised coordinate axes arising from singular value decompositions, and b) an ANN-based high-dimensional special-purpose quadrature rule. Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of the solution for large values of the underlyings and also leads to consistent outputs with respect to a priori known qualitative properties of the solution. The performance and robustness with respect to the dimension of the methods are assessed in a series of numerical experiments involving the Merton jump-diffusion model.",
        "comments": "16 pages, 11 figures",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06740"
    },
    {
        "doc_id": 551,
        "title": "Equity auction dynamics: latent liquidity models with activity acceleration",
        "authors": [
            "Mohammed Salek",
            "Damien Challet",
            "Ioane Muni Toke"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Finance"
        ],
        "abstract": "Equity auctions display several distinctive characteristics in contrast to continuous trading. As the auction time approaches, the rate of events accelerates causing a substantial liquidity buildup around the indicative price. This, in turn, results in a reduced price impact and decreased volatility of the indicative price. In this study, we adapt the latent/revealed order book framework to the specifics of equity auctions. We provide precise measurements of the model parameters, including order submissions, cancellations, and diffusion rates. Our setup allows us to describe the full dynamics of the average order book during closing auctions in Euronext Paris. These findings support the relevance of the latent liquidity framework in describing limit order book dynamics. Lastly, we analyze the factors contributing to a sub-diffusive indicative price and demonstrate the absence of indicative price predictability.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06724"
    },
    {
        "doc_id": 552,
        "title": "SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks",
        "authors": [
            "Alessio Brini",
            "Giacomo Toscano"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Finance"
        ],
        "abstract": "This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents financial assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with high-frequency prices of the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net shows improved accuracy, compared to alternative econometric and machine-learning-based models. Further, our results show that SpotV2Net maintains accuracy when performing intraday multi-step forecasts. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer, a model-agnostic interpretability tool and thereby uncover subgraphs that are critical to a node's predictions.",
        "comments": "34 pages, 9 figures",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06249"
    },
    {
        "doc_id": 553,
        "title": "CNN-DRL for Scalable Actions in Finance",
        "authors": [
            "Sina Montazeri",
            "Akram Mirzaeinia",
            "Haseebullah Jumakhan",
            "Amir Mirzaeinia"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "The published MLP-based DRL in finance has difficulties in learning the dynamics of the environment when the action scale increases. If the buying and selling increase to one thousand shares, the MLP agent will not be able to effectively adapt to the environment. To address this, we designed a CNN agent that concatenates the data from the last ninety days of the daily feature vector to create the CNN input matrix. Our extensive experiments demonstrate that the MLP-based agent experiences a loss corresponding to the initial environment setup, while our designed CNN remains stable, effectively learns the environment, and leads to an increase in rewards.",
        "comments": "10th Annual Conf. on Computational Science & Computational Intelligence",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06179"
    },
    {
        "doc_id": 554,
        "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods",
        "authors": [
            "Yue Chen",
            "Xingyi Andrew",
            "Salintip Supasanya"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.",
        "comments": "14 pages, 9 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.06172"
    },
    {
        "doc_id": 555,
        "title": "Multimodal Gen-AI for Fundamental Investment Research",
        "authors": [
            "Lezhi Li",
            "Ting-Yu Chang",
            "Hai Wang"
        ],
        "subjects": [
            "General Finance",
            "Machine Learning"
        ],
        "abstract": "This report outlines a transformative initiative in the financial investment industry, where the conventional decision-making process, laden with labor-intensive tasks such as sifting through voluminous documents, is being reimagined. Leveraging language models, our experiments aim to automate information summarization and investment idea generation. We seek to evaluate the effectiveness of fine-tuning methods on a base model (Llama2) to achieve specific application-level goals, including providing insights into the impact of events on companies and sectors, understanding market condition relationships, generating investor-aligned investment ideas, and formatting results with stock recommendations and detailed explanations. Through state-of-the-art generative modeling techniques, the ultimate objective is to develop an AI agent prototype, liberating human investors from repetitive tasks and allowing a focus on high-level strategic thinking. The project encompasses a diverse corpus dataset, including research reports, investment memos, market news, and extensive time-series market data. We conducted three experiments applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat as the base model, as well as instruction fine-tuning on the GPT3.5 model. Statistical and human evaluations both show that the fine-tuned versions perform better in solving text modeling, summarization, reasoning, and finance domain questions, demonstrating a pivotal step towards enhancing decision-making processes in the financial domain. Code implementation for the project can be found on GitHub: https://github.com/Firenze11/finance_lm.",
        "comments": " ",
        "date": "23 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06164"
    },
    {
        "doc_id": 556,
        "title": "De novo Drug Design using Reinforcement Learning with Multiple GPT Agents",
        "authors": [
            "Xiuyuan Hu",
            "Guoqing Liu",
            "Yang Zhao",
            "Hao Zhang"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "De novo drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.",
        "comments": "Accepted by NeurIPS 2023",
        "date": "21 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06155"
    },
    {
        "doc_id": 557,
        "title": "A Statistical Field Perspective on Capital Allocation and Accumulation: Individual dynamics",
        "authors": [
            "Pierre Gosselin",
            "A\u00efleen Lotz"
        ],
        "subjects": [
            "General Finance",
            "High Energy Physics - Theory"
        ],
        "abstract": "We have shown, in a series of articles, that a classical description of a large number of economic agents can be replaced by a statistical fields formalism. To better understand the accumulation and allocation of capital among different sectors, the present paper applies this statistical fields description to a large number of heterogeneous agents divided into two groups. The first group is composed of a large number of firms in different sectors that collectively own the entire physical capital. The second group, investors, holds the entire financial capital and allocates it between firms across sectors according to investment preferences, expected returns, and stock prices variations on financial markets. In return, firms pay dividends to their investors. Financial capital is thus a function of dividends and stock valuations, whereas physical capital is a function of the total capital allocated by the financial sector. Whereas our previous work focused on the background fields that describe potential long-term equilibria, here we compute the transition functions of individual agents and study their probabilistic dynamics in the background field, as a function of their initial state. We show that capital accumulation depends on various factors. The probability associated with each firm's trajectories is the result of several contradictory effects: the firm tends to shift towards sectors with the greatest long-term return, but must take into account the impact of its shift on its attractiveness for investors throughout its trajectory. Since this trajectory depends largely on the average capital of transition sectors, a firm's attractiveness during its relocation depends on the relative level of capital in those sectors. Thus, an under-capitalized firm reaching a high-capital sector will experience a loss of attractiveness, and subsequently, in investors. Moreover, the firm must also consider the effects of competition in the intermediate sectors. An under-capitalized firm will tend to be ousted out towards sectors with lower average capital, while an over-capitalized firm will tend to shift towards higher averagecapital sectors. For investors, capital allocation depends on their short and long-term returns. These returns are not independent: in the short-term, returns are composed of both the firm's dividends and the increase in its stock prices. In the long-term, returns are based on the firm's growth expectations, but also, indirectly, on expectations of higher stock prices. Investors' capital allocation directly depends on the volatility of stock prices and {\\ldots}rms'dividends. Investors will tend to reallocate their capital to maximize their short and long-term returns. The higher their level of capital, the stronger the reallocation will be.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2312.16173, arXiv:2205.03087",
        "date": "30 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06142"
    },
    {
        "doc_id": 558,
        "title": "StockFormer: A Swing Trading Strategy Based on STL Decomposition and Self-Attention Networks",
        "authors": [
            "Bohan Ma",
            "Yiheng Wang",
            "Yuchao Lu",
            "Tianzixuan Hu",
            "Jinling Xu",
            "Patrick Houlihan"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Machine Learning"
        ],
        "abstract": "Amidst ongoing market recalibration and increasing investor optimism, the U.S. stock market is experiencing a resurgence, prompting the need for sophisticated tools to protect and grow portfolios. Addressing this, we introduce \"Stockformer,\" a cutting-edge deep learning framework optimized for swing trading, featuring the TopKDropout method for enhanced stock selection. By integrating STL decomposition and self-attention networks, Stockformer utilizes the S&P 500's complex data to refine stock return predictions. Our methodology entailed segmenting data for training and validation (January 2021 to January 2023) and testing (February to June 2023). During testing, Stockformer's predictions outperformed ten industry models, achieving superior precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a remarkable accuracy rate of 62.39% in detecting market trends. In our backtests, Stockformer's swing trading strategy yielded a cumulative return of 13.19% and an annualized return of 30.80%, significantly surpassing current state-of-the-art models. Stockformer has emerged as a beacon of innovation in these volatile times, offering investors a potent tool for market forecasting. To advance the field and foster community collaboration, we have open-sourced Stockformer, available at https://github.com/Eric991005/Stockformer.",
        "comments": "Currently under consideration for publication in the International Journal of Forecasting",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.06139"
    },
    {
        "doc_id": 559,
        "title": "Quantum Probability Theoretic Asset Return Modeling: A Novel Schr\u00f6dinger-Like Trading Equation and Multimodal Distribution",
        "authors": [
            "Li Lin"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "Quantum theory provides a comprehensive framework for quantifying uncertainty, often applied in quantum finance to explore the stochastic nature of asset returns. This perspective likens returns to microscopic particle motion, governed by quantum probabilities akin to physical laws. However, such approaches presuppose specific microscopic quantum effects in return changes, a premise criticized for lack of guarantee. This paper diverges by asserting that quantum probability is a mathematical extension of classical probability to complex numbers. It isn't exclusively tied to microscopic quantum phenomena, bypassing the need for quantum effects in returns.By directly linking quantum probability's mathematical structure to traders' decisions and market behaviors, it avoids assuming quantum effects for returns and invoking the wave function. The complex phase of quantum probability, capturing transitions between long and short decisions while considering information interaction among traders, offers an inherent advantage over classical probability in characterizing the multimodal distribution of asset returns.Utilizing Fourier decomposition, we derive a Schr\u00f6dinger-like trading equation, where each term explicitly corresponds to implications of market trading. The equation indicates discrete energy levels in financial trading, with returns following a normal distribution at the lowest level. As the market transitions to higher trading levels, a phase shift occurs in the return distribution, leading to multimodality and fat tails. Empirical research on the Chinese stock market supports the existence of energy levels and multimodal distributions derived from this quantum probability asset returns model.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05823"
    },
    {
        "doc_id": 560,
        "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
        "authors": [
            "Frank Xing"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Multiagent Systems",
            "General Finance"
        ],
        "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
        "comments": "15 pages",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05799"
    },
    {
        "doc_id": 561,
        "title": "Super-hedging-pricing formulas and Immediate-Profit arbitrage for market models under random horizon",
        "authors": [
            "Tahir Choulli",
            "Emmanuel Lepinette"
        ],
        "subjects": [
            "Mathematical Finance",
            "Optimization and Control",
            "Probability",
            "Pricing of Securities"
        ],
        "abstract": "In this paper, we consider the discrete-time setting, and the market model described by (S,F,T)$. Herein F is the ``public\" flow of information which is available to all agents overtime, S is the discounted price process of d-tradable assets, and T is an arbitrary random time whose occurrence might not be observable via F. Thus, we consider the larger flow G which incorporates F and makes T an observable random time. This framework covers the credit risk theory setting, the life insurance setting and the setting of employee stock option valuation. For the stopped model (S^T,G) and for various vulnerable claims, based on this model, we address the super-hedging pricing valuation problem and its intrinsic Immediate-Profit arbitrage (IP hereafter for short). Our first main contribution lies in singling out the impact of change of prior and/or information on conditional essential supremum, which is a vital tool in super-hedging pricing. The second main contribution consists of describing as explicit as possible how the set of super-hedging prices expands under the stochasticity of T and its risks, and we address the IP arbitrage for (S^T,G) as well. The third main contribution resides in elaborating as explicit as possible pricing formulas for vulnerable claims, and singling out the various informational risks in the prices' dynamics.",
        "comments": " ",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05713"
    },
    {
        "doc_id": 562,
        "title": "Boundary conditions at infinity for Black-Scholes equations",
        "authors": [
            "Yukihiro Tsuzuki"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance"
        ],
        "abstract": "We propose numerical procedures for computing the prices of forward contracts where the underlying asset price is a Markovian local martingale. If the underlying process is a strict local martingale, multiple solutions exist for the corresponding Black-Scholes equations, and the derivative prices are characterized as the minimal solutions. Our prices are upper and lower bounds obtained using numerical methods on a finite grid under the respective boundary conditions. These bounds and the boundary values converge to the exact value as the underlying price approaches infinity. The proposed procedures are demonstrated through numerical tests.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05549"
    },
    {
        "doc_id": 563,
        "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
        "authors": [
            "Baptiste Lefort",
            "Eric Benhamou",
            "Jean-Jacques Ohana",
            "David Saltiel",
            "Beatrice Guez",
            "Damien Challet"
        ],
        "subjects": [
            "Statistical Finance",
            "Artificial Intelligence"
        ],
        "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to 2023, reposted on large financial media, to determine how global news headlines may affect stock market movements using ChatGPT and a two-stage prompt approach. We document a statistically significant positive correlation between the sentiment score and future equity market returns over short to medium term, which reverts to a negative correlation over longer horizons. Validation of this correlation pattern across multiple equity markets indicates its robustness across equity regions and resilience to non-linearity, evidenced by comparison of Pearson and Spearman correlations. Finally, we provide an estimate of the optimal horizon that strikes a balance between reactivity to new information and correlation.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05447"
    },
    {
        "doc_id": 564,
        "title": "An adaptive network-based approach for advanced forecasting of cryptocurrency values",
        "authors": [
            "Ali Mehrban",
            "Pegah Ahadian"
        ],
        "subjects": [
            "Statistical Finance",
            "Computational Engineering, Finance, and Science",
            "Cryptography and Security",
            "Machine Learning"
        ],
        "abstract": "This paper describes an architecture for predicting the price of cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy Inference System (ANFIS). Historical data of cryptocurrencies and indexes that are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D), and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach the data are hybrid and backpropagation algorithms, as well as grid partition, subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which are used in data clustering. The architectural performance designed in this paper has been compared with different inputs and neural network models in terms of statistical evaluation criteria. Finally, the proposed method can predict the price of digital currencies in a short time.",
        "comments": "11 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05441"
    },
    {
        "doc_id": 565,
        "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification",
        "authors": [
            "Zinuo You",
            "Pengju Zhang",
            "Jin Zheng",
            "John Cartlidge"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).",
        "comments": "5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05430"
    },
    {
        "doc_id": 566,
        "title": "Introduction of L0 norm and application of L1 and C1 norm in the study of time-series",
        "authors": [
            "Victor Ujaldon Garcia"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Four markets are considered: Cryptocurrencies / South American exchange rate / Spanish Banking indices and European Indices and studied using TDA (Topological Data Analysis) tools. These tools are used to predict and showcase both strengths and weakness of the current TDA tools. In this paper a new tool $L0$ norm is defined and complemented with the already existing $C1$ norm.",
        "comments": "14 pages 8 figures",
        "date": "30 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05423"
    },
    {
        "doc_id": 567,
        "title": "Multiple-bubble testing in the cryptocurrency market: a case study of bitcoin",
        "authors": [
            "Sanaz Behzadi",
            "Mahmonir Bayanati",
            "Hamed Nozari"
        ],
        "subjects": [
            "Statistical Finance"
        ],
        "abstract": "Economic periods and financial crises have highlighted the importance of evaluating financial markets to investors and researchers in recent decades.",
        "comments": " ",
        "date": "29 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05417"
    },
    {
        "doc_id": 568,
        "title": "On the Three Demons in Causality in Finance: Time Resolution, Nonstationarity, and Latent Factors",
        "authors": [
            "Xinshuai Dong",
            "Haoyue Dai",
            "Yewen Fan",
            "Songyao Jin",
            "Sathyamoorthy Rajendran",
            "Kun Zhang"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning",
            "Methodology"
        ],
        "abstract": "Financial data is generally time series in essence and thus suffers from three fundamental issues: the mismatch in time resolution, the time-varying property of the distribution - nonstationarity, and causal factors that are important but unknown/unobserved. In this paper, we follow a causal perspective to systematically look into these three demons in finance. Specifically, we reexamine these issues in the context of causality, which gives rise to a novel and inspiring understanding of how the issues can be addressed. Following this perspective, we provide systematic solutions to these problems, which hopefully would serve as a foundation for future research in the area.",
        "comments": " ",
        "date": "12 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05414"
    },
    {
        "doc_id": 569,
        "title": "RIVCoin: an alternative, integrated, CeFi/DeFi-Vaulted Cryptocurrency",
        "authors": [
            "Roberto Rivera",
            "Guido Rocco",
            "Massimiliano Marzo",
            "Enrico Talin"
        ],
        "subjects": [
            "General Finance",
            "General Economics"
        ],
        "abstract": "This whitepaper introduces RIVCoin, a cryptocurrency built on Cosmos, fully stabilized by a diversified portfolio of both CeFi and DeFi assets, available in a digital, non-custodial wallet called RIV Wallet, that aims to provide Users an easy way to access the cryptocurrency markets, compliant to the strictest AML laws and regulations up to date. The token is a cryptocurrency at any time stabilized by a basket of assets: reserves are invested in a portfolio composed long term by 50% of CeFi assets, comprised of Fixed Income, Equity, Mutual and Hedge Funds and 50% of diversified strategies focused on digital assets, mainly staking and LP farming on the major, battle tested DeFi protocols. The cryptocurrency, as well as the dollar before Bretton Woods, is always fully stabilized by vaulted proof of assets: it is born and managed as a decentralized token, minted by a Decentralized Autonomous Organization, and entirely stabilized by assets evaluated by professional independent third parties. Users will trade, pool, and exchange the token without any intermediary, being able to merge them into a Liquidity Pool whose rewards will be composed by both the trading fees and the liquidity rewards derived from the reserve's seigniorage.\n  Users who wish and decide to pool RIVCoin in the Liquidity Pool will receive additional RIVCoin for themselves, and new RIVCoin are minted when the reserves increase in value or in case of purchase of new RIVCoin. The proposed model allows for alignment of incentives: decreasing the risk exposure by wealthier Users, but implicitly increasing that of smaller ones to a level perceived by them as still sustainable. Users indirectly benefit from the access to the rewards of sophisticated cryptocurrency portfolios hitherto precluded to them, without this turning into a disadvantage for the wealthy User.",
        "comments": " ",
        "date": "19 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05393"
    },
    {
        "doc_id": 570,
        "title": "Optimal Linear Signal: An Unsupervised Machine Learning Framework to Optimize PnL with Linear Signals",
        "authors": [
            "Pierre Renucci"
        ],
        "subjects": [
            "Statistical Finance",
            "Machine Learning"
        ],
        "abstract": "This study presents an unsupervised machine learning approach for optimizing Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL generated from signals constructed linearly from exogenous variables. The methodology employs a linear relationship between exogenous variables and the trading signal, with the objective of maximizing the Sharpe Ratio through parameter optimization. Empirical application on an ETF representing U.S. Treasury bonds demonstrates the model's effectiveness, supported by regularization techniques to mitigate overfitting. The study concludes with potential avenues for further development, including generalized time steps and enhanced corrective terms.",
        "comments": "The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal",
        "date": "22 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.05337"
    },
    {
        "doc_id": 571,
        "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks",
        "authors": [
            "Zhang Chern Lee",
            "Wei Yun Tan",
            "Hoong Khen Koo",
            "Wilson Pang"
        ],
        "subjects": [
            "Portfolio Management"
        ],
        "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio",
        "comments": "19 pages, 5 figures",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05264"
    },
    {
        "doc_id": 572,
        "title": "A Mean Field Game between Informed Traders and a Broker",
        "authors": [
            "Philippe Bergault",
            "Leandro S\u00e1nchez-Betancourt"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Optimization and Control"
        ],
        "abstract": "We find closed-form solutions to the stochastic game between a broker and a mean-field of informed traders. In the finite player game, the informed traders observe a common signal and a private signal. The broker, on the other hand, observes the trading speed of each of his clients and provides liquidity to the informed traders. Each player in the game optimises wealth adjusted by inventory penalties. In the mean field version of the game, using a G\u00e2teaux derivative approach, we characterise the solution to the game with a system of forward-backward stochastic differential equations that we solve explicitly. We find that the optimal trading strategy of the broker is linear on his own inventory, on the average inventory among informed traders, and on the common signal or the average trading speed of the informed traders. The Nash equilibrium we find helps informed traders decide how to use private information, and helps brokers decide how much of the order flow they should externalise or internalise when facing a large number of clients.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05257"
    },
    {
        "doc_id": 573,
        "title": "On the Martingale Schr\u00f6dinger Bridge between Two Distributions",
        "authors": [
            "Marcel Nutz",
            "Johannes Wiesel"
        ],
        "subjects": [
            "Probability",
            "Mathematical Finance"
        ],
        "abstract": "We study a martingale Schr\u00f6dinger bridge problem: given two probability distributions, find their martingale coupling with minimal relative entropy. Our main result provides Schr\u00f6dinger potentials for this coupling. Namely, under certain conditions, the log-density of the optimal coupling is given by a triplet of real functions representing the marginal and martingale constraints. The potentials are also described as the solution of a dual problem.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05209"
    },
    {
        "doc_id": 574,
        "title": "Markowitz Portfolio Construction at Seventy",
        "authors": [
            "Stephen Boyd",
            "Kasper Johansson",
            "Ronald Kahn",
            "Philipp Schiele",
            "Thomas Schmelzer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "More than seventy years ago Harry Markowitz formulated portfolio construction as an optimization problem that trades off expected return and risk, defined as the standard deviation of the portfolio returns. Since then the method has been extended to include many practical constraints and objective terms, such as transaction cost or leverage limits. Despite several criticisms of Markowitz's method, for example its sensitivity to poor forecasts of the return statistics, it has become the dominant quantitative method for portfolio construction in practice. In this article we describe an extension of Markowitz's method that addresses many practical effects and gracefully handles the uncertainty inherent in return statistics forecasting. Like Markowitz's original formulation, the extension is also a convex optimization problem, which can be solved with high reliability and speed.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.05080"
    },
    {
        "doc_id": 575,
        "title": "Scaling Laws And Statistical Properties of The Transaction Flows And Holding Times of Bitcoin",
        "authors": [
            "Didier Sornette",
            "Yu Zhang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "We study the temporal evolution of the holding-time distribution of bitcoins and find that the average distribution of holding-time is a heavy-tailed power law extending from one day to over at least $200$ weeks with an exponent approximately equal to $0.9$, indicating very long memory effects. We also report significant sample-to-sample variations of the distribution of holding times, which can be best characterized as multiscaling, with power-law exponents varying between $0.3$ and $2.5$ depending on bitcoin price regimes. We document significant differences between the distributions of book-to-market and of realized returns, showing that traders obtain far from optimal performance. We also report strong direct qualitative and quantitative evidence of the disposition effect in the Bitcoin Blockchain data. Defining age-dependent transaction flows as the fraction of bitcoins that are traded at a given time and that were born (last traded) at some specific earlier time, we document that the time-averaged transaction flow fraction has a power law dependence as a function of age, with an exponent close to $-1.5$, a value compatible with priority queuing theory. We document the existence of multifractality on the measure defined as the normalized number of bitcoins exchanged at a given time.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04702"
    },
    {
        "doc_id": 576,
        "title": "Proof of Efficient Liquidity: A Staking Mechanism for Capital Efficient Liquidity",
        "authors": [
            "Arman Abgaryan",
            "Utkarsh Sharma",
            "Joshua Tobkin"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "The Proof of Efficient Liquidity (PoEL) protocol, designed for specialised Proof of Stake (PoS) consensus-based blockchain infrastructures that incorporate intrinsic DeFi applications, aims to support sustainable liquidity bootstrapping and network security. This innovative mechanism efficiently utilises budgeted staking rewards to attract and sustain liquidity through a risk structuring engine and incentive allocation strategy, both of which are designed to maximise capital efficiency. The proposed protocol seeks to serve the dual objective of - (i) capital creation, by efficiently attracting risk capital, and maximising its operational utility for intrinsic DeFi applications, thereby asserting sustainability; and (ii) enhancing the adopting blockchain network's economic security, by augmenting their staking (PoS) mechanism with a harmonious layer seeking to attract a diversity of digital assets. Finally, in the appendix, we seek to generalise the financial incentivisation protocol to the notion of service fee credits, such that it utilises the network's auxiliary services as a means to propagate incentives to attract liquidity and facilitate the network to achieve the critical mass of usage necessary for sustained operations and growth.",
        "comments": " ",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04521"
    },
    {
        "doc_id": 577,
        "title": "Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks",
        "authors": [
            "Zan Yu",
            "Lianzeng Zhang"
        ],
        "subjects": [
            "Numerical Analysis",
            "Probability",
            "Risk Management"
        ],
        "abstract": "In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.",
        "comments": "23 pages; 5 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04378"
    },
    {
        "doc_id": 578,
        "title": "Expiring Assets in Automated Market Makers",
        "authors": [
            "Kenan Wood",
            "Maurice Herlihy",
            "Hammurabi Mendes",
            "Jonad Pulaj"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Distributed, Parallel, and Cluster Computing",
            "Mathematical Finance",
            "Trading and Market Microstructure"
        ],
        "abstract": "An automated market maker (AMM) is a state machine that manages pools of assets, allowing parties to buy and sell those assets according to a fixed mathematical formula. AMMs are typically implemented as smart contracts on blockchains, and its prices are kept in line with the overall market price by arbitrage: if the AMM undervalues an asset with respect to the market, an \"arbitrageur\" can make a risk-free profit by buying just enough of that asset to bring the AMM's price back in line with the market.\n  AMMs, however, are not designed for assets that expire: that is, assets that cannot be produced or resold after a specified date. As assets approach expiration, arbitrage may not be able to reconcile supply and demand, and the liquidity providers that funded the AMM may have excessive exposure to risk due to rapid price variations.\n  This paper formally describes the design of a decentralized exchange (DEX) for assets that expire, combining aspects of AMMs and limit-order books. We ensure liveness and market clearance, providing mechanisms for liquidity providers to control their exposure to risk and adjust prices dynamically in response to situations where arbitrage may fail.",
        "comments": "33 pages",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04289"
    },
    {
        "doc_id": 579,
        "title": "Economic Forces in Stock Returns",
        "authors": [
            "Yue Chen",
            "Mohan Li"
        ],
        "subjects": [
            "General Economics",
            "Statistical Finance"
        ],
        "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.",
        "comments": "11 pages, 10 figures",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.04132"
    },
    {
        "doc_id": 580,
        "title": "Decomposing Smiles: A Time Change Approach",
        "authors": [
            "Liexin Cheng",
            "Xue Cheng"
        ],
        "subjects": [
            "Pricing of Securities",
            "Mathematical Finance"
        ],
        "abstract": "We develop a novel time-change approach to study the shape of implied volatility smiles. The method is applicable to common semimartingale models, including jump-diffusion, rough volatility and infinite activity models. We approximate the at-the-money skew and curvature with an improved moment-based formula. The moments are further explicitly computed under a time change framework. The limiting skew and curvature for several models are considered. We also test the accuracy of the short-term approximation results on models via numerical methods and on empirical data. Finally, we apply the method to the calibration problem.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03776"
    },
    {
        "doc_id": 581,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": [
            "Georgios Fatouros",
            "Konstantinos Metaxas",
            "John Soldatos",
            "Dimosthenis Kyriazis"
        ],
        "subjects": [
            "Computational Finance",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation with S&P 100 stocks, MarketSenseAI outperformed the benchmark index by 13%, achieving returns up to 40%, while maintaining a risk profile comparable to the market. These results demonstrate the efficacy of Large Language Models in complex financial decision-making and mark a significant advancement in the integration of AI into financial analysis and investment strategies. This research contributes to the financial AI field, presenting an innovative approach and underscoring the transformative potential of AI in revolutionizing traditional financial analysis investment methodologies.",
        "comments": "15 pages, 12 figures, 12 tables",
        "date": "8 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03737"
    },
    {
        "doc_id": 582,
        "title": "Structured factor copulas for modeling the systemic risk of European and United States banks",
        "authors": [
            "Hoang Nguyen",
            "Audron\u0117 Virbickait\u0117",
            "M. Concepci\u00f3n Aus\u00edn",
            "Pedro Galeano"
        ],
        "subjects": [
            "Statistical Finance",
            "Applications"
        ],
        "abstract": "In this paper, we employ Credit Default Swaps (CDS) to model the joint and conditional distress probabilities of banks in Europe and the U.S. using factor copulas. We propose multi-factor, structured factor, and factor-vine models where the banks in the sample are clustered according to their geographic location. We find that within each region, the co-dependence between banks is best described using both, systematic and idiosyncratic, financial contagion channels. However, if we consider the banking system as a whole, then the systematic contagion channel prevails, meaning that the distress probabilities are driven by a latent global factor and region-specific factors. In all cases, the co-dependence structure of bank CDS spreads is highly correlated in the tail. The out-of-sample forecasts of several measures of systematic risk allow us to identify the periods of distress in the banking sector over the recent years including the COVID-19 pandemic, the interest rate hikes in 2022, and the banking crisis in 2023.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03443"
    },
    {
        "doc_id": 583,
        "title": "Modelling and Predicting the Conditional Variance of Bitcoin Daily Returns: Comparsion of Markov Switching GARCH and SV Models",
        "authors": [
            "Dennis Koch",
            "Vahidin Jeleskovic",
            "Zahid I. Younas"
        ],
        "subjects": [
            "Statistical Finance",
            "Risk Management"
        ],
        "abstract": "This paper introduces a unique and valuable research design aimed at analyzing Bitcoin price volatility. To achieve this, a range of models from the Markov Switching-GARCH and Stochastic Autoregressive Volatility (SARV) model classes are considered and their out-of-sample forecasting performance is thoroughly examined. The paper provides insights into the rationale behind the recommendation for a two-stage estimation approach, emphasizing the separate estimation of coefficients in the mean and variance equations. The results presented in this paper indicate that Stochastic Volatility models, particularly SARV models, outperform MS-GARCH models in forecasting Bitcoin price volatility. Moreover, the study suggests that in certain situations, persistent simple GARCH models may even outperform Markov-Switching GARCH models in predicting the variance of Bitcoin log returns. These findings offer valuable guidance for risk management experts, highlighting the potential advantages of SARV models in managing and forecasting Bitcoin price volatility.",
        "comments": " ",
        "date": "10 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03393"
    },
    {
        "doc_id": 584,
        "title": "Volatility models in practice: Rough, Path-dependent or Markovian?",
        "authors": [
            "Eduardo Abi Jaber",
            "Shaun",
            "Li"
        ],
        "subjects": [
            "Mathematical Finance",
            "Computational Finance",
            "Pricing of Securities"
        ],
        "abstract": "An extensive empirical study of the class of Volterra Bergomi models using SPX options data between 2011 and 2022 reveals the following fact-check on two fundamental claims echoed in the rough volatility literature:\n  Do rough volatility models with Hurst index $H \\in (0,1/2)$ really capture well SPX implied volatility surface with very few parameters? No, rough volatility models are inconsistent with the global shape of SPX smiles. They suffer from severe structural limitations imposed by the roughness component, with the Hurst parameter $H \\in (0,1/2)$ controlling the smile in a poor way. In particular, the SPX at-the-money skew is incompatible with the power-law shape generated by rough volatility models. The skew of rough volatility models increases too fast on the short end, and decays too slow on the longer end where \"negative\" $H$ is sometimes needed.\n  Do rough volatility models really outperform consistently their classical Markovian counterparts? No, for short maturities they underperform their one-factor Markovian counterpart with the same number of parameters. For longer maturities, they do not systematically outperform the one-factor model and significantly underperform when compared to an under-parametrized two-factor Markovian model with only one additional calibratable parameter.\n  On the positive side: our study identifies a (non-rough) path-dependent Bergomi model and an under-parametrized two-factor Markovian Bergomi model that consistently outperform their rough counterpart in capturing SPX smiles between one week and three years with only 3 to 4 calibratable parameters. \\end{abstract}",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03345"
    },
    {
        "doc_id": 585,
        "title": "Negatively dependent optimal risk sharing",
        "authors": [
            "Jean-Gabriel Lauzier",
            "Liyuan Lin",
            "Ruodu Wang"
        ],
        "subjects": [
            "Theoretical Economics",
            "Risk Management"
        ],
        "abstract": "We analyze the problem of optimally sharing risk using allocations that exhibit counter-monotonicity, the most extreme form of negative dependence. Counter-monotonic allocations take the form of either \"winner-takes-all\" lotteries or \"loser-loses-all\" lotteries, and we respectively refer to these (normalized) cases as jackpot or scapegoat allocations. Our main theorem, the counter-monotonic improvement theorem, states that for a given set of random variables that are either all bounded from below or all bounded from above, one can always find a set of counter-monotonic random variables such that each component is greater or equal than its counterpart in the convex order. We show that Pareto optimal allocations, if they exist, must be jackpot allocations when all agents are risk seeking. We essentially obtain the opposite when all agents have discontinuous Bernoulli utility functions, as scapegoat allocations maximize the probability of being above the discontinuity threshold. We also consider the case of rank-dependent expected utility (RDU) agents and find conditions which guarantee that RDU agents prefer jackpot allocations. We provide an application for the mining of cryptocurrencies and show that in contrast to risk-averse miners, RDU miners with small computing power never join a mining pool. Finally, we characterize the competitive equilibria with risk-seeking agents, providing a first and second fundamental theorem of welfare economics where all equilibrium allocations are jackpot allocations.",
        "comments": "35 pages, 1 figure, Keywords: Pareto optimality, Risk sharing, Counter-monotonicity, Risk seeking, Rank-dependent expected utility, Cryptocurrency mining pools",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03328"
    },
    {
        "doc_id": 586,
        "title": "Optimal Order Execution subject to Reservation Strategies under Execution Risk",
        "authors": [
            "Xue Cheng",
            "Peng Guo",
            "Tai-ho Wang"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "The paper addresses the problem of meta order execution from a broker-dealer's point of view in Almgren-Chriss model under order fill uncertainty. A broker-dealer agency is authorized to execute an order of trading on client's behalf. The strategies that the agent is allowed to deploy is subject to a benchmark, referred to as the reservation strategy, regulated by the client. We formulate the broker's problem as a utility maximization problem in which the broker seeks to maximize his utility of excess profit-and-loss at the execution horizon. Optimal strategy in feedback form is obtained in closed form. In the absence of execution risk, the optimal strategies subject to reservation strategies are deterministic. We establish an affine structure among the trading trajectories under optimal strategies subject to general reservation strategies using implementation shortfall and target close orders as basis. We conclude the paper with numerical experiments illustrating the trading trajectories as well as histograms of terminal wealth and utility at investment horizon under optimal strategies versus those under TWAP strategies.",
        "comments": " ",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.03305"
    },
    {
        "doc_id": 587,
        "title": "Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning",
        "authors": [
            "Hong-Gi Shin",
            "Sukhyun Jeong",
            "Eui-Yeon Kim",
            "Sungho Hong",
            "Young-Jin Cho",
            "Yong-Hoon Choi"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Artificial Intelligence"
        ],
        "abstract": "Mining of formulaic alpha factors refers to the process of discovering and developing specific factors or indicators (referred to as alpha factors) for quantitative trading in stock market. To efficiently discover alpha factors in vast search space, reinforcement learning (RL) is commonly employed. This paper proposes a method to enhance existing alpha factor mining approaches by expanding a search space and utilizing pretrained formulaic alpha set as initial seed values to generate synergistic formulaic alpha. We employ information coefficient (IC) and rank information coefficient (Rank IC) as performance evaluation metrics for the model. Using CSI300 market data, we conducted real investment simulations and observed significant performance improvement compared to existing techniques.",
        "comments": "Accepted by ICOIN 2024",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02710"
    },
    {
        "doc_id": 588,
        "title": "Displaying risk in mergers: a diagrammatic approach for exchange ratio determination",
        "authors": [
            "Alessandra Mainini",
            "Enrico Moretto",
            "Daniela Visetti"
        ],
        "subjects": [
            "General Finance"
        ],
        "abstract": "This article extends, in a stochastic setting, previous results in the determination of feasible exchange ratios for merging companies. A first outcome is that shareholders of the companies involved in the merging process face both an upper and a lower bounds for acceptable exchange ratios. Secondly, in order for the improved `bargaining region' to be intelligibly displayed, the diagrammatic approach developed by Kulpa is exploited.",
        "comments": " ",
        "date": "5 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02681"
    },
    {
        "doc_id": 589,
        "title": "Constrained Max Drawdown: a Fast and Robust Portfolio Optimization Approach",
        "authors": [
            "Albert Dorador"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control"
        ],
        "abstract": "We propose an alternative linearization to the classical Markowitz quadratic portfolio optimization model, based on maximum drawdown. This model, which minimizes maximum portfolio drawdown, is particularly appealing during times of financial distress, like during the COVID-19 pandemic. In addition, we will present a Mixed-Integer Linear Programming variation of our new model that, based on our out-of-sample results and sensitivity analysis, delivers a more profitable and robust solution with a 200 times faster solving time compared to the standard Markowitz quadratic formulation.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02601"
    },
    {
        "doc_id": 590,
        "title": "Opinion formation in the world trade network",
        "authors": [
            "C\u00e9lestin Coquid\u00e9",
            "Jos\u00e9 Lages",
            "Dima L. Shepelyansky"
        ],
        "subjects": [
            "Trading and Market Microstructure",
            "Statistical Mechanics",
            "Social and Information Networks",
            "Physics and Society"
        ],
        "abstract": "We extend the opinion formation approach to probe the world influence of economical organizations. Our opinion formation model mimics a battle between currencies within the international trade network. Based on the United Nations Comtrade database, we construct the world trade network for the years of the last decade from 2010 to 2020. We consider different core groups constituted by countries preferring to trade in a specific currency. We will consider principally two core groups, namely, 5 Anglo-Saxon countries which prefer to trade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical currency, hereafter called BRI, pegged to their economies. We determine the trade currency preference of the other countries via a Monte Carlo process depending on the direct transactions between the countries. The results obtained in the frame of this mathematical model show that starting from year 2014 the majority of the world countries would have preferred to trade in BRI than USD. The Monte Carlo process reaches a steady state with 3 distinct groups: two groups of countries preferring, whatever is the initial distribution of the trade currency preferences, to trade, one in BRI and the other in USD, and a third group of countries swinging as a whole between USD and BRI depending on the initial distribution of the trade currency preferences. We also analyze the battle between USD, EUR and BRI, and present the reduced Google matrix description of the trade relations between the Anglo-Saxon countries and the BRICS+.",
        "comments": "16 pages, 19 figures (including 9 figures present in Appendix section) and 1 table",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02378"
    },
    {
        "doc_id": 591,
        "title": "ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach",
        "authors": [
            "Zeynep Hilal Kilimci",
            "Mustafa Yalcin"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02124"
    },
    {
        "doc_id": 592,
        "title": "Forecasting Bitcoin Volatility: A Comparative Analysis of Volatility Approaches",
        "authors": [
            "Cristina Chinazzo",
            "Vahidin Jeleskovic"
        ],
        "subjects": [
            "Trading and Market Microstructure"
        ],
        "abstract": "This paper conducts an extensive analysis of Bitcoin return series, with a primary focus on three volatility metrics: historical volatility (calculated as the sample standard deviation), forecasted volatility (derived from GARCH-type models), and implied volatility (computed from the emerging Bitcoin options market). These measures of volatility serve as indicators of market expectations for conditional volatility and are compared to elucidate their differences and similarities. The central finding of this study underscores a notably high expected level of volatility, both on a daily and annual basis, across all the methodologies employed. However, it's crucial to emphasize the potential challenges stemming from suboptimal liquidity in the Bitcoin options market. These liquidity constraints may lead to discrepancies in the computed values of implied volatility, particularly in scenarios involving extreme moneyness or maturity. This analysis provides valuable insights into Bitcoin's volatility landscape, shedding light on the unique characteristics and dynamics of this cryptocurrency within the context of financial markets.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.02049"
    },
    {
        "doc_id": 593,
        "title": "Notes on the SWIFT method based on Shannon Wavelets for Option Pricing -- Revisited",
        "authors": [
            "Fabien Le Floc'h"
        ],
        "subjects": [
            "Computational Finance",
            "Numerical Analysis"
        ],
        "abstract": "This note revisits the SWIFT method based on Shannon wavelets to price European options under models with a known characteristic function in 2023. In particular, it discusses some possible improvements and exposes some concrete drawbacks of the method.",
        "comments": " ",
        "date": "7 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01758"
    },
    {
        "doc_id": 594,
        "title": "Text mining arXiv: a look through quantitative finance papers",
        "authors": [
            "Michele Leonardo Bianchi"
        ],
        "subjects": [
            "Digital Libraries",
            "Information Retrieval",
            "General Finance"
        ],
        "abstract": "This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.",
        "comments": " ",
        "date": "3 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01751"
    },
    {
        "doc_id": 595,
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "authors": [
            "Lioba Heimbach",
            "Vabuk Pahari",
            "Eric Schertenleib"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "General Finance"
        ],
        "abstract": "The prevalence of maximal extractable value (MEV) in the Ethereum ecosystem has led to a characterization of the latter as a dark forest. Studies of MEV have thus far largely been restricted to purely on-chain MEV, i.e., sandwich attacks, cyclic arbitrage, and liquidations. In this work, we shed light on the prevalence of non-atomic arbitrage on decentralized exchanges (DEXes) on the Ethereum blockchain. Importantly, non-atomic arbitrage exploits price differences between DEXes on the Ethereum blockchain as well as exchanges outside the Ethereum blockchain (i.e., centralized exchanges or DEXes on other blockchains). Thus, non-atomic arbitrage is a type of MEV that involves actions on and off the Ethereum blockchain.\n  In our study of non-atomic arbitrage, we uncover that more than a fourth of the volume on Ethereum's biggest five DEXes from the merge until 31 October 2023 can likely be attributed to this type of MEV. We further highlight that only eleven searchers are responsible for more than 80% of the identified non-atomic arbitrage volume sitting at a staggering 137 billion US$ and draw a connection between the centralization of the block construction market and non-atomic arbitrage. Finally, we discuss the security implications of these high-value transactions that account for more than 10% of Ethereum's total block value and outline possible mitigations.",
        "comments": " ",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01622"
    },
    {
        "doc_id": 596,
        "title": "An arbitrage driven price dynamics of Automated Market Makers in the presence of fees",
        "authors": [
            "Joseph Najnudel",
            "Shen-Ning Tung",
            "Kazutoshi Yamazaki",
            "Ju-Yi Yen"
        ],
        "subjects": [
            "Mathematical Finance"
        ],
        "abstract": "We present a model for price dynamics in the Automated Market Makers (AMM) setting. Within this framework, we propose a reference market price following a geometric Brownian motion. The AMM price is constrained by upper and lower bounds, determined by constant multiplications of the reference price. Through the utilization of local times and excursion-theoretic approaches, we derive several analytical results, including its time-changed representation and limiting behavior.",
        "comments": " ",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01526"
    },
    {
        "doc_id": 597,
        "title": "Nash Equilibria in Greenhouse Gas Offset Credit Markets",
        "authors": [
            "Liam Welsh",
            "Sebastian Jaimungal"
        ],
        "subjects": [
            "General Finance",
            "Computational Finance",
            "Risk Management"
        ],
        "abstract": "In response to the global climate crisis, governments worldwide are introducing legislation to reduce greenhouse gas (GHG) emissions to help mitigate environmental catastrophes. One method to encourage emission reductions is to incentivize carbon capturing and carbon reducing projects while simultaneously penalising excess GHG output. Firms that invest in carbon capturing projects or reduce their emissions can receive offset credits (OCs) in return. These OCs can be used for regulatory purposes to offset their excess emissions in a compliance period. OCs may also be traded between firms. Thus, firms have the choice between investing in projects to generate OCs or to trade OCs. In this work, we present a novel market framework and characterise the optimal behaviour of GHG OC market participants in both single-player and two-player settings. We analyse both a single-period and multi-period setting. As the market model does not elicit a closed form solution, we develop a numerical methodology to estimate players' optimal behaviours in accordance to the Nash equilibria. Our findings indicate the actions players take are dependent on the scale of their project opportunities as well as their fellow market participants. We demonstrate the importance of behaving optimally via simulations in order to offset emission penalties and the importance of investing in GHG reducing or capturing projects from a financial perspective.",
        "comments": "MSC Class:          91G99; 35Q91; 91-08; 91A80; 91B74",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01427"
    },
    {
        "doc_id": 598,
        "title": "Accelerating Black-Box Molecular Property Optimization by Adaptively Learning Sparse Subspaces",
        "authors": [
            "Farshud Sorourifar",
            "Thomas Banker",
            "Joel A. Paulson"
        ],
        "subjects": [
            "Biomolecules",
            "Computational Engineering, Finance, and Science",
            "Machine Learning"
        ],
        "abstract": "Molecular property optimization (MPO) problems are inherently challenging since they are formulated over discrete, unstructured spaces and the labeling process involves expensive simulations or experiments, which fundamentally limits the amount of available data. Bayesian optimization (BO) is a powerful and popular framework for efficient optimization of noisy, black-box objective functions (e.g., measured property values), thus is a potentially attractive framework for MPO. To apply BO to MPO problems, one must select a structured molecular representation that enables construction of a probabilistic surrogate model. Many molecular representations have been developed, however, they are all high-dimensional, which introduces important challenges in the BO process -- mainly because the curse of dimensionality makes it difficult to define and perform inference over a suitable class of surrogate models. This challenge has been recently addressed by learning a lower-dimensional encoding of a SMILE or graph representation of a molecule in an unsupervised manner and then performing BO in the encoded space. In this work, we show that such methods have a tendency to \"get stuck,\" which we hypothesize occurs since the mapping from the encoded space to property values is not necessarily well-modeled by a Gaussian process. We argue for an alternative approach that combines numerical molecular descriptors with a sparse axis-aligned Gaussian process model, which is capable of rapidly identifying sparse subspaces that are most relevant to modeling the unknown property function. We demonstrate that our proposed method substantially outperforms existing MPO methods on a variety of benchmark and real-world problems. Specifically, we show that our method can routinely find near-optimal molecules out of a set of more than $>100$k alternatives within 100 or fewer expensive queries.",
        "comments": "9 pages, 2 figures consisting of 6 and 4 plots, accepted to NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.01398"
    },
    {
        "doc_id": 599,
        "title": "Almost Perfect Shadow Prices",
        "authors": [
            "Eberhard Mayerhofer"
        ],
        "subjects": [
            "Portfolio Management",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "Shadow prices simplify the derivation of optimal trading strategies in markets with transaction costs by transferring optimization into a more tractable, frictionless market. This paper establishes that a na\u00efve shadow price Ansatz for maximizing long term returns given average volatility yields a strategy that is, for small bid-ask-spreads, asymptotically optimal at third order. Considering the second-order impact of transaction costs, such a strategy is essentially optimal. However, for risk aversion different from one, we devise alternative strategies that outperform the shadow market at fourth order. Finally, it is shown that the risk-neutral objective rules out the existence of shadow prices.",
        "comments": "15 pages",
        "date": "1 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.00970"
    },
    {
        "doc_id": 600,
        "title": "O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold",
        "authors": [
            "Tolson Bell",
            "Alan Frieze"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Combinatorics"
        ],
        "abstract": "The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler. Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time. In this paper, we give a theoretical insertion time bound for this algorithm. More precisely, for every $d\\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists. We show that for any $d\\ge 4$ hashes and load factor $c<c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$.",
        "comments": "19 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14394"
    },
    {
        "doc_id": 601,
        "title": "Entropic Quantum Central Limit Theorem and Quantum Inverse Sumset Theorem",
        "authors": [
            "Kaifeng Bu",
            "Weichen Gu",
            "Arthur Jaffe"
        ],
        "subjects": [
            "Quantum Physics",
            "Information Theory",
            "Mathematical Physics",
            "Probability"
        ],
        "abstract": "We establish an entropic, quantum central limit theorem and quantum inverse sumset theorem in discrete-variable quantum systems describing qudits or qubits. Both results are enabled by using our recently-discovered quantum convolution. We show that the exponential rate of convergence of the entropic central limit theorem is bounded by the magic gap. We also establish an ``quantum, entropic inverse sumset theorem,'' by introducing a quantum doubling constant. Furthermore, we introduce a ``quantum Ruzsa divergence'', and we pose a conjecture called ``convolutional strong subaddivity,'' which leads to the triangle inequality for the quantum Ruzsa divergence. A byproduct of this work is a magic measure to quantify the nonstabilizer nature of a state, based on the quantum Ruzsa divergence.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14385"
    },
    {
        "doc_id": 602,
        "title": "Butterfly Points and Hyperspace Selections",
        "authors": [
            "Valentin Gutev"
        ],
        "subjects": [
            "General Topology"
        ],
        "abstract": "If $f$ is a continuous selection for the Vietoris hyperspace $\\mathscr{F}(X)$ of the nonempty closed subsets of a space $X$, then the point $f(X)\\in X$ is not as arbitrary as it might seem at first glance. In this paper, we will characterise these points by local properties at them. Briefly, we will show that $p=f(X)$ is a strong butterfly point precisely when it has a countable clopen base in $\\overline{U}$ for some open set $U\\subset X\\setminus\\{p\\}$ with $\\overline{U}=U\\cup\\{p\\}$. Moreover, the same is valid when $X$ is totally disconnected at $p=f(X)$ and $p$ is only assumed to be a butterfly point. This gives the complete affirmative solution to a question raised previously by the author. Finally, when $p=f(X)$ lacks the above local base-like property, we will show that $\\mathscr{F}(X)$ has a continuous selection $h$ with the stronger property that $h(S)=p$ for every closed $S\\subset X$ with $p\\in S$.",
        "comments": "MSC Class:          54A20; 54B20; 54C65",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14384"
    },
    {
        "doc_id": 603,
        "title": "A Sum-of-Squares Hierarchy in the Absence of Pointwise Proofs I: Energy Certificates",
        "authors": [
            "J. S. Sandhu",
            "J. Shi"
        ],
        "subjects": [
            "Computational Complexity",
            "Mathematical Physics",
            "Classical Analysis and ODEs",
            "Optimization and Control",
            "Probability"
        ],
        "abstract": "We devise a parameterized family of distributions, the high-entropy step distributions (HES), which are expressive enough to capture near-optima of spherical spin glass models in the full Replica Symmetry Breaking (fRSB) regime and yet permit low-degree Sum-of-Squares (SoS) certificates that no such distribution can achieve value slightly larger than the true optimum. This yields a SoS optimization program and rounding scheme that attains near-optimal solutions for spherical spin glasses in the fRSB regime. In other regimes, the same results occur at the ALG value, which is a conjectured best-value attainable by any polynomial time algorithm. These SoS programs optimize over families of distributions of possible solutions, and circumvent the oft-cited impossibility of providing a low-degree SoS proof of concentration of measure by instead proving the same bounds only in expectation on solution distributions that can be produced by the chosen rounding algorithm. The new SoS hierarchy does not make any specific reference to the spherical spin glass problem, and we conjecture that it can be applied to a broad range of average-case problems to obtain value that is optimal among polynomial-time algorithms. We give evidence for this with examples of ensembles that provably fool certain local iterative algorithms but for which there is either proof or evidence that the SoS program is better. This opens the door to addressing a question posed by Barak about the possible optimality of SoS on average-case optimization problems, and by Schramm about reductions between different families of algorithms for average-case problems. In this paper, we give low-degree SoS proofs certifying key properties about HES distributions as well as the ALG threshold for spherical spin glasses. The rounding algorithm is introduced and analyzed in a companion paper.",
        "comments": "130 pages, 0 figures. First of two companion papers",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14383"
    },
    {
        "doc_id": 604,
        "title": "An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Numerical Analysis",
            "Machine Learning"
        ],
        "abstract": "The recent introduction of the Least-Squares Support Vector Regression (LS-SVR) algorithm for solving differential and integral equations has sparked interest. In this study, we expand the application of this algorithm to address systems of differential-algebraic equations (DAEs). Our work presents a novel approach to solving general DAEs in an operator format by establishing connections between the LS-SVR machine learning model, weighted residual methods, and Legendre orthogonal polynomials. To assess the effectiveness of our proposed method, we conduct simulations involving various DAE scenarios, such as nonlinear systems, fractional-order derivatives, integro-differential, and partial DAEs. Finally, we carry out comparisons between our proposed method and currently established state-of-the-art approaches, demonstrating its reliability and effectiveness.",
        "comments": "17 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14382"
    },
    {
        "doc_id": 605,
        "title": "Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs",
        "authors": [
            "Martin Hanik",
            "Gabriele Steidl",
            "Christoph von Tycowicz"
        ],
        "subjects": [
            "Machine Learning",
            "Differential Geometry"
        ],
        "abstract": "We propose two graph neural network layers for graphs with features in a Riemannian manifold. First, based on a manifold-valued graph diffusion equation, we construct a diffusion layer that can be applied to an arbitrary number of nodes and graph connectivity patterns. Second, we model a tangent multilayer perceptron by transferring ideas from the vector neuron framework to our general setting. Both layers are equivariant with respect to node permutations and isometries of the feature manifold. These properties have been shown to lead to a beneficial inductive bias in many deep learning tasks. Numerical examples on synthetic data as well as on triangle meshes of the right hippocampus to classify Alzheimer's disease demonstrate the very good performance of our layers.",
        "comments": "MSC Class:          53Z50                          ACM Class:          I.2.4",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14381"
    },
    {
        "doc_id": 606,
        "title": "Splines on Cayley Graphs of the Symmetric Group",
        "authors": [
            "Nathan R. T. Lesnevich"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "A spline is an assignment of polynomials to the vertices of a graph whose edges are labeled by ideals, where the difference of two polynomials labeling adjacent vertices must belong to the corresponding ideal. The set of splines forms a ring. We consider spline rings where the underlying graph is the Cayley graph of a symmetric group generated by a collection of transpositions. These rings generalize the GKM construction for equivariant cohomology rings of flag, regular semisimple Hessenberg, and permutohedral varieties. These cohomology rings carry two actions of the symmetric group $S_n$ whose graded characters are both of general interest in algebraic combinatorics. In this paper, we generalize the graded $S_n$-representations from the cohomologies of the above varieties to splines on Cayley graphs of $S_n$, then (1) give explicit module and ring generators for whenever the $S_n$-generating set is minimal, (2) give a combinatorial characterization of when graded pieces of one $S_n$-representation is trivial, and (3) compute the first degree piece of both graded characters for all generating sets.",
        "comments": "55 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14380"
    },
    {
        "doc_id": 607,
        "title": "An analytic version of stable arithmetic regularity",
        "authors": [
            "Gabriel Conant",
            "Anand Pillay"
        ],
        "subjects": [
            "Logic",
            "Combinatorics",
            "Group Theory"
        ],
        "abstract": "We prove a structure theorem for stable functions on amenable groups, which extends the arithmetic regularity lemma for stable subsets of finite groups. Given a group $G$, a function $f\\colon G\\to [-1,1]$ is called stable if the binary function $f(x\\cdot y)$ is stable in the sense of continuous logic. Roughly speaking, our main result says that if $G$ is amenable, then any stable function on $G$ is almost constant on all translates of a unitary Bohr set in $G$ of bounded complexity. The proof uses ingredients from topological dynamics and continuous model theory. We also discuss some applications, including a short proof of the noncommutative analogue of Bogolyubov's Lemma for amenable groups.",
        "comments": "22 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14363"
    },
    {
        "doc_id": 608,
        "title": "Initial data for Minkowski stability with arbitrary decay",
        "authors": [
            "Allen Juntao Fang",
            "J\u00e9r\u00e9mie Szeftel",
            "Arthur Touati"
        ],
        "subjects": [
            "Analysis of PDEs",
            "General Relativity and Quantum Cosmology",
            "Mathematical Physics"
        ],
        "abstract": "We construct and parametrize solutions to the constraint equations of general relativity in a neighborhood of Minkowski spacetime with arbitrary prescribed decay properties at infinity. We thus provide a large class of initial data for the results on stability of Minkowski which include a mass term in the asymptotics. Due to the symmetries of Minkowski, a naive linear perturbation fails. Our construction is based on a simplified conformal method, a reduction to transverse traceless perturbations and a nonlinear fixed point argument where we face linear obstructions coming from the cokernels of both the linearized constraint operator and the Laplace operator. To tackle these obstructions, we introduce a well-chosen truncated black hole around which to perturb. The control of the parameters of the truncated black hole is the most technical part of the proof, since its center of mass and angular momentum could be arbitrarily large.",
        "comments": "86 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14353"
    },
    {
        "doc_id": 609,
        "title": "Computing Derivations on Nilpotent Quadratic Lie Algebras",
        "authors": [
            "Pilar Benito",
            "Javier R\u00e1ndez-Ib\u00e1\u00f1ez",
            "Jorge Rold\u00e1n-L\u00f3pez"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Every non-solvable and non-semisimple quadratic Lie algebra can be obtained as a double extension of a solvable quadratic Lie algebra. Thanks to a partial classification of nilpotent Lie algebras and this result, we can design different techniques to obtain any quadratic Lie algebra whose (solvable) radical ideal is nilpotent. To achieve this, we propose two alternative methods, both involving the use of quotients. In addition to their mathematical description, both approaches introduced in this paper have been computationally implemented and are publicly available to use for generating these algebras.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14348"
    },
    {
        "doc_id": 610,
        "title": "Evolving higher-order synergies reveals a trade-off between stability and information integration capacity in complex systems",
        "authors": [
            "Thomas F. Varley",
            "Joshua Bongard"
        ],
        "subjects": [
            "Information Theory",
            "Dynamical Systems",
            "Chaotic Dynamics",
            "Cellular Automata and Lattice Gases"
        ],
        "abstract": "There has recently been an explosion of interest in how \"higher-order\" structures emerge in complex systems. This \"emergent\" organization has been found in a variety of natural and artificial systems, although at present the field lacks a unified understanding of what the consequences of higher-order synergies and redundancies are for systems. Typical research treat the presence (or absence) of synergistic information as a dependent variable and report changes in the level of synergy in response to some change in the system. Here, we attempt to flip the script: rather than treating higher-order information as a dependent variable, we use evolutionary optimization to evolve boolean networks with significant higher-order redundancies, synergies, or statistical complexity. We then analyse these evolved populations of networks using established tools for characterizing discrete dynamics: the number of attractors, average transient length, and Derrida coefficient. We also assess the capacity of the systems to integrate information. We find that high-synergy systems are unstable and chaotic, but with a high capacity to integrate information. In contrast, evolved redundant systems are extremely stable, but have negligible capacity to integrate information. Finally, the complex systems that balance integration and segregation (known as Tononi-Sporns-Edelman complexity) show features of both chaosticity and stability, with a greater capacity to integrate information than the redundant systems while being more stable than the random and synergistic systems. We conclude that there may be a fundamental trade-off between the robustness of a systems dynamics and its capacity to integrate information (which inherently requires flexibility and sensitivity), and that certain kinds of complexity naturally balance this trade-off.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14347"
    },
    {
        "doc_id": 611,
        "title": "The Comma Sequence: A Simple Sequence With Bizarre Properties",
        "authors": [
            "Eric Angelini",
            "Michael S. Branicky",
            "Giovanni Resta",
            "N. J. A. Sloane",
            "David W. Wilson"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "The ``comma sequence'' starts with 1 and is defined by the property that if k and k' are consecutive terms, the two-digit number formed from the last digit of k and the first digit of k' is equal to the difference k'-k. If there is more than one such k', choose the smallest, but if there is no such k' the sequence terminates. The sequence begins 1, 12, 35, 94, 135, ... and, surprisingly, ends at term 2137453, which is 99999945. The paper analyzes the sequence and its generalizations to other starting values and other bases. A slight change in the rules allows infinitely long comma sequences to exist.",
        "comments": "19 pages, 4 figures, 1 table",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14346"
    },
    {
        "doc_id": 612,
        "title": "From the Choi Formalism in Infinite Dimensions to Unique Decompositions of Generators of Completely Positive Dynamical Semigroups",
        "authors": [
            "Frederik vom Ende"
        ],
        "subjects": [
            "Functional Analysis",
            "Mathematical Physics",
            "Quantum Physics"
        ],
        "abstract": "Given any separable complex Hilbert space, any trace-class operator $B$ which does not have purely imaginary trace, and any generator $L$ of a norm-continuous one-parameter semigroup of completely positive maps we prove that there exists a unique bounded operator $K$ and a unique completely positive map $\u03a6$ such that (i) $L=K(\\cdot)+(\\cdot)K^*+\u03a6$, (ii) the superoperator $\u03a6(B^*(\\cdot)B)$ is trace class and has vanishing trace, and (iii) ${\\rm tr}(B^*K)$ is a real number. Central to our proof is a modified version of the Choi formalism which relates completely positive maps to positive semi-definite operators. We characterize when this correspondence is injective and surjective, respectively, which in turn explains why the proof idea of our main result cannot extend to non-separable Hilbert spaces. In particular, we find examples of positive semi-definite operators which have empty pre-image under the Choi formalism as soon as the underlying Hilbert space is infinite-dimensional.",
        "comments": "25+3 pages. Generalizes arXiv:2310.04037 to infinite dimensions. To be submitted to J. Funct. Anal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14344"
    },
    {
        "doc_id": 613,
        "title": "Efficient Construction of Long Orientable Sequences",
        "authors": [
            "Daniel Gabric",
            "Joe Sawada"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Discrete Mathematics",
            "Information Theory",
            "Combinatorics"
        ],
        "abstract": "An orientable sequence of order $n$ is a cyclic binary sequence such that each length-$n$ substring appears at most once \\emph{in either direction}. Maximal length orientable sequences are known only for $n\\leq 7$, and a trivial upper bound on their length is $2^{n-1} - 2^{\\lfloor(n-1)/2\\rfloor}$. This paper presents the first efficient algorithm to construct orientable sequences with asymptotically optimal length; more specifically, our algorithm constructs orientable sequences via cycle-joining and a successor-rule approach requiring $O(n)$ time per symbol and $O(n)$ space. This answers a longstanding open question from Dai, Martin, Robshaw, Wild [Cryptography and Coding III (1993)]. Our sequences are applied to find new longest-known orientable sequences for $n\\leq 20$.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14341"
    },
    {
        "doc_id": 614,
        "title": "Vanishing center-of-mass limit of the corotational Oldroyd-B polymeric fluid-structure interaction problem",
        "authors": [
            "Prince Romeo Mensah"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We consider the Oldroyd-B model for a dilute corotational polymer fluid with center-of-mass diffusion that is interacting with a viscoelastic shell. We show that any family of strong solutions of the system described above that is parametrized by the center-of-mass diffusion coefficient converges, as the coefficient goes to zero, to a weak solution of a corotational polymer fluid-structure interaction system without center-of-mass diffusion but with essentially bounded polymer number density and extra stress tensor.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14337"
    },
    {
        "doc_id": 615,
        "title": "On the diameter of a super-order-commuting graph",
        "authors": [
            "Janko Bra\u010di\u010d",
            "Bojan Kuzma"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "We answer a question about the diameter of an order-super-commuting graph on a symmetric group by studying the number-theoretical concept of $d$-complete sequences of primes in arithmetic progression.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14335"
    },
    {
        "doc_id": 616,
        "title": "On strong growth conditions for weighted spaces of entire functions",
        "authors": [
            "Gerhard Schindl"
        ],
        "subjects": [
            "Functional Analysis",
            "Complex Variables"
        ],
        "abstract": "We characterize the inclusion relations between weighted classes of entire functions with rapid decreasing growth and study strong growth comparison relations between given weights. In our considerations first we focus on weights defined in terms of the so-called associated weight function where the weight(system) is based on a given sequence. Then the abstract weight function case is reduced to the weight sequence setting by using the so-called associated weight sequence. Finally, we compare weighted entire function spaces defined in terms of so-called dilatation-type and exponential-type weight systems.",
        "comments": "30 pages; this is the second part of the first version of submission arXiv:2211.14374. The proofs of Prop. 4.7 & 4.12, and hence of Cor. 4.14, in the first part contain a technical gap; in the appendix of this paper we provide a correction",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14330"
    },
    {
        "doc_id": 617,
        "title": "Planar binary trees, noncrossing partitions and the operator-valued S-transform",
        "authors": [
            "Kurusch Ebrahimi-Fard",
            "Timothe Ringeard"
        ],
        "subjects": [
            "Combinatorics",
            "Probability"
        ],
        "abstract": "We revisit Voiculescu's S-transform in the operator-valued setting and its twisted multiplicativity property, using a specific bijection between planar binary trees and noncrossing partitions.",
        "comments": "MSC Class:          46L54; 06A07; 16W60",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14318"
    },
    {
        "doc_id": 618,
        "title": "Higher categories",
        "authors": [
            "Rune Haugseng"
        ],
        "subjects": [
            "Category Theory",
            "Algebraic Topology"
        ],
        "abstract": "Invited contribution to the Encyclopedia of Mathematical Physics. We give an introduction to the homotopical theory of higher categories, focused on motivating the definitions of the basic objects, namely $\\infty$-categories and $(\\infty,n)$-categories.",
        "comments": "33 pages; contribution to Encyclopedia of Mathematical Physics, 2nd ed",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14311"
    },
    {
        "doc_id": 619,
        "title": "A high-order discontinuous Galerkin method for the numerical modeling of epileptic seizures",
        "authors": [
            "Caterina Beatrice Leimer Saglio",
            "Stefano Pagani",
            "Mattia Corti",
            "Paola F. Antonietti"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Epilepsy is a clinical neurological disorder characterized by recurrent and spontaneous seizures consisting of abnormal high-frequency electrical activity in the brain. In this condition, the transmembrane potential dynamics are characterized by rapid and sharp wavefronts traveling along the heterogeneous and anisotropic conduction pathways of the brain. This work employs the monodomain model, coupled with specific neuronal ionic models characterizing ion concentration dynamics, to mathematically describe brain tissue electrophysiology in grey and white matter at the organ scale. This multiscale model is discretized in space with the high-order discontinuous Galerkin method on polygonal and polyhedral grids (PolyDG) and advanced in time with a Crank-Nicolson scheme. This ensures, on the one hand, efficient and accurate simulations of the high-frequency electrical activity that is responsible for epileptic seizure and, on the other hand, keeps reasonably low the computational costs by a suitable combination of high-order approximations and agglomerated polytopal meshes. We numerically investigate synthetic test cases on a two-dimensional heterogeneous squared domain discretized with a polygonal grid, and on a two-dimensional brainstem in a sagittal plane with an agglomerated polygonal grid that takes full advantage of the flexibility of the PolyDG approximation of the semidiscrete formulation. Finally, we provide a theoretical analysis of stability and an a-priori convergence analysis for a simplified mathematical problem.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14310"
    },
    {
        "doc_id": 620,
        "title": "Andr\u00e9-Quillen cohomology in the context of curved algebras",
        "authors": [
            "Joan Bellier-Mill\u00e8s",
            "Sinan Yalin"
        ],
        "subjects": [
            "Algebraic Topology",
            "Algebraic Geometry",
            "K-Theory and Homology",
            "Symplectic Geometry"
        ],
        "abstract": "The Andr\u00e9-Quillen cohomology of an algebra with coefficients in a module is defined by deriving a functor based on K\u00e4hler differential forms. It can be computed using a cofibrant resolution of the algebra in a model category structure where weak equivalences are quasi-isomorphisms. This construction works for algebras over an operad, providing a cohomology theory tailored for each type of algebra. For curved algebras however, the notion of quasi-isomorphism is meaningless. The occurrence and importance of curved structures in various research topics (symplectic topology, deformation theory, derived geometry, mathematical physics) motivate the development of their homotopy theory and Andr\u00e9-Quillen cohomology theory. To get a homotopical context with an appropriate notion of weak equivalence, we consider filtered complete modules with a predifferential inducing a differential on the associated graded. Curved algebras in such modules are algebras over a curved operad. In this article, we consider curved operads which are not necessarily augmented. Bar and cobar constructions adapted to these curved operads are developed, as well as Koszul duality theory. Consequently, we obtain homotopy versions of our curved algebras and make it explicit for interesting cases. Two main examples are the curved operads encoding curved unital associative algebras and curved complex Lie algebras. In particular, homotopy curved unital associative algebras describe the structure of Floer complexes of lagrangian submanifolds and Fukaya categories in symplectic topology. Bar and cobar constructions for curved algebras are also developed, and we obtain resolutions from which we compute their Andr\u00e9-Quillen cohomology with module coefficients. Our computations in the case of curved complex Lie algebras reveal an interesting link between their Andr\u00e9-Quillen cohomology and derived complex analytic geometry.",
        "comments": "78 pages, comments welcome",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14309"
    },
    {
        "doc_id": 621,
        "title": "Some determinants involving quadratic residues modulo primes",
        "authors": [
            "Zhi-Wei Sun"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "In this paper we evaluate several determinants involving quadratic residues modulo primes. For example, for any prime $p>3$ with $p\\equiv3\\pmod4$ and $a,b\\in\\mathbb Z$ with $p\\nmid ab$, we prove that $$\\det\\left[1+\\tan\u03c0\\frac{aj^2+bk^2}p\\right]_{1\\le j,k\\le\\frac{p-1}2}=\\begin{cases}-2^{(p-1)/2}p^{(p-3)/4}&\\text{if}\\ (\\frac{ab}p)=1, \\\\p^{(p-3)/4}&\\text{if}\\ (\\frac{ab}p)=-1,\\end{cases}$$ where $(\\frac{\\cdot}p)$ denotes the Legendre symbol. We also pose some conjectures for further research.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14301"
    },
    {
        "doc_id": 622,
        "title": "Characterising the Haar measure on the $p$-adic rotation groups via inverse limits of measure spaces",
        "authors": [
            "Paolo Aniello",
            "Sonia L'Innocente",
            "Stefano Mancini",
            "Vincenzo Parisi",
            "Ilaria Svampa",
            "Andreas Winter"
        ],
        "subjects": [
            "Mathematical Physics",
            "Functional Analysis",
            "Group Theory",
            "Number Theory"
        ],
        "abstract": "We determine the Haar measure on the compact $p$-adic special orthogonal groups of rotations $\\mathrm{SO}(d)_p$ in dimension $d=2,3$, by exploiting the machinery of inverse limits of measure spaces, for every prime $p>2$. We characterise $\\mathrm{SO}(d)_p$ as inverse limits of finite groups, of which we provide parametrisations and orders, together with an equivalent description through a multivariable Hensel lifting. Supplying these finite groups with their normalised counting measures, we get an inverse family of Haar measure spaces for each $\\mathrm{SO}(d)_p$. Finally, we constructively prove the existence of the so-called inverse limit measure of these inverse families, which is explicitly computable, and prove that it gives the Haar measure on $\\mathrm{SO}(d)_p$. Our results pave the way towards the study of the irreducible projective unitary representations of the $p$-adic rotation groups, with potential applications to the recently proposed $p$-adic quantum information theory.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14298"
    },
    {
        "doc_id": 623,
        "title": "PWM strategy with harmonics injection and modulated frequency triangular carrier. A review",
        "authors": [
            "Antonio Ruiz-Gonzalez",
            "Mario Meco-Gutierrez",
            "Francisco Perez- Hidalgo",
            "Francisco Vargas-Merino",
            "JuanR Heredia-Larrubia"
        ],
        "subjects": [
            "Systems and Control"
        ],
        "abstract": "A new, programmed pulse width modulation (PWM) technique to control power inverters, which uses a harmonic injection modulator and a frequency modulated triangular carrier, synchronized with the modulating signal is presented in this paper. The instantaneous carrier frequency is adjusted according to a periodic function synchronized with the fundamental term of the modulating signal, in order to maintain the average value of the instantaneous frequency as an odd positive integer multiple of 3, for each period of the modulating signal which is known as the average modulation order. The advantages of using the proposed technique over the conventional PWM techniques are the reduction in the total harmonic distortion and shift the frequency up of the temporal harmonics for any average modulation order. The experimental results show the viability of optimizing the time harmonics generated to minimize the vibrations in an induction motor or avoid the resonant frequencies.The mathematical formulation for the output modulated voltage is defined and the results are also checked experimentally and compared to a sinusoidal PWM technique",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14297"
    },
    {
        "doc_id": 624,
        "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts",
        "authors": [
            "Maciej Besta",
            "Florim Memedi",
            "Zhenyu Zhang",
            "Robert Gerstenberger",
            "Nils Blach",
            "Piotr Nyczyk",
            "Marcin Copik",
            "Grzegorz Kwa\u015bniewski",
            "J\u00fcrgen M\u00fcller",
            "Lukas Gianinazzi",
            "Ales Kubicek",
            "Hubert Niewiadomski",
            "Onur Mutlu",
            "Torsten Hoefler"
        ],
        "subjects": [
            "Computation and Language",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models' (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM's capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxonomy of structure-enhanced LLM reasoning schemes. We focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. We refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the LLM context. Our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. We also outline theoretical underpinnings, relationships between prompting and others parts of the LLM ecosystem such as knowledge bases, and the associated research challenges. Our work will help to advance future prompt engineering techniques.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14295"
    },
    {
        "doc_id": 625,
        "title": "On the Algebraic Classification of Non-singular Flexible Kokotsakis Polyhedra",
        "authors": [
            "Yang Liu",
            "Yi Ouyang",
            "Dominik L. Michels"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Across various scientific and engineering domains, a growing interest in flexible and deployable structures is becoming evident. These structures facilitate seamless transitions between distinct states of shape and find broad applicability ranging from robotics and solar cells to meta-materials and architecture. In this contribution, we study a class of mechanisms known as Kokotsakis polyhedra with a quadrangular base. These are $3\\times3$ quadrilateral meshes whose faces are rigid bodies and joined by hinges at the common edges. Compared to prior work, the quadrilateral faces do not have to be planar. In general, such meshes are not flexible, and the problem of finding and classifying the flexible ones is old, but until now largely unsolved. It appears that the tangent values of the dihedral angles between different faces are algebraically related through polynomials. Specifically, by fixing one angle as a parameter, the others can be parameterized algebraically and hence belong to an extended rational function field of the parameter. We use this approach to characterize shape restrictions resulting in flexible polyhedra.",
        "comments": "MSC Class:          12D05; 12F05; 52C25",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14291"
    },
    {
        "doc_id": 626,
        "title": "Modelling Micro-Doppler Signature of Drone Propellers in Distributed ISAC",
        "authors": [
            "Heraldo Cesar Alves Costa",
            "Saw James Myint",
            "Carsten Andrich",
            "Sebastian W. Giehl",
            "Christian Schneider",
            "Reiner S. Thom\u00e4"
        ],
        "subjects": [
            "Signal Processing"
        ],
        "abstract": "Integrated Sensing and Communication (ISAC) comprises detection and analysis of non-cooperative targets by exploiting the resources of the mobile radio system. In this context, micro-Doppler is of great importance for target classification, in order to distinguish objects with local movements. For developing algorithms for target classification, it is necessary to have a large amount of target signatures. Aiming to generate these data, this paper proposes a mathematical model for the micro-Doppler of drone rotating propellers, and validate the proposed model by comparing it to measured micro-Doppler. Results show that the proposed mathematical model can generate micro-Doppler data very similar to those from measurement data.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14287"
    },
    {
        "doc_id": 627,
        "title": "An Instance-Based Approach to the Trace Reconstruction Problem",
        "authors": [
            "Kayvon Mazooji",
            "Ilan Shomorony"
        ],
        "subjects": [
            "Information Theory",
            "Data Structures and Algorithms",
            "Probability",
            "Statistics Theory"
        ],
        "abstract": "In the trace reconstruction problem, one observes the output of passing a binary string $s \\in \\{0,1\\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ \"traces.\" Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the \"Levenshtein difficulty\" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple \"Las Vegas algorithm\" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.",
        "comments": "7 pages, accepted for publication in the proceedings of the 58th Annual Conference on Information Sciences and Systems (CISS 2024)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14277"
    },
    {
        "doc_id": 628,
        "title": "Bifurcation of Dividing Surfaces Constructed from Period-Doubling Bifurcations of Periodic Orbits in a Caldera Potential Energy Surface",
        "authors": [
            "Matthaios Katsanikas",
            "Makrina Agaoglou",
            "Stephen Wiggins"
        ],
        "subjects": [
            "Chaotic Dynamics",
            "Dynamical Systems",
            "Chemical Physics"
        ],
        "abstract": "In this work we analyze the bifurcation of dividing surfaces that occurs as a result of two period-doubling bifurcations in a 2D caldera-type potential. We study the structure, the range, the minimum and maximum extents of the periodic orbit dividing surfaces before and after a subcritical period-doubling bifurcation of the family of the central minimum of the potential energy surface. Furthermore, we repeat the same study for the case of a supercritical perioddoubling bifurcation of the family of the central minimum of the potential energy surface. We will discuss and compare the results for the two cases of bifurcations of dividing surfaces.",
        "comments": "15 pages. arXiv admin note: text overlap with arXiv:2107.09623",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14275"
    },
    {
        "doc_id": 629,
        "title": "Uniformly rotating vortices for the lake equation",
        "authors": [
            "Taoufik Hmidi",
            "Haroune Houamed",
            "Emeric Roulley",
            "Mohamed Zerguine"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We investigate the existence of time-periodic vortex patch solutions, in both simply and doubly-connected cases, for the two-dimensional lake equation where the depth function of the lake is assumed to be non-degenerate and radial. The proofs employ bifurcation techniques, where the most challenging steps are related to the regularity study of some nonlinear functionals and the spectral analysis of their linearized operators around Rankine type vortices. The main difficulties stem from the roughness and the implicit form of the Green function connecting the fluid vorticity and its stream function. We handle in part these issues by exploring the asymptotic structure of the solutions to the associated elliptic problem. As to the distribution of the spectrum, it is tackled by a fixed-point argument through a perturbative approach.",
        "comments": "65 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14273"
    },
    {
        "doc_id": 630,
        "title": "Diagrammatic representations of 3-periodic entanglements",
        "authors": [
            "Toky Andriamanalina",
            "Myfanwy E. Evans",
            "Sonia Mahmoudi"
        ],
        "subjects": [
            "Geometric Topology",
            "Algebraic Topology"
        ],
        "abstract": "Diagrams enable the use of various algebraic and geometric tools in analysing and classifying knots. In this paper we introduce a new diagrammatic representation of triply periodic entangled structures, which are embeddings of simple curves in $\\mathbb{R}^3$ that are invariant under translations along three non-coplanar axes. These diagrams require an extended set of new moves in addition to the Reidemeister moves, which we show to preserve ambient isotopies of triply periodic entangled structures. We use the diagrams to define the crossing number and the unknotting number of the triply periodic entanglements, demonstrating the practicality of the diagrammatic representation.",
        "comments": "Report number:          RIKEN-iTHEMS-Report-24                          MSC Class:          57K10; 57K12 (Primary) 57K35 (Secondary)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14254"
    },
    {
        "doc_id": 631,
        "title": "Asymptotic limit of linear parabolic equations with spatio-temporal degenerated potentials",
        "authors": [
            "Pablo \u00c0lvarez-Caudevilla",
            "Matthieu Bonnivard",
            "Antoine Lemenant"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In this paper, we observe how the heat equation in a non-cylindrical domain can arise as the asymptotic limit of a parabolic problem in a cylindrical domain, by adding a potential that vanishes outside the limit domain. This can be seen as a parabolic version of a previous work by the first and last authors, concerning the stationary case. We provide a strong convergence result for the solution by use of energetic methods and $\u0393$-convergence technics. Then, we establish an exponential decay estimate coming from an adaptation of an argument due to B. Simon.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14249"
    },
    {
        "doc_id": 632,
        "title": "Asymptotic behaviour for a class of quasilinear cooperative eigenvalue problems",
        "authors": [
            "Pablo Alvarez-Caudevilla"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "This work is devoted to the analysis of the asymptotic behaviour of a parameter dependent quasilinear cooperative eigenvalue system when a parameter in front of some non-negative potentials goes to infinity. In particular we consider operators of $p$-Laplacian type. We prove that the eigenfunctions concentrate on the subdomains where those potentials vanish at the limit, while the eigenvalue approaches to an upper bound that will depend on those subdomains as well. We also show several properties for the unusual limiting problems obtained here.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14247"
    },
    {
        "doc_id": 633,
        "title": "A stationary population model with an interior interface-type boundary",
        "authors": [
            "Pablo Alvarez-Caudevilla",
            "Cristina Br\u00e4ndle"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We propose a stationary system that might be regarded as a migration model of some population abandoning their original place of abode and becoming part of another population, once they reach the interface boundary. To do so, we show a model where each population follows a logistic equation in their own environment while assuming spatial heterogeneities. Moreover, both populations are coupled through the common boundary, which acts as a permeable membrane on which their flow moves in and out. The main goal we face in this work will be to describe the precise interplay between the stationary solutions with respect to the parameters involved in the problem, in particular the growth rate of the populations and the coupling parameter involved on the boundary where the interchange of flux is taking place.",
        "comments": "28 pages, 1 figure",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14246"
    },
    {
        "doc_id": 634,
        "title": "Counting rational points in non-singular curves",
        "authors": [
            "Chunhui Liu"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "In this paper, we will give a uniform upper bound of the number of rational points of bounded height in non-singular curves by applying the global determinant method.",
        "comments": "8 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14245"
    },
    {
        "doc_id": 635,
        "title": "Equivariant $\\mathcal{D}$-stability for Actions of Tensor Categories",
        "authors": [
            "Samuel Evington",
            "Sergio Gir\u00f3n Pacheco",
            "Corey Jones"
        ],
        "subjects": [
            "Operator Algebras",
            "Quantum Algebra"
        ],
        "abstract": "We introduce a notion of equivariant $\\mathcal{D}$-stability for actions of unitary tensor categories on C$^*$-algebras. We show that, when $\\mathcal{D}$ is strongly self-absorbing, equivariant $\\mathcal{D}$-stability of an action is equivalent to a unital embedding of $\\mathcal{D}$ into a certain subalgebra of Kirchberg's central sequence algebra. We use this to show $\\mathcal{Z}$-stability for a large class of AF-actions.",
        "comments": "13 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14238"
    },
    {
        "doc_id": 636,
        "title": "Existence and regularity of random attractors for stochastic evolution equations driven by rough noise",
        "authors": [
            "Alexandra Neamtu",
            "Tim Seitz"
        ],
        "subjects": [
            "Probability",
            "Analysis of PDEs",
            "Dynamical Systems"
        ],
        "abstract": "This work establishes the existence and regularity of random pullback attractors for parabolic partial differential equations with rough nonlinear multiplicative noise under natural assumptions on the coefficients. To this aim, we combine tools from rough path theory and random dynamical systems.~An application is given by partial differential equations with rough boundary noise, for which flow transformations are not available.",
        "comments": "31 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14235"
    },
    {
        "doc_id": 637,
        "title": "Bounds for the number of moves between pants decompositions, and between triangulations",
        "authors": [
            "Marc Lackenby",
            "Mehdi Yazdi"
        ],
        "subjects": [
            "Geometric Topology"
        ],
        "abstract": "Given two pants decompositions of a compact orientable surface $S$, we give an upper bound for their distance in the pants graph that depends logarithmically on their intersection number and polynomially on the Euler characteristic of $S$. As a consequence, we find an upper bound on the volume of the convex core of a maximal cusp (which is a hyperbolic structures on $S \\times \\mathbb{R}$ where given pants decompositions of the conformal boundary are pinched to annular cusps). As a further application, we give an upper bound for the Weil--Petersson distance between two points in the Teichm\u00fcller space of $S$ in terms of their corresponding short pants decompositions. Similarly, given two one-vertex triangulations of $S$, we give an upper bound for the number of flips and twist maps needed to convert one triangulation into the other. The proofs rely on using pre-triangulations, train tracks, and an algorithm of Agol, Hass, and Thurston.",
        "comments": "43 pages, 12 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14233"
    },
    {
        "doc_id": 638,
        "title": "Strongly k-recursive sequences",
        "authors": [
            "Daniel Krenn",
            "Jeffrey Shallit"
        ],
        "subjects": [
            "Formal Languages and Automata Theory",
            "Discrete Mathematics",
            "Combinatorics"
        ],
        "abstract": "Drawing inspiration from a recent paper of Heuberger, Krenn, and Lipnik, we define the class of strongly k-recursive sequences. We show that every k-automatic sequence is strongly $k$-recursive, therefore k-recursive, and discuss that the converse is not true.\n  We also show that the class of strongly k-recursive sequences is a proper subclass of the class of k-regular sequences, and we present some explicit examples. We then extend the proof techniques to answer the same question for the class of k-recursive sequences.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14231"
    },
    {
        "doc_id": 639,
        "title": "A variational characterization of Einstein-Brillouin-Keller quantization",
        "authors": [
            "Kai Cieliebak",
            "Urs Frauenfelder"
        ],
        "subjects": [
            "Symplectic Geometry"
        ],
        "abstract": "In this paper we explain how to construct the EBK spectrum from the marked action spectrum and derive a minimax formula for concave toric domains. In the special case of the billiard on the disk we show that while the action spectrum is algebraic the EBK spectrum has infinite transcendence degree under the assumption that Schanuel's conjecture is true.",
        "comments": "19 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14223"
    },
    {
        "doc_id": 640,
        "title": "Fixed point subgroups of a supertight automorphism",
        "authors": [
            "Ulla Karhum\u00e4ki"
        ],
        "subjects": [
            "Group Theory",
            "Logic"
        ],
        "abstract": "Let $G$ be an infinite simple group of finite Morley rank and $\u03b1$ a supertight automorphism of $G$ so that the fixed point subgroup $P_n:=C_G(\u03b1^n)$ is pseudofinite for all $n\\in \\mathbb{N}\\setminus\\{0\\}$. It is know (using CFSG) that the socle $S_n:={\\rm Soc}(P_n)$ is a (twisted) Chevalley group over a pseudofinite field. We prove that there is $r\\in \\mathbb{N}\\setminus\\{0\\}$ so that for each $n$ we have $[P_n:S_n] < r$ and that there is no $m \\in \\mathbb{N}\\setminus \\{0\\}$ so that for each $n$ the sizes of the Sylow $2$-subgroups of $S_n$ are bounded by $m$. We also note that in the recent identification result of $G$ under the assumption ${\\rm pr}_2(G)=1$, the use of CFSG is not needed.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14222"
    },
    {
        "doc_id": 641,
        "title": "Orthogonal almost complex structure and its Nijenhuis tensor",
        "authors": [
            "Zizhou Tang",
            "Wenjiao Yan"
        ],
        "subjects": [
            "Differential Geometry",
            "Complex Variables"
        ],
        "abstract": "In this paper, we demonstrate that on an almost Hermitian manifold $(M^{2n}, J, ds^2)$, a 2-form $\\varphi=S^*\u03a6$, the pulling back of the K\u00e4hler form $\u03a6$ on the twistor bundle over $M^{2n}$, is non-degenerate if the squared norm $|N|^2$ of the Nijenhuis tensor is less than $\\frac{64}{5}$ when $n\\geq 3$ or less than $16$ when $n=2$. As a corollary, there exists no orthogonal almost complex structure on the standard sphere $(S^6, ds_0^2)$ with $|N|^2<\\frac{64}{5}$ everywhere.",
        "comments": "11pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14213"
    },
    {
        "doc_id": 642,
        "title": "On the growth of torsion in the cohomology of some arithmetic groups of $\\mathbb{Q}$-rank one",
        "authors": [
            "Werner Mueller",
            "Fr\u00e9d\u00e9ric Rochon"
        ],
        "subjects": [
            "Differential Geometry",
            "Geometric Topology",
            "Number Theory"
        ],
        "abstract": "Given a number field $F$ with ring of integers $\\mathcal{O}_{F}$, one can associate to any torsion free subgroup of $\\operatorname{SL}(2,\\mathcal{O}_{F})$ of finite index a complete Riemannian manifold of finite volume with fibered cusp ends. For natural choices of flat vector bundles on such a manifold, we show that analytic torsion is identified with the Reidemeister torsion of the Borel-Serre compactification. This is used to obtain exponential growth of torsion in the cohomology for sequences of congruence subgroups.",
        "comments": "45 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14205"
    },
    {
        "doc_id": 643,
        "title": "Dynamic image reconstruction in MPI with RESESOP-Kaczmarz",
        "authors": [
            "Marius Nitzsche",
            "Bernadette N Hahn"
        ],
        "subjects": [
            "Optimization and Control",
            "Numerical Analysis"
        ],
        "abstract": "In Magnetic Particle Imaging (MPI), it is typically assumed that the studied specimen is stationary during the data acquisition. In practical applications however, the searched-for 3D distribution of the magnetic nanoparticles might show a dynamic behavior, caused by e.g. breathing or movement of the blood. Neglecting those dynamics during the reconstruction step results in motion artifacts and a reduced image quality.\n  This article addresses the challenge of capturing high quality images in the presence of motion. A promising technique provides the Regularized Sequential Subspace Optimization (RESESOP) algorithm, which takes dynamics as model inexactness into account, significantly improving reconstruction compared to standard static algorithms like regularized Kaczmarz. Notably, this algorithm operates with minimal prior information and the method allows for subframe reconstruction, making it suitable for scenarios with rapid particle movement. The performance of the proposed method is demonstrated on both simulated and real data sets.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14202"
    },
    {
        "doc_id": 644,
        "title": "Proof of conjectures on series with summands involving $ \\binom{2k}{k}8^k/(\\binom{3k}{k}\\binom{6k}{3k})$",
        "authors": [
            "Zhi-Wei Sun",
            "Yajun Zhou"
        ],
        "subjects": [
            "Classical Analysis and ODEs",
            "Number Theory"
        ],
        "abstract": "Using cyclotomic multiple zeta values of level $8$, we confirm and generalize several conjectural identities on infinite series with summands involving $\\binom{2k}k8^k/(\\binom{3k}k\\binom{6k}{3k})$. For example, we prove that \\[\\sum_{k=0}^\\infty\\frac{(350k-17)\\binom{2k}k8^k} {\\binom{3k}k\\binom{6k}{3k}}=15\\sqrt2\\,\u03c0+27\\] and \\[\\sum_{k=1}^\\infty\\frac{\\left\\{(5k-1)\\left[16\\mathsf H_{2k-1}^{(2)}-3\\mathsf H_{k-1}^{(2)}\\right]-\\frac{12(6k-1)}{(2k-1)^2}\\right\\}\\binom{2k}k8^k} {k(2k-1)\\binom{3k}k\\binom{6k}{3k}}=\\frac{\u03c0^3}{12\\sqrt2},\\] where $\\mathsf H^{(2)}_m$ denotes the second-order harmonic number $\\sum_{0<j\\leq m}\\frac1{j^2}$.",
        "comments": "23 pages, 5 tables. A sequel to arXiv:2401.12083v1",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14197"
    },
    {
        "doc_id": 645,
        "title": "A few remarks on effectivity and good minimal models",
        "authors": [
            "Vladimir Lazi\u0107"
        ],
        "subjects": [
            "Algebraic Geometry"
        ],
        "abstract": "We prove several results relating the nonvanishing and the existence of good minimal models of different pairs that have the same underlying variety.",
        "comments": "MSC Class:          14E30",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14190"
    },
    {
        "doc_id": 646,
        "title": "Form Convex Hull to Coancavity: Surface Contraction Around a Point Set",
        "authors": [
            "Netzer Moriya"
        ],
        "subjects": [
            "Optimization and Control",
            "Geometric Topology"
        ],
        "abstract": "This paper investigates the transformation of a convex hull, derived from a d-dimensional point cloud, into a concave surface. Our primary focus is on the development of a methodology that ensures all points in the point cloud are encapsulated within a closed, non-intersecting concave surface. The study begins with the initial convex hull and employs an iterative process of facet replacement and expansion to evolve the surface into Scc, which accurately conforms to the complex geometry of the point cloud.",
        "comments": "15 pages, 3 figures 1 theorem",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14189"
    },
    {
        "doc_id": 647,
        "title": "Fourth-order operators with unbounded coefficients",
        "authors": [
            "Federica Gregorio",
            "Chiara Spina",
            "Cristian Tacelli"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We prove that operators of the form $A=-a(x)^2\u0394^{2}$, with $|D a(x)|\\leq c a(x)^\\frac{1}{2}$, generate analytic semigroups in $L^p(\\mathbb{R}^N)$ for $1<p\\leq\\infty$ and in $C_b(\\mathbb{R}^N)$. In particular, we deduce generation results for the operator $A :=- (1+|x|^2)^\u03b1 \u0394^{2}$, $0<\u03b1<2$. Moreover, we characterize the maximal domain of such operators in $L^p(\\mathbb{R}^N)$ for $1<p<\\infty$.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14187"
    },
    {
        "doc_id": 648,
        "title": "Towards Autonomous Supply Chains: Definition, Characteristics, Conceptual Framework, and Autonomy Levels",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Yaniv Proselkov",
            "Alexandra Brintrup"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Multiagent Systems",
            "Systems and Control",
            "Optimization and Control"
        ],
        "abstract": "Recent global disruptions, such as the pandemic and geopolitical conflicts, have profoundly exposed vulnerabilities in traditional supply chains, requiring exploration of more resilient alternatives. Autonomous supply chains (ASCs) have emerged as a potential solution, offering increased visibility, flexibility, and resilience in turbulent trade environments. Despite discussions in industry and academia over several years, ASCs lack well-established theoretical foundations. This paper addresses this research gap by presenting a formal definition of ASC along with its defining characteristics and auxiliary concepts. We propose a layered conceptual framework called the MIISI model. An illustrative case study focusing on the meat supply chain demonstrates an initial ASC implementation based on this conceptual model. Additionally, we introduce a seven-level supply chain autonomy reference model, delineating a trajectory towards achieving a full supply chain autonomy. Recognising that this work represents an initial endeavour, we emphasise the need for continued exploration in this emerging domain. We anticipate that this work will stimulate further research, both theoretical and technical, and contribute to the continual evolution of ASCs.",
        "comments": "This paper includes 20 pages and 8 figures",
        "date": "13 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.14183"
    },
    {
        "doc_id": 649,
        "title": "Harnack inequalities for kinetic integral equations",
        "authors": [
            "Francesca Anceschi",
            "Giampiero Palatucci",
            "Mirco Piccinini"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "We deal with a wide class of kinetic equations, $$ \\big[ \\partial_t + v\\cdot\\nabla_x\\big] f = \\mathcal{L}_v f. $$ Above, the diffusion term $\\mathcal{L}_v$ is an integro-differential operator, whose nonnegative kernel is of fractional order $s\\in(0,1)$ having merely measurable coefficients. Amongst other results, we are able to prove that nonnegative weak solutions $f$ do satisfy $$ \\sup_{Q^-} f \\ \\leq \\ c\\inf_{Q^+} f, $$ where $Q^{\\pm}$ are suitable slanted cylinders. No a-priori boundedness is assumed, as usually in the literature, since we are also able to prove a general interpolation inequality in turn giving local boundedness which is valid even for weak subsolutions with no sign assumptions.\n  To our knowledge, this is the very first time that a strong Harnack inequality is proven for kinetic integro-differential-type equations.\n  A new independent result, a Besicovitch-type covering argument for very general kinetic geometries, is also stated and proved.",
        "comments": "41 pages, 4 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14182"
    },
    {
        "doc_id": 650,
        "title": "On the strong separation condition for self-similar iterated function systems with random translations",
        "authors": [
            "Simon Baker",
            "Derong Kong",
            "Zhiqiang Wang"
        ],
        "subjects": [
            "Dynamical Systems",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Given a self-similar iterated function system $\u03a6=\\{ \u03c6_i(x)=\u03c1_i O_i x+t_i \\}_{i=1}^m$ acting on $\\mathbb{R}^d$, we can generate a parameterised family of iterated function systems by replacing each $t_i$ with a random vector in $\\mathbb{R}^d$. In this paper we study whether a Lebesgue typical member of this family will satisfy the strong separation condition. Our main results show that if the similarity dimension of $\u03a6$ is sufficiently small, then a Lebesgue typical member of this family will satisfy the strong separation condition.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14175"
    },
    {
        "doc_id": 651,
        "title": "A finite volume method preserving the invariant region property for the quasimonotone reaction-diffusion systems",
        "authors": [
            "Huifang Zhou"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We present a finite volume method preserving the invariant region property (IRP) for the reaction-diffusion systems with quasimonotone functions, including nondecreasing, decreasing, and mixed quasimonotone systems. The diffusion terms and time derivatives are discretized by a finite volume method satisfying the discrete maximum principle (DMP) and the backward Euler method, respectively. The discretization leads to an implicit and nonlinear scheme, and it is proved to preserve the invariant region property unconditionally. We construct an iterative algorithm and prove the invariant region property ar each iteration step. Numerical examples are shown to confirm the accuracy and invariant region property of our scheme.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14169"
    },
    {
        "doc_id": 652,
        "title": "Dynamics of a particle under the Gravitational Potential of a Massive Annulus: properties and equilibrium description",
        "authors": [
            "Eva Tresaco",
            "Antonio Elipe",
            "Andr\u00e9s Riaguas"
        ],
        "subjects": [
            "Dynamical Systems"
        ],
        "abstract": "This paper studies the main features of the dynamics around a massive annular disk. The first part addresses the difficulties finding an appropriated expression of the gravitational potential of a massive disk, which will be used to define the differential equations of motion of our dynamical system. The second part describes the main features of the dynamics with special attention to equilibrium of the system.",
        "comments": "MSC Class:          14J60 (Primary)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14164"
    },
    {
        "doc_id": 653,
        "title": "The stabilizer-free weak Galerkin finite element method for the Biharmonic equation using polynomials of reduced order",
        "authors": [
            "Shanshan Gu",
            "Qilong Zhai"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "In this article, we decrease the degree of the polynomials on the boundary of the weak functions and modify the definition of the weak laplacian which are introduced in \\cite{BiharmonicSFWG} to use the SFWG method for the biharmonic equation. Then we propose the relevant numerical format and obtain the optimal order of error estimates in $H^2$ and $L^2$ norms. Finally, we confirm the estimates using numerical experiments.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14163"
    },
    {
        "doc_id": 654,
        "title": "A view toward homomorphisms and cv-polynomials between double Ore extensions",
        "authors": [
            "Mar\u00eda Camila Ram\u00edrez",
            "Armando Reyes"
        ],
        "subjects": [
            "Rings and Algebras"
        ],
        "abstract": "Motivated by the theory of homomorphisms and cv-polynomials of Ore extensions formulated by several mathematicians, the rol of double Ore extensions introduced by Zhang and Zhang in the classification of Artin-Schelter regular algebras of dimension four, and that there are no inclusions between the classes of all double Ore extensions of an algebra and of all length two iterated Ore extensions of the same algebra, our aim in this paper is to present a first approach toward a theory of homomorphisms and cv-polynomials between double Ore extensions. We obtain several results on the characterizations of cv-polynomials and their relations with inner derivations of the ring of coefficients of the double algebra, and show that the computation of homomorphisms corresponding to these polynomials is non-trivial. We illustrate our results with different examples including Nakayama automorphisms of trimmed double Ore extensions.",
        "comments": "25 pages. arXiv admin note: text overlap with arXiv:0909.3238 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14162"
    },
    {
        "doc_id": 655,
        "title": "A Mathematical Theory of Semantic Communication: Overview",
        "authors": [
            "Kai Niu",
            "Ping Zhang"
        ],
        "subjects": [
            "Information Theory"
        ],
        "abstract": "Semantic communication initiates a new direction for future communication. In this paper, we aim to establish a systematic framework of semantic information theory (SIT). First, we propose a semantic communication model and define the synonymous mapping to indicate the critical relationship between semantic information and syntactic information. Based on this core concept, we introduce the measures of semantic information, such as semantic entropy $H_s(\\tilde{U})$, up/down semantic mutual information $I^s(\\tilde{X};\\tilde{Y})$ $(I_s(\\tilde{X};\\tilde{Y}))$, semantic capacity $C_s=\\max_{p(x)}I^s(\\tilde{X};\\tilde{Y})$, and semantic rate-distortion function $R_s(D)=\\min_{p(\\hat{x}|x):\\mathbb{E}d_s(\\tilde{x},\\hat{\\tilde{x}})\\leq D}I_s(\\tilde{X};\\hat{\\tilde{X}})$. Furthermore, we prove three coding theorems of SIT, that is, the semantic source coding theorem, semantic channel coding theorem, and semantic rate-distortion coding theorem. We find that the limits of information theory are extended by using synonymous mapping, that is, $H_s(\\tilde{U})\\leq H(U)$, $C_s\\geq C$ and $R_s(D)\\leq R(D)$. All these works composite the basis of semantic information theory. In summary, the theoretic framework proposed in this paper is a natural extension of classic information theory and may reveal great performance potential for future communication.",
        "comments": "6 pages, 2 figures. This paper is submitted to the 2024 IEEE International Symposium on Information Theory (ISIT 2024). arXiv admin note: substantial text overlap with arXiv:2401.13387",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14160"
    },
    {
        "doc_id": 656,
        "title": "A robust consensus + innovations-based distributed parameter estimator",
        "authors": [
            "Nicolai Lorenz-Meyer",
            "Juan G. Rueda-Escobedo",
            "Jaime A. Moreno",
            "Johannes Schiffer"
        ],
        "subjects": [
            "Optimization and Control"
        ],
        "abstract": "While distributed parameter estimation has been extensively studied in the literature, little has been achieved in terms of robust analysis and tuning methods in the presence of disturbances. However, disturbances such as measurement noise and model mismatches occur in any real-world setting. Therefore, providing tuning methods with specific robustness guarantees would greatly benefit the practical application. To address these issues, we recast the error dynamics of a continuous-time version of the widely used consensus + innovations-based distributed parameter estimator to reflect the error dynamics induced by the classical gradient descent algorithm. This paves the way for the construction of a strong Lyapunov function. Based on this result, we derive linear matrix inequality-based tools for tuning the algorithm gains such that a guaranteed upper bound on the L2-gain with respect to parameter variations, measurement noise, and disturbances in the communication channels is achieved. An application example illustrates the efficiency of the method.",
        "comments": "13 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14158"
    },
    {
        "doc_id": 657,
        "title": "Traces of vanishing H\u00f6lder spaces",
        "authors": [
            "Kaushik Mohanta",
            "Carlos Mudarra",
            "Tuomas Oikari"
        ],
        "subjects": [
            "Classical Analysis and ODEs",
            "Functional Analysis"
        ],
        "abstract": "For an arbitrary subset $E\\subset\\mathbb{R}^n$ and a modulus of continuity $\u03c9$, we define the subspaces of vanishing jets $\\dot{\\operatorname{VJ}}^{m,\u03c9}_\u0393(E)$ of the jet spaces $\\dot{\\operatorname{J}}^{m,\u03c9}(E),$ for the vanishing scales $\u0393\\in \\{\\operatorname{small},\\operatorname{large},\\operatorname{far}\\},$ and up to order $m\\in \\mathbb{N} \\cup \\lbrace 0 \\rbrace.$ We show that each $\u0393$-vanishing jet of order $m$ is obtained by restricting a \\emph{globally} defined function whose $m$th derivative is in the $\u0393$-vanishing H\u00f6lder space. This amounts to proving that the linear Whitney extension operator preserves separately each of the vanishing scales from $E$ to the whole ambient space $\\mathbb{R}^n.$\n  Further results will soon appear in a second version of this manuscript.",
        "comments": "17 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14156"
    },
    {
        "doc_id": 658,
        "title": "On Abel's Problem about Logarithmic Integrals in Positive Characteristic",
        "authors": [
            "Florian F\u00fcrnsinn",
            "Herwig Hauser",
            "Hiraku Kawanoue"
        ],
        "subjects": [
            "Number Theory",
            "Commutative Algebra",
            "Classical Analysis and ODEs"
        ],
        "abstract": "Linear differential equations with polynomial coefficients over a field $K$ of positive characteristic $p$ with local exponents in the prime field have a basis of solutions in the differential extension $\\mathcal{R}_p=K(z_1, z_2, \\ldots)(\\!( x)\\!)$ of $K(x)$, where $x'=1, z_1'=1/x$ and $z_i'=z_{i-1}'/z_{i-1}$. For differential equations of order $1$ it is shown that there exists a solution $y$ whose projections $y\\vert_{z_{i+1}=z_{i+2}=\\cdots=0}$ are algebraic over the field of rational functions $K(x, z_1, \\ldots, z_{i})$ for all $i$. This can be seen as a characteristic $p$ analogue of Abel's problem about the algebraicity of logarithmic integrals. Further, the existence of infinite product representations of these solutions is shown. As a main tool $p^i$-curvatures are introduced, generalizing the notion of the $p$-curvature.",
        "comments": "25 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14154"
    },
    {
        "doc_id": 659,
        "title": "Cohomology of toric diagrams",
        "authors": [
            "Grigory Solomadin"
        ],
        "subjects": [
            "Algebraic Topology"
        ],
        "abstract": "In this note, integral cohomology of homotopy colimits for toric diagrams and their classifying spaces over regular CW posets are described in terms of sheaf cohomology. Split $T$-CW-complexes with CW orbit poset $C$ have such decomposition (up to a homeomorphism) in terms of a $T$-diagram $D$ over $C$. Equivariant formality for $hocolim\\ D$ is equivalent to $H^{odd}(hocolim\\ D)=0$ (over $\\mathbb{Q}$, or over $\\mathbb{Z}$ for connected stabilizers) provided that $C$ is an oriented homology manifold. The integral singular cohomology groups and bigraded Betti numbers are computed in this setting. Similar descriptions are provided for skeleta of toric manifolds and compact nonsingular toric varieties. The cohomological orbit spectral sequence collapse over $\\mathbb{Z}$ at page $2$ is proved for any compact toric variety.",
        "comments": "27 pages; comments are welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14146"
    },
    {
        "doc_id": 660,
        "title": "Mathematical Tri-State Model for Bee Shimmering Propagation Dynamics",
        "authors": [
            "Navin Patel",
            "Henri Huijberts",
            "Kaspar Althoefer",
            "Ketao Zhang"
        ],
        "subjects": [
            "Adaptation and Self-Organizing Systems",
            "Dynamical Systems",
            "Biological Physics"
        ],
        "abstract": "Bees undergo a self-organised process known as shimmering, where they form emergent patterns when they interact with each other on the nest surface as a defence mechanism in response to predator attacks. Many experimental studies have empirically investigated how the transfer of information to neighbouring bees propagates in various shimmering processes by measuring shimmering wave strength. However, there is no analytical modelling of the collective defence mechanism in nature. Here we introduce the first analytical tri-state Inactive-Active-Relapse (IAR) model to formulate the intrinsic process of bee shimmering. The major shimmering behaviour is shown to emerge under theoretical conditions which is demonstrated numerically and visually by simulating 1,000,000 bee agents, while the number of agents is scalable. Furthermore, we elaborate on these mathematical results to construct a wave strength function to demonstrate the accuracy of shimmering dynamics. The constructed wave strength function can be adapted to peak between 50-150ms which supports the experimental studies. Our results provide a foundation for further theoretical understanding of bee shimmering wave dynamics and could serve as inspiration for modelling other self-organised phenomena across scientific applications.",
        "comments": "20 pages, 7 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14145"
    },
    {
        "doc_id": 661,
        "title": "Generalized (co)homology of symmetric quandles over homogeneous Beck modules",
        "authors": [
            "Biswadeep Karmakar",
            "Deepanshi Saraf",
            "Mahender Singh"
        ],
        "subjects": [
            "Quantum Algebra",
            "Geometric Topology"
        ],
        "abstract": "A quandle equipped with a good involution is referred to as symmetric. It is known that the cohomology of symmetric quandles gives rise to strong cocycle invariants for classical and surface links, even when they are not necessarily oriented. In this paper, we introduce the category of symmetric quandle modules and prove that these modules completely determine the Beck modules in the category of symmetric quandles. Consequently, this establishes suitable coefficient objects for constructing appropriate (co)homology theories. We develop an extension theory of modules over symmetric quandles and propose a generalized (co)homology theory for symmetric quandles with coefficients in a homogeneous Beck module, which also recovers the symmetric quandle (co)homology developed by Kamada and Oshiro [Trans. Amer. Math. Soc. (2010)]. Our constructions also apply to symmetric racks. We conclude by establishing an explicit isomorphism between the second cohomology of a symmetric quandle and the first cohomology of its associated group.",
        "comments": "30 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14143"
    },
    {
        "doc_id": 662,
        "title": "On the discriminants of truncated logarithmic polynomials",
        "authors": [
            "John Cullinan",
            "Rylan Gajek-Leonard"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We provide evidence for a conjecture of Yamamura that the truncated logarithmic polynomials \\[ F_n(x) = 1 + x + \\frac{x^2}{2} + \\cdots + \\frac{x^n}{n} \\] have Galois group $S_n$ for all $n \\geq 1$.",
        "comments": "9 pages. Submitted for publication",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14138"
    },
    {
        "doc_id": 663,
        "title": "Comparison of approaches for boundary feedback control of hyperbolic systems",
        "authors": [
            "Michael Herty",
            "Ferdinand Thein"
        ],
        "subjects": [
            "Optimization and Control",
            "Analysis of PDEs"
        ],
        "abstract": "The interest in boundary feedback control of multi-dimensional hyperbolic systems is increasing. In the present work we want to compare some of the recent results available in the literature.",
        "comments": "arXiv admin note: text overlap with arXiv:2303.05598",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14137"
    },
    {
        "doc_id": 664,
        "title": "The Shizuta-Kawashima Condition for the Barotropic SHTC Two Fluid Model",
        "authors": [
            "Ferdinand Thein"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "Recently the barotropic two fluid model belonging to the class of \\emph{symmetric hyperbolic thermodynamically compatible} (SHTC) systems was studied in detail in \\cite{Thein2022}. There the question was raised whether the dissipative structure introduced by the source terms satisfies the Shizuta-Kawashima condition. This well-known condition is a sufficient criterion for the existence of global smooth solutions of the studied system. In this work we exploit the dissipative structure of the system under consideration and verify that the Shizuta-Kawashima condition holds.",
        "comments": "Submitted and accepted for the proceedings of the XVIII International Conference on Hyperbolic Problems: Theory, Numerics, Applications. (HYP2022)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14134"
    },
    {
        "doc_id": 665,
        "title": "A note on cohomological vanishing theorems",
        "authors": [
            "Mohsen Asgharzadeh"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We study $cd(M,N):=\\sup\\{j:H^j_{m}(M,N)\\neq0\\}$, and we prove the following over $AB$-rings: $cd(M,N)<\\infty$ iff $cd(M, N)\\leq2 dim R$. For locally free over the punctured spectrum, we present the better bound, namely $cd(M, N)<\\infty$ iff $cd(M, N)\\leq dim R,$ and show this is sharp for maximal Cohen-Macaulay, and prove that this detects freeness of $M$. We present some explicit examples to compute $cd(M, N)$. Now, suppose $R$ is only Cohen-Macaulay and of prime characteristic equipped with the Frobenius map $\\varphi$. We show for some $n\\gg 0$ that $cd(^{\\varphi_n}R,M)<\\infty$ iff $id_R(M)<\\infty.$ This presents some criteria on regularity. Also, some vanishing results on $Ext^i_R(^{\\varphi}R,-)$ are given, where $(-)\\in\\{R,^{\\varphi}R\\}$. We determine conditions under which the vanishing $Ext^i_R(^{\\varphi}R,-)$ of restricted many $i$-th, implies the vanishing of all.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14133"
    },
    {
        "doc_id": 666,
        "title": "Equivariant Manifold Neural ODEs and Differential Invariants",
        "authors": [
            "Emma Andersdotter",
            "Fredrik Ohlsson"
        ],
        "subjects": [
            "Machine Learning",
            "Dynamical Systems"
        ],
        "abstract": "In this paper we develop a manifestly geometric framework for equivariant manifold neural ordinary differential equations (NODEs), and use it to analyse their modelling capabilities for symmetric data. First, we consider the action of a Lie group $G$ on a smooth manifold $M$ and establish the equivalence between equivariance of vector fields, symmetries of the corresponding Cauchy problems, and equivariance of the associated NODEs. We also propose a novel formulation of the equivariant NODEs in terms of the differential invariants of the action of $G$ on $M$, based on Lie theory for symmetries of differential equations, which provides an efficient parameterisation of the space of equivariant vector fields in a way that is agnostic to both the manifold $M$ and the symmetry group $G$. Second, we construct augmented manifold NODEs, through embeddings into equivariant flows, and show that they are universal approximators of equivariant diffeomorphisms on any path-connected $M$. Furthermore, we show that the augmented NODEs can be incorporated in the geometric framework and parameterised using higher order differential invariants. Finally, we consider the induced action of $G$ on different fields on $M$ and show how it can be used to generalise previous work, on, e.g., continuous normalizing flows, to equivariant models in any geometry.",
        "comments": "17 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14131"
    },
    {
        "doc_id": 667,
        "title": "Universal Weil cohomology",
        "authors": [
            "L. Barbieri-Viale",
            "B. Kahn"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Category Theory",
            "K-Theory and Homology",
            "Number Theory"
        ],
        "abstract": "We construct a new Weil cohomology for smooth projective varieties over a field, universal among Weil cohomologies with values in rigid additive tensor categories. A similar universal problem for Weil cohomologies with values in rigid abelian tensor categories also has a solution. We give a variant for Weil cohomologies satisfying more axioms, like Weak and Hard Lefschetz. As a consequence, we get a different construction of Andr\u00e9's category of motives for motivated correspondences and show that it has a universal property. This theory extends over suitable bases.",
        "comments": "MSC Class:          18F99; 14F99",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14127"
    },
    {
        "doc_id": 668,
        "title": "On the length of an arithmetic progression of the form ${3^x+2^y}$",
        "authors": [
            "Hongnan Chen",
            "Fenglin Huang",
            "Sihui Zhang"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "The conclusion that the length of an arithmetic progression of the form ${3^x+2^y}$ is at most six is proved.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14125"
    },
    {
        "doc_id": 669,
        "title": "Epimorphisms and Acyclic Types in Univalent Mathematics",
        "authors": [
            "Ulrik Buchholtz",
            "Tom de Jong",
            "Egbert Rijke"
        ],
        "subjects": [
            "Logic in Computer Science",
            "Algebraic Topology",
            "Category Theory"
        ],
        "abstract": "We characterize the epimorphisms in homotopy type theory (HoTT) as the fiberwise acyclic maps and develop a type-theoretic treatment of acyclic maps and types in the context of synthetic homotopy theory. We present examples and applications in group theory, such as the acyclicity of the Higman group, through the identification of groups with $0$-connected, pointed $1$-types. Many of our results are formalized as part of the agda-unimath library.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14106"
    },
    {
        "doc_id": 670,
        "title": "Inverse source problem for discrete Helmholtz equation",
        "authors": [
            "Roman Novikov",
            "Basant Lal Sharma"
        ],
        "subjects": [
            "Analysis of PDEs",
            "Mathematical Physics"
        ],
        "abstract": "We consider multi-frequency inverse source problem for the discrete Helmholtz operator on the square lattice $\\mathbb{Z}^d$, $d \\ge 1$. We consider this problem for the cases with and without phase information. We prove uniqueness results and present examples of non-uniqueness for this problem for the case of compactly supported source function. Relations with inverse scattering problem for the discrete Schr\u00f6dinger operators in the Born approximation are also provided.",
        "comments": "12 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14103"
    },
    {
        "doc_id": 671,
        "title": "Large time behavior of solutions to semilinear evolution inequalities in an annulus: the critical cases",
        "authors": [
            "Meiirkhan B. Borikhanov",
            "Berikbol T. Torebek"
        ],
        "subjects": [
            "Analysis of PDEs"
        ],
        "abstract": "In the present paper, we consider the parabolic and hyperbolic inequalities with a singular potentials and with a critical nonlinearities in the annulus domain. The problems are studied with Neumann-type and Dirichlet-type boundary conditions on the boundary. Moreover, we study the systems of problems too. We have proved that the above problems are globally unsolvable in critical cases, thereby filling the gaps the recent results by Jleli and Samet in [J. Math. Anal. Appl. 514: 2 (2022)] and in [Anal. Math. Phys. 12: 90 (2022)]. Proofs are carried out using the method of test functions with logarithmic arguments, which is being developed for the first time in bounded domains.",
        "comments": "22 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14102"
    },
    {
        "doc_id": 672,
        "title": "Randomized Complexity of Mean Computation and the Adaption Problem",
        "authors": [
            "Stefan Heinrich"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "Recently the adaption problem of Information-Based Complexity (IBC) for linear problems in the randomized setting was solved in Heinrich (J. Complexity 82, 2024, 101821). Several papers treating further aspects of this problem followed. However, all examples obtained so far were vector-valued. In this paper we settle the scalar-valued case. We study the complexity of mean computation in finite dimensional sequence spaces with mixed $L_p^N$ norms. We determine the $n$-th minimal errors in the randomized adaptive and non-adaptive setting. It turns out that among the problems considered there are examples where adaptive and non-adaptive $n$-th minimal errors deviate by a power of $n$. The gap can be (up to log factors) of the order $n^{1/4}$. We also show how to turn such results into infinite dimensional examples with suitable deviation for all $n$ simultaneously.",
        "comments": "35 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14100"
    },
    {
        "doc_id": 673,
        "title": "On a transformation of triple $q$-series and Rogers--Hecke type series",
        "authors": [
            "Zhi-Guo Liu"
        ],
        "subjects": [
            "Complex Variables",
            "Combinatorics",
            "Number Theory",
            "Quantum Algebra"
        ],
        "abstract": "Using the method of $q$-exponential differential operator we give an extension of the Sears $_4\u03c6_3$ transformation formula. Based on this extended formula and a $q$-series expansion formula for an analytic function around the origin, we present a transformation formula for triple $q$-series, which includes several interesting special cases, especially a double $q$-series summation formula. Some application of this transformation formula to Rogers--Hecke type series are discussed. More than 100 Rogers--Hecke type identities including Andrews's identities for the sums of three squares and the sums of three triangular numbers are obtained.",
        "comments": "41pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14099"
    },
    {
        "doc_id": 674,
        "title": "Prescribed mean curvature hypersurfaces in conformal product manifolds",
        "authors": [
            "Qiang Gao",
            "Hengyu Zhou"
        ],
        "subjects": [
            "Differential Geometry",
            "Analysis of PDEs"
        ],
        "abstract": "In this paper we give the existence of prescribed mean curvature (PMC) hypersurfaces in conformal product manifolds with (possibly empty) $C^{1,\u03b1}$ fixed graphical boundaries under a barrier condition. This generalizes Gerhardt's result in conformally flat spaces. It provides new examples of the Plateau problem of PMC hypersurfaces with clear topology under high dimensions. In addition, if a quasi-decreasing condition of PMC functions is satisfied, such PMC hypersurfaces are $C^1$ graphs.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14097"
    },
    {
        "doc_id": 675,
        "title": "The admissible KMS bundles on classifiable C$^*$-algebras",
        "authors": [
            "Robert Neagu"
        ],
        "subjects": [
            "Operator Algebras"
        ],
        "abstract": "Given any unital, finite, classifiable C$^*$-algebra $A$ with real rank zero and any compact simplex bundle with the fibre at zero being homeomorphic to the space of tracial states on $A$, we show that there exists a flow on $A$ realising this simplex. Moreover, we show that given any unital UCT Kirchberg algebra $A$ and any proper simplex bundle with empty fibre at zero, there exists a flow on $A$ realising this simplex.",
        "comments": "35 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14096"
    },
    {
        "doc_id": 676,
        "title": "ODC and ROC curves, comparison curves, and stochastic dominance",
        "authors": [
            "Teresa Ledwina",
            "Adam Zagda\u0144ski"
        ],
        "subjects": [
            "Methodology",
            "Statistics Theory"
        ],
        "abstract": "We discuss two novel approaches to the classical two-sample problem. Our starting point are properly standardized and combined, very popular in several areas of statistics and data analysis, ordinal dominance and receiver characteristic curves, denoted by ODC and ROC, respectively. The proposed new curves are termed the comparison curves. Their estimates, being weighted rank processes on (0,1), form the basis of inference. These weighted processes are intuitive, well-suited for visual inspection of data at hand, and are also useful for constructing some formal inferential procedures. They can be applied to several variants of two-sample problem. Their use can help to improve some existing procedures both in terms of power and the ability to identify the sources of departures from the postulated model. To simplify interpretation of finite sample results we restrict attention to values of the processes on a finite grid of points. This results in the so-called bar plots (B-plots) which readably summarize the information contained in the data. What is more, we show that B-plots along with adjusted simultaneous acceptance regions provide principled information about where the model departs from the data. This leads to a framework which facilitates identification of regions with locally significant differences.\n  We show an implementation of the considered techniques to a standard stochastic dominance testing problem. Some min-type statistics are introduced and investigated. A simulation study compares two tests pertinent to the comparison curves to well-established tests in the literature and demonstrates the strong and competitive performance of the former in many typical situations. Some real data applications illustrate simplicity and practical usefulness of the proposed approaches. A range of other applications of considered weighted processes is briefly discussed too.",
        "comments": "45 pages, 5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14094"
    },
    {
        "doc_id": 677,
        "title": "Generating Likely Counterfactuals Using Sum-Product Networks",
        "authors": [
            "Jiri Nemecek",
            "Tomas Pevny",
            "Jakub Marecek"
        ],
        "subjects": [
            "Artificial Intelligence",
            "Machine Learning",
            "Optimization and Control"
        ],
        "abstract": "Due to user demand and recent regulation (GDPR, AI Act), decisions made by AI systems need to be explained. These decisions are often explainable only post hoc, where counterfactual explanations are popular. The question of what constitutes the best counterfactual explanation must consider multiple aspects, where \"distance from the sample\" is the most common. We argue that this requirement frequently leads to explanations that are unlikely and, therefore, of limited value. Here, we present a system that provides high-likelihood explanations. We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using mixed-integer optimization (MIO). In the process, we propose an MIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate the likelihood of a counterfactual, which can be of independent interest. A numerical comparison against several methods for generating counterfactual explanations is provided.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14086"
    },
    {
        "doc_id": 678,
        "title": "Accelerating Fractional PINNs using Operational Matrices of Derivative",
        "authors": [
            "Tayebeh Taheri",
            "Alireza Afzal Aghaei",
            "Kourosh Parand"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis"
        ],
        "abstract": "This paper presents a novel operational matrix method to accelerate the training of fractional Physics-Informed Neural Networks (fPINNs). Our approach involves a non-uniform discretization of the fractional Caputo operator, facilitating swift computation of fractional derivatives within Caputo-type fractional differential problems with $0<\u03b1<1$. In this methodology, the operational matrix is precomputed, and during the training phase, automatic differentiation is replaced with a matrix-vector product. While our methodology is compatible with any network, we particularly highlight its successful implementation in PINNs, emphasizing the enhanced accuracy achieved when utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates Legendre polynomials into the PINN structure, providing a significant boost in accuracy. The effectiveness of our proposed method is validated across diverse differential equations, including Delay Differential Equations (DDEs) and Systems of Differential Algebraic Equations (DAEs). To demonstrate its versatility, we extend the application of the method to systems of differential equations, specifically addressing nonlinear Pantograph fractional-order DDEs/DAEs. The results are supported by a comprehensive analysis of numerical outcomes.",
        "comments": "19 pages, 11 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14081"
    },
    {
        "doc_id": 679,
        "title": "Minimal doubling for small subsets in compact Lie groups",
        "authors": [
            "Simon Machado"
        ],
        "subjects": [
            "Group Theory",
            "Combinatorics"
        ],
        "abstract": "We prove a sharp bound for the minimal doubling of a small measurable subset of a compact connected Lie group. Namely, let $G$ be a compact connected Lie group of dimension $d_G$, we show that for every $\u03b5> 0$ and for all measurable subsets $A$ of small enough Haar measure, we have\n  $$ \u03bc_G(A^2) > \\left(2^{d_G - d_H}-\u03b5\\right)\u03bc_G(A)$$\n  where $d_H$ is the maximal dimension of a proper closed subgroup $H$. This settles a conjecture of Breuillard and Green and recovers - with completely different methods - a recent result of Jing--Tran--Zhang corresponding to the case $G=SO_3(\\mathbb{R})$.\n  Going beyond the scope of this conjecture, our methods enable us to prove a stability result asserting that the only subsets close to saturating this inequality are essentially neighbourhoods of proper subgroups i.e. of the form\n  $$H_\u03b4:=\\{g \\in G: d(g,H)<\u03b4\\}$$\n  where $H$ denotes a maximal closed subgroup, $d$ denotes a bi-invariant distance on $G$ and $\u03b4>0$.\n  Our approach relies on two \\emph{a priori} unrelated toolsets: optimal transports and its recent applications to the Brunn--Minkowski inequality, and the structure theory of compact approximate subgroups.",
        "comments": "34 pages; comments welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14062"
    },
    {
        "doc_id": 680,
        "title": "On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications",
        "authors": [
            "Arnold Filtser"
        ],
        "subjects": [
            "Data Structures and Algorithms",
            "Computational Geometry",
            "Combinatorics"
        ],
        "abstract": "Given a metric space $(X,d_X)$, a $(\u03b2,s,\u0394)$-sparse cover is a collection of clusters $\\mathcal{C}\\subseteq P(X)$ with diameter at most $\u0394$, such that for every point $x\\in X$, the ball $B_X(x,\\frac\u0394\u03b2)$ is fully contained in some cluster $C\\in \\mathcal{C}$, and $x$ belongs to at most $s$ clusters in $\\mathcal{C}$. Our main contribution is to show that the shortest path metric of every $K_r$-minor free graphs admits $(O(r),O(r^2),\u0394)$-sparse cover, and for every $\u03b5>0$, $(4+\u03b5,O(\\frac1\u03b5)^r,\u0394)$-sparse cover (for arbitrary $\u0394>0$). We then use this sparse cover to show that every $K_r$-minor free graph embeds into $\\ell_\\infty^{\\tilde{O}(\\frac1\u03b5)^{r+1}\\cdot\\log n}$ with distortion $3+\\eps$ (resp. into $\\ell_\\infty^{\\tilde{O}(r^2)\\cdot\\log n}$ with distortion $O(r)$). Further, we provide applications of these sparse covers into padded decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy at bulk, name independent routing, and path reporting distance oracles.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14060"
    },
    {
        "doc_id": 681,
        "title": "Functors induced by comma categories",
        "authors": [
            "Suddhasattwa Das"
        ],
        "subjects": [
            "Category Theory"
        ],
        "abstract": "The purpose of category theory is to provide a collective description of many arrangements in mathematics, such as topological space, Banach spaces and game theory. Within this collective description, the perspective from any individual member of the collection is provided by its associated left or right slice. The assignment of slices to objects extends to a functor from the base category, into the category of categories. We extend this observation to a more general situation of two categories $\\mathcal{A}$ and $\\mathcal{B}$ mapping into a third category $\\mathcal{C}$, via functors $F,G$. Such arrangements abound in mathematics, and are studied via the comma category $\\left[ F; G\\right]$. Objects in this category are morphisms between objects of $\\mathcal{A}$ and $\\mathcal{B}$, via the functors $F,G$. We show that these objects also have a natural interpretation as functors between slice categories of $\\mathcal{A}$ and $\\mathcal{B}$. Thus even though $\\mathcal{A}$ and $\\mathcal{B}$ may have completely disparate structures, some functors between their slices can be interpreted as morphisms in $\\mathcal{C}$.",
        "comments": "MSC Class:          18A05; 18A40; 18A35; 18A25",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14059"
    },
    {
        "doc_id": 682,
        "title": "A Wells-like exact sequence for abelian extensions of relative Rota--Baxter groups",
        "authors": [
            "Pragya Belwal",
            "Nishant Rathee"
        ],
        "subjects": [
            "Group Theory",
            "Quantum Algebra",
            "Rings and Algebras"
        ],
        "abstract": "Relative Rota--Baxter groups, a generalization of Rota--Baxter groups, are closely connected to skew left braces, which play a fundamental role in understanding non-degenerate set-theoretical solutions to the Yang-Baxter equation. In this paper, we explore the inducibility problem for automorphisms of abelian extensions of relative Rota--Baxter groups. This problem is intricately linked to the recently introduced second cohomology of relative Rota--Baxter groups. Specifically, we prove a Wells-like exact sequence for abelian extensions of relative Rota--Baxter groups. The sequence establishes a connection among the group of derivations, certain automorphism group, and the second cohomology of relative Rota--Baxter groups, thereby giving precise structural relationships between these groups.",
        "comments": "22 pages. arXiv admin note: text overlap with arXiv:2309.00692, arXiv:2311.12384",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14058"
    },
    {
        "doc_id": 683,
        "title": "Multi-machine preventative maintenance scheduling with imperfect interventions: a restless bandit approach",
        "authors": [
            "Diego Ruiz-Hernandez",
            "Jes\u00fas Mar\u00eda Pinar-P\u00e9rez",
            "David Delgado-G\u00f3mez"
        ],
        "subjects": [
            "Discrete Mathematics",
            "Numerical Analysis"
        ],
        "abstract": "In this paper we address the problem of allocating the efforts of a collection of repairmen to a number of deteriorating machines in order to reduce operation costs and to mitigate the cost (and likelihood) of unexpected failures. Notwithstanding these preventive maintenance interventions are aimed at returning the machine to a so-called as-good-as-new state, unforeseeable factors may imply that maintenance interventions are not perfect and the machine is only returned to an earlier (uncertain) state of wear. The problem is modelled as a restless bandit problem and an index policy for the sequential allocation of maintenance tasks is proposed. A series of numerical experiments shows the strong performance of the proposed policy. Moreover, the methodology is of interest in the general context of dynamic resource allocation and restless bandit problems, as well as being useful in the particular imperfect maintenance model described.",
        "comments": "Published in Computers and Operations Research (ELSEVIER), July 2020. DOI: https://doi.org/10.1016/j.cor.2020.104927 Article available under the terms of the CC-BY-NC-ND licence",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14055"
    },
    {
        "doc_id": 684,
        "title": "Small cover approach to the suprema of positive canonical processes",
        "authors": [
            "Witold Bednorz",
            "Rafa\u0142 Martynek",
            "Rafa\u0142 Meller"
        ],
        "subjects": [
            "Probability"
        ],
        "abstract": "We extend the recent result of Park and Pham concerning the positive selector process to canonical processes generated by i.i.d. nonnegative random variables satisfying minimal tail assumptions. We also provide a result of the same nature for canonical processes based on general i.i.d. positive variables.",
        "comments": "MSC Class:          60G15; 60G17",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14045"
    },
    {
        "doc_id": 685,
        "title": "P-measures in models without P-points",
        "authors": [
            "Piotr Borodulin-Nadzieja",
            "Jonathan Cancino-Manr\u00edquez",
            "Adam Morawski"
        ],
        "subjects": [
            "Logic"
        ],
        "abstract": "We answer in negative the problem if the existence of a P-measure implies the existence of a P-point. Namely, we show that if we add random reals to a certain unique P-point model, then in the resulting model we will have a P-measure but not P-points. Also, we investigate the question if there is a P-measure in the Silver model. We show that rapid filters cannot be extended to a P-measure in the extension by $\u03c9$ product of Silver forcings and that in the model obtained by the product of $\u03c9_2$ many Silver forcings there are no P-measures of countable Maharam type",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14042"
    },
    {
        "doc_id": 686,
        "title": "Fredholm determinants, continued fractions, Jost and Evans functions for a Jacobi matrix associated with the 2D-Euler equations",
        "authors": [
            "Yuri Latushkin",
            "Shibi Vasudevan"
        ],
        "subjects": [
            "Spectral Theory",
            "Mathematical Physics",
            "Analysis of PDEs",
            "Fluid Dynamics"
        ],
        "abstract": "For a second order difference equation that arises in the study of stability of unidirectional (generalized Kolmogorov) flows for the Euler equations of ideal fluids on the two dimensional torus, we relate the following five functions of the spectral parameter: the Fredholm determinants of the Birman-Schwinger operator pencils associated with the second order equation and the equivalent system of the first order equations; the Jost function constructed by means of the Jost solutions of the second order equation; the Evans function constructed by means of the matrix valued Jost solutions of the first order system, and, finally, to backward and forward continued fractions associated with the second order difference equation. We prove that all five functions are equal, and that their zeros are the discrete eigenvalues of the second order difference equation. We use this to improve an instability result for a generalization of the Kolmogorov (unidirectional) flow for the Euler equation on the 2D torus.",
        "comments": "Results in this paper improve and extend the results of arXiv:1901.01367v3 on the instability of unidirectional flows",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14037"
    },
    {
        "doc_id": 687,
        "title": "Towards a Systems Theory of Algorithms",
        "authors": [
            "Florian D\u00f6rfler",
            "Zhiyu He",
            "Giuseppe Belgioioso",
            "Saverio Bolognani",
            "John Lygeros",
            "Michael Muehlebach"
        ],
        "subjects": [
            "Optimization and Control",
            "Machine Learning",
            "Systems and Control"
        ],
        "abstract": "Traditionally, numerical algorithms are seen as isolated pieces of code confined to an {\\em in silico} existence. However, this perspective is not appropriate for many modern computational approaches in control, learning, or optimization, wherein {\\em in vivo} algorithms interact with their environment. Examples of such {\\em open} include various real-time optimization-based control strategies, reinforcement learning, decision-making architectures, online optimization, and many more. Further, even {\\em closed} algorithms in learning or optimization are increasingly abstracted in block diagrams with interacting dynamic modules and pipelines. In this opinion paper, we state our vision on a to-be-cultivated {\\em systems theory of algorithms} and argue in favour of viewing algorithms as open dynamical systems interacting with other algorithms, physical systems, humans, or databases. Remarkably, the manifold tools developed under the umbrella of systems theory also provide valuable insights into this burgeoning paradigm shift and its accompanying challenges in the algorithmic world. We survey various instances where the principles of algorithmic systems theory are being developed and outline pertinent modeling, analysis, and design challenges.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14029"
    },
    {
        "doc_id": 688,
        "title": "Comparison of modularity-based approaches for nodes clustering in binary hypergraphs",
        "authors": [
            "Veronica Poda",
            "Catherine Matias"
        ],
        "subjects": [
            "Social and Information Networks",
            "Combinatorics",
            "Data Analysis, Statistics and Probability",
            "Applications"
        ],
        "abstract": "We conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14028"
    },
    {
        "doc_id": 689,
        "title": "On $p$-adic Minkowski's Theorems",
        "authors": [
            "Yingpu Deng"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "Dual lattice is an important concept of Euclidean lattices. In this paper, we first give the right definition of the concept of the dual lattice of a $p$-adic lattice from the duality theory of locally compact abelian groups. The concrete constructions of ``basic characters'' of local fields given in Weil's famous book ``Basic Number Theory'' help us to do so. We then prove some important properties of the dual lattice of a $p$-adic lattice, which can be viewed as $p$-adic analogues of the famous Minkowski's first, second theorems for Euclidean lattices. We do this simultaneously for local fields $\\mathbb{Q}_p$ (the field of $p$-adic numbers) and $\\mathbb{F}_p((T))$ (the field of formal power-series of one indeterminate with coefficients in the finite field with $p$ elements).",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14023"
    },
    {
        "doc_id": 690,
        "title": "Orbit problems for free-abelian times free groups and related families",
        "authors": [
            "Andr\u00e9 Carvalho",
            "Jordi Delgado"
        ],
        "subjects": [
            "Group Theory"
        ],
        "abstract": "We prove that the Brinkmann Problems (BrP & BrCP) and the twisted-conjugacy Problem (TCP) are decidable for any endomorphism of a free-abelian times free (FATF) group Fn x Z^m. Furthermore, we prove the decidability of the two-sided Brinkmann conjugacy problem (2BrCP) for monomorphisms of FATF groups (and combine it with TCP) to derive the decidability of the conjugacy problem for ascending HNN extensions of FATF groups.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14020"
    },
    {
        "doc_id": 691,
        "title": "Low-rank matrices, tournaments, and symmetric designs",
        "authors": [
            "Niranjan Balachandran",
            "Brahadeesh Sankarnarayanan"
        ],
        "subjects": [
            "Combinatorics"
        ],
        "abstract": "Let $\\mathbf{a} = (a_{i})_{i \\geq 1}$ be a sequence in a field $\\mathbb{F}$, and $f \\colon \\mathbb{F} \\times \\mathbb{F} \\to \\mathbb{F}$ be a function such that $f(a_{i},a_{i}) \\neq 0$ for all $i \\geq 1$. For any tournament $T$ over $[n]$, consider the $n \\times n$ symmetric matrix $M_{T}$ with zero diagonal whose $(i,j)$th entry (for$(i < j$) is $f(a_{i},a_{j})$ if $i \\to j$ in $T$, and $f(a_{j},a_{i})$ if $j \\to i$ in $T$. It is known (cf. Balachandran et al, Linear Algebra Appl. 658 (2023), 310-318) that if $T$ is a uniformly random tournament over $[n]$, then $\\operatorname{rank}(M_{T}) \\geq (\\frac{1}{2}-o(1))n$ with high probability when $\\operatorname{char}(\\mathbb{F}) \\neq 2$ and $f$ is a linear function.\n  In this paper, we investigate the other extremal question: how low can the ranks of such matrices be? We work with sequences $\\mathbf{a}$ that take only two distinct values, so the rank of any such $n \\times n$ matrix is at least $n/2$. First, we show that the rank of any such matrix depends on whether an associated bipartite graph has certain eigenvalues of high multiplicity. Using this, we show that if $f$ is linear, then there are real matrices $M_{T}(f;\\mathbf{a})$ of rank at most $\\frac{n}{2} + O(1)$. For rational matrices, we show that for each $\\varepsilon > 0$ we can find a sequence $\\mathbf{a}(\\varepsilon)$ for which there are matrices $M_{T}(f;\\mathbf{a})$ of rank at most $(\\frac{1}{2} + \\varepsilon)n + O(1)$. These matrices are constructed from symmetric designs, and we also use them to produce bisection-closed families of size greater than $\\lfloor 3n/2 \\rfloor - 2$ for $n \\leq 15$, which improves the previously best known bound (cf. Balachandran et al, Electron J. Combin. 26 (2019), #P2.40).",
        "comments": "11 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14015"
    },
    {
        "doc_id": 692,
        "title": "Measuring multidimensional inequality: a new proposal based on the Fourier transform",
        "authors": [
            "Paolo Giudici",
            "Emanuela Raffinetti",
            "Giuseppe Toscani"
        ],
        "subjects": [
            "Physics and Society",
            "Information Theory",
            "Probability"
        ],
        "abstract": "Inequality measures are quantitative measures that take values in the unit interval, with a zero value characterizing perfect equality. Although originally proposed to measure economic inequalities, they can be applied to several other situations, in which one is interested in the mutual variability between a set of observations, rather than in their deviations from the mean. While unidimensional measures of inequality, such as the Gini index, are widely known and employed, multidimensional measures, such as Lorenz Zonoids, are difficult to interpret and computationally expensive and, for these reasons, are not much well known. To overcome the problem, in this paper we propose a new scaling invariant multidimensional inequality index, based on the Fourier transform, which exhibits a number of interesting properties, and whose application to the multidimensional case is rather straightforward to calculate and interpret.",
        "comments": "arXiv admin note: text overlap with arXiv:2310.20483",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14012"
    },
    {
        "doc_id": 693,
        "title": "Lifting multiplicative lattices to ideal sytems",
        "authors": [
            "Tiberiu Dumitrescu",
            "Mihai Epure",
            "Alexandru Gica"
        ],
        "subjects": [
            "Commutative Algebra"
        ],
        "abstract": "We present a mechanism which lifts a multiplicative lattice to a (weak) ideal system on some monoid.",
        "comments": "6 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14001"
    },
    {
        "doc_id": 694,
        "title": "Optimal Degenerations of K-unstable Fano threefolds",
        "authors": [
            "Minghao Miao",
            "Linsheng Wang"
        ],
        "subjects": [
            "Algebraic Geometry",
            "Differential Geometry"
        ],
        "abstract": "We explicitly determine the optimal degenerations of Fano threefolds $X$ in family No 2.23 of Mori-Mukai's list as predicted by the Hamilton-Tian conjecture. More precisely, we find a special degeneration $(\\mathcal{X}, \u03be_0)$ of $X$ such that $(\\mathcal{X}_0, \u03be_0)$ is weighted K-polystable, which is equivalent to $(\\mathcal{X}_0, \u03be_0)$ admitting a K\u00e4hler-Ricci soliton (KRS) by \\cite{HL23} and \\cite{BLXZ23}. Furthermore, we study the moduli spaces of $(\\mathcal{X}_0, \u03be_0)$. The $\\mathbf{H}$-invariant of $X$ divides the natural parameter space into two strata, which leads to different moduli spaces of KRS Fano varieties. We show that one of them is isomorphic to the GIT-moduli space of biconic curves $C\\subseteq \\mathbb{P}^1\\times \\mathbb{P}^1$, and the other one is a single point.",
        "comments": "28 pages, comments are very welcome!",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13999"
    },
    {
        "doc_id": 695,
        "title": "A Combinatorial Formula for the Wedderburn Decomposition of Rational Group Algebras of Split Metacyclic $p$-groups",
        "authors": [
            "Ram Karan Choudhary",
            "Sunil Kumar Prajapati"
        ],
        "subjects": [
            "Representation Theory",
            "Rings and Algebras"
        ],
        "abstract": "In this article, we present a concise combinatorial formula for efficiently determining the Wedderburn decomposition of rational group algebra associated with a split metacyclic $p$-group $G$, where $p$ is an odd prime. We also provide a combinatorial formula to count irreducible rational representations of $G$ of distinct degrees.",
        "comments": "arXiv admin note: text overlap with arXiv:2106.12781 by other authors",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13994"
    },
    {
        "doc_id": 696,
        "title": "Inclusions of simple C$^*$-algebras arising from compact group actions",
        "authors": [
            "Miho Mukohara"
        ],
        "subjects": [
            "Operator Algebras"
        ],
        "abstract": "Inclusions of operator algebras have long been studied. In particular, inclusions arising from actions of compact groups on factors were studied by Izumi-Longo-Popa and others. The correspondence between intermediate subfactors and subgroups is called the Galois correspondence. Analogues for actions on C$^*$-algebras have been studied by Izumi, Cameron-Smith, Peligrad, and others. In this article, we give examples of compact group actions on simple C$^*$-algebras for which the Galois correspondence holds.",
        "comments": "20 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13989"
    },
    {
        "doc_id": 697,
        "title": "Homogeneity of magnetic trajectories in the real special linear group",
        "authors": [
            "Jun-ichi Inoguchi",
            "Marian-Ioan Munteanu"
        ],
        "subjects": [
            "Differential Geometry"
        ],
        "abstract": "We prove the homogeneity of contact magnetic curves in the real special linear group of degree $2$. Every contact magnetic trajectory is a product of a homogeneous geodesic and a charged Reeb flow.",
        "comments": "14 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13988"
    },
    {
        "doc_id": 698,
        "title": "A new analysis of empirical interpolation methods and Chebyshev greedy algorithms",
        "authors": [
            "Yuwen Li"
        ],
        "subjects": [
            "Numerical Analysis"
        ],
        "abstract": "We present new convergence estimates of generalized empirical interpolation methods in terms of the entropy numbers of the parametrized function class. Our analysis is transparent and leads to sharper convergence rates than the classical analysis via the Kolmogorov n-width. In addition, we also derive novel entropy-based convergence estimates of the Chebyshev greedy algorithm for sparse n-term nonlinear approximation of a target function. This also improves classical convergence analysis when corresponding entropy numbers decay fast enough.",
        "comments": "MSC Class:          41A46; 41A65; 65J05; 65M12",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13985"
    },
    {
        "doc_id": 699,
        "title": "Squarefree numbers in short intervals",
        "authors": [
            "Mayank Pandey"
        ],
        "subjects": [
            "Number Theory"
        ],
        "abstract": "We show that there exists $\u03b7> 0$ such that the interval $[X, X + X^{\\frac 15 - \u03b7}]$ contains a squarefree number for all large $X$. This improves on an earlier result of Filaseta and Trifonov who showed that there is a squarefree number in $[X, X + cX^{\\frac 15}\\log X]$ for some $c > 0$ and all large $X$.\n  We introduce a new technique to count lattice points near curves, which we use to bound in critical ranges the number of integers in a short interval divisible by a large square. This uses as an input Green and Tao's quantitative version of Leibman's theorem on the equidistribution of polynomial orbits in nilmanifolds.",
        "comments": "23 pages",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13981"
    },
    {
        "doc_id": 700,
        "title": "Health Digital Twins Supported by Artificial Intelligence-based Algorithms and Extended Reality in Cardiology",
        "authors": [
            "Zofia Rudnicka",
            "Klaudia Proniewska",
            "Mark Perkins",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, significant efforts have been made to create Health Digital Twins (HDTs), digital twins for clinical applications. Heart modeling is one of the fastest-growing fields, which favors the effective application of HDTs. The clinical application of HDTs will be increasingly widespread in the future of healthcare services and has a huge potential to form part of the mainstream in medicine. However, it requires the development of both models and algorithms for the analysis of medical data, and advances in Artificial Intelligence (AI) based algorithms have already revolutionized image segmentation processes. Precise segmentation of lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapy. In this paper, a brief overview of recent achievements in HDT technologies in the field of cardiology, including interventional cardiology was conducted. HDTs were studied taking into account the application of Extended Reality (XR) and AI, as well as data security, technical risks, and ethics-related issues. Special emphasis was put on automatic segmentation issues. It appears that improvements in data processing will focus on automatic segmentation of medical imaging in addition to three-dimensional (3D) pictures to reconstruct the anatomy of the heart and torso that can be displayed in XR-based devices. This will contribute to the development of effective heart diagnostics. The combination of AI, XR, and an HDT-based solution will help to avoid technical errors and serve as a universal methodology in the development of personalized cardiology. Additionally, we describe potential applications, limitations, and further research directions.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14208"
    },
    {
        "doc_id": 701,
        "title": "Validation of Golden Gate assemblies using highly multiplexed Nanopore amplicon sequencing",
        "authors": [
            "Adan A. Ramirez Rojas",
            "Cedric K. Brinkmann",
            "Daniel Schindler"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Golden Gate cloning has revolutionized synthetic biology. Its concept of modular, highly characterized libraries of parts that can be combined into higher order assemblies allows engineering principles to be applied to biological systems. The basic parts, typically stored in level 0 plasmids, are sequence validated by the method of choice and can be combined into higher order assemblies on demand. Higher order assemblies are typically transcriptional units, and multiple transcriptional units can be assembled into multi-gene constructs. Higher order Golden Gate assembly based on defined and validated parts usually does not introduce sequence changes. Therefore, simple validation of the assemblies, e.g. by colony PCR or restriction digest pattern analysis, is sufficient. However, in many experimental setups, researchers do not use defined parts, but rather part libraries, resulting in assemblies of high combinatorial complexity where sequencing again becomes mandatory. Here we present a detailed protocol for the use of a highly multiplexed dual barcode amplicon sequencing using the Nanopore sequencing platform for in-house sequence validation. The workflow, called DuBA.flow, is a start-to-finish procedure that provides all necessary steps from a single colony to the final easy-to-interpret sequencing report.",
        "comments": "25 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14191"
    },
    {
        "doc_id": 702,
        "title": "Dual-trigger release of berberine chloride from the Gelatin/Perfluorohexane core-shell structure",
        "authors": [
            "Mahshid Givarian",
            "Fathollah Moztarzadeh",
            "Maryam Ghaffari",
            "AmirHossein Bahmanpour",
            "Maryam Mollazadeh-Bajestani",
            "Manijhe Mokhtari-Dizaji",
            "Fatemeh Mehradnia"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "The development of smart nanocarriers that enable controlled drug release in response to internal and external triggers is an emerging approach for targeted therapy. This study focused on designing pH-sensitive, ultrasound-responsive gelatin/perfluorohexane (PFH) nanodroplets loaded with berberine chloride as a model drug. The nanodroplets were prepared using an emulsion technique and optimized by varying process parameters like homogenization rate, polymer concentration, surfactant, drug, and perfluorocarbon content. The optimal formulation yielded nanodroplets with a particle size of 281.7 nm, a drug encapsulation efficiency of 66.8, and a passive drug release of 15.4 within 24 hours. Characterization confirmed successful encapsulation and pH-responsive behavior. Ultrasound stimulation significantly enhanced drug release, with 150 kHz being more effective than 1 MHz in triggering acoustic droplet vaporization while minimizing heat generation. After 10 minutes of radiation, the optimal formulation showed 89.4% cumulative drug release. The nanodroplets displayed stability over one month at 4\u00b0C. Overall, the dual-triggered nanodroplets demonstrate excellent potential for controlled delivery and targeted release of berberine chloride.",
        "comments": "39 pages and 5 figures, to appear in Applied Biochemistry and Biotechnology journal",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14172"
    },
    {
        "doc_id": 703,
        "title": "Label-free detection of exosomes from different cellular sources based on surface-enhanced Raman spectroscopy combined with machine learning models",
        "authors": [
            "Yang Lia",
            "Xiaoming Lyu",
            "Kuo Zhan",
            "Haoyu Ji",
            "Lei Qin",
            "JianAn Huang"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Exosomes are significant facilitators of inter-cellular communication that can unveil cell-cell interactions, signaling pathways, regulatory mechanisms and disease diagnostics. Nonetheless, current analysis required large amount of data for exosome identification that it hampers efficient and timely mechanism study and diagnostics. Here, we used a machine-learning assisted Surface-enhanced Raman spectroscopy (SERS) method to detect exosomes derived from six distinct cell lines (HepG2, Hela, 143B, LO-2, BMSC, and H8) with small amount of data. By employing sodium borohydride-reduced silver nanoparticles and sodium borohydride solution as an aggregating agent, 100 SERS spectra of the each types of exosomes were collected and then subjected to multivariate and machine learning analysis. By integrating Principal Component Analysis with Support Vector Machine (PCA-SVM) models, our analysis achieved a high accuracy rate of 94.4% in predicting exosomes originating from various cellular sources. In comparison to other machine learning analysis, our method used small amount of SERS data to allow a simple and rapid exosome detection, which enables a timely subsequent study of cell-cell interactions, communication mechanisms, and disease mechanisms in life sciences.",
        "comments": "5 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14104"
    },
    {
        "doc_id": 704,
        "title": "Left/Right Brain, human motor control and the implications for robotics",
        "authors": [
            "Jarrad Rinaldo",
            "Levin Kuhlmann",
            "Jason Friedman",
            "Gideon Kowadlo"
        ],
        "subjects": [
            "Robotics",
            "Artificial Intelligence",
            "Machine Learning",
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "Neural Network movement controllers promise a variety of advantages over conventional control methods however they are not widely adopted due to their inability to produce reliably precise movements. This research explores a bilateral neural network architecture as a control system for motor tasks. We aimed to achieve hemispheric specialisation similar to what is observed in humans across different tasks; the dominant system (usually the right hand, left hemisphere) excels at tasks involving coordination and efficiency of movement, and the non-dominant system performs better at tasks requiring positional stability. Specialisation was achieved by training the hemispheres with different loss functions tailored toward the expected behaviour of the respective hemispheres. We compared bilateral models with and without specialised hemispheres, with and without inter-hemispheric connectivity (representing the biological Corpus Callosum), and unilateral models with and without specialisation. The models were trained and tested on two tasks common in the human motor control literature: the random reach task, suited to the dominant system, a model with better coordination, and the hold position task, suited to the non-dominant system, a model with more stable movement. Each system out-performed the non-favoured system in its preferred task. For both tasks, a bilateral model outperforms the 'non-preferred' hand, and is as good or better than the 'preferred' hand. The Corpus Callosum tends to improve performance, but not always for the specialised models.",
        "comments": "ACM Class:          I.2.6; I.2.9",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14057"
    },
    {
        "doc_id": 705,
        "title": "Radical Realism",
        "authors": [
            "Nicol\u00e1s Hinrichs",
            "Noah Guzm\u00e1n"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The ontogeny of cognitive neuroscience has emerged within the hegemony of substance ontology. Persistent physicalist influences are described through three developmental hallmarks that yielded epistemic attractors - promoters and perpetuators of material-discursive practices oriented toward reification and self-vindication across the interdisciplinary spectrum which, as a whole, has been driven away from its pretensions to scientific realism. In virtue of a desire for a radical return thereto, we adopt a metaphysic stance akin to pragmatism, and briefly make the case that such concerns have sociopolitical implications extending far beyond the realm of mere philosophical interest.",
        "comments": "19 pages, 3 figures",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14049"
    },
    {
        "doc_id": 706,
        "title": "DNA Sequence Classification with Compressors",
        "authors": [
            "\u015e\u00fckr\u00fc Ozan"
        ],
        "subjects": [
            "Genomics",
            "Machine Learning"
        ],
        "abstract": "Recent studies in DNA sequence classification have leveraged sophisticated machine learning techniques, achieving notable accuracy in categorizing complex genomic data. Among these, methods such as k-mer counting have proven effective in distinguishing sequences from varied species like chimpanzees, dogs, and humans, becoming a staple in contemporary genomic research. However, these approaches often demand extensive computational resources, posing a challenge in terms of scalability and efficiency. Addressing this issue, our study introduces a novel adaptation of Jiang et al.'s compressor-based, parameter-free classification method, specifically tailored for DNA sequence analysis. This innovative approach utilizes a variety of compression algorithms, such as Gzip, Brotli, and LZMA, to efficiently process and classify genomic sequences. Not only does this method align with the current state-of-the-art in terms of accuracy, but it also offers a more resource-efficient alternative to traditional machine learning methods. Our comprehensive evaluation demonstrates the proposed method's effectiveness in accurately classifying DNA sequences from multiple species. We present a detailed analysis of the performance of each algorithm used, highlighting the strengths and limitations of our approach in various genomic contexts. Furthermore, we discuss the broader implications of our findings for bioinformatics, particularly in genomic data processing and analysis. The results of our study pave the way for more efficient and scalable DNA sequence classification methods, offering significant potential for advancements in genomic research and applications.",
        "comments": " ",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.14025"
    },
    {
        "doc_id": 707,
        "title": "Temperature Compensation through Kinetic Regulation in Biochemical Oscillators",
        "authors": [
            "Haochen Fu",
            "Chenyi Fei",
            "Qi Ouyang",
            "Yuhai Tu"
        ],
        "subjects": [
            "Molecular Networks",
            "Biological Physics"
        ],
        "abstract": "Nearly all circadian clocks maintain a period that is insensitive to temperature changes, a phenomenon known as temperature compensation (TC). Yet, it is unclear whether there is any common feature among different systems that exhibit TC. From a general timescale invariance, we show that TC relies on existence of certain period-lengthening reactions wherein the period of the system increases strongly with the rates in these reactions. By studying several generic oscillator models, we show that this counter-intuitive dependence is nonetheless a common feature of oscillators in the nonlinear (far-from-onset) regime where the oscillation can be separated into fast and slow phases. The increase of the period with the period-lengthening reaction rates occurs when the amplitude of the slow phase in the oscillation increases with these rates while the progression-speed in the slow phase is controlled by other rates of the system. The positive dependence of the period on the period-lengthening rates balances its inverse dependence on other kinetic rates in the system, which gives rise to robust TC in a wide range of parameters. We demonstrate the existence of such period-lengthening reactions and their relevance for TC in all four model systems we considered. Theoretical results for a model of the Kai system are supported by experimental data. A study of the energy dissipation also shows that better TC performance requires higher energy consumption. Our study unveils a general mechanism by which a biochemical oscillator achieves TC by operating at regimes far from the onset where period-lengthening reactions exist.",
        "comments": "19 pages, 11 figures (main text + supplementary information)",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13960"
    },
    {
        "doc_id": 708,
        "title": "Towards 3D Molecule-Text Interpretation in Language Models",
        "authors": [
            "Sihang Li",
            "Zhiyuan Liu",
            "Yanchen Luo",
            "Xiang Wang",
            "Xiangnan He",
            "Kenji Kawaguchi",
            "Tat-Seng Chua",
            "Qi Tian"
        ],
        "subjects": [
            "Machine Learning",
            "Information Retrieval",
            "Biomolecules"
        ],
        "abstract": "Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder's representation space and the LM's input space. Moreover, to enhance 3D-MoLM's ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks, including molecule-text retrieval, molecule captioning, and more challenging open-text molecular QA tasks, especially focusing on 3D-dependent properties.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13923"
    },
    {
        "doc_id": 709,
        "title": "Inverse Molecular Design with Multi-Conditional Diffusion Guidance",
        "authors": [
            "Gang Liu",
            "Jiaxin Xu",
            "Tengfei Luo",
            "Meng Jiang"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We introduce multi-conditional diffusion guidance. The proposed Transformer-based denoising model has a condition encoder that learns the representations of numerical and categorical conditions. The denoising model, consisting of a structure encoder-decoder, is trained for denoising under the representation of conditions. The diffusion process becomes graph-dependent to accurately estimate graph-related noise in molecules, unlike the previous models that focus solely on the marginal distributions of atoms or bonds. We extensively validate our model for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution learning to condition control for molecular properties. An inverse polymer design task for gas separation with feedback from domain experts further demonstrates its practical utility.",
        "comments": "20 pages, 8 figures, 7 tables",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13858"
    },
    {
        "doc_id": 710,
        "title": "Engineering Yeast Cells to Facilitate Information Exchange",
        "authors": [
            "Nikolaos Ntetsikas",
            "Styliana Kyriakoudi",
            "Antonis Kirmizis",
            "Bige Deniz Unluturk",
            "Andreas Pitsillides",
            "Ian F. Akyildiz",
            "Marios Lestas"
        ],
        "subjects": [
            "Emerging Technologies",
            "Information Theory",
            "Molecular Networks"
        ],
        "abstract": "Although continuous advances in theoretical modelling of Molecular Communications (MC) are observed, there is still an insuperable gap between theory and experimental testbeds, especially at the microscale. In this paper, the development of the first testbed incorporating engineered yeast cells is reported. Different from the existing literature, eukaryotic yeast cells are considered for both the sender and the receiver, with \u03b1-factor molecules facilitating the information transfer. The use of such cells is motivated mainly by the well understood biological mechanism of yeast mating, together with their genetic amenability. In addition, recent advances in yeast biosensing establish yeast as a suitable detector and a neat interface to in-body sensor networks. The system under consideration is presented first, and the mathematical models of the underlying biological processes leading to an end-to-end (E2E) system are given. The experimental setup is then described and used to obtain experimental results which validate the developed mathematical models. Beyond that, the ability of the system to effectively generate output pulses in response to repeated stimuli is demonstrated, reporting one event per two hours. However, fast RNA fluctuations indicate cell responses in less than three minutes, demonstrating the potential for much higher rates in the future.",
        "comments": "18 pages, 9 figures (2 of which are not colored) all .png, recently accepted for publication at TMBMC",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13712"
    },
    {
        "doc_id": 711,
        "title": "Accelerating hyperbolic t-SNE",
        "authors": [
            "Martin Skrodzki",
            "Hunter van Geffen",
            "Nicolas F. Chaves-de-Plaza",
            "Thomas H\u00f6llt",
            "Elmar Eisemann",
            "Klaus Hildebrandt"
        ],
        "subjects": [
            "Human-Computer Interaction",
            "Artificial Intelligence",
            "Machine Learning",
            "Quantitative Methods",
            "Machine Learning"
        ],
        "abstract": "The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13708"
    },
    {
        "doc_id": 712,
        "title": "A generic model of consciousness",
        "authors": [
            "Mark J. Hadley"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "This is a model of consciousness. The hard problem of consciousness, what it feels like, is answered. The work builds on medical research analyzing the source and mechanisms associated with our feelings. It goes further by describing a generic model with wide applicability. The model is fully consistent with medical pathways in humans, but easily extends to animals and AI. The essence of the model is the interplay between associative memory and physiology. The model is a clear and concrete counterexample to the famous philosophical objections to a scientific explanation.",
        "comments": "Journal ref:        Journal of Artificial Intelligence and Consciousness 10 (2):291--308 (2023)",
        "date": "2 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13690"
    },
    {
        "doc_id": 713,
        "title": "Detecting local perturbations of networks in a latent hyperbolic space",
        "authors": [
            "Alice Longhena",
            "Martin Guillemaud",
            "Mario Chavez"
        ],
        "subjects": [
            "Quantitative Methods",
            "Data Analysis, Statistics and Probability"
        ],
        "abstract": "Graph theoretical approaches have been proven to be effective in the characterization of connected systems, as well as in quantifying their dysfunction due to perturbation. In this paper, we show the advantage of a non-Euclidean (hyperbolic) representation of networks to identify local connectivity perturbations and to characterize the induced effects on a large scale. We propose two perturbation scores based on representations of the networks in a latent geometric space, obtained through an embedding onto the hyperbolic Poincar\u00e9 disk. We numerically demonstrate that these methods are able to localize perturbations in networks with homogeneous or heterogeneous degree connectivity. We apply this framework to identify the most perturbed brain areas in epileptic patients following surgery. This study is conceived in the effort of developing more powerful tools to represent and analyze brain networks, and it is the first to apply geometric network embedding techniques to the case of epilepsy.",
        "comments": " ",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13495"
    },
    {
        "doc_id": 714,
        "title": "Unified neural field theory of brain dynamics underlying oscillations in Parkinson's disease and generalized epilepsies",
        "authors": [
            "Eli J M\u00fcller",
            "Sacha J van Albada",
            "Jong-Won Kim",
            "Peter A Robinson"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The mechanisms underlying pathologically synchronized neural oscillations in Parkinson's disease (PD) and generalized epilepsies are jointly explored via a neural field model of the corticothalamic-basal ganglia (CTBG) system. The basal ganglia (BG) are approximated as a single effective population and their roles in modulating oscillatory corticothalamic (CT) dynamics and vice versa are analyzed. Besides normal EEG rhythms, enhanced activity around 4 Hz and 20 Hz exists in the model, consistent with characteristic frequencies in PD. These rhythms result from resonances in loops between the BG and CT populations, analogous to those underlying epileptic oscillations in a previous CT model. Dopamine depletion is argued to weaken the dampening of these resonances in PD, and network connections explain the significant coherence between BG, thalamic, and cortical activity around 4-8 Hz and 20 Hz. Parallels between the afferent and efferent connection sites of the thalamic reticular nucleus (TRN) and BG predict low dopamine to correspond to a reduced likelihood of tonic-clonic (grand mal) seizures, agreeing with experimental findings. Further, the model predicts an increased likelihood of absence (petit mal) seizure resulting from low dopamine levels matching experimental findings. Suppression of absence seizure activity is shown when afferent and efferent BG connections to the CT system are strengthened, consistent with other CTBG modeling studies. The BG are demonstrated to suppress activity of the CTBG system near tonic-clonic seizure states, providing insight into the reported efficacy of current treatments in BG circuits. Sleep states of the TRN are also found to suppress pathological PD activity matching observations. Overall, the findings demonstrate strong parallels between coherent oscillations in generalized epilepsies and PD, and provide insights into possible comorbidities.",
        "comments": "Journal ref:        Journal of Theoretical Biology (2017) 428, 132-146",
        "date": "24 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13467"
    },
    {
        "doc_id": 715,
        "title": "TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification",
        "authors": [
            "Sathyanarayanan Aakur",
            "Vishalini R. Laguduva",
            "Priyadharsini Ramamurthy",
            "Akhilesh Ramachandran"
        ],
        "subjects": [
            "Genomics",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "A species' genetic code or genome encodes valuable evolutionary, biological, and phylogenetic information that aids in species recognition, taxonomic classification, and understanding genetic predispositions like drug resistance and virulence. However, the vast number of potential species poses significant challenges in developing a general-purpose whole genome classification tool. Traditional bioinformatics tools have made notable progress but lack scalability and are computationally expensive. Machine learning-based frameworks show promise but must address the issue of large classification vocabularies with long-tail distributions. In this study, we propose addressing this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a taxonomy-aware embedding space for reasoning and classification. This embedding space captures compositional and phylogenetic relationships of species, enabling predictions in extensive search spaces. We evaluate TEPI using two rigorous zero-shot settings and demonstrate its generalization capabilities qualitatively on curated, large-scale, publicly sourced data.",
        "comments": "Accepted to IEEE JBHI",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13219"
    },
    {
        "doc_id": 716,
        "title": "Single NV in nanodiamond for quantum sensing of protein dynamics in an ABEL trap",
        "authors": [
            "Ivan Perez",
            "Anke Krueger",
            "Joerg Wrachtrup",
            "Fedor Jelezko",
            "Michael B\u00f6rsch"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Enzymes are cellular protein machines using a variety of conformational changes to power fast biochemical catalysis. Our goal is to exploit the single-spin properties of the luminescent NV (nitrogen-vacancy) center in nanodiamonds to reveal the dynamics of an active enzyme complex at physiological conditions with the highest spatio-temporal resolution. Specifically attached to the membrane enzyme FoF1-ATP synthase, the NV sensor will report the adenosine triphosphate (ATP)-driven full rotation of Fo motor subunits in ten consecutive 36\u00b0 steps. Conformational dynamics are monitored using either a double electron-electron resonance scheme or NV- magnetometry with optical readout or using NV- relaxometry with a superparamagnetic nanoparticle as the second marker attached to the same enzyme. First, we show how all photophysical parameters like individual size, charge, brightness, spectral range of fluorescence and fluorescence lifetime can be determined for the NV- center in a single nanodiamond held in aqueous solution by a confocal anti-Brownian electrokinetic trap (ABEL trap). Stable photon count rates of individual nanodiamonds and the absence of blinking allow for observation times of single nanodiamonds in solution exceeding hundreds of seconds. For the proposed quantum sensing of nanometer-sized distance changes within an active enzyme, we show that local magnetic field fluctuations can be detected all-optically by analyzing fluorescence lifetime changes of the NV- center in each nanodiamond in solution.",
        "comments": "14 pages, 5 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13180"
    },
    {
        "doc_id": 717,
        "title": "Enabling Global Image Data Sharing in the Life Sciences",
        "authors": [
            "Peter Bajcsy",
            "Sreenivas Bhattiprolu",
            "Katy Borner",
            "Beth Cimini",
            "Lucy Collinson",
            "Jan Ellenberg",
            "Reto Fiolka",
            "Maryellen Giger",
            "Wojtek Goscinski",
            "Matthew Hartley",
            "Nathan Hotaling",
            "Rick Horwitz",
            "Florian Jug",
            "Anna Kreshuk",
            "Emma Lundberg",
            "Aastha Mathur",
            "Kedar Narayan",
            "Shuichi Onami",
            "Anne L. Plant",
            "Fred Prior",
            "Jason Swedlow",
            "Adam Taylor",
            "Antje Keppler"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Coordinated collaboration is essential to realize the added value of and infrastructure requirements for global image data sharing in the life sciences. In this White Paper, we take a first step at presenting some of the most common use cases as well as critical/emerging use cases of (including the use of artificial intelligence for) biological and medical image data, which would benefit tremendously from better frameworks for sharing (including technical, resourcing, legal, and ethical aspects). In the second half of this paper, we paint an ideal world scenario for how global image data sharing could work and benefit all life sciences and beyond. As this is still a long way off, we conclude by suggesting several concrete measures directed toward our institutions, existing imaging communities and data initiatives, and national funders, as well as publishers. Our vision is that within the next ten years, most researchers in the world will be able to make their datasets openly available and use quality image data of interest to them for their research and benefit. This paper is published in parallel with a companion White Paper entitled Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data, which addresses challenges and opportunities related to producing well-documented and high-quality image data that is ready to be shared. The driving goal is to address remaining challenges and democratize access to everyday practices and tools for a spectrum of biomedical researchers, regardless of their expertise, access to resources, and geographical location.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13023"
    },
    {
        "doc_id": 718,
        "title": "Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data",
        "authors": [
            "Nikki Bialy",
            "Frank Alber",
            "Brenda Andrews",
            "Michael Angelo",
            "Brian Beliveau",
            "Lacramioara Bintu",
            "Alistair Boettiger",
            "Ulrike Boehm",
            "Claire M. Brown",
            "Mahmoud Bukar Maina",
            "James J. Chambers",
            "Beth Cimini",
            "Kevin Eliceiri",
            "Rachel Errington",
            "Orestis Faklaris",
            "Nathalie Gaudreault",
            "Ronald N. Germain",
            "Wojtek Goscinski",
            "David Grunwald",
            "Michael Halter",
            "Dorit Hanein",
            "John W. Hickey",
            "Judith Lacoste",
            "Alex Laude",
            "Emma Lundberg",
            "et al. (22 additional authors not shown)"
        ],
        "subjects": [
            "Other Quantitative Biology"
        ],
        "abstract": "Together with the molecular knowledge of genes and proteins, biological images promise to significantly enhance the scientific understanding of complex cellular systems and to advance predictive and personalized therapeutic products for human health. For this potential to be realized, quality-assured image data must be shared among labs at a global scale to be compared, pooled, and reanalyzed, thus unleashing untold potential beyond the original purpose for which the data was generated. There are two broad sets of requirements to enable image data sharing in the life sciences. One set of requirements is articulated in the companion White Paper entitled Enabling Global Image Data Sharing in the Life Sciences, which is published in parallel and addresses the need to build the cyberinfrastructure for sharing the digital array data. In this White Paper, we detail a broad set of requirements, which involves collecting, managing, presenting, and propagating contextual information essential to assess the quality, understand the content, interpret the scientific implications, and reuse image data in the context of the experimental details. We start by providing an overview of the main lessons learned to date through international community activities, which have recently made considerable progress toward generating community standard practices for imaging Quality Control (QC) and metadata. We then provide a clear set of recommendations for amplifying this work. The driving goal is to address remaining challenges and democratize access to everyday practices and tools for a spectrum of biomedical researchers, regardless of their expertise, access to resources, and geographical location.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13022"
    },
    {
        "doc_id": 719,
        "title": "How norms shape the evolution of prosocial behavior. Compassion, Universalizability, Reciprocity, Equity: A C.U.R.E for social dilemmas",
        "authors": [
            "Brian Mintz",
            "Feng Fu"
        ],
        "subjects": [
            "Physics and Society",
            "Populations and Evolution"
        ],
        "abstract": "How cooperation evolves and particularly maintains at a large scale remains an open problem for improving humanity across domains ranging from climate change to pandemic response. To shed light on how behavioral norms can resolve the social dilemma of cooperation, here we present a formal mathematical model of individuals' decision making under general social norms, encompassing a variety of concerns and motivations an individual may have beyond simply maximizing their own payoffs. Using the canonical game of the Prisoner's Dilemma, we compare four different norms: compassion, universalizability, reciprocity, and equity, to determine which social forces can facilitate the evolution of cooperation, if any. We analyze our model through a variety of limiting cases, including weak selection, low mutation, and large population sizes. This is complemented by computer simulations of population dynamics via a Fisher process, which confirm our theoretical results. We find that the first two norms lead to the emergence of cooperation in a wide range of games, but the latter two do not on their own. Due to its generality, our framework can be used to investigate many more norms, as well as how norms themselves emerge and evolve. Our work complements recent work on fair-minded learning dynamics and provides a useful bottom-up perspective into understanding the impact of top-down social norms on collective cooperative intelligence.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13015"
    },
    {
        "doc_id": 720,
        "title": "Ready for climate change? The importance of adaptive thermoregulatory flexibility for the Malagasy bat species Triaenops menamena",
        "authors": [
            "Sina Remmers"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "The balance between energy intake and expenditure is essential and crucial for survival for all organisms. The energy management is closely linked to the ecology. Thus, changes in environmental conditions can be challenging, especially for the animals physiology. Different strategies of thermoregulation have evolved and heterothermy seems to be the most efficient way for saving energy. Daily torpor, a temporally controlled reduction of the metabolic rate and body temperature, is one form of heterothermy and recent studies revealed that this physiological strategy is used by many tropical and subtropical species. Yet, little is known about torpor in bats and their intraspecific thermoregulatory flexibility. Therefore, three populations of the Malagasy bat species Triaenops menamena were investigated, to examine their metabolic rate, skin temperature and related energy expenditure during normothermic and torpid states in context of different microclimatic conditions. This study exposed significant physiological differences among these three populations along a gradient of fluctuation in environmental conditions. The greater the fluctuations in ambient temperature and humidity, the higher was the general resting metabolic rate and the rate of its reduction, but the lower was the torpid metabolic rate. This species shows a highly adaptive flexibility in their physiology and are able to cope with unfavorable environmental conditions by using different strategies of thermoregulation and hypometabolism, which is beneficial regarding ongoing climatic changes.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.13012"
    },
    {
        "doc_id": 721,
        "title": "SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI",
        "authors": [
            "Hanxue Gu",
            "Roy Colglazier",
            "Haoyu Dong",
            "Jikai Zhang",
            "Yaqian Chen",
            "Zafer Yildiz",
            "Yuwen Chen",
            "Lin Li",
            "Jichen Yang",
            "Jay Willhite",
            "Alex M. Meyer",
            "Brian Guo",
            "Yashvi Atul Shah",
            "Emily Luo",
            "Shipra Rajput",
            "Sally Kuehn",
            "Clark Bulleit",
            "Kevin A. Wu",
            "Jisoo Lee",
            "Brandon Ramirez",
            "Darui Lu",
            "Jay M. Levin",
            "Maciej A. Mazurowski"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Quantitative Methods"
        ],
        "abstract": "Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering non-invasive and high-quality insights into the human body. Precise segmentation of MRIs into different organs and tissues would be highly beneficial since it would allow for a higher level of understanding of the image content and enable important measurements, which are essential for accurate diagnosis and effective treatment planning. Specifically, segmenting bones in MRI would allow for more quantitative assessments of musculoskeletal conditions, while such assessments are largely absent in current radiological practice. The difficulty of bone MRI segmentation is illustrated by the fact that limited algorithms are publicly available for use, and those contained in the literature typically address a specific anatomic area. In our study, we propose a versatile, publicly available deep-learning model for bone segmentation in MRI across multiple standard MRI locations. The proposed model can operate in two modes: fully automated segmentation and prompt-based segmentation. Our contributions include (1) collecting and annotating a new MRI dataset across various MRI protocols, encompassing over 300 annotated volumes and 8485 annotated slices across diverse anatomic regions; (2) investigating several standard network architectures and strategies for automated segmentation; (3) introducing SegmentAnyBone, an innovative foundational model-based approach that extends Segment Anything Model (SAM); (4) comparative analysis of our algorithm and previous approaches; and (5) generalization analysis of our algorithm across different anatomical locations and MRI sequences, as well as an external dataset. We publicly release our model at https://github.com/mazurowski-lab/SegmentAnyBone.",
        "comments": "15 pages, 15 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12974"
    },
    {
        "doc_id": 722,
        "title": "Analysis of a detailed multi-stage model of stochastic gene expression using queueing theory and model reduction",
        "authors": [
            "Muhan Ma",
            "Juraj Szavits-Nossan",
            "Abhyudai Singh",
            "Ramon Grima"
        ],
        "subjects": [
            "Molecular Networks",
            "Quantitative Methods",
            "Subcellular Processes"
        ],
        "abstract": "We introduce a biologically detailed, stochastic model of gene expression describing the multiple rate-limiting steps of transcription, nuclear pre-mRNA processing, nuclear mRNA export, cytoplasmic mRNA degradation and translation of mRNA into protein. The processes in sub-cellular compartments are described by an arbitrary number of processing stages, thus accounting for a significantly finer molecular description of gene expression than conventional models such as the telegraph, two-stage and three-stage models of gene expression. We use two distinct tools, queueing theory and model reduction using the slow-scale linear-noise approximation, to derive exact or approximate analytic expressions for the moments or distributions of nuclear mRNA, cytoplasmic mRNA and protein fluctuations, as well as lower bounds for their Fano factors in steady-state conditions. We use these to study the phase diagram of the stochastic model; in particular we derive parametric conditions determining three types of transitions in the properties of mRNA fluctuations: from sub-Poissonian to super-Poissonian noise, from high noise in the nucleus to high noise in the cytoplasm, and from a monotonic increase to a monotonic decrease of the Fano factor with the number of processing stages. In contrast, protein fluctuations are always super-Poissonian and show weak dependence on the number of mRNA processing stages. Our results delineate the region of parameter space where conventional models give qualitatively incorrect results and provide insight into how the number of processing stages, e.g. the number of rate-limiting steps in initiation, splicing and mRNA degradation, shape stochastic gene expression by modulation of molecular memory.",
        "comments": "49 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12661"
    },
    {
        "doc_id": 723,
        "title": "The stability and instability of the language control network: a longitudinal resting-state functional magnetic resonance imaging study",
        "authors": [
            "Zilong Li",
            "Cong Liu",
            "Xin Pan",
            "Guosheng Ding",
            "Ruiming Wanga"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The language control network is vital among language-related networks responsible for solving the problem of multiple language switching. Researchers have expressed concerns about the instability of the language control network when exposed to external influences (e.g., Long-term second language learning). However, some studies have suggested that the language control network is stable. Therefore, whether the language control network is stable or not remains unclear. In the present study, we directly evaluated the stability and instability of the language control network using resting-state functional magnetic resonance imaging (rs-fMRI). We employed cohorts of Chinese first-year college students majoring in English who underwent second language (L2) acquisition courses at a university and those who did not. Two resting-state fMRI scans were acquired approximately 1 year apart. We found that the language control network was both moderately stable and unstable. We further investigated the morphological coexistence patterns of stability and instability within the language control network. First, we extracted connections representing stability and plasticity from the entire network. We then evaluated whether the coexistence patterns were modular (stability and instability involve different brain regions) or non-modular (stability and plasticity involve the same brain regions but have unique connectivity patterns). We found that both stability and instability coexisted in a non-modular pattern. Compared with the non-English major group, the English major group has a more non-modular coexistence pattern.. These findings provide preliminary evidence of the coexistence of stability and instability in the language control network.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12616"
    },
    {
        "doc_id": 724,
        "title": "Experiencing an elongated limb in virtual reality modifies the tactile distance perception of the corresponding real limb",
        "authors": [
            "Fran\u00e7ois Le Jeune",
            "Marco D'Alonzo",
            "Valeria Piombino",
            "Alessia Noccaro",
            "Domenico Formica",
            "Giovanni Di Pino"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In measurement, a reference frame is needed to compare the measured object to something already known. This raises the neuroscientific question of which reference frame is used by humans when exploring the environment. Previous studies suggested that, in touch, the body employed as measuring tool also serves as reference frame. Indeed, an artificial modification of the perceived dimensions of the body changes the tactile perception of external object dimensions. However, it is unknown if such a change in tactile perception would occur when the body schema is modified through the illusion of owning an limb altered in size. Therefore, employing a virtual hand illusion paradigm with an elongated forearm of different lengths, we systematically tested the subjective perception of distance between two points (tactile distance perception task, TDP task) on the corresponding real forearm following the illusion. Thus, TDP task is used as a proxy to gauge changes in the body schema. Embodiment of the virtual arm was found significantly greater after the synchronous visuo-tactile stimulation condition compared to the asynchronous one, and the forearm elongation significantly increased the TDP. However, we did not find any link between the visuo-tactile induced ownership over the elongated arm and TDP variation, suggesting that vision plays the main role in the modification of the body schema. Additionally, significant effect of elongation found on TDP but not on proprioception suggests that these are affected differently by body schema modifications. These findings confirm the body schema malleability and its role as reference frame in touch.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12601"
    },
    {
        "doc_id": 725,
        "title": "A robust balancing mechanism for spiking neural networks",
        "authors": [
            "Antonio Politi",
            "Alessandro Torcini"
        ],
        "subjects": [
            "Disordered Systems and Neural Networks",
            "Neurons and Cognition"
        ],
        "abstract": "Dynamical balance of excitation and inhibition is usually invoked to explain the irregular low firing activity observed in the cortex. We propose a robust nonlinear balancing mechanism for a random network of spiking neurons, which works also in absence of strong external currents. Biologically, the mechanism exploits the plasticity of excitatory-excitatory synapses induced by short-term depression. Mathematically, the nonlinear response of the synaptic activity is the key ingredient responsible for the emergence of a stable balanced regime. Our claim is supported by a simple self-consistent analysis accompanied by extensive simulations performed for increasing network sizes. The observed regime is essentially fluctuation driven and characterized by highly irregular spiking dynamics of all neurons.",
        "comments": "9 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12559"
    },
    {
        "doc_id": 726,
        "title": "Understanding Cellular Noise with Optical Perturbation and Deep Learning",
        "authors": [
            "Chuanbo Liu",
            "Yu Fu",
            "Lu Lin",
            "Elliot L. Elson",
            "Jin Wang"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Noise plays a crucial role in the regulation of cellular and organismal function and behavior.\n  Exploring noise's impact is key to understanding fundamental biological processes, such as gene expression, signal transduction, and the mechanisms of development and evolution.\n  Currently, a comprehensive method to quantify dynamical behavior of cellular noise within these biochemical systems is lacking.\n  In this study, we introduce an optically-controlled perturbation system utilizing the light-sensitive Phytochrome B (PhyB) from \\textit{Arabidopsis thaliana}, which enables precise noise modulation with high spatial-temporal resolution.\n  Our system exhibits exceptional sensitivity to light, reacting consistently to pulsed light signals, distinguishing it from other photoreceptor-based promoter systems that respond to a single light wavelength.\n  To characterize our system, we developed a stochastic model for phytochromes that accounts for photoactivation/deactivation, thermal reversion, and the dynamics of the light-activated gene promoter system.\n  To precisely control our system, we determined the rate constants for this model using an omniscient deep neural network that can directly map rate constant combinations to time-dependent state joint distributions.\n  By adjusting the activation rates through light intensity and degradation rates via N-terminal mutagenesis, we illustrate that out optical-controlled perturbation can effectively modulate molecular expression level as well as noise.\n  Our results highlight the potential of employing an optically-controlled gene perturbation system as a noise-controlled stimulus source.\n  This approach, when combined with the analytical capabilities of a sophisticated deep neural network, enables the accurate estimation of rate constants from observational data in a broad range of biochemical reaction networks.",
        "comments": "33 pages, 4 figures",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12498"
    },
    {
        "doc_id": 727,
        "title": "Modular Control of Biological Networks",
        "authors": [
            "David Murrugarra",
            "Alan Veliz-Cuba",
            "Elena Dimitrova",
            "Claus Kadelka",
            "Matthew Wheeler",
            "Reinhard Laubenbacher"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "The concept of control is central to understanding and applications of biological network models. Some of their key structural features relate to control functions, through gene regulation, signaling, or metabolic mechanisms, and computational models need to encode these. Applications of models often focus on model-based control, such as in biomedicine or metabolic engineering. This paper presents an approach to model-based control that exploits two common features of biological networks, namely their modular structure and canalizing features of their regulatory mechanisms. The paper focuses on intracellular regulatory networks, represented by Boolean network models. A main result of this paper is that control strategies can be identified by focusing on one module at a time. This paper also presents a criterion based on canalizing features of the regulatory rules to identify modules that do not contribute to network control and can be excluded. For even moderately sized networks, finding global control inputs is computationally very challenging. The modular approach presented here leads to a highly efficient approach to solving this problem. This approach is applied to a published Boolean network model of blood cancer large granular lymphocyte (T-LGL) leukemia to identify a minimal control set that achieves a desired control objective.",
        "comments": "15 pages, 5 figures. arXiv admin note: text overlap with arXiv:2206.04217",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12477"
    },
    {
        "doc_id": 728,
        "title": "A dynamic model to study the potential TB infections and assessment of control strategies in China",
        "authors": [
            "Chuanqing Xu",
            "Kedeng Cheng",
            "Songbai Guo",
            "Dehui Yuan",
            "Xiaoyu Zhao"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "China is one of the countries with a high burden of tuberculosis, and although the number of new cases of tuberculosis has been decreasing year by year, the number of new infections per year has remained high and the diagnosis rate of tuberculosis-infected patients has remained low. Based on the analysis of TB infection data, we develop a model of TB transmission dynamics that include potentially infected individuals and BCG vaccination, fit the model parameters to the data on new TB cases, calculate the basic reproduction number \\mathcal{R}_v= 0.4442. A parametric sensitivity analysis of \\mathcal{R}_v is performed, and we obtained the correlation coefficients of BCG vaccination rate and effectiveness rate with \\mathcal{R}_v as -0.810, -0.825. According to the model, we estimate that there are 614,186 (95% CI [562,631,665,741]) potentially infected TB cases in China, accounting for about 39.5% of the total number of TB cases. We assess the feasibility of achieving the goals of the WHO strategy to end tuberculosis in China and find that reducing the number of new cases by 90 per cent by 2035 is very difficult with the current tuberculosis control measures. However, with an effective combination of control measures such as increased detection of potentially infected persons, improved drug treatment, and reduction of overall exposure to tuberculosis patients, it is feasible to reach the WHO strategic goal of ending tuberculosis by 2035.",
        "comments": "20 pages, 10 figures, 33 conference",
        "date": "25 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12462"
    },
    {
        "doc_id": 729,
        "title": "Hypochaos prevents tragedy of the commons in discrete-time eco-evolutionary game dynamics",
        "authors": [
            "Samrat Sohel Mondal",
            "Avishuman Ray",
            "Sagar Chakraborty"
        ],
        "subjects": [
            "Populations and Evolution",
            "Adaptation and Self-Organizing Systems"
        ],
        "abstract": "While quite a few recent papers have explored game-resource feedback using the framework of evolutionary game theory, almost all the studies are confined to using time-continuous dynamical equations. Moreover, in such literature, the effect of ubiquitous chaos in the resulting eco-evolutionary dynamics is rather missing. Here, we present a deterministic eco-evolutionary discrete-time dynamics in generation-wise non-overlapping population of two types of harvesters, one harvesting at a faster rate than the other, consuming a self-renewing resource capable of showing chaotic dynamics. In the light of our finding that sometimes chaos is confined exclusively to either the dynamics of the resource or that of the consumer fractions, an interesting scenario is realized: The resource state can keep oscillating chaotically, and hence, it does not vanish to result in the tragedy of the commons, extinction of the resource due to selfish indiscriminate exploitation, and yet the consumer population, whose dynamics depends directly on the state of the resource, may end up being composed exclusively of defectors, i.e., high harvesters. This appears non-intuitive because it is well known that prevention of tragedy of the commons usually requires substantial cooperation to be present.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12245"
    },
    {
        "doc_id": 730,
        "title": "A distribution-guided Mapper algorithm",
        "authors": [
            "Yuyang Tao",
            "Shufei Ge"
        ],
        "subjects": [
            "Algebraic Topology",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Motivation: The Mapper algorithm is an essential tool to explore shape of data in topology data analysis. With a dataset as an input, the Mapper algorithm outputs a graph representing the topological features of the whole dataset. This graph is often regarded as an approximation of a reeb graph of data. The classic Mapper algorithm uses fixed interval lengths and overlapping ratios, which might fail to reveal subtle features of data, especially when the underlying structure is complex.\n  Results: In this work, we introduce a distribution guided Mapper algorithm named D-Mapper, that utilizes the property of the probability model and data intrinsic characteristics to generate density guided covers and provides enhanced topological features. Our proposed algorithm is a probabilistic model-based approach, which could serve as an alternative to non-prababilistic ones. Moreover, we introduce a metric accounting for both the quality of overlap clustering and extended persistence homology to measure the performance of Mapper type algorithm. Our numerical experiments indicate that the D-Mapper outperforms the classical Mapper algorithm in various scenarios. We also apply the D-Mapper to a SARS-COV-2 coronavirus RNA sequences dataset to explore the topological structure of different virus variants. The results indicate that the D-Mapper algorithm can reveal both vertical and horizontal evolution processes of the viruses.\n  Availability: Our package is available at https://github.com/ShufeiGe/D-Mapper.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12237"
    },
    {
        "doc_id": 731,
        "title": "Machine Learning Modeling Of SiRNA Structure-Potency Relationship With Applications Against Sars-Cov-2 Spike Gene",
        "authors": [
            "Damilola Oshunyinka"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "The pharmaceutical Research and development (R&D) process is lengthy and costly, taking nearly a decade to bring a new drug to the market. However, advancements in biotechnology, computational methods, and machine learning algorithms have the potential to revolutionize drug discovery, speeding up the process and improving patient outcomes. The COVID-19 pandemic has further accelerated and deepened the recognition of the potential of these techniques, especially in the areas of drug repurposing and efficacy predictions. Meanwhile, non-small molecule therapeutic modalities such as cell therapies, monoclonal antibodies, and RNA interference (RNAi) technology have gained importance due to their ability to target specific disease pathways and/or patient populations. In the field of RNAi, many experiments have been carried out to design and select highly efficient siRNAs. However, the established patterns for efficient siRNAs are sometimes contradictory and unable to consistently determine the most potent siRNA molecules against a target mRNA. Thus, this paper focuses on developing machine learning models based on the cheminformatics representation of the nucleotide composition (i.e. AUTGC) of siRNA to predict their potency and aid the selection of the most efficient siRNAs for further development. The PLS (Partial Least Square) and SVR (Support Vector Regression) machine learning models built in this work outperformed previously published models. These models can help in predicting siRNA potency and aid in selecting the best siRNA molecules for experimental validation and further clinical development. The study has demonstrated the potential of AI/machine learning models to help expedite siRNA-based drug discovery including the discovery of potent siRNAs against SARS-CoV-2.",
        "comments": "Master's thesis",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12232"
    },
    {
        "doc_id": 732,
        "title": "Biological species delimitation based on genetic and spatial dissimilarity: a comparative study",
        "authors": [
            "Gabriele d'Angella",
            "Christian Hennig"
        ],
        "subjects": [
            "Populations and Evolution",
            "Applications",
            "Methodology"
        ],
        "abstract": "The delimitation of biological species, i.e., deciding which individuals belong to the same species and whether and how many different species are represented in a data set, is key to the conservation of biodiversity. Much existing work uses only genetic data for species delimitation, often employing some kind of cluster analysis. This can be misleading, because geographically distant groups of individuals can be genetically quite different even if they belong to the same species. This paper investigates the problem of testing whether two potentially separated groups of individuals can belong to a single species or not based on genetic and spatial data. Various approaches are compared (some of which already exist in the literature) based on simulated metapopulations generated with SLiM and GSpace - two software packages that can simulate spatially-explicit genetic data at an individual level. Approaches involve partial Mantel testing, maximum likelihood mixed-effects models with a population effect, and jackknife-based homogeneity tests. A key challenge is that most tests perform on genetic and geographical distance data, violating standard independence assumptions. Simulations showed that partial Mantel tests and mixed-effects models have larger power than jackknife-based methods, but tend to display type-I-error rates slightly above the significance level. Moreover, a multiple regression model neglecting the dependence in the dissimilarities did not show inflated type-I-error rate. An application on brassy ringlets concludes the paper.",
        "comments": "paper of 23 pages with 4 figures; appendix of 11 pages with 4 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12126"
    },
    {
        "doc_id": 733,
        "title": "Matching biomolecular structures by registration of point clouds",
        "authors": [
            "Michael Habeck",
            "Andreas Kr\u00f6pelin",
            "Nima Vakili"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Motivation: Assessing the match between two biomolecular structures is at the heart of structural analyses such as superposition, alignment and docking. These tasks are typically solved with specialized structure-matching techniques implemented in software for protein structural alignment, rigid-body docking, or rigid fitting into cryo-EM maps. Results: We present a unifying framework to compare biomolecular structures by applying ideas from computer vision. The structures are represented as three-dimensional point clouds and compared by quantifying their overlap. We use the kernel correlation to measure point cloud overlap, and discuss local and global optimization strategies for maximizing the kernel correlation over the space of rigid transformations. We derive a majorization-minimization procedure that can be used to register two point clouds without establishing a point-to-point correspondence. We demonstrate that the majorization-minimization algorithms outperform the commonly used Iterative Closest Point registration algorithm. Furthermore, we discuss and benchmark a randomization strategy for globally optimizing the kernel correlation. We illustrate the approach on various 3D fitting problems such as the comparison of circularly permuted structures and rigid fitting of cryo-EM maps or bead models from small-angle scattering.",
        "comments": "18 pages (main text), 7 figures (main text)",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12082"
    },
    {
        "doc_id": 734,
        "title": "DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI",
        "authors": [
            "Sergio Morell-Ortega",
            "Marina Ruiz-Perez",
            "Marien Gadea",
            "Roberto Vivo-Hernando",
            "Gregorio Rubio",
            "Fernando Aparici",
            "Maria de la Iglesia-Vaya",
            "Gwenaelle Catheline",
            "Pierrick Coup\u00e9",
            "Jos\u00e9 V. Manj\u00f3n"
        ],
        "subjects": [
            "Image and Video Processing",
            "Computer Vision and Pattern Recognition",
            "Neurons and Cognition"
        ],
        "abstract": "This paper introduces a novel multimodal and high-resolution human brain cerebellum lobule segmentation method. Unlike current tools that operate at standard resolution ($1 \\text{ mm}^{3}$) or using mono-modal data, the proposed method improves cerebellum lobule segmentation through the use of a multimodal and ultra-high resolution ($0.125 \\text{ mm}^{3}$) training dataset. To develop the method, first, a database of semi-automatically labelled cerebellum lobules was created to train the proposed method with ultra-high resolution T1 and T2 MR images. Then, an ensemble of deep networks has been designed and developed, allowing the proposed method to excel in the complex cerebellum lobule segmentation task, improving precision while being memory efficient. Notably, our approach deviates from the traditional U-Net model by exploring alternative architectures. We have also integrated deep learning with classical machine learning methods incorporating a priori knowledge from multi-atlas segmentation, which improved precision and robustness. Finally, a new online pipeline, named DeepCERES, has been developed to make available the proposed method to the scientific community requiring as input only a single T1 MR image at standard resolution.",
        "comments": "20 pages",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.12074"
    },
    {
        "doc_id": 735,
        "title": "Approximating a linear dynamical system from non-sequential data",
        "authors": [
            "Cliff Stein",
            "Pratik Worah"
        ],
        "subjects": [
            "Genomics"
        ],
        "abstract": "Given non-sequential snapshots from instances of a dynamical system, we design a compressed sensing based algorithm that reconstructs the dynamical system. We formally prove that successful reconstruction is possible under the assumption that we can construct an approximate clock from a subset of the coordinates of the underlying system.\n  As an application, we argue that our assumption is likely true for genomic datasets, and we recover the underlying nuclear receptor networks and predict pathways, as opposed to genes, that may differentiate phenotypes in some publicly available datasets.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11858"
    },
    {
        "doc_id": 736,
        "title": "The NOSTRA model: coherent estimation of infection sources in the case of possible nosocomial transmission",
        "authors": [
            "David J Pascall",
            "Chris Jackson",
            "Stephanie Evans",
            "Theodore Gouliouris",
            "Chris Illingworth",
            "Stefan Piatek",
            "Julie V Robotham",
            "Oliver Stirrup",
            "Ben Warne",
            "Judith Breuer",
            "Daniela De Angelis"
        ],
        "subjects": [
            "Applications",
            "Quantitative Methods"
        ],
        "abstract": "Nosocomial infections have important consequences for patients and hospital staff: they worsen patient outcomes and their management stresses already overburdened health systems. Accurate judgements of whether an infection is nosocomial helps staff make appropriate choices to protect other patients within the hospital. Nosocomiality cannot be properly assessed without considering whether the infected patient came into contact with high risk potential infectors within the hospital. We developed a Bayesian model that integrates epidemiological, contact and pathogen genetic data to determine how likely an infection is to be nosocomial and the probability of given infection candidates being the source of the infection.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11837"
    },
    {
        "doc_id": 737,
        "title": "Full-dimensional characterisation of time-warped spike-time stimulus-response distribution geometries",
        "authors": [
            "James B Isbister"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Characterising the representation of sensory stimuli in the brain is a fundamental scientific endeavor, which can illuminate principles of information coding. Most characterizations reduce the dimensionality of neural data by converting spike trains to firing rates or binned spike counts, applying explicitly named methods of ``dimensionality reduction'', or collapsing trial-to-trial variability. Characterisation of the full-dimensional geometry of timing-based representations may provide unexpected insights into how complex high-dimensional information is encoded. Recent research shows that the distribution of representations elicited over trials of a single stimulus can be geometrically characterized without the application of dimensionality reduction, maintaining the temporal spiking information of individual neurons in a cell assembly and illuminating rich geometric structure. We extend these results, showing that precise spike time patterns for larger cell assemblies are time-warped (i.e. stretched or compressed) on each trial. Moreover, by geometrically characterizing distributions of large spike time patterns, our analysis supports the hypothesis that the degree to which a spike time pattern is time-warped depends on the cortical area's background activity level on a single trial. Finally, we suggest that the proliferation of large electrophysiology datasets and the increasing concentration of ``neural geometrists'', creates ideal conditions for characterization of full-dimensional spike time representations, in complement to dimensionality reduction approaches.",
        "comments": "Accepted as an extended abstract at the NeurReps workshop at NeurIPS 2023. The workshop doesn't publish extended abstracts so submitting here",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11784"
    },
    {
        "doc_id": 738,
        "title": "Impact of temporal interaction on the evolution of cooperation",
        "authors": [
            "Yujie He",
            "Tianyu Ren",
            "Junjun Zheng",
            "Huawen Liang"
        ],
        "subjects": [
            "Physics and Society",
            "Social and Information Networks",
            "Populations and Evolution"
        ],
        "abstract": "This research investigates the impact of dynamic interactions with time-varying topologies on the evolution of cooperative behaviours in social dilemmas. Traditional research has focused on deterministic rules governing pairwise interactions, yet the impact of interaction frequency and synchronicity on cooperation remains underexplored. Addressing this gap, our work introduces two temporal interaction mechanisms to model the stochastic or periodic participation of individuals in these games, acknowledging real-life variances due to exogenous temporal factors and geographical time differences. We consider that the interaction state significantly influences both game payoff calculations and the strategy updating process, offering new insights into the emergence and sustainability of cooperation. Our results indicate that maximum game participation frequency is suboptimal under a stochastic interaction mechanism. Instead, an intermediate region of activation probability yields the highest cooperation level, especially under strong dilemma conditions. This suggests that a balance between inactivity security and interaction frequency is crucial. Furthermore, local synchronization of interactions within specific areas is shown to be beneficial, as time differences hinder the spread of cross-structures but promote the formation of dense cooperative clusters with smoother boundaries. Our findings provide an intuitive understanding of node-based temporality and probabilistic interactions, contributing to the broader discourse on resolving social dilemmas.",
        "comments": "7 pages, 6 figures",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11782"
    },
    {
        "doc_id": 739,
        "title": "Combining oligo pools and Golden Gate cloning to create protein variant libraries or guide RNA libraries for CRISPR applications",
        "authors": [
            "Alicia Maci\u00e1 Valero",
            "Rianne C. Prins",
            "Thijs de Vroet",
            "Sonja Billerbeck"
        ],
        "subjects": [
            "Quantitative Methods",
            "Biomolecules"
        ],
        "abstract": "Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 350 bases), a higher error rate compared to alternative synthesis methods, and the presence of truncated molecules in the pool due to incomplete synthesis. Here, we provide users with a comprehensive protocol that details how oligo pools can be used in combination with Golden Gate cloning to create user-defined protein mutant libraries, as well as single guide RNA libraries for CRISPR applications. Our methods are optimized to work within the Yeast Toolkit Golden Gate scheme, but are in principle compatible with any other Golden Gate-based modular cloning toolkit and extendable to other restriction enzyme-based cloning methods beyond Golden Gate. Our methods yield high-quality, affordable, in-house variant libraries.",
        "comments": " ",
        "date": "22 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11746"
    },
    {
        "doc_id": 740,
        "title": "Evolutionary dynamics of any multiplayer game on regular graphs",
        "authors": [
            "Chaoqian Wang",
            "Matja\u017e Perc",
            "Attila Szolnoki"
        ],
        "subjects": [
            "Computer Science and Game Theory",
            "Statistical Mechanics",
            "Computational Complexity",
            "Cellular Automata and Lattice Gases",
            "Populations and Evolution"
        ],
        "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of key evolutionary processes that govern vital social and natural systems. However, a comprehensive theoretical framework for solving multiplayer games with an arbitrary number of strategies on graphs is still missing. Here, we solve this by drawing an analogy with the Ball-and-Box problem, based on which we show that the local configuration of multiplayer games on graphs is equivalent to distributing $k$ identical co-players among $n$ distinct strategies. We use this to derive the replicator equation for any $n$-strategy multiplayer game under weak selection, which can be solved in polynomial time. As an example, we revisit the second-order free-riding problem, where costly punishment cannot truly resolve social dilemmas in a well-mixed population. Yet, in structured populations, we derive an accurate threshold for the punishment strength, beyond which punishment can either lead to the extinction of defection or transform the system into a rock-paper-scissors-like cycle. The analytical solution also qualitatively agrees with the phase diagrams that were previously obtained for non-marginal selection strengths. Our framework thus allows an exploration of any multi-strategy multiplayer game on regular graphs.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11686"
    },
    {
        "doc_id": 741,
        "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a Commercial Compute-in-SRAM Architecture",
        "authors": [
            "Courtney Golden",
            "Dan Ilan",
            "Nicholas Cebry",
            "Christopher Batten"
        ],
        "subjects": [
            "Hardware Architecture",
            "Genomics"
        ],
        "abstract": "DNA sequence alignment is an important workload in computational genomics. Reference-guided DNA assembly involves aligning many read sequences against candidate locations in a long reference genome. To reduce the computational load of this alignment, candidate locations can be pre-filtered using simpler alignment algorithms like edit distance. Prior work has explored accelerating filtering on simulated compute-in-DRAM, due to the massive parallelism of compute-in-memory architectures. In this paper, we present work-in-progress on accelerating filtering using a commercial compute-in-SRAM accelerator. We leverage the recently released Gemini accelerator platform from GSI Technology, which is the first, to our knowledge, commercial-scale compute-in-SRAM system. We accelerate the Myers' bit-parallel edit distance algorithm, producing average speedups of 14.1x over single-core CPU performance. Individual query/candidate alignments produce speedups of up to 24.1x. These early results suggest this novel architecture is well-suited to accelerating the filtering step of sequence-to-sequence DNA alignment.",
        "comments": "Journal ref:        5th Workshop on Accelerator Architecture in Computational Biology and Bioinformatics (AACBB), June 2023",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11685"
    },
    {
        "doc_id": 742,
        "title": "Modern approaches to improving phase contrast electron microscopy",
        "authors": [
            "Jeremy J. Axelrod",
            "Jessie T. Zhang",
            "Petar N. Petrov",
            "Robert M. Glaeser",
            "Holger Mueller"
        ],
        "subjects": [
            "Quantitative Methods",
            "Optics",
            "Biomolecules"
        ],
        "abstract": "Although defocus can be used to generate partial phase contrast in transmission electron microscope images, cryo-electron microscopy (cryo-EM) can be further improved by the development of phase plates which increase contrast by applying a phase shift to the unscattered part of the electron beam. Many approaches have been investigated, including the ponderomotive interaction between light and electrons. We review the recent successes achieved with this method in high-resolution, single-particle cryo-EM. We also review the status of using pulsed or near-field enhanced laser light as alternatives, along with approaches that use scanning transmission electron microscopy (STEM) with a segmented detector rather than a phase plate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11678"
    },
    {
        "doc_id": 743,
        "title": "Enhancing selectivity using Wasserstein distance based reweighing",
        "authors": [
            "Pratik Worah"
        ],
        "subjects": [
            "Machine Learning",
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Given two labeled data-sets $\\mathcal{S}$ and $\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\mathcal{T}$.\n  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). We tune the algorithm's parameter so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\% to 95\\%, as a result of our reweighing. Of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\% but not MNK1, at 10$\u03bc$M -- a 5\\% success rate.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11562"
    },
    {
        "doc_id": 744,
        "title": "Understanding Hepatitis B Virus Infection through Hepatocyte Proliferation and Capsid Recycling",
        "authors": [
            "Rupchand Sutradhar",
            "D C Dalal"
        ],
        "subjects": [
            "Populations and Evolution",
            "Dynamical Systems"
        ],
        "abstract": "Proliferation of uninfected as well as infected hepatocytes and recycling of DNA-containing\n  capsids are two major mechanisms playing significant roles in the clearance of hepatitis B\n  virus (HBV) infection. In this study, the temporal dynamics of this infection are investigated\n  through two in silico bio-mathematical models considering both proliferation of hepatocytes\n  and the recycling of capsids. Both models are formulated on the basis of a key finding in the existing literature: mitosis of infected yields in two uninfected progenies. In the first model,\n  we examine regular proliferation (occurs continuously), while the second model deals with the\n  irregular proliferation (happens when the total number of liver cells decreases to less than 70%\n  of its initial volume). The models are calibrated with the experimental data obtained from\n  an adult chimpanzee. Results of this study suggest that when both hepatocytes proliferate\n  with equal rate, proliferation aids the individual in a rapid recovery from the acute infection\n  whereas in the case of chronic infection, the severity of the infection increases if the proliferation\n  occurs frequently. On the other hand, if the infected cells proliferate at a slower rate than uninfected cells, the proliferation of uninfected hepatocytes contributes to increase the infection,\n  but the proliferation of infected hepatocytes acts to reduce the infection from the long-term\n  perspective. Furthermore, it is also observed that the differences between the outcomes of\n  regular and irregular proliferations are substantial and noteworthy.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11481"
    },
    {
        "doc_id": 745,
        "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis",
        "authors": [
            "Yin Li",
            "Yu Xiong",
            "Wenxin Fan",
            "Kai Wang",
            "Qingqing Yu",
            "Liping Si",
            "Patrick van der Smagt",
            "Jun Tang",
            "Nutan Chen"
        ],
        "subjects": [
            "Machine Learning",
            "Quantitative Methods"
        ],
        "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis. How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of patients and related systematic symptom scores, to provide a novel approach in the management of long-term AIT.\n  Methods: The research develops and analyzes two models, Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on scoring and adherence prediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM models, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and $2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these RMSEs are significantly lower than the random prediction error of $4.55$.\n  Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in Allergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11447"
    },
    {
        "doc_id": 746,
        "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts",
        "authors": [
            "Haoqiang Guo",
            "Sendong Zhao",
            "Haochun Wang",
            "Yanrui Du",
            "Bing Qin"
        ],
        "subjects": [
            "Machine Learning",
            "Computation and Language",
            "Biomolecules"
        ],
        "abstract": "Deep learning is now widely used in drug discovery, providing significant acceleration and cost reduction. As the most fundamental building block, molecular representation is essential for predicting molecular properties to enable various downstream applications. Most existing methods attempt to incorporate more information to learn better representations. However, not all features are equally important for a specific task. Ignoring this would potentially compromise the training efficiency and predictive accuracy. To address this issue, we propose a novel approach, which treats language models as an agent and molecular pretraining models as a knowledge base. The agent accentuates task-relevant features in the molecular representation by understanding the natural language description of the task, just as a tailor customizes clothes for clients. Thus, we call this approach MolTailor. Evaluations demonstrate MolTailor's superior performance over baselines, validating the efficacy of enhancing relevance for molecular representation learning. This illustrates the potential of language model guided optimization to better exploit and unleash the capabilities of existing powerful molecular representation methods. Our codes and appendix are available at https://github.com/SCIR-HI/MolTailor.",
        "comments": "Accepted by AAAI 2024",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11403"
    },
    {
        "doc_id": 747,
        "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
        "authors": [
            "Ruochi Zhang",
            "Haoran Wu",
            "Chang Liu",
            "Huaping Li",
            "Yuqian Wu",
            "Kewei Li",
            "Yifan Wang",
            "Yifan Deng",
            "Jiahui Chen",
            "Fengfeng Zhou",
            "Xin Gao"
        ],
        "subjects": [
            "Machine Learning",
            "Artificial Intelligence",
            "Computational Engineering, Finance, and Science",
            "Biomolecules"
        ],
        "abstract": "Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or http://www.healthinformaticslab.org/supp/.",
        "comments": "25 pages, 5 figures, 3 tables",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11360"
    },
    {
        "doc_id": 748,
        "title": "Sensory adaptation in a continuum model of bacterial chemotaxis -- working range, cost-accuracy relation, and coupled systems",
        "authors": [
            "Vansh Kharbanda",
            "Benedikt Sabass"
        ],
        "subjects": [
            "Cell Behavior",
            "Soft Condensed Matter"
        ],
        "abstract": "Sensory adaptation enables organisms to adjust their perception in a changing environment. A paradigm is bacterial chemotaxis, where the output activity of chemoreceptors is adapted to different baseline concentrations via receptor methylation. The range of internal receptor states limits the stimulus magnitude to which these systems can adapt. Here, we employ a highly idealized, Langevin-equation based model to study how the finite range of state variables affects the adaptation accuracy and the energy dissipation in individual and coupled systems. Maintaining an adaptive state requires constant energy dissipation. We show that the steady-state dissipation rate increases approximately linearly with the adaptation accuracy for varying stimulus magnitudes in the so-called perfect adaptation limit. This result complements the well-known logarithmic cost-accuracy relationship for varying chemical driving. Next, we study linearly coupled pairs of sensory units. We find that the interaction reduces the dissipation rate per unit and affects the overall cost-accuracy relationship. A coupling of the slow methylation variables results in a better accuracy than a coupling of activities. Overall, the findings highlight the significance of both the working range and collective operation mode as crucial design factors that impact the accuracy and energy expenditure of molecular adaptation networks.",
        "comments": " ",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11341"
    },
    {
        "doc_id": 749,
        "title": "Uncertainty quantification of receptor ligand binding sites prediction",
        "authors": [
            "Nanjie Chen",
            "Dongliang Yu",
            "Dmitri Beglov",
            "Mark Kon",
            "Julio Enrique Castrillon-Candas"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Recent advancements in protein docking site prediction have highlighted the limitations of traditional rigid docking algorithms, like PIPER, which often neglect critical stochastic elements such as solvent-induced fluctuations. These oversights can lead to inaccuracies in identifying viable docking sites due to the complexity of high-dimensional, stochastic energy manifolds with low regularity. To address this issue, our research introduces a novel model where the molecular shapes of ligands and receptors are represented using multi-variate Karhunen-Lo `eve (KL) expansions. This method effectively captures the stochastic nature of energy manifolds, allowing for a more accurate representation of molecular interactions.Developed as a plugin for PIPER, our scientific computing software enhances the platform, delivering robust uncertainty measures for the energy manifolds of ranked binding sites. Our results demonstrate that top-ranked binding sites, characterized by lower uncertainty in the stochastic energy manifold, align closely with actual docking sites. Conversely, sites with higher uncertainty correlate with less optimal docking positions. This distinction not only validates our approach but also sets a new standard in protein docking predictions, offering substantial implications for future molecular interaction research and drug development.",
        "comments": " ",
        "date": "23 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11312"
    },
    {
        "doc_id": 750,
        "title": "Seasonality of primary productivity affects coastal species more than its magnitude",
        "authors": [
            "Carlota Muniz",
            "Christopher McQuaid",
            "Nicolas Weidberg"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "While the importance of extreme conditions is recognised, patterns in species abundances are often interpreted through average environmental conditions within their distributional range. For marine species with pelagic larvae, temperature and phytoplankton concentration are key variables. Along the south coast of South Africa, conspicuous spatial patterns in recruitment rates and the abundances of different mussel species exist, with focal areas characterized by large populations. We studied 15 years of sea surface temperature (SST) and chlorophyll-a (chl-a) satellite data, using spectral analyses to partition their temporal variability over ecologically relevant time periods, including seasonal (101 to 365 days) and intra-seasonal cycles (20 to 100 days). Adult cover and mussel recruitment were measured at 10 sites along the south coast and regression models showed that about 70 percent of the variability in recruitment and adult cover was explained by seasonal variability in chl-a, while mean annual chl-a and SST only explained 30 percent of the recruitment, with no significant effect for adult cover. SST and chl-a at two upwelling centres showed less predictable seasonal cycles during the second half of the study period with a significant cooling trend during austral autumn, coinciding with one of the mussel reproductive peaks. This likely reflects recent changes in the Agulhas Current, the world largest western boundary current, which affects coastal ecosystems by driving upwelling.",
        "comments": "Journal ref:        Science of the Total Environment, 757:143740, 2021",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11289"
    },
    {
        "doc_id": 751,
        "title": "Smart Drug-Delivery Systems for Cancer Nanotherapy",
        "authors": [
            "Paola Sanchez-Moreno",
            "Juan Luis Ortega-Vinuesa",
            "Jose Manuel Peula-Garcia",
            "Juan Antonio Marchal",
            "Houria Boulaiz"
        ],
        "subjects": [
            "Tissues and Organs",
            "Mesoscale and Nanoscale Physics",
            "Applied Physics",
            "Biological Physics"
        ],
        "abstract": "Despite all the advances achieved in the field of tumor-biology research, in most cases conventional therapies including chemotherapy are still the leading choices. The main disadvantage of these treatments, in addition to the low solubility of many antitumor drugs, is their lack of specificity, which explains the frequent occurrence of serious side effects due to nonspecific drug uptake by healthy cells. Progress in nanotechnology and its application in medicine have provided new opportunities and different smart systems. Such systems can improve the intracellular delivery of the drugs due to their multifunctionality and targeting potential. The purpose of this manuscript is to review and analyze the recent progress made in nanotherapy applied to cancer treatment. First, we provide a global overview of cancer and different smart nanoparticles currently used in oncology. Then, we analyze in detail the development of drug-delivery strategies in cancer therapy, focusing mainly on the intravenously administered smart nanoparticles with protein corona to avoid immune-system clearance. Finally, we discuss the challenges, clinical trials, and future directions of the nanoparticle-based therapy in cancer.",
        "comments": "Preprint version, 25 pages, 7 figures, 3 tables. Authors thank to Bentham Science the posibility of deposit the ACCEPTED VERSION of the peer-reviewed article after 12 months of publication on journal web site on arXiv repository. The published manuscript is available at EurekaSelect via https://www.eurekaselect.com/openurl/content.php?genre=article&doi=10.2174/1389450117666160527142544",
        "date": "20 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11192"
    },
    {
        "doc_id": 752,
        "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge",
        "authors": [
            "Chih-Hsuan Wei",
            "Alexis Allot",
            "Po-Ting Lai",
            "Robert Leaman",
            "Shubo Tian",
            "Ling Luo",
            "Qiao Jin",
            "Zhizheng Wang",
            "Qingyu Chen",
            "Zhiyong Lu"
        ],
        "subjects": [
            "Computation and Language",
            "Quantitative Methods"
        ],
        "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a biomedical literature resource using state-of-the-art AI techniques to offer semantic and relation searches for key concepts like proteins, genetic variants, diseases, and chemicals. It currently provides over one billion entity and relation annotations across approximately 36 million PubMed abstracts and 6 million full-text articles from the PMC open access subset, updated weekly. PubTator 3.0's online interface and API utilize these precomputed entity relations and synonyms to provide advanced search capabilities and enable large-scale analyses, streamlining many complex information needs. We showcase the retrieval quality of PubTator 3.0 using a series of entity pair queries, demonstrating that PubTator 3.0 retrieves a greater number of articles than either PubMed or Google Scholar, with higher precision in the top 20 results. We further show that integrating ChatGPT (GPT-4) with PubTator APIs dramatically improves the factuality and verifiability of its responses. In summary, PubTator 3.0 offers a comprehensive set of features and tools that allow researchers to navigate the ever-expanding wealth of biomedical literature, expediting research and unlocking valuable insights for scientific discovery.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11048"
    },
    {
        "doc_id": 753,
        "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
        "authors": [
            "Minkai Xu",
            "Jiaqi Han",
            "Aaron Lou",
            "Jean Kossaifi",
            "Arvind Ramanathan",
            "Kamyar Azizzadenesheli",
            "Jure Leskovec",
            "Stefano Ermon",
            "Anima Anandkumar"
        ],
        "subjects": [
            "Machine Learning",
            "Numerical Analysis",
            "Quantitative Methods"
        ],
        "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.11037"
    },
    {
        "doc_id": 754,
        "title": "Clustering Molecular Energy Landscapes by Adaptive Network Embedding",
        "authors": [
            "Paula Mercurio",
            "Di Liu"
        ],
        "subjects": [
            "Biomolecules",
            "Statistical Mechanics",
            "Machine Learning"
        ],
        "abstract": "In order to efficiently explore the chemical space of all possible small molecules, a common approach is to compress the dimension of the system to facilitate downstream machine learning tasks. Towards this end, we present a data driven approach for clustering potential energy landscapes of molecular structures by applying recently developed Network Embedding techniques, to obtain latent variables defined through the embedding function. To scale up the method, we also incorporate an entropy sensitive adaptive scheme for hierarchical sampling of the energy landscape, based on Metadynamics and Transition Path Theory. By taking into account the kinetic information implied by a system's energy landscape, we are able to interpret dynamical node-node relationships in reduced dimensions. We demonstrate the framework through Lennard-Jones (LJ) clusters and a human DNA sequence.",
        "comments": "19 pages, 10 figures",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10972"
    },
    {
        "doc_id": 755,
        "title": "Homogenisation of nonlinear blood flow in periodic networks: the limit of small haematocrit heterogeneity",
        "authors": [
            "Y. Ben-Ami",
            "B. D. Wood",
            "J. M. Pitt-Francis",
            "P. K. Maini",
            "H. M. Byrne"
        ],
        "subjects": [
            "Tissues and Organs",
            "Soft Condensed Matter",
            "Biological Physics"
        ],
        "abstract": "In this work we develop a homogenisation methodology to upscale mathematical descriptions of microcirculatory blood flow from the microscale (where individual vessels are resolved) to the macroscopic (or tissue) scale. Due to the assumed two-phase nature of blood and specific features of red blood cells (RBCs), mathematical models for blood flow in the microcirculation are highly nonlinear, coupling the flow and RBC concentrations (haematocrit). In contrast to previous works which accomplished blood-flow homogenisation by assuming that the haematocrit level remains constant, here we allow for spatial heterogeneity in the haematocrit concentration and thus begin with a nonlinear microscale model. We simplify the analysis by considering the limit of small haematocrit heterogeneity which prevails when variations in haematocrit concentration between neighbouring vessels are small. Homogenisation results in a system of coupled, nonlinear partial differential equations describing the flow and haematocrit transport at the macroscale, in which a nonlinear Darcy-type model relates the flow and pressure gradient via a haematocrit-dependent permeability tensor. During the analysis we obtain further that haematocrit transport at the macroscale is governed by a purely advective equation. Applying the theory to particular examples of two- and three-dimensional geometries of periodic networks, we calculate the effective permeability tensor associated with blood flow in these vascular networks. We demonstrate how the statistical distribution of vessel lengths and diameters, together with the average haematocrit level, affect the statistical properties of the macroscopic permeability tensor. These data can be used to simulate blood flow and haematocrit transport at the macroscale.",
        "comments": "34 pages, 8 figures",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10932"
    },
    {
        "doc_id": 756,
        "title": "A Chaotic Associative Memory",
        "authors": [
            "Nurani Rajagopal Rohan",
            "Sayan Gupta",
            "V. Srinivasa Chakravarthy"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Chaotic Dynamics"
        ],
        "abstract": "We propose a novel Chaotic Associative Memory model using a network of chaotic Rossler systems and investigate the storage capacity and retrieval capabilities of this model as a function of increasing periodicity and chaos. In early models of associate memory networks, memories were modeled as fixed points, which may be mathematically convenient but has poor neurobiological plausibility. Since brain dynamics is inherently oscillatory, attempts have been made to construct associative memories using nonlinear oscillatory networks. However, oscillatory associative memories are plagued by the problem of poor storage capacity, though efforts have been made to improve capacity by adding higher order oscillatory modes. The chaotic associative memory proposed here exploits the continuous spectrum of chaotic elements and has higher storage capacity than previously described oscillatory associate memories.",
        "comments": "10 pages, 8 Figures, Submitted to \"Chaos: An Interdisciplinary Journal of Nonlinear Science\"",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10922"
    },
    {
        "doc_id": 757,
        "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
        "authors": [
            "Jason Toy",
            "Josh MacAdam",
            "Phil Tabor"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.",
        "comments": "9 pages, 4 figures",
        "date": "9 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10910"
    },
    {
        "doc_id": 758,
        "title": "Novel community data in ecology -- properties and prospects",
        "authors": [
            "Florian Hartig",
            "Nerea Abrego",
            "Alex Bush",
            "Jonathan M. Chase",
            "Gurutzeta Guillera-Arroita",
            "Mathew A. Leibold",
            "Otso Ovaskainen",
            "Lo\u00efc Pellissier",
            "Maximilian Pichler",
            "Giovanni Poggiato",
            "Laura Pollock",
            "Sara Si-Moussi",
            "Wilfried Thuiller",
            "Duarte S. Viana",
            "David I. Warton",
            "Damaris Zurell",
            "Douglas W. Yu"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "New technologies for acquiring biological information such as eDNA, acoustic or optical sensors, make it possible to generate spatial community observations at unprecedented scales. The potential of these novel community data to standardize community observations at high spatial, temporal, and taxonomic resolution and at large spatial scale ('many rows and many columns') has been widely discussed, but so far, there has been little integration of these data with ecological models and theory. Here, we review these developments and highlight emerging solutions, focusing on statistical methods for analyzing novel community data, in particular joint species distribution models; the new ecological questions that can be answered with these data; and the potential implications of these developments for policy and conservation.",
        "comments": "Journal ref:        Trends in Ecology & Evolution, 2024",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10860"
    },
    {
        "doc_id": 759,
        "title": "Exploring the role of structure in a time constrained decision task",
        "authors": [
            "Naomi Chaix-Eichel",
            "Gautham Venugopal",
            "Thomas Boraud",
            "Nicolas P. Rougier"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Neurons and Cognition"
        ],
        "abstract": "The structure of the basal ganglia is remarkably similar across a number of species (often described in terms of direct, indirect and hyperdirect pathways) and is deeply involved in decision making and action selection. In this article, we are interested in exploring the role of structure when solving a decision task while avoiding to make any strong assumption regarding the actual structure. To do so, we exploit the echo state network paradigm that allows to solve complex task based on a random architecture. Considering a temporal decision task, the question is whether a specific structure allows for better performance and if so, whether this structure shares some similarity with the basal ganglia. Our results highlight the advantage of having a slow (direct) and a fast (hyperdirect) pathway that allows to deal with late information during a decision making task.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10849"
    },
    {
        "doc_id": 760,
        "title": "Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer Subtype Diagnosis",
        "authors": [
            "Charles Theodore Kent",
            "Leila Bagheriye",
            "Johan Kwisthout"
        ],
        "subjects": [
            "Neural and Evolutionary Computing",
            "Machine Learning",
            "Genomics",
            "Quantitative Methods",
            "Applications"
        ],
        "abstract": "Recent strides in the field of neural computation has seen the adoption of Winner Take All (WTA) circuits to facilitate the unification of hierarchical Bayesian inference and spiking neural networks as a neurobiologically plausible model of information processing. Current research commonly validates the performance of these networks via classification tasks, particularly of the MNIST dataset. However, researchers have not yet reached consensus about how best to translate the stochastic responses from these networks into discrete decisions, a process known as population decoding. Despite being an often underexamined part of SNNs, in this work we show that population decoding has a significanct impact on the classification performance of WTA networks. For this purpose, we apply a WTA network to the problem of cancer subtype diagnosis from multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing so we utilise a novel implementation of gene similarity networks, a feature encoding technique based on Kohoens self organising map algorithm. We further show that the impact of selecting certain population decoding methods is amplified when facing imbalanced datasets.",
        "comments": "This paper has been accepted in BIOINFORMATICS 2024 (BIOSTEC 2024)",
        "date": "6 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10844"
    },
    {
        "doc_id": 761,
        "title": "DeepRLI: A Multi-objective Framework for Universal Protein--Ligand Interaction Prediction",
        "authors": [
            "Haoyu Lin",
            "Shiwei Wang",
            "Jintao Zhu",
            "Yibo Li",
            "Jianfeng Pei",
            "Luhua Lai"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "Protein (receptor)--ligand interaction prediction is a critical component in computer-aided drug design, significantly influencing molecular docking and virtual screening processes. Despite the development of numerous scoring functions in recent years, particularly those employing machine learning, accurately and efficiently predicting binding affinities for protein--ligand complexes remains a formidable challenge. Most contemporary methods are tailored for specific tasks, such as binding affinity prediction, binding pose prediction, or virtual screening, often failing to encompass all aspects. In this study, we put forward DeepRLI, a novel protein--ligand interaction prediction architecture. It encodes each protein--ligand complex into a fully connected graph, retaining the integrity of the topological and spatial structure, and leverages the improved graph transformer layers with cosine envelope as the central module of the neural network, thus exhibiting superior scoring power. In order to equip the model to generalize to conformations beyond the confines of crystal structures and to adapt to molecular docking and virtual screening tasks, we propose a multi-objective strategy, that is, the model outputs three scores for scoring and ranking, docking, and screening, and the training process optimizes these three objectives simultaneously. For the latter two objectives, we augment the dataset through a docking procedure, incorporate suitable physics-informed blocks and employ an effective contrastive learning approach. Eventually, our model manifests a balanced performance across scoring, ranking, docking, and screening, thereby demonstrating its ability to handle a range of tasks. Overall, this research contributes a multi-objective framework for universal protein--ligand interaction prediction, augmenting the landscape of structure-based drug design.",
        "comments": " ",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10806"
    },
    {
        "doc_id": 762,
        "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature Importance Adversarial Attacks",
        "authors": [
            "Heorhii Skovorodnikov",
            "Hoda Alkhzaimi"
        ],
        "subjects": [
            "Machine Learning",
            "Cryptography and Security",
            "Genomics"
        ],
        "abstract": "With the steady rise of the use of AI in bio-technical applications and the widespread adoption of genomics sequencing, an increasing amount of AI-based algorithms and tools is entering the research and production stage affecting critical decision-making streams like drug discovery and clinical outcomes. This paper demonstrates the vulnerability of AI models often utilized downstream tasks on recognized public genomics datasets. We undermine model robustness by deploying an attack that focuses on input transformation while mimicking the real data and confusing the model decision-making, ultimately yielding a pronounced deterioration in model performance. Further, we enhance our approach by generating poisoned data using a variational autoencoder-based model. Our empirical findings unequivocally demonstrate a decline in model performance, underscored by diminished accuracy and an upswing in false positives and false negatives. Furthermore, we analyze the resulting adversarial samples via spectral analysis yielding conclusions for countermeasures against such attacks.",
        "comments": "15 pages, core code available at: https://github.com/HeorhiiS/fimba-attack",
        "date": "19 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10657"
    },
    {
        "doc_id": 763,
        "title": "Exact analytical algorithm for solvent accessible surface area and derivatives in implicit solvent molecular simulations on GPUs",
        "authors": [
            "Xin Cao",
            "Michelle H. Hummel",
            "Yuzhang Wang",
            "Carlos Simmerling",
            "Evangelos A. Coutsias"
        ],
        "subjects": [
            "Biomolecules"
        ],
        "abstract": "In this paper, we present dSASA (differentiable SASA), an exact geometric method to calculate solvent accessible surface area (SASA) analytically along with atomic derivatives on GPUs. The atoms in a molecule are first assigned to tetrahedra in groups of four atoms by Delaunay tetrahedrization adapted for efficient GPU implementation and the SASA values for atoms and molecules are calculated based on the tetrahedrization information and inclusion-exclusion method. The SASA values from the numerical icosahedral-based method can be reproduced with more than 98% accuracy for both proteins and RNAs. Having been implemented on GPUs and incorporated into the software Amber, we can apply dSASA to implicit solvent molecular dynamics simulations with inclusion of this nonpolar term. The current GPU version of GB/SA simulations has been accelerated up to nearly 20-fold compared to the CPU version and it outperforms LCPO as the system size increases. The performance and importance of the nonpolar part in implicit solvent modeling are demonstrated in GB/SA simulations of proteins and accurate SASA calculation of nucleic acids.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10462"
    },
    {
        "doc_id": 764,
        "title": "Ecosystem models cannot predict the consequences of conservation decisions",
        "authors": [
            "Larissa Lubiana Botelho",
            "Cailan Jeynes-Smith",
            "Sarah Vollert",
            "Michael Bode"
        ],
        "subjects": [
            "Populations and Evolution",
            "Quantitative Methods"
        ],
        "abstract": "Ecosystem models are often used to predict the consequences of management decisions in applied ecology, including fisheries management and threatened species conservation. These models are high-dimensional, parameter-rich, and nonlinear, yet limited data is available to calibrate them, and they are rarely tested or validated. Consequently, the accuracy of their forecasts, and their utility as decision-support tools is a matter of debate. In this paper, we calibrate ecosystem models to time-series data from 110 different experimental microcosm ecosystems, each containing between three and five interacting species. We then assess how often these calibrated models offer accurate and useful predictions about how the ecosystem will respond to a set of standard management interventions. Our results show that for each timeseries dataset, a large number of very different parameter sets offer equivalent, good fits. However, these calibrated ecosystem models have poor predictive accuracy when forecasting future dynamics and offer ambiguous predictions about how species in the ecosystem will respond to management interventions. Closer inspection reveals that the ecosystem models fail because calibration cannot determine the types of interactions that occur within the ecosystem. Our findings call into question claims that ecosystem modelling can support applied ecological decision-making when they are calibrated against real-world datasets.",
        "comments": "23 pages (main text + supplementary material) 9 figures (main text + supplementary material)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10439"
    },
    {
        "doc_id": 765,
        "title": "Diffusion of intrinsically disordered proteins within viscoelastic membraneless droplets",
        "authors": [
            "Fuga Watanabe",
            "Takuma Akimoto",
            "Robert B. Best",
            "Kresten Lindorff-Larsen",
            "Ralf Metzler",
            "Eiji Yamamoto"
        ],
        "subjects": [
            "Soft Condensed Matter",
            "Statistical Mechanics",
            "Biological Physics",
            "Computational Physics",
            "Biomolecules"
        ],
        "abstract": "In living cells, intrinsically disordered proteins (IDPs), such as FUS and DDX4, undergo phase separation, forming biomolecular condensates. Using molecular dynamics simulations, we investigate their behavior in their respective homogenous droplets. We find that the proteins exhibit transient subdiffusion due to the viscoelastic nature and confinement effects in the droplets. The conformation and the instantaneous diffusivity of the proteins significantly vary between the interior and the interface of the droplet, resulting in non-Gaussianity in the displacement distributions. This study highlights key aspects of IDP behavior in biomolecular condensates.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10438"
    },
    {
        "doc_id": 766,
        "title": "Exploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies",
        "authors": [
            "Gang Qu",
            "Anton Orlichenko",
            "Junqi Wang",
            "Gemeng Zhang",
            "Li Xiao",
            "Aiying Zhang",
            "Zhengming Ding",
            "Yu-Ping Wang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Artificial Intelligence"
        ],
        "abstract": "Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined graph structure to depict associations between brain regions, a detail not solely provided by FCs. To bridge this gap, we introduce the Gated Graph Transformer (GGT) framework, designed to predict cognitive metrics based on FCs. Empirical validation on the Philadelphia Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of our model, further accentuating its potential in identifying pivotal neural connectivities that correlate with human cognitive processes.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10348"
    },
    {
        "doc_id": 767,
        "title": "DrugAssist: A Large Language Model for Molecule Optimization",
        "authors": [
            "Geyan Ye",
            "Xibao Cai",
            "Houtim Lai",
            "Xing Wang",
            "Junhong Huang",
            "Longyue Wang",
            "Wei Liu",
            "Xiangxiang Zeng"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Computation and Language",
            "Machine Learning"
        ],
        "abstract": "Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called MolOpt-Instructions for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.",
        "comments": "Geyan Ye and Xibao Cai are equal contributors; Longyue Wang is corresponding author",
        "date": "28 December, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10334"
    },
    {
        "doc_id": 768,
        "title": "Fine scale depth regulation of invertebrate larvae around coastal fronts",
        "authors": [
            "Nicolas Weidberg",
            "Wayne Goschen",
            "Jennifer M. Jackson",
            "Paula Pattrick",
            "Christopher D. McQuaid",
            "Francesca Porri"
        ],
        "subjects": [
            "Quantitative Methods"
        ],
        "abstract": "Vertical migrations of zooplankters have been widely described, but their active movements through shallow, highly dynamic water columns within the inner shelf may be more complex and difficult to characterize. In this study, invertebrate larvae, currents, and hydrographic variables were sampled at different depths during and after the presence of fronts on three different cruises off the southern coast of South Africa. Internal wave dynamics were observed in the hydrographic data set but also through satellite imagery, although strong surface convergent currents were absent and thermal stratification was weak. During the first two cruises, fronts were more conspicuous and they preceded strong onshore currents at depth which developed with the rising tide. Vertical distributions of larvae changed accordingly, with higher abundances at these deep layers once the front disappeared. The third cruise was carried out during slack tides, the front was not conspicuous, deep strong onshore currents did not occur afterward and larval distributions did not change consistently through time. Overall, the vertical distributions of many larval taxa matched the vertical profiles of shoreward currents and multivariate analyses revealed that these flows structured the larval community, which was neither influenced by temperature nor chlorophyll. Thus, the ability to regulate active vertical positioning may enhance shoreward advection and determine nearshore larval distributions.",
        "comments": "Journal ref:        Limnology and Oceanography. 64 - 2, pp. 785 - 802, 2019",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10303"
    },
    {
        "doc_id": 769,
        "title": "Forecasting dengue outbreaks with uncertainty using seasonal weather patterns",
        "authors": [
            "Piumi Chathurangika",
            "Sanjeewa Perera",
            "Kushani De Silva"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Dengue is a vector-borne disease transmitted to humans by vectors of genus Aedes and is a global threat with health, social, and economic impact in many of the tropical countries including Sri Lanka. The virus transmission is significantly impacted by environmental conditions, with a notable contribution from elevated per-capita vector density. These conditions are dynamic in nature and specially having the tropical climate, Sri Lanka experiences seasonal weather patterns dominated by monsoons. In this work, we investigate the dynamic influence of environmental conditions on dengue emergence in Colombo district where dengue is extremely prevalent in Sri Lanka. A novel approach leveraging the Markov chain Monte Carlo simulations has been employed to identify seasonal patterns of dengue disease emergence, utilizing the dynamics of weather patterns governing in the region. The newly developed algorithm allows us to estimate the timing of dengue outbreaks with uncertainty, enabling accurate forecasts of upcoming disease emergence patterns for better preparedness.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10295"
    },
    {
        "doc_id": 770,
        "title": "Mechanisms of nearshore retention and offshore export of mussel larvae over the Agulhas Bank",
        "authors": [
            "Nicolas Weidberg",
            "Francesca Porri",
            "Charles von der Meden",
            "Jennifer M. Jackson",
            "Wayne Goschen",
            "Christopher McQuaid"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "Ecological connectivity is critical for population dynamics but in many benthic species it is complicated by a planktonic larval phase, whose dispersal remains poorly understood. Using a plankton pump, we examine the distribution of intertidal mussel larvae along three axes: alongshore, cross-shelf and by depth during a large scale (600 km) cruise over the Agulhas Bank off southern Africa in August/September 2010. As a general pattern, higher veliger abundances were found close to the coast. Our analyses of the nearshore flow, estimated from ADCP data and the vertical distribution of larvae, show that onshore larval retention may be mediated by active vertical swimming through the water column guided by light and wind-induced turbulence. A massive offshore export of larvae off St Francis Bay was, however, observed during an Agulhas Current meander which influenced inner shelf waters. We hypothesize that, by increasing and homogenizing flow, the Agulhas Current may erase the effects of larval vertical positioning on onshore retention and transport larvae offshore. Our study highlights the need to integrate the effects of complex, region-specific physical dynamics with the swimming behaviour of larvae in order to explain their spatial distribution, population connectivity and the consequences for population dynamics.",
        "comments": "Journal ref:        Journal of Plankton Research. 37 - 6, pp. 1166 - 1180. Oxford Journals, 11/2015",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10292"
    },
    {
        "doc_id": 771,
        "title": "Analyzing Brain Activity During Learning Tasks with EEG and Machine Learning",
        "authors": [
            "Ryan Cho",
            "Mobasshira Zaman",
            "Kyu Taek Cho",
            "Jaejin Hwang"
        ],
        "subjects": [
            "Signal Processing",
            "Machine Learning",
            "Neurons and Cognition"
        ],
        "abstract": "This study aimed to analyze brain activity during various STEM activities, exploring the feasibility of classifying between different tasks. EEG brain data from twenty subjects engaged in five cognitive tasks were collected and segmented into 4-second clips. Power spectral densities of brain frequency waves were then analyzed. Testing different k-intervals with XGBoost, Random Forest, and Bagging Classifier revealed that Random Forest performed best, achieving a testing accuracy of 91.07% at an interval size of two. When utilizing all four EEG channels, cognitive flexibility was most recognizable. Task-specific classification accuracy showed the right frontal lobe excelled in mathematical processing and planning, the left frontal lobe in cognitive flexibility and mental flexibility, and the left temporoparietal lobe in connections. Notably, numerous connections between frontal and temporoparietal lobes were observed during STEM activities. This study contributes to a deeper understanding of implementing machine learning in analyzing brain activity and sheds light on the brain's mechanisms.",
        "comments": "20 pages, 7 figures",
        "date": "15 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10285"
    },
    {
        "doc_id": 772,
        "title": "EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model",
        "authors": [
            "Yuqi Chen",
            "Kan Ren",
            "Kaitao Song",
            "Yansen Wang",
            "Yifan Wang",
            "Dongsheng Li",
            "Lili Qiu"
        ],
        "subjects": [
            "Signal Processing",
            "Artificial Intelligence",
            "Machine Learning",
            "Multimedia",
            "Neurons and Cognition"
        ],
        "abstract": "Self-supervised learning has emerged as a highly effective approach in the fields of natural language processing and computer vision. It is also applicable to brain signals such as electroencephalography (EEG) data, given the abundance of available unlabeled data that exist in a wide spectrum of real-world medical applications ranging from seizure detection to wave analysis. The existing works leveraging self-supervised learning on EEG modeling mainly focus on pretraining upon each individual dataset corresponding to a single downstream task, which cannot leverage the power of abundant data, and they may derive sub-optimal solutions with a lack of generalization. Moreover, these methods rely on end-to-end model learning which is not easy for humans to understand. In this paper, we present a novel EEG foundation model, namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained model cannot only learn universal representations on EEG signals with adaptable performance on various downstream tasks but also provide interpretable outcomes of the useful patterns within the data. To validate the effectiveness of our model, we extensively evaluate it on various downstream tasks and assess the performance under different transfer settings. Furthermore, we demonstrate how the learned model exhibits transferable anomaly detection performance and provides valuable interpretability of the acquired patterns via self-supervised learning.",
        "comments": "A preprint version of an ongoing work",
        "date": "11 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10278"
    },
    {
        "doc_id": 773,
        "title": "Evolving Diploid Boolean and Multi-Valued Gene Networks",
        "authors": [
            "Larry Bull"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Boolean networks have been widely used to explore aspects of gene regulation, traditionally with a single network. A modified form of the model to explore the effects of increasing the number of gene states has also recently been introduced. In this paper, these discrete dynamical networks are evolved as diploids within rugged fitness landscapes to explore their behaviour. Results suggest the general properties of haploid networks in similar circumstances remain for diploids. The previously proposed inherent fitness landscape smoothing properties of eukaryotic sex are shown to be exhibited in these dynamical systems, as is their propensity to change in size based upon the characteristics of the network and fitness landscape.",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2302.01694",
        "date": "19 November, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.10237"
    },
    {
        "doc_id": 774,
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authors": [
            "Shengjie Luo",
            "Tianlang Chen",
            "Aditi S. Krishnapriyan"
        ],
        "subjects": [
            "Machine Learning",
            "Materials Science",
            "Group Theory",
            "Chemical Physics",
            "Biomolecules"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.",
        "comments": "36 pages; ICLR 2024 (Spotlight Presentation); Code: https://github.com/lsj2408/Gaunt-Tensor-Product",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10216"
    },
    {
        "doc_id": 775,
        "title": "Improving PTM Site Prediction by Coupling of Multi-Granularity Structure and Multi-Scale Sequence Representation",
        "authors": [
            "Zhengyi Li",
            "Menglu Li",
            "Lida Zhu",
            "Wen Zhang"
        ],
        "subjects": [
            "Quantitative Methods",
            "Artificial Intelligence",
            "Machine Learning"
        ],
        "abstract": "Protein post-translational modification (PTM) site prediction is a fundamental task in bioinformatics. Several computational methods have been developed to predict PTM sites. However, existing methods ignore the structure information and merely utilize protein sequences. Furthermore, designing a more fine-grained structure representation learning method is urgently needed as PTM is a biological event that occurs at the atom granularity. In this paper, we propose a PTM site prediction method by Coupling of Multi-Granularity structure and Multi-Scale sequence representation, PTM-CMGMS for brevity. Specifically, multigranularity structure-aware representation learning is designed to learn neighborhood structure representations at the amino acid, atom, and whole protein granularity from AlphaFold predicted structures, followed by utilizing contrastive learning to optimize the structure representations.Additionally, multi-scale sequence representation learning is used to extract context sequence information, and motif generated by aligning all context sequences of PTM sites assists the prediction. Extensive experiments on three datasets show that PTM-CMGMS outperforms the state-of-the-art methods.",
        "comments": " ",
        "date": "4 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10211"
    },
    {
        "doc_id": 776,
        "title": "Exploiting Hierarchical Interactions for Protein Surface Learning",
        "authors": [
            "Yiqun Lin",
            "Liang Pan",
            "Yi Li",
            "Ziwei Liu",
            "Xiaomeng Li"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning"
        ],
        "abstract": "Predicting interactions between proteins is one of the most important yet challenging problems in structural bioinformatics. Intrinsically, potential function sites in protein surfaces are determined by both geometric and chemical features. However, existing works only consider handcrafted or individually learned chemical features from the atom type and extract geometric features independently. Here, we identify two key properties of effective protein surface learning: 1) relationship among atoms: atoms are linked with each other by covalent bonds to form biomolecules instead of appearing alone, leading to the significance of modeling the relationship among atoms in chemical feature learning. 2) hierarchical feature interaction: the neighboring residue effect validates the significance of hierarchical feature interaction among atoms and between surface points and atoms (or residues). In this paper, we present a principled framework based on deep learning techniques, namely Hierarchical Chemical and Geometric Feature Interaction Network (HCGNet), for protein surface analysis by bridging chemical and geometric features with hierarchical interactions. Extensive experiments demonstrate that our method outperforms the prior state-of-the-art method by 2.3% in site prediction task and 3.2% in interaction matching task, respectively. Our code is available at https://github.com/xmed-lab/HCGNet.",
        "comments": "Accepted to J-BHI",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10144"
    },
    {
        "doc_id": 777,
        "title": "Correlating fluorescence microscopy, optical and magnetic tweezers to study single chiral biopolymers, tested on DNA plectoneme formation dynamics",
        "authors": [
            "Jack W Shepherd",
            "Sebastien Guilbaud",
            "Zhaokun Zhou",
            "Jamieson Howard",
            "Matthew Burman",
            "Charley Schaefer",
            "Adam Kerrigan",
            "Clare Steele-King",
            "Agnes Noy",
            "Mark C Leake"
        ],
        "subjects": [
            "Biological Physics",
            "Biomolecules"
        ],
        "abstract": "Biopolymer topology is critical for determining interactions inside cell environments, exemplified by DNA where its response to mechanical perturbation is as important as biochemical properties to its cellular roles. The dynamic structures of chiral biopolymers exhibit complex dependence with extension and torsion, however the physical mechanisms underpinning the emergence of structural motifs upon physiological twisting and stretching are poorly understood due to technological limitations in correlating force, torque and spatial localization information. We present COMBI-Tweez (Combined Optical and Magnetic BIomolecule TWEEZers), a transformative tool that overcomes these challenges by integrating optical trapping, time-resolved electromagnetic tweezers, and fluorescence microscopy, demonstrated on single DNA molecules, that can controllably form and visualise higher order structural motifs including plectonemes. This technology combined with cutting-edge MD simulations provides quantitative insight into complex dynamic structures relevant to DNA cellular processes and can be adapted to study a range of filamentous biopolymers.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10087"
    },
    {
        "doc_id": 778,
        "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue Heterogeneity",
        "authors": [
            "Anik Chaudhuri",
            "Anwoy Mohanty",
            "Manoranjan Satpathy"
        ],
        "subjects": [
            "Distributed, Parallel, and Cluster Computing",
            "Quantitative Methods"
        ],
        "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges in cancer diagnosis and treatment. Studying the heterogeneity in cell populations from gene expression measurement data in the context of cancer research is a problem of paramount importance. In addition, reducing the computation time of the algorithms that deal with high volumes of data has its obvious merits. Parallelizable models using Markov chain Monte Carlo methods are typically slow. This paper shows a novel, computationally efficient, and parallelizable model to analyze heterogeneity in cancer tissues using GPUs. Because our model is parallelizable, the input data size does not affect the computation time much, provided the hardware resources are not exhausted. Our model uses qPCR (quantitative polymerase chain reaction) gene expression measurements to study heterogeneity in cancer tissue. We compute the cell proportion breakup by accelerating variational methods on a GPU. We test this model on synthetic and real-world gene expression data collected from fibroblasts and compare the performance of our algorithm with those of MCMC and Expectation Maximization. Our new model is computationally less complex and faster than existing Bayesian models for cancer tissue heterogeneity.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10068"
    },
    {
        "doc_id": 779,
        "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation",
        "authors": [
            "Julia Camps",
            "Zhinuo Jenny Wang",
            "Ruben Doste",
            "Maxx Holmes",
            "Brodie Lawson",
            "Jakub Tomek",
            "Kevin Burrage",
            "Alfonso Bueno-Orovio",
            "Blanca Rodriguez"
        ],
        "subjects": [
            "Computational Engineering, Finance, and Science",
            "Tissues and Organs"
        ],
        "abstract": "Cardiac digital twins are computational tools capturing key functional and anatomical characteristics of patient hearts for investigating disease phenotypes and predicting responses to therapy. When paired with large-scale computational resources and large clinical datasets, digital twin technology can enable virtual clinical trials on virtual cohorts to fast-track therapy development. Here, we present an automated pipeline for personalising ventricular anatomy and electrophysiological function based on routinely acquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead electrocardiogram (ECG). Using CMR-based anatomical models, a sequential Monte-Carlo approximate Bayesian computational inference method is extended to infer electrical activation and repolarisation characteristics from the ECG. Fast simulations are conducted with a reaction-Eikonal model, including the Purkinje network and biophysically-detailed subcellular ionic current dynamics for repolarisation. For each patient, parameter uncertainty is represented by inferring a population of ventricular models rather than a single one, which means that parameter uncertainty can be propagated to therapy evaluation. Furthermore, we have developed techniques for translating from reaction-Eikonal to monodomain simulations, which allows more realistic simulations of cardiac electrophysiology. The pipeline is demonstrated in a healthy female subject, where our inferred reaction-Eikonal models reproduced the patient's ECG with a Pearson's correlation coefficient of 0.93, and the translated monodomain simulations have a correlation coefficient of 0.89. We then apply the effect of Dofetilide to the monodomain population of models for this subject and show dose-dependent QT and T-peak to T-end prolongations that are in keeping with large population drug response data.",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10029"
    },
    {
        "doc_id": 780,
        "title": "An optimization-based equilibrium measure describes non-equilibrium steady state dynamics: application to edge of chaos",
        "authors": [
            "Junbin Qiu",
            "Haiping Huang"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Statistical Mechanics",
            "Neural and Evolutionary Computing"
        ],
        "abstract": "Understanding neural dynamics is a central topic in machine learning, non-linear physics and neuroscience. However, the dynamics is non-linear, stochastic and particularly non-gradient, i.e., the driving force can not be written as gradient of a potential. These features make analytic studies very challenging. The common tool is to use path integral approach or dynamical mean-field theory, but the drawback is one has to solve the integro-differential or dynamical mean-field equations, which is computationally expensive and has no closed form solutions in general. From the aspect of associated Fokker-Planck equation, the steady state solution is generally unknown. Here, we treat searching for the steady state as an optimization problem, and construct an approximate potential closely related to the speed of the dynamics, and find that searching for the ground state of this potential is equivalent to running a stochastic gradient dynamics. The resultant stationary state follows exactly the canonical Boltzmann measure. Within this framework, the quenched disorder intrinsic in the neural networks can be averaged out by applying the replica method. Our theory reproduces the well-known result of edge-of-chaos, and further the order parameters characterizing the continuous transition are derived, and different scaling behavior with respect to inverse temperature in both sides of the transition is also revealed. Our method opens the door to analytically study the steady state landscape of the deterministic or stochastic high dimensional dynamics.",
        "comments": "16 pages, 7 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.10009"
    },
    {
        "doc_id": 781,
        "title": "Artificial Intelligence-based algorithms in medical image scan seg-mentation and intelligent visual-content generation -- a concise overview",
        "authors": [
            "Zofia Rudnicka",
            "Janusz Szczepanski",
            "Agnieszka Pregowska"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Recently, Artificial Intelligence (AI)-based algorithms have revolutionized the medical image segmentation processes. Thus, the precise segmentation of organs and their lesions may contribute to an efficient diagnostics process and a more effective selection of targeted therapies as well as increasing the effectiveness of the training process. In this context, AI may contribute to the automatization of the image scan segmentation process and increase the quality of the resulting 3D objects, which may lead to the generation of more realistic virtual objects. In this paper, we focus on the AI-based solutions applied in the medical image scan segmentation, and intelligent visual-content generation, i.e. computer-generated three-dimensional (3D) images in the context of Extended Reality (XR). We consider different types of neural networks used with a special emphasis on the learning rules applied, taking into account algorithm accuracy and performance, as well as open data availability. This paper attempts to summarize the current development of AI-based segmentation methods in medical imaging and intelligent visual content generation that are applied in XR. It concludes also with possible developments and open challenges in AI application in Extended Reality-based solutions. Finally, the future lines of research and development directions of Artificial Intelligence applications both in medical image segmentation and Extended Reality-based medical solutions are discussed",
        "comments": " ",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09857"
    },
    {
        "doc_id": 782,
        "title": "FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction",
        "authors": [
            "Alexander Telepov",
            "Artem Tsypin",
            "Kuzma Khrabrov",
            "Sergey Yakukhnov",
            "Pavel Strashnov",
            "Petr Zhilyaev",
            "Egor Rumiantsev",
            "Daniel Ezhov",
            "Manvel Avetisian",
            "Olga Popova",
            "Artur Kadurin"
        ],
        "subjects": [
            "Biomolecules",
            "Machine Learning",
            "Machine Learning"
        ],
        "abstract": "A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.",
        "comments": "37 pages, 10 figures, to be published in TMLR journal (https://www.jmlr.org/tmlr/)",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09840"
    },
    {
        "doc_id": 783,
        "title": "The impact of Covid-19 vaccination in Aotearoa New Zealand: a modelling study",
        "authors": [
            "Samik Datta",
            "Giorgia Vattiato",
            "Oliver J Maclaren",
            "Ning Hua",
            "Andrew Sporle",
            "Michael J Plank"
        ],
        "subjects": [
            "Populations and Evolution",
            "Physics and Society"
        ],
        "abstract": "Aotearoa New Zealand implemented a Covid-19 elimination strategy in 2020 and 2021, which enabled a large majority of the population to be vaccinated before being exposed to the virus. This strategy delivered one of the lowest pandemic mortality rates in the world. However, quantitative estimates of the population-level health benefits of vaccination are lacking. Here, we use a validated mathematical model to investigate counterfactual scenarios with differing levels of vaccine coverage in different age and ethnicity groups. The model builds on earlier research by adding age- and time-dependent case ascertainment, the effect of antiviral medications, improved hospitalisation rate estimates, and the impact of relaxing control measures. The model was used for scenario analysis and policy advice for the New Zealand Government in 2022 and 2023. We compare the number of Covid-19 hospitalisations, deaths, and years of life lost in each counterfactual scenario to a baseline scenario that is fitted to epidemiological data between January 2022 and June 2023. Our results estimate that vaccines saved 6650 (95% credible interval [4424, 10180]) lives, and prevented 74500 [51000, 115400] years of life lost and 45100 [34400, 55600] hospitalisations during this 18-month period. Making the same comparison before the benefit of antiviral medications is accounted for, the estimated number of lives saved by vaccines increases to 7604 [5080, 11942]. Due to inequities in the vaccine rollout, vaccination rates among M\u0101ori were lower than in people of European ethnicity. Our results show that, if vaccination rates had been equitable, an estimated 11-26% of the 292 M\u0101ori Covid-19 deaths that were recorded in this time period could have been prevented. We conclude that Covid-19 vaccination greatly reduced health burden in New Zealand and that equity needs to be a key focus of future vaccination programmes.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09679"
    },
    {
        "doc_id": 784,
        "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery",
        "authors": [
            "Tian-Le Yang",
            "Kuang-Yao Lee",
            "Kun Zhang",
            "Joe Suzuki"
        ],
        "subjects": [
            "Machine Learning",
            "Statistics Theory",
            "Neurons and Cognition",
            "Methodology"
        ],
        "abstract": "In causal discovery, non-Gaussianity has been used to characterize the complete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM), encompassing both the causal ordering of variables and their respective connection strengths. However, LiNGAM can only deal with the finite-dimensional case. To expand this concept, we extend the notion of variables to encompass vectors and even functions, leading to the Functional Linear Non-Gaussian Acyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify causal relationships in brain-effective connectivity tasks involving, for example, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to handle these inherently infinite-dimensional datasets and explain the availability of functional data analysis from both empirical and theoretical perspectives. {We establish theoretical guarantees of the identifiability of the causal relationship among non-Gaussian random vectors and even random functions in infinite-dimensional Hilbert spaces.} To address the issue of sparsity in discrete time points within intrinsic infinite-dimensional functional data, we propose optimizing the coordinates of the vectors using functional principal component analysis. Experimental results on synthetic data verify the ability of the proposed framework to identify causal relationships among multivariate functions using the observed samples. For real data, we focus on analyzing the brain connectivity patterns derived from fMRI data.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09641"
    },
    {
        "doc_id": 785,
        "title": "Molecular causality in the advent of foundation models",
        "authors": [
            "Sebastian Lobentanzer",
            "Pablo Rodriguez-Mier",
            "Stefan Bauer",
            "Julio Saez-Rodriguez"
        ],
        "subjects": [
            "Molecular Networks"
        ],
        "abstract": "Correlation is not causation. As simple as this widely agreed-upon statement may seem, scientifically defining causality and using it to drive our modern biomedical research is immensely challenging. In this perspective, we attempt to synergise the partly disparate fields of systems biology, causal reasoning, and machine learning, to inform future approaches in the field of systems biology and molecular networks.",
        "comments": "22 pages, 0 figures, 87 references; submitted to MSB",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09558"
    },
    {
        "doc_id": 786,
        "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations of Disease Heterogeneity Through Machine Learning",
        "authors": [
            "Junhao Wen",
            "Mathilde Antoniades",
            "Zhijian Yang",
            "Gyujoon Hwang",
            "Ioanna Skampardoni",
            "Rongguang Wang",
            "Christos Davatzikos"
        ],
        "subjects": [
            "Machine Learning",
            "Image and Video Processing",
            "Quantitative Methods"
        ],
        "abstract": "Machine learning has been increasingly used to obtain individualized neuroimaging signatures for disease diagnosis, prognosis, and response to treatment in neuropsychiatric and neurodegenerative disorders. Therefore, it has contributed to a better understanding of disease heterogeneity by identifying disease subtypes that present significant differences in various brain phenotypic measures. In this review, we first present a systematic literature overview of studies using machine learning and multimodal MRI to unravel disease heterogeneity in various neuropsychiatric and neurodegenerative disorders, including Alzheimer disease, schizophrenia, major depressive disorder, autism spectrum disorder, multiple sclerosis, as well as their potential in transdiagnostic settings. Subsequently, we summarize relevant machine learning methodologies and discuss an emerging paradigm which we call dimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological heterogeneity of neuropsychiatric and neurodegenerative disorders into a low dimensional yet informative, quantitative brain phenotypic representation, serving as a robust intermediate phenotype (i.e., endophenotype) largely reflecting underlying genetics and etiology. Finally, we discuss the potential clinical implications of the current findings and envision future research avenues.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09517"
    },
    {
        "doc_id": 787,
        "title": "Is the Emergence of Life an Expected Phase Transition in the Evolving Universe?",
        "authors": [
            "Stuart Kauffman",
            "Andrea Roli"
        ],
        "subjects": [
            "Populations and Evolution",
            "Biological Physics"
        ],
        "abstract": "We propose a novel definition of life in terms of which its emergence in the universe is expected, and its ever-creative open-ended evolution is entailed by no law. Living organisms are Kantian Wholes that achieve Catalytic Closure, Constraint Closure, and Spatial Closure. We here unite for the first time two established mathematical theories, namely Collectively Autocatalytic Sets and the Theory of the Adjacent Possible. The former establishes that a first-order phase transition to molecular reproduction is expected in the chemical evolution of the universe where the diversity and complexity of molecules increases; the latter posits that, under loose hypotheses, if the system starts with a small number of beginning molecules, each of which can combine with copies of itself or other molecules to make new molecules, over time the number of kinds of molecules increases slowly but then explodes upward hyperbolically. Together these theories imply that life is expected as a phase transition in the evolving universe. The familiar distinction between software and hardware loses its meaning in living cells. We propose new ways to study the phylogeny of metabolisms, new astronomical ways to search for life on exoplanets, new experiments to seek the emergence of the most rudimentary life, and the hint of a coherent testable pathway to prokaryotes with template replication and coding.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09514"
    },
    {
        "doc_id": 788,
        "title": "Role of Upwelling on Larval Dispersal and Productivity of Gooseneck Barnacle Populations in the Cantabrian Sea: Management Implications",
        "authors": [
            "Antonella Rivera",
            "Nicolas Weidberg",
            "Antonio F. Pardi\u00f1as",
            "Ricardo Gonzalez-Gil",
            "Luc\u0131a Garc\u0131a- Florez",
            "Jose Luis Acu\u00f1a"
        ],
        "subjects": [
            "Populations and Evolution"
        ],
        "abstract": "The effect of coastal upwelling on the recruitment and connectivity of coastal marine populations has rarely been characterized to a level of detail to be included into sound fishery management strategies. The gooseneck barnacle (Pollicipes pollicipes) fishery at the Cantabrian Coast (Northern Spain) is located at the fringes of the NW Spanish Upwelling system. This fishery is being co-managed through a fine-scale, interspersed set of protected rocks where each rock receives a distinct level of protection. Such interspersion is potentially beneficial, but the extent to which such spacing is consistent with mean larval dispersal distances is as yet unknown. We have simulated the spread of gooseneck barnacle larvae in the Central Cantabrian Coast using a high-resolution time-series of current profiles measured at a nearshore location. During a year of high upwelling activity (2009), theoretical recruitment success was 94% with peak recruitment predicted 56 km west of the emission point. However, for a year of low upwelling activity (2011) theoretical recruitment success dropped to 15.4% and peak recruitment was expected 13 km east of the emission point. This is consistent with a positive correlation between catch rates and the Integrated Upwelling Index, using a 4-year lag to allow recruits to reach commercial size. Furthermore, a net long-term westward larval transport was estimated by means of mitochondrial cytochrome c oxidase subunit I (COI) sequences for five populations in the Cantabrian Sea. Our results call into question the role of long distance dispersal, driven by the mesoscale processes in the area, in gooseneck barnacle populations and point to the prevalent role of small-scale, asymmetric connectivity more consistent with the typical scale of the co-management process in this fishery.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09513"
    },
    {
        "doc_id": 789,
        "title": "A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation",
        "authors": [
            "Nianzu Yang",
            "Kaipeng Zeng",
            "Haotian Lu",
            "Yexin Wu",
            "Zexin Yuan",
            "Shengdian Jiang",
            "Jiaxiang Wu",
            "Yimin Wang",
            "Junchi Yan"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "Neuronal morphology is essential for studying brain functioning and understanding neurodegenerative disorders. As the acquiring of real-world morphology data is expensive, computational approaches especially learning-based ones e.g. MorphVAE for morphology generation were recently studied, which are often conducted in a way of randomly augmenting a given authentic morphology to achieve plausibility. Under such a setting, this paper proposes \\textbf{MorphGrower} which aims to generate more plausible morphology samples by mimicking the natural growth mechanism instead of a one-shot treatment as done in MorphVAE. Specifically, MorphGrower generates morphologies layer by layer synchronously and chooses a pair of sibling branches as the basic generation block, and the generation of each layer is conditioned on the morphological structure of previous layers and then generate morphologies via a conditional variational autoencoder with spherical latent space. Extensive experimental results on four real-world datasets demonstrate that MorphGrower outperforms MorphVAE by a notable margin. Our code will be publicly available to facilitate future research.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09500"
    },
    {
        "doc_id": 790,
        "title": "Gene-associated Disease Discovery Powered by Large Language Models",
        "authors": [
            "Jiayu Chang",
            "Shiyu Wang",
            "Chen Ling",
            "Zhaohui Qin",
            "Liang Zhao"
        ],
        "subjects": [
            "Quantitative Methods",
            "Information Retrieval"
        ],
        "abstract": "The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations.",
        "comments": "This is the official paper accepted by AAAI 2024 Workshop on Large Language Models for Biological Discoveries",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09490"
    },
    {
        "doc_id": 791,
        "title": "The Interplay Between Logical Phenomena and the Cognitive System of the Mind",
        "authors": [
            "Kazem Haghnejad Azar"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "In this article, we employ mathematical concepts as a tool to examine the phenomenon of consciousness experience and logical phenomena. Through our investigation, we aim to demonstrate that our experiences, while not confined to limitations, cannot be neatly encapsulated within a singular collection. Our conscious experience emerges as a result of the developmental and augmentative trajectory of our cognitive system. As our cognitive abilities undergo refinement and advancement, our capacity for logical thinking likewise evolves, thereby manifesting a heightened level of conscious experience. The primary objective of this article is to embark upon a profound exploration of the concept of logical experience, delving into the intricate process by which these experiences are derived from our mind.",
        "comments": " ",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09465"
    },
    {
        "doc_id": 792,
        "title": "Diffusion-Driven Generative Framework for Molecular Conformation Prediction",
        "authors": [
            "Bobin Yang",
            "Jie Deng",
            "Zhenghan Chen",
            "Ruoxue Wu"
        ],
        "subjects": [
            "Biomolecules",
            "Artificial Intelligence",
            "Machine Learning",
            "Chemical Physics"
        ],
        "abstract": "The task of deducing three-dimensional molecular configurations from their two-dimensional graph representations holds paramount importance in the fields of computational chemistry and pharmaceutical development. The rapid advancement of machine learning, particularly within the domain of deep generative networks, has revolutionized the precision of predictive modeling in this context. Traditional approaches often adopt a two-step strategy: initially estimating interatomic distances and subsequently refining the spatial molecular structure by solving a distance geometry problem. However, this sequential approach occasionally falls short in accurately capturing the intricacies of local atomic arrangements, thereby compromising the fidelity of the resulting structural models. Addressing these limitations, this research introduces a cutting-edge generative framework named \\method{}. This framework is grounded in the principles of diffusion observed in classical non-equilibrium thermodynamics. \\method{} views atoms as discrete entities and excels in guiding the reversal of diffusion, transforming a distribution of stochastic noise back into coherent molecular structures through a process akin to a Markov chain. This transformation commences with the initial representation of a molecular graph in an abstract latent space, culminating in the realization of three-dimensional structures via a sophisticated bilevel optimization scheme meticulously tailored to meet the specific requirements of the task. One of the formidable challenges in this modeling endeavor involves preserving roto-translational invariance to ensure that the generated molecular conformations adhere to the laws of physics. Extensive experimental evaluations confirm the efficacy of the proposed \\method{} in comparison to state-of-the-art methods.",
        "comments": "arXiv admin note: text overlap with arXiv:2105.07246 by other authors",
        "date": "21 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09451"
    },
    {
        "doc_id": 793,
        "title": "Regenerative Medicine for Tendon/Ligament Injuries: De Novo Equine Tendon/Ligament Neotissue Generation and Application",
        "authors": [
            "Takashi Taguchi"
        ],
        "subjects": [
            "Tissues and Organs"
        ],
        "abstract": "Tendon and ligament injuries are debilitating conditions across species. Poor regenerative capacities of these tissues limit restoration of original functions. The first study of this dissertation evaluated the effect of cellular administration on tendon/ligament injuries in horses using meta-analysis. The findings led to the second study that engineered implantable de novo tendon neotissue using equine adipose-derived multipotent stromal cells and collagen type I. The neotendon was evaluated for its biocompatibility and therapeutic potential in the third study using immunocompetent and immunocompromised rat bilateral calcaneal tendon elongation model. The fourth study investigated the therapeutic effects of neotendon in surgically-induced non-terminal equine accessory ligament of deep digital flexor tendon injury model.",
        "comments": " ",
        "date": "24 October, 2023",
        "pdf_url": "https://arxiv.org/pdf/2401.09423"
    },
    {
        "doc_id": 794,
        "title": "PERMUTOOLS: A MATLAB Package for Multivariate Permutation Testing",
        "authors": [
            "Michael J. Crosse",
            "John J. Foxe",
            "Sophie Molholm"
        ],
        "subjects": [
            "Methodology",
            "Quantitative Methods",
            "Computation"
        ],
        "abstract": "Statistical hypothesis testing and effect size measurement are routine parts of quantitative research. Advancements in computer processing power have greatly improved the capability of statistical inference through the availability of resampling methods. However, many of the statistical practices used today are based on traditional, parametric methods that rely on assumptions about the underlying population. These assumptions may not always be valid, leading to inaccurate results and misleading interpretations. Permutation testing, on the other hand, generates the sampling distribution empirically by permuting the observed data, providing distribution-free hypothesis testing. Furthermore, this approach lends itself to a powerful method for multiple comparison correction - known as max correction - which is less prone to type II errors than conventional correction methods. Parametric methods have also traditionally been utilized for estimating the confidence interval of various test statistics and effect size measures. However, these too can be estimated empirically using permutation or bootstrapping techniques. Whilst resampling methods are generally considered preferable, many popular programming languages and statistical software packages lack efficient implementations. Here, we introduce PERMUTOOLS, a MATLAB package for multivariate permutation testing and effect size measurement.",
        "comments": "7 pages, 2 figures, for PERMUTOOLS toolbox, see https://github.com/mickcrosse/PERMUTOOLS",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09401"
    },
    {
        "doc_id": 795,
        "title": "Graph-based vulnerability assessment of resting-state functional brain networks in full-term neonates",
        "authors": [
            "Mahshid Fouladivanda",
            "Kamran Kazemi",
            "Habibollah Danyali",
            "Ardalan Aarabi"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Quantitative Methods"
        ],
        "abstract": "Network disruption during early brain development can result in long-term cognitive impairments. In this study, we investigated rich-club organization in resting-state functional brain networks in full-term neonates using a multiscale connectivity analysis. We further identified the most influential nodes, also called spreaders, having higher impacts on the flow of information throughout the network. The network vulnerability to damage to rich-club (RC) connectivity within and between resting-state networks was also assessed using a graph-based vulnerability analysis. Our results revealed a rich club organization and small-world topology for resting-state functional brain networks in full term neonates, regardless of the network size. Interconnected mostly through short-range connections, functional rich-club hubs were confined to sensory-motor, cognitive-attention-salience (CAS), default mode, and language-auditory networks with an average cross-scale overlap of 36%, 20%, 15% and 12%, respectively. The majority of the functional hubs also showed high spreading potential, except for several non-RC spreaders within CAS and temporal networks. The functional networks exhibited high vulnerability to loss of RC nodes within sensorimotor cortices, resulting in a significant increase and decrease in network segregation and integration, respectively. The network vulnerability to damage to RC nodes within the language-auditory, cognitive-attention-salience, and default mode networks was also significant but relatively less prominent. Our findings suggest that the network integration in neonates can be highly compromised by damage to RC connectivity due to brain immaturity.",
        "comments": " ",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09255"
    },
    {
        "doc_id": 796,
        "title": "Reproducibility via neural fields of visual illusions induced by localized stimuli",
        "authors": [
            "Cyprien Tamekue",
            "Dario Prandi",
            "Yacine Chitour"
        ],
        "subjects": [
            "Neurons and Cognition",
            "Analysis of PDEs",
            "Numerical Analysis",
            "Pattern Formation and Solitons"
        ],
        "abstract": "This paper investigates the replication of experiments by Billock and Tsou [PNAS, 2007] using the controllability of neural fields of Amari-type modelling the cortical activity in the primary visual cortex (V1), focusing on a regular funnel pattern localised in the fovea or the peripheral visual field. The aim is to understand and model the visual phenomena observed in these experiments, emphasising their nonlinear nature. The study involves designing sensory inputs simulating the visual stimuli from Billock and Tsou's experiments. The after-images induced by these inputs are then theoretically and numerically studied to determine their capacity to replicate the experimentally observed visual effects. A key aspect of this research is investigating the effects induced by the nonlinear nature of neural responses. In particular, by highlighting the importance of both excitatory and inhibitory neurons in the emergence of certain visual phenomena, this study suggests that an interplay of both types of neuronal activities plays an essential role in visual processes, challenging the assumption that the latter is mainly driven by excitatory activities alone.",
        "comments": "MSC Class:          92C20; 35B36; 45A05; 45G15; 45K05; 65R20",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09108"
    },
    {
        "doc_id": 797,
        "title": "A hybrid tau-leap for simulating chemical kinetics with applications to parameter estimation",
        "authors": [
            "Thomas Trigo Trindade",
            "Konstantinos C. Zygalakis"
        ],
        "subjects": [
            "Molecular Networks",
            "Numerical Analysis",
            "Computation"
        ],
        "abstract": "We consider the problem of efficiently simulating stochastic models of chemical kinetics. The Gillespie Stochastic Simulation algorithm (SSA) is often used to simulate these models, however, in many scenarios of interest, the computational cost quickly becomes prohibitive. This is further exasperated in the Bayesian inference context when estimating parameters of chemical models, as the intractability of the likelihood requires multiple simulations of the underlying system. To deal with issues of computational complexity in this paper, we propose a novel hybrid $\u03c4$-leap algorithm for simulating well-mixed chemical systems. In particular, the algorithm uses $\u03c4$-leap when appropriate (high population densities), and SSA when necessary (low population densities, when discrete effects become non-negligible). In the intermediate regime, a combination of the two methods, which leverages the properties of the underlying Poisson formulation, is employed. As illustrated through a number of numerical experiments the hybrid $\u03c4$ offers significant computational savings when compared to SSA without however sacrificing the overall accuracy. This feature is particularly welcomed in the Bayesian inference context, as it allows for parameter estimation of stochastic chemical kinetics at reduced computational cost.",
        "comments": "25 pages, 8 figures",
        "date": "18 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.09097"
    },
    {
        "doc_id": 798,
        "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction",
        "authors": [
            "Ziyang Yu",
            "Wenbing Huang",
            "Yang Liu"
        ],
        "subjects": [
            "Machine Learning",
            "Biomolecules"
        ],
        "abstract": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods and is strongly competitive with current state-of-the-art learning-based models such as DiffDock-PP and Multimer particularly for antibody-antigen docking.",
        "comments": "ICLR 2024",
        "date": "17 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08986"
    },
    {
        "doc_id": 799,
        "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
        "authors": [
            "Zahra Sheikhbahaee",
            "Adam Safron",
            "Casper Hesp",
            "Guillaume Dumas"
        ],
        "subjects": [
            "Neurons and Cognition"
        ],
        "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
        "comments": " ",
        "date": "16 January, 2024",
        "pdf_url": "https://arxiv.org/pdf/2401.08873"
    }
]